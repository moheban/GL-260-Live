# GL-260 Data Analysis and Plotter
# Version: v3.0.7
# Date: 2026-02-17

import os
import sys
import logging
from logging.handlers import RotatingFileHandler


def _supports_free_threading_build():
    """Check whether free threading build is supported.
    Used to gate optional capabilities in the workflow."""
    return hasattr(sys, "_is_gil_enabled")


def _current_gil_status():
    """Return current GIL status.
    Used to surface GIL status for downstream logic."""
    if hasattr(sys, "_is_gil_enabled"):
        try:
            return bool(sys._is_gil_enabled())
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
    return None


def _is_running_under_vscode():
    """Check whether it is running under vscode.
    Used to gate conditional behavior in the workflow."""
    return "VSCODE_PID" in os.environ or os.environ.get("TERM_PROGRAM") == "vscode"


_STARTUP_GIL_STATUS = _current_gil_status()
_GIL_IMPORT_REENABLES = []
_GIL_IMPORT_STATUS = _STARTUP_GIL_STATUS


def _note_gil_reenable(module_name, before_status):
    """Record GIL reenable.
    Used to track diagnostic state during startup."""
    after_status = _current_gil_status()
    if before_status is False and after_status is True:
        _GIL_IMPORT_REENABLES.append(module_name)
    return after_status


import matplotlib.pyplot as plt

_GIL_IMPORT_STATUS = _note_gil_reenable("matplotlib", _GIL_IMPORT_STATUS)

from matplotlib.axes import Axes
from matplotlib.figure import Figure

from matplotlib.backends.backend_agg import FigureCanvasAgg
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.lines import Line2D
from matplotlib.transforms import Bbox, blended_transform_factory

from matplotlib.ticker import FuncFormatter, ScalarFormatter
from matplotlib import font_manager, mathtext
from matplotlib.ft2font import FT2Font

import great_tables as gt

_GIL_IMPORT_STATUS = _note_gil_reenable("great_tables", _GIL_IMPORT_STATUS)

import pandas as pd

_GIL_IMPORT_STATUS = _note_gil_reenable("pandas", _GIL_IMPORT_STATUS)

import numpy as np

_GIL_IMPORT_STATUS = _note_gil_reenable("numpy", _GIL_IMPORT_STATUS)

import tkinter as tk

from tkinter import (
    ttk,
    filedialog,
    messagebox,
    scrolledtext,
    simpledialog,
    colorchooser,
)

try:
    import customtkinter as ctk  # type: ignore
except Exception:  # pragma: no cover - optional dependency
    ctk = None


def _ui_button(parent, *args, **kwargs):
    """Create a button using CTk when available, else ttk.

    Purpose:
        Provide one compatibility constructor for push-button controls.
    Why:
        Stage-wise CTk migration requires preserving existing callbacks and layout
        code while avoiding repeated availability checks in each UI builder.
    Args:
        parent: Parent widget that owns the button.
        *args: Positional arguments accepted by ttk/CTk constructors.
        **kwargs: Keyword arguments such as text, command, width, and state.
    Returns:
        Widget instance (`ctk.CTkButton` or `ttk.Button`).
    Side Effects:
        None beyond widget construction.
    Exceptions:
        Unsupported CTk-only/ttk-only kwargs are ignored on the CTk branch.
    """
    if ctk is None:
        return ttk.Button(parent, *args, **kwargs)
    ctk_kwargs = dict(kwargs)
    ctk_kwargs.pop("style", None)
    ctk_kwargs.pop("padding", None)
    return ctk.CTkButton(parent, *args, **ctk_kwargs)


def _ui_checkbutton(parent, *args, **kwargs):
    """Create a checkbutton using CTk when available, else ttk.

    Purpose:
        Normalize checkbutton creation across ttk and CTk toolkits.
    Why:
        CTk migration should not force callback/business-logic rewrites.
    Args:
        parent: Parent widget that owns the checkbutton.
        *args: Positional constructor args.
        **kwargs: Keyword args including text, variable, command, and state.
    Returns:
        Widget instance (`ctk.CTkCheckBox` or `ttk.Checkbutton`).
    Side Effects:
        None beyond widget construction.
    Exceptions:
        ttk-specific style kwargs are ignored on the CTk branch.
    """
    if ctk is None:
        return ttk.Checkbutton(parent, *args, **kwargs)
    ctk_kwargs = dict(kwargs)
    ctk_kwargs.pop("style", None)
    ctk_kwargs.pop("padding", None)
    return ctk.CTkCheckBox(parent, *args, **ctk_kwargs)


def _ui_radiobutton(parent, *args, **kwargs):
    """Create a radio button using CTk when available, else ttk.

    Purpose:
        Provide one constructor for mutually-exclusive choice controls.
    Why:
        Reduces repetitive conditional widget creation in migrated dialogs/tabs.
    Args:
        parent: Parent widget for the radiobutton.
        *args: Positional constructor args.
        **kwargs: Keyword args such as text, value, variable, and command.
    Returns:
        Widget instance (`ctk.CTkRadioButton` or `ttk.Radiobutton`).
    Side Effects:
        None beyond widget construction.
    Exceptions:
        ttk-only style kwargs are ignored on the CTk branch.
    """
    if ctk is None:
        return ttk.Radiobutton(parent, *args, **kwargs)
    ctk_kwargs = dict(kwargs)
    ctk_kwargs.pop("style", None)
    ctk_kwargs.pop("padding", None)
    return ctk.CTkRadioButton(parent, *args, **ctk_kwargs)


def _normalize_ctk_input_width(width_value: Any) -> Any:
    """Normalize entry/combobox width when constructing CTk widgets.

    Purpose:
        Translate legacy ttk-style character widths into readable CTk pixel widths.
    Why:
        The codebase historically uses ttk width values (character units), while CTk
        interprets width in pixels. Without conversion, migrated inputs can render as
        one-character boxes and become difficult to use.
    Args:
        width_value: Width value from widget kwargs (usually int/float, sometimes None).
    Returns:
        A pixel width for CTk-compatible numeric inputs, or the original value when
        conversion is not applicable.
    Side Effects:
        None.
    Exceptions:
        Invalid or non-numeric values are passed through unchanged.
    """
    if isinstance(width_value, bool) or not isinstance(width_value, (int, float)):
        return width_value
    if width_value <= 0:
        return width_value
    width_int = int(round(float(width_value)))
    # Widths at or below this threshold are most likely legacy ttk character widths.
    if width_int <= 60:
        return max(96, (width_int * 8) + 24)
    return width_int


def _ui_entry(parent, *args, **kwargs):
    """Create an entry widget using CTk when available, else ttk.

    Purpose:
        Unify text-entry construction across ttk and CTk.
    Why:
        Keeps existing grid/pack wiring intact during incremental migration.
    Args:
        parent: Parent widget that owns the entry.
        *args: Positional constructor args.
        **kwargs: Keyword args, including `textvariable`, `width`, and `state`.
    Returns:
        Widget instance (`ctk.CTkEntry` or `ttk.Entry`).
    Side Effects:
        None beyond widget construction.
    Exceptions:
        ttk-specific style kwargs are ignored on the CTk branch.
    """
    if ctk is None:
        return ttk.Entry(parent, *args, **kwargs)
    ctk_kwargs = dict(kwargs)
    if str(ctk_kwargs.get("state", "")).strip().lower() == "readonly":
        ctk_kwargs["state"] = "disabled"
    if "width" in ctk_kwargs:
        normalized_width = _normalize_ctk_input_width(ctk_kwargs.get("width"))
        if normalized_width is None:
            ctk_kwargs.pop("width", None)
        else:
            ctk_kwargs["width"] = normalized_width
    ctk_kwargs.pop("style", None)
    ctk_kwargs.pop("padding", None)
    return ctk.CTkEntry(parent, *args, **ctk_kwargs)


def _ui_combobox(parent, *args, **kwargs):
    """Create a combobox using CTk when available, else ttk.

    Purpose:
        Provide a toolkit-agnostic constructor for dropdown selectors.
    Why:
        CTk and ttk use different keyword names (`variable` vs `textvariable`);
        this helper normalizes the call-site contract.
    Args:
        parent: Parent widget that owns the combobox.
        *args: Positional constructor args.
        **kwargs: Keyword args such as values, textvariable/variable, width, state.
    Returns:
        Widget instance (`ctk.CTkComboBox` or `ttk.Combobox`).
    Side Effects:
        None beyond widget construction.
    Exceptions:
        Unsupported kwargs are ignored on the CTk branch.
    """
    if ctk is None:
        return ttk.Combobox(parent, *args, **kwargs)

    ctk_kwargs = dict(kwargs)
    user_command = ctk_kwargs.pop("command", None)
    text_var = ctk_kwargs.pop("textvariable", None)
    explicit_var = ctk_kwargs.pop("variable", None)
    if explicit_var is None and text_var is not None:
        ctk_kwargs["variable"] = text_var
    elif explicit_var is not None:
        ctk_kwargs["variable"] = explicit_var
    ctk_kwargs.pop("style", None)
    ctk_kwargs.pop("padding", None)
    ctk_kwargs.pop("postcommand", None)
    if "width" in ctk_kwargs:
        normalized_width = _normalize_ctk_input_width(ctk_kwargs.get("width"))
        if normalized_width is None:
            ctk_kwargs.pop("width", None)
        else:
            ctk_kwargs["width"] = normalized_width
    widget = ctk.CTkComboBox(parent, *args, **ctk_kwargs)

    def _dispatch(selection_value: Any) -> None:
        """Dispatch CTk combobox selection to command and virtual event hooks."""
        if callable(user_command):
            try:
                user_command(selection_value)
            except TypeError:
                user_command()
        try:
            widget.event_generate("<<ComboboxSelected>>")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    try:
        widget.configure(command=_dispatch)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    return widget


def _ui_scrollbar(parent, *args, **kwargs):
    """Create a scrollbar using CTk when available, else ttk.

    Purpose:
        Standardize vertical/horizontal scrollbar creation during migration.
    Why:
        Scrollable layouts appear in multiple tabs and dialogs with shared logic.
    Args:
        parent: Parent widget that owns the scrollbar.
        *args: Positional constructor args.
        **kwargs: Keyword args such as orient/orientation and command.
    Returns:
        Widget instance (`ctk.CTkScrollbar` or `ttk.Scrollbar`).
    Side Effects:
        None beyond widget construction.
    Exceptions:
        Orientation keyword is normalized for CTk when needed.
    """
    if ctk is None:
        return ttk.Scrollbar(parent, *args, **kwargs)

    ctk_kwargs = dict(kwargs)
    orientation = ctk_kwargs.pop("orient", None)
    if orientation is None:
        orientation = ctk_kwargs.get("orientation", None)
    if orientation is not None:
        ctk_kwargs["orientation"] = orientation
    ctk_kwargs.pop("style", None)
    return ctk.CTkScrollbar(parent, *args, **ctk_kwargs)


def _ui_scale(parent, *args, **kwargs):
    """Create a slider/scale using CTk when available, else ttk.

    Purpose:
        Provide one constructor for numeric slider controls.
    Why:
        Some migrated tabs use scales heavily and should adopt CTk styling when
        available without changing callback logic.
    Args:
        parent: Parent widget that owns the scale.
        *args: Positional constructor args.
        **kwargs: Keyword args including from_/to, variable, and command.
    Returns:
        Widget instance (`ctk.CTkSlider` or `ttk.Scale`).
    Side Effects:
        None beyond widget construction.
    Exceptions:
        Non-horizontal orientation falls back to ttk for compatibility.
    """
    if ctk is None:
        return ttk.Scale(parent, *args, **kwargs)
    orientation = kwargs.get("orient")
    if orientation not in (None, "horizontal", tk.HORIZONTAL):
        return ttk.Scale(parent, *args, **kwargs)
    ctk_kwargs = dict(kwargs)
    ctk_kwargs.pop("orient", None)
    ctk_kwargs.pop("style", None)
    ctk_kwargs.pop("length", None)
    return ctk.CTkSlider(parent, *args, **ctk_kwargs)

import json
import csv
import contextlib
import importlib
import platform
from datetime import datetime

import base64
import io
import math
import copy
import re
import textwrap

from pathlib import Path

import shutil

import threading

import time

import traceback

import tempfile

import unicodedata

import uuid

from concurrent.futures import ThreadPoolExecutor

from collections import OrderedDict

from dataclasses import asdict, dataclass, field, replace

from functools import lru_cache, partial

from tkinter import font as tkfont

from typing import (
    Any,
    Callable,
    Dict,
    Iterable,
    List,
    Mapping,
    Optional,
    Sequence,
    Set,
    Self,
    Tuple,
    Union,
)

from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk

from matplotlib.widgets import SpanSelector

import ctypes

try:
    _gil_before_mplcursors = _current_gil_status()
    import mplcursors  # type: ignore

    _note_gil_reenable("mplcursors", _gil_before_mplcursors)
except Exception:  # pragma: no cover - optional dependency
    mplcursors = None

from solubility_models import (
    SOL_KA1,
    SOL_KA2,
    SOL_KW,
    SOL_KSP_NAHCO3,
    SOL_KSP_NA2CO3,
    SOL_SATURATION_TOL,
    SOL_DAVIES_LIMIT,
    SOL_DAVIES_COEFF,
    SOL_ACTIVITY_EXTRAPOLATION_LIMIT,
    SOL_MW_NAHCO3,
    SOL_MW_NA2CO3,
    SOL_MW_NAOH,
    SOL_MW_CO2,
    SOL_A_DEBYE,
    SOL_B_DEBYE,
    SOL_WATER_DENSITY_25C_G_PER_ML,
    SOL_HEADSPACE_DEFAULT_PCO2_ATM,
    SOL_DEFAULT_SENSITIVITY_PCT,
    SOL_PH_SWEEP_DEFAULT,
    SOL_PKA1_COEFFS,
    SOL_PKA2_COEFFS,
    SOL_SPECIES_MOLAR_MASSES,
    SOL_GLOSSARY_ENTRIES,
    SOLUBILITY_PRESETS,
    CYCLE_TRACKER_NOTE_PREFIX,
    SOL_ION_CHARGES,
    SOL_ION_SIZES_NM,
    SolubilityInputs,
    SolubilitySpeciationResult,
    SolubilityMathStep,
    SolubilityMathLogger,
    DEFAULT_SOLUBILITY_INPUTS,
    ModelMetadata,
    ModelOptions,
    SpeciationModel,
    ClosedCarbonateInputs,
    solve_closed_carbonate_system,
    generate_closed_system_curve,
    register_speciation_model,
    get_speciation_model,
    list_speciation_models,
    DEFAULT_SPEC_MODEL_KEY,
)

_NAOH_PITZER_MODULE = None
_NAOH_PITZER_IMPORT_ERROR = None
try:
    _gil_before_pitzer = _current_gil_status()
    import naoh_co2_pitzer_ph_model as _naoh_pitzer_module

    _note_gil_reenable("naoh_co2_pitzer_ph_model", _gil_before_pitzer)
except Exception as exc:  # pragma: no cover - optional dependency
    _NAOH_PITZER_IMPORT_ERROR = exc
    _naoh_pitzer_module = None
    print(f"[WARN] NaOH-CO2 Pitzer model unavailable; module import failed: {exc}")
_NAOH_PITZER_MODULE = _naoh_pitzer_module

_PREFERRED_PLOT_FONT = "STIXGeneral"
_FONT_FALLBACKS = ("DejaVu Serif", "DejaVu Sans", "Segoe UI Symbol")
_REQUIRED_FONT_GLYPHS = "₀₁₂₃₄₅₆₇₈₉¹²³⁻"
CYCLE_TIMELINE_EXPORT_DEFAULT_TITLE = "Cycle Speciation Timeline"

DEFAULT_TAB_ORDER_KEYS = (
    "data",
    "columns",
    "plot",
    "cycle",
    "contamination",
    "solubility",
    "solubility_new",
    "final_report",
)
STARTUP_REQUIRED_TAB_KEYS = (
    "data",
    "columns",
    "plot",
    "cycle",
    "solubility_new",
    "final_report",
)


def _dependency_audit_targets() -> List[str]:
    """Perform dependency audit targets.
    Used to keep the workflow logic localized and testable."""
    return [
        "numpy",
        "pandas",
        "matplotlib",
        "openpyxl",
        "great_tables",
        "scipy",
        "mplcursors",
    ]


def _audit_dependency_import(name: str) -> Dict[str, Any]:
    """Import value.
    Used by audit dependency workflows to import value."""
    before = _current_gil_status()
    record: Dict[str, Any] = {
        "name": name,
        "imported": False,
        "version": None,
        "gil_before": before,
        "gil_after": None,
        "gil_changed": False,
        "error": None,
    }
    try:
        module = importlib.import_module(name)
        record["imported"] = True
        version = getattr(module, "__version__", None)
        if version is None:
            version = getattr(module, "VERSION", None)
        if version is not None:
            record["version"] = str(version)
    except Exception as exc:
        record["error"] = str(exc)
        record["gil_after"] = _current_gil_status()
        record["gil_changed"] = bool(before is False and record["gil_after"] is True)
        return record
    after = _current_gil_status()
    record["gil_after"] = after
    record["gil_changed"] = bool(before is False and after is True)
    return record


def _run_dependency_audit() -> Dict[str, Any]:
    """Run dependency audit.
    Used to execute dependency audit and coordinate results."""
    report: Dict[str, Any] = {
        "timestamp": datetime.now().isoformat(),
        "python_version": sys.version,
        "platform": platform.platform(),
        "free_threading_supported": _supports_free_threading_build(),
        "gil_status": _current_gil_status(),
        "dependencies": [],
    }
    # Iterate over _dependency_audit_targets() to apply the per-item logic.
    for name in _dependency_audit_targets():
        report["dependencies"].append(_audit_dependency_import(name))
    return report


class TkTaskRunner:
    def __init__(self, tk_root: tk.Misc, max_workers: int = 1) -> None:
        """Initialize TkTaskRunner instance.
        Used at object creation to configure initial state and bindings."""
        self._root = tk_root
        self._max_workers = max(1, int(max_workers))
        self._executor = ThreadPoolExecutor(max_workers=self._max_workers)
        self._lock = threading.Lock()
        self._task_counter = 0
        self._latest_task_id: Dict[str, int] = {}
        self._latest_future: Dict[str, Any] = {}
        self._futures: Dict[int, Any] = {}

    def set_max_workers(self, max_workers: int) -> None:
        """Set max workers.
        Used to persist max workers into the current state."""
        max_workers = max(1, int(max_workers))
        if max_workers == self._max_workers:
            return
        self._max_workers = max_workers
        old_executor = self._executor
        self._executor = ThreadPoolExecutor(max_workers=self._max_workers)
        try:
            old_executor.shutdown(wait=False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def submit(
        self,
        task_name: str,
        fn: Callable[[], Any],
        on_ok: Optional[Callable[[Any], None]],
        on_err: Optional[Callable[[BaseException], None]],
    ) -> int:
        """Perform submit.
        Used to keep the workflow logic localized and testable."""
        with self._lock:
            self._task_counter += 1
            task_id = self._task_counter
            previous_future = self._latest_future.get(task_name)
            self._latest_task_id[task_name] = task_id
        if previous_future is not None:
            try:
                previous_future.cancel()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        future = self._executor.submit(fn)
        with self._lock:
            self._latest_future[task_name] = future
            self._futures[task_id] = future

        def _handle_result(fut) -> None:
            """Handle result.
            Used as an event callback for result."""
            with self._lock:
                is_latest = self._latest_task_id.get(task_name) == task_id
            if not is_latest:
                return
            try:
                result = fut.result()
            except Exception as exc:  # pragma: no cover - background thread
                if on_err is not None:
                    on_err(exc)
                return
            if on_ok is not None:
                on_ok(result)

        future.add_done_callback(lambda fut: self._root.after(0, _handle_result, fut))
        return task_id


def _get_font_path(font_name: str) -> Optional[str]:
    """Return font path.
    Used to retrieve font path for downstream logic."""
    lowered = font_name.lower()
    try:
        # Iterate over font_manager.fontManager.ttflist to apply the per-item logic.
        for entry in font_manager.fontManager.ttflist:
            if entry.name.lower() == lowered:
                return entry.fname
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    try:
        return font_manager.findfont(font_name, fallback_to_default=False)
    except TypeError:
        try:
            path = font_manager.findfont(font_name)
        except Exception:
            return None
        return path if lowered in os.path.basename(path).lower() else None
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None


def _font_supports_required_glyphs(font_name: str) -> bool:
    """Check whether required glyphs is supported.
    Used by font workflows to check required glyphs."""
    path = _get_font_path(font_name)
    if not path:
        return False
    try:
        face = FT2Font(path)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return False
    return all(face.get_char_index(ord(ch)) != 0 for ch in _REQUIRED_FONT_GLYPHS)


@lru_cache(maxsize=1)
def _preferred_plot_font_stack() -> Tuple[str, ...]:
    """Perform preferred plot font stack.
    Used to keep the workflow logic localized and testable."""
    fonts: List[str] = []
    if _font_supports_required_glyphs(_PREFERRED_PLOT_FONT):
        fonts.append(_PREFERRED_PLOT_FONT)
    # Iterate over _FONT_FALLBACKS to apply the per-item logic.
    for fallback_name in _FONT_FALLBACKS:
        if fallback_name not in fonts:
            fonts.append(fallback_name)
    if not fonts:
        fonts.extend(plt.rcParams.get("font.serif", []))
    return tuple(fonts)


def _apply_default_plot_fonts(font_family: Optional[str] = None) -> None:
    """Apply default plot fonts.
    Used to apply default plot fonts changes to live state."""
    stack = list(_preferred_plot_font_stack())
    family_value = (font_family or "").strip()
    if family_value:
        plt.rcParams["font.family"] = family_value
        if family_value not in stack:
            stack = [family_value] + stack
        if stack:
            existing_serif = [
                name for name in plt.rcParams.get("font.serif", []) if name not in stack
            ]
            plt.rcParams["font.serif"] = stack + existing_serif
        return
    if not stack:
        return
    plt.rcParams["font.family"] = stack
    existing_serif = [
        name for name in plt.rcParams.get("font.serif", []) if name not in stack
    ]
    plt.rcParams["font.serif"] = stack + existing_serif


_apply_default_plot_fonts()


def _enforce_axis_text_style(
    ax,
    *,
    font_family: str = "",
    tick_fontsize: Optional[float] = None,
    label_fontsize: Optional[float] = None,
) -> None:
    """Perform enforce axis text style.
    Used to keep the workflow logic localized and testable."""
    if ax is None:
        return
    if tick_fontsize is not None:
        try:
            ax.tick_params(axis="both", which="major", labelsize=tick_fontsize)
            ax.tick_params(axis="both", which="minor", labelsize=tick_fontsize)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
    labels = []
    try:
        labels.extend(ax.get_xticklabels())
        labels.extend(ax.get_yticklabels())
        labels.extend(ax.get_xticklabels(minor=True))
        labels.extend(ax.get_yticklabels(minor=True))
    except Exception:
        labels = list(ax.get_xticklabels()) + list(ax.get_yticklabels())
    # Iterate over labels to apply the per-item logic.
    for lbl in labels:
        try:
            if tick_fontsize is not None:
                lbl.set_fontsize(tick_fontsize)
            if font_family:
                lbl.set_fontfamily(font_family)
        except Exception:
            continue
    # Iterate over (ax.xaxis.get_offset_text(), ax.yaxis.get_offset_text()) to apply the per-item logic.
    for offset_text in (ax.xaxis.get_offset_text(), ax.yaxis.get_offset_text()):
        try:
            if tick_fontsize is not None:
                offset_text.set_fontsize(tick_fontsize)
            if font_family:
                offset_text.set_fontfamily(font_family)
        except Exception:
            continue
    # Iterate over (ax.xaxis.label, ax.yaxis.label) to apply the per-item logic.
    for axis_label in (ax.xaxis.label, ax.yaxis.label):
        try:
            if label_fontsize is not None:
                axis_label.set_fontsize(label_fontsize)
            if font_family:
                axis_label.set_fontfamily(font_family)
        except Exception:
            continue


_TITLE_FONT_DEBUG_CHECKED = False


def _resolve_fontsize_points(value, default: float = 12.0) -> float:
    """Resolve fontsize points.
    Used to compute fontsize points before rendering or export."""
    try:
        if value is None:
            return float(default)
        if isinstance(value, (int, float)):
            size = float(value)
            if math.isfinite(size) and size > 0.0:
                return size
            return float(default)
        if isinstance(value, str):
            cleaned = value.strip()
            if not cleaned:
                return float(default)
            try:
                size = float(cleaned)
            except Exception:
                size = None
            if size is not None and math.isfinite(size) and size > 0.0:
                return float(size)
            try:
                return float(
                    font_manager.FontProperties(size=cleaned).get_size_in_points()
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                base = float(plt.rcParams.get("font.size", default))
            except Exception:
                base = float(default)
            try:
                scale = font_manager.font_scalings.get(cleaned.lower())
            except Exception:
                scale = None
            if scale is not None:
                try:
                    return float(base) * float(scale)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    return float(default)
        try:
            size = float(value)
            if math.isfinite(size) and size > 0.0:
                return size
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return float(default)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return float(default)


def _debug_title_font_resolution_once() -> None:
    """Perform debug title font resolution once.
    Used to keep the workflow logic localized and testable."""
    global _TITLE_FONT_DEBUG_CHECKED
    if not DEBUG_TITLE_FONT_RESOLVE or _TITLE_FONT_DEBUG_CHECKED:
        return
    _TITLE_FONT_DEBUG_CHECKED = True
    try:
        samples = ("large", "medium", 12, "nonsense")
        results = [_resolve_fontsize_points(value, default=12.0) for value in samples]
        if not all(isinstance(value, float) for value in results):
            print("[TitleSize] font size resolution returned non-float")
    except Exception as exc:
        print(f"[TitleSize] font size resolution check failed: {exc}")


def _center_titles_to_axes_union(
    fig: Figure,
    axes: Sequence[Optional[Axes]],
    title: Optional[str],
    suptitle: Optional[str],
    title_fs: Optional[float],
    suptitle_fs: Optional[float],
    font_family: str,
    title_pad_pts: float,
    suptitle_pad_pts: float,
    *,
    suptitle_y: Optional[float] = None,
) -> None:
    """Center titles to axes union.
    Used to align titles to axes union within layout bounds."""
    if fig is None:
        return
    _debug_title_font_resolution_once()
    axes_list: List[Axes] = []
    # Iterate over axes or [] to apply the per-item logic.
    for axis in axes or []:
        if axis is None:
            continue
        try:
            if not axis.get_visible():
                continue
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if getattr(axis, "_gl260_legend_only", False):
            continue
        try:
            if not axis.axison and not axis.has_data():
                continue
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        axes_list.append(axis)
    primary_axis = None
    # Title transform parity with combined rendering:
    # the layout solver repositions titles in axes coordinates, so non-combined
    # plots must keep title artists axes-bound (ax.set_title), not fig.text.
    if axes_list:
        # Iterate over axes_list to apply the per-item logic.
        for axis in axes_list:
            if getattr(axis, "_gl260_axis_role", None) == "primary":
                primary_axis = axis
                break
        if primary_axis is None:
            primary_axis = axes_list[0]
        try:
            bbox = Bbox.union([axis.get_position() for axis in axes_list])
            center_x = (bbox.x0 + bbox.x1) / 2.0
        except Exception:
            center_x = 0.5
    else:
        center_x = 0.5

    # Iterate over axes_list to apply the per-item logic.
    for axis in axes_list:
        try:
            axis.set_title("")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    # Remove stale figure-level and axes-bound title artists before rebuilding.
    for attr in ("_gl260_title_text", "_gl260_suptitle_text"):
        existing = getattr(fig, attr, None)
        if existing is not None:
            try:
                owner_ax = getattr(existing, "axes", None)
                if owner_ax is not None:
                    try:
                        existing.set_text("")
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                else:
                    existing.remove()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            setattr(fig, attr, None)
    old_suptitle = getattr(fig, "_suptitle", None)
    if old_suptitle is not None:
        try:
            old_suptitle.remove()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
    try:
        fig._suptitle = None
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    fig_h_pts = max(fig.get_size_inches()[1] * 72.0, 1.0)
    if title_fs is not None:
        title_fs_value = _resolve_fontsize_points(title_fs, default=12.0)
    else:
        title_fs_value = _resolve_fontsize_points(
            plt.rcParams.get("axes.titlesize", 12.0), default=12.0
        )
    if suptitle_fs is not None:
        suptitle_fs_value = _resolve_fontsize_points(suptitle_fs, default=12.0)
    else:
        suptitle_fs_value = _resolve_fontsize_points(
            plt.rcParams.get("figure.titlesize", 12.0), default=12.0
        )

    dy_suptitle = float(suptitle_pad_pts or 0.0) / fig_h_pts

    def _clamp_y(value: float) -> float:
        """Clamp y.
        Used to keep y within safe bounds."""
        return max(0.0, min(1.05, value))

    title_text = (title or "").strip()
    suptitle_text = (suptitle or "").strip()

    title_artist = None
    if title_text:
        if primary_axis is not None:
            title_kwargs: Dict[str, Any] = {
                "fontsize": title_fs_value,
                "pad": float(title_pad_pts or 0.0),
            }
            if font_family:
                title_kwargs["fontfamily"] = font_family
            try:
                title_artist = primary_axis.set_title(title_text, **title_kwargs)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                title_artist = None
        if title_artist is None:
            # Fallback for figures without data axes.
            title_kwargs_fallback: Dict[str, Any] = {
                "ha": "center",
                "va": "top",
                "fontsize": title_fs_value,
            }
            if font_family:
                title_kwargs_fallback["fontfamily"] = font_family
            title_artist = fig.text(0.5, 0.98, title_text, **title_kwargs_fallback)

    suptitle_artist = None
    if suptitle_text:
        if suptitle_y is None:
            y_suptitle = 0.98
        else:
            y_suptitle = float(suptitle_y) + dy_suptitle
        y_suptitle = _clamp_y(y_suptitle)
        suptitle_kwargs: Dict[str, Any] = {
            "fontsize": suptitle_fs_value,
            "x": center_x,
            "y": y_suptitle,
        }
        if font_family:
            suptitle_kwargs["fontfamily"] = font_family
        suptitle_artist = fig.suptitle(suptitle_text, **suptitle_kwargs)

    fig._gl260_title_text = title_artist
    fig._gl260_suptitle_text = suptitle_artist
    fig._suptitle = suptitle_artist
    fig._gl260_title_state = {
        "title": title_text,
        "suptitle": suptitle_text,
        "title_fs": title_fs_value,
        "suptitle_fs": suptitle_fs_value,
        "font_family": font_family,
        "title_pad_pts": title_pad_pts,
        "suptitle_pad_pts": suptitle_pad_pts,
        "suptitle_y": suptitle_y,
    }
    if fig.canvas is None:
        FigureCanvasAgg(fig)
    try:
        fig.canvas.draw()
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass


def _filter_installed_fonts(candidates: Sequence[str]) -> List[str]:
    """Filter installed fonts.
    Used to remove non-relevant entries from installed fonts."""
    filtered: List[str] = []
    # Iterate over candidates to apply the per-item logic.
    for candidate in candidates:
        name = (candidate or "").strip()
        if not name or name in filtered:
            continue
        try:
            font_manager.findfont(name, fallback_to_default=False)
        except TypeError:
            lowered = name.lower()
            if any(
                entry.name.lower() == lowered
                # Iterate to apply the per-item logic.
                for entry in font_manager.fontManager.ttflist
            ):
                filtered.append(name)
        except Exception:
            continue
        else:
            filtered.append(name)
    if "DejaVu Serif" not in filtered:
        filtered.append("DejaVu Serif")
    return filtered


def _normalize_elapsed_time_unit(value: Any) -> str:
    """Normalize elapsed time unit.
    Used to keep elapsed time unit consistent across workflows and persistence."""
    if isinstance(value, str):
        normalized = value.strip().lower()
        if normalized in ELAPSED_TIME_UNITS:
            return normalized
    return DEFAULT_ELAPSED_TIME_UNIT


def _normalize_title_type_list(value: Any) -> List[str]:
    """Normalize title type list.
    Used to keep title type list consistent across workflows and persistence."""
    if not isinstance(value, (list, tuple)):
        return list(DEFAULT_TITLE_TYPES)
    normalized: List[str] = []
    seen: Set[str] = set()
    # Iterate over value to apply the per-item logic.
    for raw in value:
        name = str(raw).strip() if raw is not None else ""
        if not name:
            continue
        key = name.casefold()
        if key in seen:
            continue
        seen.add(key)
        normalized.append(name)
    if not normalized:
        return list(DEFAULT_TITLE_TYPES)
    return normalized


def _normalize_mpl_color(value: Any) -> str:
    """Normalize Matplotlib color.
    Used to keep Matplotlib color consistent across workflows and persistence."""
    try:
        from matplotlib import colors as mcolors
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return "#000000"
    try:
        if value is None:
            return "#000000"
        if isinstance(value, str):
            stripped = value.strip()
            if not stripped:
                return "#000000"
            lowered = stripped.lower()
            if lowered in {"none", "transparent"}:
                return "#000000"
            value = stripped
        return mcolors.to_hex(mcolors.to_rgba(value), keep_alpha=False)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return "#000000"


ANNOTATION_MODES = (
    "select",
    "text",
    "callout",
    "arrow",
    "point",
    "xspan",
    "xspan_label",
    "trace_mask",
    "trace_start",
    "rect",
    "ref_line",
    "ink",
    "erase",
)

ANNOTATION_TYPE_LABELS = {
    "text": "Text",
    "callout": "Callout",
    "arrow": "Arrow",
    "point": "Point / Marker",
    "xspan": "X-Span",
    "xspan_label": "Span + Label",
    "trace_mask": "Trace Mask",
    "trace_start": "Trace Start",
    "rect": "Box Region",
    "ref_line": "Reference Line",
    "ink": "Freehand",
}

TRACE_SERIES_KEYS: Tuple[str, ...] = ("y1", "y3", "y2", "z", "z2")


def _normalize_trace_series_key(value: Any, default: str = "y2") -> str:
    """Normalize a trace-series key for behavior plot elements.
    Used to keep trace-targeted behavior elements constrained to known series keys."""
    fallback_raw = "" if default is None else str(default).strip().lower()
    if fallback_raw in TRACE_SERIES_KEYS:
        fallback = fallback_raw
    elif fallback_raw == "":
        fallback = ""
    else:
        fallback = "y2"
    if not isinstance(value, str):
        return fallback
    candidate = value.strip().lower()
    if candidate in TRACE_SERIES_KEYS:
        return candidate
    return fallback


def _trace_series_option_pairs() -> List[Tuple[str, str]]:
    """Return display/value pairs for trace-target selectors.
    Used by Add Element and Properties editors to show consistent trace choices."""
    return [
        ("Reactor Pressure (y1)", "y1"),
        ("Manifold Pressure (y3)", "y3"),
        ("Derivative (y2)", "y2"),
        ("Internal Temperature (z)", "z"),
        ("External Temperature (z2)", "z2"),
    ]

ANNOTATION_DEFAULT_ZORDER = 10
ANNOTATION_SPAN_BACKGROUND_ZORDER = 0.9
ANNOTATION_STYLE_PRESETS = {
    "highlight": {
        "facecolor": "#ffd166",
        "edgecolor": "#f4a261",
        "color": "#f4a261",
        "alpha": 0.35,
        "linewidth": 1.6,
        "text_color": "#1f1f1f",
        "bbox_facecolor": "#fff3c4",
        "bbox_edgecolor": "#f4a261",
        "bbox_alpha": 0.85,
    },
    "outline": {
        "facecolor": "none",
        "edgecolor": "#1f77b4",
        "color": "#1f77b4",
        "alpha": 1.0,
        "linewidth": 2.0,
        "text_color": "#1f77b4",
        "bbox_facecolor": "none",
        "bbox_edgecolor": "#1f77b4",
        "bbox_alpha": 1.0,
    },
    "callout": {
        "color": "#1f77b4",
        "text_color": "#1f77b4",
        "linewidth": 1.6,
        "bbox_facecolor": "#f5f5f5",
        "bbox_edgecolor": "#1f77b4",
        "bbox_alpha": 0.9,
        "arrowstyle": "->",
    },
}


def _canonicalize_annotation_type(value: str) -> Optional[str]:
    """Perform canonicalize annotation type.
    Used to keep the workflow logic localized and testable."""
    if not isinstance(value, str):
        return None
    lowered = value.strip().lower()
    if lowered in ANNOTATION_TYPE_LABELS:
        return lowered
    mapping = {
        "xspan_text": "xspan_label",
        "span_label": "xspan_label",
        "span+label": "xspan_label",
        "span_label_text": "xspan_label",
        "tracemask": "trace_mask",
        "trace mask": "trace_mask",
        "trace-mask": "trace_mask",
        "mask": "trace_mask",
        "tracestart": "trace_start",
        "trace start": "trace_start",
        "trace-start": "trace_start",
        "start_x": "trace_start",
        "freehand": "ink",
        "ink": "ink",
        "rectangle": "rect",
        "rect_region": "rect",
        "box_region": "rect",
        "reference_line": "ref_line",
        "refline": "ref_line",
    }
    return mapping.get(lowered)


def _default_annotation_name(element_type: str, index: int) -> str:
    """Return default annotation name.
    Used when callers need a safe fallback."""
    base = ANNOTATION_TYPE_LABELS.get(element_type, "Annotation")
    return f"{base} {index + 1}"


def _normalize_axes_target(value: Any) -> str:
    """Normalize axes target.
    Used to keep axes target consistent across workflows and persistence."""
    if isinstance(value, str):
        lowered = value.strip().lower()
        if lowered in {"primary", "right", "third"}:
            return lowered
    return "primary"


def _coerce_float(value: Any) -> Optional[float]:
    """Coerce float.
    Used to force float into a safe type or range."""
    try:
        number = float(value)
    except (TypeError, ValueError):
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None
    if not math.isfinite(number):
        return None
    return number


def _style_float_from_style(
    style: Mapping[str, Any], key: str, default: float, minimum: float
) -> float:
    """Perform style float from style.
    Used to keep the workflow logic localized and testable."""
    value = _coerce_float(style.get(key))
    if value is None:
        value = default
    return max(minimum, value)


def _style_alpha_from_style(style: Mapping[str, Any], default: float = 0.9) -> float:
    """Perform style alpha from style.
    Used to keep the workflow logic localized and testable."""
    value = _coerce_float(style.get("alpha"))
    if value is None:
        value = default
    return max(0.0, min(1.0, value))


def _annotation_text_bbox_style(style: Mapping[str, Any]) -> Dict[str, Any]:
    """Perform annotation text bbox style.
    Used to keep the workflow logic localized and testable."""
    boxstyle = style.get("bbox_boxstyle") or style.get("boxstyle") or "round"
    pad = _style_float_from_style(style, "bbox_pad", 0.3, 0.0)
    bbox_alpha = _coerce_float(style.get("bbox_alpha"))
    if bbox_alpha is None:
        bbox_alpha = _style_alpha_from_style(style, 0.85)
    return {
        "boxstyle": f"{boxstyle},pad={pad}",
        "facecolor": style.get("bbox_facecolor", "white"),
        "edgecolor": style.get("bbox_edgecolor", "none"),
        "linewidth": _style_float_from_style(style, "bbox_linewidth", 1.0, 0.0),
        "linestyle": style.get("bbox_linestyle", "solid"),
        "alpha": bbox_alpha,
    }


def _wrap_text_for_display(
    ax: Axes,
    text_value: str,
    x: Optional[float],
    y: Optional[float],
    wrap_width_x: Optional[float],
    fontsize: float,
) -> str:
    """Wrap text for display.
    Used to format text for display to fit display constraints."""
    if not wrap_width_x or x is None or y is None:
        return text_value
    try:
        y_limits = ax.get_ylim()
        y_ref = y if y is not None else (y_limits[0] + y_limits[1]) / 2.0
        x0_disp = ax.transData.transform((x, y_ref))[0]
        x1_disp = ax.transData.transform((x + wrap_width_x, y_ref))[0]
        span_px = abs(x1_disp - x0_disp)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return text_value
    fig = ax.figure
    dpi = fig.dpi if fig is not None else 72.0
    fontsize_px = max(1.0, fontsize * dpi / 72.0)
    pad_px = max(4.0, fontsize_px * 0.6)
    usable_px = max(1.0, span_px - pad_px)
    avg_char_px = max(4.0, fontsize_px * 0.6)
    max_chars = max(1, int(usable_px / avg_char_px))
    wrapped_lines = []
    # Iterate over str(text_value).splitlines() to apply the per-item logic.
    for line in str(text_value).splitlines():
        if not line:
            wrapped_lines.append("")
            continue
        wrapped_lines.extend(textwrap.fill(line, width=max_chars).splitlines())
    return "\n".join(wrapped_lines)


def _normalize_annotation_style(value: Any) -> Dict[str, Any]:
    """Normalize annotation style.
    Used to keep annotation style consistent across workflows and persistence."""
    return dict(value) if isinstance(value, dict) else {}


def _normalize_annotation_geometry(value: Any) -> Dict[str, Any]:
    """Normalize annotation geometry.
    Used to keep annotation geometry consistent across workflows and persistence."""
    return dict(value) if isinstance(value, dict) else {}


def _migrate_legacy_geometry(
    element_type: str, element: Mapping[str, Any]
) -> Dict[str, Any]:
    """Perform migrate legacy geometry.
    Used to keep the workflow logic localized and testable."""
    geometry: Dict[str, Any] = {}
    data = element.get("data")
    if not isinstance(data, dict):
        data = {}
    if element_type == "text":
        geometry["x"] = _coerce_float(data.get("x"))
        geometry["y"] = _coerce_float(data.get("y"))
        geometry["text"] = str(data.get("text", "Text"))
        if "wrap_width_x" in data:
            geometry["wrap_width_x"] = _coerce_float(data.get("wrap_width_x"))
    elif element_type in {"callout", "arrow"}:
        geometry["x0"] = _coerce_float(data.get("x0"))
        geometry["y0"] = _coerce_float(data.get("y0"))
        geometry["x1"] = _coerce_float(data.get("x1"))
        geometry["y1"] = _coerce_float(data.get("y1"))
        text_value = data.get("text")
        if text_value is not None:
            geometry["text"] = str(text_value)
    elif element_type == "point":
        geometry["x"] = _coerce_float(data.get("x"))
        geometry["y"] = _coerce_float(data.get("y"))
    elif element_type in {"xspan", "xspan_label"}:
        geometry["x0"] = _coerce_float(data.get("x0"))
        geometry["x1"] = _coerce_float(data.get("x1"))
        if element_type == "xspan_label":
            geometry["text"] = str(data.get("text", "Label"))
            legacy_text_y = data.get("text_y")
            if legacy_text_y is not None:
                geometry["legacy_label_y_axes"] = legacy_text_y
            legacy_align = data.get("text_align")
            if legacy_align:
                geometry["label_anchor"] = str(legacy_align).strip().lower()
    elif element_type == "trace_mask":
        geometry["x0"] = _coerce_float(data.get("x0"))
        geometry["x1"] = _coerce_float(data.get("x1"))
        geometry["trace_key"] = _normalize_trace_series_key(
            data.get("trace_key") or data.get("series_key") or "y2"
        )
    elif element_type == "trace_start":
        start_value = data.get("x_start")
        if start_value is None:
            start_value = data.get("x")
        geometry["x_start"] = _coerce_float(start_value)
        geometry["trace_key"] = _normalize_trace_series_key(
            data.get("trace_key") or data.get("series_key") or "y2"
        )
    elif element_type == "rect":
        geometry["x0"] = _coerce_float(data.get("x0"))
        geometry["x1"] = _coerce_float(data.get("x1"))
        geometry["y0"] = _coerce_float(data.get("y0"))
        geometry["y1"] = _coerce_float(data.get("y1"))
        label = data.get("text")
        if label is not None:
            geometry["text"] = str(label)
    elif element_type == "ref_line":
        orientation = data.get("orientation")
        if isinstance(orientation, str):
            geometry["orientation"] = orientation.strip().lower()
        else:
            geometry["orientation"] = "vertical"
        value = data.get("value")
        if value is None and geometry["orientation"] == "horizontal":
            value = data.get("y")
        if value is None and geometry["orientation"] == "vertical":
            value = data.get("x")
        geometry["value"] = _coerce_float(value)
        label = data.get("text")
        if label is not None:
            geometry["text"] = str(label)
    elif element_type == "ink":
        points = data.get("points")
        if not points:
            points = element.get("points")
        if isinstance(points, list):
            cleaned = []
            # Iterate over points to apply the per-item logic.
            for point in points:
                if not isinstance(point, (list, tuple)) or len(point) < 2:
                    continue
                x_val = _coerce_float(point[0])
                y_val = _coerce_float(point[1])
                if x_val is None or y_val is None:
                    continue
                cleaned.append((x_val, y_val))
            if cleaned:
                geometry["points"] = cleaned
    return geometry


def _normalize_plot_elements(value: Any) -> Dict[str, List[Dict[str, Any]]]:
    """Normalize plot elements.
    Used to keep plot elements consistent across workflows and persistence."""
    if not isinstance(value, dict):
        return {}
    sanitized: Dict[str, List[Dict[str, Any]]] = {}
    # Iterate over items from value to apply the per-item logic.
    for plot_id, elements in value.items():
        if not isinstance(plot_id, str) or not plot_id.strip():
            continue
        if not isinstance(elements, list):
            continue
        normalized_list: List[Dict[str, Any]] = []
        # Iterate over indexed elements from elements to apply the per-item logic.
        for index, element in enumerate(elements):
            if not isinstance(element, dict):
                continue
            element_type = _canonicalize_annotation_type(element.get("type", ""))
            if not element_type:
                continue
            geometry = _normalize_annotation_geometry(element.get("geometry"))
            if not geometry:
                geometry = _migrate_legacy_geometry(element_type, element)
            style = _normalize_annotation_style(element.get("style"))
            coord_space = (
                str(element.get("coord_space", element.get("coords", "data")) or "data")
                .strip()
                .lower()
            )
            if coord_space not in {"data", "axes"}:
                coord_space = "data"
            axes_target = _normalize_axes_target(element.get("axes_target"))
            normalized: Dict[str, Any] = {
                "id": str(element.get("id") or uuid.uuid4()),
                "name": str(
                    element.get("name") or _default_annotation_name(element_type, index)
                ),
                "type": element_type,
                "axes_target": axes_target,
                "coord_space": coord_space,
                "visible": bool(element.get("visible", True)),
                "locked": bool(element.get("locked", False)),
                "zorder": _coerce_float(element.get("zorder"))
                or float(ANNOTATION_DEFAULT_ZORDER + index),
                "style": style,
                "geometry": geometry,
            }
            if element_type == "xspan_label":
                geometry.setdefault("label_anchor", "center")
                if "wrap_width_x" not in geometry:
                    x0 = _coerce_float(geometry.get("x0"))
                    x1 = _coerce_float(geometry.get("x1"))
                    if x0 is not None and x1 is not None:
                        geometry["wrap_width_x"] = abs(x1 - x0)
            if element_type == "trace_mask":
                geometry = {
                    "x0": _coerce_float(geometry.get("x0")),
                    "x1": _coerce_float(geometry.get("x1")),
                    "trace_key": _normalize_trace_series_key(geometry.get("trace_key")),
                }
                normalized["geometry"] = geometry
            if element_type == "trace_start":
                geometry = {
                    "x_start": _coerce_float(geometry.get("x_start")),
                    "trace_key": _normalize_trace_series_key(geometry.get("trace_key")),
                }
                normalized["geometry"] = geometry
            if element_type in {"xspan", "xspan_label"}:
                style.setdefault("span_layer", "behind_data")
            if element_type == "ink" and coord_space != "data":
                normalized["_legacy_pixel_based"] = True
            # Iterate over ("_draft", "_editor_only") to apply the per-item logic.
            for flag_key in ("_draft", "_editor_only"):
                if flag_key in element:
                    normalized[flag_key] = element[flag_key]
            normalized_list.append(normalized)
        sanitized[plot_id] = normalized_list
    return sanitized


def _default_add_defaults() -> Dict[str, Any]:
    """Return default add defaults.
    Used when callers need a safe fallback."""
    base_style = _default_style_for_type("xspan")
    return {
        "add_type": "xspan",
        "add_fillcolor": str(base_style.get("facecolor", "#cccccc")),
        "add_alpha": float(base_style.get("alpha", 0.9)),
        "add_label_text": "Label",
        "add_trace_key": "y2",
        "add_axis_target": "primary",
        "add_coord_space": "data",
    }


def _normalize_annotations_ui(value: Any) -> Dict[str, Dict[str, Any]]:
    """Normalize persisted Plot Elements editor UI state.

    Purpose:
        Sanitize per-plot editor state loaded from settings before the UI consumes it.
    Why:
        The Plot Elements dialog depends on valid collapsed/sash defaults to keep both
        panes visible and avoid startup with an unusable layout.
    Args:
        value: Raw settings payload from `settings["annotations_ui"]`.
    Returns:
        A normalized dictionary keyed by plot id containing safe UI state values.
    Side Effects:
        None.
    Exceptions:
        Invalid or malformed entries are skipped or coerced to safe defaults.
    """
    if not isinstance(value, dict):
        return {}
    sanitized: Dict[str, Dict[str, Any]] = {}
    # Iterate over items from value to apply the per-item logic.
    for plot_id, state in value.items():
        if not isinstance(plot_id, str) or not plot_id.strip():
            continue
        if not isinstance(state, dict):
            continue
        last_mode = state.get("last_mode")
        if not isinstance(last_mode, str) or last_mode not in ANNOTATION_MODES:
            last_mode = "select"
        collapsed = bool(state.get("collapsed", False))
        selected_id = state.get("last_selected_id")
        if selected_id is not None and not isinstance(selected_id, str):
            selected_id = None
        add_defaults = state.get("add_defaults")
        if not isinstance(add_defaults, dict):
            add_defaults = {}
        add_type = _canonicalize_annotation_type(add_defaults.get("add_type", ""))
        if not add_type:
            add_type = "xspan"
        fill_color = add_defaults.get("add_fillcolor")
        if not isinstance(fill_color, str) or not fill_color.strip():
            fill_color = _default_add_defaults()["add_fillcolor"]
        alpha_value = _coerce_float(add_defaults.get("add_alpha"))
        if alpha_value is None:
            alpha_value = float(_default_add_defaults()["add_alpha"])
        alpha_value = max(0.0, min(1.0, alpha_value))
        label_text = add_defaults.get("add_label_text")
        if not isinstance(label_text, str):
            label_text = _default_add_defaults()["add_label_text"]
        trace_key = _normalize_trace_series_key(
            add_defaults.get("add_trace_key"),
            default=str(_default_add_defaults().get("add_trace_key", "y2")),
        )
        axis_target = _normalize_axes_target(add_defaults.get("add_axis_target"))
        coord_space = str(add_defaults.get("add_coord_space") or "data").strip().lower()
        if coord_space not in {"data", "axes"}:
            coord_space = "data"
        editor_geometry = state.get("editor_geometry")
        if not isinstance(editor_geometry, str) or not editor_geometry.strip():
            editor_geometry = None
        editor_sash = state.get("editor_sash")
        if isinstance(editor_sash, bool):
            editor_sash = None
        if not isinstance(editor_sash, (int, float)):
            editor_sash = None
        if isinstance(editor_sash, (int, float)) and editor_sash <= 0:
            editor_sash = None
        live_update = bool(state.get("live_update", False))
        sanitized[plot_id] = {
            "collapsed": collapsed,
            "last_mode": last_mode,
            "last_selected_id": selected_id,
            "live_update": live_update,
            "editor_geometry": editor_geometry,
            "editor_sash": editor_sash,
            "add_defaults": {
                "add_type": add_type,
                "add_fillcolor": fill_color,
                "add_alpha": alpha_value,
                "add_label_text": label_text,
                "add_trace_key": trace_key,
                "add_axis_target": axis_target,
                "add_coord_space": coord_space,
            },
        }
    return sanitized


DEFAULT_EXPORT_BOTTOM_MARGIN = 0.184
_DEFAULT_LAYOUT_MARGINS = {
    "fig_pressure_temp": {
        "display": {"left": 0.071, "right": 0.924, "top": 0.91, "bottom": 0.143},
    },
    "fig_pressure_derivative": {
        "display": {"left": 0.071, "right": 0.924, "top": 0.91, "bottom": 0.143},
    },
    "fig_cycle_analysis": {
        "display": {"left": 0.076, "right": 0.97, "top": 0.914, "bottom": 0.079},
    },
    "fig_combined_triple_axis": {
        "display": {"left": 0.125, "right": 0.9, "top": 0.88, "bottom": 0.11},
    },
}
_DEFAULT_LAYOUT_MARGINS_GENERIC = {
    "display": {"left": 0.08, "right": 0.97, "top": 0.92, "bottom": 0.12},
}
_DEFAULT_LAYOUT_PLOT_IDS = (
    "fig_pressure_temp",
    "fig_pressure_derivative",
    "fig_combined_triple_axis",
    "fig_cycle_analysis",
)


def _default_layout_margins(plot_id: Optional[str], mode: str) -> Dict[str, float]:
    """Return default layout margins.
    Used when callers need a safe fallback."""
    defaults = _DEFAULT_LAYOUT_MARGINS.get(plot_id, _DEFAULT_LAYOUT_MARGINS_GENERIC)
    base = defaults.get("display", _DEFAULT_LAYOUT_MARGINS_GENERIC["display"])
    margins = dict(base)
    if mode == "export":
        margins["bottom"] = DEFAULT_EXPORT_BOTTOM_MARGIN
    return margins


def _validated_anchor_pair(anchor: Any) -> Optional[Tuple[float, float]]:
    """Perform validated anchor pair.
    Used to keep the workflow logic localized and testable."""
    try:
        values = [float(v) for v in anchor]
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None
    if len(values) < 2:
        return None
    x0, y0 = values[0], values[1]
    if -0.05 <= x0 <= 1.05 and -0.05 <= y0 <= 1.05:
        return (x0, y0)
    return None


def _normalize_layout_margins(
    value: Any, defaults: Mapping[str, float]
) -> Dict[str, float]:
    """Normalize layout margins.
    Used to keep layout margins consistent across workflows and persistence."""
    if not isinstance(value, dict):
        value = {}
    margins: Dict[str, float] = {}
    # Iterate over ("left", "right", "top", "bottom") to apply the per-item logic.
    for key in ("left", "right", "top", "bottom"):
        raw = value.get(key, defaults.get(key))
        try:
            candidate = float(raw)
        except Exception:
            candidate = float(defaults.get(key, 0.0))
        candidate = max(0.0, min(1.0, candidate))
        margins[key] = candidate
    if margins["left"] >= margins["right"] or margins["bottom"] >= margins["top"]:
        margins = {
            "left": float(defaults.get("left", 0.0)),
            "right": float(defaults.get("right", 1.0)),
            "top": float(defaults.get("top", 1.0)),
            "bottom": float(defaults.get("bottom", 0.0)),
        }
    return margins


def _normalize_layout_xy(value: Any) -> Optional[Tuple[float, float]]:
    """Normalize layout xy.
    Used to keep layout xy consistent across workflows and persistence."""
    anchor = _validated_anchor_pair(value)
    if anchor is None:
        return None
    return anchor


def _normalize_legend_loc_value(
    value: Any,
) -> Optional[Union[str, int, Tuple[float, float]]]:
    """Normalize legend loc value.
    Used to keep legend loc value consistent across workflows and persistence."""
    if isinstance(value, str):
        value = value.strip()
        return value or None
    if isinstance(value, (list, tuple)):
        return _validated_anchor_pair(value)
    try:
        loc_int = int(value)
        return loc_int
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None


def _normalize_combined_cycle_ref_axis(value):
    """Normalize combined cycle ref axis.
    Used to keep combined cycle ref axis consistent across workflows and persistence."""
    if value is None:
        return None
    if not isinstance(value, str):
        return None
    candidate = value.strip().lower()
    if candidate in ("", "none", "auto", "default"):
        return None
    if candidate in ("main", "primary", "host", "base"):
        return "main"
    if candidate in ("right", "y2", "y_right", "right_y"):
        return "right"
    if candidate in ("deriv", "derivative", "third"):
        return "deriv"
    return None


def _normalize_combined_cycle_ref_corner(value: Any) -> str:
    """Normalize combined cycle ref corner.
    Used to keep combined cycle ref corner consistent across workflows and persistence."""
    if isinstance(value, str):
        candidate = value.strip().lower()
        if candidate in COMBINED_CYCLE_REF_CORNER_CHOICES:
            return candidate
    return "upper right"


def _normalize_layout_profile(value: Any, plot_id: Optional[str]) -> Dict[str, Any]:
    """Normalize layout profile.
    Used to keep layout profile consistent across workflows and persistence."""
    defaults = {
        "display": {
            "margins": _default_layout_margins(plot_id, "display"),
            "title_xy": None,
            "suptitle_xy": None,
            "legend_anchor": None,
            "legend_anchor_y": None,
            "legend_loc": None,
            "cycle_legend_anchor": None,
            "cycle_legend_loc": None,
            "xlabel_pad_pts": None,
            "axis_labelpads": {},
            "detached_spine_offset": None,
            "detached_labelpad": None,
        },
        "export": {
            "margins": _default_layout_margins(plot_id, "export"),
            "title_xy": None,
            "suptitle_xy": None,
            "legend_anchor": None,
            "legend_anchor_y": None,
            "legend_loc": None,
            "cycle_legend_anchor": None,
            "cycle_legend_loc": None,
            "xlabel_pad_pts": None,
            "axis_labelpads": {},
            "detached_spine_offset": None,
            "detached_labelpad": None,
        },
        "mirror_detached_labelpad": False,
    }
    if not isinstance(value, dict):
        value = {}
    normalized: Dict[str, Any] = {
        "mirror_detached_labelpad": bool(value.get("mirror_detached_labelpad", False))
    }
    normalize_loc_fn = globals().get("_normalize_legend_loc_value")
    if not callable(normalize_loc_fn):

        # Closure captures _normalize_layout_profile local context to keep helper logic scoped and invoked directly within _normalize_layout_profile.
        def _fallback_normalize_legend_loc_value(v):
            """Normalize legend loc value.
            Used by fallback workflows to normalize legend loc value."""
            if isinstance(v, str):
                v = v.strip()
                return v or None
            try:
                return int(v)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None

        normalize_loc_fn = _fallback_normalize_legend_loc_value
    # Iterate over ("display", "export") to apply the per-item logic.
    for mode in ("display", "export"):
        section = value.get(mode, {}) if isinstance(value.get(mode), dict) else {}
        defaults_section = defaults[mode]
        normalized_section = {
            "margins": _normalize_layout_margins(
                section.get("margins"), defaults_section["margins"]
            ),
            "title_xy": _normalize_layout_xy(section.get("title_xy")),
            "suptitle_xy": _normalize_layout_xy(section.get("suptitle_xy")),
            "legend_anchor": _validated_anchor_pair(section.get("legend_anchor")),
            "legend_loc": normalize_loc_fn(section.get("legend_loc")),
            "cycle_legend_anchor": _validated_anchor_pair(
                section.get("cycle_legend_anchor")
            ),
            "cycle_legend_loc": normalize_loc_fn(section.get("cycle_legend_loc")),
            "axis_labelpads": {},
            "xlabel_pad_pts": None,
            "detached_spine_offset": None,
            "detached_labelpad": None,
            "legend_anchor_y": None,
        }
        raw_anchor_y = section.get("legend_anchor_y")
        if raw_anchor_y is not None:
            try:
                anchor_y = float(raw_anchor_y)
            except Exception:
                anchor_y = None
            if anchor_y is not None and math.isfinite(anchor_y):
                normalized_section["legend_anchor_y"] = max(-0.1, min(1.1, anchor_y))
        raw_xlabel_pad = section.get("xlabel_pad_pts")
        if raw_xlabel_pad is not None:
            try:
                pad_value = float(raw_xlabel_pad)
            except Exception:
                pad_value = None
            if pad_value is not None and math.isfinite(pad_value):
                normalized_section["xlabel_pad_pts"] = pad_value
        raw_pad_overrides = section.get("axis_labelpads")
        if isinstance(raw_pad_overrides, dict):
            axis_labelpads: Dict[str, float] = {}
            # Iterate over items from raw_pad_overrides to apply the per-item logic.
            for key, raw_value in raw_pad_overrides.items():
                try:
                    pad_value = float(raw_value)
                except Exception:
                    continue
                if not math.isfinite(pad_value):
                    continue
                axis_labelpads[str(key)] = pad_value
            normalized_section["axis_labelpads"] = axis_labelpads
        raw_spine_offset = section.get("detached_spine_offset")
        if raw_spine_offset is not None:
            try:
                offset_value = float(raw_spine_offset)
            except Exception:
                offset_value = None
            if offset_value is not None and math.isfinite(offset_value):
                normalized_section["detached_spine_offset"] = offset_value
        raw_detached_pad = section.get("detached_labelpad")
        if raw_detached_pad is not None:
            try:
                pad_value = float(raw_detached_pad)
            except Exception:
                pad_value = None
            if pad_value is not None and math.isfinite(pad_value):
                normalized_section["detached_labelpad"] = pad_value
        normalized[mode] = normalized_section
    return normalized


def _normalize_layout_profiles(value: Any) -> Dict[str, Dict[str, Any]]:
    """Normalize layout profiles.
    Used to keep layout profiles consistent across workflows and persistence."""
    profiles: Dict[str, Dict[str, Any]] = {}
    if isinstance(value, dict):
        # Iterate over items from value to apply the per-item logic.
        for plot_id, profile in value.items():
            if not isinstance(plot_id, str) or not plot_id.strip():
                continue
            profiles[plot_id] = _normalize_layout_profile(profile, plot_id)
    # Iterate over _DEFAULT_LAYOUT_PLOT_IDS to apply the per-item logic.
    for plot_id in _DEFAULT_LAYOUT_PLOT_IDS:
        if plot_id not in profiles:
            profiles[plot_id] = _normalize_layout_profile({}, plot_id)
    return profiles


CORE_RENDER_PROFILE_PLOT_IDS = ("fig_pressure_temp", "fig_pressure_derivative")


def _default_core_plot_render_profile(
    seed_source: Optional[Mapping[str, Any]] = None,
) -> Dict[str, Any]:
    """Build default core plot render profile.
    Seeds values from combined settings when available."""
    source = seed_source if isinstance(seed_source, Mapping) else {}
    legend_loc_choice = source.get("combined_cycle_legend_loc_choice", "upper right")
    if isinstance(legend_loc_choice, str):
        legend_loc_choice = legend_loc_choice.strip().lower()
    else:
        legend_loc_choice = str(legend_loc_choice).strip().lower()
    if legend_loc_choice not in {
        "upper right",
        "upper left",
        "lower right",
        "lower left",
        "center right",
        "center left",
        "upper center",
        "lower center",
        "center",
    }:
        legend_loc_choice = "upper right"
    try:
        legend_rows_value = int(source.get("combined_legend_rows", 2))
    except Exception:
        legend_rows_value = 2
    legend_rows_value = max(1, legend_rows_value)
    alignment_value = str(source.get("combined_legend_alignment", "center") or "").strip().lower()
    if alignment_value not in {"left", "center", "right"}:
        alignment_value = "center"
    return {
        "x_axis_label": str(source.get("combined_x_axis_label", "") or "").strip(),
        "primary_axis_label": str(
            source.get("combined_primary_axis_label", "") or ""
        ).strip(),
        "right_axis_label": str(source.get("combined_temp_axis_label", "") or "").strip(),
        "third_axis_label": str(
            source.get("combined_deriv_axis_label", "") or ""
        ).strip(),
        "primary_labelpad": source.get("combined_primary_labelpad", yaxis_labelpad_amount),
        "right_labelpad": source.get(
            "combined_temp_labelpad", twinyaxis_labelpad_amount
        ),
        "third_labelpad": source.get(
            "combined_deriv_labelpad", twinyaxis_labelpad_amount
        ),
        "third_axis_offset": source.get("combined_deriv_axis_offset", 1.12),
        "left_padding_pct": source.get(
            "combined_left_pad_pct", DEFAULT_COMBINED_LEFT_PAD_PCT
        ),
        "right_padding_pct": source.get(
            "combined_right_pad_pct", DEFAULT_COMBINED_RIGHT_PAD_PCT
        ),
        "export_pad_pts": source.get(
            "combined_export_pad_pts", DEFAULT_COMBINED_EXPORT_PAD_PTS
        ),
        "title_pad_pts": source.get(
            "combined_title_pad_pts", DEFAULT_COMBINED_TITLE_PAD_PTS
        ),
        "suptitle_pad_pts": source.get(
            "combined_suptitle_pad_pts", DEFAULT_COMBINED_SUPTITLE_PAD_PTS
        ),
        "suptitle_y": source.get("combined_suptitle_y", DEFAULT_COMBINED_SUPTITLE_Y),
        "top_margin_pct": source.get(
            "combined_top_margin_pct", DEFAULT_COMBINED_TOP_MARGIN_PCT
        ),
        "font_family": str(source.get("combined_font_family", "") or "").strip(),
        "suptitle_fontsize": source.get(
            "combined_suptitle_fontsize", DEFAULT_COMBINED_SUPTITLE_FONTSIZE
        ),
        "title_fontsize": source.get(
            "combined_title_fontsize", DEFAULT_COMBINED_TITLE_FONTSIZE
        ),
        "label_fontsize": source.get(
            "combined_label_fontsize", DEFAULT_COMBINED_LABEL_FONTSIZE
        ),
        "tick_fontsize": source.get(
            "combined_tick_fontsize", DEFAULT_COMBINED_TICK_FONTSIZE
        ),
        "legend_fontsize": source.get(
            "combined_legend_fontsize",
            source.get("core_legend_fontsize", DEFAULT_COMBINED_LEGEND_FONTSIZE),
        ),
        "cycle_legend_fontsize": source.get(
            "combined_cycle_legend_fontsize",
            source.get(
                "core_cycle_legend_fontsize",
                source.get("core_legend_fontsize", DEFAULT_COMBINED_LEGEND_FONTSIZE),
            ),
        ),
        "legend_wrap": bool(source.get("combined_legend_wrap", False)),
        "legend_rows": legend_rows_value,
        "legend_label_gap_pts": source.get(
            "combined_legend_gap_pts", DEFAULT_COMBINED_LEGEND_GAP_PTS
        ),
        "xlabel_tick_gap_pts": source.get(
            "combined_xlabel_tick_gap_pts", DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS
        ),
        "legend_bottom_margin_pts": source.get(
            "combined_legend_bottom_margin_pts", DEFAULT_COMBINED_LEGEND_MARGIN_PTS
        ),
        "legend_alignment": alignment_value,
        "cycle_legend_loc_choice": legend_loc_choice,
        "cycle_legend_ref_axis": _normalize_combined_cycle_ref_axis(
            source.get("combined_cycle_legend_ref_axis")
        ),
        "cycle_legend_ref_corner": _normalize_combined_cycle_ref_corner(
            source.get("combined_cycle_legend_ref_corner")
        ),
    }


def _normalize_core_plot_render_profile(
    value: Any,
    *,
    defaults: Optional[Mapping[str, Any]] = None,
) -> Dict[str, Any]:
    """Normalize one core plot render profile."""
    defaults_map = defaults if isinstance(defaults, Mapping) else {}
    if not isinstance(value, dict):
        value = {}

    def _text(key: str, fallback: str = "") -> str:
        raw = value.get(key, defaults_map.get(key, fallback))
        if raw is None:
            return ""
        return str(raw).strip()

    def _finite_float(key: str, fallback: float) -> float:
        raw = value.get(key, defaults_map.get(key, fallback))
        try:
            parsed = float(raw)
        except Exception:
            parsed = float(fallback)
        if not math.isfinite(parsed):
            parsed = float(fallback)
        return parsed

    legend_alignment = _text("legend_alignment", "center").lower()
    if legend_alignment not in {"left", "center", "right"}:
        legend_alignment = "center"

    legend_loc_choice = _text("cycle_legend_loc_choice", "upper right").lower()
    if legend_loc_choice not in {
        "upper right",
        "upper left",
        "lower right",
        "lower left",
        "center right",
        "center left",
        "upper center",
        "lower center",
        "center",
    }:
        legend_loc_choice = "upper right"

    try:
        legend_rows_raw = value.get("legend_rows", defaults_map.get("legend_rows", 2))
        legend_rows = int(legend_rows_raw)
    except Exception:
        legend_rows = 2
    legend_rows = max(1, legend_rows)

    return {
        "x_axis_label": _text("x_axis_label"),
        "primary_axis_label": _text("primary_axis_label"),
        "right_axis_label": _text("right_axis_label"),
        "third_axis_label": _text("third_axis_label"),
        "primary_labelpad": _finite_float("primary_labelpad", yaxis_labelpad_amount),
        "right_labelpad": _finite_float("right_labelpad", twinyaxis_labelpad_amount),
        "third_labelpad": _finite_float("third_labelpad", twinyaxis_labelpad_amount),
        "third_axis_offset": max(1.1, _finite_float("third_axis_offset", 1.12)),
        "left_padding_pct": _sanitize_spacing_value(
            _finite_float("left_padding_pct", DEFAULT_COMBINED_LEFT_PAD_PCT),
            DEFAULT_COMBINED_LEFT_PAD_PCT,
            MIN_COMBINED_SIDE_PAD_PCT,
            MAX_COMBINED_SIDE_PAD_PCT,
        ),
        "right_padding_pct": _sanitize_spacing_value(
            _finite_float("right_padding_pct", DEFAULT_COMBINED_RIGHT_PAD_PCT),
            DEFAULT_COMBINED_RIGHT_PAD_PCT,
            MIN_COMBINED_SIDE_PAD_PCT,
            MAX_COMBINED_SIDE_PAD_PCT,
        ),
        "export_pad_pts": _sanitize_spacing_value(
            _finite_float("export_pad_pts", DEFAULT_COMBINED_EXPORT_PAD_PTS),
            DEFAULT_COMBINED_EXPORT_PAD_PTS,
            MIN_COMBINED_EXPORT_PAD_PTS,
            MAX_COMBINED_EXPORT_PAD_PTS,
        ),
        "title_pad_pts": _sanitize_spacing_value(
            _finite_float("title_pad_pts", DEFAULT_COMBINED_TITLE_PAD_PTS),
            DEFAULT_COMBINED_TITLE_PAD_PTS,
            MIN_COMBINED_TITLE_PAD_PTS,
            MAX_COMBINED_TITLE_PAD_PTS,
        ),
        "suptitle_pad_pts": _sanitize_spacing_value(
            _finite_float("suptitle_pad_pts", DEFAULT_COMBINED_SUPTITLE_PAD_PTS),
            DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
            MIN_COMBINED_SUPTITLE_PAD_PTS,
            MAX_COMBINED_SUPTITLE_PAD_PTS,
        ),
        "suptitle_y": _sanitize_spacing_value(
            _finite_float("suptitle_y", DEFAULT_COMBINED_SUPTITLE_Y),
            DEFAULT_COMBINED_SUPTITLE_Y,
            MIN_COMBINED_SUPTITLE_Y,
            MAX_COMBINED_SUPTITLE_Y,
        ),
        "top_margin_pct": _sanitize_spacing_value(
            _finite_float("top_margin_pct", DEFAULT_COMBINED_TOP_MARGIN_PCT),
            DEFAULT_COMBINED_TOP_MARGIN_PCT,
            MIN_COMBINED_TOP_MARGIN_PCT,
            MAX_COMBINED_TOP_MARGIN_PCT,
        ),
        "font_family": _text("font_family"),
        "suptitle_fontsize": _sanitize_spacing_value(
            _finite_float("suptitle_fontsize", DEFAULT_COMBINED_SUPTITLE_FONTSIZE),
            DEFAULT_COMBINED_SUPTITLE_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        ),
        "title_fontsize": _sanitize_spacing_value(
            _finite_float("title_fontsize", DEFAULT_COMBINED_TITLE_FONTSIZE),
            DEFAULT_COMBINED_TITLE_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        ),
        "label_fontsize": _sanitize_spacing_value(
            _finite_float("label_fontsize", DEFAULT_COMBINED_LABEL_FONTSIZE),
            DEFAULT_COMBINED_LABEL_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        ),
        "tick_fontsize": _sanitize_spacing_value(
            _finite_float("tick_fontsize", DEFAULT_COMBINED_TICK_FONTSIZE),
            DEFAULT_COMBINED_TICK_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        ),
        "legend_fontsize": _sanitize_spacing_value(
            _finite_float("legend_fontsize", DEFAULT_COMBINED_LEGEND_FONTSIZE),
            DEFAULT_COMBINED_LEGEND_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        ),
        "cycle_legend_fontsize": _sanitize_spacing_value(
            _finite_float("cycle_legend_fontsize", DEFAULT_COMBINED_LEGEND_FONTSIZE),
            DEFAULT_COMBINED_LEGEND_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        ),
        "legend_wrap": bool(value.get("legend_wrap", defaults_map.get("legend_wrap", False))),
        "legend_rows": legend_rows,
        "legend_label_gap_pts": _sanitize_spacing_value(
            _finite_float("legend_label_gap_pts", DEFAULT_COMBINED_LEGEND_GAP_PTS),
            DEFAULT_COMBINED_LEGEND_GAP_PTS,
            MIN_COMBINED_LEGEND_GAP_PTS,
            MAX_COMBINED_LEGEND_GAP_PTS,
        ),
        "xlabel_tick_gap_pts": _sanitize_spacing_value(
            _finite_float("xlabel_tick_gap_pts", DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS),
            DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS,
            MIN_COMBINED_XLABEL_TICK_GAP_PTS,
            MAX_COMBINED_XLABEL_TICK_GAP_PTS,
        ),
        "legend_bottom_margin_pts": _sanitize_spacing_value(
            _finite_float("legend_bottom_margin_pts", DEFAULT_COMBINED_LEGEND_MARGIN_PTS),
            DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
            MIN_COMBINED_LEGEND_MARGIN_PTS,
            MAX_COMBINED_LEGEND_MARGIN_PTS,
        ),
        "legend_alignment": legend_alignment,
        "cycle_legend_loc_choice": legend_loc_choice,
        "cycle_legend_ref_axis": _normalize_combined_cycle_ref_axis(
            value.get(
                "cycle_legend_ref_axis",
                defaults_map.get("cycle_legend_ref_axis", "main"),
            )
        ),
        "cycle_legend_ref_corner": _normalize_combined_cycle_ref_corner(
            value.get(
                "cycle_legend_ref_corner",
                defaults_map.get("cycle_legend_ref_corner", "upper right"),
            )
        ),
    }


def _normalize_core_plot_render_profiles(
    value: Any,
    *,
    seed_source: Optional[Mapping[str, Any]] = None,
) -> Dict[str, Dict[str, Any]]:
    """Normalize all core plot render profiles."""
    profiles: Dict[str, Dict[str, Any]] = {}
    raw_map = value if isinstance(value, dict) else {}
    default_profile = _default_core_plot_render_profile(seed_source=seed_source)
    # Iterate over configured core plot IDs to apply the per-item logic.
    for plot_id in CORE_RENDER_PROFILE_PLOT_IDS:
        raw_profile = raw_map.get(plot_id, {})
        profiles[plot_id] = _normalize_core_plot_render_profile(
            raw_profile,
            defaults=default_profile,
        )
    return profiles


def _write_legacy_core_legend_settings_from_profile(
    profile: Optional[Mapping[str, Any]]
) -> None:
    """Mirror per-plot core legend values onto legacy flat settings keys."""
    if not isinstance(profile, Mapping):
        return
    legend_value = _sanitize_spacing_value(
        _coerce_float(profile.get("legend_fontsize")),
        label_fontsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    cycle_value = _sanitize_spacing_value(
        _coerce_float(profile.get("cycle_legend_fontsize")),
        legend_value,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    settings["core_legend_fontsize"] = legend_value
    settings["core_cycle_legend_fontsize"] = cycle_value


def _get_core_plot_render_profiles() -> Dict[str, Dict[str, Any]]:
    """Return normalized core plot render profiles with migration defaults."""
    profiles = settings.get("core_plot_render_profiles")
    normalized = _normalize_core_plot_render_profiles(profiles, seed_source=settings)
    settings["core_plot_render_profiles"] = normalized
    return normalized


def _get_core_plot_render_profile(plot_id: str) -> Dict[str, Any]:
    """Return one normalized core plot render profile."""
    profiles = _get_core_plot_render_profiles()
    if plot_id in profiles:
        return profiles[plot_id]
    fallback_key = CORE_RENDER_PROFILE_PLOT_IDS[0]
    return profiles.get(
        fallback_key,
        _normalize_core_plot_render_profile({}, defaults=_default_core_plot_render_profile(settings)),
    )


def _set_core_plot_render_profile(
    plot_id: str,
    profile: Optional[Mapping[str, Any]],
) -> Dict[str, Any]:
    """Persist one normalized core plot render profile."""
    profiles = _get_core_plot_render_profiles()
    target_plot_id = plot_id if plot_id in CORE_RENDER_PROFILE_PLOT_IDS else CORE_RENDER_PROFILE_PLOT_IDS[0]
    defaults = _default_core_plot_render_profile(seed_source=settings)
    normalized_profile = _normalize_core_plot_render_profile(
        dict(profile) if isinstance(profile, Mapping) else {},
        defaults=defaults,
    )
    profiles[target_plot_id] = normalized_profile
    settings["core_plot_render_profiles"] = _normalize_core_plot_render_profiles(
        profiles,
        seed_source=settings,
    )
    stored_profile = settings["core_plot_render_profiles"].get(target_plot_id, normalized_profile)
    _write_legacy_core_legend_settings_from_profile(stored_profile)
    return stored_profile


def _get_layout_profile(plot_id: str) -> Dict[str, Any]:
    """Return layout profile.
    Used to retrieve layout profile for downstream logic."""
    profiles = settings.get("layout_profiles")
    if not isinstance(profiles, dict):
        profiles = _normalize_layout_profiles(profiles)
        settings["layout_profiles"] = profiles
    profile = profiles.get(plot_id)
    if not isinstance(profile, dict):
        profile = _normalize_layout_profile({}, plot_id)
        profiles[plot_id] = profile
    return profile


def _layout_profile_section(profile: Mapping[str, Any], mode: str) -> Dict[str, Any]:
    """Perform layout profile section.
    Used to keep the workflow logic localized and testable."""
    key = "export" if str(mode).lower() == "export" else "display"
    section = profile.get(key, {})
    return section if isinstance(section, dict) else {}


def _apply_title_positions(
    fig: Figure,
    *,
    title_xy: Optional[Tuple[float, float]] = None,
    suptitle_xy: Optional[Tuple[float, float]] = None,
) -> None:
    """Apply title positions.
    Used to apply title positions changes to live state."""
    if fig is None:
        return

    def _apply_text_position(text_artist, target_xy) -> None:
        """Apply text position.
        Used to apply text position changes to live state."""
        if text_artist is None or target_xy is None:
            return
        try:
            ax = getattr(text_artist, "axes", None)
            if ax is not None:
                try:
                    fig_ref = getattr(text_artist, "figure", None) or ax.figure
                    if fig_ref is not None:
                        display_xy = fig_ref.transFigure.transform(target_xy)
                        axes_xy = ax.transAxes.inverted().transform(display_xy)
                        text_artist.set_position(axes_xy)
                        return
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            text_artist.set_position(target_xy)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    title_artist = getattr(fig, "_gl260_title_text", None)
    _apply_text_position(title_artist, title_xy)
    suptitle_artist = getattr(fig, "_gl260_suptitle_text", None)
    if suptitle_artist is None:
        suptitle_artist = getattr(fig, "_suptitle", None)
    _apply_text_position(suptitle_artist, suptitle_xy)


def _apply_layout_profile_to_figure(fig: Figure, plot_id: str, mode: str) -> None:
    """Apply layout profile to figure.
    Used to apply layout profile to figure changes to live state."""
    if fig is None or not plot_id:
        return
    profile = _get_layout_profile(plot_id)
    section = _layout_profile_section(profile, mode)
    margins = section.get("margins")
    axes = []
    # Iterate over fig.get_axes() to apply the per-item logic.
    for axis in fig.get_axes():
        if axis is None:
            continue
        try:
            if not axis.get_visible():
                continue
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if getattr(axis, "_gl260_legend_only", False):
            continue
        axes.append(axis)
    axis_labelpads = section.get("axis_labelpads", {})
    mirror_detached_labelpad = bool(profile.get("mirror_detached_labelpad", False))
    detached_labelpad = section.get("detached_labelpad")
    detached_spine_offset = section.get("detached_spine_offset")
    primary_axis = None
    right_axis = None
    third_axis = None
    # Iterate over axes to apply the per-item logic.
    for axis in axes:
        role = getattr(axis, "_gl260_axis_role", None)
        if role == "primary" and primary_axis is None:
            primary_axis = axis
        elif role == "right" and right_axis is None:
            right_axis = axis
        elif role == "third" and third_axis is None:
            third_axis = axis
    if primary_axis is None and axes:
        primary_axis = axes[0]
    if isinstance(axis_labelpads, dict):
        if primary_axis is not None and "x" in axis_labelpads:
            try:
                primary_axis.xaxis.set_labelpad(axis_labelpads["x"])
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if primary_axis is not None and "primary" in axis_labelpads:
            try:
                primary_axis.yaxis.set_labelpad(axis_labelpads["primary"])
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if right_axis is not None:
            pad_value = axis_labelpads.get("right")
            if pad_value is None:
                pad_value = axis_labelpads.get("temperature")
            if pad_value is not None:
                try:
                    right_axis.yaxis.set_labelpad(pad_value)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
    if third_axis is not None:
        detached_pad_value = None
        if mirror_detached_labelpad:
            if isinstance(axis_labelpads, dict):
                detached_pad_value = axis_labelpads.get("right")
                if detached_pad_value is None:
                    detached_pad_value = axis_labelpads.get("temperature")
            if detached_pad_value is None and right_axis is not None:
                try:
                    detached_pad_value = float(right_axis.yaxis.labelpad)
                except Exception:
                    detached_pad_value = None
        elif detached_labelpad is not None:
            detached_pad_value = detached_labelpad
        elif isinstance(axis_labelpads, dict):
            detached_pad_value = axis_labelpads.get("third")
            if detached_pad_value is None:
                detached_pad_value = axis_labelpads.get("derivative")
        if detached_pad_value is not None:
            try:
                third_axis.yaxis.set_labelpad(detached_pad_value)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
    if detached_spine_offset is not None and third_axis is not None:
        try:
            offset_value = float(detached_spine_offset)
        except Exception:
            offset_value = None
        if offset_value is not None and math.isfinite(offset_value):
            try:
                third_axis.spines["right"].set_position(("axes", offset_value))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    fig_legends = [lg for lg in getattr(fig, "legends", []) if lg is not None]
    axis_legends = []
    axis_legend_map = {}
    # Iterate over axes to apply the per-item logic.
    for axis in axes:
        try:
            legend = axis.get_legend()
        except Exception:
            legend = None
        if legend is None:
            continue
        axis_legends.append(legend)
        axis_legend_map[legend] = axis
    main_legend = fig_legends[0] if fig_legends else None
    if main_legend is None:
        # Iterate over axis_legends to apply the per-item logic.
        for legend in axis_legends:
            if getattr(legend, "_cycle_overlay_legend", False):
                continue
            main_legend = legend
            break
    cycle_legend = None
    # Iterate over fig_legends to apply the per-item logic.
    for legend in fig_legends:
        if getattr(legend, "_cycle_overlay_legend", False):
            cycle_legend = legend
            break
    if cycle_legend is None:
        # Iterate over axis_legends to apply the per-item logic.
        for legend in axis_legends:
            if getattr(legend, "_cycle_overlay_legend", False):
                cycle_legend = legend
                break
    legend_anchor = section.get("legend_anchor")
    legend_loc = section.get("legend_loc")
    legend_anchor_y = section.get("legend_anchor_y")
    if main_legend is not None:
        anchor_to_apply = legend_anchor
        if anchor_to_apply is None and legend_anchor_y is not None:
            anchor_to_apply = (0.5, legend_anchor_y)
        if anchor_to_apply is not None:
            _apply_legend_anchor_to_artist(
                main_legend,
                anchor_to_apply,
                transform=fig.transFigure,
                loc_override=legend_loc,
            )
        elif legend_loc is not None:
            try:
                main_legend.set_loc(_normalize_legend_loc_value(legend_loc))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    cycle_anchor = section.get("cycle_legend_anchor")
    cycle_loc = section.get("cycle_legend_loc")
    core_render_profile = None
    if plot_id in CORE_RENDER_PROFILE_PLOT_IDS:
        core_render_profile = _get_core_plot_render_profile(plot_id)
        if cycle_loc is None:
            cycle_loc = _normalize_legend_loc_value(
                core_render_profile.get("cycle_legend_loc_choice")
            )
    combined_cycle_anchor = None
    combined_axis_offset = None
    if plot_id == "fig_combined_triple_axis":
        combined_axis_offset = _combined_cycle_axis_offset_values()
        combined_cycle_anchor = _validated_anchor_pair(
            settings.get("combined_cycle_legend_anchor")
        )
    if (
        cycle_anchor is not None
        and combined_cycle_anchor is None
        and combined_axis_offset is None
        and cycle_legend is not None
    ):
        axis = axis_legend_map.get(cycle_legend)
        if axis is not None:
            _apply_legend_anchor_to_artist(
                cycle_legend,
                cycle_anchor,
                target_ax=axis,
                loc_override=cycle_loc,
            )
        else:
            _apply_legend_anchor_to_artist(
                cycle_legend,
                cycle_anchor,
                transform=fig.transFigure,
                loc_override=cycle_loc,
            )

    if plot_id == "fig_combined_triple_axis":
        layout_mgr = getattr(fig, "_gl260_layout_manager", None)
        if layout_mgr is not None:
            if isinstance(margins, dict):
                # Iterate to apply the per-item logic.
                for key, attr in (
                    ("left", "_baseline_left"),
                    ("right", "_baseline_right"),
                    ("top", "_baseline_top"),
                    ("bottom", "_baseline_bottom"),
                ):
                    try:
                        raw_value = float(margins.get(key))
                    except Exception:
                        raw_value = None
                    if raw_value is not None and math.isfinite(raw_value):
                        setattr(layout_mgr, attr, max(0.0, min(1.0, float(raw_value))))
            if legend_anchor is not None:
                layout_mgr.legend_anchor = _validated_anchor_pair(legend_anchor)
            if legend_anchor_y is not None:
                try:
                    anchor_value = float(legend_anchor_y)
                except Exception:
                    anchor_value = None
                if anchor_value is not None and math.isfinite(anchor_value):
                    layout_mgr.legend_anchor_y = max(-0.1, min(1.1, anchor_value))
            xlabel_pad_value = section.get("xlabel_pad_pts")
            if xlabel_pad_value is None and isinstance(axis_labelpads, dict):
                xlabel_pad_value = axis_labelpads.get("x")
            if xlabel_pad_value is not None:
                try:
                    layout_mgr.xlabel_pad_pts = float(xlabel_pad_value)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            if axes:
                layout_mgr.register_axes(*axes)
            title_artist = getattr(fig, "_gl260_title_text", None)
            if title_artist is not None:
                layout_mgr.register_artist("title", title_artist)
            suptitle_artist = getattr(fig, "_gl260_suptitle_text", None)
            if suptitle_artist is None:
                suptitle_artist = getattr(fig, "_suptitle", None)
            if suptitle_artist is not None:
                layout_mgr.register_artist("suptitle", suptitle_artist)
            xlabel_artist = getattr(fig, "_gl260_xlabel_text", None)
            if xlabel_artist is not None:
                layout_mgr.register_artist("xlabel", xlabel_artist)
            if main_legend is not None:
                layout_mgr.register_artist("plot_legend", main_legend)
            if cycle_legend is not None:
                layout_mgr.register_artist("cycle_legend", cycle_legend)
            try:
                layout_mgr.solve()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if combined_axis_offset is not None and cycle_legend is not None:
            ref_axis = _resolve_combined_cycle_ref_axis(
                fig,
                ax_main=primary_axis,
                ax_right=right_axis,
                ax_deriv=third_axis,
                ref_axis_key=settings.get("combined_cycle_legend_ref_axis"),
            )
            loc_value = _resolve_combined_cycle_legend_loc()
            _apply_cycle_legend_axis_offset(
                fig,
                cycle_legend,
                ref_axis,
                settings.get("combined_cycle_legend_ref_corner"),
                combined_axis_offset[0],
                combined_axis_offset[1],
                loc_value,
            )

    if plot_id != "fig_combined_triple_axis":
        title_state = getattr(fig, "_gl260_title_state", {}) or {}
        title_pad_pts = float(title_state.get("title_pad_pts", 0.0) or 0.0)
        suptitle_pad_pts = float(title_state.get("suptitle_pad_pts", 0.0) or 0.0)
        suptitle_y = title_state.get("suptitle_y")
        top_margin_pct = 0.0
        legend_gap_pts = 0.0
        xlabel_tick_gap_pts = 0.0
        legend_margin_pts = 0.0
        left_pad_pct = 0.0
        right_pad_pct = 0.0
        export_pad_pts = 0.0
        legend_alignment = "center"
        if plot_id in CORE_RENDER_PROFILE_PLOT_IDS:
            if core_render_profile is None:
                core_render_profile = _get_core_plot_render_profile(plot_id)
            title_pad_pts = _sanitize_spacing_value(
                core_render_profile.get("title_pad_pts", title_pad_pts),
                DEFAULT_COMBINED_TITLE_PAD_PTS,
                MIN_COMBINED_TITLE_PAD_PTS,
                MAX_COMBINED_TITLE_PAD_PTS,
            )
            suptitle_pad_pts = _sanitize_spacing_value(
                core_render_profile.get("suptitle_pad_pts", suptitle_pad_pts),
                DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
                MIN_COMBINED_SUPTITLE_PAD_PTS,
                MAX_COMBINED_SUPTITLE_PAD_PTS,
            )
            suptitle_y = _sanitize_spacing_value(
                core_render_profile.get("suptitle_y", suptitle_y),
                DEFAULT_COMBINED_SUPTITLE_Y,
                MIN_COMBINED_SUPTITLE_Y,
                MAX_COMBINED_SUPTITLE_Y,
            )
            top_margin_pct = _sanitize_spacing_value(
                core_render_profile.get("top_margin_pct", DEFAULT_COMBINED_TOP_MARGIN_PCT),
                DEFAULT_COMBINED_TOP_MARGIN_PCT,
                MIN_COMBINED_TOP_MARGIN_PCT,
                MAX_COMBINED_TOP_MARGIN_PCT,
            )
            legend_gap_pts = _sanitize_spacing_value(
                core_render_profile.get("legend_label_gap_pts", DEFAULT_COMBINED_LEGEND_GAP_PTS),
                DEFAULT_COMBINED_LEGEND_GAP_PTS,
                MIN_COMBINED_LEGEND_GAP_PTS,
                MAX_COMBINED_LEGEND_GAP_PTS,
            )
            xlabel_tick_gap_pts = _sanitize_spacing_value(
                core_render_profile.get(
                    "xlabel_tick_gap_pts", DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS
                ),
                DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS,
                MIN_COMBINED_XLABEL_TICK_GAP_PTS,
                MAX_COMBINED_XLABEL_TICK_GAP_PTS,
            )
            legend_margin_pts = _sanitize_spacing_value(
                core_render_profile.get(
                    "legend_bottom_margin_pts", DEFAULT_COMBINED_LEGEND_MARGIN_PTS
                ),
                DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
                MIN_COMBINED_LEGEND_MARGIN_PTS,
                MAX_COMBINED_LEGEND_MARGIN_PTS,
            )
            left_pad_pct = _sanitize_spacing_value(
                core_render_profile.get("left_padding_pct", DEFAULT_COMBINED_LEFT_PAD_PCT),
                DEFAULT_COMBINED_LEFT_PAD_PCT,
                MIN_COMBINED_SIDE_PAD_PCT,
                MAX_COMBINED_SIDE_PAD_PCT,
            )
            right_pad_pct = _sanitize_spacing_value(
                core_render_profile.get("right_padding_pct", DEFAULT_COMBINED_RIGHT_PAD_PCT),
                DEFAULT_COMBINED_RIGHT_PAD_PCT,
                MIN_COMBINED_SIDE_PAD_PCT,
                MAX_COMBINED_SIDE_PAD_PCT,
            )
            export_pad_pts = _sanitize_spacing_value(
                core_render_profile.get("export_pad_pts", DEFAULT_COMBINED_EXPORT_PAD_PTS),
                DEFAULT_COMBINED_EXPORT_PAD_PTS,
                MIN_COMBINED_EXPORT_PAD_PTS,
                MAX_COMBINED_EXPORT_PAD_PTS,
            )
            legend_alignment = _normalize_legend_alignment(
                core_render_profile.get("legend_alignment")
            )
        xlabel_pad_pts = section.get("xlabel_pad_pts")
        if xlabel_pad_pts is None and isinstance(axis_labelpads, dict):
            xlabel_pad_pts = axis_labelpads.get("x")
        try:
            xlabel_pad_pts_value = float(xlabel_pad_pts) if xlabel_pad_pts is not None else 0.0
        except Exception:
            xlabel_pad_pts_value = 0.0
        layout_mgr = PlotLayoutManager(
            fig,
            mode=mode,
            baseline_margins=margins,
            left_pad_pct=left_pad_pct,
            right_pad_pct=right_pad_pct,
            export_pad_pts=export_pad_pts,
            legend_anchor=legend_anchor,
            legend_anchor_y=legend_anchor_y,
            title_pad_pts=title_pad_pts,
            suptitle_pad_pts=suptitle_pad_pts,
            suptitle_y=(
                suptitle_y if suptitle_y is not None else DEFAULT_COMBINED_SUPTITLE_Y
            ),
            top_margin_pct=top_margin_pct,
            legend_gap_pts=legend_gap_pts,
            xlabel_tick_gap_pts=xlabel_tick_gap_pts,
            legend_margin_pts=legend_margin_pts,
            xlabel_pad_pts=xlabel_pad_pts_value,
        )
        layout_mgr.set_legend_alignment(legend_alignment)
        if axes:
            layout_mgr.register_axes(*axes)
        title_artist = getattr(fig, "_gl260_title_text", None)
        if title_artist is not None:
            layout_mgr.register_artist("title", title_artist)
        suptitle_artist = getattr(fig, "_gl260_suptitle_text", None)
        if suptitle_artist is None:
            suptitle_artist = getattr(fig, "_suptitle", None)
        if suptitle_artist is not None:
            layout_mgr.register_artist("suptitle", suptitle_artist)
        xlabel_artist = getattr(fig, "_gl260_xlabel_text", None)
        if xlabel_artist is not None:
            layout_mgr.register_artist("xlabel", xlabel_artist)
        if main_legend is not None:
            layout_mgr.register_artist("plot_legend", main_legend)
        if cycle_legend is not None:
            layout_mgr.register_artist("cycle_legend", cycle_legend)
        try:
            layout_mgr.solve()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        fig._gl260_layout_manager = layout_mgr  # type: ignore[attr-defined]

    _apply_title_positions(
        fig,
        title_xy=section.get("title_xy"),
        suptitle_xy=section.get("suptitle_xy"),
    )


class AnnotationHistory:
    def __init__(self, limit: int = 80) -> None:
        """Initialize AnnotationHistory instance.
        Used at object creation to configure initial state and bindings."""
        self._limit = max(10, int(limit))
        self._states: List[List[Dict[str, Any]]] = []
        self._index = -1

    def push(self, elements: List[Dict[str, Any]]) -> None:
        """Perform push.
        Used to keep the workflow logic localized and testable."""
        snapshot = copy.deepcopy(elements)
        if self._index < len(self._states) - 1:
            self._states = self._states[: self._index + 1]
        self._states.append(snapshot)
        if len(self._states) > self._limit:
            self._states.pop(0)
        self._index = len(self._states) - 1

    def can_undo(self) -> bool:
        """Check whether it can undo.
        Used to gate conditional behavior in the workflow."""
        return self._index > 0

    def can_redo(self) -> bool:
        """Check whether it can redo.
        Used to gate conditional behavior in the workflow."""
        return 0 <= self._index < len(self._states) - 1

    def undo(self) -> Optional[List[Dict[str, Any]]]:
        """Perform undo.
        Used to keep the workflow logic localized and testable."""
        if not self.can_undo():
            return None
        self._index -= 1
        return copy.deepcopy(self._states[self._index])

    def redo(self) -> Optional[List[Dict[str, Any]]]:
        """Perform redo.
        Used to keep the workflow logic localized and testable."""
        if not self.can_redo():
            return None
        self._index += 1
        return copy.deepcopy(self._states[self._index])


class AnnotationStore:
    def __init__(self, settings_ref: Dict[str, Any]) -> None:
        """Initialize AnnotationStore instance.
        Used at object creation to configure initial state and bindings."""
        self._settings = settings_ref
        self._settings["plot_elements"] = _normalize_plot_elements(
            self._settings.get("plot_elements")
        )
        self._settings["annotations_ui"] = _normalize_annotations_ui(
            self._settings.get("annotations_ui")
        )

    def elements_for(self, plot_id: str) -> List[Dict[str, Any]]:
        """Perform elements for.
        Used to keep the workflow logic localized and testable."""
        elements = self._settings.setdefault("plot_elements", {}).get(plot_id)
        if not isinstance(elements, list):
            elements = []
            self._settings["plot_elements"][plot_id] = elements
        return elements

    def set_elements(self, plot_id: str, elements: List[Dict[str, Any]]) -> None:
        """Set elements.
        Used to persist elements into the current state."""
        normalized = _normalize_plot_elements({plot_id: elements}).get(plot_id, [])
        self._settings.setdefault("plot_elements", {})[plot_id] = normalized

    def ui_state_for(self, plot_id: str) -> Dict[str, Any]:
        """Return or initialize the persisted editor UI state for one plot.

        Purpose:
            Provide a normalized state bucket used by the Plot Elements panel.
        Why:
            The editor stores collapsed/sash/add-defaults state per plot and expects
            this method to always return a complete dictionary.
        Args:
            plot_id: Plot identifier used as the persistence key.
        Returns:
            A mutable state dictionary for the requested plot.
        Side Effects:
            Initializes missing state in `settings["annotations_ui"]`.
        Exceptions:
            None; malformed existing values are replaced with defaults.
        """
        state = self._settings.setdefault("annotations_ui", {}).get(plot_id)
        if not isinstance(state, dict):
            state = {
                "collapsed": False,
                "last_mode": "select",
                "last_selected_id": None,
                "live_update": False,
                "editor_geometry": None,
                "editor_sash": None,
                "add_defaults": _default_add_defaults(),
            }
            self._settings["annotations_ui"][plot_id] = state
        if not isinstance(state.get("add_defaults"), dict):
            state["add_defaults"] = _default_add_defaults()
        return state

    def set_ui_state(self, plot_id: str, **updates: Any) -> None:
        """Set UI state.
        Used to persist UI state into the current state."""
        state = self.ui_state_for(plot_id)
        state.update(updates)
        self._settings.setdefault("annotations_ui", {})[plot_id] = state


class AnnotationRenderer:
    def __init__(self) -> None:
        """Initialize AnnotationRenderer instance.
        Used at object creation to configure initial state and bindings."""
        self._warned_legacy: Set[str] = set()
        self._wrap_cache: Dict[Tuple[Any, ...], str] = {}

    def clear(self, fig: Figure) -> None:
        """Clear value.
        Used to reset value state safely."""
        if fig is None:
            return
        self._wrap_cache.clear()
        artists = list(getattr(fig, "_gl260_annotation_artists", []) or [])
        # Iterate over artists to apply the per-item logic.
        for artist in artists:
            if isinstance(artist, (list, tuple)):
                # Iterate over artist to apply the per-item logic.
                for child in artist:
                    if child is None:
                        continue
                    try:
                        child.remove()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
            else:
                try:
                    artist.remove()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        fig._gl260_annotation_artists = []
        fig._gl260_annotation_artist_map = {}

    def render(
        self,
        fig: Figure,
        axes_map: Dict[str, Axes],
        elements: List[Dict[str, Any]],
    ) -> None:
        """Render value.
        Used to draw value for preview or export workflows."""
        if fig is None:
            return
        self.clear(fig)
        if not elements:
            return
        artists: List[Any] = []
        artist_map: Dict[str, List[Any]] = {}
        ordered = sorted(
            [el for el in elements if isinstance(el, dict)],
            key=lambda item: float(item.get("zorder", ANNOTATION_DEFAULT_ZORDER)),
        )
        # Iterate over ordered to apply the per-item logic.
        for element in ordered:
            if not element.get("visible", True):
                continue
            if element.get("_draft") or element.get("_editor_only"):
                continue
            axes_target = str(element.get("axes_target") or "primary").strip().lower()
            ax = axes_map.get(axes_target) or axes_map.get("primary")
            if ax is None:
                continue
            element_id = str(element.get("id") or "")
            rendered = self._render_element(ax, element)
            if rendered is None:
                continue
            if isinstance(rendered, (list, tuple)):
                # Iterate over rendered to apply the per-item logic.
                for artist in rendered:
                    if artist is None:
                        continue
                    artists.append(artist)
                    if element_id:
                        artist._gl260_annotation_id = element_id
                        artist_map.setdefault(element_id, []).append(artist)
            else:
                artists.append(rendered)
                if element_id:
                    rendered._gl260_annotation_id = element_id
                    artist_map.setdefault(element_id, []).append(rendered)
        fig._gl260_annotation_artists = artists
        fig._gl260_annotation_artist_map = artist_map

    def _iter_trace_target_artists(self, fig: Figure) -> Iterable[Tuple[str, Any]]:
        """Iterate over plot artists that map to trace series keys.
        Used to drive trace-mask and trace-start behavior updates."""
        if fig is None:
            return []
        items: List[Tuple[str, Any]] = []
        for ax in getattr(fig, "axes", []) or []:
            for artist in getattr(ax, "lines", []) or []:
                series_key = _normalize_trace_series_key(
                    getattr(artist, "_gl260_series_key", None),
                    default="",
                )
                if series_key:
                    items.append((series_key, artist))
            for artist in getattr(ax, "collections", []) or []:
                series_key = _normalize_trace_series_key(
                    getattr(artist, "_gl260_series_key", None),
                    default="",
                )
                if series_key:
                    items.append((series_key, artist))
        return items

    def _capture_trace_filter_baseline(self, artist: Any) -> Optional[Tuple[str, Any, Any]]:
        """Capture baseline (unfiltered) data for one trace artist.
        Used to make trace behaviors reversible across redraw/update cycles."""
        if artist is None:
            return None
        baseline = getattr(artist, "_gl260_trace_filter_baseline", None)
        if isinstance(baseline, tuple) and len(baseline) == 3:
            return baseline
        if isinstance(artist, Line2D):
            try:
                x_vals = np.asarray(artist.get_xdata()).reshape(-1)
                y_vals = np.asarray(artist.get_ydata()).reshape(-1)
            except Exception:
                return None
            if x_vals.size != y_vals.size:
                return None
            baseline = ("line", np.array(x_vals, copy=True), np.array(y_vals, copy=True))
            try:
                artist._gl260_trace_filter_baseline = baseline
            except Exception:
                pass
            return baseline
        if hasattr(artist, "get_offsets") and hasattr(artist, "set_offsets"):
            try:
                offsets = np.asarray(artist.get_offsets())
            except Exception:
                return None
            if offsets.ndim != 2 or offsets.shape[1] < 2:
                return None
            x_vals = np.array(offsets[:, 0], copy=True).reshape(-1)
            y_vals = np.array(offsets[:, 1], copy=True).reshape(-1)
            baseline = ("scatter", x_vals, y_vals)
            try:
                artist._gl260_trace_filter_baseline = baseline
            except Exception:
                pass
            return baseline
        return None

    def invalidate_trace_filter_baselines(
        self, fig: Figure, series_keys: Optional[Iterable[str]] = None
    ) -> None:
        """Invalidate cached baseline data for trace-filtering artists.
        Used when upstream plot data changes so behavior filters rebase on fresh arrays."""
        if fig is None:
            return
        key_filter: Optional[Set[str]] = None
        if series_keys is not None:
            key_filter = set()
            for key in series_keys:
                normalized = _normalize_trace_series_key(key, default="")
                if normalized:
                    key_filter.add(normalized)
        for series_key, artist in self._iter_trace_target_artists(fig):
            if key_filter is not None and series_key not in key_filter:
                continue
            try:
                if hasattr(artist, "_gl260_trace_filter_baseline"):
                    delattr(artist, "_gl260_trace_filter_baseline")
            except Exception:
                pass

    def _collect_trace_behavior_rules(
        self,
        elements: Sequence[Mapping[str, Any]],
        scatter_series_settings: Optional[Mapping[str, Any]] = None,
    ) -> Dict[str, Dict[str, Any]]:
        """Collect effective trace-mask and trace-start rules by series key.
        Used to apply consistent behavior filtering across display/export renders."""
        rules: Dict[str, Dict[str, Any]] = {}
        series_settings = (
            scatter_series_settings if isinstance(scatter_series_settings, Mapping) else {}
        )
        for series_key in TRACE_SERIES_KEYS:
            series_cfg = series_settings.get(series_key)
            if not isinstance(series_cfg, Mapping):
                continue
            start_x = _coerce_float(series_cfg.get("start_x"))
            if start_x is None:
                continue
            rules[series_key] = {"start_x": float(start_x), "mask_ranges": []}

        for element in elements or []:
            if not isinstance(element, Mapping):
                continue
            if not element.get("visible", True):
                continue
            if element.get("_draft") or element.get("_editor_only"):
                continue
            element_type = str(element.get("type") or "").strip().lower()
            if element_type not in {"trace_mask", "trace_start"}:
                continue
            geometry = (
                element.get("geometry") if isinstance(element.get("geometry"), Mapping) else {}
            )
            trace_key = _normalize_trace_series_key(geometry.get("trace_key"), default="y2")
            bucket = rules.setdefault(trace_key, {"start_x": None, "mask_ranges": []})
            if element_type == "trace_start":
                x_start = _coerce_float(geometry.get("x_start"))
                if x_start is None:
                    continue
                current = _coerce_float(bucket.get("start_x"))
                if current is None or float(x_start) > float(current):
                    bucket["start_x"] = float(x_start)
                continue
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            if x0 is None or x1 is None:
                continue
            if not math.isfinite(x0) or not math.isfinite(x1):
                continue
            left = min(float(x0), float(x1))
            right = max(float(x0), float(x1))
            if abs(right - left) <= 1e-12:
                continue
            ranges = bucket.setdefault("mask_ranges", [])
            if isinstance(ranges, list):
                ranges.append((left, right))

        for bucket in rules.values():
            ranges = bucket.get("mask_ranges")
            if not isinstance(ranges, list) or not ranges:
                bucket["mask_ranges"] = []
                continue
            merged: List[Tuple[float, float]] = []
            for left, right in sorted(ranges, key=lambda item: (item[0], item[1])):
                if not merged:
                    merged.append((left, right))
                    continue
                prev_left, prev_right = merged[-1]
                if left <= prev_right:
                    merged[-1] = (prev_left, max(prev_right, right))
                else:
                    merged.append((left, right))
            bucket["mask_ranges"] = merged
        return rules

    def apply_trace_behavior_filters(
        self,
        fig: Figure,
        elements: Sequence[Mapping[str, Any]],
        scatter_series_settings: Optional[Mapping[str, Any]] = None,
    ) -> None:
        """Apply trace-start and trace-mask behavior filters to plotted artists.
        Used to hide selected trace segments without mutating source data."""
        if fig is None:
            return
        rules = self._collect_trace_behavior_rules(elements, scatter_series_settings)
        for series_key, artist in self._iter_trace_target_artists(fig):
            baseline = self._capture_trace_filter_baseline(artist)
            if baseline is None:
                continue
            _, x_base, y_base = baseline
            try:
                x_arr = np.asarray(x_base).reshape(-1)
                y_arr = np.asarray(y_base).reshape(-1)
            except Exception:
                continue
            if x_arr.size != y_arr.size:
                continue
            rule = rules.get(series_key, {})
            start_x = _coerce_float(rule.get("start_x")) if isinstance(rule, Mapping) else None
            ranges = rule.get("mask_ranges") if isinstance(rule, Mapping) else []
            hide_mask = np.zeros(x_arr.size, dtype=bool)
            if start_x is not None:
                hide_mask |= x_arr < float(start_x)
            if isinstance(ranges, list):
                for left, right in ranges:
                    hide_mask |= (x_arr >= float(left)) & (x_arr <= float(right))

            if isinstance(artist, Line2D):
                if hide_mask.any():
                    try:
                        y_filtered = np.asarray(y_arr, dtype=float).copy()
                    except Exception:
                        y_filtered = np.array(y_arr, copy=True)
                        if y_filtered.dtype.kind in {"b", "i", "u"}:
                            y_filtered = y_filtered.astype(float, copy=False)
                    try:
                        y_filtered[hide_mask] = np.nan
                    except Exception:
                        y_filtered = np.array(
                            [np.nan if flag else val for val, flag in zip(y_arr, hide_mask)],
                            dtype=float,
                        )
                    try:
                        artist.set_data(x_arr, y_filtered)
                    except Exception:
                        continue
                else:
                    try:
                        artist.set_data(x_arr, y_arr)
                    except Exception:
                        continue
                continue

            if hasattr(artist, "set_offsets"):
                try:
                    if hide_mask.any():
                        visible_mask = ~hide_mask
                        offsets = np.column_stack((x_arr[visible_mask], y_arr[visible_mask]))
                    else:
                        offsets = np.column_stack((x_arr, y_arr))
                    artist.set_offsets(offsets)
                except Exception:
                    continue

    def _style_float(
        self, style: Mapping[str, Any], key: str, default: float, minimum: float
    ) -> float:
        """Perform style float.
        Used to keep the workflow logic localized and testable."""
        return _style_float_from_style(style, key, default, minimum)

    def _style_alpha(self, style: Mapping[str, Any], default: float = 0.9) -> float:
        """Perform style alpha.
        Used to keep the workflow logic localized and testable."""
        return _style_alpha_from_style(style, default)

    def _resolve_color(self, style: Mapping[str, Any], *keys: str) -> str:
        """Resolve color.
        Used to compute color before rendering or export."""
        # Iterate over keys to apply the per-item logic.
        for key in keys:
            value = style.get(key)
            if value:
                return value
        return "#000000"

    def _text_bbox(self, style: Mapping[str, Any]) -> Dict[str, Any]:
        """Perform text bbox.
        Used to keep the workflow logic localized and testable."""
        return _annotation_text_bbox_style(style)

    def _apply_text_shadow(self, text_artist: Any, style: Mapping[str, Any]) -> None:
        """Apply text shadow.
        Used to apply text shadow changes to live state."""
        if not style.get("bbox_shadow"):
            return
        try:
            import matplotlib.patheffects as patheffects

            offset_x = _coerce_float(style.get("bbox_shadow_offset_x"))
            if offset_x is None:
                offset_x = 2.0
            offset_y = _coerce_float(style.get("bbox_shadow_offset_y"))
            if offset_y is None:
                offset_y = -2.0
            shadow_alpha = _coerce_float(style.get("bbox_shadow_alpha"))
            if shadow_alpha is None:
                shadow_alpha = 0.35
            bbox_patch = text_artist.get_bbox_patch()
            if bbox_patch is None:
                return
            bbox_patch.set_path_effects(
                [
                    patheffects.SimplePatchShadow(
                        offset=(offset_x, offset_y), alpha=shadow_alpha
                    ),
                    patheffects.Normal(),
                ]
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return

    def _wrap_text(
        self,
        ax: Axes,
        text_value: str,
        x: Optional[float],
        y: Optional[float],
        wrap_width_x: Optional[float],
        fontsize: float,
    ) -> str:
        """Wrap text.
        Used to format text to fit display constraints."""
        return _wrap_text_for_display(ax, text_value, x, y, wrap_width_x, fontsize)

    def _wrap_text_for_coord_space(
        self,
        ax: Axes,
        text_value: str,
        x: Optional[float],
        y: Optional[float],
        wrap_width_x: Optional[float],
        fontsize: float,
        coord_space: str,
    ) -> str:
        """Wrap text for coord space.
        Used to format text for coord space to fit display constraints."""
        if coord_space != "axes":
            return self._wrap_text(ax, text_value, x, y, wrap_width_x, fontsize)
        if not wrap_width_x or x is None or y is None:
            return text_value
        try:
            disp0 = ax.transAxes.transform((x, y))
            data0 = ax.transData.inverted().transform(disp0)
            disp1 = ax.transAxes.transform((x + wrap_width_x, y))
            data1 = ax.transData.inverted().transform(disp1)
            wrap_width_data = data1[0] - data0[0]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return text_value
        return self._wrap_text(
            ax, text_value, data0[0], data0[1], wrap_width_data, fontsize
        )

    def _wrap_cache_key(
        self,
        ax: Axes,
        element_id: Optional[str],
        text_value: str,
        fontsize: float,
        wrap_width_x: Optional[float],
        coord_space: str,
    ) -> Tuple[Any, ...]:
        """Wrap cache key.
        Used to format cache key to fit display constraints."""
        xlim = None
        ylim = None
        try:
            xlim = tuple(round(val, 6) for val in ax.get_xlim())
            ylim = tuple(round(val, 6) for val in ax.get_ylim())
        except Exception:
            xlim = None
            ylim = None
        return (
            element_id or "",
            text_value,
            round(float(fontsize or 0.0), 3),
            wrap_width_x,
            coord_space,
            xlim,
            ylim,
        )

    def _cached_wrap_text_for_coord_space(
        self,
        ax: Axes,
        element_id: Optional[str],
        text_value: str,
        x: Optional[float],
        y: Optional[float],
        wrap_width_x: Optional[float],
        fontsize: float,
        coord_space: str,
    ) -> str:
        """Wrap text for coord space.
        Used by cached workflows to wrap text for coord space."""
        if not wrap_width_x or x is None or y is None:
            return text_value
        key = self._wrap_cache_key(
            ax, element_id, text_value, fontsize, wrap_width_x, coord_space
        )
        cached = self._wrap_cache.get(key)
        if cached is not None:
            return cached
        wrapped = self._wrap_text_for_coord_space(
            ax, text_value, x, y, wrap_width_x, fontsize, coord_space
        )
        if len(self._wrap_cache) >= 256:
            self._wrap_cache.clear()
        self._wrap_cache[key] = wrapped
        return wrapped

    def _arm_text_bbox_picker(
        self, text_artist: Any, element_id: Optional[str], handle_id: str = "label"
    ) -> None:
        """Perform arm text bbox picker.
        Used to keep the workflow logic localized and testable."""
        if text_artist is None:
            return
        try:
            text_artist.set_picker(5)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if element_id:
            try:
                text_artist._gl260_annotation_id = element_id
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                text_artist._gl260_annotation_handle = handle_id
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                text_artist._gl260_element_id = element_id
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            bbox_patch = text_artist.get_bbox_patch()
        except Exception:
            bbox_patch = None
        if bbox_patch is None:
            return
        try:
            bbox_patch.set_picker(5)
        except Exception:
            try:
                bbox_patch.set_picker(True)
            except Exception:
                pass
        if element_id:
            try:
                bbox_patch._gl260_annotation_id = element_id
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                bbox_patch._gl260_annotation_handle = handle_id
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                bbox_patch._gl260_element_id = element_id
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _resolve_label_y_data(self, ax: Axes, geometry: Mapping[str, Any]) -> float:
        """Resolve label y data.
        Used to compute label y data before rendering or export."""
        label_axes = geometry.get("label_y_axes")
        if label_axes is not None:
            coerced = _coerce_float(label_axes)
            if coerced is not None:
                frac = max(0.0, min(1.0, float(coerced)))
                y_min, y_max = ax.get_ylim()
                return y_min + frac * (y_max - y_min)
        label_y_data = geometry.get("label_y_data")
        if label_y_data is not None:
            coerced = _coerce_float(label_y_data)
            if coerced is not None:
                return coerced
        legacy_axes = geometry.get("legacy_label_y_axes")
        if legacy_axes is None:
            return ax.get_ylim()[1]
        try:
            frac = float(legacy_axes)
        except Exception:
            frac = 0.9
        y_min, y_max = ax.get_ylim()
        migrated = y_min + frac * (y_max - y_min)
        try:
            if isinstance(geometry, dict):
                geometry["label_y_data"] = migrated
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return migrated

    def _migrate_axes_to_data(self, ax: Axes, element: Mapping[str, Any]) -> None:
        """Perform migrate axes to data.
        Used to keep the workflow logic localized and testable."""
        geometry = (
            element.get("geometry")
            if isinstance(element.get("geometry"), Mapping)
            else {}
        )
        if not isinstance(geometry, dict):
            return

        # Closure captures _migrate_axes_to_data local context to keep helper logic scoped and invoked directly within _migrate_axes_to_data.
        def _axes_to_data(x_axes: float, y_axes: float) -> Tuple[float, float]:
            """Perform axes to data.
            Used to keep the workflow logic localized and testable."""
            disp = ax.transAxes.transform((x_axes, y_axes))
            return tuple(ax.transData.inverted().transform(disp))

        element_type = str(element.get("type") or "").strip().lower()
        if element_type in {"text", "point"}:
            x = _coerce_float(geometry.get("x"))
            y = _coerce_float(geometry.get("y"))
            if x is not None and y is not None:
                geometry["x"], geometry["y"] = _axes_to_data(x, y)
        elif element_type in {"callout", "arrow"}:
            # Iterate over ("x0", "y0", "x1", "y1") to apply the per-item logic.
            for key in ("x0", "y0", "x1", "y1"):
                if geometry.get(key) is None:
                    return
            x0, y0 = _axes_to_data(
                _coerce_float(geometry.get("x0")) or 0.0,
                _coerce_float(geometry.get("y0")) or 0.0,
            )
            x1, y1 = _axes_to_data(
                _coerce_float(geometry.get("x1")) or 0.0,
                _coerce_float(geometry.get("y1")) or 0.0,
            )
            geometry.update({"x0": x0, "y0": y0, "x1": x1, "y1": y1})
        elif element_type in {"xspan", "xspan_label"}:
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            if x0 is not None and x1 is not None:
                geometry["x0"] = _axes_to_data(x0, 0.5)[0]
                geometry["x1"] = _axes_to_data(x1, 0.5)[0]
            label_x = _coerce_float(geometry.get("label_x"))
            label_y = _coerce_float(geometry.get("label_y_data"))
            if label_x is not None and label_y is not None:
                geometry["label_x"], geometry["label_y_data"] = _axes_to_data(
                    label_x, label_y
                )
            legacy_axes = geometry.get("legacy_label_y_axes")
            if legacy_axes is not None:
                try:
                    frac = float(legacy_axes)
                except Exception:
                    frac = 0.9
                y_min, y_max = ax.get_ylim()
                geometry["label_y_data"] = y_min + frac * (y_max - y_min)
        elif element_type == "rect":
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            y0 = _coerce_float(geometry.get("y0"))
            y1 = _coerce_float(geometry.get("y1"))
            if None not in (x0, x1, y0, y1):
                geometry["x0"], geometry["y0"] = _axes_to_data(x0, y0)
                geometry["x1"], geometry["y1"] = _axes_to_data(x1, y1)
        elif element_type == "ref_line":
            orientation = str(geometry.get("orientation") or "vertical").strip().lower()
            value = _coerce_float(geometry.get("value"))
            if value is not None:
                if orientation == "horizontal":
                    geometry["value"] = _axes_to_data(0.5, value)[1]
                else:
                    geometry["value"] = _axes_to_data(value, 0.5)[0]
        elif element_type == "ink":
            points = geometry.get("points")
            if isinstance(points, list):
                migrated = []
                # Iterate over points to apply the per-item logic.
                for px, py in points:
                    dx, dy = _axes_to_data(px, py)
                    migrated.append((dx, dy))
                geometry["points"] = migrated
        try:
            element["coord_space"] = "data"
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _render_element(self, ax: Axes, element: Mapping[str, Any]) -> Optional[Any]:
        """Render element.
        Used to draw element for preview or export workflows."""
        element_type = str(element.get("type") or "").strip().lower()
        style = (
            element.get("style") if isinstance(element.get("style"), Mapping) else {}
        )
        geometry = (
            element.get("geometry")
            if isinstance(element.get("geometry"), Mapping)
            else {}
        )
        element_id = str(element.get("id") or "")
        coord_space = str(element.get("coord_space") or "data").strip().lower()
        if coord_space == "axes":
            self._migrate_axes_to_data(ax, element)
            coord_space = "data"
        transform = ax.transAxes if coord_space == "axes" else ax.transData
        alpha = self._style_alpha(style, 0.9)
        linewidth = self._style_float(style, "linewidth", 1.5, 0.2)
        zorder = _coerce_float(element.get("zorder")) or ANNOTATION_DEFAULT_ZORDER
        color = self._resolve_color(style, "color", "edgecolor", "linecolor")

        if element_type in {"trace_mask", "trace_start"}:
            # Behavior-only elements do not render persistent artists.
            return None

        if element_type == "text":
            x = _coerce_float(geometry.get("x"))
            y = _coerce_float(geometry.get("y"))
            if x is None or y is None:
                return None
            fontsize = self._style_float(style, "fontsize", 10.0, 4.0)
            text_value = geometry.get("text", "Text")
            wrap_width = _coerce_float(geometry.get("wrap_width_x"))
            wrapped = self._cached_wrap_text_for_coord_space(
                ax,
                element_id,
                str(text_value),
                x,
                y,
                wrap_width,
                fontsize,
                coord_space,
            )
            artist = ax.text(
                x,
                y,
                wrapped,
                transform=transform,
                fontsize=fontsize,
                fontfamily=style.get("fontfamily", None),
                fontweight=style.get("fontweight", None),
                color=self._resolve_color(style, "text_color", "color"),
                alpha=alpha,
                ha=style.get("text_align", "left"),
                va=style.get("text_valign", "bottom"),
                zorder=zorder,
                bbox=self._text_bbox(style),
            )
            artist.set_wrap(True)
            self._arm_text_bbox_picker(artist, element_id, "label")
            self._apply_text_shadow(artist, style)
            return artist

        if element_type == "callout":
            x0 = _coerce_float(geometry.get("x0"))
            y0 = _coerce_float(geometry.get("y0"))
            x1 = _coerce_float(geometry.get("x1"))
            y1 = _coerce_float(geometry.get("y1"))
            if None in (x0, y0, x1, y1):
                return None
            fontsize = self._style_float(style, "fontsize", 10.0, 4.0)
            text_value = str(geometry.get("text", "Callout"))
            arrowstyle = style.get("arrowstyle", "->")
            artist = ax.annotate(
                text_value,
                xy=(x0, y0),
                xytext=(x1, y1),
                xycoords=transform,
                textcoords=transform,
                fontsize=fontsize,
                fontfamily=style.get("fontfamily", None),
                fontweight=style.get("fontweight", None),
                color=self._resolve_color(style, "text_color", "color"),
                alpha=alpha,
                ha=style.get("text_align", "left"),
                va=style.get("text_valign", "bottom"),
                bbox=self._text_bbox(style),
                arrowprops={
                    "arrowstyle": arrowstyle,
                    "linewidth": linewidth,
                    "color": color,
                    "alpha": alpha,
                },
            )
            artist.set_zorder(zorder)
            self._arm_text_bbox_picker(artist, element_id, "label")
            self._apply_text_shadow(artist, style)
            return artist

        if element_type == "arrow":
            x0 = _coerce_float(geometry.get("x0"))
            y0 = _coerce_float(geometry.get("y0"))
            x1 = _coerce_float(geometry.get("x1"))
            y1 = _coerce_float(geometry.get("y1"))
            if None in (x0, y0, x1, y1):
                return None
            arrowstyle = style.get("arrowstyle", "->")
            text_value = geometry.get("text")
            artist = ax.annotate(
                "" if text_value is None else str(text_value),
                xy=(x1, y1),
                xytext=(x0, y0),
                xycoords=transform,
                textcoords=transform,
                fontsize=self._style_float(style, "fontsize", 10.0, 4.0),
                fontfamily=style.get("fontfamily", None),
                fontweight=style.get("fontweight", None),
                color=self._resolve_color(style, "text_color", "color"),
                alpha=alpha,
                ha=style.get("text_align", "left"),
                va=style.get("text_valign", "bottom"),
                bbox=self._text_bbox(style) if text_value else None,
                arrowprops={
                    "arrowstyle": arrowstyle,
                    "linewidth": linewidth,
                    "color": color,
                    "alpha": alpha,
                },
            )
            artist.set_zorder(zorder)
            if text_value:
                self._arm_text_bbox_picker(artist, element_id, "label")
                self._apply_text_shadow(artist, style)
            return artist

        if element_type == "point":
            x = _coerce_float(geometry.get("x"))
            y = _coerce_float(geometry.get("y"))
            if x is None or y is None:
                return None
            marker = style.get("marker", "o")
            marker_size = self._style_float(style, "marker_size", 8.0, 2.0)
            face = self._resolve_color(style, "marker_facecolor", "color")
            edge = self._resolve_color(style, "marker_edgecolor", "color")
            (artist,) = ax.plot(
                [x],
                [y],
                linestyle="None",
                marker=marker,
                markersize=marker_size,
                markerfacecolor=face,
                markeredgecolor=edge,
                alpha=alpha,
                transform=transform,
                zorder=zorder,
            )
            return artist

        if element_type in {"xspan", "xspan_label"}:
            from matplotlib import patches as mpatches
  
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            if x0 is None or x1 is None:
                return None
            left = min(x0, x1)
            width = abs(x1 - x0)
            if coord_space == "axes":
                span_transform = ax.transAxes
            else:
                span_transform = ax.get_xaxis_transform()
            face = self._resolve_color(style, "facecolor", "fill_color", "color")
            edge = self._resolve_color(style, "edgecolor", "color")
            span_layer = str(style.get("span_layer") or "behind_data").strip().lower()
            span_zorder = (
                zorder if span_layer == "above_data" else ANNOTATION_SPAN_BACKGROUND_ZORDER
            )
            rect = mpatches.Rectangle(
                (left, 0.0),
                width,
                1.0,
                transform=span_transform,
                facecolor=face,
                edgecolor=edge,
                linewidth=linewidth,
                alpha=alpha,
                zorder=span_zorder,
            )
            ax.add_patch(rect)
            artists: List[Any] = [rect]
            if element_type == "xspan_label":
                label_x = _coerce_float(geometry.get("label_x"))
                if label_x is None:
                    label_x = (x0 + x1) / 2.0
                label_y_axes = _coerce_float(geometry.get("label_y_axes"))
                if label_y_axes is not None:
                    label_y_axes = max(0.0, min(1.0, float(label_y_axes)))
                    if coord_space == "axes":
                        label_transform = ax.transAxes
                    else:
                        label_transform = blended_transform_factory(
                            ax.transData, ax.transAxes
                        )
                    label_y = label_y_axes
                    label_y_data = self._resolve_label_y_data(ax, geometry)
                else:
                    label_y = self._resolve_label_y_data(ax, geometry)
                    label_transform = transform if coord_space == "axes" else ax.transData
                    label_y_data = label_y
                text_value = str(geometry.get("text", "Label"))
                fontsize = self._style_float(style, "fontsize", 10.0, 4.0)
                wrap_width = _coerce_float(geometry.get("wrap_width_x"))
                if coord_space == "axes":
                    wrap_target_y = label_y
                else:
                    wrap_target_y = label_y_data
                wrapped = self._cached_wrap_text_for_coord_space(
                    ax,
                    element_id,
                    text_value,
                    label_x,
                    wrap_target_y,
                    wrap_width,
                    fontsize,
                    coord_space,
                )
                text_artist = ax.text(
                    label_x,
                    label_y,
                    wrapped,
                    transform=label_transform,
                    fontsize=fontsize,
                    fontfamily=style.get("fontfamily", None),
                    fontweight=style.get("fontweight", None),
                    color=self._resolve_color(style, "text_color", "color"),
                    alpha=alpha,
                    ha=style.get("text_align", geometry.get("label_anchor", "center")),
                    va=style.get("text_valign", "center"),
                    zorder=zorder + 1,
                    bbox=self._text_bbox(style),
                )
                self._arm_text_bbox_picker(text_artist, element_id, "label")
                text_artist.set_wrap(True)
                self._apply_text_shadow(text_artist, style)
                artists.append(text_artist)
            return artists

        if element_type == "rect":
            from matplotlib import patches as mpatches

            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            y0 = _coerce_float(geometry.get("y0"))
            y1 = _coerce_float(geometry.get("y1"))
            if None in (x0, x1, y0, y1):
                return None
            left = min(x0, x1)
            bottom = min(y0, y1)
            width = abs(x1 - x0)
            height = abs(y1 - y0)
            face = self._resolve_color(style, "facecolor", "fill_color", "color")
            edge = self._resolve_color(style, "edgecolor", "color")
            rect = mpatches.Rectangle(
                (left, bottom),
                width,
                height,
                transform=transform,
                facecolor=face,
                edgecolor=edge,
                linewidth=linewidth,
                linestyle=style.get("linestyle", "solid"),
                alpha=alpha,
                zorder=zorder,
            )
            ax.add_patch(rect)
            artists = [rect]
            label = geometry.get("text")
            if label:
                text_artist = ax.text(
                    (x0 + x1) / 2.0,
                    (y0 + y1) / 2.0,
                    str(label),
                    transform=transform,
                    fontsize=self._style_float(style, "fontsize", 10.0, 4.0),
                    fontfamily=style.get("fontfamily", None),
                    fontweight=style.get("fontweight", None),
                    color=self._resolve_color(style, "text_color", "color"),
                    alpha=alpha,
                    ha=style.get("text_align", "center"),
                    va=style.get("text_valign", "center"),
                    zorder=zorder + 1,
                    bbox=self._text_bbox(style),
                )
                self._arm_text_bbox_picker(text_artist, element_id, "label")
                self._apply_text_shadow(text_artist, style)
                artists.append(text_artist)
            return artists

        if element_type == "ref_line":
            orientation = str(geometry.get("orientation") or "vertical").strip().lower()
            value = _coerce_float(geometry.get("value"))
            if value is None:
                return None
            if orientation == "horizontal":
                line = ax.axhline(
                    value,
                    color=color,
                    linewidth=linewidth,
                    linestyle=style.get("linestyle", "solid"),
                    alpha=alpha,
                    zorder=zorder,
                )
            else:
                line = ax.axvline(
                    value,
                    color=color,
                    linewidth=linewidth,
                    linestyle=style.get("linestyle", "solid"),
                    alpha=alpha,
                    zorder=zorder,
                )
            artists = [line]
            label = geometry.get("text")
            if label:
                if orientation == "horizontal":
                    label_x = _coerce_float(geometry.get("label_x"))
                    if label_x is None:
                        label_x = ax.get_xlim()[0]
                    label_y = value
                else:
                    label_x = value
                    label_y = _coerce_float(geometry.get("label_y"))
                    if label_y is None:
                        label_y = ax.get_ylim()[1]
                text_artist = ax.text(
                    label_x,
                    label_y,
                    str(label),
                    transform=ax.transData,
                    fontsize=self._style_float(style, "fontsize", 10.0, 4.0),
                    fontfamily=style.get("fontfamily", None),
                    fontweight=style.get("fontweight", None),
                    color=self._resolve_color(style, "text_color", "color"),
                    alpha=alpha,
                    ha=style.get("text_align", "left"),
                    va=style.get("text_valign", "bottom"),
                    zorder=zorder + 1,
                    bbox=self._text_bbox(style),
                )
                self._arm_text_bbox_picker(text_artist, element_id, "label")
                self._apply_text_shadow(text_artist, style)
                artists.append(text_artist)
            return artists

        if element_type == "ink":
            points = (
                geometry.get("points")
                if isinstance(geometry.get("points"), list)
                else []
            )
            if not points:
                return None
            if element.get("_legacy_pixel_based"):
                element_id = str(element.get("id"))
                if element_id not in self._warned_legacy:
                    self._warned_legacy.add(element_id)
                    print(
                        f"[WARN] Legacy ink element '{element_id}' uses non-data coordinates."
                    )
            try:
                xs, ys = zip(*points)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            line = Line2D(xs, ys, color=color, alpha=alpha, linewidth=linewidth)
            if coord_space == "axes":
                line.set_transform(ax.transAxes)
            line.set_zorder(zorder)
            ax.add_line(line)
            return line

        return None

    def update_artists(
        self,
        ax: Axes,
        element: Mapping[str, Any],
        artists: Sequence[Any],
        *,
        skip_wrap: bool = False,
    ) -> bool:
        """Update artists.
        Used to keep artists in sync with current state."""
        if ax is None or not artists:
            return False
        element_type = str(element.get("type") or "").strip().lower()
        style = (
            element.get("style") if isinstance(element.get("style"), Mapping) else {}
        )
        geometry = (
            element.get("geometry")
            if isinstance(element.get("geometry"), Mapping)
            else {}
        )
        coord_space = str(element.get("coord_space") or "data").strip().lower()
        transform = ax.transAxes if coord_space == "axes" else ax.transData
        alpha = self._style_alpha(style, 0.9)
        linewidth = self._style_float(style, "linewidth", 1.5, 0.2)
        zorder = _coerce_float(element.get("zorder")) or ANNOTATION_DEFAULT_ZORDER
        color = self._resolve_color(style, "color", "edgecolor", "linecolor")
        if element_type in {"trace_mask", "trace_start"}:
            return False

        try:
            if element_type == "text":
                artist = artists[0]
                x = _coerce_float(geometry.get("x"))
                y = _coerce_float(geometry.get("y"))
                if x is None or y is None:
                    return False
                fontsize = self._style_float(style, "fontsize", 10.0, 4.0)
                text_value = geometry.get("text", "Text")
                wrap_width = _coerce_float(geometry.get("wrap_width_x"))
                element_id = str(element.get("id") or "")
                if skip_wrap:
                    wrapped = artist.get_text()
                else:
                    wrapped = self._cached_wrap_text_for_coord_space(
                        ax,
                        element_id,
                        str(text_value),
                        x,
                        y,
                        wrap_width,
                        fontsize,
                        coord_space,
                    )
                artist.set_transform(transform)
                artist.set_position((x, y))
                if not skip_wrap:
                    artist.set_text(wrapped)
                artist.set_fontsize(fontsize)
                artist.set_color(self._resolve_color(style, "text_color", "color"))
                artist.set_alpha(alpha)
                artist.set_ha(style.get("text_align", "left"))
                artist.set_va(style.get("text_valign", "bottom"))
                artist.set_zorder(zorder)
                if not skip_wrap:
                    artist.set_bbox(self._text_bbox(style))
                    artist.set_wrap(True)
                    self._arm_text_bbox_picker(artist, element_id, "label")
                return True

            if element_type == "callout":
                artist = artists[0]
                x0 = _coerce_float(geometry.get("x0"))
                y0 = _coerce_float(geometry.get("y0"))
                x1 = _coerce_float(geometry.get("x1"))
                y1 = _coerce_float(geometry.get("y1"))
                if None in (x0, y0, x1, y1):
                    return False
                artist.xy = (x0, y0)
                artist.set_position((x1, y1))
                artist.set_text(str(geometry.get("text", "Callout")))
                artist.set_color(self._resolve_color(style, "text_color", "color"))
                artist.set_alpha(alpha)
                artist.set_fontsize(self._style_float(style, "fontsize", 10.0, 4.0))
                artist.set_bbox(self._text_bbox(style))
                self._arm_text_bbox_picker(artist, str(element.get("id") or ""), "label")
                arrow_patch = getattr(artist, "arrow_patch", None)
                if arrow_patch is not None:
                    arrow_patch.set_linewidth(linewidth)
                    arrow_patch.set_alpha(alpha)
                    arrow_patch.set_edgecolor(color)
                    arrow_patch.set_facecolor(color)
                artist.set_zorder(zorder)
                return True

            if element_type == "arrow":
                artist = artists[0]
                x0 = _coerce_float(geometry.get("x0"))
                y0 = _coerce_float(geometry.get("y0"))
                x1 = _coerce_float(geometry.get("x1"))
                y1 = _coerce_float(geometry.get("y1"))
                if None in (x0, y0, x1, y1):
                    return False
                artist.xy = (x1, y1)
                artist.set_position((x0, y0))
                text_value = geometry.get("text")
                if text_value is not None:
                    artist.set_text(str(text_value))
                    artist.set_bbox(self._text_bbox(style))
                    artist.set_color(self._resolve_color(style, "text_color", "color"))
                    self._arm_text_bbox_picker(
                        artist, str(element.get("id") or ""), "label"
                    )
                arrow_patch = getattr(artist, "arrow_patch", None)
                if arrow_patch is not None:
                    arrow_patch.set_linewidth(linewidth)
                    arrow_patch.set_alpha(alpha)
                    arrow_patch.set_edgecolor(color)
                    arrow_patch.set_facecolor(color)
                artist.set_zorder(zorder)
                return True

            if element_type == "point":
                artist = artists[0]
                x = _coerce_float(geometry.get("x"))
                y = _coerce_float(geometry.get("y"))
                if x is None or y is None:
                    return False
                marker = style.get("marker", "o")
                marker_size = self._style_float(style, "marker_size", 8.0, 2.0)
                face = self._resolve_color(style, "marker_facecolor", "color")
                edge = self._resolve_color(style, "marker_edgecolor", "color")
                artist.set_data([x], [y])
                artist.set_marker(marker)
                artist.set_markersize(marker_size)
                artist.set_markerfacecolor(face)
                artist.set_markeredgecolor(edge)
                artist.set_alpha(alpha)
                artist.set_zorder(zorder)
                return True

            if element_type in {"xspan", "xspan_label"}:
                from matplotlib import patches as mpatches

                patch = next(
                    (a for a in artists if isinstance(a, mpatches.Rectangle)), None
                )
                if patch is None:
                    return False
                x0 = _coerce_float(geometry.get("x0"))
                x1 = _coerce_float(geometry.get("x1"))
                if x0 is None or x1 is None:
                    return False
                left = min(x0, x1)
                width = abs(x1 - x0)
                span_layer = str(style.get("span_layer") or "behind_data").strip().lower()
                span_zorder = (
                    zorder
                    if span_layer == "above_data"
                    else ANNOTATION_SPAN_BACKGROUND_ZORDER
                )
                patch.set_x(left)
                patch.set_width(width)
                patch.set_facecolor(self._resolve_color(style, "facecolor", "color"))
                patch.set_edgecolor(self._resolve_color(style, "edgecolor", "color"))
                patch.set_linewidth(linewidth)
                patch.set_alpha(alpha)
                patch.set_zorder(span_zorder)
                if element_type == "xspan_label":
                    text_artist = next(
                        (a for a in artists if hasattr(a, "set_text")), None
                    )
                    if text_artist is None:
                        return False
                    label_x = _coerce_float(geometry.get("label_x"))
                    if label_x is None:
                        label_x = (x0 + x1) / 2.0
                    label_y_axes = _coerce_float(geometry.get("label_y_axes"))
                    if label_y_axes is not None:
                        label_y_axes = max(0.0, min(1.0, float(label_y_axes)))
                    if label_y_axes is not None:
                        if coord_space == "axes":
                            label_transform = ax.transAxes
                            label_y = label_y_axes
                        else:
                            label_transform = blended_transform_factory(
                                ax.transData, ax.transAxes
                            )
                            label_y = label_y_axes
                        label_y_data = self._resolve_label_y_data(ax, geometry)
                    else:
                        label_y = self._resolve_label_y_data(ax, geometry)
                        label_transform = (
                            transform if coord_space == "axes" else ax.transData
                        )
                        label_y_data = label_y
                    text_value = str(geometry.get("text", "Label"))
                    fontsize = self._style_float(style, "fontsize", 10.0, 4.0)
                    wrap_width = _coerce_float(geometry.get("wrap_width_x"))
                    wrap_target_y = label_y if coord_space == "axes" else label_y_data
                    text_artist.set_transform(label_transform)
                    text_artist.set_position((label_x, label_y))
                    if not skip_wrap:
                        element_id = str(element.get("id") or "")
                        wrapped = self._cached_wrap_text_for_coord_space(
                            ax,
                            element_id,
                            text_value,
                            label_x,
                            wrap_target_y,
                            wrap_width,
                            fontsize,
                            coord_space,
                        )
                        text_artist.set_text(wrapped)
                    text_artist.set_fontsize(fontsize)
                    text_artist.set_color(self._resolve_color(style, "text_color", "color"))
                    text_artist.set_alpha(alpha)
                    text_artist.set_ha(style.get("text_align", geometry.get("label_anchor", "center")))
                    text_artist.set_va(style.get("text_valign", "center"))
                    text_artist.set_zorder(zorder + 1)
                    if not skip_wrap:
                        text_artist.set_bbox(self._text_bbox(style))
                        text_artist.set_wrap(True)
                        self._arm_text_bbox_picker(
                            text_artist, str(element.get("id") or ""), "label"
                        )
                return True

            if element_type == "rect":
                from matplotlib import patches as mpatches

                patch = next(
                    (a for a in artists if isinstance(a, mpatches.Rectangle)), None
                )
                if patch is None:
                    return False
                x0 = _coerce_float(geometry.get("x0"))
                x1 = _coerce_float(geometry.get("x1"))
                y0 = _coerce_float(geometry.get("y0"))
                y1 = _coerce_float(geometry.get("y1"))
                if None in (x0, x1, y0, y1):
                    return False
                left = min(x0, x1)
                bottom = min(y0, y1)
                width = abs(x1 - x0)
                height = abs(y1 - y0)
                patch.set_x(left)
                patch.set_y(bottom)
                patch.set_width(width)
                patch.set_height(height)
                patch.set_alpha(alpha)
                patch.set_edgecolor(self._resolve_color(style, "edgecolor", "color"))
                patch.set_facecolor(self._resolve_color(style, "facecolor", "color"))
                patch.set_linewidth(linewidth)
                patch.set_linestyle(style.get("linestyle", "solid"))
                patch.set_zorder(zorder)
                label = geometry.get("text")
                text_artist = next(
                    (a for a in artists if hasattr(a, "set_text")), None
                )
                if label:
                    if text_artist is None:
                        return False
                    text_artist.set_position(((x0 + x1) / 2.0, (y0 + y1) / 2.0))
                    text_artist.set_text(str(label))
                    text_artist.set_alpha(alpha)
                    text_artist.set_color(self._resolve_color(style, "text_color", "color"))
                    text_artist.set_fontsize(self._style_float(style, "fontsize", 10.0, 4.0))
                    text_artist.set_zorder(zorder + 1)
                    text_artist.set_bbox(self._text_bbox(style))
                    self._arm_text_bbox_picker(
                        text_artist, str(element.get("id") or ""), "label"
                    )
                return True

            if element_type == "ref_line":
                line = next((a for a in artists if hasattr(a, "set_data")), None)
                if line is None:
                    return False
                orientation = str(geometry.get("orientation") or "vertical").strip().lower()
                value = _coerce_float(geometry.get("value"))
                if value is None:
                    return False
                if orientation == "horizontal":
                    line.set_ydata([value, value])
                else:
                    line.set_xdata([value, value])
                line.set_color(color)
                line.set_alpha(alpha)
                line.set_linewidth(linewidth)
                line.set_linestyle(style.get("linestyle", "solid"))
                line.set_zorder(zorder)
                label = geometry.get("text")
                text_artist = next(
                    (a for a in artists if hasattr(a, "set_text")), None
                )
                if label:
                    if text_artist is None:
                        return False
                    if orientation == "horizontal":
                        label_x = _coerce_float(geometry.get("label_x"))
                        if label_x is None:
                            label_x = ax.get_xlim()[0]
                        label_y = value
                    else:
                        label_x = value
                        label_y = _coerce_float(geometry.get("label_y"))
                        if label_y is None:
                            label_y = ax.get_ylim()[1]
                    text_artist.set_position((label_x, label_y))
                    text_artist.set_text(str(label))
                    text_artist.set_alpha(alpha)
                    text_artist.set_color(self._resolve_color(style, "text_color", "color"))
                    text_artist.set_fontsize(self._style_float(style, "fontsize", 10.0, 4.0))
                    text_artist.set_zorder(zorder + 1)
                    text_artist.set_bbox(self._text_bbox(style))
                    self._arm_text_bbox_picker(
                        text_artist, str(element.get("id") or ""), "label"
                    )
                return True

            if element_type == "ink":
                line = artists[0]
                points = (
                    geometry.get("points")
                    if isinstance(geometry.get("points"), list)
                    else []
                )
                if points:
                    xs, ys = zip(*points)
                    line.set_data(xs, ys)
                line.set_color(color)
                line.set_alpha(alpha)
                line.set_linewidth(linewidth)
                line.set_zorder(zorder)
                return True
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return False
        return False


class AnnotationHitTest:
    def __init__(self, pixel_tolerance: float = 8.0) -> None:
        """Initialize AnnotationHitTest instance.
        Used at object creation to configure initial state and bindings."""
        self._pixel_tolerance = float(pixel_tolerance)
        self._text_bbox_cache: Dict[Tuple[Any, ...], Tuple[float, float, float, float]] = {}
        self._span_bbox_cache: Dict[
            Tuple[Any, ...], Tuple[Tuple[float, float, float, float], Optional[float]]
        ] = {}

    def clear_cache(self) -> None:
        """Clear cache.
        Used to reset cache state safely."""
        self._text_bbox_cache.clear()
        self._span_bbox_cache.clear()

    def _text_bbox_display(
        self, ax: Axes, element: Mapping[str, Any]
    ) -> Optional[Tuple[float, float, float, float]]:
        """Perform text bbox display.
        Used to keep the workflow logic localized and testable."""
        text_artist = None
        try:
            if ax is None or element is None:
                return None
            geometry = (
                element.get("geometry")
                if isinstance(element.get("geometry"), Mapping)
                else {}
            )
            style = (
                element.get("style")
                if isinstance(element.get("style"), Mapping)
                else {}
            )
            coord_space = str(element.get("coord_space") or "data").strip().lower()
            x = _coerce_float(geometry.get("x"))
            y = _coerce_float(geometry.get("y"))
            if x is None or y is None:
                return None
            fontsize = _style_float_from_style(style, "fontsize", 10.0, 4.0)
            text_value = geometry.get("text", "Text")
            wrap_width = _coerce_float(geometry.get("wrap_width_x"))
            element_id = str(element.get("id") or "")
            xlim = ylim = None
            try:
                xlim = tuple(round(val, 6) for val in ax.get_xlim())
                ylim = tuple(round(val, 6) for val in ax.get_ylim())
            except Exception:
                xlim = None
                ylim = None
            cache_key = (
                element_id,
                str(text_value),
                round(float(fontsize or 0.0), 3),
                wrap_width,
                coord_space,
                round(float(x), 6),
                round(float(y), 6),
                xlim,
                ylim,
            )
            cached = self._text_bbox_cache.get(cache_key)
            if cached is not None:
                return cached
            wrapped = str(text_value)
            if coord_space == "axes":
                try:
                    disp0 = ax.transAxes.transform((x, y))
                    data0 = ax.transData.inverted().transform(disp0)
                    wrap_width_data = None
                    if wrap_width is not None:
                        disp1 = ax.transAxes.transform((x + wrap_width, y))
                        data1 = ax.transData.inverted().transform(disp1)
                        wrap_width_data = data1[0] - data0[0]
                    wrapped = _wrap_text_for_display(
                        ax, str(text_value), data0[0], data0[1], wrap_width_data, fontsize
                    )
                except Exception:
                    wrapped = str(text_value)
            else:
                wrapped = _wrap_text_for_display(
                    ax, str(text_value), x, y, wrap_width, fontsize
                )
            fig = ax.figure
            if fig is None or fig.canvas is None:
                return None
            renderer = fig.canvas.get_renderer()
            if renderer is None:
                return None
            text_artist = ax.text(
                x,
                y,
                wrapped,
                transform=ax.transAxes if coord_space == "axes" else ax.transData,
                fontsize=fontsize,
                fontfamily=style.get("fontfamily", None),
                fontweight=style.get("fontweight", None),
                color=style.get("text_color") or style.get("color") or "#000000",
                alpha=_style_alpha_from_style(style, 0.9),
                ha=style.get("text_align", "left"),
                va=style.get("text_valign", "bottom"),
                bbox=_annotation_text_bbox_style(style),
            )
            text_artist.set_wrap(True)
            bbox = text_artist.get_window_extent(renderer=renderer)
            result = (bbox.x0, bbox.y0, bbox.x1, bbox.y1)
            if len(self._text_bbox_cache) >= 256:
                self._text_bbox_cache.clear()
            self._text_bbox_cache[cache_key] = result
            return result
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        finally:
            if text_artist is not None:
                try:
                    text_artist.remove()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

    def hit_test(
        self, ax: Axes, element: Mapping[str, Any], event: Any
    ) -> Optional[str]:
        """Perform hit test.
        Used to keep the workflow logic localized and testable."""
        if ax is None or event is None:
            return None
        element_type = str(element.get("type") or "").strip().lower()
        geometry = (
            element.get("geometry")
            if isinstance(element.get("geometry"), Mapping)
            else {}
        )
        coord_space = str(element.get("coord_space") or "data").strip().lower()
        transform = ax.transAxes if coord_space == "axes" else ax.transData
        event_xy = (event.x, event.y)
        if event_xy[0] is None or event_xy[1] is None:
            return None
        event_data = None
        event_axes = None

        def _event_data_coords() -> Optional[Tuple[float, float]]:
            """Perform event data coords.
            Used to keep the workflow logic localized and testable."""
            try:
                return tuple(ax.transData.inverted().transform(event_xy))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None

        def _event_axes_coords() -> Optional[Tuple[float, float]]:
            """Perform event axes coords.
            Used to keep the workflow logic localized and testable."""
            try:
                return tuple(ax.transAxes.inverted().transform(event_xy))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None

        def _dist_to_point(data_x: float, data_y: float) -> float:
            """Perform dist to point.
            Used to keep the workflow logic localized and testable."""
            try:
                disp = transform.transform((data_x, data_y))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return float("inf")
            return math.hypot(disp[0] - event_xy[0], disp[1] - event_xy[1])

        def _close_to_line(p0: Tuple[float, float], p1: Tuple[float, float]) -> bool:
            """Close to line.
            Used by UI actions to close to line safely."""
            try:
                p0_disp = transform.transform(p0)
                p1_disp = transform.transform(p1)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return False
            x0, y0 = p0_disp
            x1, y1 = p1_disp
            px, py = event_xy
            dx = x1 - x0
            dy = y1 - y0
            if dx == 0 and dy == 0:
                return math.hypot(px - x0, py - y0) <= self._pixel_tolerance
            t = ((px - x0) * dx + (py - y0) * dy) / (dx * dx + dy * dy)
            t = max(0.0, min(1.0, t))
            proj_x = x0 + t * dx
            proj_y = y0 + t * dy
            return math.hypot(px - proj_x, py - proj_y) <= self._pixel_tolerance

        if element_type == "text":
            x = _coerce_float(geometry.get("x"))
            y = _coerce_float(geometry.get("y"))
            if x is None or y is None:
                return None
            bbox = self._text_bbox_display(ax, element)
            if bbox is not None:
                x0, y0, x1, y1 = bbox
                tol = self._pixel_tolerance
                px, py = event_xy
                wrap_edge_x = x1
                wrap_width = _coerce_float(geometry.get("wrap_width_x"))
                if wrap_width is None or wrap_width <= 0:
                    try:
                        x_limits = ax.get_xlim()
                        wrap_width = 0.20 * abs(x_limits[1] - x_limits[0])
                    except Exception:
                        wrap_width = None
                if wrap_width is not None:
                    try:
                        if coord_space == "axes":
                            wrap_edge_x = ax.transAxes.transform((x + wrap_width, y))[0]
                        else:
                            wrap_edge_x = ax.transData.transform((x + wrap_width, y))[0]
                    except Exception:
                        wrap_edge_x = x1
                if abs(px - wrap_edge_x) <= tol and (y0 - tol) <= py <= (y1 + tol):
                    return "wrap"
                if (x0 - tol) <= px <= (x1 + tol) and (y0 - tol) <= py <= (y1 + tol):
                    return "move"
                return None
            if _dist_to_point(x, y) <= self._pixel_tolerance:
                return "move"
            return None

        if element_type == "callout":
            x0 = _coerce_float(geometry.get("x0"))
            y0 = _coerce_float(geometry.get("y0"))
            x1 = _coerce_float(geometry.get("x1"))
            y1 = _coerce_float(geometry.get("y1"))
            if None in (x0, y0, x1, y1):
                return None
            if _dist_to_point(x0, y0) <= self._pixel_tolerance:
                return "anchor"
            if _dist_to_point(x1, y1) <= self._pixel_tolerance:
                return "text"
            if _close_to_line((x0, y0), (x1, y1)):
                return "move"
            text_artist = None
            try:
                fig = ax.figure
                if fig is None or fig.canvas is None:
                    return None
                renderer = fig.canvas.get_renderer()
                if renderer is None:
                    return None
                style = (
                    element.get("style")
                    if isinstance(element.get("style"), Mapping)
                    else {}
                )
                fontsize = _style_float_from_style(style, "fontsize", 10.0, 4.0)
                text_value = str(geometry.get("text", "Callout"))
                text_artist = ax.text(
                    x1,
                    y1,
                    text_value,
                    transform=transform,
                    fontsize=fontsize,
                    fontfamily=style.get("fontfamily", None),
                    fontweight=style.get("fontweight", None),
                    color=style.get("text_color") or style.get("color") or "#000000",
                    alpha=_style_alpha_from_style(style, 0.9),
                    ha=style.get("text_align", "left"),
                    va=style.get("text_valign", "bottom"),
                    bbox=_annotation_text_bbox_style(style),
                )
                text_artist.set_wrap(True)
                bbox = text_artist.get_window_extent(renderer=renderer)
                tol = self._pixel_tolerance
                if (bbox.x0 - tol) <= event_xy[0] <= (bbox.x1 + tol) and (
                    bbox.y0 - tol
                ) <= event_xy[1] <= (bbox.y1 + tol):
                    return "move"
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            finally:
                if text_artist is not None:
                    try:
                        text_artist.remove()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

        if element_type == "arrow":
            x0 = _coerce_float(geometry.get("x0"))
            y0 = _coerce_float(geometry.get("y0"))
            x1 = _coerce_float(geometry.get("x1"))
            y1 = _coerce_float(geometry.get("y1"))
            if None in (x0, y0, x1, y1):
                return None
            if _dist_to_point(x0, y0) <= self._pixel_tolerance:
                return "tail"
            if _dist_to_point(x1, y1) <= self._pixel_tolerance:
                return "head"
            if _close_to_line((x0, y0), (x1, y1)):
                return "move"
            return None

        if element_type == "point":
            x = _coerce_float(geometry.get("x"))
            y = _coerce_float(geometry.get("y"))
            if x is None or y is None:
                return None
            if _dist_to_point(x, y) <= self._pixel_tolerance:
                return "move"
            return None

        if element_type == "trace_start":
            x_start = _coerce_float(geometry.get("x_start"))
            if x_start is None:
                return None
            if event_data is None:
                event_data = _event_data_coords()
            y_ref = event_data[1] if event_data is not None else sum(ax.get_ylim()) / 2.0
            if _dist_to_point(x_start, y_ref) <= self._pixel_tolerance:
                return "x_start"
            try:
                x_disp = transform.transform((x_start, y_ref))[0]
            except Exception:
                return None
            return "move" if abs(x_disp - event_xy[0]) <= self._pixel_tolerance else None

        if element_type == "trace_mask":
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            if x0 is None or x1 is None:
                return None
            if event_data is None:
                event_data = _event_data_coords()
            y_ref = event_data[1] if event_data is not None else sum(ax.get_ylim()) / 2.0
            if _dist_to_point(x0, y_ref) <= self._pixel_tolerance:
                return "x0"
            if _dist_to_point(x1, y_ref) <= self._pixel_tolerance:
                return "x1"
            try:
                x0_disp = transform.transform((x0, y_ref))[0]
                x1_disp = transform.transform((x1, y_ref))[0]
            except Exception:
                return None
            tol = self._pixel_tolerance
            if min(x0_disp, x1_disp) - tol <= event_xy[0] <= max(x0_disp, x1_disp) + tol:
                return "move"
            return None

        if element_type in {"xspan", "xspan_label"}:
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            if x0 is None or x1 is None:
                return None
            if coord_space == "axes":
                if event_axes is None:
                    event_axes = _event_axes_coords()
                y_ref = event_axes[1] if event_axes is not None else None
            else:
                if event_data is None:
                    event_data = _event_data_coords()
                y_ref = event_data[1] if event_data is not None else None
            if y_ref is None:
                y_min, y_max = ax.get_ylim()
                y_ref = (y_min + y_max) / 2.0
            if _dist_to_point(x0, y_ref) <= self._pixel_tolerance:
                return "x0"
            if _dist_to_point(x1, y_ref) <= self._pixel_tolerance:
                return "x1"
            if element_type == "xspan_label":
                label_hit = self._span_label_bbox_display(ax, element)
                if label_hit is not None:
                    (bx0, by0, bx1, by1), wrap_edge_x = label_hit
                    tol = self._pixel_tolerance
                    px, py = event_xy
                    if (
                        wrap_edge_x is not None
                        and abs(px - wrap_edge_x) <= tol
                        and (by0 - tol) <= py <= (by1 + tol)
                    ):
                        return "wrap"
                    if (bx0 - tol) <= px <= (bx1 + tol) and (by0 - tol) <= py <= (
                        by1 + tol
                    ):
                        return "label"
                label_x = _coerce_float(geometry.get("label_x"))
                if label_x is None:
                    label_x = (x0 + x1) / 2.0
                label_y = _coerce_float(geometry.get("label_y_data"))
                if label_y is None:
                    label_y = self._resolve_label_y_from_event(ax, geometry)
                if _dist_to_point(label_x, label_y) <= self._pixel_tolerance:
                    return "label"
            try:
                x0_disp = transform.transform((x0, y_ref))[0]
                x1_disp = transform.transform((x1, y_ref))[0]
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            tol = self._pixel_tolerance
            if (
                min(x0_disp, x1_disp) - tol
                <= event_xy[0]
                <= max(x0_disp, x1_disp) + tol
            ):
                return "move"
            return None

        if element_type == "rect":
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            y0 = _coerce_float(geometry.get("y0"))
            y1 = _coerce_float(geometry.get("y1"))
            if None in (x0, x1, y0, y1):
                return None
            # Iterate to apply the per-item logic.
            for handle_id, (hx, hy) in {
                "nw": (x0, y1),
                "ne": (x1, y1),
                "sw": (x0, y0),
                "se": (x1, y0),
            }.items():
                if _dist_to_point(hx, hy) <= self._pixel_tolerance:
                    return handle_id
            try:
                p0_disp = transform.transform((x0, y0))
                p1_disp = transform.transform((x1, y1))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            tol = self._pixel_tolerance
            if (
                min(p0_disp[0], p1_disp[0]) - tol
                <= event_xy[0]
                <= max(p0_disp[0], p1_disp[0]) + tol
                and min(p0_disp[1], p1_disp[1]) - tol
                <= event_xy[1]
                <= max(p0_disp[1], p1_disp[1]) + tol
            ):
                return "move"
            return None

        if element_type == "ref_line":
            orientation = str(geometry.get("orientation") or "vertical").strip().lower()
            value = _coerce_float(geometry.get("value"))
            if value is None:
                return None
            if event_data is None:
                event_data = _event_data_coords()
            if orientation == "horizontal":
                x_ref = (
                    event_data[0]
                    if event_data is not None
                    else sum(ax.get_xlim()) / 2.0
                )
                try:
                    y_disp = transform.transform((x_ref, value))[1]
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    return None
                return (
                    "move"
                    if abs(y_disp - event_xy[1]) <= self._pixel_tolerance
                    else None
                )
            y_ref = (
                event_data[1] if event_data is not None else sum(ax.get_ylim()) / 2.0
            )
            try:
                x_disp = transform.transform((value, y_ref))[0]
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            return (
                "move" if abs(x_disp - event_xy[0]) <= self._pixel_tolerance else None
            )

        if element_type == "ink":
            points = (
                geometry.get("points")
                if isinstance(geometry.get("points"), list)
                else []
            )
            if not points:
                return None
            # Iterate over the configured range to apply the per-item logic.
            for i in range(len(points) - 1):
                p0 = points[i]
                p1 = points[i + 1]
                if _close_to_line(p0, p1):
                    return "move"
            return None

        return None

    def _span_label_bbox_display(
        self, ax: Axes, element: Mapping[str, Any]
    ) -> Optional[Tuple[Tuple[float, float, float, float], Optional[float]]]:
        """Perform span label bbox display.
        Used to keep the workflow logic localized and testable."""
        text_artist = None
        try:
            if ax is None or element is None:
                return None
            geometry = (
                element.get("geometry")
                if isinstance(element.get("geometry"), Mapping)
                else {}
            )
            style = (
                element.get("style")
                if isinstance(element.get("style"), Mapping)
                else {}
            )
            coord_space = str(element.get("coord_space") or "data").strip().lower()
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            label_x = _coerce_float(geometry.get("label_x"))
            if label_x is None and x0 is not None and x1 is not None:
                label_x = (x0 + x1) / 2.0
            if label_x is None:
                return None
            label_y_axes = _coerce_float(geometry.get("label_y_axes"))
            if label_y_axes is not None:
                label_y_axes = max(0.0, min(1.0, float(label_y_axes)))
            if label_y_axes is not None:
                if coord_space == "axes":
                    label_transform = ax.transAxes
                    label_y = label_y_axes
                else:
                    label_transform = blended_transform_factory(ax.transData, ax.transAxes)
                    label_y = label_y_axes
                label_y_data = self._resolve_label_y_from_event(ax, geometry)
            else:
                label_y_data = _coerce_float(geometry.get("label_y_data"))
                if label_y_data is None:
                    label_y_data = self._resolve_label_y_from_event(ax, geometry)
                label_y = label_y_data
                label_transform = ax.transAxes if coord_space == "axes" else ax.transData
            text_value = str(geometry.get("text", "Label"))
            fontsize = _style_float_from_style(style, "fontsize", 10.0, 4.0)
            wrap_width_value = _coerce_float(geometry.get("wrap_width_x"))
            element_id = str(element.get("id") or "")
            xlim = ylim = None
            try:
                xlim = tuple(round(val, 6) for val in ax.get_xlim())
                ylim = tuple(round(val, 6) for val in ax.get_ylim())
            except Exception:
                xlim = None
                ylim = None
            cache_key = (
                element_id,
                str(text_value),
                round(float(fontsize or 0.0), 3),
                wrap_width_value,
                coord_space,
                round(float(label_x), 6),
                round(float(label_y), 6) if label_y is not None else None,
                round(float(label_y_data), 6) if label_y_data is not None else None,
                label_y_axes,
                xlim,
                ylim,
            )
            cached = self._span_bbox_cache.get(cache_key)
            if cached is not None:
                return cached
            data_x = label_x
            data_y = label_y_data
            wrap_width_data = wrap_width_value
            if coord_space == "axes":
                try:
                    disp = ax.transAxes.transform((label_x, label_y))
                    data_x, data_y = ax.transData.inverted().transform(disp)
                except Exception:
                    data_x, data_y = label_x, label_y_data
                if wrap_width_value is not None:
                    try:
                        disp0 = ax.transAxes.transform((label_x, label_y))
                        disp1 = ax.transAxes.transform(
                            (label_x + wrap_width_value, label_y)
                        )
                        data0 = ax.transData.inverted().transform(disp0)
                        data1 = ax.transData.inverted().transform(disp1)
                        wrap_width_data = data1[0] - data0[0]
                    except Exception:
                        wrap_width_data = None
            wrapped = _wrap_text_for_display(
                ax, text_value, data_x, data_y, wrap_width_data, fontsize
            )
            fig = ax.figure
            if fig is None or fig.canvas is None:
                return None
            renderer = fig.canvas.get_renderer()
            if renderer is None:
                return None
            text_artist = ax.text(
                label_x,
                label_y,
                wrapped,
                transform=label_transform,
                fontsize=fontsize,
                fontfamily=style.get("fontfamily", None),
                fontweight=style.get("fontweight", None),
                color=style.get("text_color") or style.get("color") or "#000000",
                alpha=_style_alpha_from_style(style, 0.9),
                ha=style.get("text_align", geometry.get("label_anchor", "center")),
                va=style.get("text_valign", "center"),
                bbox=_annotation_text_bbox_style(style),
            )
            text_artist.set_wrap(True)
            bbox = text_artist.get_window_extent(renderer=renderer)
            wrap_edge_x = None
            if wrap_width_value is not None:
                try:
                    if coord_space == "axes":
                        wrap_edge_x = ax.transAxes.transform(
                            (label_x + wrap_width_value, label_y)
                        )[0]
                    elif label_y_axes is not None:
                        wrap_edge_x = blended_transform_factory(
                            ax.transData, ax.transAxes
                        ).transform((label_x + wrap_width_value, label_y_axes))[0]
                    else:
                        wrap_edge_x = ax.transData.transform(
                            (label_x + wrap_width_value, label_y)
                        )[0]
                except Exception:
                    wrap_edge_x = None
            result = ((bbox.x0, bbox.y0, bbox.x1, bbox.y1), wrap_edge_x)
            if len(self._span_bbox_cache) >= 256:
                self._span_bbox_cache.clear()
            self._span_bbox_cache[cache_key] = result
            return result
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        finally:
            if text_artist is not None:
                try:
                    text_artist.remove()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

    def _resolve_label_y_from_event(
        self, ax: Axes, geometry: Mapping[str, Any]
    ) -> float:
        """Resolve label y from event.
        Used to compute label y from event before rendering or export."""
        label_axes = geometry.get("label_y_axes")
        if label_axes is not None:
            coerced = _coerce_float(label_axes)
            if coerced is not None:
                frac = max(0.0, min(1.0, float(coerced)))
                y_min, y_max = ax.get_ylim()
                return y_min + frac * (y_max - y_min)
        label_y = geometry.get("label_y_data")
        if label_y is not None:
            coerced = _coerce_float(label_y)
            if coerced is not None:
                return coerced
        legacy = geometry.get("legacy_label_y_axes")
        if legacy is None:
            return ax.get_ylim()[1]
        try:
            frac = float(legacy)
        except Exception:
            frac = 0.9
        y_min, y_max = ax.get_ylim()
        return y_min + frac * (y_max - y_min)


def _default_style_for_type(element_type: str) -> Dict[str, Any]:
    """Return default style for type.
    Used when callers need a safe fallback."""
    base = {
        "color": "#000000",
        "alpha": 0.9,
        "linewidth": 1.5,
        "linestyle": "solid",
    }
    if element_type in {"text", "callout", "arrow", "xspan_label", "rect", "ref_line"}:
        base.update(
            {
                "fontsize": 10.0,
                "fontfamily": _PREFERRED_PLOT_FONT,
                "fontweight": "normal",
                "text_align": "left",
                "text_valign": "bottom",
                "bbox_facecolor": "white",
                "bbox_alpha": 0.85,
                "bbox_edgecolor": "none",
                "bbox_linewidth": 1.0,
                "bbox_linestyle": "solid",
                "bbox_boxstyle": "round",
                "bbox_pad": 0.3,
                "bbox_shadow": False,
                "bbox_shadow_offset_x": 2.0,
                "bbox_shadow_offset_y": -2.0,
                "bbox_shadow_alpha": 0.35,
            }
        )
    if element_type == "point":
        base.update(
            {
                "marker": "o",
                "marker_size": 8.0,
                "marker_facecolor": "#000000",
                "marker_edgecolor": "#000000",
                "snap_to_data": False,
            }
        )
    if element_type in {"xspan", "xspan_label", "rect"}:
        base.update({"facecolor": "#cccccc", "edgecolor": "#333333"})
    if element_type in {"xspan", "xspan_label"}:
        base.setdefault("span_layer", "behind_data")
    if element_type in {"callout", "arrow"}:
        base.update({"arrowstyle": "->"})
    return base


def _annotation_style_keys_for_type(element_type: str) -> Set[str]:
    """Perform annotation style keys for type.
    Used to keep the workflow logic localized and testable."""
    element_type = str(element_type or "").strip().lower()
    keys: Set[str] = {"alpha"}
    text_like = {"text", "callout", "arrow", "xspan_label", "rect", "ref_line"}
    if element_type in text_like:
        keys.update(
            {
                "fontsize",
                "fontfamily",
                "fontweight",
                "text_align",
                "text_valign",
                "text_color",
                "bbox_facecolor",
                "bbox_alpha",
                "bbox_edgecolor",
                "bbox_linewidth",
                "bbox_linestyle",
                "bbox_boxstyle",
                "bbox_pad",
                "bbox_shadow",
                "bbox_shadow_offset_x",
                "bbox_shadow_offset_y",
                "bbox_shadow_alpha",
            }
        )
    if element_type in {"xspan", "xspan_label", "rect"}:
        keys.update({"facecolor", "edgecolor", "linewidth", "linestyle"})
    if element_type in {"callout", "arrow", "ref_line", "ink"}:
        keys.update({"color", "linewidth", "linestyle"})
    if element_type in {"callout", "arrow"}:
        keys.add("arrowstyle")
    if element_type == "point":
        keys.update(
            {
                "marker",
                "marker_size",
                "marker_facecolor",
                "marker_edgecolor",
                "snap_to_data",
                "snap_tolerance",
            }
        )
    if element_type in {"xspan", "xspan_label"}:
        keys.add("span_layer")
    return keys


# Controller drives plot-element lifecycle: it owns interaction state, renders
# annotations onto the figure, and syncs changes back to the shared store.
class PlotAnnotationsController:
    def __init__(
        self,
        plot_id: str,
        fig: Figure,
        canvas: FigureCanvasTkAgg,
        store: AnnotationStore,
        renderer: AnnotationRenderer,
        axes_map: Dict[str, Axes],
        axis_labels: Dict[str, str],
        on_elements_changed: Optional[Callable[[str], None]] = None,
    ) -> None:
        """Initialize PlotAnnotationsController instance.
        Used at object creation to configure initial state and bindings."""
        self._plot_id = plot_id
        self._fig = fig
        self._canvas = canvas
        self._store = store
        self._renderer = renderer
        self._axes_map = axes_map
        self._axis_labels = axis_labels
        self._on_elements_changed = on_elements_changed
        self._axes_role_map = {ax: role for role, ax in axes_map.items() if ax}
        self._history = AnnotationHistory()
        self._hit_test = AnnotationHitTest()
        ui_state = self._store.ui_state_for(plot_id)
        self._mode = ui_state.get("last_mode", "select")
        self._selected_id = ui_state.get("last_selected_id")
        self._panel: Optional["AnnotationsPanel"] = None
        self._drag_state: Optional[Dict[str, Any]] = None
        self._drag_blit_state: Optional[Dict[str, Any]] = None
        self._placing_type: Optional[str] = None
        self._placing_style_overrides: Dict[str, Any] = {}
        self._placing_geometry_seed: Optional[Dict[str, Any]] = None
        self._placing_keep_placing = False
        self._placing_axis_target: Optional[str] = None
        self._placing_coord_space: Optional[str] = None
        self._placing_state: Optional[Dict[str, Any]] = None
        self._draft_element: Optional[Dict[str, Any]] = None
        self._draft_artists: List[Any] = []
        self._span_selectors: List[SpanSelector] = []
        self._span_commit_in_progress = False
        self._overlay_artists: List[Any] = []
        self._dirty = False
        self._cids: List[int] = []
        self._style_clipboard: Optional[Dict[str, Any]] = None
        self._span_selector_props: Dict[str, Any] = {}
        self._history.push(self._elements())
        self._connect_events()
        self.render()

    def _elements(self) -> List[Dict[str, Any]]:
        """Perform elements.
        Used to keep the workflow logic localized and testable."""
        return self._store.elements_for(self._plot_id)

    def set_panel(self, panel: Optional["AnnotationsPanel"]) -> None:
        """Set panel.
        Used to persist panel into the current state."""
        self._panel = panel
        if self._panel is not None:
            self._panel.refresh()
        # Overlay visibility depends on whether the editor is open.
        self.render()

    def set_target(self, fig: Figure, canvas: FigureCanvasTkAgg) -> None:
        """Set target.
        Used to persist target into the current state."""
        if fig is None or canvas is None:
            return
        canvas_changed = self._canvas is not canvas
        fig_changed = self._fig is not fig
        if not canvas_changed and not fig_changed:
            return
        if canvas_changed:
            self.disconnect()
            self._canvas = canvas
            self._connect_events()
        self._fig = fig

    def rebind(
        self,
        fig: Figure,
        canvas: FigureCanvasTkAgg,
        axes_map: Dict[str, Axes],
        axis_labels: Dict[str, str],
    ) -> None:
        """Perform rebind.
        Used to keep the workflow logic localized and testable."""
        if fig is None or canvas is None:
            return
        try:
            self.disconnect()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._canvas = canvas
        self._fig = fig
        self._connect_events()
        self._axes_map = axes_map or {}
        if axis_labels is not None:
            self._axis_labels = axis_labels
        self._axes_role_map = {ax: role for role, ax in self._axes_map.items() if ax}
        self._drag_state = None
        self._dirty = False
        self._placing_state = None
        self._clear_span_selectors()
        self._span_commit_in_progress = False
        try:
            self.cancel_place_element()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._end_drag_blit()
        except Exception:
            self._drag_blit_state = None
        try:
            self._hit_test = AnnotationHitTest()
        except Exception:
            try:
                self._hit_test.clear_cache()
            except Exception:
                pass
        self._clear_draft()
        self._clear_overlays()
        self.render()
        if self._panel is not None:
            self._panel.refresh()

    def set_mode(self, mode: str) -> None:
        """Set mode.
        Used to persist mode into the current state."""
        if mode not in ANNOTATION_MODES:
            return
        if self._placing_type is not None:
            self.cancel_place_element()
        self._mode = mode
        self._store.set_ui_state(self._plot_id, last_mode=mode)

    def get_mode(self) -> str:
        """Return mode.
        Used to retrieve mode for downstream logic."""
        return self._mode

    def begin_place_element(
        self,
        element_type: str,
        style_overrides: Dict[str, Any],
        geometry_seed: Optional[Dict[str, Any]] = None,
        axis_target: Optional[str] = None,
        coord_space: Optional[str] = None,
    ) -> None:
        """Perform begin place element.
        Used to keep the workflow logic localized and testable."""
        # Root cause: the prior annotations panel only toggled mode without arming a
        # placement tool, so users had no explicit "place" action to create elements.
        canonical = _canonicalize_annotation_type(element_type)
        if not canonical:
            return
        if canonical not in ANNOTATION_TYPE_LABELS:
            return
        self.cancel_place_element()
        if canonical not in {"xspan", "xspan_label", "trace_mask"}:
            self._clear_span_selectors()
        self._cancel_draft()
        overrides = dict(style_overrides or {})
        self._placing_keep_placing = bool(overrides.pop("_keep_placing", False))
        self._placing_type = canonical
        self._placing_style_overrides = overrides
        self._placing_geometry_seed = dict(geometry_seed or {})
        self._placing_axis_target = _normalize_axes_target(axis_target)
        coord_value = str(coord_space or "data").strip().lower()
        if coord_value not in {"data", "axes"}:
            coord_value = "data"
        self._placing_coord_space = coord_value
        if canonical in {"xspan", "xspan_label", "trace_mask"} and coord_value == "data":
            if not self._arm_span_selectors():
                self.cancel_place_element()
                return
        self._placing_state = None
        self._draft_element = None
        self._draft_artists = []
        if self._canvas is not None:
            try:
                self._canvas.draw_idle()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def cancel_place_element(self) -> None:
        """Perform cancel place element.
        Used to keep the workflow logic localized and testable."""
        self._clear_span_selectors()
        self._span_commit_in_progress = False
        self._placing_type = None
        self._placing_style_overrides = {}
        self._placing_geometry_seed = None
        self._placing_keep_placing = False
        self._placing_axis_target = None
        self._placing_coord_space = None
        self._placing_state = None
        self._clear_draft()
        if self._panel is not None:
            try:
                self._panel.set_add_placement_active(False)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if self._canvas is not None:
            try:
                self._canvas.draw_idle()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _clear_span_selectors(self) -> None:
        """Clear span selectors.
        Used to reset span selectors state safely."""
        # Iterate over list(self._span_selectors) to apply the per-item logic.
        for selector in list(self._span_selectors):
            try:
                rect = getattr(selector, "rect", None)
                if rect is None:
                    rect = getattr(selector, "_selection_artist", None)
                if rect is None:
                    rect = getattr(selector, "_rect", None)
                if rect is not None:
                    rect.set_visible(False)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                selector.set_active(False)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                selector.disconnect_events()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._span_selectors = []

    def _span_selector_style(self) -> Dict[str, Any]:
        """Perform span selector style.
        Used to keep the workflow logic localized and testable."""
        if self._placing_type == "trace_mask":
            # Trace-mask editing shows boundary guidance only while dragging.
            return {
                "facecolor": "none",
                "edgecolor": "#9AA0A6",
                "alpha": 0.9,
                "linewidth": 1.0,
                "linestyle": "--",
            }
        base = _default_style_for_type("xspan")
        base.update(self._placing_style_overrides or {})
        alpha = _coerce_float(base.get("alpha"))
        if alpha is None:
            alpha = 0.9
        linewidth = _coerce_float(base.get("linewidth"))
        if linewidth is None:
            linewidth = 1.5
        color = base.get("color") or "#000000"
        facecolor = base.get("facecolor") or base.get("fill_color") or color
        edgecolor = base.get("edgecolor") or color
        linestyle = base.get("linestyle")
        props = {
            "facecolor": facecolor,
            "edgecolor": edgecolor,
            "alpha": max(0.0, min(1.0, float(alpha))),
            "linewidth": max(0.5, float(linewidth)),
        }
        if linestyle:
            props["linestyle"] = linestyle
        return props

    def _apply_span_selector_style(
        self, selector: SpanSelector, props: Mapping[str, Any]
    ) -> None:
        """Apply span selector style.
        Used to apply span selector style changes to live state."""
        if selector is None or not props:
            return
        applied = False
        if hasattr(selector, "set_props"):
            try:
                selector.set_props(props)
                applied = True
            except Exception:
                applied = False
        if applied:
            return
        rect = getattr(selector, "rect", None)
        if rect is None:
            rect = getattr(selector, "_selection_artist", None)
        if rect is None:
            rect = getattr(selector, "_rect", None)
        if rect is None:
            return
        try:
            if "facecolor" in props:
                rect.set_facecolor(props["facecolor"])
            if "edgecolor" in props:
                rect.set_edgecolor(props["edgecolor"])
            if "alpha" in props:
                rect.set_alpha(props["alpha"])
            if "linewidth" in props:
                rect.set_linewidth(props["linewidth"])
            if "linestyle" in props:
                rect.set_linestyle(props["linestyle"])
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _arm_span_selectors(self) -> bool:
        """Perform arm span selectors.
        Used to keep the workflow logic localized and testable."""
        self._clear_span_selectors()
        self._span_commit_in_progress = False
        props = self._span_selector_style()
        self._span_selector_props = dict(props)
        axes: List[Axes] = []
        # Iterate over ("primary", "right", "third") to apply the per-item logic.
        for role in ("primary", "right", "third"):
            ax = self._axes_map.get(role)
            if ax is not None and ax not in axes:
                axes.append(ax)
        if not axes:
            ax = next((axis for axis in self._axes_map.values() if axis), None)
            if ax is not None:
                axes.append(ax)
        if not axes:
            return False
        # Iterate over axes to apply the per-item logic.
        for ax in axes:
            try:
                selector = SpanSelector(
                    ax,
                    self._commit_new_xspan_from_selector,
                    "horizontal",
                    useblit=False,
                    interactive=False,
                    minspan=1e-9,
                    props=props,
                )
            except TypeError:
                try:
                    selector = SpanSelector(
                        ax,
                        self._commit_new_xspan_from_selector,
                        "horizontal",
                        useblit=False,
                        minspan=1e-9,
                        rectprops=props,
                    )
                except TypeError:
                    selector = SpanSelector(
                        ax,
                        self._commit_new_xspan_from_selector,
                        "horizontal",
                        useblit=False,
                        minspan=1e-9,
                    )
            self._apply_span_selector_style(selector, props)
            self._span_selectors.append(selector)
        return True

    def _commit_new_xspan_from_selector(self, xmin: float, xmax: float) -> None:
        """Perform commit new xspan from selector.
        Used to keep the workflow logic localized and testable."""
        if self._placing_type not in {"xspan", "xspan_label", "trace_mask"}:
            return
        x0 = _coerce_float(xmin)
        x1 = _coerce_float(xmax)
        if x0 is None or x1 is None:
            return
        if x0 > x1:
            x0, x1 = x1, x0
        if not math.isfinite(x0) or not math.isfinite(x1):
            return
        if abs(x1 - x0) <= 1e-12:
            return
        if self._span_commit_in_progress:
            return
        self._span_commit_in_progress = True
        if self._span_selectors and self._span_selector_props:
            # Iterate over self._span_selectors to apply the per-item logic.
            for selector in self._span_selectors:
                self._apply_span_selector_style(selector, self._span_selector_props)
            if self._canvas is not None:
                try:
                    self._canvas.draw_idle()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        self._clear_span_selectors()
        element_type = self._placing_type
        style = _default_style_for_type(element_type)
        style.update(self._placing_style_overrides or {})
        alpha = _coerce_float(style.get("alpha"))
        if alpha is None:
            alpha = 0.9
        style["alpha"] = max(0.0, min(1.0, float(alpha)))
        geometry: Dict[str, Any] = {"x0": x0, "x1": x1}
        if element_type == "xspan_label":
            seed = self._placing_geometry_seed or {}
            label_text = seed.get("text")
            if not isinstance(label_text, str) or not label_text.strip():
                label_text = "Label"
            label_y_axes = _coerce_float(seed.get("label_y_axes"))
            if label_y_axes is None:
                label_y_axes = 0.95
            label_anchor = seed.get("label_anchor")
            if not isinstance(label_anchor, str) or not label_anchor.strip():
                label_anchor = "center"
            geometry.update(
                {
                    "text": label_text,
                    "label_y_axes": max(0.0, min(1.0, float(label_y_axes))),
                    "label_anchor": label_anchor,
                }
            )
            span_ax = None
            axis_target = _normalize_axes_target(self._placing_axis_target)
            if axis_target:
                span_ax = self._axes_map.get(axis_target)
            if span_ax is None:
                span_ax = self._axes_map.get("primary")
            if span_ax is None:
                span_ax = next((axis for axis in self._axes_map.values() if axis), None)
            wrap_width = self._default_span_wrap_width(span_ax, x0, x1, "data")
            if wrap_width is not None:
                geometry.setdefault("wrap_width_x", wrap_width)
        elif element_type == "trace_mask":
            seed = self._placing_geometry_seed or {}
            geometry["trace_key"] = _normalize_trace_series_key(
                seed.get("trace_key"), default="y2"
            )
        element_id = str(uuid.uuid4())
        element = {
            "id": element_id,
            "name": _default_annotation_name(element_type, len(self._elements())),
            "type": element_type,
            "axes_target": _normalize_axes_target(self._placing_axis_target),
            "coord_space": "data",
            "visible": True,
            "locked": False,
            "zorder": self._next_zorder(),
            "style": style,
            "geometry": geometry,
        }
        self._elements().append(element)
        self._commit_history()
        self.set_selected_id(element_id)
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if not self._placing_keep_placing:
            self.cancel_place_element()
            self.set_mode("select")
            if self._panel is not None:
                try:
                    self._panel.set_add_placement_active(False)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        else:
            if not self._arm_span_selectors():
                self.cancel_place_element()
                self.set_mode("select")

    def set_selected_id(
        self, element_id: Optional[str], *, refresh_panel: bool = True
    ) -> None:
        """Set selected ID.
        Used to persist selected ID into the current state."""
        if element_id:
            element_id = str(element_id)
            if not any(el.get("id") == element_id for el in self._elements()):
                element_id = None
        self._selected_id = element_id
        self._store.set_ui_state(self._plot_id, last_selected_id=element_id)
        if element_id and (
            self._placing_type not in {"xspan", "xspan_label", "trace_mask"}
            or (self._placing_coord_space or "data") != "data"
        ):
            self._clear_span_selectors()
        self.render()
        if refresh_panel and self._panel is not None:
            self._panel.refresh()

    def selected_element(self) -> Optional[Dict[str, Any]]:
        """Perform selected element.
        Used to keep the workflow logic localized and testable."""
        if not self._selected_id:
            return None
        # Iterate over self._elements() to apply the per-item logic.
        for element in self._elements():
            if element.get("id") == self._selected_id:
                return element
        return None

    def get_axis_choices(self) -> List[Tuple[str, str]]:
        """Return axis choices.
        Used to retrieve axis choices for downstream logic."""
        return [(label, role) for role, label in self._axis_labels.items()]

    def update_axes_map(
        self, axes_map: Dict[str, Axes], axis_labels: Optional[Dict[str, str]] = None
    ) -> None:
        """Update axes map.
        Used to keep axes map in sync with current state."""
        self._axes_map = axes_map
        if axis_labels is not None:
            self._axis_labels = axis_labels
        self._axes_role_map = {ax: role for role, ax in axes_map.items() if ax}
        self._clear_span_selectors()
        self._span_commit_in_progress = False
        if self._drag_state is not None:
            self._drag_state = None
            self._dirty = False
        if self._placing_state is not None or self._draft_element is not None:
            self._placing_state = None
            self._clear_draft()
        if self._placing_type in {"xspan", "xspan_label", "trace_mask"} and (
            self._placing_coord_space or "data"
        ) == "data":
            if not self._arm_span_selectors():
                self.cancel_place_element()
        self.render()

    def update_axis_map(
        self, fig: Figure, axes_map: Dict[str, Axes], axis_labels: Dict[str, str]
    ) -> None:
        """Update axis map.
        Used to keep axis map in sync with current state."""
        self._fig = fig
        self.update_axes_map(axes_map, axis_labels)

    def render(self) -> None:
        """Render annotations and interaction overlays.
        Used to redraw the plot elements whenever state changes."""
        if self._fig is None:
            return
        try:
            self._hit_test.clear_cache()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        # Render lifecycle: clear overlays, draw stored elements, then add
        # interaction handles and drafts so UI state matches the store.
        self._clear_overlays()
        self._renderer.render(self._fig, self._axes_map, self._elements())
        self._render_handles()
        self._render_draft()
        try:
            self._canvas.draw_idle()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _clear_overlays(self) -> None:
        """Clear overlays.
        Used to reset overlays state safely."""
        # Iterate over self._overlay_artists to apply the per-item logic.
        for artist in self._overlay_artists:
            try:
                artist.remove()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._overlay_artists = []

    def _refresh_overlays_only(self) -> None:
        """Refresh overlays only.
        Used to sync overlays only with current settings."""
        if self._fig is None:
            return
        self._clear_overlays()
        self._render_handles()
        self._render_draft()
        try:
            self._canvas.draw_idle()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _sync_dragged_element_artists(
        self, element: Mapping[str, Any], *, skip_wrap: bool = False
    ) -> bool:
        """Perform sync dragged element artists.
        Used to keep the workflow logic localized and testable."""
        if self._fig is None or element is None:
            return False
        element_id = str(element.get("id") or "")
        if not element_id:
            return False
        artist_map = getattr(self._fig, "_gl260_annotation_artist_map", None)
        if not isinstance(artist_map, dict):
            return False
        artists = artist_map.get(element_id)
        if not artists:
            return False
        ax = self._axes_map.get(element.get("axes_target", "primary"))
        if ax is None:
            return False
        return self._renderer.update_artists(
            ax, element, artists, skip_wrap=skip_wrap
        )

    def _arm_drag_blit(self, element_id: str) -> None:
        """Perform arm drag blit.
        Used to keep the workflow logic localized and testable."""
        if self._fig is None or self._canvas is None:
            self._drag_blit_state = None
            return
        artist_map = getattr(self._fig, "_gl260_annotation_artist_map", None)
        if not isinstance(artist_map, dict):
            self._drag_blit_state = None
            return
        artists = [a for a in artist_map.get(element_id, []) if a is not None]
        if not artists:
            self._drag_blit_state = None
            return
        # Iterate over artists to apply the per-item logic.
        for artist in artists:
            try:
                artist.set_animated(True)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        background = None
        try:
            background = self._canvas.copy_from_bbox(self._fig.bbox)
        except Exception:
            background = None
        self._drag_blit_state = {"background": background, "artists": artists}

    def _blit_drag_update(self) -> bool:
        """Update value.
        Used by blit drag workflows to update value."""
        if self._fig is None or self._canvas is None:
            return False
        state = self._drag_blit_state
        if not isinstance(state, dict):
            return False
        background = state.get("background")
        artists = state.get("artists")
        if background is None or not artists:
            return False
        try:
            self._canvas.restore_region(background)
            # Iterate over artists to apply the per-item logic.
            for artist in artists:
                try:
                    self._fig.draw_artist(artist)
                except Exception:
                    continue
            self._canvas.blit(self._fig.bbox)
            return True
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return False

    def _end_drag_blit(self) -> None:
        """Perform end drag blit.
        Used to keep the workflow logic localized and testable."""
        state = self._drag_blit_state
        if not isinstance(state, dict):
            self._drag_blit_state = None
            return
        artists = state.get("artists") or []
        # Iterate over artists to apply the per-item logic.
        for artist in artists:
            try:
                artist.set_animated(False)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._drag_blit_state = None

    def _render_handles(self) -> None:
        """Render handles.
        Used to draw handles for preview or export workflows."""
        element = self.selected_element()
        if element is None:
            return
        ax = self._axes_map.get(element.get("axes_target", "primary"))
        if ax is None:
            return
        coord_space = element.get("coord_space", "data")
        transform = ax.transAxes if coord_space == "axes" else ax.transData
        handles = self._handle_positions(element, ax)
        element_type = str(element.get("type") or "").strip().lower()
        if element_type in {"xspan", "xspan_label"} and coord_space == "data":
            ymid = sum(ax.get_ylim()) / 2.0
            geometry = (
                element.get("geometry", {})
                if isinstance(element.get("geometry"), dict)
                else {}
            )
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            new_handles: List[Tuple[str, Tuple[float, float]]] = []
            if x0 is not None:
                new_handles.append(("x0", (x0, ymid)))
            if x1 is not None:
                new_handles.append(("x1", (x1, ymid)))
            if element_type == "xspan_label":
                label_x = _coerce_float(geometry.get("label_x"))
                if label_x is None and x0 is not None and x1 is not None:
                    label_x = (x0 + x1) / 2.0
                label_y = _coerce_float(geometry.get("label_y_data"))
                if label_y is None:
                    label_y_axes = _coerce_float(geometry.get("label_y_axes"))
                    if label_y_axes is not None and ax is not None:
                        y_min, y_max = ax.get_ylim()
                        label_y = y_min + max(0.0, min(1.0, label_y_axes)) * (
                            y_max - y_min
                        )
                if label_x is not None and label_y is not None:
                    new_handles.append(("label", (label_x, label_y)))
                    wrap_width = _coerce_float(geometry.get("wrap_width_x"))
                    if wrap_width is None or wrap_width <= 0:
                        if x0 is not None and x1 is not None:
                            wrap_width = abs(x1 - x0)
                        if (wrap_width is None or wrap_width <= 0) and ax is not None:
                            try:
                                x_limits = ax.get_xlim()
                                wrap_width = 0.25 * abs(x_limits[1] - x_limits[0])
                            except Exception:
                                wrap_width = None
                    if wrap_width is not None:
                        new_handles.append(("wrap", (label_x + wrap_width, label_y)))
            if new_handles:
                handles = new_handles
        if element_type == "trace_mask":
            geometry = (
                element.get("geometry", {})
                if isinstance(element.get("geometry"), dict)
                else {}
            )
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            if x0 is not None and x1 is not None and self._panel is not None:
                for x_value in (x0, x1):
                    try:
                        line = ax.axvline(
                            x=x_value,
                            color="#9AA0A6",
                            linestyle="--",
                            linewidth=1.0,
                            alpha=0.95,
                            zorder=2000,
                        )
                        self._overlay_artists.append(line)
                    except Exception:
                        continue
            # Trace-mask uses boundary guides while editing; no marker handles.
            handles = []
        if element_type == "trace_start":
            geometry = (
                element.get("geometry", {})
                if isinstance(element.get("geometry"), dict)
                else {}
            )
            x_start = _coerce_float(geometry.get("x_start"))
            if x_start is not None:
                ymid = sum(ax.get_ylim()) / 2.0
                handles = [("x_start", (x_start, ymid))]
        if element_type == "ref_line":
            value = _coerce_float(element.get("geometry", {}).get("value"))
            orientation = (
                str(element.get("geometry", {}).get("orientation") or "vertical")
                .strip()
                .lower()
            )
            if value is not None:
                if orientation == "horizontal":
                    xmid = sum(ax.get_xlim()) / 2.0
                    handles = [("move", (xmid, value))]
                else:
                    ymid = sum(ax.get_ylim()) / 2.0
                    handles = [("move", (value, ymid))]
        # Iterate over handles to apply the per-item logic.
        for handle_id, (hx, hy) in handles:
            try:
                (artist,) = ax.plot(
                    [hx],
                    [hy],
                    marker="s",
                    markersize=6,
                    markerfacecolor="white",
                    markeredgecolor="#1f77b4",
                    linestyle="None",
                    transform=transform,
                    zorder=2000,
                )
                artist._gl260_annotation_handle = handle_id
                self._overlay_artists.append(artist)
            except Exception:
                continue

    def _handle_positions(
        self, element: Mapping[str, Any], ax: Optional[Axes] = None
    ) -> List[Tuple[str, Tuple[float, float]]]:
        """Handle positions.
        Used as an event callback for positions."""
        geometry = (
            element.get("geometry") if isinstance(element.get("geometry"), dict) else {}
        )
        element_type = str(element.get("type") or "").strip().lower()
        coord_space = str(element.get("coord_space") or "data").strip().lower()
        handles: List[Tuple[str, Tuple[float, float]]] = []
        if element_type == "text":
            x = _coerce_float(geometry.get("x"))
            y = _coerce_float(geometry.get("y"))
            if x is not None and y is not None:
                handles.append(("move", (x, y)))
                wrap_width = _coerce_float(geometry.get("wrap_width_x"))
                if wrap_width is not None and wrap_width <= 0:
                    wrap_width = None
                if wrap_width is None and ax is not None:
                    try:
                        x_limits = ax.get_xlim()
                        wrap_width = 0.20 * abs(x_limits[1] - x_limits[0])
                    except Exception:
                        wrap_width = None
                if wrap_width is not None:
                    handles.append(("wrap", (x + wrap_width, y)))
        elif element_type == "callout":
            x0 = _coerce_float(geometry.get("x0"))
            y0 = _coerce_float(geometry.get("y0"))
            x1 = _coerce_float(geometry.get("x1"))
            y1 = _coerce_float(geometry.get("y1"))
            if None not in (x0, y0, x1, y1):
                handles.extend(
                    [("anchor", (x0, y0)), ("text", (x1, y1)), ("move", (x1, y1))]
                )
        elif element_type == "arrow":
            x0 = _coerce_float(geometry.get("x0"))
            y0 = _coerce_float(geometry.get("y0"))
            x1 = _coerce_float(geometry.get("x1"))
            y1 = _coerce_float(geometry.get("y1"))
            if None not in (x0, y0, x1, y1):
                handles.extend(
                    [("tail", (x0, y0)), ("head", (x1, y1)), ("move", (x1, y1))]
                )
        elif element_type == "point":
            x = _coerce_float(geometry.get("x"))
            y = _coerce_float(geometry.get("y"))
            if x is not None and y is not None:
                handles.append(("move", (x, y)))
        elif element_type == "trace_start":
            x_start = _coerce_float(geometry.get("x_start"))
            if x_start is not None:
                handles.append(("x_start", (x_start, 0.5)))
        elif element_type == "trace_mask":
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            if x0 is not None and x1 is not None:
                handles.append(("x0", (x0, 0.5)))
                handles.append(("x1", (x1, 0.5)))
        elif element_type in {"xspan", "xspan_label"}:
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            if x0 is not None and x1 is not None:
                handles.append(("x0", (x0, 0.5)))
                handles.append(("x1", (x1, 0.5)))
                if element_type == "xspan_label":
                    label_x = _coerce_float(geometry.get("label_x"))
                    if label_x is None:
                        label_x = (x0 + x1) / 2.0
                    label_y = _coerce_float(geometry.get("label_y_data"))
                    if label_y is None and ax is not None:
                        label_y_axes = _coerce_float(geometry.get("label_y_axes"))
                        if label_y_axes is not None:
                            if coord_space == "axes":
                                label_y = max(0.0, min(1.0, label_y_axes))
                            else:
                                y_min, y_max = ax.get_ylim()
                                label_y = y_min + max(0.0, min(1.0, label_y_axes)) * (
                                    y_max - y_min
                                )
                    if label_y is not None:
                        handles.append(("label", (label_x, label_y)))
                        wrap_width = _coerce_float(geometry.get("wrap_width_x"))
                        if wrap_width is None or wrap_width <= 0:
                            if x0 is not None and x1 is not None:
                                wrap_width = abs(x1 - x0)
                            if (wrap_width is None or wrap_width <= 0) and ax is not None:
                                try:
                                    x_limits = ax.get_xlim()
                                    wrap_width = 0.25 * abs(x_limits[1] - x_limits[0])
                                except Exception:
                                    wrap_width = None
                            if coord_space == "axes":
                                wrap_width = max(0.02, float(wrap_width or 0.25))
                        if wrap_width is not None:
                            handles.append(("wrap", (label_x + wrap_width, label_y)))
        elif element_type == "rect":
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            y0 = _coerce_float(geometry.get("y0"))
            y1 = _coerce_float(geometry.get("y1"))
            if None not in (x0, x1, y0, y1):
                handles.extend(
                    [
                        ("nw", (x0, y1)),
                        ("ne", (x1, y1)),
                        ("sw", (x0, y0)),
                        ("se", (x1, y0)),
                    ]
                )
        elif element_type == "ref_line":
            value = _coerce_float(geometry.get("value"))
            if value is not None:
                orientation = (
                    str(geometry.get("orientation") or "vertical").strip().lower()
                )
                if orientation == "horizontal":
                    handles.append(("move", (0.5, value)))
                else:
                    handles.append(("move", (value, 0.5)))
        elif element_type == "ink":
            points = (
                geometry.get("points")
                if isinstance(geometry.get("points"), list)
                else []
            )
            if points:
                x, y = points[0]
                handles.append(("move", (x, y)))
        return handles

    def _connect_events(self) -> None:
        """Perform connect events.
        Used to keep the workflow logic localized and testable."""
        if self._canvas is None:
            return
        self._cids.append(
            self._canvas.mpl_connect("button_press_event", self._on_press)
        )
        self._cids.append(self._canvas.mpl_connect("pick_event", self._on_press))
        self._cids.append(
            self._canvas.mpl_connect("motion_notify_event", self._on_motion)
        )
        self._cids.append(
            self._canvas.mpl_connect("button_release_event", self._on_release)
        )
        self._cids.append(self._canvas.mpl_connect("key_press_event", self._on_key))

    def disconnect(self) -> None:
        """Perform disconnect.
        Used to keep the workflow logic localized and testable."""
        if self._canvas is None:
            return
        # Iterate over self._cids to apply the per-item logic.
        for cid in self._cids:
            try:
                self._canvas.mpl_disconnect(cid)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._cids = []

    def _on_key(self, event: Any) -> None:
        """Handle key.
        Used as an event callback for key."""
        if event is None:
            return
        key = str(getattr(event, "key", "") or "").lower()
        if key in {"delete", "backspace"}:
            self.delete_selected()
        elif key.endswith(("left", "right", "up", "down")):
            direction = key.split("+")[-1]
            self._nudge_selected(direction, large=("shift" in key))
        elif key == "escape":
            if self._placing_type is not None:
                self.cancel_place_element()
                if self._panel is not None:
                    try:
                        self._panel.set_add_placement_active(False)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
            self._cancel_draft()
        elif key in {"ctrl+z", "cmd+z"}:
            self.undo()
        elif key in {"ctrl+y", "cmd+y"}:
            self.redo()

    def _nudge_selected(self, direction: str, *, large: bool = False) -> None:
        """Perform nudge selected.
        Used to keep the workflow logic localized and testable."""
        element = self.selected_element()
        if element is None or element.get("locked"):
            return
        ax = self._axes_map.get(element.get("axes_target", "primary"))
        if ax is None:
            return
        coord_space = str(element.get("coord_space") or "data").strip().lower()
        if coord_space == "axes":
            step = 0.05 if large else 0.01
            step_x = step_y = step
        else:
            try:
                x_limits = ax.get_xlim()
                y_limits = ax.get_ylim()
                x_range = abs(x_limits[1] - x_limits[0]) or 1.0
                y_range = abs(y_limits[1] - y_limits[0]) or 1.0
            except Exception:
                x_range = y_range = 1.0
            factor = 0.02 if large else 0.005
            step_x = factor * x_range
            step_y = factor * y_range
        dx = step_x if direction == "right" else -step_x if direction == "left" else 0.0
        dy = step_y if direction == "up" else -step_y if direction == "down" else 0.0
        geometry = element.get("geometry")
        if not isinstance(geometry, dict):
            return
        element_type = str(element.get("type") or "").strip().lower()
        if element_type in {"text", "point"}:
            if "x" in geometry:
                geometry["x"] = (_coerce_float(geometry.get("x")) or 0.0) + dx
            if "y" in geometry:
                geometry["y"] = (_coerce_float(geometry.get("y")) or 0.0) + dy
        elif element_type in {"callout", "arrow"}:
            # Iterate over ("x0", "x1") to apply the per-item logic.
            for key in ("x0", "x1"):
                if key in geometry:
                    geometry[key] = (_coerce_float(geometry.get(key)) or 0.0) + dx
            # Iterate over ("y0", "y1") to apply the per-item logic.
            for key in ("y0", "y1"):
                if key in geometry:
                    geometry[key] = (_coerce_float(geometry.get(key)) or 0.0) + dy
        elif element_type in {"xspan", "trace_mask"}:
            # Iterate over ("x0", "x1") to apply the per-item logic.
            for key in ("x0", "x1"):
                if key in geometry:
                    geometry[key] = (_coerce_float(geometry.get(key)) or 0.0) + dx
        elif element_type == "xspan_label":
            # Iterate over ("x0", "x1", "label_x") to apply the per-item logic.
            for key in ("x0", "x1", "label_x"):
                if key in geometry:
                    geometry[key] = (_coerce_float(geometry.get(key)) or 0.0) + dx
            if "label_y_axes" in geometry:
                geometry["label_y_axes"] = (_coerce_float(geometry.get("label_y_axes")) or 0.0) + dy
            elif "label_y_data" in geometry:
                geometry["label_y_data"] = (_coerce_float(geometry.get("label_y_data")) or 0.0) + dy
        elif element_type == "rect":
            # Iterate over ("x0", "x1") to apply the per-item logic.
            for key in ("x0", "x1"):
                if key in geometry:
                    geometry[key] = (_coerce_float(geometry.get(key)) or 0.0) + dx
            # Iterate over ("y0", "y1") to apply the per-item logic.
            for key in ("y0", "y1"):
                if key in geometry:
                    geometry[key] = (_coerce_float(geometry.get(key)) or 0.0) + dy
        elif element_type == "ref_line":
            orientation = str(geometry.get("orientation") or "vertical").strip().lower()
            if orientation == "horizontal":
                geometry["value"] = (_coerce_float(geometry.get("value")) or 0.0) + dy
            else:
                geometry["value"] = (_coerce_float(geometry.get("value")) or 0.0) + dx
        elif element_type == "trace_start":
            if "x_start" in geometry:
                geometry["x_start"] = (_coerce_float(geometry.get("x_start")) or 0.0) + dx
        elif element_type == "ink":
            points = geometry.get("points")
            if isinstance(points, list) and points:
                geometry["points"] = [(px + dx, py + dy) for px, py in points]
        else:
            return
        self._commit_history()
        self.render()
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _on_press(self, event: Any) -> None:
        """Handle press.
        Used as an event callback for press."""
        if event is None:
            return
        press_event = getattr(event, "mouseevent", None) or event
        artist = getattr(event, "artist", None)
        resolved_ax = getattr(press_event, "inaxes", None) or self._resolve_axes_from_pixels(
            press_event
        )
        if (
            artist is not None
            and getattr(artist, "_gl260_annotation_handle", None) == "label"
        ):
            if self._placing_type is None:
                if self._mode != "select":
                    return
                element_id = getattr(artist, "_gl260_annotation_id", None) or getattr(
                    artist, "_gl260_element_id", None
                )
                if element_id:
                    element = next(
                        (el for el in self._elements() if el.get("id") == element_id),
                        None,
                    )
                    if element is None:
                        return
                    if self._placing_type not in {"xspan", "xspan_label", "trace_mask"} or (
                        self._placing_coord_space or "data"
                    ) != "data":
                        self._clear_span_selectors()
                    self.set_selected_id(element.get("id"))
                    if element.get("locked"):
                        return
                    ax = self._axes_map.get(element.get("axes_target", "primary"))
                    if ax is None:
                        ax = resolved_ax
                    if ax is None:
                        return
                    self._start_drag(element, "label", press_event, ax)
                return
        if (
            getattr(event, "name", "") == "pick_event"
            and self._placing_type is None
        ):
            return
        if DEBUG_ANNOTATIONS_INTERACTION:
            print(
                "[ANNOTATIONS] press armed="
                f"{self._placing_type} mode={self._mode} "
                f"inaxes={press_event.inaxes is not None} "
                f"resolved={resolved_ax is not None} "
                f"drag={self._drag_state is not None} "
                f"selected={self._selected_id}"
            )
        if resolved_ax is None:
            return
        if self._placing_type is not None:
            if self._span_selectors:
                selector_axes = {
                    getattr(selector, "ax", None) for selector in self._span_selectors
                }
                if resolved_ax in selector_axes:
                    return
            self._start_placing(press_event)
            return
        ax = resolved_ax
        if self._mode == "erase":
            if self._erase_ink(ax, press_event):
                self._commit_history()
            return
        if self._mode == "select":
            element, handle, hit_ax = self._hit_test_element(press_event)
            if element is None:
                self.set_selected_id(None)
                return
            if element.get("locked"):
                self.set_selected_id(element.get("id"))
                return
            if self._placing_type not in {"xspan", "xspan_label", "trace_mask"} or (
                self._placing_coord_space or "data"
            ) != "data":
                self._clear_span_selectors()
            self.set_selected_id(element.get("id"))
            self._start_drag(element, handle, press_event, hit_ax or ax)
            return
        self._start_creation(ax, press_event)

    def _on_motion(self, event: Any) -> None:
        """Handle motion.
        Used as an event callback for motion."""
        if DEBUG_ANNOTATIONS_INTERACTION:
            inaxes = (
                bool(getattr(event, "inaxes", None)) if event is not None else False
            )
            print(
                "[ANNOTATIONS] motion armed="
                f"{self._placing_type} mode={self._mode} "
                f"inaxes={inaxes} "
                f"drag={self._drag_state is not None} "
                f"selected={self._selected_id}"
            )
        if event is None:
            return
        if self._placing_state is not None:
            self._update_placing(event)
            return
        if self._drag_state is None:
            return
        drag_ax = self._drag_state.get("ax")
        if drag_ax is None:
            return
        if getattr(event, "x", None) is None or getattr(event, "y", None) is None:
            return
        element = self._drag_state.get("element")
        if not element:
            return
        if element.get("locked"):
            return
        self._dirty = True
        self._update_dragged_element(element, event)
        handle = self._drag_state.get("handle", "move") if self._drag_state else "move"
        skip_wrap = handle != "wrap"
        if self._sync_dragged_element_artists(element, skip_wrap=skip_wrap):
            if not self._blit_drag_update():
                try:
                    if self._canvas is not None:
                        self._canvas.draw_idle()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        else:
            self._end_drag_blit()
            self.render()

    def _on_release(self, event: Any) -> None:
        """Handle release.
        Used as an event callback for release."""
        if DEBUG_ANNOTATIONS_INTERACTION:
            inaxes = (
                bool(getattr(event, "inaxes", None)) if event is not None else False
            )
            print(
                "[ANNOTATIONS] release armed="
                f"{self._placing_type} mode={self._mode} "
                f"inaxes={inaxes} "
                f"drag={self._drag_state is not None} "
                f"selected={self._selected_id}"
            )
        if self._placing_state is not None:
            self._commit_placing(event)
            return
        if self._drag_state is None:
            return
        if self._drag_state.get("creating"):
            element = self._drag_state.get("element")
            self._drag_state = None
            self._dirty = False
            if not element:
                return
            element_type = str(element.get("type") or "").strip().lower()
            geometry = (
                element.get("geometry")
                if isinstance(element.get("geometry"), dict)
                else {}
            )
            valid = True
            if element_type in {"xspan", "xspan_label", "trace_mask"}:
                x0 = _coerce_float(geometry.get("x0"))
                x1 = _coerce_float(geometry.get("x1"))
                if x0 is None or x1 is None or abs(x1 - x0) <= 1e-12:
                    valid = False
            if element_type == "trace_start":
                if _coerce_float(geometry.get("x_start")) is None:
                    valid = False
            if element_type == "rect":
                x0 = _coerce_float(geometry.get("x0"))
                x1 = _coerce_float(geometry.get("x1"))
                y0 = _coerce_float(geometry.get("y0"))
                y1 = _coerce_float(geometry.get("y1"))
                if None in (x0, x1, y0, y1):
                    valid = False
                elif abs(x1 - x0) <= 1e-12 and abs(y1 - y0) <= 1e-12:
                    valid = False
            if element_type == "ink":
                points = geometry.get("points")
                if not isinstance(points, list) or len(points) < 2:
                    valid = False
            if not valid:
                if element in self._elements():
                    self._elements().remove(element)
                if element.get("id") == self._selected_id:
                    self.set_selected_id(None)
                if self._placing_type is not None and not self._placing_keep_placing:
                    self.cancel_place_element()
                    self.set_mode("select")
                else:
                    self.render()
                return
            self._commit_history()
            self.set_selected_id(element.get("id"))
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if self._placing_type is not None and not self._placing_keep_placing:
                self.cancel_place_element()
                self.set_mode("select")
            return
        element = self._drag_state.get("element")
        if element and not element.get("locked"):
            try:
                self._sync_dragged_element_artists(element, skip_wrap=False)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._end_drag_blit()
        self._refresh_overlays_only()
        if self._dirty:
            self._commit_history()
        self._drag_state = None
        self._dirty = False
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _commit_history(self) -> None:
        """Perform commit history.
        Used to keep the workflow logic localized and testable."""
        self._history.push(self._elements())
        if self._panel is not None:
            self._panel.refresh()
        if self._on_elements_changed is not None:
            try:
                self._on_elements_changed(self._plot_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _resolve_axes_from_pixels(self, event: Any) -> Optional[Axes]:
        """Resolve axes from pixels.
        Used to compute axes from pixels before rendering or export."""
        if event is None:
            return None
        x = getattr(event, "x", None)
        y = getattr(event, "y", None)
        if x is None or y is None:
            return None
        candidates = list(self._axes_map.values()) if self._axes_map else []
        if not candidates:
            fig_axes = getattr(self._fig, "axes", None)
            if isinstance(fig_axes, list):
                candidates = fig_axes
        seen = set()
        unique_axes: List[Axes] = []
        # Iterate over candidates to apply the per-item logic.
        for ax in candidates:
            if ax is None or ax in seen:
                continue
            unique_axes.append(ax)
            seen.add(ax)
        matches: List[Tuple[float, int, Axes]] = []
        # Iterate over indexed elements from unique_axes to apply the per-item logic.
        for idx, ax in enumerate(unique_axes):
            try:
                if ax.bbox.contains(x, y):
                    try:
                        zorder = float(ax.get_zorder())
                    except Exception:
                        zorder = 0.0
                    matches.append((zorder, idx, ax))
            except Exception:
                continue
        if not matches:
            return None
        matches.sort(key=lambda item: (item[0], item[1]))
        return matches[-1][2]

    def _hit_test_element(
        self, event: Any
    ) -> Tuple[Optional[Dict[str, Any]], Optional[str], Optional[Axes]]:
        """Perform hit test element.
        Used to keep the workflow logic localized and testable."""
        elements = sorted(
            self._elements(),
            key=lambda item: float(item.get("zorder", ANNOTATION_DEFAULT_ZORDER)),
            reverse=True,
        )
        # Iterate over elements to apply the per-item logic.
        for element in elements:
            if not element.get("visible", True):
                continue
            target_ax = self._axes_map.get(element.get("axes_target", "primary"))
            if target_ax is None:
                continue
            handle = self._hit_test.hit_test(target_ax, element, event)
            if handle:
                return element, handle, target_ax
        return None, None, None

    def _event_coords(
        self, event: Any, coord_space: str, ax: Axes
    ) -> Optional[Tuple[float, float]]:
        """Perform event coords.
        Used to keep the workflow logic localized and testable."""
        try:
            if coord_space == "axes":
                return tuple(ax.transAxes.inverted().transform((event.x, event.y)))
            x = getattr(event, "x", None)
            y = getattr(event, "y", None)
            if x is None or y is None:
                return None
            xdata = getattr(event, "xdata", None)
            ydata = getattr(event, "ydata", None)
            if xdata is not None and ydata is not None:
                return float(xdata), float(ydata)
            return tuple(ax.transData.inverted().transform((x, y)))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None

    def _event_coords_for_axis(
        self, event: Any, coord_space: str, ax: Axes
    ) -> Optional[Tuple[float, float]]:
        """Perform event coords for axis.
        Used to keep the workflow logic localized and testable."""
        try:
            if coord_space == "axes":
                return tuple(ax.transAxes.inverted().transform((event.x, event.y)))
            x = getattr(event, "x", None)
            y = getattr(event, "y", None)
            if x is None or y is None:
                return None
            return tuple(ax.transData.inverted().transform((x, y)))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None

    def _placement_axis(self, event: Any) -> Tuple[str, Optional[Axes]]:
        """Perform placement axis.
        Used to keep the workflow logic localized and testable."""
        axis_role = self._placing_axis_target
        resolved_ax = getattr(event, "inaxes", None) or self._resolve_axes_from_pixels(
            event
        )
        if not axis_role:
            axis_role = self._axes_role_map.get(resolved_ax, "primary")
        axis_role = _normalize_axes_target(axis_role)
        ax = self._axes_map.get(axis_role) or resolved_ax
        if ax is None:
            ax = next((axis for axis in self._axes_map.values() if axis), None)
        return axis_role, ax

    def _default_span_wrap_width(
        self,
        ax: Optional[Axes],
        x0: Optional[float],
        x1: Optional[float],
        coord_space: str,
    ) -> Optional[float]:
        """Return default span wrap width.
        Used when callers need a safe fallback."""
        if coord_space == "axes":
            width = abs((x1 or 0.0) - (x0 or 0.0))
            if width <= 0:
                width = 0.25
            return max(0.02, min(width, 1.0))
        width = abs((x1 or 0.0) - (x0 or 0.0))
        if width <= 0 and ax is not None:
            try:
                x_limits = ax.get_xlim()
                width = 0.25 * abs(x_limits[1] - x_limits[0])
            except Exception:
                width = 0.0
        if ax is None:
            return width if width > 0 else None
        try:
            x_limits = ax.get_xlim()
            x_range = abs(x_limits[1] - x_limits[0]) or 1.0
        except Exception:
            x_range = 1.0
        if width <= 0:
            width = 0.25 * x_range
        return max(0.01 * x_range, min(width, x_range))

    def _clear_draft(self) -> None:
        """Clear draft.
        Used to reset draft state safely."""
        # Iterate over list(self._draft_artists or []) to apply the per-item logic.
        for artist in list(self._draft_artists or []):
            try:
                artist.remove()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._draft_artists = []
        self._draft_element = None

    def _render_draft(self) -> None:
        """Render draft.
        Used to draw draft for preview or export workflows."""
        if self._draft_element is None:
            return
        axes_target = str(self._draft_element.get("axes_target") or "primary").strip()
        ax = self._axes_map.get(axes_target) or self._axes_map.get("primary")
        if ax is None:
            return
        try:
            rendered = self._renderer._render_element(ax, self._draft_element)
        except Exception:
            rendered = None
        if rendered is None:
            return
        artists = list(rendered) if isinstance(rendered, (list, tuple)) else [rendered]
        # Iterate over artists to apply the per-item logic.
        for artist in artists:
            if artist is None:
                continue
            self._overlay_artists.append(artist)
            self._draft_artists.append(artist)

    def _build_new_element(
        self,
        element_type: str,
        axis_target: str,
        coord_space: str,
        geometry: Dict[str, Any],
        style: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Build new element.
        Used to assemble new element during UI or plot setup."""
        element_id = str(uuid.uuid4())
        return {
            "id": element_id,
            "name": _default_annotation_name(element_type, len(self._elements())),
            "type": element_type,
            "axes_target": axis_target,
            "coord_space": coord_space,
            "visible": True,
            "locked": False,
            "zorder": self._next_zorder(),
            "style": style,
            "geometry": geometry,
        }

    def _start_placing(self, event: Any) -> None:
        """Perform start placing.
        Used to keep the workflow logic localized and testable."""
        if self._placing_type is None or event is None:
            return
        axis_role, ax = self._placement_axis(event)
        if ax is None:
            return
        coord_space = self._placing_coord_space or "data"
        coords = self._event_coords_for_axis(event, coord_space, ax)
        if coords is None:
            return
        x, y = coords
        element_type = self._placing_type
        style = _default_style_for_type(element_type)
        style.update(self._placing_style_overrides or {})
        seed = self._placing_geometry_seed or {}
        shift = "shift" in str(getattr(event, "key", "") or "").lower()

        if element_type in {"point", "text", "ref_line", "trace_start"}:
            if element_type == "point":
                geometry = {"x": x, "y": y}
            elif element_type == "ref_line":
                orientation = "horizontal" if shift else "vertical"
                value = y if orientation == "horizontal" else x
                geometry = {"orientation": orientation, "value": value}
                label_text = seed.get("text")
                if isinstance(label_text, str) and label_text.strip():
                    geometry["text"] = label_text
            elif element_type == "trace_start":
                geometry = {
                    "x_start": x,
                    "trace_key": _normalize_trace_series_key(
                        seed.get("trace_key"), default="y2"
                    ),
                }
            else:
                text_value = seed.get("text")
                if not isinstance(text_value, str) or not text_value.strip():
                    text_value = "Text"
                if coord_space == "axes":
                    wrap_width = 0.25
                else:
                    wrap_width = None
                    try:
                        x_limits = ax.get_xlim()
                        wrap_width = 0.20 * (x_limits[1] - x_limits[0])
                    except Exception:
                        wrap_width = None
                geometry = {"x": x, "y": y, "text": text_value}
                if wrap_width is not None:
                    geometry["wrap_width_x"] = wrap_width
            element = self._build_new_element(
                element_type, axis_role, coord_space, geometry, style
            )
            self._elements().append(element)
            self._commit_history()
            self.set_selected_id(element.get("id"))
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if not self._placing_keep_placing:
                self.cancel_place_element()
                self.set_mode("select")
            return

        geometry: Dict[str, Any] = {}
        label_text = seed.get("text")
        if not isinstance(label_text, str):
            label_text = ""
        if element_type == "callout":
            if not label_text.strip():
                label_text = "Callout"
            geometry.update({"x0": x, "y0": y, "x1": x, "y1": y, "text": label_text})
        elif element_type == "arrow":
            geometry.update({"x0": x, "y0": y, "x1": x, "y1": y})
        elif element_type == "xspan":
            geometry.update({"x0": x, "x1": x})
        elif element_type == "trace_mask":
            geometry.update(
                {
                    "x0": x,
                    "x1": x,
                    "trace_key": _normalize_trace_series_key(
                        seed.get("trace_key"), default="y2"
                    ),
                }
            )
        elif element_type == "xspan_label":
            if not label_text.strip():
                label_text = "Label"
            label_y_axes = _coerce_float(seed.get("label_y_axes"))
            if label_y_axes is None:
                label_y_axes = 0.95
            label_anchor = seed.get("label_anchor")
            if not isinstance(label_anchor, str) or not label_anchor.strip():
                label_anchor = "center"
            geometry.update(
                {
                    "x0": x,
                    "x1": x,
                    "label_x": x,
                    "label_y_axes": max(0.0, min(1.0, float(label_y_axes))),
                    "label_anchor": label_anchor,
                    "text": label_text,
                }
            )
            wrap_width = self._default_span_wrap_width(ax, x, x, coord_space)
            if wrap_width is not None:
                geometry["wrap_width_x"] = wrap_width
        elif element_type == "rect":
            geometry.update({"x0": x, "y0": y, "x1": x, "y1": y})
            if isinstance(label_text, str) and label_text.strip():
                geometry["text"] = label_text
        elif element_type == "ink":
            geometry.update({"points": [(x, y)]})
        else:
            return

        self._placing_state = {
            "ax": ax,
            "axis_role": axis_role,
            "coord_space": coord_space,
            "start": (x, y),
            "last": (x, y),
        }
        draft = {
            "id": "__draft__",
            "name": "Draft",
            "type": element_type,
            "axes_target": axis_role,
            "coord_space": coord_space,
            "visible": True,
            "locked": False,
            "zorder": self._next_zorder(),
            "style": style,
            "geometry": geometry,
            "_draft": True,
        }
        self._draft_element = draft
        self.render()

    def _update_placing(self, event: Any) -> None:
        """Update placing.
        Used to keep placing in sync with current state."""
        if self._placing_state is None or self._draft_element is None:
            return
        ax = self._placing_state.get("ax")
        coord_space = self._placing_state.get("coord_space", "data")
        if ax is None or event is None:
            return
        coords = self._event_coords_for_axis(event, coord_space, ax)
        if coords is None:
            return
        x, y = coords
        geometry = (
            self._draft_element.get("geometry")
            if isinstance(self._draft_element.get("geometry"), dict)
            else {}
        )
        element_type = str(self._draft_element.get("type") or "").strip().lower()
        if element_type in {"callout", "arrow", "rect"}:
            geometry["x1"] = x
            geometry["y1"] = y
        elif element_type in {"xspan", "trace_mask"}:
            geometry["x1"] = x
        elif element_type == "xspan_label":
            geometry["x1"] = x
            x0 = _coerce_float(geometry.get("x0"))
            if x0 is None:
                x0 = x
            geometry["label_x"] = (x0 + x) / 2.0
        elif element_type == "ink":
            points = geometry.get("points")
            if not isinstance(points, list):
                points = []
                geometry["points"] = points
            if not points or points[-1] != (x, y):
                points.append((x, y))
        self._draft_element["geometry"] = geometry
        self.render()

    def _commit_placing(self, event: Any) -> None:
        """Perform commit placing.
        Used to keep the workflow logic localized and testable."""
        if self._placing_state is None or self._draft_element is None:
            return
        element_type = str(self._draft_element.get("type") or "").strip().lower()
        geometry = copy.deepcopy(self._draft_element.get("geometry", {}))
        axis_target = str(self._draft_element.get("axes_target") or "primary").strip()
        coord_space = str(self._draft_element.get("coord_space") or "data").strip()
        style = copy.deepcopy(self._draft_element.get("style", {}))
        valid = True
        if element_type in {"xspan", "xspan_label", "trace_mask"}:
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            if x0 is None or x1 is None or abs(x1 - x0) <= 1e-12:
                valid = False
            if element_type == "xspan_label":
                wrap_width = _coerce_float(geometry.get("wrap_width_x"))
                if wrap_width is None or wrap_width <= 0:
                    ax = self._placing_state.get("ax") if self._placing_state else None
                    wrap_width = self._default_span_wrap_width(
                        ax, x0, x1, coord_space
                    )
                    if wrap_width is not None:
                        geometry["wrap_width_x"] = wrap_width
        if element_type == "trace_start":
            if _coerce_float(geometry.get("x_start")) is None:
                valid = False
        if element_type == "rect":
            x0 = _coerce_float(geometry.get("x0"))
            x1 = _coerce_float(geometry.get("x1"))
            y0 = _coerce_float(geometry.get("y0"))
            y1 = _coerce_float(geometry.get("y1"))
            if None in (x0, x1, y0, y1):
                valid = False
        if element_type == "ink":
            points = geometry.get("points")
            if not isinstance(points, list) or len(points) < 2:
                valid = False
        if element_type in {"trace_mask", "trace_start"}:
            geometry["trace_key"] = _normalize_trace_series_key(
                geometry.get("trace_key"), default="y2"
            )
        if not valid:
            self._placing_state = None
            self._clear_draft()
            if not self._placing_keep_placing:
                self.cancel_place_element()
                self.set_mode("select")
            else:
                self.render()
            return
        element = self._build_new_element(
            element_type, axis_target, coord_space, geometry, style
        )
        self._elements().append(element)
        self._placing_state = None
        self._clear_draft()
        self._commit_history()
        self.set_selected_id(element.get("id"))
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if not self._placing_keep_placing:
            self.cancel_place_element()
            self.set_mode("select")

    def _start_drag(
        self, element: Dict[str, Any], handle: Optional[str], event: Any, ax: Axes
    ) -> None:
        """Perform start drag.
        Used to keep the workflow logic localized and testable."""
        coord_space = str(element.get("coord_space") or "data").strip().lower()
        coords = self._event_coords(event, coord_space, ax)
        if coords is None:
            return
        self._drag_state = {
            "element": element,
            "handle": handle or "move",
            "start_coords": coords,
            "start_geometry": copy.deepcopy(element.get("geometry", {})),
            "ax": ax,
            "coord_space": coord_space,
        }
        element_id = str(element.get("id") or "")
        if element_id:
            self._arm_drag_blit(element_id)

    def _start_creation(
        self, ax: Axes, event: Any, *, element_type: Optional[str] = None
    ) -> None:
        """Perform start creation.
        Used to keep the workflow logic localized and testable."""
        coord_space = "data"
        coords = self._event_coords(event, coord_space, ax)
        if coords is None:
            return
        x, y = coords
        element_type = element_type or self._mode
        element_id = str(uuid.uuid4())
        element = {
            "id": element_id,
            "name": _default_annotation_name(element_type, len(self._elements())),
            "type": element_type,
            "axes_target": self._axes_role_map.get(ax, "primary"),
            "coord_space": coord_space,
            "visible": True,
            "locked": False,
            "zorder": self._next_zorder(),
            "style": _default_style_for_type(element_type),
            "geometry": {},
        }
        geometry = element["geometry"]
        if element_type == "text":
            x_limits = ax.get_xlim()
            wrap_width = 0.20 * (x_limits[1] - x_limits[0])
            geometry.update(
                {"x": x, "y": y, "text": "Text", "wrap_width_x": wrap_width}
            )
            self._elements().append(element)
            self.set_selected_id(element_id)
            self._commit_history()
            return
        if element_type == "point":
            geometry.update({"x": x, "y": y})
            self._elements().append(element)
            self.set_selected_id(element_id)
            self._commit_history()
            return
        if element_type == "trace_start":
            geometry.update({"x_start": x, "trace_key": "y2"})
            self._elements().append(element)
            self.set_selected_id(element_id)
            self._commit_history()
            return
        if element_type == "callout":
            geometry.update({"x0": x, "y0": y, "x1": x, "y1": y, "text": "Callout"})
        elif element_type == "arrow":
            geometry.update({"x0": x, "y0": y, "x1": x, "y1": y})
        elif element_type == "xspan":
            geometry.update({"x0": x, "x1": x})
        elif element_type == "trace_mask":
            geometry.update({"x0": x, "x1": x, "trace_key": "y2"})
        elif element_type == "xspan_label":
            geometry.update(
                {"x0": x, "x1": x, "label_x": x, "label_y_data": y, "text": "Label"}
            )
            wrap_width = self._default_span_wrap_width(ax, x, x, coord_space)
            if wrap_width is not None:
                geometry["wrap_width_x"] = wrap_width
        elif element_type == "rect":
            geometry.update({"x0": x, "y0": y, "x1": x, "y1": y})
        elif element_type == "ref_line":
            geometry.update({"orientation": "vertical", "value": x})
        elif element_type == "ink":
            geometry.update({"points": [(x, y)]})
        else:
            return
        self._elements().append(element)
        self.set_selected_id(element_id)
        self._drag_state = {
            "element": element,
            "handle": "create",
            "start_coords": (x, y),
            "start_geometry": copy.deepcopy(geometry),
            "ax": ax,
            "coord_space": coord_space,
            "creating": True,
        }
        self._dirty = True

    def _update_dragged_element(self, element: Dict[str, Any], event: Any) -> None:
        """Update dragged element.
        Used to keep dragged element in sync with current state."""
        geometry = element.get("geometry")
        if not isinstance(geometry, dict):
            return
        coord_space = str(element.get("coord_space") or "data").strip().lower()
        ax = self._drag_state.get("ax")
        if ax is None:
            return
        coords = self._event_coords(event, coord_space, ax)
        if coords is None:
            return
        x, y = coords
        start_geom = self._drag_state.get("start_geometry", {})
        handle = self._drag_state.get("handle", "move")
        element_type = str(element.get("type") or "").strip().lower()
        start_x, start_y = self._drag_state.get("start_coords", (x, y))
        dx = x - start_x
        dy = y - start_y

        if element_type == "text":
            if handle == "wrap":
                x_limits = ax.get_xlim()
                x_range = abs(x_limits[1] - x_limits[0])
                if x_range <= 0:
                    x_range = 1.0
                base_width = _coerce_float(start_geom.get("wrap_width_x"))
                if base_width is None or base_width <= 0:
                    base_width = 0.20 * x_range
                new_width = base_width + dx
                min_width = 0.01 * x_range
                max_width = 10.0 * x_range
                if new_width < min_width:
                    new_width = min_width
                elif new_width > max_width:
                    new_width = max_width
                geometry["wrap_width_x"] = new_width
            else:
                geometry["x"] = start_geom.get("x", x) + dx
                geometry["y"] = start_geom.get("y", y) + dy
        elif element_type == "callout":
            if handle == "anchor":
                geometry["x0"] = x
                geometry["y0"] = y
            elif handle == "text":
                geometry["x1"] = x
                geometry["y1"] = y
            else:
                geometry["x0"] = start_geom.get("x0", x) + dx
                geometry["y0"] = start_geom.get("y0", y) + dy
                geometry["x1"] = start_geom.get("x1", x) + dx
                geometry["y1"] = start_geom.get("y1", y) + dy
        elif element_type == "arrow":
            if handle == "tail":
                geometry["x0"] = x
                geometry["y0"] = y
            elif handle == "head":
                geometry["x1"] = x
                geometry["y1"] = y
            else:
                geometry["x0"] = start_geom.get("x0", x) + dx
                geometry["y0"] = start_geom.get("y0", y) + dy
                geometry["x1"] = start_geom.get("x1", x) + dx
                geometry["y1"] = start_geom.get("y1", y) + dy
        elif element_type == "point":
            new_x = start_geom.get("x", x) + dx
            new_y = start_geom.get("y", y) + dy
            style = (
                element.get("style", {})
                if isinstance(element.get("style"), dict)
                else {}
            )
            if style.get("snap_to_data"):
                new_x, new_y = self._snap_to_nearest_data(ax, new_x, new_y, style)
            geometry["x"] = new_x
            geometry["y"] = new_y
        elif element_type == "xspan":
            if handle == "x0":
                geometry["x0"] = x
            elif handle == "x1":
                geometry["x1"] = x
            else:
                geometry["x0"] = start_geom.get("x0", x) + dx
                geometry["x1"] = start_geom.get("x1", x) + dx
        elif element_type == "trace_mask":
            if handle == "x0":
                geometry["x0"] = x
            elif handle == "x1":
                geometry["x1"] = x
            else:
                geometry["x0"] = start_geom.get("x0", x) + dx
                geometry["x1"] = start_geom.get("x1", x) + dx
        elif element_type == "trace_start":
            geometry["x_start"] = start_geom.get("x_start", x) + dx
        elif element_type == "xspan_label":
            if handle == "wrap":
                if coord_space == "axes":
                    axis_range = 1.0
                else:
                    try:
                        x_limits = ax.get_xlim()
                        axis_range = abs(x_limits[1] - x_limits[0]) or 1.0
                    except Exception:
                        axis_range = 1.0
                base_width = _coerce_float(start_geom.get("wrap_width_x"))
                if base_width is None or base_width <= 0:
                    base_width = 0.25 * axis_range
                new_width = base_width + dx
                min_width = 0.02 * axis_range
                max_width = 2.0 * axis_range
                if new_width < min_width:
                    new_width = min_width
                elif new_width > max_width:
                    new_width = max_width
                geometry["wrap_width_x"] = new_width
            elif handle == "label":
                geometry["label_x"] = x
                if "label_y_axes" in geometry:
                    if coord_space == "axes":
                        geometry["label_y_axes"] = max(0.0, min(1.0, float(y)))
                    else:
                        try:
                            disp = ax.transData.transform((x, y))
                            y_axes = ax.transAxes.inverted().transform(disp)[1]
                            geometry["label_y_axes"] = max(
                                0.0, min(1.0, float(y_axes))
                            )
                        except Exception:
                            geometry["label_y_data"] = y
                else:
                    geometry["label_y_data"] = y
            elif handle == "x0":
                geometry["x0"] = x
            elif handle == "x1":
                geometry["x1"] = x
            else:
                geometry["x0"] = start_geom.get("x0", x) + dx
                geometry["x1"] = start_geom.get("x1", x) + dx
                geometry["label_x"] = start_geom.get("label_x", x) + dx
        elif element_type == "rect":
            if handle in {"nw", "ne", "sw", "se"}:
                if "n" in handle:
                    geometry["y1"] = y
                if "s" in handle:
                    geometry["y0"] = y
                if "w" in handle:
                    geometry["x0"] = x
                if "e" in handle:
                    geometry["x1"] = x
            else:
                geometry["x0"] = start_geom.get("x0", x) + dx
                geometry["x1"] = start_geom.get("x1", x) + dx
                geometry["y0"] = start_geom.get("y0", y) + dy
                geometry["y1"] = start_geom.get("y1", y) + dy
        elif element_type == "ref_line":
            if (
                str(geometry.get("orientation") or "vertical").strip().lower()
                == "horizontal"
            ):
                geometry["value"] = y
            else:
                geometry["value"] = x
        elif element_type == "ink":
            points = geometry.get("points")
            if isinstance(points, list) and points:
                if self._mode == "ink" and self._drag_state.get("creating"):
                    points.append((x, y))
                else:
                    geometry["points"] = [(px + dx, py + dy) for px, py in points]

    def _next_zorder(self) -> float:
        """Perform next zorder.
        Used to keep the workflow logic localized and testable."""
        orders = [
            float(el.get("zorder", ANNOTATION_DEFAULT_ZORDER))
            # Iterate to apply the per-item logic.
            for el in self._elements()
        ]
        return max(orders + [ANNOTATION_DEFAULT_ZORDER]) + 1.0

    def _snap_to_nearest_data(
        self, ax: Axes, x: float, y: float, style: Mapping[str, Any]
    ) -> Tuple[float, float]:
        """Perform snap to nearest data.
        Used to keep the workflow logic localized and testable."""
        tolerance = _coerce_float(style.get("snap_tolerance"))
        if tolerance is None:
            xlim = ax.get_xlim()
            ylim = ax.get_ylim()
            tolerance = 0.01 * max(abs(xlim[1] - xlim[0]), abs(ylim[1] - ylim[0]))
        best = None
        best_dist = None
        # Iterate over ax.lines to apply the per-item logic.
        for line in ax.lines:
            try:
                xs = line.get_xdata()
                ys = line.get_ydata()
            except Exception:
                continue
            # Iterate over paired elements from multiple sequences to apply the per-item logic.
            for px, py in zip(xs, ys):
                try:
                    dist = (float(px) - x) ** 2 + (float(py) - y) ** 2
                except Exception:
                    continue
                if best_dist is None or dist < best_dist:
                    best_dist = dist
                    best = (float(px), float(py))
        if best is None:
            return x, y
        if best_dist is not None and best_dist <= tolerance * tolerance:
            return best
        return x, y

    def _erase_ink(self, ax: Axes, event: Any) -> bool:
        """Perform erase ink.
        Used to keep the workflow logic localized and testable."""
        if event is None:
            return False
        event_xy = (event.x, event.y)
        # Iterate over reversed elements from self._elements( to apply the per-item logic.
        for element in reversed(self._elements()):
            if element.get("type") != "ink":
                continue
            target_ax = self._axes_map.get(element.get("axes_target", "primary"))
            if target_ax is None or target_ax is not ax:
                continue
            geometry = element.get("geometry", {})
            points = geometry.get("points")
            if not isinstance(points, list) or not points:
                continue
            coord_space = str(element.get("coord_space") or "data").strip().lower()
            transform = ax.transAxes if coord_space == "axes" else ax.transData
            kept = []
            removed_any = False
            # Iterate over points to apply the per-item logic.
            for px, py in points:
                try:
                    disp = transform.transform((px, py))
                except Exception:
                    kept.append((px, py))
                    continue
                dist = math.hypot(disp[0] - event_xy[0], disp[1] - event_xy[1])
                if dist <= self._hit_test._pixel_tolerance:
                    removed_any = True
                    continue
                kept.append((px, py))
            if removed_any:
                if len(kept) < 2:
                    self._elements().remove(element)
                else:
                    geometry["points"] = kept
                self.render()
                return True
        return False

    def _cancel_draft(self) -> None:
        """Perform cancel draft.
        Used to keep the workflow logic localized and testable."""
        if self._drag_state and self._drag_state.get("creating"):
            element = self._drag_state.get("element")
            if element in self._elements():
                self._elements().remove(element)
            self._drag_state = None
            self._dirty = False
            self.render()
        if self._draft_element is not None:
            self._placing_state = None
            self._clear_draft()
            self.render()

    def undo(self) -> None:
        """Perform undo.
        Used to keep the workflow logic localized and testable."""
        restored = self._history.undo()
        if restored is None:
            return
        self._store.set_elements(self._plot_id, restored)
        self._selected_id = None
        self.render()
        if self._panel is not None:
            self._panel.refresh()
        if self._on_elements_changed is not None:
            try:
                self._on_elements_changed(self._plot_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def redo(self) -> None:
        """Perform redo.
        Used to keep the workflow logic localized and testable."""
        restored = self._history.redo()
        if restored is None:
            return
        self._store.set_elements(self._plot_id, restored)
        self._selected_id = None
        self.render()
        if self._panel is not None:
            self._panel.refresh()
        if self._on_elements_changed is not None:
            try:
                self._on_elements_changed(self._plot_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def delete_selected(self) -> None:
        """Perform delete selected.
        Used to keep the workflow logic localized and testable."""
        element = self.selected_element()
        if element is None:
            return
        if element.get("locked"):
            return
        try:
            self._elements().remove(element)
        except ValueError:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        self._selected_id = None
        self._store.set_ui_state(self._plot_id, last_selected_id=None)
        self._commit_history()
        self.render()

    def duplicate_selected(self) -> None:
        """Perform duplicate selected.
        Used to keep the workflow logic localized and testable."""
        element = self.selected_element()
        if element is None:
            return
        duplicate = copy.deepcopy(element)
        duplicate["id"] = str(uuid.uuid4())
        duplicate["name"] = f"{duplicate.get('name', 'Annotation')} Copy"
        duplicate["zorder"] = self._next_zorder()
        self._elements().append(duplicate)
        self._commit_history()
        self.set_selected_id(duplicate["id"])

    def copy_style(self) -> None:
        """Perform copy style.
        Used to keep the workflow logic localized and testable."""
        element = self.selected_element()
        if element is None:
            return
        style = element.get("style")
        if not isinstance(style, dict):
            return
        self._style_clipboard = copy.deepcopy(style)

    def paste_style(self) -> None:
        """Perform paste style.
        Used to keep the workflow logic localized and testable."""
        element = self.selected_element()
        if element is None or element.get("locked"):
            return
        if not self._style_clipboard:
            return
        element_type = str(element.get("type") or "").strip().lower()
        allowed = _annotation_style_keys_for_type(element_type)
        updates = {
            key: value
            # Iterate to apply the per-item logic.
            for key, value in self._style_clipboard.items()
            if key in allowed
        }
        if not updates:
            return
        self.update_element_properties(element.get("id"), style_updates=updates)

    def apply_style_preset(self, preset_name: str) -> None:
        """Apply style preset.
        Used to apply style preset changes to live state."""
        element = self.selected_element()
        if element is None or element.get("locked"):
            return
        preset_key = str(preset_name or "").strip().lower()
        preset = ANNOTATION_STYLE_PRESETS.get(preset_key)
        if not preset:
            return
        element_type = str(element.get("type") or "").strip().lower()
        allowed = _annotation_style_keys_for_type(element_type)
        updates = {key: value for key, value in preset.items() if key in allowed}
        if not updates:
            return
        self.update_element_properties(element.get("id"), style_updates=updates)

    def toggle_visibility(self, element_id: str) -> None:
        """Toggle visibility.
        Used to flip visibility and refresh dependent views."""
        # Iterate over self._elements() to apply the per-item logic.
        for element in self._elements():
            if element.get("id") == element_id:
                element["visible"] = not bool(element.get("visible", True))
                self._commit_history()
                self.render()
                return

    def toggle_lock(self, element_id: str) -> None:
        """Toggle lock.
        Used to flip lock and refresh dependent views."""
        # Iterate over self._elements() to apply the per-item logic.
        for element in self._elements():
            if element.get("id") == element_id:
                element["locked"] = not bool(element.get("locked", False))
                self._commit_history()
                self.render()
                return

    def rename_element(self, element_id: str, name: str) -> None:
        """Perform rename element.
        Used to keep the workflow logic localized and testable."""
        # Iterate over self._elements() to apply the per-item logic.
        for element in self._elements():
            if element.get("id") == element_id:
                if element.get("locked"):
                    return
                element["name"] = name
                self._commit_history()
                self.render()
                return

    def nudge_zorder(self, element_id: str, direction: int) -> None:
        """Perform nudge zorder.
        Used to keep the workflow logic localized and testable."""
        elements = self._elements()
        ordered = sorted(
            elements,
            key=lambda item: float(item.get("zorder", ANNOTATION_DEFAULT_ZORDER)),
        )
        index = next(
            (i for i, el in enumerate(ordered) if el.get("id") == element_id), None
        )
        if index is None:
            return
        target = index + direction
        if target < 0 or target >= len(ordered):
            return
        ordered[index]["zorder"], ordered[target]["zorder"] = (
            ordered[target].get("zorder", ANNOTATION_DEFAULT_ZORDER),
            ordered[index].get("zorder", ANNOTATION_DEFAULT_ZORDER),
        )
        self._commit_history()
        self.render()

    def update_element_properties(
        self,
        element_id: str,
        *,
        element_updates: Optional[Dict[str, Any]] = None,
        geometry_updates: Optional[Dict[str, Any]] = None,
        style_updates: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Update element properties.
        Used to keep element properties in sync with current state."""
        # Iterate over self._elements() to apply the per-item logic.
        for element in self._elements():
            if element.get("id") != element_id:
                continue
            if element.get("locked"):
                return
            if element_updates:
                element.update(element_updates)
            if geometry_updates:
                geometry = element.get("geometry")
                if not isinstance(geometry, dict):
                    geometry = {}
                    element["geometry"] = geometry
                geometry.update(geometry_updates)
            if style_updates:
                style = element.get("style")
                if not isinstance(style, dict):
                    style = {}
                    element["style"] = style
                style.update(style_updates)
            self._commit_history()
            self.render()
            return

    def restore_element_snapshot(
        self, element_id: str, snapshot: Dict[str, Any]
    ) -> None:
        """Perform restore element snapshot.
        Used to keep the workflow logic localized and testable."""
        if not snapshot:
            return
        elements = self._elements()
        # Iterate over indexed elements from elements to apply the per-item logic.
        for idx, element in enumerate(elements):
            if element.get("id") != element_id:
                continue
            if element.get("locked"):
                return
            restored = copy.deepcopy(snapshot)
            restored["id"] = element_id
            elements[idx] = restored
            self._commit_history()
            self.render()
            return


# Panel owns the UI controls for annotations; it delegates edits to the
# controller, which updates the figure and store for persistence.
class AnnotationsPanel:
    def __init__(
        self, parent: tk.Widget, controller: PlotAnnotationsController, plot_id: str
    ) -> None:
        """Initialize the Plot Elements/Annotations editor panel.

        Purpose:
            Build panel state, UI bindings, and editing variables for one plot.
        Why:
            The editor needs per-plot state for selected-element properties,
            pending manual edits, and add-element defaults.
        Inputs:
            parent: Tk parent widget hosting the panel frame.
            controller: PlotAnnotationsController that owns element mutations.
            plot_id: Plot identifier used for per-plot persistence keys.
        Outputs:
            None.
        Side Effects:
            Creates Tk variables/widgets and initializes editor tracking flags.
        Exceptions:
            None. Construction relies on existing controller/store guards.
        """
        self._controller = controller
        self._plot_id = plot_id
        self._store = controller._store
        self._frame = ttk.LabelFrame(parent, text="Annotations")
        self._content = ttk.Frame(self._frame)
        initial_mode = self._controller.get_mode()
        if initial_mode not in {"select", "erase"}:
            initial_mode = "select"
            self._controller.set_mode(initial_mode)
        self._mode_var = tk.StringVar(value=initial_mode)
        self._tree: Optional[ttk.Treeview] = None
        self._suppress_tree_events = False
        self._name_var = tk.StringVar(value="")
        add_defaults = self._load_add_defaults()
        self._add_type_var = tk.StringVar(value=add_defaults["add_type"])
        self._add_type_label_var = tk.StringVar(value="")
        self._add_axis_var = tk.StringVar(value=add_defaults["add_axis_target"])
        self._add_axis_label_var = tk.StringVar(value="")
        self._add_coord_var = tk.StringVar(value=add_defaults["add_coord_space"])
        self._add_coord_label_var = tk.StringVar(value="")
        self._add_trace_var = tk.StringVar(value=add_defaults["add_trace_key"])
        self._add_trace_label_var = tk.StringVar(value="")
        self._add_hint_var = tk.StringVar(value="")
        self._add_fill_var = tk.StringVar(value=add_defaults["add_fillcolor"])
        alpha_value = float(add_defaults["add_alpha"])
        self._add_alpha_var = tk.StringVar(value=f"{alpha_value:.2f}")
        self._add_alpha_scale_var = tk.DoubleVar(value=alpha_value)
        self._add_label_var = tk.StringVar(value=add_defaults["add_label_text"])
        self._add_keep_placing_var = tk.BooleanVar(value=False)
        self._add_status_var = tk.StringVar(value="")
        self._add_armed = False
        self._add_armed_guard = False
        self._add_place_button: Optional[ttk.Button] = None
        self._add_cancel_button: Optional[ttk.Button] = None
        self._add_label_entry: Optional[ttk.Entry] = None
        self._add_color_swatch: Optional[tk.Label] = None
        self._add_axis_combo: Optional[ttk.Combobox] = None
        self._add_trace_combo: Optional[ttk.Combobox] = None
        self._collapse_button: Optional[Any] = None
        self._apply_button: Optional[ttk.Button] = None
        self._apply_keep_button: Optional[ttk.Button] = None
        self._revert_button: Optional[ttk.Button] = None
        self._undo_button: Optional[ttk.Button] = None
        self._redo_button: Optional[ttk.Button] = None
        self._paned: Optional[ttk.Panedwindow] = None
        self._style_preset_var = tk.StringVar(value="None (Manual)")
        self._style_preset_key_map: Dict[str, str] = {}
        self._props_canvas: Optional[tk.Canvas] = None
        self._props_scrollbar: Optional[ttk.Scrollbar] = None
        self._props_inner: Optional[ttk.Frame] = None
        self._props_window_id: Optional[int] = None
        self._props_mousewheel_bound: Set[str] = set()
        self._live_update_var = tk.BooleanVar(
            value=bool(self._store.ui_state_for(plot_id).get("live_update", False))
        )
        self._live_update_after_id: Optional[str] = None
        self._suppress_live_update = False
        self._element_snapshots: Dict[str, Dict[str, Any]] = {}
        self._current_axis_map: Dict[str, str] = {}
        self._current_axis_var: Optional[tk.StringVar] = None
        self._current_zorder_var: Optional[tk.StringVar] = None
        self._current_trace_key_var: Optional[tk.StringVar] = None
        self._current_trace_key_map: Dict[str, str] = {}
        self._current_geom_vars: Dict[str, tk.Variable] = {}
        self._current_style_vars: Dict[str, tk.Variable] = {}
        self._pending_manual_changes = False
        self._zorder_pending_change = False
        self._zorder_initial_value: Optional[float] = None
        self._suppress_add_traces = False
        self._paned_restore_second_pass_scheduled = False
        self._collapsed = bool(self._store.ui_state_for(plot_id).get("collapsed", False))
        self._build_ui()
        self.set_collapsed(self._collapsed)

    @property
    def frame(self) -> ttk.LabelFrame:
        """Perform frame.
        Used to keep the workflow logic localized and testable."""
        return self._frame

    def _load_add_defaults(self) -> Dict[str, Any]:
        """Load add defaults.
        Used when restoring add defaults from storage."""
        state = self._store.ui_state_for(self._plot_id)
        add_defaults = state.get("add_defaults")
        if not isinstance(add_defaults, dict):
            add_defaults = {}
        merged = _default_add_defaults()
        merged.update(add_defaults)
        add_type = _canonicalize_annotation_type(merged.get("add_type", "")) or "xspan"
        fill_color = (
            merged.get("add_fillcolor") or _default_add_defaults()["add_fillcolor"]
        )
        if not isinstance(fill_color, str) or not fill_color.strip():
            fill_color = _default_add_defaults()["add_fillcolor"]
        alpha_value = _coerce_float(merged.get("add_alpha"))
        if alpha_value is None:
            alpha_value = float(_default_add_defaults()["add_alpha"])
        alpha_value = max(0.0, min(1.0, float(alpha_value)))
        label_text = merged.get("add_label_text")
        if not isinstance(label_text, str):
            label_text = _default_add_defaults()["add_label_text"]
        trace_key = _normalize_trace_series_key(
            merged.get("add_trace_key"),
            default=str(_default_add_defaults().get("add_trace_key", "y2")),
        )
        axis_target = _normalize_axes_target(merged.get("add_axis_target"))
        coord_space = str(merged.get("add_coord_space") or "data").strip().lower()
        if coord_space not in {"data", "axes"}:
            coord_space = "data"
        return {
            "add_type": add_type,
            "add_fillcolor": fill_color,
            "add_alpha": alpha_value,
            "add_label_text": label_text,
            "add_trace_key": trace_key,
            "add_axis_target": axis_target,
            "add_coord_space": coord_space,
        }

    def _persist_add_defaults(self, **updates: Any) -> None:
        """Perform persist add defaults.
        Used to keep the workflow logic localized and testable."""
        state = self._store.ui_state_for(self._plot_id)
        add_defaults = state.get("add_defaults")
        if not isinstance(add_defaults, dict):
            add_defaults = _default_add_defaults()
        add_defaults.update(updates)
        self._store.set_ui_state(self._plot_id, add_defaults=add_defaults)
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _normalize_color_value(self, value: Any, fallback: str = "#cccccc") -> str:
        """Normalize color value.
        Used to keep color value consistent across workflows and persistence."""
        if value is None:
            return fallback
        if isinstance(value, str):
            stripped = value.strip()
            if not stripped:
                return fallback
            lowered = stripped.lower()
            if lowered in {"none", "transparent"}:
                return _normalize_mpl_color(stripped)
        try:
            from matplotlib import colors as mcolors

            if not mcolors.is_color_like(value):
                return fallback
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        normalized = _normalize_mpl_color(value)
        return normalized or fallback

    def _add_status_idle_text(self) -> str:
        """Perform add status idle text.
        Used to keep the workflow logic localized and testable."""
        return "Status: Choose a type, then click 'Place on Plot'."

    def _add_status_armed_text(self, element_type: str) -> str:
        """Perform add status armed text.
        Used to keep the workflow logic localized and testable."""
        label = ANNOTATION_TYPE_LABELS.get(element_type, "Element")
        hint = self._add_hint_var.get().strip()
        if hint:
            return f"Placing: {label} - {hint} (Esc to cancel)"
        return f"Placing: {label} (Esc to cancel)"

    def set_add_placement_active(self, active: bool) -> None:
        """Set add placement active.
        Used to persist add placement active into the current state."""
        self._add_armed = bool(active)
        self._add_armed_guard = self._add_armed
        if self._add_place_button is not None:
            self._add_place_button.configure(
                state="disabled" if self._add_armed else "normal"
            )
        if self._add_cancel_button is not None:
            self._add_cancel_button.configure(
                state="normal" if self._add_armed else "disabled"
            )
        if self._add_status_var is not None:
            if self._add_armed:
                self._add_status_var.set(
                    self._add_status_armed_text(self._add_type_var.get())
                )
            else:
                self._add_status_var.set(self._add_status_idle_text())

    def _build_ui(self) -> None:
        """Build the Plot Elements editor layout and wire panel controls.

        Purpose:
            Create the split-pane annotations editor, including add controls,
            elements table, property editors, and apply/action button rows.
        Why:
            This panel is the primary workflow surface for adding, selecting, and
            editing per-plot annotation elements.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Creates Tk/CTk widgets, stores widget references, and registers
            callbacks for selection/edit/apply interactions.
        Exceptions:
            Widget-construction errors are handled by Tkinter at runtime.
        """
        self._frame.grid_columnconfigure(0, weight=1)
        self._frame.grid_rowconfigure(1, weight=1)

        header = ttk.Frame(self._frame)
        header.grid(row=0, column=0, sticky="ew")
        self._collapse_button = _ui_button(
            header, text="Collapse", command=self.toggle_collapsed
        )
        self._collapse_button.pack(
            side="right", padx=4, pady=2
        )

        self._content.grid(row=1, column=0, sticky="nsew")
        self._content.grid_columnconfigure(0, weight=1)
        self._content.grid_rowconfigure(0, weight=1)

        self._paned = ttk.Panedwindow(self._content, orient="horizontal")
        self._paned.grid(row=0, column=0, sticky="nsew")

        left_pane = ttk.Frame(self._paned)
        right_pane = ttk.Frame(self._paned)
        left_pane.grid_columnconfigure(0, weight=1)
        left_pane.grid_rowconfigure(1, weight=1)
        right_pane.grid_columnconfigure(0, weight=1)
        right_pane.grid_rowconfigure(0, weight=1)
        right_pane.grid_rowconfigure(1, weight=0)

        self._paned.add(left_pane, weight=3)
        self._paned.add(right_pane, weight=2)

        add_frame = ttk.LabelFrame(left_pane, text="Add Element")
        add_frame.grid(row=0, column=0, sticky="ew", padx=4, pady=(4, 2))
        add_frame.grid_columnconfigure(1, weight=1)
        add_frame.grid_columnconfigure(3, weight=1)

        add_type_options = [
            ("Text", "text"),
            ("Callout", "callout"),
            ("Arrow", "arrow"),
            ("Point / Marker", "point"),
            ("X-Span", "xspan"),
            ("Span + Label", "xspan_label"),
            ("Trace Mask", "trace_mask"),
            ("Trace Start", "trace_start"),
            ("Box Region", "rect"),
            ("Reference Line", "ref_line"),
            ("Freehand", "ink"),
        ]
        add_label_map = {label: value for label, value in add_type_options}
        add_value_map = {value: label for label, value in add_type_options}

        # Closure captures _build_ui local context to keep helper logic scoped and invoked directly within _build_ui.
        def _sync_add_type_label() -> None:
            """Perform sync add type label.
            Used to keep the workflow logic localized and testable."""
            self._add_type_label_var.set(
                add_value_map.get(self._add_type_var.get(), "Text")
            )

        # Closure captures _build_ui local context to keep helper logic scoped and invoked directly within _build_ui.
        def _placement_hint_for_type(element_type: str) -> str:
            """Perform placement hint for type.
            Used to keep the workflow logic localized and testable."""
            hints = {
                "point": "Click to place.",
                "text": "Click to place.",
                "arrow": "Click-drag start + end.",
                "callout": "Click-drag start + end (label attaches to end).",
                "rect": "Click-drag to draw.",
                "ref_line": "Click for vertical line. Shift + click for horizontal.",
                "xspan": "Drag across plot; release to create.",
                "xspan_label": "Drag across plot; release to create.",
                "trace_mask": "Drag across plot to hide one trace in-range.",
                "trace_start": "Click once to set where one trace starts.",
                "ink": "Click-drag freehand.",
            }
            return hints.get(element_type, "Click to place.")

        _sync_add_type_label()

        axis_choices = self._controller.get_axis_choices()
        if not axis_choices:
            axis_choices = [("Primary", "primary")]
        axis_label_map = {label: role for label, role in axis_choices}
        axis_value_map = {role: label for label, role in axis_choices}

        # Closure captures _build_ui local context to keep helper logic scoped and invoked directly within _build_ui.
        def _sync_add_axis_label() -> None:
            """Perform sync add axis label.
            Used to keep the workflow logic localized and testable."""
            label = axis_value_map.get(self._add_axis_var.get(), "")
            if not label:
                label = axis_choices[0][0]
                self._add_axis_var.set(axis_label_map.get(label, "primary"))
            self._add_axis_label_var.set(label)

        _sync_add_axis_label()
        coord_choices = [
            ("Data (moves with pan/zoom)", "data"),
            ("Axes (fixed relative position)", "axes"),
        ]
        coord_label_map = {label: value for label, value in coord_choices}
        coord_value_map = {value: label for label, value in coord_choices}

        # Closure captures _build_ui local context to keep helper logic scoped and invoked directly within _build_ui.
        def _sync_add_coord_label() -> None:
            """Perform sync add coord label.
            Used to keep the workflow logic localized and testable."""
            label = coord_value_map.get(self._add_coord_var.get(), "")
            if not label:
                label = coord_choices[0][0]
                self._add_coord_var.set(coord_label_map.get(label, "data"))
            self._add_coord_label_var.set(label)

        _sync_add_coord_label()
        trace_choices = _trace_series_option_pairs()
        trace_label_map = {label: key for label, key in trace_choices}
        trace_value_map = {key: label for label, key in trace_choices}

        # Closure captures _build_ui local context to keep helper logic scoped and invoked directly within _build_ui.
        def _sync_add_trace_label() -> None:
            """Perform sync add trace label.
            Used to keep the workflow logic localized and testable."""
            trace_key = _normalize_trace_series_key(self._add_trace_var.get(), default="y2")
            self._add_trace_var.set(trace_key)
            self._add_trace_label_var.set(
                trace_value_map.get(trace_key, trace_choices[2][0])
            )

        _sync_add_trace_label()
        self._add_hint_var.set(_placement_hint_for_type(self._add_type_var.get()))

        ttk.Label(add_frame, text="Element Type:").grid(
            row=0, column=0, sticky="w", padx=6, pady=2
        )
        add_type_combo = _ui_combobox(
            add_frame,
            values=[label for label, _ in add_type_options],
            textvariable=self._add_type_label_var,
            state="readonly",
            width=22,
        )
        add_type_combo.grid(row=0, column=1, sticky="w", padx=6, pady=2)

        ttk.Label(add_frame, text="Target Axis:").grid(
            row=0, column=2, sticky="w", padx=6, pady=2
        )
        self._add_axis_combo = _ui_combobox(
            add_frame,
            values=[label for label, _ in axis_choices],
            textvariable=self._add_axis_label_var,
            state="readonly",
            width=18,
        )
        self._add_axis_combo.grid(row=0, column=3, sticky="w", padx=6, pady=2)

        ttk.Label(add_frame, text="Coordinates:").grid(
            row=1, column=0, sticky="w", padx=6, pady=2
        )
        add_coord_combo = _ui_combobox(
            add_frame,
            values=[label for label, _ in coord_choices],
            textvariable=self._add_coord_label_var,
            state="readonly",
            width=28,
        )
        add_coord_combo.grid(row=1, column=1, columnspan=3, sticky="w", padx=6, pady=2)

        ttk.Label(add_frame, text="Target Trace:").grid(
            row=2, column=0, sticky="w", padx=6, pady=2
        )
        self._add_trace_combo = _ui_combobox(
            add_frame,
            values=[label for label, _ in trace_choices],
            textvariable=self._add_trace_label_var,
            state="readonly",
            width=28,
        )
        self._add_trace_combo.grid(
            row=2, column=1, columnspan=3, sticky="w", padx=6, pady=2
        )

        ttk.Label(add_frame, text="Color:").grid(
            row=3, column=0, sticky="w", padx=6, pady=2
        )
        add_color_frame = ttk.Frame(add_frame)
        add_color_frame.grid(row=3, column=1, columnspan=3, sticky="w", padx=6, pady=2)
        self._add_color_swatch = tk.Label(add_color_frame, width=2, relief="groove")
        self._add_color_swatch.grid(row=0, column=0, padx=(0, 4))

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _update_add_color_swatch() -> None:
            """Update add color swatch.
            Used to keep add color swatch in sync with current state."""
            color = self._normalize_color_value(self._add_fill_var.get())
            try:
                if self._add_color_swatch is not None:
                    self._add_color_swatch.configure(background=color)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Closure captures _build_ui local context to keep helper logic scoped and invoked directly within _build_ui.
        def _choose_add_fill_color() -> None:
            """Perform choose add fill color.
            Used to keep the workflow logic localized and testable."""
            initial = self._normalize_color_value(self._add_fill_var.get())
            result = colorchooser.askcolor(
                color=initial, parent=self._frame.winfo_toplevel()
            )
            if not result or not result[1]:
                return
            chosen = self._normalize_color_value(result[1])
            self._suppress_add_traces = True
            try:
                self._add_fill_var.set(chosen)
                _update_add_color_swatch()
            finally:
                self._suppress_add_traces = False
            self._persist_add_defaults(add_fillcolor=chosen)

        _ui_button(
            add_color_frame, text="Color...", command=_choose_add_fill_color
        ).grid(row=0, column=1, padx=(0, 4))
        _ui_entry(add_color_frame, textvariable=self._add_fill_var, width=12).grid(
            row=0, column=2, sticky="ew"
        )
        add_color_frame.grid_columnconfigure(2, weight=1)
        _update_add_color_swatch()

        ttk.Label(add_frame, text="Transparency:").grid(
            row=4, column=0, sticky="w", padx=6, pady=2
        )
        add_alpha_frame = ttk.Frame(add_frame)
        add_alpha_frame.grid(row=4, column=1, columnspan=3, sticky="ew", padx=6, pady=2)
        add_alpha_entry = _ui_entry(
            add_alpha_frame, textvariable=self._add_alpha_var, width=6
        )
        add_alpha_entry.grid(row=0, column=0, sticky="w", padx=(0, 6))

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _on_add_alpha_scale(value: Any) -> None:
            """Handle add alpha scale.
            Used as an event callback for add alpha scale."""
            if self._suppress_add_traces:
                return
            try:
                alpha_value = float(value)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return
            alpha_value = max(0.0, min(1.0, float(alpha_value)))
            self._suppress_add_traces = True
            try:
                self._add_alpha_var.set(f"{alpha_value:.2f}")
            finally:
                self._suppress_add_traces = False
            self._persist_add_defaults(add_alpha=alpha_value)

        add_alpha_scale = _ui_scale(
            add_alpha_frame,
            from_=0.0,
            to=1.0,
            variable=self._add_alpha_scale_var,
            command=_on_add_alpha_scale,
        )
        add_alpha_scale.grid(row=0, column=1, sticky="ew")
        add_alpha_frame.grid_columnconfigure(1, weight=1)

        ttk.Label(add_frame, text="Label/Text:").grid(
            row=5, column=0, sticky="w", padx=6, pady=2
        )
        self._add_label_entry = _ui_entry(
            add_frame, textvariable=self._add_label_var, width=24
        )
        self._add_label_entry.grid(
            row=5, column=1, columnspan=3, sticky="ew", padx=6, pady=2
        )

        action_frame = ttk.Frame(add_frame)
        action_frame.grid(
            row=6, column=0, columnspan=4, sticky="ew", padx=6, pady=(4, 2)
        )
        self._add_place_button = _ui_button(
            action_frame, text="Place on Plot", command=self._on_place_add_element
        )
        self._add_place_button.pack(side="left", padx=(0, 6))
        self._add_cancel_button = _ui_button(
            action_frame, text="Cancel Placement", command=self._on_cancel_add_element
        )
        self._add_cancel_button.pack(side="left", padx=(0, 6))
        _ui_checkbutton(
            action_frame, text="Keep placing", variable=self._add_keep_placing_var
        ).pack(side="left")

        hint_label = ttk.Label(
            add_frame,
            textvariable=self._add_hint_var,
            wraplength=600,
            justify="left",
        )
        hint_label.grid(row=7, column=0, columnspan=4, sticky="w", padx=6, pady=(0, 2))

        status_label = ttk.Label(
            add_frame,
            textvariable=self._add_status_var,
            wraplength=600,
            justify="left",
        )
        status_label.grid(
            row=8, column=0, columnspan=4, sticky="w", padx=6, pady=(0, 6)
        )

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _update_add_label_state() -> None:
            """Update add label state.
            Used to keep add label state in sync with current state."""
            if self._add_label_entry is None:
                return
            label_types = {"text", "callout", "xspan_label", "rect", "ref_line"}
            is_label = self._add_type_var.get() in label_types
            self._add_label_entry.configure(state="normal" if is_label else "disabled")

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _update_add_trace_state() -> None:
            """Update add trace state.
            Used to keep add trace state in sync with current state."""
            if self._add_trace_combo is None:
                return
            trace_types = {"trace_mask", "trace_start"}
            enabled = self._add_type_var.get() in trace_types
            self._add_trace_combo.configure(state="readonly" if enabled else "disabled")

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _on_add_type_selected(_event: Any = None) -> None:
            """Handle add type selected.
            Used as an event callback for add type selected."""
            new_type = add_label_map.get(self._add_type_label_var.get(), "text")
            if new_type != self._add_type_var.get():
                self._add_type_var.set(new_type)
                self._persist_add_defaults(add_type=new_type)
            self._add_hint_var.set(_placement_hint_for_type(new_type))
            _update_add_label_state()
            _update_add_trace_state()
            if self._add_armed:
                self._on_cancel_add_element()

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _on_add_axis_selected(_event: Any = None) -> None:
            """Handle add axis selected.
            Used as an event callback for add axis selected."""
            new_axis = axis_label_map.get(self._add_axis_label_var.get(), "primary")
            self._add_axis_var.set(new_axis)
            self._persist_add_defaults(add_axis_target=new_axis)
            if self._add_armed:
                self._on_cancel_add_element()

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _on_add_coord_selected(_event: Any = None) -> None:
            """Handle add coord selected.
            Used as an event callback for add coord selected."""
            new_coord = coord_label_map.get(self._add_coord_label_var.get(), "data")
            self._add_coord_var.set(new_coord)
            self._persist_add_defaults(add_coord_space=new_coord)
            if self._add_armed:
                self._on_cancel_add_element()

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _on_add_trace_selected(_event: Any = None) -> None:
            """Handle add trace selected.
            Used as an event callback for add trace selected."""
            new_trace = trace_label_map.get(self._add_trace_label_var.get(), "y2")
            normalized = _normalize_trace_series_key(new_trace, default="y2")
            self._add_trace_var.set(normalized)
            self._persist_add_defaults(add_trace_key=normalized)
            if self._add_armed:
                self._on_cancel_add_element()

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _on_add_fill_change(*_args: Any) -> None:
            """Handle add fill change.
            Used as an event callback for add fill change."""
            if self._suppress_add_traces:
                return
            normalized = self._normalize_color_value(self._add_fill_var.get())
            if normalized != self._add_fill_var.get():
                self._suppress_add_traces = True
                try:
                    self._add_fill_var.set(normalized)
                finally:
                    self._suppress_add_traces = False
            _update_add_color_swatch()
            self._persist_add_defaults(add_fillcolor=normalized)

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _commit_add_alpha_entry(_event: Any = None) -> None:
            """Perform commit add alpha entry.
            Used to keep the workflow logic localized and testable."""
            if self._suppress_add_traces:
                return
            try:
                alpha_value = float(self._add_alpha_var.get())
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return
            alpha_value = max(0.0, min(1.0, float(alpha_value)))
            self._suppress_add_traces = True
            try:
                self._add_alpha_var.set(f"{alpha_value:.2f}")
                self._add_alpha_scale_var.set(alpha_value)
            finally:
                self._suppress_add_traces = False
            self._persist_add_defaults(add_alpha=alpha_value)

        # Closure captures _build_ui state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_ui.
        def _on_add_label_change(*_args: Any) -> None:
            """Handle add label change.
            Used as an event callback for add label change."""
            if self._suppress_add_traces:
                return
            self._persist_add_defaults(add_label_text=self._add_label_var.get())

        add_type_combo.bind("<<ComboboxSelected>>", _on_add_type_selected)
        if self._add_axis_combo is not None:
            self._add_axis_combo.bind("<<ComboboxSelected>>", _on_add_axis_selected)
        add_coord_combo.bind("<<ComboboxSelected>>", _on_add_coord_selected)
        if self._add_trace_combo is not None:
            self._add_trace_combo.bind("<<ComboboxSelected>>", _on_add_trace_selected)
        self._add_fill_var.trace_add("write", _on_add_fill_change)
        self._add_label_var.trace_add("write", _on_add_label_change)
        add_alpha_entry.bind("<Return>", _commit_add_alpha_entry)
        add_alpha_entry.bind("<FocusOut>", _commit_add_alpha_entry)
        _update_add_label_state()
        _update_add_trace_state()
        self.set_add_placement_active(False)

        list_frame = ttk.LabelFrame(left_pane, text="Elements")
        list_frame.grid(row=1, column=0, sticky="nsew", padx=4, pady=(2, 2))
        list_frame.grid_columnconfigure(0, weight=1)
        list_frame.grid_rowconfigure(1, weight=1)

        mode_bar = ttk.Frame(list_frame)
        mode_bar.grid(row=0, column=0, sticky="ew", padx=4, pady=(4, 2))
        ttk.Label(mode_bar, text="Interaction:").pack(side="left")
        _ui_radiobutton(
            mode_bar,
            text="Select / Edit",
            value="select",
            variable=self._mode_var,
            command=self._on_mode_changed,
        ).pack(side="left", padx=(6, 2))
        _ui_radiobutton(
            mode_bar,
            text="Erase Ink",
            value="erase",
            variable=self._mode_var,
            command=self._on_mode_changed,
        ).pack(side="left", padx=2)

        tree = ttk.Treeview(
            list_frame,
            columns=("visible", "locked", "type", "name"),
            show="headings",
            height=8,
            selectmode="browse",
        )
        tree.heading("visible", text="Vis")
        tree.heading("locked", text="Lock")
        tree.heading("type", text="Type")
        tree.heading("name", text="Name")
        tree.column("visible", width=40, anchor="center")
        tree.column("locked", width=50, anchor="center")
        tree.column("type", width=90, anchor="w")
        tree.column("name", width=220, anchor="w")
        tree.bind("<<TreeviewSelect>>", self._on_tree_select)
        tree.bind("<Button-1>", self._on_tree_click, add="+")
        scrollbar = _ui_scrollbar(list_frame, orient="vertical", command=tree.yview)
        tree.configure(yscrollcommand=scrollbar.set)
        tree.grid(row=1, column=0, sticky="nsew", padx=(4, 0))
        scrollbar.grid(row=1, column=1, sticky="ns")
        self._tree = tree

        list_controls = ttk.Frame(list_frame)
        list_controls.grid(row=2, column=0, sticky="ew", padx=4, pady=(2, 4))
        list_controls.grid_columnconfigure(0, weight=1)
        name_row = ttk.Frame(list_controls)
        name_row.grid(row=0, column=0, sticky="ew")
        action_row = ttk.Frame(list_controls)
        action_row.grid(row=1, column=0, sticky="w", pady=(2, 0))
        ttk.Label(name_row, text="Name:").pack(side="left")
        name_entry = _ui_entry(name_row, textvariable=self._name_var, width=24)
        name_entry.pack(side="left", padx=(2, 6), pady=4)
        name_entry.bind("<Return>", self._apply_name)
        name_entry.bind("<FocusOut>", self._apply_name)
        _ui_button(
            name_row, text="Send Backward", command=lambda: self._nudge_zorder(-1)
        ).pack(side="left", padx=4, pady=4)
        _ui_button(
            name_row, text="Bring Forward", command=lambda: self._nudge_zorder(1)
        ).pack(side="left", padx=4, pady=4)
        _ui_button(
            action_row, text="Duplicate", command=self._duplicate_selected
        ).pack(side="left", padx=4, pady=4)
        _ui_button(action_row, text="Delete", command=self._delete_selected).pack(
            side="left", padx=4, pady=4
        )
        _ui_button(
            action_row, text="Lock/Unlock", command=self._toggle_lock_selected
        ).pack(side="left", padx=4, pady=4)

        style_controls = ttk.Frame(list_frame)
        style_controls.grid(row=3, column=0, sticky="ew", padx=4, pady=(0, 4))
        _ui_button(
            style_controls, text="Copy Style", command=self._copy_style
        ).pack(side="left", padx=4, pady=2)
        _ui_button(
            style_controls, text="Paste Style", command=self._paste_style
        ).pack(side="left", padx=4, pady=2)
        ttk.Label(style_controls, text="Preset:").pack(side="left", padx=(12, 2))
        preset_labels = ["None (Manual)"]
        self._style_preset_key_map.clear()
        # Iterate over keys from ANNOTATION_STYLE_PRESETS to apply the per-item logic.
        for key in ANNOTATION_STYLE_PRESETS.keys():
            display = key.replace("_", " ").title()
            self._style_preset_key_map[display] = key
            preset_labels.append(display)
        if self._style_preset_var.get() not in preset_labels:
            self._style_preset_var.set("None (Manual)")
        preset_combo = _ui_combobox(
            style_controls,
            values=preset_labels,
            textvariable=self._style_preset_var,
            state="readonly",
            width=16,
        )
        preset_combo.pack(side="left", padx=2, pady=2)
        _ui_button(
            style_controls, text="Apply Preset", command=self._apply_style_preset
        ).pack(side="left", padx=4, pady=2)

        props_frame = ttk.LabelFrame(right_pane, text="Properties")
        props_frame.grid(row=0, column=0, sticky="nsew", padx=4, pady=(4, 2))
        props_frame.grid_rowconfigure(0, weight=1)
        props_frame.grid_columnconfigure(0, weight=1)

        # Canvas + inner frame keeps Properties scrollable when fields exceed the view.
        self._props_canvas = tk.Canvas(props_frame, highlightthickness=0)
        self._props_canvas.grid(row=0, column=0, sticky="nsew")
        self._props_scrollbar = _ui_scrollbar(
            props_frame, orient="vertical", command=self._props_canvas.yview
        )
        self._props_scrollbar.grid(row=0, column=1, sticky="ns")
        self._props_canvas.configure(yscrollcommand=self._props_scrollbar.set)

        self._props_inner = ttk.Frame(self._props_canvas)
        self._props_window_id = self._props_canvas.create_window(
            (0, 0), window=self._props_inner, anchor="nw"
        )

        # Keep scrollregion and inner-frame width synced as the properties rebuild.
        def _refresh_props_scrollregion(_event: Any = None) -> None:
            """Refresh props scrollregion.
            Used to sync props scrollregion with current settings."""
            if self._props_canvas is None:
                return
            self._props_canvas.configure(scrollregion=self._props_canvas.bbox("all"))

        self._props_inner.bind("<Configure>", _refresh_props_scrollregion)

        # Closure captures _build_ui local context to keep helper logic scoped and invoked directly within _build_ui.
        def _expand_props_width(event: Any) -> None:
            """Perform expand props width.
            Used to keep the workflow logic localized and testable."""
            if self._props_canvas is None or self._props_window_id is None:
                return
            self._props_canvas.itemconfigure(self._props_window_id, width=event.width)

        self._props_canvas.bind("<Configure>", _expand_props_width)

        self._props_container = self._props_inner
        self._props_container.grid_columnconfigure(0, weight=0)
        self._props_container.grid_columnconfigure(1, weight=1)
        self._frame.after_idle(self._bind_props_mousewheel)
        self._frame.after_idle(self._restore_paned_sash)
        if not self._paned_restore_second_pass_scheduled:
            self._paned_restore_second_pass_scheduled = True

            # Closure captures _build_ui local context to keep helper logic scoped and invoked directly within _build_ui.
            def _restore_paned_sash_second_pass() -> None:
                """Run one deferred sash restore after layout settles.
                Used to reapply left-biased split once widget requested sizes stabilize."""
                self._restore_paned_sash()

            try:
                self._frame.after(120, _restore_paned_sash_second_pass)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        apply_frame = ttk.Frame(right_pane)
        apply_frame.grid(row=1, column=0, sticky="ew", padx=4, pady=(0, 4))
        self._apply_button = _ui_button(
            apply_frame, text="Apply", command=self._apply_properties
        )
        self._apply_button.pack(side="left", padx=4, pady=4)
        self._apply_keep_button = _ui_button(
            apply_frame,
            text="Apply + Keep Editing",
            command=lambda: self._apply_properties(keep_editing=True),
        )
        self._apply_keep_button.pack(side="left", padx=4, pady=4)
        self._revert_button = _ui_button(
            apply_frame, text="Revert", command=self._revert_properties
        )
        self._revert_button.pack(side="left", padx=4, pady=4)
        self._undo_button = _ui_button(
            apply_frame, text="Undo", command=self._controller.undo
        )
        self._undo_button.pack(side="left", padx=4, pady=4)
        self._redo_button = _ui_button(
            apply_frame, text="Redo", command=self._controller.redo
        )
        self._redo_button.pack(side="left", padx=4, pady=4)
        _ui_checkbutton(
            apply_frame,
            text="Live Update",
            variable=self._live_update_var,
            command=self._on_toggle_live_update,
        ).pack(side="right", padx=4, pady=4)

    def _bind_props_mousewheel(self) -> None:
        """Perform bind props mousewheel.
        Used to keep the workflow logic localized and testable."""
        canvas = self._props_canvas
        inner = self._props_inner
        if canvas is None or inner is None:
            return

        # Closure captures _bind_props_mousewheel local context to keep helper logic scoped and invoked directly within _bind_props_mousewheel.
        def _bind(widget: tk.Widget) -> None:
            """Perform bind.
            Used to keep the workflow logic localized and testable."""
            widget_id = str(widget)
            if widget_id not in self._props_mousewheel_bound:
                self._props_mousewheel_bound.add(widget_id)

                # Closure captures _bind state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _bind.
                def _on_mousewheel(event: Any) -> Optional[str]:
                    """Handle mousewheel.
                    Used as an event callback for mousewheel."""
                    delta = event.delta
                    if delta == 0:
                        return None
                    step = -1 if delta > 0 else 1
                    if abs(delta) >= 120:
                        step = int(-delta / 120)
                    canvas.yview_scroll(step, "units")
                    return "break"

                widget.bind("<MouseWheel>", _on_mousewheel, add="+")
                widget.bind(
                    "<Button-4>",
                    lambda _event: canvas.yview_scroll(-1, "units"),
                    add="+",
                )
                widget.bind(
                    "<Button-5>",
                    lambda _event: canvas.yview_scroll(1, "units"),
                    add="+",
                )
            # Iterate over widget.winfo_children() to apply the per-item logic.
            for child in widget.winfo_children():
                _bind(child)

        _bind(canvas)
        _bind(inner)

    def _restore_paned_sash(self) -> None:
        """Restore a safe split position for the Plot Elements paned editor.

        Purpose:
            Reapply the previously saved sash position while guaranteeing both panes
            remain visible.
        Why:
            Legacy or invalid persisted sash values (for example `0`) can hide the
            left pane and make element selection unavailable.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Updates paned split position and may persist a repaired sash value.
        Exceptions:
            Paned geometry and persistence operations are best-effort guarded.
        """
        if self._paned is None:
            return
        state = self._store.ui_state_for(self._plot_id)
        try:
            self._paned.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        total_width = int(self._paned.winfo_width() or 0)
        if total_width <= 0:
            try:
                total_width = int(self._content.winfo_width() or 0)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                total_width = 0
        if total_width <= 0:
            return

        # Use requested pane widths to keep the left controls visible at current scale.
        pane_names: Tuple[str, ...] = ()
        try:
            pane_names = tuple(self._paned.panes())
        except Exception:
            pane_names = ()
        left_req = 360
        if len(pane_names) >= 1:
            try:
                left_widget = self._paned.nametowidget(pane_names[0])
                left_req = max(left_req, int(left_widget.winfo_reqwidth() or 0) + 28)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        right_min_floor = max(260, int(total_width * 0.20))
        right_max_preferred = max(right_min_floor, int(total_width * 0.36))
        left_min_content = max(360, left_req)
        min_left = max(left_min_content, total_width - right_max_preferred)
        max_left = max(min_left, total_width - right_min_floor)
        fallback = max(min_left, min(max_left, int(total_width * 0.66)))

        raw_sash = state.get("editor_sash")
        if isinstance(raw_sash, bool) or not isinstance(raw_sash, (int, float)):
            raw_sash = None
        if isinstance(raw_sash, (int, float)) and raw_sash <= 0:
            raw_sash = None

        repaired = False
        target_sash = fallback if raw_sash is None else int(round(float(raw_sash)))
        if target_sash < min_left or target_sash > max_left:
            target_sash = max(min_left, min(max_left, target_sash))
            repaired = True
        if raw_sash is None:
            repaired = True

        try:
            self._paned.sashpos(0, int(target_sash))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return

        if repaired:
            self._store.set_ui_state(self._plot_id, editor_sash=int(target_sash))
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def get_sash_pos(self) -> Optional[int]:
        """Return sash pos.
        Used to retrieve sash pos for downstream logic."""
        if self._paned is None:
            return None
        try:
            return int(self._paned.sashpos(0))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None

    def _refresh_props_scroll(self) -> None:
        """Refresh props scroll.
        Used to sync props scroll with current settings."""
        if self._props_canvas is None:
            return
        try:
            self._props_canvas.update_idletasks()
            self._props_canvas.configure(scrollregion=self._props_canvas.bbox("all"))
            self._props_canvas.yview_moveto(0.0)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        # Mousewheel bindings are refreshed to cover rebuilt property widgets.
        self._frame.after_idle(self._bind_props_mousewheel)

    def toggle_collapsed(self) -> None:
        """Toggle collapsed.
        Used to flip collapsed and refresh dependent views."""
        self.set_collapsed(not self._collapsed)

    def set_collapsed(self, collapsed: bool) -> None:
        """Show or hide the panel body and persist the collapsed state.

        Purpose:
            Apply collapsed/expanded visibility for the Plot Elements content area.
        Why:
            The dialog needs a compact mode while still making current state obvious.
        Args:
            collapsed: True to hide the panel content, False to show it.
        Returns:
            None.
        Side Effects:
            Toggles content visibility, updates header button label, and persists UI
            state for the current plot.
        Exceptions:
            None.
        """
        self._collapsed = bool(collapsed)
        if self._collapsed:
            self._content.grid_remove()
        else:
            self._content.grid()
        if self._collapse_button is not None:
            try:
                self._collapse_button.configure(
                    text="Expand" if self._collapsed else "Collapse"
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._store.set_ui_state(self._plot_id, collapsed=self._collapsed)

    def refresh(self) -> None:
        """Refresh value.
        Used to sync value with current settings."""
        self._refresh_add_axis_choices()
        self._refresh_tree()
        self._refresh_properties()

    def apply_selected(self) -> None:
        """Apply selected.
        Used to apply selected changes to live state."""
        self._apply_properties()

    def duplicate_selected(self) -> None:
        """Perform duplicate selected.
        Used to keep the workflow logic localized and testable."""
        self._duplicate_selected()

    def delete_selected(self) -> None:
        """Perform delete selected.
        Used to keep the workflow logic localized and testable."""
        self._delete_selected()

    def _refresh_add_axis_choices(self) -> None:
        """Refresh add axis choices.
        Used to sync add axis choices with current settings."""
        combo = self._add_axis_combo
        if combo is None:
            return
        axis_choices = self._controller.get_axis_choices()
        if not axis_choices:
            axis_choices = [("Primary", "primary")]
        values = [label for label, _ in axis_choices]
        try:
            combo.configure(values=values)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        axis_value_map = {role: label for label, role in axis_choices}
        current_role = _normalize_axes_target(self._add_axis_var.get())
        if current_role not in axis_value_map:
            current_role = axis_choices[0][1]
            self._add_axis_var.set(current_role)
        self._add_axis_label_var.set(axis_value_map.get(current_role, values[0]))

    def _on_mode_changed(self) -> None:
        """Handle mode changed.
        Used as an event callback for mode changed."""
        if self._add_armed_guard:
            return
        if self._add_armed:
            self._on_cancel_add_element()
        self._controller.set_mode(self._mode_var.get())

    def _resolve_selected_add_type(self) -> Optional[str]:
        """Resolve add-element type from visible selector and synchronize state.

        Purpose:
            Derive one canonical add-element type from the UI selection widgets.
        Why:
            The visible combobox label and the internal value can drift out of sync
            when a toolkit callback path does not fire; placement must follow the
            visible user selection deterministically.
        Args:
            None.
        Returns:
            Canonical element type string, or None when no valid type can be resolved.
        Side Effects:
            May update `_add_type_var` so internal placement state matches what the
            user sees in the Element Type dropdown.
        Exceptions:
            None; invalid values are normalized to safe fallbacks.
        """
        label_to_value = {
            "Text": "text",
            "Callout": "callout",
            "Arrow": "arrow",
            "Point / Marker": "point",
            "X-Span": "xspan",
            "Span + Label": "xspan_label",
            "Trace Mask": "trace_mask",
            "Trace Start": "trace_start",
            "Box Region": "rect",
            "Reference Line": "ref_line",
            "Freehand": "ink",
        }
        visible_label = str(self._add_type_label_var.get() or "").strip()
        candidate = label_to_value.get(visible_label, self._add_type_var.get())
        canonical = _canonicalize_annotation_type(candidate)
        if canonical is None:
            canonical = _canonicalize_annotation_type(self._add_type_var.get())
        if canonical is not None and canonical != self._add_type_var.get():
            self._add_type_var.set(canonical)
        return canonical

    def _on_place_add_element(self) -> None:
        """Handle place add element.
        Used as an event callback for place add element."""
        canonical = self._resolve_selected_add_type()
        if not canonical:
            return
        fill_color = _normalize_mpl_color(self._add_fill_var.get())
        alpha_value = _coerce_float(self._add_alpha_var.get())
        if alpha_value is None:
            alpha_value = 0.9
        alpha_value = max(0.0, min(1.0, float(alpha_value)))
        label_text = self._add_label_var.get().strip()
        axis_target = _normalize_axes_target(self._add_axis_var.get())
        coord_space = str(self._add_coord_var.get() or "data").strip().lower()
        if coord_space not in {"data", "axes"}:
            coord_space = "data"
        trace_key = _normalize_trace_series_key(self._add_trace_var.get(), default="y2")
        self._persist_add_defaults(
            add_type=canonical,
            add_fillcolor=fill_color,
            add_alpha=alpha_value,
            add_label_text=label_text,
            add_trace_key=trace_key,
            add_axis_target=axis_target,
            add_coord_space=coord_space,
        )
        style_overrides = {"alpha": alpha_value}
        if canonical in {"xspan", "xspan_label", "rect"}:
            style_overrides["facecolor"] = fill_color
            style_overrides["edgecolor"] = fill_color
        else:
            style_overrides["color"] = fill_color
            if canonical == "point":
                style_overrides["marker_facecolor"] = fill_color
                style_overrides["marker_edgecolor"] = fill_color
        if self._add_keep_placing_var.get():
            style_overrides["_keep_placing"] = True
        geometry_seed: Dict[str, Any] = {}
        if (
            canonical in {"text", "callout", "xspan_label", "rect", "ref_line"}
            and label_text
        ):
            geometry_seed["text"] = label_text
        if canonical == "xspan_label":
            geometry_seed.setdefault("text", label_text or "Label")
            geometry_seed["label_y_axes"] = 0.95
            geometry_seed["label_anchor"] = "center"
        if canonical in {"trace_mask", "trace_start"}:
            geometry_seed["trace_key"] = trace_key
        self._controller.set_mode(canonical)
        self._controller.begin_place_element(
            canonical,
            style_overrides,
            geometry_seed,
            axis_target=axis_target,
            coord_space=coord_space,
        )
        self.set_add_placement_active(True)

    def _on_cancel_add_element(self) -> None:
        """Handle cancel add element.
        Used as an event callback for cancel add element."""
        self._controller.cancel_place_element()
        self.set_add_placement_active(False)

    def _refresh_tree(self) -> None:
        """Refresh tree.
        Used to sync tree with current settings."""
        if self._tree is None:
            return
        # Suppress Treeview events to avoid the selection -> refresh recursion loop.
        self._suppress_tree_events = True
        try:
            self._tree.delete(*self._tree.get_children())
            elements = sorted(
                self._controller._elements(),
                key=lambda item: float(item.get("zorder", ANNOTATION_DEFAULT_ZORDER)),
                reverse=True,
            )
            selected_id = self._controller._selected_id
            # Iterate over elements to apply the per-item logic.
            for element in elements:
                element_id = element.get("id")
                if not element_id:
                    continue
                element_id = str(element_id)
                visible = "Yes" if element.get("visible", True) else "No"
                locked = "Yes" if element.get("locked", False) else "No"
                element_type = str(element.get("type") or "").strip().lower()
                type_label = ANNOTATION_TYPE_LABELS.get(
                    element_type, element_type or "Element"
                )
                name = str(element.get("name", "") or "").strip()
                preview = ""
                geometry = (
                    element.get("geometry")
                    if isinstance(element.get("geometry"), dict)
                    else {}
                )
                if isinstance(geometry, dict):
                    preview = str(geometry.get("text", "") or "").strip()
                if preview:
                    preview = " ".join(preview.split())
                    if len(preview) > 40:
                        preview = f"{preview[:37].rstrip()}..."
                if preview:
                    display_name = (
                        f"{name} - {preview}" if name and preview != name else preview
                    )
                else:
                    display_name = name
                self._tree.insert(
                    "",
                    "end",
                    iid=element_id,
                    values=(visible, locked, type_label, display_name),
                )
                if element_id == selected_id:
                    self._tree.selection_set(element_id)
        finally:
            self._suppress_tree_events = False
        selected = self._controller.selected_element()
        self._name_var.set(selected.get("name", "") if selected else "")

    def _on_tree_select(self, _event: Any) -> None:
        """Handle tree select.
        Used as an event callback for tree select."""
        if self._suppress_tree_events or self._tree is None:
            return
        selection = self._tree.selection()
        element_id = selection[0] if selection else None
        self._controller.set_selected_id(element_id, refresh_panel=False)
        selected = self._controller.selected_element()
        self._name_var.set(selected.get("name", "") if selected else "")
        self._refresh_properties()

    def _on_tree_click(self, event: Any) -> None:
        """Handle tree click.
        Used as an event callback for tree click."""
        if self._tree is None:
            return
        region = self._tree.identify("region", event.x, event.y)
        if region != "cell":
            return
        item = self._tree.identify_row(event.y)
        column = self._tree.identify_column(event.x)
        if not item:
            return
        self._tree.selection_set(item)
        self._tree.focus(item)
        element_id = str(item)
        if column == "#1":
            self._controller.toggle_visibility(element_id)
            return
        if column == "#2":
            self._controller.toggle_lock(element_id)
            return

    def _apply_name(self, _event: Any = None) -> None:
        """Apply name.
        Used to apply name changes to live state."""
        element = self._controller.selected_element()
        if element is None:
            return
        name = self._name_var.get().strip()
        if not name:
            return
        self._controller.rename_element(element.get("id"), name)

    def _nudge_zorder(self, direction: int) -> None:
        """Perform nudge zorder.
        Used to keep the workflow logic localized and testable."""
        element = self._controller.selected_element()
        if element is None:
            return
        self._controller.nudge_zorder(element.get("id"), direction)

    def _duplicate_selected(self) -> None:
        """Perform duplicate selected.
        Used to keep the workflow logic localized and testable."""
        self._controller.duplicate_selected()

    def _delete_selected(self) -> None:
        """Perform delete selected.
        Used to keep the workflow logic localized and testable."""
        if self._tree is None:
            return
        if not self._tree.selection():
            return
        self._controller.delete_selected()
        try:
            self._tree.selection_remove(self._tree.selection())
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self.refresh()

    def _toggle_lock_selected(self) -> None:
        """Toggle lock selected.
        Used to flip lock selected and refresh dependent views."""
        element = self._controller.selected_element()
        if element is None:
            return
        self._controller.toggle_lock(element.get("id"))
        self.refresh()

    def _toggle_visibility_selected(self) -> None:
        """Toggle visibility selected.
        Used to flip visibility selected and refresh dependent views."""
        element = self._controller.selected_element()
        if element is None:
            return
        self._controller.toggle_visibility(element.get("id"))
        self.refresh()

    def _copy_style(self) -> None:
        """Perform copy style.
        Used to keep the workflow logic localized and testable."""
        self._controller.copy_style()

    def _paste_style(self) -> None:
        """Perform paste style.
        Used to keep the workflow logic localized and testable."""
        self._controller.paste_style()
        self.refresh()

    def _apply_style_preset(self) -> None:
        """Apply style preset.
        Used to apply style preset changes to live state."""
        preset_label = self._style_preset_var.get().strip()
        if not preset_label or preset_label == "None (Manual)":
            return
        preset_key = self._style_preset_key_map.get(preset_label)
        if preset_key is None:
            preset_key = preset_label.strip().lower().replace(" ", "_")
        self._controller.apply_style_preset(preset_key)
        self.refresh()

    def _refresh_properties(self) -> None:
        """Rebuild the selected-element properties form from current state.

        Purpose:
            Regenerate editor controls for the active plot element selection.
        Why:
            Selection changes and applied edits must refresh field values and
            baseline tracking so Apply/Revert state is deterministic.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Recreates property widgets, traces variable changes, and resets
            pending-edit tracking/baselines for manual Apply behavior.
        Exceptions:
            Widget creation and state writes are guarded in downstream calls.
        """
        # Iterate over self._props_container.winfo_children() to apply the per-item logic.
        for child in self._props_container.winfo_children():
            child.destroy()
        self._current_axis_map = {}
        self._current_axis_var = None
        self._current_zorder_var = None
        self._current_trace_key_var = None
        self._current_trace_key_map = {}
        self._current_geom_vars = {}
        self._current_style_vars = {}
        self._suppress_live_update = True
        element = self._controller.selected_element()
        if element is None:
            ttk.Label(self._props_container, text="Select an element to edit.").pack(
                anchor="w", padx=6, pady=6
            )
            self._reset_manual_apply_tracking(None)
            self._set_apply_controls_state(False)
            self._suppress_live_update = False
            self._refresh_props_scroll()
            return
        element_id = str(element.get("id") or "")
        if element_id:
            self._element_snapshots[element_id] = copy.deepcopy(element)
        locked = bool(element.get("locked", False))
        element_type = str(element.get("type") or "").strip().lower()
        coord_space = str(element.get("coord_space") or "data").strip().lower()
        row = 0
        type_label = ANNOTATION_TYPE_LABELS.get(element_type, element_type or "Element")
        ttk.Label(self._props_container, text=f"Type: {type_label}").grid(
            row=row, column=0, sticky="w", padx=6, pady=(6, 2), columnspan=2
        )
        row += 1
        if locked:
            ttk.Label(
                self._props_container, text="Locked element - editing disabled."
            ).grid(row=row, column=0, sticky="w", padx=6, pady=(0, 4), columnspan=2)
            row += 1

        behavior_frame = ttk.LabelFrame(self._props_container, text="Behavior")
        behavior_frame.grid(row=row, column=0, columnspan=2, sticky="ew", padx=6, pady=4)
        behavior_frame.grid_columnconfigure(1, weight=1)
        row += 1

        axis_choices = self._controller.get_axis_choices()
        if not axis_choices:
            axis_choices = [("Primary", "primary")]
        axis_label_var = tk.StringVar()
        axis_map = {label: role for label, role in axis_choices}
        current_role = element.get("axes_target", "primary")
        current_label = next(
            (label for label, role in axis_choices if role == current_role),
            current_role,
        )
        axis_label_var.set(current_label)
        self._current_axis_map = axis_map
        self._current_axis_var = axis_label_var
        ttk.Label(behavior_frame, text="Axis Target:").grid(
            row=0, column=0, sticky="w", padx=6, pady=2
        )
        _ui_combobox(
            behavior_frame,
            values=[label for label, _ in axis_choices],
            textvariable=axis_label_var,
            state="readonly",
            width=22,
        ).grid(row=0, column=1, sticky="w", padx=6, pady=2)

        ttk.Label(behavior_frame, text="Coordinate Mode:").grid(
            row=1, column=0, sticky="w", padx=6, pady=2
        )
        coord_label = "Axes" if coord_space == "axes" else "Data"
        ttk.Label(behavior_frame, text=coord_label).grid(
            row=1, column=1, sticky="w", padx=6, pady=2
        )
        behavior_row = 2
        if element_type in {"trace_mask", "trace_start"}:
            trace_choices = _trace_series_option_pairs()
            trace_label_map = {label: key for label, key in trace_choices}
            trace_value_map = {key: label for label, key in trace_choices}
            geometry = (
                element.get("geometry")
                if isinstance(element.get("geometry"), dict)
                else {}
            )
            current_trace_key = _normalize_trace_series_key(
                geometry.get("trace_key"), default="y2"
            )
            trace_key_var = tk.StringVar(
                value=trace_value_map.get(current_trace_key, trace_choices[2][0])
            )
            self._current_trace_key_var = trace_key_var
            self._current_trace_key_map = trace_label_map
            ttk.Label(behavior_frame, text="Target Trace:").grid(
                row=behavior_row, column=0, sticky="w", padx=6, pady=2
            )
            _ui_combobox(
                behavior_frame,
                values=[label for label, _ in trace_choices],
                textvariable=trace_key_var,
                state="readonly",
                width=22,
            ).grid(row=behavior_row, column=1, sticky="w", padx=6, pady=2)
            behavior_row += 1

        zorder_var = tk.StringVar(value=str(element.get("zorder", "")))
        self._current_zorder_var = zorder_var
        ttk.Label(behavior_frame, text="Z-Order:").grid(
            row=behavior_row, column=0, sticky="w", padx=6, pady=2
        )
        _ui_entry(behavior_frame, textvariable=zorder_var, width=10).grid(
            row=behavior_row, column=1, sticky="w", padx=6, pady=2
        )

        zorder_frame = ttk.Frame(behavior_frame)
        zorder_frame.grid(
            row=behavior_row + 1, column=0, columnspan=2, sticky="w", padx=6, pady=2
        )
        _ui_button(
            zorder_frame, text="Send Backward", command=lambda: self._nudge_zorder(-1)
        ).pack(side="left", padx=(0, 6))
        _ui_button(
            zorder_frame, text="Bring Forward", command=lambda: self._nudge_zorder(1)
        ).pack(side="left", padx=4)

        toggle_frame = ttk.Frame(behavior_frame)
        toggle_frame.grid(
            row=behavior_row + 2, column=0, columnspan=2, sticky="w", padx=6, pady=2
        )
        _ui_button(
            toggle_frame, text="Toggle Visibility", command=self._toggle_visibility_selected
        ).pack(side="left", padx=(0, 6))
        _ui_button(
            toggle_frame, text="Lock/Unlock", command=self._toggle_lock_selected
        ).pack(side="left", padx=4)

        style_vars: Dict[str, tk.Variable] = {}
        if element_type in {"xspan", "xspan_label"}:
            span_layer_map = {
                "Behind data": "behind_data",
                "Above data": "above_data",
            }
            current_layer = str(
                element.get("style", {}).get("span_layer", "behind_data")
            ).strip()
            label_value = next(
                (label for label, value in span_layer_map.items() if value == current_layer),
                "Behind data",
            )
            span_layer_var = tk.StringVar(value=label_value)
            span_layer_row = behavior_row + 3
            ttk.Label(behavior_frame, text="Span Layer:").grid(
                row=span_layer_row, column=0, sticky="w", padx=6, pady=2
            )
            _ui_combobox(
                behavior_frame,
                values=list(span_layer_map.keys()),
                textvariable=span_layer_var,
                state="readonly",
                width=18,
            ).grid(row=span_layer_row, column=1, sticky="w", padx=6, pady=2)
            style_vars["span_layer"] = span_layer_var

        geom_vars = {}
        geom_frame = ttk.LabelFrame(self._props_container, text="Geometry")
        geom_frame.grid(row=row, column=0, columnspan=2, sticky="ew", padx=6, pady=4)
        row += 1
        geom_vars.update(self._build_geometry_fields(geom_frame, element))

        appearance_vars = self._build_appearance_fields(
            self._props_container, element, row, self._schedule_live_update
        )
        row = appearance_vars.pop("_next_row", row)
        style_vars.update(appearance_vars)

        text_like = {"text", "callout", "arrow", "xspan_label", "rect", "ref_line"}
        if element_type in text_like:
            text_vars, text_style_vars, row = self._build_text_fields(
                self._props_container, element, row, self._schedule_live_update
            )
            geom_vars.update(text_vars)
            style_vars.update(text_style_vars)

        self._current_geom_vars = geom_vars
        self._current_style_vars = style_vars
        self._reset_manual_apply_tracking(element)

        tracked_vars = [axis_label_var, zorder_var]
        if self._current_trace_key_var is not None:
            tracked_vars.append(self._current_trace_key_var)
        # Iterate over tracked_vars to apply the per-item logic.
        for var in tracked_vars:
            self._register_live_update(var)
        # Iterate over values from geom_vars to apply the per-item logic.
        for var in geom_vars.values():
            self._register_live_update(var)
        # Iterate over values from style_vars to apply the per-item logic.
        for var in style_vars.values():
            self._register_live_update(var)

        self._set_apply_controls_state(not locked)
        self._suppress_live_update = False
        self._refresh_props_scroll()

    def _reset_manual_apply_tracking(self, element: Optional[Dict[str, Any]]) -> None:
        """Reset pending manual-apply tracking for the properties editor.

        Purpose:
            Clear staged-change flags and establish the current z-order baseline.
        Why:
            The Apply controls should react to edits since the most recent
            selected-state snapshot, and z-order comparisons need a stable
            baseline value.
        Inputs:
            element: Selected plot element snapshot, or None when no selection.
        Outputs:
            None.
        Side Effects:
            Updates pending-change flags and cached baseline z-order.
        Exceptions:
            None. Invalid/missing z-order values fall back to defaults.
        """
        self._pending_manual_changes = False
        self._zorder_pending_change = False
        self._zorder_initial_value = None
        if not isinstance(element, dict):
            return
        baseline = _coerce_float(element.get("zorder"))
        if baseline is None:
            baseline = float(ANNOTATION_DEFAULT_ZORDER)
        self._zorder_initial_value = float(baseline)

    def _update_zorder_pending_state(self) -> None:
        """Recompute whether the current z-order field has unapplied changes.

        Purpose:
            Compare the edited z-order value against the selected-element
            baseline to determine if Apply should be actionable.
        Why:
            Live Update can be disabled, so z-order edits must explicitly
            surface as pending manual changes.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Updates `_zorder_pending_change`.
        Exceptions:
            None. Invalid numeric input is treated as pending.
        """
        zorder_var = self._current_zorder_var
        baseline = self._zorder_initial_value
        if zorder_var is None or baseline is None:
            self._zorder_pending_change = False
            return
        raw_value = str(zorder_var.get()).strip()
        parsed_value = _coerce_float(raw_value)
        if parsed_value is None:
            self._zorder_pending_change = bool(raw_value)
            return
        self._zorder_pending_change = not math.isclose(
            float(parsed_value),
            float(baseline),
            rel_tol=0.0,
            abs_tol=1e-9,
        )

    def _on_property_editor_value_changed(
        self, watched_var: Optional[tk.Variable] = None
    ) -> None:
        """Handle one property-field edit for Apply-state and live-update flow.

        Purpose:
            Track manual pending edits and schedule optional live updates.
        Why:
            The Apply button state must reflect unsaved property edits, with a
            dedicated path for z-order field changes when Live Update is off.
        Inputs:
            watched_var: The variable that fired the write trace callback.
        Outputs:
            None.
        Side Effects:
            Updates pending-change flags, refreshes Apply/Revert button state,
            and schedules debounced live updates when enabled.
        Exceptions:
            UI/state lookups are guarded to avoid interrupting editor workflow.
        """
        if self._suppress_live_update:
            return
        if watched_var is self._current_zorder_var:
            self._update_zorder_pending_state()
        else:
            self._pending_manual_changes = True
        selected = self._controller.selected_element()
        locked = bool(selected.get("locked", False)) if isinstance(selected, dict) else True
        self._set_apply_controls_state(not locked)
        self._schedule_live_update()

    def _set_apply_controls_state(self, enabled: bool) -> None:
        """Set Apply/Revert control availability for the current editor state.

        Purpose:
            Toggle Apply/Apply+Keep/Revert based on lock state and pending edits.
        Why:
            With Live Update disabled, users should only apply when there are
            pending changes; z-order edits must explicitly activate Apply.
        Inputs:
            enabled: True when the selected element is editable (not locked).
        Outputs:
            None.
        Side Effects:
            Updates button widget states in the properties action row.
        Exceptions:
            Widget state updates are guarded to keep the panel responsive.
        """
        has_pending_changes = bool(
            self._pending_manual_changes or self._zorder_pending_change
        )
        manual_apply_required = not bool(self._live_update_var.get())
        allow_apply = bool(enabled) and (
            has_pending_changes or not manual_apply_required
        )
        state = "normal" if allow_apply else "disabled"
        # Iterate to apply the per-item logic.
        for button in (
            self._apply_button,
            self._apply_keep_button,
            self._revert_button,
        ):
            if button is not None:
                try:
                    button.configure(state=state)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        # Iterate over (self._undo_button, self._redo_button) to apply the per-item logic.
        for button in (self._undo_button, self._redo_button):
            if button is not None:
                try:
                    button.configure(state="normal")
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

    def _register_live_update(self, var: tk.Variable) -> None:
        """Register one property variable for pending-state and live-update flow.

        Purpose:
            Attach a write-trace callback for one editor variable.
        Why:
            Variable writes drive manual Apply-state tracking and optional
            debounced Live Update applies.
        Inputs:
            var: Tk variable bound to a property editor field.
        Outputs:
            None.
        Side Effects:
            Adds a Tk trace callback to the provided variable.
        Exceptions:
            Trace registration failures are swallowed to avoid UI interruption.
        """
        if var is None:
            return
        try:
            var.trace_add(
                "write",
                lambda *_args, watched_var=var: self._on_property_editor_value_changed(
                    watched_var
                ),
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return

    def _schedule_live_update(self) -> None:
        """Schedule live update.
        Used to queue live update without blocking the UI."""
        if self._suppress_live_update:
            return
        if not self._live_update_var.get():
            return
        if self._live_update_after_id is not None:
            try:
                self._frame.after_cancel(self._live_update_after_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            self._live_update_after_id = self._frame.after(
                250, lambda: self._apply_properties(keep_editing=True)
            )
        except Exception:
            self._live_update_after_id = None

    def _on_toggle_live_update(self) -> None:
        """Persist Live Update toggle state and refresh Apply control state.

        Purpose:
            Save user preference for automatic property application behavior.
        Why:
            Apply button gating differs between live and manual modes, so state
            must be recomputed immediately when the toggle changes.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Updates persisted UI state and recalculates action-button enabled state.
        Exceptions:
            Settings persistence failures are guarded to keep editing active.
        """
        self._store.set_ui_state(
            self._plot_id, live_update=bool(self._live_update_var.get())
        )
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        selected = self._controller.selected_element()
        locked = bool(selected.get("locked", False)) if isinstance(selected, dict) else True
        self._set_apply_controls_state(not locked)

    def _apply_properties(self, *, keep_editing: bool = False) -> None:
        """Apply current property-form values to the selected plot element.

        Purpose:
            Commit staged editor values into the selected element model.
        Why:
            Manual Apply mode must reliably persist element edits, including
            z-order values such as `0`, and then clear pending-change tracking.
        Inputs:
            keep_editing: When True, keep the form open without full panel refresh.
        Outputs:
            None.
        Side Effects:
            Mutates selected element fields, re-renders via controller update,
            updates snapshots/baselines, and resets pending Apply state.
        Exceptions:
            Invalid numeric fields fall back to prior values; all controller
            mutation guards remain inside update_element_properties.
        """
        element = self._controller.selected_element()
        if element is None:
            return
        if element.get("locked"):
            return
        axis_var = self._current_axis_var
        zorder_var = self._current_zorder_var
        if axis_var is None or zorder_var is None:
            return
        axis_role = self._current_axis_map.get(
            axis_var.get(), element.get("axes_target")
        )
        zorder_candidate = _coerce_float(zorder_var.get())
        zorder_value = (
            float(zorder_candidate)
            if zorder_candidate is not None
            else element.get("zorder")
        )
        element_type = str(element.get("type") or "").strip().lower()
        geometry_updates: Dict[str, Any] = {}
        if (
            element_type in {"trace_mask", "trace_start"}
            and self._current_trace_key_var is not None
        ):
            trace_label = self._current_trace_key_var.get()
            trace_key_value = self._current_trace_key_map.get(trace_label, trace_label)
            geometry_updates["trace_key"] = _normalize_trace_series_key(
                trace_key_value, default="y2"
            )
        string_geom_keys = {"text", "orientation", "label_anchor"}
        # Iterate over items from self._current_geom_vars to apply the per-item logic.
        for key, var in self._current_geom_vars.items():
            value = var.get()
            if key in string_geom_keys:
                geometry_updates[key] = value
            elif value == "":
                continue
            else:
                geometry_updates[key] = _coerce_float(value)
        style_updates: Dict[str, Any] = {}
        boolean_style_keys = {"bbox_shadow", "snap_to_data"}
        color_style_keys = {
            "color",
            "facecolor",
            "edgecolor",
            "text_color",
            "bbox_facecolor",
            "bbox_edgecolor",
            "marker_facecolor",
            "marker_edgecolor",
        }
        string_style_keys = {
            "linestyle",
            "marker",
            "fontfamily",
            "fontweight",
            "text_align",
            "text_valign",
            "bbox_linestyle",
            "bbox_boxstyle",
            "arrowstyle",
            "span_layer",
        }
        span_layer_labels = {
            "behind data": "behind_data",
            "above data": "above_data",
        }
        bbox_enabled_var = self._current_style_vars.get("bbox_enabled")
        bbox_enabled = bool(bbox_enabled_var.get()) if bbox_enabled_var is not None else True
        # Iterate over items from self._current_style_vars to apply the per-item logic.
        for key, var in self._current_style_vars.items():
            if key == "bbox_enabled":
                continue
            value = var.get()
            if key in boolean_style_keys:
                style_updates[key] = bool(value)
            elif value == "":
                continue
            elif key == "span_layer":
                label = str(value or "").strip().lower()
                style_updates[key] = span_layer_labels.get(label, label or "behind_data")
            elif key in color_style_keys:
                color_value = str(value).strip()
                if color_value.lower() in {"none", "transparent"}:
                    style_updates[key] = "none"
                else:
                    style_updates[key] = _normalize_mpl_color(color_value)
            elif key in string_style_keys:
                style_updates[key] = value
            else:
                float_val = _coerce_float(value)
                style_updates[key] = float_val if float_val is not None else value
        if not bbox_enabled:
            style_updates["bbox_facecolor"] = "none"
            style_updates["bbox_edgecolor"] = "none"
            style_updates["bbox_alpha"] = 0.0
        element_updates = {
            "axes_target": axis_role,
            "zorder": zorder_value,
        }
        self._controller.update_element_properties(
            element.get("id"),
            element_updates=element_updates,
            geometry_updates=geometry_updates,
            style_updates=style_updates,
        )
        updated = self._controller.selected_element()
        if updated is not None and updated.get("id"):
            self._element_snapshots[str(updated.get("id"))] = copy.deepcopy(updated)
            if keep_editing and self._current_zorder_var is not None:
                applied_zorder = _coerce_float(updated.get("zorder"))
                if applied_zorder is not None:
                    self._suppress_live_update = True
                    try:
                        # Keep the entry synchronized with the applied value so
                        # pending-state tracking clears immediately after Apply.
                        self._current_zorder_var.set(f"{float(applied_zorder):g}")
                    finally:
                        self._suppress_live_update = False
            self._reset_manual_apply_tracking(updated)
            self._set_apply_controls_state(not bool(updated.get("locked", False)))
        if not keep_editing:
            self.refresh()

    def _revert_properties(self) -> None:
        """Perform revert properties.
        Used to keep the workflow logic localized and testable."""
        element = self._controller.selected_element()
        if element is None:
            return
        element_id = str(element.get("id") or "")
        if not element_id:
            return
        snapshot = self._element_snapshots.get(element_id)
        if snapshot is None:
            return
        self._controller.restore_element_snapshot(element_id, snapshot)
        self.refresh()

    def _build_geometry_fields(
        self, parent: ttk.Frame, element: Dict[str, Any]
    ) -> Dict[str, tk.Variable]:
        """Build geometry fields.
        Used to assemble geometry fields during UI or plot setup."""
        geometry = element.get("geometry", {})
        element_type = str(element.get("type") or "").strip().lower()
        coord_space = str(element.get("coord_space") or "data").strip().lower()
        fields = []
        if element_type == "text":
            fields = [("x", "x"), ("y", "y")]
        elif element_type in {"callout", "arrow"}:
            fields = [("x0", "x0"), ("y0", "y0"), ("x1", "x1"), ("y1", "y1")]
        elif element_type == "point":
            fields = [("x", "x"), ("y", "y")]
        elif element_type == "xspan":
            fields = [("x0", "x0"), ("x1", "x1")]
        elif element_type == "trace_mask":
            fields = [("x0", "x0"), ("x1", "x1")]
        elif element_type == "trace_start":
            fields = [("x_start", "x_start")]
        elif element_type == "xspan_label":
            fields = [("x0", "x0"), ("x1", "x1"), ("label_x", "label_x")]
            label_y_axes = _coerce_float(geometry.get("label_y_axes"))
            if coord_space == "axes" or label_y_axes is not None:
                fields.append(("label_y_axes", "label_y_axes"))
            else:
                fields.append(("label_y_data", "label_y_data"))
        elif element_type == "rect":
            fields = [("x0", "x0"), ("y0", "y0"), ("x1", "x1"), ("y1", "y1")]
        elif element_type == "ref_line":
            fields = [
                ("orientation", "orientation"),
                ("value", "value"),
            ]
            if geometry.get("text"):
                fields.extend([("label_x", "label_x"), ("label_y", "label_y")])
        elif element_type == "ink":
            points = (
                geometry.get("points")
                if isinstance(geometry.get("points"), list)
                else []
            )
            ttk.Label(parent, text=f"Points: {len(points)}").pack(
                anchor="w", padx=6, pady=4
            )
            return {}
        vars_out: Dict[str, tk.Variable] = {}
        # Iterate over indexed elements from fields to apply the per-item logic.
        for idx, (label, key) in enumerate(fields):
            ttk.Label(parent, text=f"{label}:").grid(
                row=idx, column=0, sticky="w", padx=6, pady=2
            )
            value = geometry.get(key, "")
            var = tk.StringVar(value=str(value) if value is not None else "")
            _ui_entry(parent, textvariable=var, width=20).grid(
                row=idx, column=1, sticky="w", padx=6, pady=2
            )
            vars_out[key] = var
        return vars_out

    def _build_appearance_fields(
        self,
        parent: ttk.Frame,
        element: Dict[str, Any],
        start_row: int,
        apply_callback: Optional[Callable[[], None]] = None,
    ) -> Dict[str, tk.Variable]:
        """Build appearance fields.
        Used to assemble appearance fields during UI or plot setup."""
        style = element.get("style", {})
        element_type = str(element.get("type") or "").strip().lower()
        frame = ttk.LabelFrame(parent, text="Appearance")
        frame.grid(row=start_row, column=0, columnspan=2, sticky="ew", padx=6, pady=4)
        frame.grid_columnconfigure(1, weight=1)
        vars_out: Dict[str, tk.Variable] = {}
        row = 0

        def _add_entry(label: str, key: str, width: int = 18) -> None:
            """Perform add entry.
            Used to keep the workflow logic localized and testable."""
            nonlocal row
            ttk.Label(frame, text=f"{label}:").grid(
                row=row, column=0, sticky="w", padx=6, pady=2
            )
            value = style.get(key, "")
            var = tk.StringVar(value=str(value) if value is not None else "")
            _ui_entry(frame, textvariable=var, width=width).grid(
                row=row, column=1, sticky="w", padx=6, pady=2
            )
            vars_out[key] = var
            row += 1

        def _add_color_field(label: str, key: str, default: str) -> None:
            """Perform add color field.
            Used to keep the workflow logic localized and testable."""
            nonlocal row
            value = style.get(key, default)
            var = tk.StringVar(value=str(value) if value is not None else "")
            ttk.Label(frame, text=f"{label}:").grid(
                row=row, column=0, sticky="w", padx=6, pady=2
            )
            color_frame = ttk.Frame(frame)
            color_frame.grid(row=row, column=1, sticky="ew", padx=6, pady=2)
            swatch = tk.Label(color_frame, width=2, relief="groove")
            swatch.grid(row=0, column=0, padx=(0, 4))

            # Closure captures _add_color_field state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _add_color_field.
            def _update_swatch() -> None:
                """Update swatch.
                Used to keep swatch in sync with current state."""
                color = self._normalize_color_value(var.get(), default)
                try:
                    swatch.configure(background=color)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

            # Closure captures _add_color_field state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _add_color_field.
            def _commit_color(_event: Any = None) -> None:
                """Perform commit color.
                Used to keep the workflow logic localized and testable."""
                normalized = self._normalize_color_value(var.get(), default)
                var.set(normalized)
                _update_swatch()
                if apply_callback is not None:
                    apply_callback()

            # Closure captures _add_color_field local context to keep helper logic scoped and invoked directly within _add_color_field.
            def _choose_color() -> None:
                """Perform choose color.
                Used to keep the workflow logic localized and testable."""
                initial = self._normalize_color_value(var.get(), default)
                result = colorchooser.askcolor(
                    color=initial, parent=self._frame.winfo_toplevel()
                )
                if not result or not result[1]:
                    return
                var.set(self._normalize_color_value(result[1], default))
                _update_swatch()
                if apply_callback is not None:
                    apply_callback()

            _ui_button(color_frame, text="Color...", command=_choose_color).grid(
                row=0, column=1, padx=(0, 4)
            )
            entry = _ui_entry(color_frame, textvariable=var, width=12)
            entry.grid(row=0, column=2, sticky="ew")
            entry.bind("<Return>", _commit_color)
            entry.bind("<FocusOut>", _commit_color)
            color_frame.grid_columnconfigure(2, weight=1)
            _update_swatch()
            vars_out[key] = var
            row += 1

        patch_types = {"xspan", "xspan_label", "rect"}
        line_types = {"callout", "arrow", "ref_line", "ink"}

        if element_type in patch_types:
            _add_color_field("Fill Color", "facecolor", "#cccccc")
            _add_color_field("Edge Color", "edgecolor", "#333333")
            _add_entry("Alpha", "alpha", width=8)
            _add_entry("Line Width", "linewidth", width=8)
            _add_entry("Line Style", "linestyle")
        elif element_type in line_types:
            _add_color_field("Line Color", "color", "#000000")
            _add_entry("Alpha", "alpha", width=8)
            _add_entry("Line Width", "linewidth", width=8)
            _add_entry("Line Style", "linestyle")
            if element_type in {"callout", "arrow"}:
                _add_entry("Arrow Style", "arrowstyle")
        elif element_type == "point":
            _add_color_field("Marker Face", "marker_facecolor", "#000000")
            _add_color_field("Marker Edge", "marker_edgecolor", "#000000")
            _add_entry("Marker", "marker")
            _add_entry("Marker Size", "marker_size", width=8)
            _add_entry("Alpha", "alpha", width=8)
            snap_var = tk.BooleanVar(value=bool(style.get("snap_to_data", False)))
            _ui_checkbutton(frame, text="Snap to Data", variable=snap_var).grid(
                row=row, column=0, columnspan=2, sticky="w", padx=6, pady=2
            )
            vars_out["snap_to_data"] = snap_var
            row += 1
        else:
            _add_entry("Alpha", "alpha", width=8)

        vars_out["_next_row"] = start_row + 1
        return vars_out

    def _build_text_fields(
        self,
        parent: ttk.Frame,
        element: Dict[str, Any],
        start_row: int,
        apply_callback: Optional[Callable[[], None]] = None,
    ) -> Tuple[Dict[str, tk.Variable], Dict[str, tk.Variable], int]:
        """Build text fields.
        Used to assemble text fields during UI or plot setup."""
        geometry = element.get("geometry", {})
        style = element.get("style", {})
        element_type = str(element.get("type") or "").strip().lower()
        frame = ttk.LabelFrame(parent, text="Text")
        frame.grid(row=start_row, column=0, columnspan=2, sticky="ew", padx=6, pady=4)
        frame.grid_columnconfigure(1, weight=1)
        geom_vars: Dict[str, tk.Variable] = {}
        style_vars: Dict[str, tk.Variable] = {}
        row = 0

        def _add_geom_entry(label: str, key: str, width: int = 22) -> None:
            """Perform add geom entry.
            Used to keep the workflow logic localized and testable."""
            nonlocal row
            ttk.Label(frame, text=f"{label}:").grid(
                row=row, column=0, sticky="w", padx=6, pady=2
            )
            value = geometry.get(key, "")
            var = tk.StringVar(value=str(value) if value is not None else "")
            _ui_entry(frame, textvariable=var, width=width).grid(
                row=row, column=1, sticky="w", padx=6, pady=2
            )
            geom_vars[key] = var
            row += 1

        def _add_style_entry(label: str, key: str, width: int = 22) -> None:
            """Perform add style entry.
            Used to keep the workflow logic localized and testable."""
            nonlocal row
            ttk.Label(frame, text=f"{label}:").grid(
                row=row, column=0, sticky="w", padx=6, pady=2
            )
            value = style.get(key, "")
            var = tk.StringVar(value=str(value) if value is not None else "")
            _ui_entry(frame, textvariable=var, width=width).grid(
                row=row, column=1, sticky="w", padx=6, pady=2
            )
            style_vars[key] = var
            row += 1

        def _add_style_check(label: str, key: str) -> None:
            """Perform add style check.
            Used to keep the workflow logic localized and testable."""
            nonlocal row
            var = tk.BooleanVar(value=bool(style.get(key, False)))
            _ui_checkbutton(frame, text=label, variable=var).grid(
                row=row, column=0, columnspan=2, sticky="w", padx=6, pady=2
            )
            style_vars[key] = var
            row += 1
            if apply_callback is not None:
                var.trace_add("write", lambda *_args: apply_callback())

        _add_geom_entry("Text", "text")
        if element_type in {"text", "xspan_label"}:
            _add_geom_entry("Wrap Width (x)", "wrap_width_x")
        if element_type == "xspan_label":
            _add_geom_entry("Label Anchor", "label_anchor")

        _add_style_entry("Font Size", "fontsize", width=10)
        _add_style_entry("Font Family", "fontfamily")
        _add_style_entry("Font Weight", "fontweight", width=10)
        _add_style_entry("Text Color", "text_color")
        _add_style_entry("Text Align", "text_align", width=10)
        _add_style_entry("Text Valign", "text_valign", width=10)
        bbox_face = str(style.get("bbox_facecolor", "") or "").strip().lower()
        bbox_edge = str(style.get("bbox_edgecolor", "") or "").strip().lower()
        bbox_enabled = not (
            bbox_face in {"", "none", "transparent"}
            and bbox_edge in {"", "none", "transparent"}
        )
        bbox_enabled_var = tk.BooleanVar(value=bbox_enabled)
        _ui_checkbutton(frame, text="BBox Enabled", variable=bbox_enabled_var).grid(
            row=row, column=0, columnspan=2, sticky="w", padx=6, pady=2
        )
        style_vars["bbox_enabled"] = bbox_enabled_var
        row += 1
        _add_style_entry("BBox Face", "bbox_facecolor")
        _add_style_entry("BBox Edge", "bbox_edgecolor")
        _add_style_entry("BBox Alpha", "bbox_alpha", width=10)
        _add_style_entry("BBox Line Width", "bbox_linewidth", width=10)
        _add_style_entry("BBox Line Style", "bbox_linestyle", width=10)
        _add_style_entry("BBox Box Style", "bbox_boxstyle")
        _add_style_entry("BBox Pad", "bbox_pad", width=10)
        _add_style_check("BBox Shadow", "bbox_shadow")
        _add_style_entry("Shadow Offset X", "bbox_shadow_offset_x", width=10)
        _add_style_entry("Shadow Offset Y", "bbox_shadow_offset_y", width=10)
        _add_style_entry("Shadow Alpha", "bbox_shadow_alpha", width=10)

        return geom_vars, style_vars, start_row + 1


EXPORT_DPI = 1200

APP_VERSION = "v3.0.7"

DEBUG_LOGGER_NAME = "gl260"
DEBUG_LOG_FILE = "gl260_debug.log"

DEBUG_CATEGORIES = (
    "ui.events",
    "cache.render",
    "perf.timing",
    "plotting.render",
    "plotting.layout",
    "plotting.legends",
    "cycle.analysis",
    "cycle.interaction",
    "report.build",
    "report.figures",
    "report.export",
    "speciation.engine",
    "speciation.solver",
    "speciation.chemistry",
    "speciation.results",
    "io.excel",
    "io.files",
)

DEBUG_CATEGORY_LABELS = {
    "ui.events": "UI Events",
    "cache.render": "Render Cache",
    "perf.timing": "Performance Timing",
    "plotting.render": "Plotting: Render",
    "plotting.layout": "Plotting: Layout",
    "plotting.legends": "Plotting: Legends",
    "cycle.analysis": "Cycle Analysis",
    "cycle.interaction": "Cycle Interaction",
    "report.build": "Final Report: Build",
    "report.figures": "Final Report: Figures",
    "report.export": "Final Report: Export",
    "speciation.engine": "Speciation: Engine",
    "speciation.solver": "Speciation: Solver",
    "speciation.chemistry": "Speciation: Chemistry",
    "speciation.results": "Speciation: Results",
    "io.excel": "IO: Excel",
    "io.files": "IO: Files",
}

DEBUG_CATEGORY_DEFAULTS = {name: False for name in DEBUG_CATEGORIES}

_GL260_LOGGER = logging.getLogger(DEBUG_LOGGER_NAME)
_GL260_LOGGER.addHandler(logging.NullHandler())

AUTO_TITLE_SOURCE_FULL = "full_dataset"
AUTO_TITLE_SOURCE_CURRENT = "current_view"
AUTO_TITLE_SOURCES = (AUTO_TITLE_SOURCE_FULL, AUTO_TITLE_SOURCE_CURRENT)
AUTO_TITLE_DAY_DIFF = "date_diff"
AUTO_TITLE_DAY_INCLUSIVE = "inclusive"
AUTO_TITLE_DAY_MODES = (AUTO_TITLE_DAY_DIFF, AUTO_TITLE_DAY_INCLUSIVE)
DEFAULT_AUTO_TITLE_TEMPLATE = "{type} Day {day_start}-{day_end} {date_start}-{date_end}"
DEFAULT_TITLE_TYPES = ["Reaction"]


DEBUG_SERIES_FLOW = False
DEBUG_RENDER_CACHE = True
DEBUG_TITLE_FONT_RESOLVE = False
DEBUG_ANNOTATIONS_INTERACTION = False
DEFAULT_EXPORT_DPI = EXPORT_DPI
FINAL_REPORT_PREVIEW_BASE_DPI = 150.0
FINAL_REPORT_PREVIEW_MIN_DPI = 48.0
FINAL_REPORT_PREVIEW_BASE_SCREEN_WIDTH_RATIO = 0.84
FINAL_REPORT_PREVIEW_BASE_SCREEN_HEIGHT_RATIO = 0.82
FINAL_REPORT_PREVIEW_WINDOW_MAX_SCREEN_RATIO = 0.92
FINAL_REPORT_PREVIEW_WINDOW_SCREEN_MARGIN_PX = 24
FINAL_REPORT_PREVIEW_MIN_WINDOW_WIDTH = 640
FINAL_REPORT_PREVIEW_MIN_WINDOW_HEIGHT = 480
PLANNING_DEFAULT_STOP_PH = 8.25
PLANNING_DEFAULT_STOP_CO2_ADDED_G = 2000.0
PLANNING_PH_TARGET = PLANNING_DEFAULT_STOP_PH
PLANNING_PLATEAU_CARBONATE_THRESHOLD = 1e-9
PLANNING_PLATEAU_RELATIVE_THRESHOLD = 0.02
PLANNING_PLATEAU_PH_MIN = 8.0
PLANNING_PLATEAU_PH_MAX = 8.3
PLANNING_PLATEAU_WINDOW = 10
PLANNING_MIN_PH_DROP = 0.01
MAX_PLANNING_SYNTH_CYCLES = 500

ELAPSED_TIME_UNITS = ("days", "hours", "minutes", "seconds")
DEFAULT_ELAPSED_TIME_UNIT = "days"
ELAPSED_UNIT_SECONDS = {
    "days": 86400.0,
    "hours": 3600.0,
    "minutes": 60.0,
    "seconds": 1.0,
}

CSV_IMPORT_DERIVATIVE_SOURCES = ("reactor", "manifold")
CSV_IMPORT_SHEET_EXISTS_MODES = ("error", "overwrite", "autosuffix")
CSV_IMPORT_DEFAULT_DERIVATIVE_SOURCE = "reactor"
CSV_IMPORT_DEFAULT_SHEET_EXISTS_MODE = "error"
CSV_IMPORT_DEFAULT_DAMPENING = 0.98
CSV_IMPORT_DEFAULT_MOVING_AVG_WINDOW = 100
CSV_IMPORT_MAPPING_FIELDS = OrderedDict(
    [
        ("date_time", "Date & Time"),
        ("reactor_pressure", "Reactor Pressure (PSI)"),
        ("manifold_pressure", "Manifold Pressure (PSI)"),
        ("external_temp", "External Reactor Temperature"),
        ("internal_temp", "Internal Reactor Temperature"),
    ]
)
CSV_IMPORT_OUTPUT_COLUMNS = [
    "Date & Time",
    "Elapsed Time (days)",
    "Elapsed Time (hours)",
    "Elapsed Time (minutes)",
    "Elapsed Time (seconds)",
    "Reactor Pressure (PSI)",
    "Manifold Pressure (PSI)",
    "External Reactor Temperature",
    "Internal Reactor Temperature",
    "First Derivative (ΔPSI/Δhour)",
    "Smoothed First Derivative",
    "First Derivative Moving Average",
]
CSV_IMPORT_DERIVATIVE_SOURCE_LABELS = {
    "reactor": "Reactor Pressure (PSI)",
    "manifold": "Manifold Pressure (PSI)",
}
CSV_IMPORT_SHEET_MODE_LABELS = {
    "error": "Error if sheet exists",
    "overwrite": "Overwrite existing sheet",
    "autosuffix": "Auto-suffix (_1, _2, ...)",
}


def _apply_csv_import_settings_defaults(settings_dict: Dict[str, Any]) -> None:
    """Apply CSV import settings defaults.
    Used to apply CSV import settings defaults changes to live state."""
    if not isinstance(settings_dict, dict):
        return
    mapping = settings_dict.get("csv_import_mapping")
    if not isinstance(mapping, dict):
        mapping = {}
    normalized_mapping = {}
    # Iterate over keys from CSV_IMPORT_MAPPING_FIELDS to apply the per-item logic.
    for key in CSV_IMPORT_MAPPING_FIELDS.keys():
        value = mapping.get(key, "")
        if value is None:
            value = ""
        if not isinstance(value, str):
            value = str(value)
        normalized_mapping[key] = value
    settings_dict["csv_import_mapping"] = normalized_mapping

    # Iterate over ("csv_import_last_csv_path", "csv_import_last_workbook_path") to apply the per-item logic.
    for key in ("csv_import_last_csv_path", "csv_import_last_workbook_path"):
        value = settings_dict.get(key, "")
        if value is None:
            value = ""
        if not isinstance(value, str):
            value = str(value)
        settings_dict[key] = value

    sheet_name = settings_dict.get("csv_import_last_sheet_name", "")
    if sheet_name is None:
        sheet_name = ""
    if not isinstance(sheet_name, str):
        sheet_name = str(sheet_name)
    settings_dict["csv_import_last_sheet_name"] = sheet_name

    mode = str(
        settings_dict.get("csv_import_sheet_exists_mode", CSV_IMPORT_DEFAULT_SHEET_EXISTS_MODE)
    ).strip().lower()
    if mode not in CSV_IMPORT_SHEET_EXISTS_MODES:
        mode = CSV_IMPORT_DEFAULT_SHEET_EXISTS_MODE
    settings_dict["csv_import_sheet_exists_mode"] = mode

    source = str(
        settings_dict.get(
            "csv_import_derivative_source", CSV_IMPORT_DEFAULT_DERIVATIVE_SOURCE
        )
    ).strip().lower()
    if source not in CSV_IMPORT_DERIVATIVE_SOURCES:
        source = CSV_IMPORT_DEFAULT_DERIVATIVE_SOURCE
    settings_dict["csv_import_derivative_source"] = source

    dampening = settings_dict.get(
        "csv_import_smoothing_factor", CSV_IMPORT_DEFAULT_DAMPENING
    )
    try:
        dampening_value = float(dampening)
    except (TypeError, ValueError):
        dampening_value = CSV_IMPORT_DEFAULT_DAMPENING
    if not math.isfinite(dampening_value) or not (0.0 <= dampening_value < 1.0):
        dampening_value = CSV_IMPORT_DEFAULT_DAMPENING
    settings_dict["csv_import_smoothing_factor"] = dampening_value

    window = settings_dict.get(
        "csv_import_moving_average_window", CSV_IMPORT_DEFAULT_MOVING_AVG_WINDOW
    )
    try:
        window_value = int(window)
    except (TypeError, ValueError):
        window_value = CSV_IMPORT_DEFAULT_MOVING_AVG_WINDOW
    if window_value < 1:
        window_value = CSV_IMPORT_DEFAULT_MOVING_AVG_WINDOW
    settings_dict["csv_import_moving_average_window"] = window_value

_FINAL_REPORT_FONT_FAMILY = _preferred_plot_font_stack()
_FINAL_REPORT_SUBSCRIPT_MAP = {
    "\u2080": "0",
    "\u2081": "1",
    "\u2082": "2",
    "\u2083": "3",
    "\u2084": "4",
    "\u2085": "5",
    "\u2086": "6",
    "\u2087": "7",
    "\u2088": "8",
    "\u2089": "9",
}
_FINAL_REPORT_SUPERSCRIPT_MAP = {
    "\u2070": "0",
    "\u00b9": "1",
    "\u00b2": "2",
    "\u00b3": "3",
    "\u2074": "4",
    "\u2075": "5",
    "\u2076": "6",
    "\u2077": "7",
    "\u2078": "8",
    "\u2079": "9",
    "\u207a": "+",
    "\u207b": "-",
}
_FINAL_REPORT_SUBSCRIPT_RE = re.compile(r"[\u2080-\u2089]+")
_FINAL_REPORT_SUPERSCRIPT_RE = re.compile(
    r"[\u2070\u00b9\u00b2\u00b3\u2074-\u2079\u207a\u207b]+"
)

OUTPUT_PROFILE_MODES = ("auto", "fixed", "aspect")
OUTPUT_PROFILE_UNITS = ("in", "px")
OUTPUT_PROFILE_LIMIT_DIMENSIONS = ("width", "height")

DEFAULT_OUTPUT_PROFILE_SETTINGS: "OrderedDict[str, Dict[str, Any]]" = OrderedDict(
    [
        (
            "plot_export",
            {
                "label": "General Plot Exports",
                "defaults": {
                    "mode": "fixed",
                    "units": "in",
                    "width": 11.0,
                    "height": 8.5,
                    "aspect_width": 4.0,
                    "aspect_height": 3.0,
                    "limit_dimension": "width",
                    "limit_value": 11.0,
                },
            },
        ),
        (
            "cycle_summary_png",
            {
                "label": "Cycle Analysis Summary PNG",
                "defaults": {
                    "mode": "auto",
                    "units": "in",
                    "width": 8.5,
                    "height": 11.0,
                    "aspect_width": 3.0,
                    "aspect_height": 4.0,
                    "limit_dimension": "height",
                    "limit_value": 11.0,
                },
            },
        ),
        (
            "solubility_summary_png",
            {
                "label": "Advanced Solubility Summary PNG",
                "defaults": {
                    "mode": "auto",
                    "units": "in",
                    "width": 8.5,
                    "height": 11.0,
                    "aspect_width": 3.0,
                    "aspect_height": 4.0,
                    "limit_dimension": "height",
                    "limit_value": 11.0,
                },
            },
        ),
        (
            "sol_planner_narrative_png",
            {
                "label": "Planner Narrative PNG",
                "defaults": {
                    "mode": "auto",
                    "units": "in",
                    "width": 8.5,
                    "height": 10.0,
                    "aspect_width": 3.0,
                    "aspect_height": 4.0,
                    "limit_dimension": "height",
                    "limit_value": 10.0,
                },
            },
        ),
        (
            "sol_co2_guidance_png",
            {
                "label": "CO₂ Guidance PNG",
                "defaults": {
                    "mode": "auto",
                    "units": "in",
                    "width": 6.0,
                    "height": 4.0,
                    "aspect_width": 3.0,
                    "aspect_height": 2.0,
                    "limit_dimension": "width",
                    "limit_value": 6.0,
                },
            },
        ),
        (
            "sol_math_preview_png",
            {
                "label": "Math Preview PNG",
                "defaults": {
                    "mode": "auto",
                    "units": "in",
                    "width": 8.5,
                    "height": 6.0,
                    "aspect_width": 3.0,
                    "aspect_height": 2.0,
                    "limit_dimension": "width",
                    "limit_value": 8.5,
                },
            },
        ),
        (
            "sol_math_detail_export",
            {
                "label": "Detailed Math Viewer Export",
                "defaults": {
                    "mode": "auto",
                    "units": "in",
                    "width": 8.5,
                    "height": 11.0,
                    "aspect_width": 3.0,
                    "aspect_height": 4.0,
                    "limit_dimension": "height",
                    "limit_value": 11.0,
                },
            },
        ),
        (
            "final_report_png",
            {
                "label": "Final Report PNG",
                "defaults": {
                    "mode": "fixed",
                    "units": "in",
                    "width": 8.5,
                    "height": 11.0,
                    "aspect_width": 3.0,
                    "aspect_height": 4.0,
                    "limit_dimension": "height",
                    "limit_value": 11.0,
                },
            },
        ),
        (
            "contamination_summary_png",
            {
                "label": "Contamination Summary PNG",
                "defaults": {
                    "mode": "auto",
                    "units": "in",
                    "width": 8.5,
                    "height": 11.0,
                    "aspect_width": 3.0,
                    "aspect_height": 4.0,
                    "limit_dimension": "height",
                    "limit_value": 11.0,
                },
            },
        ),
    ]
)


FINAL_REPORT_LAYOUT_MODES = (
    "single_page_portrait",
    "mixed_pages",
    "plots_landscape_pages",
)

FINAL_REPORT_FIT_MODES = (
    "Preserve Export Layout",
    "Report Layout (legacy)",
)

FINAL_REPORT_SAFE_MARGIN_PRESETS = (
    "Normal",
    "Extra-Safe",
)

FINAL_REPORT_CAPTION_PLACEMENTS = (
    "Same Page",
    "Next Page",
)

FINAL_REPORT_TABLE_STYLE_PRESETS = (
    "Compact",
    "Normal",
    "Large",
)

FINAL_REPORT_SECTION_METADATA = OrderedDict(
    [
        (
            "cycle_plot",
            {
                "label": "Cycle Analysis Plot with peaks/troughs",
                "group": "Core Plots & Cycle Analysis",
                "type": "figure",
            },
        ),
        (
            "fig1",
            {
                "label": "Figure 1: Pressure + Temperature",
                "group": "Core Plots & Cycle Analysis",
                "type": "figure",
            },
        ),
        (
            "fig2",
            {
                "label": "Figure 2: Pressure + Derivative",
                "group": "Core Plots & Cycle Analysis",
                "type": "figure",
            },
        ),
        (
            "combined_plot",
            {
                "label": "Combined Triple-Axis Plot",
                "group": "Core Plots & Cycle Analysis",
                "type": "figure",
            },
        ),
        (
            "cycle_summary",
            {
                "label": "Cycle Analysis Summary",
                "group": "Core Plots & Cycle Analysis",
                "type": "text",
            },
        ),
        (
            "cycle_stats_table",
            {
                "label": "Cycle Statistics Table",
                "group": "Core Plots & Cycle Analysis",
                "type": "table",
            },
        ),
        (
            "cycle_timeline_plot",
            {
                "label": "Cycle Speciation Timeline Plot",
                "group": "Cycle Speciation & Guidance",
                "type": "figure",
            },
        ),
        (
            "cycle_timeline_table",
            {
                "label": "Cycle Speciation Timeline Table",
                "group": "Cycle Speciation & Guidance",
                "type": "table",
            },
        ),
        (
            "predicted_ph_callouts",
            {
                "label": "Predicted pH Callouts",
                "group": "Cycle Speciation & Guidance",
                "type": "text",
            },
        ),
        (
            "co2_dosing_guidance",
            {
                "label": "CO₂ Dosing Guidance",
                "group": "Cycle Speciation & Guidance",
                "type": "text",
            },
        ),
        (
            "planner_narrative",
            {
                "label": "Planner Narrative",
                "group": "Workflows & Speciation Narrative",
                "type": "text",
            },
        ),
        (
            "key_metrics",
            {
                "label": "Key Metrics Summary",
                "group": "Workflows & Speciation Narrative",
                "type": "table",
            },
        ),
        (
            "sol_summary",
            {
                "label": "Solubility Summary",
                "group": "Workflows & Speciation Narrative",
                "type": "text",
            },
        ),
        (
            "math_preview",
            {
                "label": "Math Details",
                "group": "Workflows & Speciation Narrative",
                "type": "text",
            },
        ),
    ]
)

FINAL_REPORT_SECTION_GROUPS: "OrderedDict[str, List[str]]" = OrderedDict()
# Iterate over items from FINAL_REPORT_SECTION_METADATA to apply the per-item logic.
for section_id, metadata in FINAL_REPORT_SECTION_METADATA.items():
    group = metadata.get("group", "General")
    FINAL_REPORT_SECTION_GROUPS.setdefault(group, []).append(section_id)

FINAL_REPORT_PLOT_SECTIONS = {
    section_id
    # Iterate to apply the per-item logic.
    for section_id, metadata in FINAL_REPORT_SECTION_METADATA.items()
    if metadata.get("type") == "figure"
}

FINAL_REPORT_COMBINED_SECTION_ID = "combined_plot"
FINAL_REPORT_EXCLUDED_SECTIONS = {"cycle_plot", "cycle_timeline_plot"}

FINAL_REPORT_ORIENTATION_OPTIONS = ("inherit", "portrait", "landscape")
FINAL_REPORT_TEMPLATE_PLACEHOLDER = "[Current layout (unsaved)]"

FINAL_REPORT_SECTION_HEADER_DEFAULTS = {
    section_id: True
    # Iterate to apply the per-item logic.
    for section_id in FINAL_REPORT_SECTION_METADATA.keys()
}

FINAL_REPORT_SECTION_CAPTION_DEFAULTS = {
    section_id: metadata.get("type") in ("figure", "table")
    # Iterate to apply the per-item logic.
    for section_id, metadata in FINAL_REPORT_SECTION_METADATA.items()
}

FINAL_REPORT_SECTION_CAPTION_PLACEMENT_DEFAULTS = {
    section_id: "Same Page"
    # Iterate to apply the per-item logic.
    for section_id in FINAL_REPORT_SECTION_METADATA.keys()
}

FINAL_REPORT_DEFAULT_SECTION_ORDER = [
    "cycle_plot",
    "fig1",
    "fig2",
    "combined_plot",
    "cycle_summary",
    "cycle_stats_table",
    "cycle_timeline_plot",
    "cycle_timeline_table",
    "predicted_ph_callouts",
    "co2_dosing_guidance",
    "planner_narrative",
    "key_metrics",
    "sol_summary",
    "math_preview",
]

FINAL_REPORT_DEFAULT_SELECTED_SECTIONS = [
    section_id
    # Iterate to apply the per-item logic.
    for section_id in FINAL_REPORT_DEFAULT_SECTION_ORDER
    if section_id not in FINAL_REPORT_EXCLUDED_SECTIONS
]

def _normalize_final_report_section_order(
    section_order: Optional[Sequence[str]],
    *,
    warn_missing: bool = True,
) -> List[str]:
    """Normalize final report section order.
    Used to keep final report section order consistent across workflows and persistence."""
    normalized: List[str] = []
    if isinstance(section_order, (list, tuple)):
        # Iterate over section_order to apply the per-item logic.
        for section_id in section_order:
            if isinstance(section_id, str) and section_id not in normalized:
                normalized.append(section_id)
    metadata_keys = list(FINAL_REPORT_SECTION_METADATA.keys())
    missing = [key for key in metadata_keys if key not in normalized]
    if missing:
        normalized.extend(missing)
        if warn_missing:
            print(
                "Warning: Final Report section order missing keys; appended: "
                + ", ".join(missing)
            )
    return normalized


FINAL_REPORT_DEFAULT_SECTION_ORDER = _normalize_final_report_section_order(
    FINAL_REPORT_DEFAULT_SECTION_ORDER
)

FINAL_REPORT_DEFAULT_STATE = {
    "title": "GL-260 Final Report",
    "combined_plot_title_override": "",
    "selected_sections": list(FINAL_REPORT_DEFAULT_SELECTED_SECTIONS),
    "narrative": "",
    "global_layout_mode": "mixed_pages",
    "fit_mode": "Preserve Export Layout",
    "font_scale": 1.0,
    "margin_in": 0.75,
    "safe_margin_preset": "Normal",
    "show_page_numbers": True,
    "show_section_headers": True,
    "table_style_preset": "Normal",
    "section_header_enabled": dict(FINAL_REPORT_SECTION_HEADER_DEFAULTS),
    "section_caption_enabled": dict(FINAL_REPORT_SECTION_CAPTION_DEFAULTS),
    "section_caption_placement": dict(FINAL_REPORT_SECTION_CAPTION_PLACEMENT_DEFAULTS),
    "section_orientation": {
        section_id: "inherit" for section_id in FINAL_REPORT_PLOT_SECTIONS
    },
    "profile_key": "final_report_png",
}


def _coerce_positive_float(value: Any, fallback: float) -> float:
    """Coerce positive float.
    Used to force positive float into a safe type or range."""
    try:
        candidate = float(value)
        if math.isfinite(candidate) and candidate > 0:
            return candidate
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    return float(fallback)


def _sanitize_single_output_profile(
    key: str, overrides: Optional[Dict[str, Any]]
) -> Dict[str, Any]:
    """Sanitize single output profile.
    Used to strip or normalize single output profile before use."""
    spec = DEFAULT_OUTPUT_PROFILE_SETTINGS.get(key)
    if not spec:
        return {}
    base_defaults = spec.get("defaults", {})
    sanitized = dict(base_defaults)
    values = overrides if isinstance(overrides, dict) else {}

    mode = values.get("mode")
    if mode in OUTPUT_PROFILE_MODES:
        sanitized["mode"] = mode

    units = values.get("units")
    if units in OUTPUT_PROFILE_UNITS:
        sanitized["units"] = units

    sanitized["width"] = _coerce_positive_float(
        values.get("width", sanitized["width"]), sanitized["width"]
    )
    sanitized["height"] = _coerce_positive_float(
        values.get("height", sanitized["height"]), sanitized["height"]
    )
    sanitized["aspect_width"] = _coerce_positive_float(
        values.get("aspect_width", sanitized["aspect_width"]),
        sanitized["aspect_width"],
    )
    sanitized["aspect_height"] = _coerce_positive_float(
        values.get("aspect_height", sanitized["aspect_height"]),
        sanitized["aspect_height"],
    )

    limit_dim = values.get("limit_dimension")
    if limit_dim in OUTPUT_PROFILE_LIMIT_DIMENSIONS:
        sanitized["limit_dimension"] = limit_dim

    sanitized["limit_value"] = _coerce_positive_float(
        values.get("limit_value", sanitized["limit_value"]),
        sanitized["limit_value"],
    )

    return sanitized


def _sanitize_output_profile_dict(
    raw: Optional[Dict[str, Any]],
) -> "OrderedDict[str, Dict[str, Any]]":
    """Sanitize output profile dict.
    Used to strip or normalize output profile dict before use."""
    raw = raw if isinstance(raw, dict) else {}
    sanitized: "OrderedDict[str, Dict[str, Any]]" = OrderedDict()
    # Iterate over keys from DEFAULT_OUTPUT_PROFILE_SETTINGS to apply the per-item logic.
    for key in DEFAULT_OUTPUT_PROFILE_SETTINGS.keys():
        sanitized[key] = _sanitize_single_output_profile(key, raw.get(key))
    return sanitized


def _sanitize_export_dpi_value(value: Any) -> int:
    """Sanitize export DPI value.
    Used to strip or normalize export DPI value before use."""
    try:
        dpi = int(value)
    except Exception:
        dpi = int(DEFAULT_EXPORT_DPI)
    if dpi <= 0:
        dpi = int(DEFAULT_EXPORT_DPI)
    return dpi


def _detect_latex_compiler(prefer_unicode: bool = False) -> Optional[str]:
    """Detect latex compiler.
    Used to decide runtime capabilities or configuration."""
    if prefer_unicode:
        compilers = ("xelatex", "lualatex", "pdflatex")
    else:
        compilers = ("xelatex", "pdflatex", "lualatex")
    # Iterate over compilers to apply the per-item logic.
    for compiler in compilers:
        if shutil.which(compiler):
            return compiler
    return None


def _contains_unicode(text: str) -> bool:
    """Check whether it contains unicode.
    Used to guard downstream processing decisions."""
    return any(ord(ch) > 127 for ch in text)


def _shorten_text(value: str, limit: int = 600) -> str:
    """Perform shorten text.
    Used to keep the workflow logic localized and testable."""
    text = value.strip()
    if len(text) <= limit:
        return text
    return text[: limit - 3].rstrip() + "..."


def _format_timeline_table_value(
    value: Any, decimals: Optional[Union[int, str]]
) -> str:
    """Format timeline table value.
    Used to prepare timeline table value for display or export."""
    if value is None:
        return ""
    if decimals is None:
        return str(value)
    try:
        numeric_value = float(value)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return str(value)
    if isinstance(decimals, str):
        if decimals == "sig3":
            try:
                return f"{numeric_value:.3g}"
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return str(value)
        return str(value)
    try:
        return f"{numeric_value:.{int(decimals)}f}"
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return str(value)


def _format_timeline_header_label(label: Any) -> str:
    """Format timeline header label.
    Used to prepare timeline header label for display or export."""
    text = "" if label is None else str(label)
    cleaned = text.strip()
    if not cleaned:
        return ""
    if "\n" in cleaned:
        return cleaned
    if "%" in cleaned:
        base = cleaned.replace("(%)", "").replace("%", "").strip()
        if base:
            return f"{base}\n(%)"
        return "(%)"
    match = re.match(r"^(.*?)(\s*\([^()]*\))\s*$", cleaned)
    if match:
        prefix = match.group(1).strip()
        unit = match.group(2).strip()
        if prefix and unit:
            return f"{prefix}\n{unit}"
    return cleaned


def _wrap_table_text(text: str, width: int) -> str:
    """Wrap table text.
    Used to format table text to fit display constraints."""
    if width <= 0:
        return text
    wrapped = textwrap.fill(
        text,
        width=width,
        break_long_words=True,
        break_on_hyphens=False,
    )
    return wrapped


def _wrap_table_text_preserve_newlines(text: str, width: int) -> str:
    """Wrap table text preserve newlines.
    Used to format table text preserve newlines to fit display constraints."""
    if width <= 0:
        return text
    wrapped_lines: List[str] = []
    # Iterate over text.splitlines() or [""] to apply the per-item logic.
    for line in text.splitlines() or [""]:
        if not line:
            wrapped_lines.append("")
            continue
        segments = textwrap.wrap(
            line,
            width=width,
            break_long_words=True,
            break_on_hyphens=False,
        )
        if segments:
            wrapped_lines.extend(segments)
        else:
            wrapped_lines.append("")
    return "\n".join(wrapped_lines)


def _wrap_table_text_limited(
    text: str, width: int, max_lines: int, *, ellipsis: str = "..."
) -> str:
    """Wrap table text limited.
    Used to format table text limited to fit display constraints."""
    if width <= 0:
        return text
    lines = textwrap.wrap(
        text,
        width=width,
        break_long_words=True,
        break_on_hyphens=False,
    )
    if not lines:
        return ""
    if max_lines > 0 and len(lines) > max_lines:
        lines = lines[:max_lines]
        if ellipsis:
            last = lines[-1]
            if width > len(ellipsis):
                allowed = max(0, width - len(ellipsis))
                last = last[:allowed].rstrip()
                lines[-1] = f"{last}{ellipsis}"
            else:
                lines[-1] = ellipsis[:width]
    return "\n".join(lines)


def _fit_column_widths(
    widths: List[int], min_widths: List[int], max_total: int
) -> List[int]:
    """Fit column widths.
    Used to size column widths within layout constraints."""
    adjusted = list(widths)
    total = sum(adjusted)
    if total <= max_total:
        return adjusted
    # Repeat while total > max_total to advance the looped workflow.
    while total > max_total:
        shrinkable = [idx for idx, w in enumerate(adjusted) if w > min_widths[idx]]
        if not shrinkable:
            break
        excess = total - max_total
        shrink_each = max(1, int(math.ceil(excess / len(shrinkable))))
        # Iterate over shrinkable to apply the per-item logic.
        for idx in shrinkable:
            current = adjusted[idx]
            new_value = max(min_widths[idx], current - shrink_each)
            total -= current - new_value
            adjusted[idx] = new_value
            if total <= max_total:
                break
    return adjusted


def _render_timeline_table_matplotlib_pages(
    headers: Sequence[str],
    rows: Sequence[Sequence[Any]],
    numeric_specs: Mapping[str, Union[int, str]],
    title: str,
    subtitle: str,
    dpi: int,
    orientation: str = "portrait",
    column_ids: Optional[Sequence[str]] = None,
    font_family: Optional[str] = None,
    acs_quality: bool = False,
) -> List[Figure]:
    """Render timeline table matplotlib pages.
    Used to draw timeline table matplotlib pages for preview or export workflows."""
    if not headers or not rows:
        return []
    header_texts = ["" if h is None else str(h) for h in headers]
    render_headers = [_format_timeline_header_label(col) for col in header_texts]
    numeric_flags = [col in numeric_specs for col in header_texts]
    formatted_rows: List[List[str]] = []
    # Iterate over rows to apply the per-item logic.
    for row in rows:
        formatted_row: List[str] = []
        # Iterate over indexed elements from zip(header_texts, numeric_flags to apply the per-item logic.
        for idx, (col, is_numeric) in enumerate(zip(header_texts, numeric_flags)):
            raw_value = row[idx] if idx < len(row) else ""
            decimals = numeric_specs.get(col) if is_numeric else None
            formatted_row.append(_format_timeline_table_value(raw_value, decimals))
        formatted_rows.append(formatted_row)

    n_cols = len(header_texts)
    orientation = (orientation or "").strip().lower()
    if orientation not in {"portrait", "landscape"}:
        orientation = "portrait"
    landscape = orientation == "landscape"
    page_size = (11.0, 8.5) if landscape else (8.5, 11.0)
    max_total_chars = 140 if landscape else 110
    notes_max_width = 42 if landscape else 36
    notes_min_width = 18 if landscape else 16
    notes_max_lines = 3

    notes_column_idxs: Set[int] = set()
    # Iterate over indexed elements from header_texts to apply the per-item logic.
    for idx, col_name in enumerate(header_texts):
        if "note" in col_name.lower():
            notes_column_idxs.add(idx)
    if column_ids:
        # Iterate over indexed elements from column_ids to apply the per-item logic.
        for idx, col_id in enumerate(column_ids):
            if col_id is None:
                continue
            col_label = str(col_id).lower()
            if "note" in col_label or "warn" in col_label:
                notes_column_idxs.add(idx)

    def _max_line_length(value: Any) -> int:
        """Perform max line length.
        Used to keep the workflow logic localized and testable."""
        lines = str(value).splitlines()
        if not lines:
            return 0
        return max(len(line) for line in lines)

    max_chars = []
    # Iterate over indexed elements from render_headers to apply the per-item logic.
    for col_idx, col_name in enumerate(render_headers):
        col_values = [col_name] + [
            formatted_row[col_idx] for formatted_row in formatted_rows
        ]
        max_chars.append(max(_max_line_length(val) for val in col_values))

    min_widths = [6 for _ in header_texts]
    widths = []
    # Iterate over indexed elements from max_chars to apply the per-item logic.
    for col_idx, max_len in enumerate(max_chars):
        if col_idx in notes_column_idxs:
            widths.append(max(notes_min_width, min(max_len, notes_max_width)))
        elif numeric_flags[col_idx]:
            widths.append(max(8, min(max_len, 14)))
        else:
            widths.append(max(8, min(max_len, 26 if landscape else 22)))
    widths = _fit_column_widths(widths, min_widths, max_total_chars)

    wrapped_headers = []
    # Iterate over paired elements from multiple sequences to apply the per-item logic.
    for col_name, width in zip(render_headers, widths):
        wrapped_headers.append(_wrap_table_text_preserve_newlines(col_name, width))
    max_header_lines = max(1, max(h.count("\n") + 1 for h in wrapped_headers))

    wrapped_rows: List[List[str]] = []
    row_line_counts: List[int] = []
    # Iterate over formatted_rows to apply the per-item logic.
    for row in formatted_rows:
        wrapped_row: List[str] = []
        max_lines = 1
        # Iterate over indexed elements from row to apply the per-item logic.
        for col_idx, value in enumerate(row):
            text = "" if value is None else str(value)
            if col_idx in notes_column_idxs:
                text = _wrap_table_text_limited(text, widths[col_idx], notes_max_lines)
            elif not numeric_flags[col_idx]:
                text = _wrap_table_text(text, widths[col_idx])
            line_count = max(1, len(text.splitlines()))
            max_lines = max(max_lines, line_count)
            wrapped_row.append(text)
        wrapped_rows.append(wrapped_row)
        row_line_counts.append(max_lines)

    base_font_size = 10.0
    if n_cols > 10:
        base_font_size = max(7.0, 10.0 - 0.35 * (n_cols - 10))
    elif n_cols > 7:
        base_font_size = max(8.0, 10.0 - 0.2 * (n_cols - 7))
    if acs_quality:
        base_font_size = min(10.0, max(8.0, base_font_size))
        header_font_size = min(11.0, base_font_size + 1.0)
        title_font_size = min(10.0, max(8.0, base_font_size + 1.0))
        subtitle_font_size = min(9.5, max(8.0, base_font_size))
    else:
        header_font_size = base_font_size
        title_font_size = max(12.0, base_font_size + 4.0)
        subtitle_font_size = max(9.0, base_font_size + 1.5)

    page_width, page_height = page_size
    margin_in = 0.55
    top_margin_in = 0.45
    wrapped_subtitle = subtitle
    subtitle_lines = 0
    if subtitle:
        available_width_in = page_width - 2 * margin_in
        chars_per_line = max(40, int(available_width_in * 10))
        wrapped_subtitle = _wrap_table_text(subtitle, chars_per_line)
        subtitle_lines = wrapped_subtitle.count("\n") + 1
    title_block_in = (title_font_size / 72.0) * 1.3
    if subtitle:
        title_block_in += subtitle_lines * (subtitle_font_size / 72.0) * 1.2 + 0.08
    table_top_in = top_margin_in + title_block_in
    table_bottom_in = margin_in
    table_height_in = max(1.5, page_height - table_top_in - table_bottom_in)

    base_row_in = (base_font_size / 72.0) * 1.35
    header_line_in = (header_font_size / 72.0) * 1.5
    header_in = header_line_in * max_header_lines

    pages: List[Tuple[List[List[str]], List[float]]] = []
    current_rows: List[List[str]] = []
    current_heights: List[float] = []
    current_height = header_in
    # Iterate over paired elements from multiple sequences to apply the per-item logic.
    for row, line_count in zip(wrapped_rows, row_line_counts):
        row_height = base_row_in * max(1, line_count)
        if current_rows and current_height + row_height > table_height_in:
            pages.append((current_rows, current_heights))
            current_rows = []
            current_heights = []
            current_height = header_in
        current_rows.append(row)
        current_heights.append(row_height)
        current_height += row_height
    if current_rows:
        pages.append((current_rows, current_heights))
    if not pages:
        pages.append((wrapped_rows, [base_row_in for _ in wrapped_rows]))

    if acs_quality:
        acs_font_stack = [
            "Times New Roman",
            "Times",
            "Nimbus Roman",
            "TeX Gyre Termes",
            "DejaVu Serif",
            "serif",
        ]
        if font_family:
            font_candidates = [font_family] + [
                name for name in acs_font_stack if name != font_family
            ]
        else:
            font_candidates = list(acs_font_stack)
        font_stack = _filter_installed_fonts(font_candidates)
        font_family = font_stack[0]
    else:
        font_family = font_family or (
            _preferred_plot_font_stack()[0]
            if _preferred_plot_font_stack()
            else "DejaVu Serif"
        )
        font_stack = [font_family]
    title_weight = "normal" if acs_quality else "bold"
    title_props = font_manager.FontProperties(
        family=font_stack, size=title_font_size, weight=title_weight
    )
    subtitle_props = font_manager.FontProperties(
        family=font_stack, size=subtitle_font_size
    )
    col_widths_rel = [width / sum(widths) for width in widths]
    if acs_quality:
        header_color = "white"
        stripe_color = "white"
        row_sep_color = "#c7c7c7"
        rule_color = "#4f4f4f"
        header_linewidth = 0.6
        body_linewidth = 0.3
        header_padding = 0.1
        body_padding = 0.06
        top_rule_width = 1.2
        mid_rule_width = 0.8
        bottom_rule_width = 1.2
    else:
        header_color = "#e6e9ef"
        stripe_color = "#f7f8fa"
        row_sep_color = "#c5c9d3"
        header_linewidth = 0.6
        body_linewidth = 0.4
        header_padding = 0.08
        body_padding = 0.07

    figures: List[Figure] = []
    # Iterate over pages to apply the per-item logic.
    for page_rows, row_heights in pages:
        fig = Figure(figsize=page_size, dpi=dpi)
        FigureCanvasAgg(fig)
        fig.patch.set_facecolor("white")
        title_y = 1 - (top_margin_in / page_height)
        fig.text(
            margin_in / page_width,
            title_y,
            title or CYCLE_TIMELINE_EXPORT_DEFAULT_TITLE,
            ha="left",
            va="top",
            fontproperties=title_props,
        )
        if subtitle:
            fig.text(
                margin_in / page_width,
                title_y - (title_font_size / 72.0) / page_height * 1.15,
                wrapped_subtitle,
                ha="left",
                va="top",
                fontproperties=subtitle_props,
            )

        left = margin_in / page_width
        bottom = table_bottom_in / page_height
        width = 1 - 2 * (margin_in / page_width)
        height = table_height_in / page_height
        ax = fig.add_axes([left, bottom, width, height])
        ax.axis("off")

        table = ax.table(
            cellText=page_rows,
            colLabels=wrapped_headers,
            colWidths=col_widths_rel,
            cellLoc="center",
            loc="upper left",
            bbox=[0, 0, 1, 1],
        )
        table.auto_set_font_size(False)
        table.set_fontsize(base_font_size)
        if acs_quality:
            col_aligns = ["center"] * n_cols
            header_aligns = ["center"] * n_cols
            header_edges = "horizontal"
            body_edges = "B"
        else:
            col_aligns = ["center"] * n_cols
            header_aligns = ["center"] * n_cols
            header_edges = "closed"
            body_edges = "closed"

        total_height = header_in + sum(row_heights)
        if total_height <= 0:
            total_height = 1.0
        row_height_ratios = [
            height_value / total_height for height_value in row_heights
        ]
        header_ratio = header_in / total_height

        # Iterate over the configured range to apply the per-item logic.
        for col_idx in range(n_cols):
            cell = table[(0, col_idx)]
            cell.set_facecolor(header_color)
            cell.set_edgecolor(row_sep_color)
            cell.set_linewidth(header_linewidth)
            cell.PAD = header_padding
            cell.get_text().set_fontweight("bold")
            cell.get_text().set_ha(header_aligns[col_idx])
            cell.get_text().set_va("center")
            try:
                cell.get_text().set_fontfamily(font_stack)
            except Exception:
                cell.get_text().set_fontfamily(font_family)
            if header_font_size != base_font_size:
                cell.get_text().set_fontsize(header_font_size)
            cell.set_height(header_ratio)
            try:
                cell.visible_edges = header_edges
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Iterate over the configured range to apply the per-item logic.
        for row_idx in range(1, len(page_rows) + 1):
            row_color = (
                "white"
                if acs_quality
                else stripe_color if row_idx % 2 == 0 else "white"
            )
            height_ratio = row_height_ratios[row_idx - 1]
            # Iterate over the configured range to apply the per-item logic.
            for col_idx in range(n_cols):
                cell = table[(row_idx, col_idx)]
                cell.set_facecolor(row_color)
                cell.set_edgecolor(row_sep_color)
                cell.set_linewidth(body_linewidth)
                cell.PAD = body_padding
                try:
                    cell.get_text().set_fontfamily(font_stack)
                except Exception:
                    cell.get_text().set_fontfamily(font_family)
                cell.get_text().set_va("center")
                cell.get_text().set_ha(col_aligns[col_idx])
                cell.set_height(height_ratio)
                try:
                    cell.visible_edges = body_edges
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        if acs_quality:
            try:
                ax.hlines(
                    [1.0, 1.0 - header_ratio, 0.0],
                    xmin=0.0,
                    xmax=1.0,
                    colors=rule_color,
                    linewidths=[top_rule_width, mid_rule_width, bottom_rule_width],
                    transform=ax.transAxes,
                    zorder=5,
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        figures.append(fig)
    return figures


def _svg_safe_text(value: Any) -> str:
    """Perform SVG safe text.
    Used to keep the workflow logic localized and testable."""

    text = "" if value is None else str(value)
    replacements = {
        "&": "and",
        "<": "less than",
        ">": "greater than",
        '"': "",
        "'": "",
    }
    sanitized_parts: List[str] = []
    # Iterate over text to apply the per-item logic.
    for ch in text:
        sanitized_parts.append(replacements.get(ch, ch))
    sanitized = "".join(sanitized_parts)
    sanitized = re.sub(r"\s+", " ", sanitized).strip()
    return sanitized


try:
    _gil_before_scipy = _current_gil_status()
    from scipy.optimize import fsolve  # type: ignore
    from scipy.signal import find_peaks  # type: ignore

    _note_gil_reenable("scipy", _gil_before_scipy)

except Exception as _scipy_exc:  # pragma: no cover - optional dependency

    fsolve = None  # type: ignore

    find_peaks = None  # type: ignore

    _SCIPY_IMPORT_ERROR = _scipy_exc

else:

    _SCIPY_IMPORT_ERROR = None


def _enable_windows_dpi_awareness() -> None:
    """Perform enable windows DPI awareness.
    Used to keep the workflow logic localized and testable."""

    if not sys.platform.startswith("win"):
        return
    if ctypes is None:
        return
    try:
        awareness_func = getattr(
            ctypes.windll.user32, "SetProcessDpiAwarenessContext", None
        )
    except Exception:
        awareness_func = None

    if awareness_func:
        try:
            # DPI_AWARENESS_CONTEXT_PER_MONITOR_AWARE_V2 == -4
            context_value = ctypes.c_void_p((1 << 64) - 4)
            if awareness_func(context_value):
                return
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    try:
        ctypes.windll.shcore.SetProcessDpiAwareness(2)  # PROCESS_PER_MONITOR_DPI_AWARE
        return
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    try:
        ctypes.windll.user32.SetProcessDPIAware()
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass


def _detect_windows_scale(hwnd: Optional[int] = None) -> Optional[float]:
    """Detect windows scale.
    Used to decide runtime capabilities or configuration."""

    if not sys.platform.startswith("win"):
        return None
    if ctypes is None:
        return None

    # Closure captures _detect_windows_scale local context to keep helper logic scoped and invoked directly within _detect_windows_scale.
    def _normalize_ratio(value: float) -> float:
        """Normalize ratio.
        Used to keep ratio consistent across workflows and persistence."""
        return max(0.5, min(value, 4.0))

    try:
        get_dpi_for_window = getattr(ctypes.windll.user32, "GetDpiForWindow", None)
    except Exception:
        get_dpi_for_window = None

    if hwnd and get_dpi_for_window:
        try:
            dpi = get_dpi_for_window(ctypes.c_void_p(int(hwnd)))
            if dpi:
                return _normalize_ratio(dpi / 96.0)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    try:
        get_dpi_for_system = getattr(ctypes.windll.user32, "GetDpiForSystem", None)
    except Exception:
        get_dpi_for_system = None

    if get_dpi_for_system:
        try:
            dpi = get_dpi_for_system()
            if dpi:
                return _normalize_ratio(dpi / 96.0)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    try:
        monitor_from_window = getattr(ctypes.windll.user32, "MonitorFromWindow", None)
    except Exception:
        monitor_from_window = None

    if monitor_from_window:
        try:
            target_hwnd = (
                ctypes.c_void_p(int(hwnd))
                if hwnd
                else ctypes.c_void_p(ctypes.windll.user32.GetDesktopWindow())
            )
            monitor = monitor_from_window(target_hwnd, 2)  # MONITOR_DEFAULTTONEAREST
            dpi_x = ctypes.c_uint()
            dpi_y = ctypes.c_uint()
            get_dpi_for_monitor = getattr(
                ctypes.windll.shcore, "GetDpiForMonitor", None
            )
            if monitor and get_dpi_for_monitor:
                if (
                    get_dpi_for_monitor(
                        monitor, 2, ctypes.byref(dpi_x), ctypes.byref(dpi_y)
                    )
                    == 0
                ):
                    if dpi_x.value:
                        return _normalize_ratio(dpi_x.value / 96.0)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    try:
        get_scale_factor = getattr(
            ctypes.windll.shcore, "GetScaleFactorForDevice", None
        )
        if get_scale_factor:
            scale_pct = get_scale_factor(0)
            if scale_pct:
                return _normalize_ratio(scale_pct / 100.0)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    return None


_enable_windows_dpi_awareness()

MIN_UI_SCALE = 0.75
MAX_UI_SCALE = 2.5


@dataclass(frozen=True)
class DataFingerprint:
    """Immutable key for prepared data cache entries."""

    file_path: str
    sheet_key: Tuple[str, ...]
    columns_key: Tuple[Tuple[str, str], ...]
    cycle_temp_column: str
    elapsed_unit: str
    multi_sheet: bool
    prep_signature: Tuple[Any, ...] = ()


@dataclass(frozen=True)
class CycleFingerprint:
    """Immutable key for cached cycle segmentation + metrics."""

    data_fingerprint: DataFingerprint
    mode: str
    auto_params: Tuple[Any, ...]
    manual_revision: int
    mask_signature: int
    moles_signature: Tuple[Any, ...]
    policy: str


@dataclass(frozen=True)
class CycleSegFingerprint:
    """Immutable key for cached cycle segmentation results."""

    data_fingerprint: DataFingerprint
    mode: str
    auto_params: Tuple[Any, ...]
    manual_revision: int
    mask_signature: int
    policy: str


@dataclass(frozen=True)
class CycleMetricsFingerprint:
    """Immutable key for cached cycle metrics results."""

    seg_fingerprint: CycleSegFingerprint
    moles_signature: Tuple[Any, ...]


@dataclass
class RenderCacheManager:
    """Simple cache manager for prepared series and cycle segmentation."""

    prepared: Dict[DataFingerprint, Dict[str, Any]] = field(default_factory=dict)
    cycles: Dict[CycleFingerprint, Dict[str, Any]] = field(default_factory=dict)
    cycle_segments: Dict[CycleSegFingerprint, Dict[str, Any]] = field(
        default_factory=dict
    )
    cycle_metrics: Dict[CycleMetricsFingerprint, Dict[str, Any]] = field(
        default_factory=dict
    )

    def get_prepared(self, fingerprint: DataFingerprint) -> Optional[Dict[str, Any]]:
        """Return prepared.
        Used to retrieve prepared for downstream logic."""
        return self.prepared.get(fingerprint)

    def set_prepared(
        self, fingerprint: DataFingerprint, payload: Dict[str, Any]
    ) -> None:
        """Set prepared.
        Used to persist prepared into the current state."""
        self.prepared[fingerprint] = payload

    def get_cycles(self, fingerprint: CycleFingerprint) -> Optional[Dict[str, Any]]:
        """Return cycles.
        Used to retrieve cycles for downstream logic."""
        return self.cycles.get(fingerprint)

    def set_cycles(
        self, fingerprint: CycleFingerprint, payload: Dict[str, Any]
    ) -> None:
        """Set cycles.
        Used to persist cycles into the current state."""
        self.cycles[fingerprint] = payload

    def get_cycle_segments(
        self, fingerprint: CycleSegFingerprint
    ) -> Optional[Dict[str, Any]]:
        """Return cycle segments.
        Used to retrieve cycle segmentation for downstream logic."""
        return self.cycle_segments.get(fingerprint)

    def set_cycle_segments(
        self, fingerprint: CycleSegFingerprint, payload: Dict[str, Any]
    ) -> None:
        """Set cycle segments.
        Used to persist cycle segmentation into the current state."""
        self.cycle_segments[fingerprint] = payload

    def get_cycle_metrics(
        self, fingerprint: CycleMetricsFingerprint
    ) -> Optional[Dict[str, Any]]:
        """Return cycle metrics.
        Used to retrieve cycle metrics for downstream logic."""
        return self.cycle_metrics.get(fingerprint)

    def set_cycle_metrics(
        self, fingerprint: CycleMetricsFingerprint, payload: Dict[str, Any]
    ) -> None:
        """Set cycle metrics.
        Used to persist cycle metrics into the current state."""
        self.cycle_metrics[fingerprint] = payload


@dataclass
class RenderContext:
    """Explicit render context passed into plot builders."""

    data_ctx: Dict[str, Any]
    cycle_ctx: Dict[str, Any]
    overlay_ctx: Dict[str, Any]
    gates_ctx: Dict[str, Any]
    style_ctx: Dict[str, Any]
    layout_ctx: Dict[str, Any]
    plot_elements_ctx: Dict[str, Any]


@dataclass
class RenderPacket:
    """Background render packet for UI-thread plot assembly."""

    render_ctx: RenderContext
    data_fingerprint: DataFingerprint
    args: Tuple[Any, ...]
    fig_size: Optional[Tuple[float, float]]
    plot_id: Optional[str]
    target: str = "display"
    perf: Optional[Dict[str, Any]] = None


@dataclass(frozen=True)
class CarbonateInputs:
    """Structured container for the carbonate contamination inputs."""

    mass_naoh_g: float
    purity_wt_percent: float
    ph: float
    temp_c: float
    final_volume_l: float
    pka2: float = 10.33
    naoh_carbonate_wt_percent: Optional[float] = None


@dataclass(frozen=True)
class CarbonateResults:
    """Computed carbonate speciation and contamination outputs."""

    sodium_moles: float
    ratio: float
    hydrogen_moles: float
    hydroxide_moles: float
    bicarbonate_moles: float
    carbonate_moles: float
    sodium_bicarbonate_moles: float
    sodium_carbonate_moles: float
    sodium_carbonate_mass_g: float
    pellet_sodium_carbonate_moles: float
    pellet_sodium_carbonate_mass_g: float


@dataclass(frozen=True)
class CarbonateEquilibriumOptions:
    """Optional equilibrium controls for the augmented carbonate model."""

    pka1: float = 6.35
    kh_co2_m_per_atm: float = 0.033
    pco2_atm: Optional[float] = None
    slurry_ph: Optional[float] = None
    s_hco3_max_m: Optional[float] = None
    s_co3_max_m: Optional[float] = None
    max_iter: int = 100
    tol_mol: float = 1e-9


@dataclass(frozen=True)
class CarbonateAugmentedResults:
    """Expanded contamination outputs including SLE and dissolved CO2 diagnostics."""

    baseline: CarbonateResults
    co2star_moles: float
    dic_moles: float
    co2star_henry_moles: Optional[float]
    co2star_consistency_ratio: Optional[float]
    iterations: int
    sodium_dissolved_moles: float
    bicarbonate_aqueous_moles: float
    carbonate_aqueous_moles: float
    sodium_bicarbonate_solid_moles: float
    sodium_carbonate_solid_moles: float
    sodium_bicarbonate_solid_mass_g: float
    sodium_carbonate_solid_mass_g: float
    solid_total_mass_g: float
    solid_sodium_carbonate_mass_fraction: float


# Advanced Solubility Module (from Advanced Bicarbonate Equilibrium Solubility Calculations)

SOL_SIMULATION_MODES: "OrderedDict[str, Dict[str, Any]]" = OrderedDict(
    [
        (
            "nahco3_dissolution",
            {
                "label": "Start with NaHCO\u2083 solids",
                "description": (
                    "Use the sodium bicarbonate mass and solvent entries to describe the "
                    "batch you are dissolving. Headspace settings inject Henry-law carbon."
                ),
                "assumption": (
                    "CO\u2082 is only available from the headspace slider or forced pH scenario."
                ),
                "steps": ["basis_inputs", "conditions_ready", "run_ready"],
            },
        ),
        (
            "naoh_reaction",
            {
                "label": "Start with NaOH + excess CO\u2082",
                "description": (
                    "Model a complete NaOH neutralization run. Enter the NaOH charge, "
                    "process liquor volume, and the running CO\u2082 total or target pH."
                ),
                "assumption": (
                    "CO\u2082 supply is unconstrained; solver projects speciation at the "
                    "headspace or target pH you provide."
                ),
                "steps": ["reaction_charge", "co2_or_goal", "run_ready"],
            },
        ),
        (
            "contaminated_feed",
            {
                "label": "Contaminated NaHCO\u2083 purification",
                "description": (
                    "Enter the contaminated NaHCO\u2083 mass and desired purity / pH. "
                    "The solver reports how much CO\u2082 and headspace pressure is required."
                ),
                "assumption": (
                    "Input mass already reflects contamination; solver targets the requested "
                    "pH/purity using forced-pH or target controls."
                ),
                "steps": ["basis_inputs", "goal_defined", "run_ready"],
            },
        ),
        (
            "contaminated_bicarb_diagnostic",
            {
                "label": "Contaminated NaHCO\u2083 diagnostic",
                "description": (
                    "Start from lab measurements on a failing NaHCO\u2083 batch (dried-sample "
                    "pH, optional open-system slurry pH) to estimate present Na\u2082CO\u2083 "
                    "and CO\u2082 needed to neutralize carbonate and reach a passing pH."
                ),
                "assumption": (
                    "Slurry pH readings are taken at atmospheric pressure. Without a slurry "
                    "measurement, the dried-sample pH seeds the solver."
                ),
                "steps": [
                    "diagnostic_measurements",
                    "diagnostic_slurry",
                    "diagnostic_target",
                    "run_ready",
                ],
            },
        ),
    ]
)

SOL_DEFAULT_SIM_MODE = next(iter(SOL_SIMULATION_MODES.keys()))

SOL_MODE_STEP_LABELS: Dict[str, str] = {
    "basis_inputs": "Enter NaHCO\u2083 mass and solvent basis",
    "conditions_ready": "Confirm temperature/headspace constraints",
    "reaction_charge": "Enter NaOH charge and process liquor volume",
    "co2_or_goal": "Provide CO\u2082 feed total or desired pH/headspace",
    "goal_defined": "Specify the target pH / purity requirement",
    "run_ready": "Run analysis and review the outputs",
    "diagnostic_measurements": "Record failing sample mass and initial pH measurement",
    "diagnostic_slurry": "Log atmospheric slurry pH (optional but more accurate)",
    "diagnostic_target": "Select the desired pass/final pH for CO\u2082 planning",
}

_BASE_SOL_GUIDE = [
    {"label": "Mass NaHCO\u2083", "keys": ["mass_na_hco3_g"], "mode": "positive"},
    {
        "label": "Water mass or final volume",
        "keys": ["water_mass_g", "solution_volume_l"],
        "mode": "any_positive",
    },
    {"label": "Temperature", "keys": ["temperature_c"], "mode": "positive"},
]

SOL_MODE_INPUT_GUIDE: Dict[str, List[Dict[str, Any]]] = {
    "default": list(_BASE_SOL_GUIDE),
    "nahco3_dissolution": [
        {"label": "NaOH mass", "keys": ["mass_naoh_g"], "mode": "positive"},
        {
            "label": "Pressure drop per cycle (psi)",
            "keys": ["planning_cycle_delta_p_psi"],
            "mode": "positive",
        },
        {
            "label": "Headspace pressure setpoint high (psig)",
            "keys": ["planning_headspace_pressure_high_psi"],
            "mode": "positive",
        },
        {
            "label": "Water mass or final volume",
            "keys": ["water_mass_g", "solution_volume_l"],
            "mode": "any_positive",
        },
        {"label": "Temperature", "keys": ["temperature_c"], "mode": "positive"},
        {
            "label": "Manual CO₂ per cycle (g; overrides ΔP/headspace)",
            "keys": ["planning_cycle_co2_g"],
            "mode": "positive",
            "optional": True,
        },
        {
            "label": "Stop when total CO₂ added reaches (g)",
            "keys": ["planning_stop_co2_added_g"],
            "mode": "positive",
            "optional": True,
        },
        {
            "label": "Stop when pH reaches",
            "keys": ["planning_stop_ph"],
            "mode": "range_optional",
            "range": (0.0, 14.5),
            "optional": True,
        },
    ],
    "naoh_reaction": list(_BASE_SOL_GUIDE)
    + [
        {
            "label": "Initial NaOH mass",
            "keys": ["reaction_naoh_mass_g"],
            "mode": "positive",
        },
        {
            "label": "Process liquor volume",
            "keys": ["reaction_solution_volume_l"],
            "mode": "positive",
        },
        {
            "label": "CO\u2082 total / target pH / forced pH / headspace",
            "keys": [
                "reaction_co2_charged_g",
                "reaction_target_ph",
                "forced_ph_target",
                "headspace_pco2_atm",
            ],
            "mode": "naoh_goal",
        },
    ],
    "contaminated_feed": list(_BASE_SOL_GUIDE)
    + [
        {
            "label": "Target pH or forced pH",
            "keys": ["reaction_target_ph", "forced_ph_target"],
            "mode": "range_any",
            "range": (0.0, 14.0),
        }
    ],
    "contaminated_bicarb_diagnostic": list(_BASE_SOL_GUIDE)
    + [
        {
            "label": "Dried sample mass",
            "keys": ["diag_sample_mass_g"],
            "mode": "positive",
        },
        {
            "label": "Dried sample pH",
            "keys": ["diag_dried_sample_ph"],
            "mode": "range",
            "range": (0.0, 14.5),
        },
        {
            "label": "Atmospheric slurry pH (optional)",
            "keys": ["diag_slurry_ph"],
            "mode": "range_optional",
            "range": (0.0, 14.5),
            "optional": True,
        },
        {
            "label": "Target pass pH",
            "keys": ["diag_target_ph"],
            "mode": "range",
            "range": (0.0, 14.0),
        },
        {
            "label": "CO\u2082 vented fraction (optional)",
            "keys": ["diag_slurry_degas_pct"],
            "mode": "range_optional",
            "range": (0.0, 100.0),
            "optional": True,
        },
    ],
    "reprocessing_diagnostic": list(_BASE_SOL_GUIDE)
    + [
        {
            "label": "Failing slurry pH (atm)",
            "keys": ["diag_slurry_ph"],
            "mode": "range",
            "range": (0.0, 14.5),
        },
        {
            "label": "Target pass pH",
            "keys": ["diag_target_ph"],
            "mode": "range",
            "range": (0.0, 14.0),
        },
    ],
}

SOL_MODE_FIELD_LABELS: Dict[str, str] = {
    "mass_naoh_g": "NaOH mass (g)",
    "mass_na_hco3_g": "NaHCO₃ mass (g)",
    "water_mass_g": "Water mass (g)",
    "solution_volume_l": "Final volume (L)",
    "temperature_c": "Temperature (°C)",
    "initial_ph_guess": "Initial pH guess",
    "forced_ph_target": "Forced pH target",
    "reaction_naoh_mass_g": "Initial NaOH mass (g)",
    "reaction_solution_volume_l": "Process liquor volume (L)",
    "reaction_co2_charged_g": "CO₂ added so far (g)",
    "reaction_target_ph": "Target pH",
    "reaction_final_ph": "Measured final pH",
    "reaction_slurry_ph": "Measured slurry pH",
    "diag_sample_mass_g": "Sample mass (g)",
    "diag_dried_sample_ph": "Dried sample pH",
    "diag_slurry_ph": "Slurry pH (atm)",
    "diag_target_ph": "Desired pass pH",
    "diag_slurry_degas_pct": "Degassed slurry loss (%)",
    "headspace_pco2_atm": "Headspace pCO₂ (atm)",
    "headspace_kh_m_per_atm": "Henry constant (mol·L⁻¹·atm⁻¹)",
    "analysis_headspace_volume_l": "Headspace Volume (L)",
    "planning_headspace_volume_l": "Headspace Volume (L)",
    "planning_headspace_pressure_high_psi": "Headspace pressure setpoint high (psig)",
    "planning_cycle_delta_p_psi": "Pressure drop per cycle (psi)",
    "planning_cycle_co2_g": "Manual CO₂ per cycle (g; overrides ΔP/headspace)",
    "planning_stop_co2_added_g": "Stop when total CO₂ added reaches (g)",
    "planning_stop_ph": "Stop when pH reaches",
}

SOL_MODE_FIELD_HELP: Dict[str, str] = {
    "mass_naoh_g": "Mass of NaOH pellets being charged (grams).",
    "mass_na_hco3_g": "Equivalent NaHCO3 mass used for calculations (auto-derived).",
    "water_mass_g": "Mass of make-up water before dissolution (grams).",
    "solution_volume_l": "Final liquid volume after dissolution (liters).",
    "temperature_c": "Temperature used for equilibration (deg C).",
    "initial_ph_guess": "Initial guess for the Newton solver and forced scenario (pH units).",
    "analysis_headspace_volume_l": "Fixed headspace gas volume used to accumulate excess CO₂ during cycle replay.",
    "planning_headspace_volume_l": "Fixed headspace gas volume used with ΔP to estimate absorbed CO₂ per planning cycle.",
    "planning_headspace_pressure_high_psi": "Headspace pressure setpoint high (psig) used for planning model inputs.",
    "planning_cycle_delta_p_psi": "Pressure drop from the CO₂ setpoint to trough each cycle before re-pressurization (psi).",
    "planning_cycle_co2_g": "Manual per-cycle CO₂ dose (g). When set, it overrides the ΔP/headspace-derived value.",
    "planning_stop_co2_added_g": "Optional stop cap: halt planning projection once total CO₂ added reaches this mass (g).",
    "planning_stop_ph": "Optional stop: halt planning projection once pH is at or below this value.",
}

SOL_PLANNING_DEFAULTS: Dict[str, str] = {
    "planning_cycle_co2_g": "",
    "planning_headspace_volume_l": "1.0",
    "planning_headspace_pressure_high_psi": "750.0",
    "analysis_headspace_volume_l": "1.0",
    "planning_cycle_delta_p_psi": "250.0",
    "planning_stop_co2_added_g": "2000.0",
    "planning_stop_ph": "8.25",
}

PLANNING_STANDARD_REQUIRED_FIELDS = {
    "mass_naoh_g",
    "water_mass_g",
    "solution_volume_l",
    "temperature_c",
    "planning_cycle_delta_p_psi",
    "planning_headspace_volume_l",
}

PLANNING_STANDARD_OPTIONAL_FIELDS = {
    "planning_cycle_co2_g",
    "planning_stop_co2_added_g",
    "planning_stop_ph",
    "headspace_pco2_atm",
    "headspace_kh_m_per_atm",
    "initial_ph_guess",
    "forced_ph_target",
}

MODEL_REQUIRED_FIELDS: Dict[str, Set[str]] = {
    "debye_huckel_full": PLANNING_STANDARD_REQUIRED_FIELDS,
    "debye_huckel_capped": PLANNING_STANDARD_REQUIRED_FIELDS,
    "davies_limited": PLANNING_STANDARD_REQUIRED_FIELDS,
    "pitzer_lite": PLANNING_STANDARD_REQUIRED_FIELDS,
    "aqion_closed": PLANNING_STANDARD_REQUIRED_FIELDS,
    "naoh_co2_pitzer_hmw": {
        "mass_naoh_g",
        "water_mass_g",
        "solution_volume_l",
        "temperature_c",
        "planning_headspace_volume_l",
        "planning_headspace_pressure_high_psi",
        "planning_cycle_delta_p_psi",
    },
}

MODEL_OPTIONAL_FIELDS: Dict[str, Set[str]] = {
    "debye_huckel_full": PLANNING_STANDARD_OPTIONAL_FIELDS,
    "debye_huckel_capped": PLANNING_STANDARD_OPTIONAL_FIELDS,
    "davies_limited": PLANNING_STANDARD_OPTIONAL_FIELDS,
    "pitzer_lite": PLANNING_STANDARD_OPTIONAL_FIELDS,
    "aqion_closed": PLANNING_STANDARD_OPTIONAL_FIELDS,
    "naoh_co2_pitzer_hmw": {
        "planning_cycle_co2_g",
        "planning_stop_co2_added_g",
        "planning_stop_ph",
    },
}

SOL_WORKFLOW_TEMPLATES: "OrderedDict[str, Dict[str, Any]]" = OrderedDict(
    [
        (
            "Planning",
            {
                "label": "Planning workflow",
                "description": (
                    "Plan a NaHCO₃ dissolution run by defining the solid charge, solvent, "
                    "temperature, and a target pH before any cycle data exists."
                ),
                "assumption": (
                    "Headspace CO₂ is pressure-controlled at the setpoint; each cycle pulls ΔP worth of CO₂ before being re-pressurized."
                ),
                "context_start": (
                    "Plan for a starting point that is 100% NaOH with zero bicarbonate/carbonate; "
                    "each cycle draws down the headspace by the provided ΔP before recharge."
                ),
                "context_goal": (
                    "Project how pH/speciation drift will move from ~14 toward ~8 as each pressure-driven CO₂ increment is applied."
                ),
                "steps": [
                    "basis_inputs",
                    "conditions_ready",
                    "goal_defined",
                    "co2_or_goal",
                    "run_ready",
                ],
                "prompt": "Capture NaHCO₃, solvent, and target pH/headspace details to estimate the CO₂ demand.",
                "expectations": "Estimate the CO₂ mass needed to neutralize the selected NaOH/NaHCO₃ basis and surface the projected steady-state pH.",
                "mode_key": "nahco3_dissolution",
                "guide_mode": "nahco3_dissolution",
                "input_include_keys": [
                    "mass_naoh_g",
                    "water_mass_g",
                    "solution_volume_l",
                    "temperature_c",
                    "planning_cycle_delta_p_psi",
                    "planning_headspace_pressure_high_psi",
                    "planning_cycle_co2_g",
                    "planning_stop_co2_added_g",
                    "planning_stop_ph",
                ],
                "input_extra_fields": [
                    ("initial_ph_guess", "Initial pH guess", False),
                    ("forced_ph_target", "Forced pH target", False),
                ],
                "include_shared_slider": False,
                "include_headspace": True,
            },
        ),
        (
            "Analysis",
            {
                "label": "Analysis workflow",
                "description": (
                    "Use cycle analysis results or manual NaOH/CO₂ inputs to evaluate the current "
                    "speciation and project future CO₂ dosing."
                ),
                "assumption": (
                    "Cycle-derived CO₂ totals drive the speciation; the slider sets the target pH for guidance."
                ),
                "context_start": (
                    "Start from the imported cycle analysis (or manual NaOH + CO₂ entries) assuming "
                    "100% NaOH at cycle zero and replay each 250 PSI addition."
                ),
                "context_goal": (
                    "Summarize the per-cycle pH/speciation trend and report how much CO₂ is required "
                    "to reach the selected target slider."
                ),
                "steps": ["reaction_charge", "co2_or_goal", "run_ready"],
                "prompt": "Import or enter reaction data and a target pH to compare speciation across cycles.",
                "expectations": "Review per-cycle speciation (pH, carbonate fractions, warnings) and highlight how much CO₂ must be added to reach the target pH.",
                "mode_key": "naoh_reaction",
                "guide_mode": "naoh_reaction",
                "input_include_keys": [
                    "reaction_naoh_mass_g",
                    "reaction_solution_volume_l",
                    "reaction_co2_charged_g",
                    "reaction_target_ph",
                ],
                "input_extra_fields": [
                    ("reaction_final_ph", "Measured final pH", False),
                    ("reaction_slurry_ph", "Measured slurry pH", False),
                    ("analysis_headspace_volume_l", "Headspace Volume (L)", True),
                ],
                "include_shared_slider": True,
            },
        ),
        (
            "Reprocessing",
            {
                "label": "Reprocessing workflow",
                "description": (
                    "Define the NaHCO₃ mass, solvent, and current pH of a failing batch "
                    "and run the slider toward the pass pH to quantify the CO₂ required."
                ),
                "assumption": (
                    "The batch starts as a NaHCO₃ slurry at the reported pH; the slider controls the pass target."
                ),
                "context_start": (
                    "Assume a batch that begins with a known NaHCO₃ mass dissolved into user-supplied water at the selected pH."
                ),
                "context_goal": (
                    "Calculate the CO₂ needed (via the target slider) to drive the slurry down to the requested pass pH."
                ),
                "steps": [
                    "diagnostic_measurements",
                    "diagnostic_slurry",
                    "diagnostic_target",
                    "run_ready",
                ],
                "prompt": "Record the batch mass, solvent, and measured pH, then use the slider to set the pass pH and calculate additional CO₂.",
                "expectations": "Surface the current carbonate state, the assumed starting composition, and the CO₂ dose needed to hit the pass pH.",
                "mode_key": "contaminated_bicarb_diagnostic",
                "guide_mode": "reprocessing_diagnostic",
                "input_include_keys": [
                    "mass_na_hco3_g",
                    "solution_volume_l",
                    "temperature_c",
                    "diag_slurry_ph",
                    "diag_target_ph",
                ],
                "input_extra_fields": [],
                "include_shared_slider": True,
            },
        ),
    ]
)

SOL_WORKFLOW_DEFAULT = next(iter(SOL_WORKFLOW_TEMPLATES.keys()))

_SOL_IDEAL_GAS_R_L_ATM_PER_MOLK = 0.082057


def _clamp_temperature(temp_c: float) -> float:
    """Clamp temperature.
    Used to keep temperature within safe bounds."""
    return max(-5.0, min(80.0, temp_c))


def _estimate_temperature_adjusted_pka(
    temp_c: float, coeffs: Tuple[float, float, float]
) -> float:
    """Estimate temperature adjusted pKa.
    Used to approximate temperature adjusted pKa for model workflows."""
    t = _clamp_temperature(temp_c)
    a, b, c = coeffs
    return max(0.0, a * (t**2) + b * t + c)


def _resolve_solubility_constants(
    params: SolubilityInputs,
    math_logger: Optional[SolubilityMathLogger] = None,
    section: str = "Speciation",
) -> Tuple[float, float, float, List[str]]:
    """Resolve solubility constants.
    Used to compute solubility constants before rendering or export."""
    notes: List[str] = []
    if params.use_temperature_adjusted_constants:
        pka1 = _estimate_temperature_adjusted_pka(params.temperature_c, SOL_PKA1_COEFFS)
        pka2 = _estimate_temperature_adjusted_pka(params.temperature_c, SOL_PKA2_COEFFS)
        pkw_value = carbonate_pkw_from_temp(params.temperature_c)
        kw = 10.0 ** (-pkw_value)
        notes.append(
            f"Equilibrium constants adjusted for {params.temperature_c:.1f} °C."
        )
    else:
        pka1 = -math.log10(SOL_KA1)
        pka2 = -math.log10(SOL_KA2)
        kw = SOL_KW
        pkw_value = -math.log10(SOL_KW)
        notes.append("Equilibrium constants fixed at 25 °C.")
    ka1 = 10.0 ** (-pka1)
    ka2 = 10.0 ** (-pka2)
    if math_logger:
        ka1_steps = [
            SolubilityMathStep(
                title="Definition",
                expression="Ka1 = 10^-pKa1",
                latex=r"K_{a1}=10^{-pK_{a1}}",
                detail="Convert the reported pKa1 into Ka1.",
            ),
            SolubilityMathStep(
                title="Substitute pKa1",
                expression=f"Ka1 = 10^(-{pka1:.4f})",
                latex=rf"K_{{a1}} = 10^{{-{pka1:.4f}}}",
            ),
            SolubilityMathStep(
                title="Evaluate",
                expression=f"Ka1 = {ka1:.3e}",
            ),
        ]
        math_logger.log(
            section,
            "Ka1",
            f"10^-pKa1 = 10^-{pka1:.4f}",
            f"{ka1:.3e}",
            steps=ka1_steps,
        )
        ka2_steps = [
            SolubilityMathStep(
                title="Definition",
                expression="Ka2 = 10^-pKa2",
                latex=r"K_{a2}=10^{-pK_{a2}}",
                detail="Convert the reported pKa2 into Ka2.",
            ),
            SolubilityMathStep(
                title="Substitute pKa2",
                expression=f"Ka2 = 10^(-{pka2:.4f})",
                latex=rf"K_{{a2}} = 10^{{-{pka2:.4f}}}",
            ),
            SolubilityMathStep(
                title="Evaluate",
                expression=f"Ka2 = {ka2:.3e}",
            ),
        ]
        math_logger.log(
            section,
            "Ka2",
            f"10^-pKa2 = 10^-{pka2:.4f}",
            f"{ka2:.3e}",
            steps=ka2_steps,
        )
        kw_detail = (
            f"Temperature-adjusted correlation ({params.temperature_c:.1f} °C)"
            if params.use_temperature_adjusted_constants
            else "Fixed 25 °C reference"
        )
        kw_steps = [
            SolubilityMathStep(
                title="Definition",
                expression="Kw = 10^-pKw",
                latex=r"K_w = 10^{-pK_w}",
                detail=kw_detail,
            ),
            SolubilityMathStep(
                title="Substitute pKw",
                expression=f"Kw = 10^(-{pkw_value:.4f})",
                latex=rf"K_w = 10^{{-{pkw_value:.4f}}}",
            ),
            SolubilityMathStep(
                title="Evaluate",
                expression=f"Kw = {kw:.3e}",
            ),
        ]
        math_logger.log(
            section,
            "Kw",
            "Kw from temperature correlation",
            f"{kw:.3e}",
            steps=kw_steps,
        )
    return ka1, ka2, kw, notes


@dataclass
class SolubilitySolverInputs:
    params: SolubilityInputs
    forced_target: Optional[float]
    sweep_low: float
    sweep_high: float
    sweep_steps: int
    reaction_naoh_mass: Optional[float]
    reaction_solution_volume: Optional[float]
    reaction_co2_g: Optional[float]
    reaction_final_ph: Optional[float]
    reaction_slurry_ph: Optional[float]
    reaction_target_ph: Optional[float]
    diagnostic_data: Optional[Dict[str, Any]]
    mode_key: str
    model_key: str
    model_options: Optional[ModelOptions]
    guide_key: str
    workflow_key: str
    assumed_solution_volume_l: Optional[float]
    failing_ph: Optional[float]
    solvent_basis: Optional[str]
    solvent_basis_value: Optional[float]


@dataclass
class SolubilityStructuredPayload:
    highlights: Dict[str, str]
    warnings: List[str] = field(default_factory=list)
    species_rows: List[Dict[str, str]] = field(default_factory=list)
    saturation_rows: List[Dict[str, str]] = field(default_factory=list)
    sensitivity_rows: List[Dict[str, str]] = field(default_factory=list)
    sweep_rows: List[Dict[str, str]] = field(default_factory=list)
    sweep_plot: List[Dict[str, float]] = field(default_factory=list)
    assumptions: List[str] = field(default_factory=list)
    chart_data: Dict[str, Any] = field(default_factory=dict)
    reaction_guidance: Optional[Dict[str, Any]] = None
    tracking_entries: List[Dict[str, Any]] = field(default_factory=list)
    cycle_timeline: Optional[List[Dict[str, Any]]] = None
    planner_context: List[str] = field(default_factory=list)
    math_sections: List[Dict[str, Any]] = field(default_factory=list)
    math_preview_lines: List[str] = field(default_factory=list)
    mode_context: Dict[str, str] = field(default_factory=dict)
    workflow_key: str = ""
    guide_key: str = ""
    assumed_solution_volume_l: Optional[float] = None
    co2_guidance: str = ""
    reprocessing_context: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Perform to dict.
        Used to keep the workflow logic localized and testable."""
        return asdict(self)


def _basic_carbonate_constants(
    temperature_c: Optional[float], use_temp_adjusted_constants: bool
) -> Tuple[float, float, float]:
    """Perform basic carbonate constants.
    Used to keep the workflow logic localized and testable."""

    temp = 25.0 if temperature_c is None else _clamp_temperature(float(temperature_c))
    if use_temp_adjusted_constants:
        pka1 = _estimate_temperature_adjusted_pka(temp, SOL_PKA1_COEFFS)
        pka2 = _estimate_temperature_adjusted_pka(temp, SOL_PKA2_COEFFS)
        pkw_value = carbonate_pkw_from_temp(temp)
        kw = 10.0 ** (-pkw_value)
    else:
        pka1 = -math.log10(SOL_KA1)
        pka2 = -math.log10(SOL_KA2)
        kw = SOL_KW
    ka1 = 10.0 ** (-pka1)
    ka2 = 10.0 ** (-pka2)
    return ka1, ka2, kw


def _solubility_fractional_carbon(concentrations: Dict[str, float]) -> Dict[str, float]:
    """Perform solubility fractional carbon.
    Used to keep the workflow logic localized and testable."""
    carbon_total = (
        concentrations.get("H2CO3", 0.0)
        + concentrations.get("HCO3-", 0.0)
        + concentrations.get("CO3^2-", 0.0)
    )
    if carbon_total <= 0:
        return {species: 0.0 for species in ("H2CO3", "HCO3-", "CO3^2-")}
    return {
        "H2CO3": concentrations.get("H2CO3", 0.0) / carbon_total,
        "HCO3-": concentrations.get("HCO3-", 0.0) / carbon_total,
        "CO3^2-": concentrations.get("CO3^2-", 0.0) / carbon_total,
    }


def _solubility_mass_concentrations(
    concentrations: Dict[str, float],
) -> Dict[str, float]:
    """Perform solubility mass concentrations.
    Used to keep the workflow logic localized and testable."""
    return {
        species: concentrations[species] * SOL_SPECIES_MOLAR_MASSES.get(species, 0.0)
        # Iterate to apply the per-item logic.
        for species in concentrations
    }


def _solubility_log_result_math(
    *,
    logger: Optional[SolubilityMathLogger],
    section: str,
    params: SolubilityInputs,
    result: SolubilitySpeciationResult,
) -> None:
    """Perform solubility log result math.
    Used to keep the workflow logic localized and testable."""
    if not logger:
        return

    def _step(
        title: str,
        expression: str = "",
        detail: str = "",
        latex: str = "",
        units: str = "",
    ) -> SolubilityMathStep:
        """Perform step.
        Used to keep the workflow logic localized and testable."""
        return SolubilityMathStep(
            title=title, expression=expression, detail=detail, latex=latex, units=units
        )

    volume_l = params.volume_l()
    total_moles = params.total_moles()
    base_conc = total_moles / volume_l
    headspace = params.headspace_carbon_contribution()
    rich_mole_steps = (
        [
            _step(
                "Start with definition",
                "n = m / MW",
                "Moles equal sample mass divided by molecular weight.",
                latex=r"n=\frac{m}{MW}",
                units="mol",
            ),
            _step(
                "Substitute values",
                f"n = {params.mass_na_hco3_g:.4f} g / {SOL_MW_NAHCO3:.4f} g/mol",
                "Keep explicit units to verify cancellation.",
                units="g / (g/mol)",
            ),
            _step(
                "Cancel units",
                f"n = ({params.mass_na_hco3_g:.4f} / {SOL_MW_NAHCO3:.4f}) mol",
                "Grams cancel, leaving mol.",
                units="mol",
            ),
            _step(
                "Compute value",
                f"n = {total_moles:.6f} mol",
                "Final resolved NaHCO3 moles.",
                units="mol",
            ),
        ]
        if params.mass_na_hco3_g is not None
        else []
    )
    logger.log(
        section,
        "NaHCO3 moles",
        f"n = m / MW = {params.mass_na_hco3_g:.4f} g / {SOL_MW_NAHCO3:.4f} g/mol",
        f"{total_moles:.6f}",
        "mol",
        steps=rich_mole_steps,
    )
    if params.solution_volume_l is not None:
        volume_expr = "User-specified final volume"
        volume_steps = [
            _step(
                "User-entered value",
                f"V = {volume_l:.4f} L",
                "Final solution volume provided directly by the user.",
                units="L",
            )
        ]
    elif params.water_mass_g is not None:
        volume_expr = (
            f"V = m_water / rho = {params.water_mass_g:.2f} g / "
            f"{SOL_WATER_DENSITY_25C_G_PER_ML:.4f} g/mL / 1000"
        )
        raw_volume_ml = params.water_mass_g / SOL_WATER_DENSITY_25C_G_PER_ML
        volume_steps = [
            _step(
                "Definition",
                "V = m_water / rho_water",
                "Convert water mass to volume using density.",
                latex=r"V=\frac{m_{water}}{\rho_{water}}",
                units="mL",
            ),
            _step(
                "Substitute values",
                f"V = {params.water_mass_g:.2f} g / "
                f"{SOL_WATER_DENSITY_25C_G_PER_ML:.4f} g/mL",
                units="g/(g/mL)",
            ),
            _step(
                "Convert to liters",
                f"{raw_volume_ml:.2f} mL / 1000 = {volume_l:.4f} L",
                "Divide by 1000 to convert mL to liters.",
                units="L",
            ),
        ]
    else:
        volume_expr = "Volume derived from stored defaults"
        volume_steps = [
            _step(
                "Estimated volume",
                f"V = {volume_l:.4f} L",
                "Using stored defaults for slurry density and fill.",
                units="L",
            )
        ]
    logger.log(
        section,
        "Solution volume",
        volume_expr,
        f"{volume_l:.4f}",
        "L",
        steps=volume_steps,
    )
    base_conc_steps = [
        _step(
            "Definition",
            "[Na+] = n / V",
            "Base sodium concentration equals moles divided by volume.",
            latex=r"[Na^+] = \frac{n}{V}",
            units="mol/L",
        ),
        _step(
            "Substitute values",
            f"[Na+] = {total_moles:.6f} mol / {volume_l:.6f} L",
            units="mol/L",
        ),
        _step(
            "Evaluate",
            f"[Na+] = {base_conc:.6e} mol/L",
            units="mol/L",
        ),
    ]
    logger.log(
        section,
        "Base Na+ concentration",
        f"[Na+] = n / V = {total_moles:.6f} mol / {volume_l:.6f} L",
        f"{base_conc:.6e}",
        "mol/L",
        steps=base_conc_steps,
    )
    if headspace > 0 and params.headspace_pco2_atm and params.headspace_kh_m_per_atm:
        headspace_steps = [
            _step(
                "Henry's law",
                "C = pCO2 * KH",
                "Relate headspace partial pressure to dissolved concentration.",
                latex=r"C = p_{\mathrm{CO_2}} \cdot K_H",
                units="mol/L",
            ),
            _step(
                "Substitute values",
                f"C = {params.headspace_pco2_atm:.3f} atm * "
                f"{params.headspace_kh_m_per_atm:.4f} mol/(L*atm)",
                units="mol/L",
            ),
            _step(
                "Evaluate",
                f"C = {headspace:.6e} mol/L",
                units="mol/L",
            ),
        ]
        logger.log(
            section,
            "Headspace carbon",
            f"C_headspace = pCO2 * KH = {params.headspace_pco2_atm:.3f} atm * "
            f"{params.headspace_kh_m_per_atm:.4f} mol/(L*atm)",
            f"{headspace:.6e}",
            "mol/L",
            steps=headspace_steps,
        )
    h2co3_conc = result.concentrations_m.get("H2CO3", 0.0)
    hco3_conc = result.concentrations_m.get("HCO3-", 0.0)
    co3_conc = result.concentrations_m.get("CO3^2-", 0.0)
    ric_steps = [
        _step(
            "Definition",
            "CT = [H2CO3] + [HCO3-] + [CO3^2-]",
            "Total resolved inorganic carbon sums the carbonate species.",
            latex=r"C_T=[H_2CO_3]+[HCO_3^-]+[CO_3^{2-}]",
            units="mol/L",
        ),
        _step(
            "Substitute values",
            f"CT = {h2co3_conc:.6e} + {hco3_conc:.6e} + {co3_conc:.6e}",
            units="mol/L",
        ),
        _step(
            "Evaluate",
            f"CT = {result.total_carbon_m:.6e} mol/L",
            units="mol/L",
        ),
    ]
    logger.log(
        section,
        "Resolved inorganic carbon",
        "Sum(H2CO3 + HCO3- + CO3^2-)",
        f"{result.total_carbon_m:.6e}",
        "mol/L",
        steps=ric_steps,
    )
    h_conc = result.concentrations_m.get("H+", 0.0)
    ph_steps = [
        _step(
            "Definition",
            "pH = -log10[H+]",
            "Negative log of the proton activity.",
            latex=r"pH = -\log_{10}[H^+]",
        )
    ]
    if h_conc > 0:
        ph_steps.append(
            _step(
                "Substitute [H+]",
                f"pH = -log10({h_conc:.3e})",
            )
        )
        ph_steps.append(
            _step(
                "Evaluate",
                f"pH = {result.ph:.4f}",
            )
        )
    else:
        ph_steps.append(
            _step(
                "Evaluate",
                f"pH = {result.ph:.4f}",
                "Derived from electroneutrality due to extremely low [H+].",
            )
        )
    logger.log(
        section,
        "Equilibrium pH",
        "pH = -log10[H+]",
        f"{result.ph:.4f}",
        steps=ph_steps,
    )
    ionic_species = (
        ("Na+", 1),
        ("H+", 1),
        ("HCO3-", -1),
        ("CO3^2-", -2),
        ("OH-", -1),
    )
    ionic_terms = []
    # Iterate over ionic_species to apply the per-item logic.
    for species, charge in ionic_species:
        conc = result.concentrations_m.get(species, 0.0)
        ionic_terms.append((species, conc, charge, conc * (charge**2)))
    ionic_detail = " + ".join(
        f"{name}: {conc:.3e}*(|{charge}|^2)" for name, conc, charge, _ in ionic_terms
    )
    ionic_steps = [
        _step(
            "Definition",
            "I = 0.5 * Sum(c_i * z_i^2)",
            "Half the sum of each ion concentration times charge squared.",
            latex=r"I = \frac{1}{2}\sum c_i z_i^2",
            units="mol/L",
        ),
        _step(
            "Substitute values",
            ionic_detail,
            units="mol/L",
        ),
        _step(
            "Evaluate",
            f"I = {result.ionic_strength:.6e} mol/L",
            units="mol/L",
        ),
    ]
    hco3_conc = result.concentrations_m.get("HCO3-", 0.0)
    co3_conc = result.concentrations_m.get("CO3^2-", 0.0)
    oh_conc = result.concentrations_m.get("OH-", 0.0)
    h_conc_value = result.concentrations_m.get("H+", 0.0)
    alk_mol = hco3_conc + 2.0 * co3_conc + oh_conc - h_conc_value
    alk_steps = [
        _step(
            "Definition",
            "Alk = [HCO3-] + 2[CO3^2-] + [OH-] - [H+]",
            "Charge balance expression for alkalinity.",
            latex=r"\text{Alk} = [HCO_3^-] + 2[CO_3^{2-}] + [OH^-] - [H^+]",
            units="mol/L",
        ),
        _step(
            "Substitute values",
            f"Alk = {hco3_conc:.6e} + 2*{co3_conc:.6e} + {oh_conc:.6e} - {h_conc_value:.6e}",
            units="mol/L",
        ),
        _step(
            "Convert to meq/L",
            f"{alk_mol:.6e} mol/L * 1000 = {result.alkalinity_meq_per_l:.2f} meq/L",
            units="meq/L",
        ),
    ]
    cation_sum = result.concentrations_m.get("Na+", 0.0) + result.concentrations_m.get(
        "H+", 0.0
    )
    anion_sum = (
        result.concentrations_m.get("HCO3-", 0.0)
        + 2.0 * result.concentrations_m.get("CO3^2-", 0.0)
        + result.concentrations_m.get("OH-", 0.0)
    )
    charge_steps = [
        _step(
            "Definition",
            "Residual = (Na+ + H+) - (HCO3- + 2CO3^2- + OH-)",
            "Difference between total positive and negative charge.",
            units="mol/L",
        ),
        _step(
            "Substitute values",
            f"{cation_sum:.6e} - {anion_sum:.6e}",
            units="mol/L",
        ),
        _step(
            "Evaluate",
            f"{result.charge_balance_residual:+.2e} mol/L",
            units="mol/L",
        ),
    ]
    logger.log(
        section,
        "Ionic strength",
        "I = 0.5 * Sum(c_i z_i^2)",
        f"{result.ionic_strength:.6e}",
        "mol/L",
        steps=ionic_steps,
    )
    logger.log(
        section,
        "Alkalinity",
        "[HCO3-] + 2[CO3^2-] + [OH-] - [H+]",
        f"{result.alkalinity_meq_per_l:.2f}",
        "meq/L",
        steps=alk_steps,
    )
    logger.log(
        section,
        "Charge balance residual",
        "Na+ + H+ - (HCO3- + 2CO3^2- + OH-)",
        f"{result.charge_balance_residual:+.2e}",
        "mol/L",
        steps=charge_steps,
    )
    # Iterate over items from result.saturation_indices to apply the per-item logic.
    for salt, ratio in result.saturation_indices.items():
        if ratio > 1.0:
            saturation_detail = "Supersaturated (ratio > 1)."
        elif ratio < 1.0:
            saturation_detail = "Undersaturated (ratio < 1)."
        else:
            saturation_detail = "At equilibrium (ratio ≈ 1)."
        sat_steps = [
            _step(
                "Definition",
                "SI = ionic product / Ksp",
                "Compare ion activity product to solubility product.",
                latex=r"SI = \frac{Q}{K_{sp}}",
            ),
            _step(
                "Evaluate",
                f"SI = {ratio:.3f}",
                saturation_detail,
            ),
        ]
        logger.log(
            section,
            f"{salt} saturation index",
            "SI = ionic product / Ksp",
            f"{ratio:.3f}",
            steps=sat_steps,
        )
    frac_line = ", ".join(
        f"{species} {fraction*100:.2f}%"
        # Iterate to apply the per-item logic.
        for species, fraction in result.fractional_carbon.items()
    )
    carbon_steps = [
        _step(
            "Definition",
            "Fraction = species / total inorganic carbon",
            "Each species share relative to CT.",
        )
    ]
    # Iterate over items from result.fractional_carbon to apply the per-item logic.
    for species, fraction in result.fractional_carbon.items():
        carbon_steps.append(
            _step(
                f"{species} contribution",
                f"{fraction*100:.2f} %",
                units="%",
            )
        )
    logger.log(section, "Carbon fractions", frac_line, "", "%", steps=carbon_steps)
    ordered = ["Na+", "H+", "HCO3-", "CO3^2-", "H2CO3", "OH-"]
    # Iterate over ordered to apply the per-item logic.
    for species in ordered:
        conc = result.concentrations_m.get(species, 0.0)
        moles = result.moles.get(species, 0.0)
        balance_steps = [
            _step(
                "Concentration",
                f"[{species}] = {conc:.6e} mol/L",
                units="mol/L",
            ),
            _step(
                "Convert to moles",
                f"n = [{species}] * V = {conc:.6e} * {volume_l:.6f}",
                latex=r"n = C \cdot V",
                units="mol",
            ),
            _step(
                "Evaluate",
                f"n = {moles:.6e} mol",
                units="mol",
            ),
        ]
        logger.log(
            section,
            f"{species} balance",
            f"[{species}] = {conc:.6e} mol/L; n = [{species}] * V",
            f"{moles:.6e}",
            "mol",
            steps=balance_steps,
        )


def _solubility_charge_balance(concentrations: Dict[str, float]) -> float:
    """Perform solubility charge balance.
    Used to keep the workflow logic localized and testable."""
    left = concentrations.get("Na+", 0.0) + concentrations.get("H+", 0.0)
    right = (
        concentrations.get("HCO3-", 0.0)
        + 2.0 * concentrations.get("CO3^2-", 0.0)
        + concentrations.get("OH-", 0.0)
    )
    return left - right


def _solubility_build_warnings(
    params: SolubilityInputs,
    saturation_indices: Dict[str, float],
    charge_residual: float,
    target_total_carbon: float,
    resolved_total_carbon: float,
    ionic_strength_capped: bool,
    ph: float,
    alkalinity_meq: float,
    ionic_strength: float,
    *,
    dissolved_fraction: Optional[float] = None,
    saturation_enforced: Optional[Sequence[str]] = None,
) -> List[str]:
    """Build warnings.
    Used by solubility workflows to build warnings."""
    warnings: List[str] = []
    # Iterate over items from saturation_indices to apply the per-item logic.
    for salt, ratio in saturation_indices.items():
        if ratio > 1.0:
            warnings.append(f"{salt} supersaturated (SI={ratio:.2f}).")
    if abs(charge_residual) > 1e-6:
        warnings.append(
            "Charge balance residual "
            f"{charge_residual:+.2e} mol/L exceeds tight tolerance. "
            "This is the net positive minus negative ionic charge; large values "
            "mean the solution is not electrically neutral and the speciation may "
            "be unreliable."
        )
    if target_total_carbon > 0:
        deviation = (
            abs(resolved_total_carbon - target_total_carbon) / target_total_carbon
        )
        if deviation > 0.01:
            warnings.append(
                f"Total inorganic carbon deviates by {deviation*100:.1f}% from target."
            )
    if ionic_strength_capped and params.ionic_strength_cap is not None:
        warnings.append(
            f"Ionic strength capped at {params.ionic_strength_cap:.3f} M per user preference."
        )
    if ionic_strength > SOL_DAVIES_LIMIT:
        warnings.append(
            "Ionic strength exceeds the Davies activity range; γ estimates are extrapolated."
        )
    if ionic_strength > SOL_ACTIVITY_EXTRAPOLATION_LIMIT:
        warnings.append(
            "Ionic strength beyond validated range (>2.5 M); speciation error risk is high."
        )
    if ph < 5.5 and alkalinity_meq > 1.0:
        warnings.append(
            "Alkalinity indicates excess OH⁻ while pH is acidic; verify CO₂/headspace inputs."
        )
    if ph > 8.5 and alkalinity_meq < -0.5:
        warnings.append(
            "Negative alkalinity with basic pH detected; check dissolved CO₂ and measurement data."
        )
    if saturation_enforced:
        salts = ", ".join(sorted(saturation_enforced))
        warnings.append(
            f"Saturation limits enforced for {salts}; excess solid remains undissolved."
        )
    if (
        dissolved_fraction is not None
        and params.mass_na_hco3_g > 0
        and dissolved_fraction < 0.999
    ):
        undissolved_pct = max(0.0, (1.0 - dissolved_fraction) * 100.0)
        warnings.append(
            f"Only {dissolved_fraction*100:.1f}% of charged NaHCO₃ dissolved; "
            f"{undissolved_pct:.1f}% retained as solids."
        )
    return warnings


def _solubility_finalize_result(
    *,
    params: SolubilityInputs,
    volume: float,
    ionic_strength: float,
    ph: float,
    concentrations: Dict[str, float],
    moles: Dict[str, float],
    activity_coeffs: Dict[str, float],
    saturation_indices: Dict[str, float],
    constant_notes: List[str],
    ionic_strength_capped: bool,
    kw_value: float,
    dissolved_na_moles: Optional[float] = None,
    saturation_enforced: Optional[Sequence[str]] = None,
    fixed_co2_boundary: Optional[float] = None,
    speciation_mode: Optional[str] = None,
) -> SolubilitySpeciationResult:
    """Perform solubility finalize result.
    Used to keep the workflow logic localized and testable."""
    mode = _normalize_speciation_mode(
        speciation_mode or getattr(params, "speciation_mode", None)
    )
    fractional = _solubility_fractional_carbon(concentrations)
    mass_conc = _solubility_mass_concentrations(concentrations)
    resolved_h = 10.0 ** (-ph) if ph > 0 else concentrations.get("H+", 0.0)
    if not (resolved_h is not None and math.isfinite(resolved_h) and resolved_h > 0):
        resolved_h = concentrations.get("H+", 0.0)
    resolved_oh = (
        kw_value / resolved_h
        if resolved_h and math.isfinite(resolved_h) and resolved_h > 0
        else concentrations.get("OH-", 0.0)
    )
    alkalinity_meq = (
        concentrations.get("HCO3-", 0.0)
        + 2.0 * concentrations.get("CO3^2-", 0.0)
        + resolved_oh
        - resolved_h
    ) * 1000.0
    total_carbon = (
        concentrations.get("H2CO3", 0.0)
        + concentrations.get("HCO3-", 0.0)
        + concentrations.get("CO3^2-", 0.0)
    )
    charge_residual = _solubility_charge_balance(concentrations)
    dissolved_mass = None
    undissolved_mass = None
    dissolved_fraction = None
    if dissolved_na_moles is not None:
        dissolved_mass = max(dissolved_na_moles, 0.0) * SOL_MW_NAHCO3
        if params.mass_na_hco3_g > 0:
            dissolved_fraction = max(
                0.0, min(dissolved_mass / params.mass_na_hco3_g, 1.0)
            )
            undissolved_mass = max(params.mass_na_hco3_g - dissolved_mass, 0.0)
    carbonate_wt_percent = None
    if params.mass_na_hco3_g > 0:
        carbonate_mass = moles.get("CO3^2-", 0.0) * SOL_MW_NA2CO3
        if carbonate_mass > 0:
            carbonate_wt_percent = max(
                0.0, min(100.0, (carbonate_mass / params.mass_na_hco3_g) * 100.0)
            )
    target_total_carbon = (
        params.total_carbon_with_headspace() if mode == SPEC_MODE_CLOSED else 0.0
    )
    warnings = _solubility_build_warnings(
        params,
        saturation_indices,
        charge_residual,
        target_total_carbon,
        total_carbon,
        ionic_strength_capped,
        ph,
        alkalinity_meq,
        ionic_strength,
        dissolved_fraction=dissolved_fraction,
        saturation_enforced=saturation_enforced,
    )
    assumptions = list(constant_notes)
    retained_frac = params._retained_carbon_fraction()
    if retained_frac < 1.0:
        vented_pct = max(0.0, (1.0 - retained_frac) * 100.0)
        if vented_pct > 0:
            assumptions.append(
                f"{vented_pct:.1f}% of initial inorganic carbon vented before equilibration."
            )
    elif retained_frac > 1.0:
        enrichment_pct = (retained_frac - 1.0) * 100.0
        assumptions.append(
            f"CO₂ enrichment equivalent to {enrichment_pct:.1f}% of the charged inorganic carbon."
        )
    if mode == SPEC_MODE_FIXED_PCO2:
        boundary = fixed_co2_boundary
        if boundary is None:
            boundary, _ = _resolved_fixed_co2_boundary(params)
        assumptions.append(
            "Open-system speciation constrained by fixed pCO2; dissolved CO2* is set by Henry's law."
        )
        assumptions.append(
            f"Henry boundary: pCO2={params.headspace_pco2_atm or SOL_HEADSPACE_DEFAULT_PCO2_ATM:.3g} atm, CO2*~{boundary:.2e} M."
        )
    else:
        target_h2co3 = params.headspace_target_h2co3()
        if target_h2co3:
            assumptions.append(
                "Henry's law headspace CO2 contribution applied "
                f"({params.headspace_pco2_atm or 0:.2e} atm CO2, adds {target_h2co3:.2e} M carbonic acid)."
            )
        else:
            assumptions.append("No explicit headspace CO2 boundary provided.")
    if params.ionic_strength_cap is not None:
        assumptions.append(
            f"Ionic strength constrained to {params.ionic_strength_cap:.3f} M."
        )
    if saturation_enforced:
        salts = ", ".join(sorted(set(saturation_enforced)))
        assumptions.append(
            f"Precipitation limits enforced for {salts} (Ksp boundary held at ~1)."
        )
    assumptions.append(f"Resolved volume {volume:.4f} L.")
    assumptions.append(
        "Speciation solver enforces charge neutrality; residual warnings highlight any imbalance."
    )
    return SolubilitySpeciationResult(
        concentrations_m=concentrations,
        moles=moles,
        activity_coefficients=activity_coeffs,
        ionic_strength=ionic_strength,
        ph=ph,
        saturation_indices=saturation_indices,
        fractional_carbon=fractional,
        mass_concentrations_g_per_l=mass_conc,
        alkalinity_meq_per_l=alkalinity_meq,
        total_carbon_m=total_carbon,
        charge_balance_residual=charge_residual,
        assumptions=assumptions,
        warnings=warnings,
        carbonate_as_na2co3_wt_percent=carbonate_wt_percent,
        ionic_strength_capped=ionic_strength_capped,
        dissolved_mass_na_hco3_g=dissolved_mass,
        undissolved_mass_na_hco3_g=undissolved_mass,
        dissolved_fraction=dissolved_fraction,
    )


def solubility_generate_ph_sweep(
    params: SolubilityInputs,
    constants: Tuple[float, float, float, List[str]],
    sweep_low: float,
    sweep_high: float,
    sweep_steps: int,
    math_logger: Optional[SolubilityMathLogger] = None,
    *,
    model_options: Optional[ModelOptions] = None,
) -> List[Dict[str, float]]:
    """Generate pH sweep.
    Used by solubility workflows to generate pH sweep."""
    sweep_data: List[Dict[str, float]] = []
    if sweep_steps <= 0 or sweep_high <= sweep_low:
        return sweep_data
    ph_values = np.linspace(sweep_low, sweep_high, sweep_steps)
    # Iterate over ph_values to apply the per-item logic.
    for ph_value in ph_values:
        try:
            spec = solubility_speciation_at_forced_ph(
                params,
                float(ph_value),
                constants=constants,
                model_options=model_options,
            )
        except Exception:
            continue
        row = {
            "ph": float(ph_value),
            "hco3_pct": spec.fractional_carbon.get("HCO3-", 0.0) * 100.0,
            "co3_pct": spec.fractional_carbon.get("CO3^2-", 0.0) * 100.0,
            "h2co3_pct": spec.fractional_carbon.get("H2CO3", 0.0) * 100.0,
        }
        sweep_data.append(row)
        if math_logger:
            sweep_steps = [
                SolubilityMathStep(
                    title="HCO3- share",
                    expression=f"{row['hco3_pct']:.2f}%",
                    detail="Bicarbonate percent of inorganic carbon.",
                    units="%",
                ),
                SolubilityMathStep(
                    title="CO3^2- share",
                    expression=f"{row['co3_pct']:.2f}%",
                    detail="Carbonate percent of inorganic carbon.",
                    units="%",
                ),
                SolubilityMathStep(
                    title="H2CO3 share",
                    expression=f"{row['h2co3_pct']:.2f}%",
                    detail="Dissolved carbonic acid percent.",
                    units="%",
                ),
            ]
            math_logger.log(
                "pH Sweep",
                f"pH {row['ph']:.2f}",
                "% HCO3- / CO3^2- / H2CO3",
                f"{row['hco3_pct']:.2f} / {row['co3_pct']:.2f} / {row['h2co3_pct']:.2f}",
                "%",
                steps=sweep_steps,
            )
    return sweep_data


def solubility_sensitivity_analysis(
    params: SolubilityInputs,
    enabled_axes: Dict[str, bool],
    delta_pct: float = SOL_DEFAULT_SENSITIVITY_PCT,
    math_logger: Optional[SolubilityMathLogger] = None,
    *,
    model_options: Optional[ModelOptions] = None,
) -> List[Dict[str, str]]:
    """Perform solubility sensitivity analysis.
    Used to keep the workflow logic localized and testable."""
    rows: List[Dict[str, str]] = []
    delta = delta_pct / 100.0

    def _format_row(
        label: str, spec: Optional[SolubilitySpeciationResult], error: Optional[str]
    ) -> None:
        """Format row.
        Used to prepare row for display or export."""
        if spec is None or error:
            rows.append(
                {
                    "label": label,
                    "ph": error or "n/a",
                    "ionic_strength": error or "n/a",
                    "na2co3_si": error or "n/a",
                }
            )
            return
        rows.append(
            {
                "label": label,
                "ph": f"{spec.ph:.2f}",
                "ionic_strength": f"{spec.ionic_strength:.3e}",
                "na2co3_si": f"{spec.saturation_indices.get('Na2CO3', float('nan')):.3f}",
            }
        )

    def _run(label: str, attr: str, factor: float) -> None:
        """Run value.
        Used to execute value and coordinate results."""
        base_value = getattr(params, attr)
        if base_value is None:
            return
        try:
            new_value = base_value * factor
            if attr == "mass_na_hco3_g" and new_value <= 0:
                raise ValueError("Mass must stay positive.")
            candidate = replace(params, **{attr: new_value})
            spec = solubility_solve_speciation(
                candidate,
                math_logger=math_logger,
                math_section=f"Sensitivity ({label})",
                model_options=model_options,
            )
            _format_row(label, spec, None)
        except Exception as exc:
            _format_row(label, None, f"err: {exc}")

    if enabled_axes.get("mass"):
        _run(f"-{delta_pct:.0f}% NaHCO3 mass", "mass_na_hco3_g", 1 - delta)
        _run(f"+{delta_pct:.0f}% NaHCO3 mass", "mass_na_hco3_g", 1 + delta)

    solvent_attr = None
    if params.water_mass_g is not None:
        solvent_attr = "water_mass_g"
    elif params.solution_volume_l is not None:
        solvent_attr = "solution_volume_l"
    if enabled_axes.get("solvent") and solvent_attr:
        _run(f"-{delta_pct:.0f}% solvent", solvent_attr, 1 - delta)
        _run(f"+{delta_pct:.0f}% solvent", solvent_attr, 1 + delta)

    if enabled_axes.get("temperature"):
        _run(f"-{delta_pct:.0f}% temperature", "temperature_c", 1 - delta)
        _run(f"+{delta_pct:.0f}% temperature", "temperature_c", 1 + delta)

    return rows


def _should_apply_excess_headspace_handling(
    treat_excess_as_headspace: bool,
    ledger_state: Optional[Dict[str, float]],
    *,
    carbonate_trace_threshold: float = 1e-6,
    carbonate_fraction_threshold: float = 1e-3,
) -> bool:
    """Check whether it should apply excess headspace handling.
    Used to gate conditional behavior in the workflow."""
    if not treat_excess_as_headspace or not ledger_state:
        return False

    carbonate_mol = max(ledger_state.get("na2co3_mol", 0.0), 0.0)
    bicarbonate_mol = max(ledger_state.get("nahco3_mol", 0.0), 0.0)
    dissolved_excess_mol = max(ledger_state.get("co2_excess_mol", 0.0), 0.0)
    total_carbon_pool = carbonate_mol + bicarbonate_mol + dissolved_excess_mol
    if carbonate_mol <= carbonate_trace_threshold:
        return True
    if total_carbon_pool <= 0:
        return False
    carbonate_fraction = carbonate_mol / total_carbon_pool
    return carbonate_fraction <= carbonate_fraction_threshold


def _split_by_solubility_na2co3(
    total_mol: float, vol_L: Optional[float], temp_C: Optional[float]
) -> Tuple[float, float]:
    """Split by solubility Na2CO3.
    Used to separate by solubility Na2CO3 for downstream processing."""

    total = max(total_mol, 0.0)
    if vol_L is None or vol_L <= 0:
        return 0.0, total
    base_solubility = 2.0  # mol/L @25 C (deterministic planning split, reporting only)
    try:
        temp = float(temp_C) if temp_C is not None else 25.0
    except Exception:
        temp = 25.0
    solubility = base_solubility * (1.0 + 0.004 * (temp - 25.0))
    dissolved = min(total, solubility * vol_L)
    solid = max(total - dissolved, 0.0)
    return dissolved, solid


def _split_by_solubility_nahco3(
    total_mol: float, vol_L: Optional[float], temp_C: Optional[float]
) -> Tuple[float, float]:
    """Split by solubility NaHCO3.
    Used to separate by solubility NaHCO3 for downstream processing."""

    total = max(total_mol, 0.0)
    if vol_L is None or vol_L <= 0:
        return 0.0, total
    base_solubility = 1.1  # mol/L @25 C (deterministic planning split, reporting only)
    try:
        temp = float(temp_C) if temp_C is not None else 25.0
    except Exception:
        temp = 25.0
    solubility = base_solubility * (1.0 + 0.004 * (temp - 25.0))
    dissolved = min(total, solubility * vol_L)
    solid = max(total - dissolved, 0.0)
    return dissolved, solid


def _planning_species_fractions_from_model_species(
    species: Optional[Dict[str, float]],
) -> Dict[str, float]:
    """Perform planning species fractions from model species.
    Used to keep the workflow logic localized and testable."""
    if not species:
        return {}
    m_co2 = max(float(species.get("m_CO2", 0.0) or 0.0), 0.0)
    m_hco3 = max(float(species.get("m_HCO3", 0.0) or 0.0), 0.0)
    m_co3 = max(float(species.get("m_CO3", 0.0) or 0.0), 0.0)
    total = m_co2 + m_hco3 + m_co3
    if total <= 0:
        return {}
    return {
        "H2CO3": m_co2 / total,
        "HCO3-": m_hco3 / total,
        "CO3^2-": m_co3 / total,
    }


def _map_current_state_to_planning_curve(
    current_co2_g: Optional[float],
    x_series: Sequence[float],
    ph_series: Sequence[Optional[float]],
) -> Tuple[Optional[float], Optional[float], Optional[int]]:
    """Map current state to planning curve.
    Used to translate current state to planning curve into application-specific terms."""
    if current_co2_g is None:
        return None, None, None
    try:
        current_value = float(current_co2_g)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None, None, None
    if not math.isfinite(current_value):
        return None, None, None
    pairs: List[Tuple[float, Optional[float], int]] = []
    # Iterate over indexed elements from zip(x_series or [], ph_series or [] to apply the per-item logic.
    for idx, (x_val, ph_val) in enumerate(zip(x_series or [], ph_series or [])):
        x_float = _safe_float(x_val)
        if x_float is None or not math.isfinite(x_float):
            continue
        ph_float = _safe_float(ph_val)
        pairs.append((x_float, ph_float, idx))
    if not pairs:
        return None, None, None
    pairs.sort(key=lambda item: item[0])
    xs = [item[0] for item in pairs]
    phs = [item[1] for item in pairs]
    if current_value <= xs[0]:
        return xs[0], phs[0], pairs[0][2]
    if current_value >= xs[-1]:
        return xs[-1], phs[-1], pairs[-1][2]
    idx_right = next(
        (idx for idx, value in enumerate(xs) if value >= current_value), None
    )
    if idx_right is None:
        return xs[-1], phs[-1], pairs[-1][2]
    idx_left = max(idx_right - 1, 0)
    x_left, x_right = xs[idx_left], xs[idx_right]
    ph_left, ph_right = phs[idx_left], phs[idx_right]
    if (
        ph_left is None
        or ph_right is None
        or not math.isfinite(ph_left)
        or not math.isfinite(ph_right)
        or x_right == x_left
    ):
        nearest_idx = idx_left
        if abs(current_value - x_right) < abs(current_value - x_left):
            nearest_idx = idx_right
        return xs[nearest_idx], phs[nearest_idx], pairs[nearest_idx][2]
    ratio = (current_value - x_left) / (x_right - x_left)
    mapped_ph = ph_left + ratio * (ph_right - ph_left)
    return current_value, mapped_ph, pairs[idx_left][2]


def _analysis_regime_label(mapped_ph: Optional[float]) -> str:
    """Perform analysis regime label.
    Used to keep the workflow logic localized and testable."""
    if mapped_ph is None or not math.isfinite(mapped_ph):
        return "Regime: Unknown (pH unavailable)"
    if mapped_ph < 7.0 or mapped_ph > 14.0:
        return "Regime: Outside expected range"
    if mapped_ph > 10.3:
        return "Regime: Carbonate (14 > pH > 10.3)"
    return "Regime: Equilibrium (10.3 > pH > 7)"


def _predict_planning_ph_for_model(
    model: Optional[SpeciationModel],
    *,
    planning_context: Dict[str, Any],
    cumulative_co2_moles: float,
    cycle_index: int,
    fallback_ph: Optional[float] = None,
) -> Tuple[Optional[float], Optional[Dict[str, float]], Optional[str], Optional[str]]:
    """Predict planning pH for model.
    Used to compute planning pH for model for planning workflows."""
    source = "ledger" if fallback_ph is not None else None
    if model is None:
        return fallback_ph, None, source, None
    predictor = getattr(model, "predict_planning_ph", None)
    if not callable(predictor):
        return fallback_ph, None, source, None
    try:
        result = predictor(
            planning_context=planning_context,
            cumulative_co2_moles=cumulative_co2_moles,
            cycle_index=cycle_index,
        )
    except Exception as exc:
        warning = f"Planning pH model failed: {exc}"
        return fallback_ph, None, source, warning
    ph_value = None
    species = None
    if isinstance(result, tuple):
        if result:
            ph_value = result[0]
        if len(result) > 1:
            species = result[1]
    else:
        ph_value = result
    if ph_value is None or not math.isfinite(ph_value):
        warning = "Planning pH model returned an invalid pH value."
        return fallback_ph, species, source, warning
    return _clamp_ph_value(float(ph_value)), species, "planning_model", None


def solubility_simulate_cycle_timeline(
    params: SolubilityInputs,
    cycles: Sequence[Dict[str, Any]],
    *,
    supersaturation_factor: float = 1.0,
    slurry_mode: bool = True,
    model: Optional[SpeciationModel] = None,
    ph_model: Optional[SpeciationModel] = None,
    model_options: Optional[ModelOptions] = None,
    reaction_context: Optional[Dict[str, Any]] = None,
    treat_excess_as_headspace: bool = False,
) -> Dict[str, Any]:
    """Perform solubility simulate cycle timeline.
    Used to keep the workflow logic localized and testable."""

    timeline: List[Dict[str, Any]] = []
    treat_excess_as_headspace = bool(treat_excess_as_headspace)
    supersaturation = 1.0
    if slurry_mode:
        try:
            supersaturation = max(float(supersaturation_factor), 1.0)
        except Exception:
            supersaturation = 1.0
    base_moles = max(params.total_moles(), 0.0)
    cumulative_moles = float(base_moles)
    cumulative_mass = cumulative_moles * SOL_MW_NAHCO3
    co2_added_moles = 0.0
    co2_consumed_moles = 0.0
    co2_unconsumed_moles = 0.0
    equivalence_crossed_cycle: Optional[int] = None
    last_pco2_value: Optional[float] = None
    headspace_volume_warning_logged = False
    missing_pco2_warning_logged = False
    plateau_warning_logged = False
    post_equivalence_plateau_count = 0
    post_equivalence_plateau_ph: Optional[float] = None
    errors: List[str] = []
    headspace_volume_l = getattr(params, "headspace_volume_l", None)
    try:
        timeline_constants: Optional[Tuple[float, float, float, List[str]]] = (
            _resolve_solubility_constants(
                params, math_logger=None, section="Cycle timeline constants"
            )
        )
    except Exception:
        timeline_constants = None

    model = model or get_speciation_model(None)
    ph_model = ph_model or model
    selected_model = model
    spec_model = selected_model
    context = reaction_context or {}
    naoh_mass_g = _safe_float(context.get("naoh_mass_g"))
    solution_volume_l = context.get("solution_volume_l")
    context_temperature_c = context.get("temperature_c")
    if context_temperature_c is None:
        context_temperature_c = params.temperature_c
    context_use_temp_constants = bool(
        context.get(
            "use_temp_adjusted_constants", params.use_temperature_adjusted_constants
        )
    )
    context_ionic_cap = context.get("ionic_strength_cap")
    if context_ionic_cap is None:
        context_ionic_cap = params.ionic_strength_cap
    context_target_ph = context.get("target_ph")
    context_measured_ph = context.get("measured_ph")
    context_slurry_ph = context.get("slurry_ph")
    reprocessing_mode = bool(context.get("reprocessing_mode"))
    reproc_helpers: Dict[str, Any] = {}
    fallback_cycles = list(cycles or [])
    baseline_headspace_pressure_psi = (
        _cycle_headspace_pressure_psi(fallback_cycles[0]) if fallback_cycles else None
    )
    baseline_headspace_pco2_atm = _pressure_psi_to_atm(baseline_headspace_pressure_psi)
    workflow_key = context.get("workflow_key")
    pressure_controlled = workflow_key == "Planning"
    if pressure_controlled:
        context_measured_ph = None
        context_slurry_ph = None
    planning_measured_note = context.get("planning_measured_note")
    planning_delta_psi = context.get("planning_cycle_delta_p_psi")
    planning_headspace_volume = context.get("planning_headspace_volume_l")
    planning_headspace_pressure_high_psi = context.get(
        "planning_headspace_pressure_high_psi"
    )
    if planning_headspace_volume is not None:
        try:
            headspace_volume_l = float(planning_headspace_volume)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
    planning_context = {
        "naoh_mass_g": naoh_mass_g,
        "water_mass_g": params.water_mass_g,
        "solution_volume_l": solution_volume_l,
        "temperature_c": context_temperature_c,
        "headspace_volume_l": headspace_volume_l,
        "planning_headspace_pressure_high_psi": planning_headspace_pressure_high_psi,
        "planning_cycle_delta_p_psi": planning_delta_psi,
        "planning_cycle_co2_g": context.get("planning_cycle_co2_g"),
    }

    def _derive_cycle_moles_from_pressure(
        delta_psi_value: Optional[float],
        volume_l: Optional[float],
        temp_c_value: Optional[float],
    ) -> Optional[float]:
        """Perform derive cycle moles from pressure.
        Used to keep the workflow logic localized and testable."""
        if (
            delta_psi_value is None
            or volume_l is None
            or not math.isfinite(volume_l)
            or volume_l <= 0
        ):
            return None
        atm_drop = _pressure_psi_to_atm(delta_psi_value)
        if atm_drop is None or not math.isfinite(atm_drop) or atm_drop <= 0:
            return None
        try:
            temp_k_val = (
                temp_c_value if temp_c_value is not None else params.temperature_c
            ) + 273.15
        except Exception:
            temp_k_val = 298.15
        if temp_k_val <= 0 or not math.isfinite(temp_k_val):
            temp_k_val = 298.15
        return atm_drop * volume_l / (_SOL_IDEAL_GAS_R_L_ATM_PER_MOLK * temp_k_val)

    try:
        initial_naoh_mol = (
            float(naoh_mass_g) / SOL_MW_NAOH if naoh_mass_g is not None else base_moles
        )
    except Exception:
        initial_naoh_mol = base_moles
    initial_naoh_mol = max(initial_naoh_mol, 0.0)
    transition_pka2 = _resolve_pka2_value(
        context_temperature_c, context_use_temp_constants
    )
    if timeline_constants:
        try:
            transition_pka2 = -math.log10(max(timeline_constants[1], 1e-30))
        except Exception:
            transition_pka2 = transition_pka2
    transition_ph_value = max(
        10.1, min(transition_pka2 if transition_pka2 is not None else 10.33, 10.5)
    )
    transition_pka1: float = 6.35
    if timeline_constants:
        try:
            transition_pka1 = -math.log10(max(timeline_constants[0], 1e-30))
        except Exception:
            transition_pka1 = transition_pka1

    def _carbonate_fractions_from_ph(ph_value: Optional[float]) -> Dict[str, float]:
        """Perform carbonate fractions from pH.
        Used to keep the workflow logic localized and testable."""
        if ph_value is None or not math.isfinite(ph_value):
            return {}
        try:
            H = 10 ** (-ph_value)
            Ka1 = 10 ** (-transition_pka1)
            Ka2 = 10 ** (-(transition_pka2 if transition_pka2 is not None else 10.33))
            denom = H * H + Ka1 * H + Ka1 * Ka2
            if denom <= 0:
                return {}
            h2co3 = max(H * H / denom, 0.0)
            hco3 = max(Ka1 * H / denom, 0.0)
            co3 = max(Ka1 * Ka2 / denom, 0.0)
            total = h2co3 + hco3 + co3
            if total <= 0:
                return {}
            return {
                "H2CO3": h2co3 / total,
                "HCO3-": hco3 / total,
                "CO3^2-": co3 / total,
            }
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return {}

    def _smooth_buffer_ph(
        total_co2_mol: float,
        sodium_total_mol: float,
        base_ph: Optional[float],
        pco2_value: Optional[float],
    ) -> Tuple[Optional[float], Optional[str]]:
        """Perform smooth buffer pH.
        Used to keep the workflow logic localized and testable."""
        if (
            sodium_total_mol <= 0
            or total_co2_mol is None
            or not math.isfinite(total_co2_mol)
        ):
            return base_ph, None
        ratio = total_co2_mol / max(sodium_total_mol, 1e-12)
        candidate_ph = (
            base_ph if base_ph is not None and math.isfinite(base_ph) else 14.0
        )
        candidate_ph = _clamp_ph_value(candidate_ph)
        pre_high = min(max(candidate_ph, transition_ph_value, 13.8), 14.3)
        if ratio < 1.0:
            blend = max(0.0, min(ratio, 1.0))
            shaped = blend**1.25
            ph_val = pre_high * (1.0 - shaped) + transition_ph_value * shaped
            return _clamp_ph_value(ph_val), "pre"
        excess_ratio = max(ratio - 1.0, 0.0)
        floor = 8.0
        if not pressure_controlled:
            adj = 0.0
            if pco2_value is None or not math.isfinite(pco2_value):
                adj = 0.15
            elif pco2_value < 0.8:
                adj = 0.2 * (0.8 - pco2_value) / 0.8
            floor = 8.0 + max(adj, 0.0)
        decay = (
            0.85
            if pressure_controlled
            else 0.75 + 0.05 * min(max(pco2_value or 0.0, 0.0), 5.0)
        )
        ph_val = floor + (transition_ph_value - floor) * math.exp(-decay * excess_ratio)
        return _clamp_ph_value(ph_val), "post"

    if reprocessing_mode:
        failing_ph = context.get("failing_ph")
        baseline_spec_context = context.get("baseline_spec")
        target_spec_context = context.get("target_spec")
        measured_alk_meq = context.get("measured_alk_meq")

        def _spec_value(spec: Any, key: str, default: Any = None) -> Any:
            """Perform spec value.
            Used to keep the workflow logic localized and testable."""
            if spec is None:
                return default
            if isinstance(spec, Mapping):
                return spec.get(key, default)
            return getattr(spec, key, default)

        def _spec_fractions(spec: Any) -> Dict[str, float]:
            """Perform spec fractions.
            Used to keep the workflow logic localized and testable."""
            if spec is None:
                return {}
            if isinstance(spec, Mapping):
                return spec.get("fractional_carbon", {}) or spec.get("fractions", {})
            return getattr(spec, "fractional_carbon", {}) or {}

        def _spec_moles(spec: Any) -> Dict[str, float]:
            """Perform spec moles.
            Used to keep the workflow logic localized and testable."""
            if spec is None:
                return {}
            if isinstance(spec, Mapping):
                return spec.get("moles", {}) or {}
            return getattr(spec, "moles", {}) or {}

        try:
            volume_l = max(params.volume_l(), 1e-9)
        except Exception:
            volume_l = max(params.solution_volume_l or 1e-9, 1e-9)
        try:
            basis_m, basis_label = _reprocessing_charge_basis(params, measured_alk_meq)
        except Exception:
            basis_m, basis_label = 0.0, "sodium charge balance"

        baseline_spec_obj = baseline_spec_context
        if baseline_spec_obj is None and failing_ph is not None:
            try:
                baseline_spec_obj, _ = _reprocessing_speciation_from_ph(
                    params,
                    failing_ph,
                    constants=timeline_constants,
                    charge_basis_m=basis_m,
                    measured_alk_meq=measured_alk_meq,
                    basis_label=basis_label,
                )
            except Exception:
                baseline_spec_obj = None
        baseline_carbon_m = _spec_value(baseline_spec_obj, "total_carbon_m", 0.0)
        recommended_co2_g = context.get("recommended_co2_g")
        dissolved_limit_moles = 0.0
        if recommended_co2_g is not None and math.isfinite(recommended_co2_g):
            dissolved_limit_moles = max(recommended_co2_g / SOL_MW_CO2, 0.0)
        capacity_carbon_m = baseline_carbon_m
        if target_spec_context is not None:
            capacity_carbon_m = max(
                baseline_carbon_m,
                _spec_value(target_spec_context, "total_carbon_m", baseline_carbon_m),
            )
        elif dissolved_limit_moles > 0.0:
            capacity_carbon_m = baseline_carbon_m + dissolved_limit_moles / volume_l
        dissolved_limit_moles = max(
            dissolved_limit_moles,
            max(capacity_carbon_m - baseline_carbon_m, 0.0) * volume_l,
        )

        def _solve_reproc_spec_for_carbon(
            target_carbon_m: float,
        ) -> Optional[Tuple[float, Any]]:
            """Solve reproc spec for carbon.
            Used to run the solver for reproc spec for carbon workflows."""
            if target_carbon_m is None:
                return None
            if target_carbon_m <= 0:
                if baseline_spec_obj is not None:
                    return getattr(baseline_spec_obj, "ph", None), baseline_spec_obj
                return None
            low, high = 2.0, 12.5
            best_spec = None
            # Iterate over the configured range to apply the per-item logic.
            for _ in range(36):
                mid = 0.5 * (low + high)
                try:
                    spec_mid, carbon_mid = _reprocessing_speciation_from_ph(
                        params,
                        mid,
                        constants=timeline_constants,
                        charge_basis_m=basis_m,
                        measured_alk_meq=measured_alk_meq,
                        basis_label=basis_label,
                    )
                except Exception:
                    break
                best_spec = spec_mid
                if abs(carbon_mid - target_carbon_m) < 1e-5:
                    return mid, spec_mid
                if carbon_mid > target_carbon_m:
                    low = mid
                else:
                    high = mid
            if best_spec is None:
                return None
            return best_spec.ph, best_spec

        reproc_helpers = {
            "spec_value": _spec_value,
            "spec_fractions": _spec_fractions,
            "spec_moles": _spec_moles,
            "baseline_spec": baseline_spec_obj,
            "target_spec": target_spec_context,
            "baseline_carbon_m": baseline_carbon_m,
            "volume_l": volume_l,
            "solve_spec_for_carbon": _solve_reproc_spec_for_carbon,
            "basis_label": basis_label,
            "capacity_carbon_m": capacity_carbon_m,
            "dissolved_limit_moles": dissolved_limit_moles,
            "recommended_co2_g": recommended_co2_g,
            "baseline_headspace_pressure_psi": baseline_headspace_pressure_psi,
            "baseline_headspace_pco2_atm": baseline_headspace_pco2_atm,
        }

        if failing_ph is not None:
            target_ph_value = context.get("target_ph")
            recommended_co2 = context.get("recommended_co2_g")
            baseline_fractions = _spec_fractions(baseline_spec_obj)
            baseline_moles = _spec_moles(baseline_spec_obj)
            timeline.append(
                {
                    "cycle_id": 0,
                    "temperature_c": context_temperature_c,
                    "delta_pressure_psi": 0.0,
                    "co2_moles": 0.0,
                    "co2_mass_g": 0.0,
                    "co2_total_moles": 0.0,
                    "co2_g": 0.0,
                    "solution_ph": _spec_value(baseline_spec_obj, "ph", failing_ph),
                    "speciation_ph": _spec_value(baseline_spec_obj, "ph", failing_ph),
                    "ionic_strength": _spec_value(baseline_spec_obj, "ionic_strength"),
                    "dissolved_mass_g": _spec_value(
                        baseline_spec_obj, "dissolved_mass_na_hco3_g"
                    ),
                    "solid_mass_g": _spec_value(
                        baseline_spec_obj, "undissolved_mass_na_hco3_g", 0.0
                    ),
                    "solid_na2co3_g": baseline_moles.get("CO3^2-", 0.0) * SOL_MW_NA2CO3,
                    "solid_nahco3_g": baseline_moles.get("HCO3-", 0.0) * SOL_MW_NAHCO3,
                    "saturation_index": None,
                    "warnings": ["Failing batch pH recorded before cycle resume."],
                    "supersaturated": False,
                    "analysis_prediction": "Failing batch",
                    "forecast_ph": target_ph_value,
                    "target_ph": target_ph_value,
                    "co2_to_target_g": recommended_co2,
                    "fractions": (
                        baseline_fractions
                        if baseline_fractions
                        else {"H2CO3": 0.0, "HCO3-": 0.0, "CO3^2-": 0.0}
                    ),
                    "baseline_spec": baseline_spec_obj,
                    "target_spec": target_spec_context,
                    "basis_label": basis_label,
                    "headspace_pressure_psi": baseline_headspace_pressure_psi,
                    "pco2_atm": baseline_headspace_pco2_atm,
                    "headspace_co2_mol": 0.0,
                    "headspace_co2_g": 0.0,
                }
            )
    ledger_state: Optional[Dict[str, float]] = None
    ledger_constants: Optional[Tuple[float, float, float]] = None
    ledger_pka2: Optional[float] = None
    ledger_ph_guess: Optional[float] = params.initial_ph_guess
    if (
        not reprocessing_mode
        and naoh_mass_g is not None
        and naoh_mass_g > 0
        and solution_volume_l is not None
        and solution_volume_l > 0
    ):
        try:
            naoh_moles = float(naoh_mass_g) / SOL_MW_NAOH
        except Exception:
            naoh_moles = 0.0
        if naoh_moles > 0:
            ledger_state = {
                "naoh_remaining_mol": naoh_moles,
                "na2co3_mol": 0.0,
                "nahco3_mol": 0.0,
                "co2_excess_mol": 0.0,
            }
            ledger_constants = _basic_carbonate_constants(
                context_temperature_c, context_use_temp_constants
            )
            ledger_pka2 = _resolve_pka2_value(
                context_temperature_c, context_use_temp_constants
            )

    # Iterate over indexed elements from cycles or [], 1 to apply the per-item logic.
    for idx, cycle in enumerate(cycles or [], 1):
        cycle_id = cycle.get("cycle_id", idx)
        entry_warnings: List[str] = []
        if pressure_controlled and planning_measured_note and idx == 1:
            entry_warnings.append(planning_measured_note)
        ledger_fractions: Optional[Dict[str, float]] = None
        ph_aqueous_value: Optional[float] = None
        ph_source = "unset"
        fractions_source = "unset"
        model_species: Optional[Dict[str, float]] = None
        try:
            delta_moles = float(cycle.get("selected_moles"))
        except Exception:
            delta_moles = float("nan")
        if not math.isfinite(delta_moles) or delta_moles < 0:
            delta_pressure_value = cycle.get("delta_pressure_psi")
            if delta_pressure_value is None:
                delta_pressure_value = planning_delta_psi
            derived = _derive_cycle_moles_from_pressure(
                delta_pressure_value, headspace_volume_l, context_temperature_c
            )
            if derived is not None and math.isfinite(derived) and derived >= 0:
                delta_moles = derived
                entry_warnings.append(
                    "CO₂ uptake derived from ΔP and headspace volume for this cycle."
                )
            else:
                delta_moles = 0.0
                entry_warnings.append(
                    "Missing CO₂ mole data; treated as zero uptake for this cycle."
                )
        co2_added_moles += delta_moles
        cumulative_moles += delta_moles
        cumulative_mass = cumulative_moles * SOL_MW_NAHCO3
        total_added_moles = co2_added_moles
        equivalence_moles = initial_naoh_mol / 2.0
        equivalence_reached = (
            initial_naoh_mol > 0.0 and total_added_moles >= equivalence_moles - 1e-12
        )
        excess_moles = max(total_added_moles - equivalence_moles, 0.0)
        effective_excess_handling = False
        carbonate_fraction: Optional[float] = None
        if equivalence_reached and equivalence_crossed_cycle is None:
            equivalence_crossed_cycle = cycle_id
        if (
            equivalence_reached
            and ledger_state is not None
            and ledger_state.get("naoh_remaining_mol", 0.0) > 0.0
            and not pressure_controlled
        ):
            buffer_total = ledger_state.get("na2co3_mol", 0.0) + ledger_state.get(
                "nahco3_mol", 0.0
            )
            frac = (
                ledger_state.get("na2co3_mol", 0.0) / max(buffer_total, 1e-12)
                if buffer_total > 0
                else 0.0
            )
            rebuilt_ledger = _ledger_from_sodium_and_carbonate_fraction(
                initial_naoh_mol, frac
            )
            rebuilt_ledger["co2_excess_mol"] = max(
                ledger_state.get("co2_excess_mol", 0.0), 0.0
            )
            ledger_state = rebuilt_ledger
        temp_c = cycle.get("mean_temperature_c")
        try:
            temp_c = float(temp_c)
            if not math.isfinite(temp_c):
                raise ValueError
        except Exception:
            temp_c = params.temperature_c
        planning_context["temperature_c"] = temp_c
        planning_context["solution_volume_l"] = solution_volume_l
        planning_context["headspace_volume_l"] = headspace_volume_l
        base_cycle_params = SolubilityInputs(
            mass_na_hco3_g=cumulative_mass,
            water_mass_g=params.water_mass_g,
            solution_volume_l=params.solution_volume_l,
            temperature_c=float(temp_c),
            initial_ph_guess=params.initial_ph_guess,
            forced_ph_target=params.forced_ph_target,
            use_temperature_adjusted_constants=params.use_temperature_adjusted_constants,
            ionic_strength_cap=params.ionic_strength_cap,
            headspace_pco2_atm=params.headspace_pco2_atm,
            headspace_kh_m_per_atm=params.headspace_kh_m_per_atm,
            degassed_fraction=params.degassed_fraction,
            headspace_volume_l=headspace_volume_l,
            speciation_mode=SPEC_MODE_FIXED_PCO2,
        )
        cycle_params = base_cycle_params
        cumulative_added_mass = co2_added_moles * SOL_MW_CO2
        spec_model = selected_model
        guidance_prediction: Optional[Dict[str, Any]] = None
        target_ph_value: Optional[float] = None
        co2_remaining_value: Optional[float] = None
        solid_na2co3_g = 0.0
        solid_nahco3_g = 0.0
        na2co3_total_mol = 0.0
        nahco3_total_mol = 0.0
        na2co3_dissolved_mol = 0.0
        na2co3_solid_mol = 0.0
        nahco3_dissolved_mol = 0.0
        nahco3_solid_mol = 0.0
        forecast_ph_value: Optional[float] = None
        ledger_ph_value: Optional[float] = None
        basic_high_ph: Optional[float] = None
        regime_label: Optional[str] = None
        consumed_cycle = 0.0
        unconsumed_cycle = 0.0
        if equivalence_reached and equivalence_crossed_cycle == cycle_id:
            entry_warnings.append(
                "NaOH equivalence reached; entering carbonate/bicarbonate regime."
                if pressure_controlled
                else "NaOH equivalence reached; carbonate/bicarbonate equilibrium governs excess CO₂."
            )
        if (
            not reprocessing_mode
            and ledger_state is not None
            and ledger_constants is not None
            and ledger_pka2 is not None
        ):
            try:
                state, accounting = _simulate_reaction_state_with_accounting(
                    ledger_state,
                    delta_moles,
                    ledger_pka2,
                    solution_volume_l=solution_volume_l,
                    temperature_c=context_temperature_c,
                    ionic_strength_cap=context_ionic_cap,
                    use_temp_adjusted_constants=context_use_temp_constants,
                    initial_ph_guess=ledger_ph_guess,
                    constants=ledger_constants,
                    planning_mode=pressure_controlled,
                )
                ledger_state = {
                    "naoh_remaining_mol": max(
                        state.get("naoh_remaining_mol", 0.0), 0.0
                    ),
                    "na2co3_mol": max(state.get("na2co3_mol", 0.0), 0.0),
                    "nahco3_mol": max(state.get("nahco3_mol", 0.0), 0.0),
                    "co2_excess_mol": max(state.get("co2_excess_mol", 0.0), 0.0),
                }
                ledger_ph_value = state.get("ph")
                if ledger_ph_value is not None and math.isfinite(ledger_ph_value):
                    ph_aqueous_value = _clamp_ph_value(ledger_ph_value)
                    ph_source = "ledger_solver"
                consumed_cycle = accounting.get("co2_consumed_total_mol", 0.0)
                unconsumed_cycle = accounting.get("co2_unconsumed_mol", 0.0)
                co2_consumed_moles += consumed_cycle
                co2_unconsumed_moles = ledger_state.get("co2_excess_mol", 0.0)
                basic_hint = _estimate_highly_basic_ph(
                    ledger_state,
                    volume_l=solution_volume_l,
                    temperature_c=context_temperature_c,
                    use_temp_adjusted_constants=context_use_temp_constants,
                )
                if basic_hint is not None:
                    if ledger_ph_value is None or not math.isfinite(ledger_ph_value):
                        ledger_ph_value = basic_hint
                        ph_aqueous_value = _clamp_ph_value(basic_hint)
                        if ph_source == "unset":
                            ph_source = "ledger_solver"
                basic_high_ph = basic_hint
                if ledger_ph_value is not None and math.isfinite(ledger_ph_value):
                    ledger_ph_guess = ledger_ph_value
                carbonate_mol = max(ledger_state.get("na2co3_mol", 0.0), 0.0)
                bicarbonate_mol = max(ledger_state.get("nahco3_mol", 0.0), 0.0)
                dissolved_excess_mol = max(ledger_state.get("co2_excess_mol", 0.0), 0.0)
                carbon_pool = carbonate_mol + bicarbonate_mol
                if not pressure_controlled:
                    carbon_pool += dissolved_excess_mol
                ledger_fraction_pool = (
                    carbonate_mol + bicarbonate_mol + dissolved_excess_mol
                )
                if ledger_fraction_pool > 0:
                    ledger_fractions = {
                        "H2CO3": dissolved_excess_mol / ledger_fraction_pool,
                        "HCO3-": bicarbonate_mol / ledger_fraction_pool,
                        "CO3^2-": carbonate_mol / ledger_fraction_pool,
                    }
                if carbon_pool > 0:
                    carbonate_fraction = carbonate_mol / carbon_pool
                effective_excess_handling = _should_apply_excess_headspace_handling(
                    treat_excess_as_headspace=treat_excess_as_headspace,
                    ledger_state=ledger_state,
                )
                na2co3_total_mol = carbonate_mol
                nahco3_total_mol = bicarbonate_mol
                if pressure_controlled:
                    # Planning pH computed BEFORE solubility split (all aqueous basis).
                    na2co3_dissolved_mol, na2co3_solid_mol = (
                        _split_by_solubility_na2co3(
                            na2co3_total_mol, solution_volume_l, context_temperature_c
                        )
                    )
                    nahco3_dissolved_mol, nahco3_solid_mol = (
                        _split_by_solubility_nahco3(
                            nahco3_total_mol, solution_volume_l, context_temperature_c
                        )
                    )
                    # Solids split applied for reporting only.
                    solid_na2co3_g = na2co3_solid_mol * SOL_MW_NA2CO3
                    solid_nahco3_g = nahco3_solid_mol * SOL_MW_NAHCO3
                else:
                    na2co3_dissolved_mol, na2co3_solid_mol = (
                        na2co3_total_mol,
                        0.0,
                    )
                    nahco3_dissolved_mol, nahco3_solid_mol = (
                        nahco3_total_mol,
                        0.0,
                    )
                    solid_na2co3_g = na2co3_total_mol * SOL_MW_NA2CO3
                    solid_nahco3_g = nahco3_total_mol * SOL_MW_NAHCO3
                ledger_params = _ledger_state_to_solubility_inputs(
                    ledger_state=ledger_state,
                    base_params=params,
                    evaluation={
                        "volume_l": solution_volume_l,
                        "temperature_c": context_temperature_c,
                        "ionic_strength_cap": context_ionic_cap,
                        "use_temp_adjusted_constants": context_use_temp_constants,
                        "initial_ph_guess": ledger_ph_value,
                        # Treat CO2 beyond Na stoichiometry as headspace inventory when enabled or after equivalence.
                        "treat_excess_as_headspace": effective_excess_handling,
                    },
                    fallback_volume_l=solution_volume_l,
                    headspace_volume_l=params.headspace_volume_l,
                )
                if ledger_params is not None:
                    cycle_params = ledger_params
                if (
                    selected_model
                    and getattr(selected_model, "key", "") == "aqion_closed"
                ):
                    try:
                        spec_model = get_speciation_model(DEFAULT_SPEC_MODEL_KEY)
                        entry_warnings.append(
                            "Aqion closed model is sodium-free; using Debye–Hückel for NaOH stoichiometry while retaining headspace pCO2."
                        )
                    except Exception:
                        spec_model = selected_model
            except Exception as exc:
                entry_warnings.append(f"Ledger update failed: {exc}")
                ledger_state = None
        if pressure_controlled:
            ph_aqueous_value, model_species, model_source, model_warning = (
                _predict_planning_ph_for_model(
                    ph_model,
                    planning_context=planning_context,
                    cumulative_co2_moles=co2_added_moles,
                    cycle_index=cycle_id,
                    fallback_ph=ph_aqueous_value,
                )
            )
            if model_warning:
                entry_warnings.append(model_warning)
            if model_source:
                ph_source = model_source
        if (
            not reprocessing_mode
            and naoh_mass_g is not None
            and naoh_mass_g > 0
            and solution_volume_l is not None
            and math.isfinite(cumulative_added_mass)
        ):
            try:
                guidance = analyze_bicarbonate_reaction(
                    naoh_mass_g=naoh_mass_g,
                    co2_charged_g=cumulative_added_mass,
                    solution_volume_l=solution_volume_l,
                    measured_ph=context_measured_ph,
                    slurry_ph=context_slurry_ph,
                    target_ph=context_target_ph,
                    temperature_c=context_temperature_c,
                    use_temp_adjusted_constants=context_use_temp_constants,
                    ionic_strength_cap=context_ionic_cap,
                )
            except Exception:
                guidance = None
            if guidance:
                target_ph_value = guidance.get("target_ph")
                co2_remaining_value = guidance.get("recommended_co2_g")
                guidance_ledger = guidance.get("ledger") or {}
                forecast_ph_value = guidance.get("predicted_ph_after")
                entry_warnings.extend(guidance.get("warnings") or [])
                guidance_prediction = {
                    "cycle_id": cycle_id,
                    "predicted_ph": forecast_ph_value,
                    "target_ph": target_ph_value,
                    "co2_to_target_g": co2_remaining_value,
                    "ledger": guidance_ledger,
                }
                if ledger_state is None:
                    solid_na2co3_g = (
                        guidance_ledger.get("na2co3_mol", 0.0) * SOL_MW_NA2CO3
                    )
                    solid_nahco3_g = (
                        guidance_ledger.get("nahco3_mol", 0.0) * SOL_MW_NAHCO3
                    )
        used_ledger_params = cycle_params is not base_cycle_params
        if reprocessing_mode and reproc_helpers:
            baseline_carbon_m = reproc_helpers.get("baseline_carbon_m", 0.0)
            volume_l = reproc_helpers.get("volume_l", 1e-9)
            dissolved_moles = max(co2_added_moles, 0.0)
            target_carbon_m = baseline_carbon_m + dissolved_moles / volume_l
            solver = reproc_helpers.get("solve_spec_for_carbon")
            solved = solver(target_carbon_m) if solver else None
            if solved is None:
                msg = f"Cycle {cycle_id}: speciation failed (reprocessing inversion)."
                errors.append(msg)
                timeline.append(
                    {
                        "cycle_id": cycle_id,
                        "temperature_c": temp_c,
                        "delta_pressure_psi": cycle.get("delta_pressure_psi"),
                        "co2_moles": delta_moles,
                        "co2_mass_g": delta_moles * SOL_MW_CO2,
                        "error": msg,
                    }
                )
                continue
            predicted_ph_value, spec = solved
            co2_remaining_value = None
            rec_co2_g = reproc_helpers.get("recommended_co2_g")
            if rec_co2_g is not None:
                co2_remaining_value = max(
                    rec_co2_g - (dissolved_moles * SOL_MW_CO2), 0.0
                )
        else:
            try:
                spec = spec_model.solve(
                    cycle_params,
                    model_options=model_options,
                    math_logger=None,
                    math_section=f"Cycle {cycle_id}",
                )
            except Exception as exc:
                fallback_spec: Optional[SolubilitySpeciationResult] = None
                if used_ledger_params:
                    entry_warnings.append(
                        "Ledger-driven speciation failed; reverting to NaHCO3 mass basis."
                    )
                    try:
                        fallback_spec = spec_model.solve(
                            base_cycle_params,
                            model_options=model_options,
                            math_logger=None,
                            math_section=f"Cycle {cycle_id} (Fallback)",
                        )
                        cycle_params = base_cycle_params
                    except Exception:
                        fallback_spec = None
                if fallback_spec is None:
                    entry_warnings.append(
                        f"Speciation failed ({exc}); using buffered approximation."
                    )
                    spec = None
                else:
                    spec = fallback_spec

        entry_warnings.extend(getattr(spec, "warnings", []))
        spec_ph_value = getattr(spec, "ph", None)
        if (
            ph_source == "unset"
            and spec_ph_value is not None
            and math.isfinite(spec_ph_value)
        ):
            ph_source = "spec_solver"
        spec_moles = getattr(spec, "moles", {}) or {}
        dissolved_moles = max(
            0.0, spec_moles.get("HCO3-", 0.0) + spec_moles.get("CO3^2-", 0.0)
        )
        dissolved_mass = dissolved_moles * SOL_MW_NAHCO3
        allowance = dissolved_mass
        if pressure_controlled:
            dissolved_mass = (
                na2co3_dissolved_mol * SOL_MW_NA2CO3
                + nahco3_dissolved_mol * SOL_MW_NAHCO3
            )
            allowance = dissolved_mass
            solid_mass = (
                na2co3_solid_mol * SOL_MW_NA2CO3 + nahco3_solid_mol * SOL_MW_NAHCO3
            )
        else:
            if slurry_mode:
                allowance = dissolved_mass * supersaturation
            allowance = min(allowance, cumulative_mass)
            solid_mass = max(cumulative_mass - allowance, 0.0)
        if (
            ledger_state is not None
            and ledger_state.get("naoh_remaining_mol", 0.0) > 1e-6
            and spec_ph_value is not None
            and spec_ph_value < 8.0
        ):
            entry_warnings.append(
                "Simulated pH dropped below 8.0 while NaOH remains; verify CO2 totals."
            )
        spec_value = (
            reproc_helpers.get("spec_value")
            if reproc_helpers
            else lambda obj, key, default=None: getattr(obj, key, default)
        )
        spec_fractions = (
            reproc_helpers.get("spec_fractions")
            if reproc_helpers
            else (lambda obj: getattr(obj, "fractional_carbon", {}) or {})
        )
        spec_moles = (
            reproc_helpers.get("spec_moles")
            if reproc_helpers
            else (lambda obj: getattr(obj, "moles", {}) or {})
        )
        co2_to_target_value = co2_remaining_value
        headspace_moles_entry = 0.0
        pco2_value: Optional[float] = None
        pco2_from_excess: Optional[float] = None
        if reprocessing_mode and reproc_helpers:
            rec_co2_g = reproc_helpers.get("recommended_co2_g")
            limit_moles = reproc_helpers.get("dissolved_limit_moles", 0.0)
            headspace_moles_entry = max(co2_added_moles - limit_moles, 0.0)
            if rec_co2_g is not None:
                co2_to_target_value = max(
                    rec_co2_g - (co2_added_moles * SOL_MW_CO2), 0.0
                )
            if headspace_moles_entry > 0 and headspace_volume_l:
                temp_k = (
                    context_temperature_c
                    if context_temperature_c is not None
                    else params.temperature_c
                ) + 273.15
                pco2_from_excess = (
                    headspace_moles_entry
                    * _SOL_IDEAL_GAS_R_L_ATM_PER_MOLK
                    * temp_k
                    / max(headspace_volume_l, 1e-12)
                )
            elif headspace_moles_entry > 0 and not headspace_volume_l:
                if not headspace_volume_warning_logged:
                    entry_warnings.append(
                        "Headspace volume missing; unable to project pCO₂ rise from excess CO₂."
                    )
                    headspace_volume_warning_logged = True
        elif (
            not reprocessing_mode
            and ledger_state is not None
            and effective_excess_handling
        ):
            ledger_excess = max(ledger_state.get("co2_excess_mol", 0.0), 0.0)
            headspace_moles_entry = max(excess_moles, ledger_excess)
            if (
                headspace_moles_entry > 0
                and headspace_volume_l
                and not pressure_controlled
            ):
                temp_k = (
                    context_temperature_c
                    if context_temperature_c is not None
                    else params.temperature_c
                ) + 273.15
                pco2_from_excess = (
                    headspace_moles_entry
                    * _SOL_IDEAL_GAS_R_L_ATM_PER_MOLK
                    * temp_k
                    / max(headspace_volume_l, 1e-12)
                )
            elif headspace_moles_entry > 0 and headspace_volume_l in (None, 0):
                if not headspace_volume_warning_logged:
                    entry_warnings.append(
                        "Headspace volume missing; unable to project pCO₂ rise from excess CO₂."
                    )
                    headspace_volume_warning_logged = True
        headspace_moles_entry = max(headspace_moles_entry, excess_moles)
        measured_pressure = _cycle_headspace_pressure_psi(cycle)
        measured_pco2 = (
            None if pressure_controlled else _pressure_psi_to_atm(measured_pressure)
        )
        base_pco2_candidates: List[Optional[float]] = [
            measured_pco2,
            baseline_headspace_pco2_atm,
            getattr(cycle_params, "headspace_pco2_atm", None),
            params.headspace_pco2_atm,
        ]
        base_pco2_value = next(
            (
                val
                # Iterate to apply the per-item logic.
                for val in base_pco2_candidates
                if val is not None and math.isfinite(val)
            ),
            None,
        )
        if pressure_controlled and params.headspace_pco2_atm is not None:
            base_pco2_value = params.headspace_pco2_atm
        if pressure_controlled:
            headspace_moles_entry = max(excess_moles, 0.0)
            pco2_value = base_pco2_value if base_pco2_value is not None else 0.0
            last_pco2_value = pco2_value
            pco2_from_excess = None
        else:
            if (
                measured_pco2 is None
                and base_pco2_value is None
                and headspace_moles_entry <= 0
                and not missing_pco2_warning_logged
            ):
                entry_warnings.append(
                    "Headspace pCO2 not provided; assuming 0 atm baseline for this cycle."
                )
                missing_pco2_warning_logged = True
            if headspace_moles_entry > 0 and pco2_from_excess is None:
                if headspace_volume_l and headspace_volume_l > 0:
                    temp_k = (
                        context_temperature_c
                        if context_temperature_c is not None
                        else params.temperature_c
                    ) + 273.15
                    pco2_from_excess = (
                        headspace_moles_entry
                        * _SOL_IDEAL_GAS_R_L_ATM_PER_MOLK
                        * temp_k
                        / max(headspace_volume_l, 1e-12)
                    )
                else:
                    if not headspace_volume_warning_logged:
                        entry_warnings.append(
                            "Headspace volume not provided; headspace pCO₂ cannot reflect excess CO₂."
                        )
                        headspace_volume_warning_logged = True
            pco2_base_component = (
                float(base_pco2_value)
                if base_pco2_value is not None and math.isfinite(base_pco2_value)
                else 0.0
            )
            if measured_pco2 is not None and math.isfinite(measured_pco2):
                pco2_value = measured_pco2
            else:
                pco2_value = pco2_base_component + (
                    pco2_from_excess if pco2_from_excess is not None else 0.0
                )
                if base_pco2_value is not None and pco2_value < base_pco2_value:
                    pco2_value = base_pco2_value
        if pco2_value is None:
            entry_warnings.append(
                "Headspace pCO₂ unavailable for this cycle; verify headspace inputs and measurements."
            )
            pco2_value = 0.0
        if (
            equivalence_reached
            and last_pco2_value is not None
            and pco2_value < last_pco2_value
        ):
            pco2_value = last_pco2_value
        pco2_value = max(pco2_value, 0.0)
        last_pco2_value = pco2_value
        try:
            cycle_params = replace(
                cycle_params,
                headspace_pco2_atm=pco2_value,
                speciation_mode=SPEC_MODE_FIXED_PCO2,
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if (
            reprocessing_mode
            and context.get("recommended_co2_g") is not None
            and co2_to_target_value is None
        ):
            co2_to_target_value = max(
                (context.get("recommended_co2_g") or 0.0) - cumulative_added_mass, 0.0
            )
        buffer_moles = co2_added_moles
        if pressure_controlled:
            buffer_moles = max(co2_added_moles, co2_added_moles - co2_unconsumed_moles)
        solution_ph_value: Optional[float] = None
        speciation_ph_value: Optional[float] = None
        if pressure_controlled:
            solution_ph_value = ph_aqueous_value
            if (
                solution_ph_value is None
                and spec_ph_value is not None
                and math.isfinite(spec_ph_value)
            ):
                solution_ph_value = _clamp_ph_value(spec_ph_value)
                ph_source = "spec_solver"
            if (
                (solution_ph_value is None or not math.isfinite(solution_ph_value))
                and basic_high_ph is not None
                and math.isfinite(basic_high_ph)
            ):
                solution_ph_value = _clamp_ph_value(basic_high_ph)
                if ph_source == "unset":
                    ph_source = "basic_hint"
            if solution_ph_value is None or not math.isfinite(solution_ph_value):
                base_ph_for_buffer = (
                    ledger_ph_value if ledger_ph_value is not None else basic_high_ph
                )
                buffered_ph, regime_label = _smooth_buffer_ph(
                    buffer_moles, initial_naoh_mol, base_ph_for_buffer, pco2_value
                )
                if buffered_ph is not None and math.isfinite(buffered_ph):
                    solution_ph_value = buffered_ph
                    if ph_source == "unset":
                        ph_source = "buffer_fallback"
            if solution_ph_value is None or not math.isfinite(solution_ph_value):
                solution_ph_value = _clamp_ph_value(
                    transition_ph_value
                    if equivalence_reached
                    else max(basic_high_ph or 14.0, transition_ph_value)
                )
                if ph_source == "unset":
                    ph_source = "fallback_clamp"
            speciation_ph_value = solution_ph_value
        else:
            solution_ph_value = spec_ph_value
            if solution_ph_value is not None and math.isfinite(solution_ph_value):
                ph_source = "spec_solver"
            if (
                (solution_ph_value is None or not math.isfinite(solution_ph_value))
                and ledger_ph_value is not None
                and math.isfinite(ledger_ph_value)
            ):
                solution_ph_value = float(ledger_ph_value)
                if ph_source == "unset":
                    ph_source = "ledger_solver"
            if (
                basic_high_ph is not None
                and math.isfinite(basic_high_ph)
                and (
                    solution_ph_value is None
                    or not math.isfinite(solution_ph_value)
                    or basic_high_ph > solution_ph_value
                )
            ):
                solution_ph_value = float(basic_high_ph)
                if ph_source == "unset":
                    ph_source = "basic_hint"
            base_ph_for_buffer = solution_ph_value
            if base_ph_for_buffer is None or not math.isfinite(base_ph_for_buffer):
                base_ph_for_buffer = (
                    ledger_ph_value if ledger_ph_value is not None else basic_high_ph
                )
            buffered_ph, regime_label = _smooth_buffer_ph(
                buffer_moles, initial_naoh_mol, base_ph_for_buffer, pco2_value
            )
            if (
                (solution_ph_value is None or not math.isfinite(solution_ph_value))
                and buffered_ph is not None
                and math.isfinite(buffered_ph)
            ):
                solution_ph_value = buffered_ph
                if ph_source == "unset":
                    ph_source = "buffer_fallback"
            if solution_ph_value is None or not math.isfinite(solution_ph_value):
                solution_ph_value = _clamp_ph_value(
                    transition_ph_value
                    if equivalence_reached
                    else max(basic_high_ph or 14.0, transition_ph_value)
                )
                if ph_source == "unset":
                    ph_source = "fallback_clamp"
            speciation_ph_value = (
                spec_ph_value
                if spec_ph_value is not None and math.isfinite(spec_ph_value)
                else solution_ph_value
            )
        model_fractions = _planning_species_fractions_from_model_species(model_species)
        ph_fallback_fractions = _carbonate_fractions_from_ph(solution_ph_value)
        solver_fractions = spec_fractions(spec)
        fractions: Dict[str, float] = {}
        if model_fractions:
            fractions = model_fractions
            fractions_source = "planning_model"
        elif solver_fractions and any(
            key in solver_fractions for key in ("H2CO3", "HCO3-", "CO3^2-")
        ):
            fractions = solver_fractions
            fractions_source = "solver"
        elif ledger_fractions:
            fractions = ledger_fractions
            fractions_source = "ledger"
        elif ph_fallback_fractions:
            fractions = ph_fallback_fractions
            fractions_source = "ph_fallback"
            entry_warnings.append(
                "Fractions derived from pH fallback (solver unavailable)."
            )
        else:
            fractions_source = "empty"
        if ph_source == "unset":
            ph_source = "unspecified"
        if pressure_controlled and solution_ph_value is not None:
            speciation_ph_value = solution_ph_value
        elif speciation_ph_value is None:
            speciation_ph_value = solution_ph_value
        if (
            not reprocessing_mode
            and carbonate_fraction is not None
            and equivalence_reached
            and delta_moles > 0
            and solution_ph_value is not None
            and math.isfinite(solution_ph_value)
        ):
            if carbonate_fraction > 0.01:
                if (
                    post_equivalence_plateau_ph is not None
                    and abs(solution_ph_value - post_equivalence_plateau_ph) < 1e-3
                ):
                    post_equivalence_plateau_count += 1
                else:
                    post_equivalence_plateau_count = 0
                post_equivalence_plateau_ph = solution_ph_value
                if post_equivalence_plateau_count >= 3 and not plateau_warning_logged:
                    entry_warnings.append(
                        "Post-equivalence pH is holding while carbonate remains; aqueous COƒ,, should continue driving conversion."
                    )
                    plateau_warning_logged = True
            else:
                post_equivalence_plateau_count = 0
                post_equivalence_plateau_ph = solution_ph_value
        else:
            post_equivalence_plateau_count = 0
            if solution_ph_value is not None and math.isfinite(solution_ph_value):
                post_equivalence_plateau_ph = solution_ph_value
        timeline.append(
            {
                "cycle_id": cycle_id,
                "temperature_c": temp_c,
                "delta_pressure_psi": cycle.get("delta_pressure_psi"),
                "co2_moles": delta_moles,
                "co2_mass_g": delta_moles * SOL_MW_CO2,
                "co2_added_moles": delta_moles,
                "co2_added_mass_g": delta_moles * SOL_MW_CO2,
                "co2_consumed_moles": consumed_cycle,
                "co2_consumed_mass_g": consumed_cycle * SOL_MW_CO2,
                "co2_unconsumed_moles": unconsumed_cycle,
                "co2_unconsumed_mass_g": unconsumed_cycle * SOL_MW_CO2,
                "co2_total_moles": co2_added_moles,
                "co2_g": cumulative_added_mass,
                "cumulative_co2_added_moles": co2_added_moles,
                "cumulative_co2_added_mass_g": cumulative_added_mass,
                "cumulative_co2_consumed_moles": co2_consumed_moles,
                "cumulative_co2_consumed_mass_g": co2_consumed_moles * SOL_MW_CO2,
                "cumulative_co2_unconsumed_moles": co2_unconsumed_moles,
                "cumulative_co2_unconsumed_mass_g": co2_unconsumed_moles * SOL_MW_CO2,
                "ledger_naoh_remaining_mol": (
                    ledger_state.get("naoh_remaining_mol") if ledger_state else None
                ),
                "ledger_na2co3_mol": (
                    ledger_state.get("na2co3_mol") if ledger_state else None
                ),
                "ledger_nahco3_mol": (
                    ledger_state.get("nahco3_mol") if ledger_state else None
                ),
                "ledger_co2_excess_mol": (
                    ledger_state.get("co2_excess_mol") if ledger_state else None
                ),
                "ledger_h2co3_fraction": (
                    ledger_fractions.get("H2CO3") if ledger_fractions else None
                ),
                "solution_ph": solution_ph_value,
                "speciation_ph": speciation_ph_value,
                "ph_source": ph_source,
                "ionic_strength": spec_value(spec, "ionic_strength"),
                "dissolved_mass_g": spec_value(
                    spec, "dissolved_mass_na_hco3_g", dissolved_mass
                ),
                "effective_dissolved_mass_g": allowance,
                "solid_mass_g": solid_mass,
                "solid_na2co3_g": (
                    solid_na2co3_g
                    if not reprocessing_mode
                    else spec_moles(spec).get("CO3^2-", 0.0) * SOL_MW_NA2CO3
                ),
                "solid_nahco3_g": (
                    solid_nahco3_g
                    if not reprocessing_mode
                    else spec_moles(spec).get("HCO3-", 0.0) * SOL_MW_NAHCO3
                ),
                "na2co3_total_mol": na2co3_total_mol,
                "nahco3_total_mol": nahco3_total_mol,
                "na2co3_dissolved_mol": na2co3_dissolved_mol,
                "na2co3_solid_mol": na2co3_solid_mol,
                "nahco3_dissolved_mol": nahco3_dissolved_mol,
                "nahco3_solid_mol": nahco3_solid_mol,
                "na2co3_dissolved_g": na2co3_dissolved_mol * SOL_MW_NA2CO3,
                "nahco3_dissolved_g": nahco3_dissolved_mol * SOL_MW_NAHCO3,
                "saturation_index": spec_value(
                    spec, "saturation_index", getattr(spec, "saturation_index", None)
                ),
                "headspace_pressure_psi": measured_pressure,
                "pco2_atm": pco2_value,
                "warnings": entry_warnings
                + (
                    ["Excess CO2 diverted to headspace."]
                    if reprocessing_mode and headspace_moles_entry > 0
                    else []
                ),
                "supersaturated": bool(solid_mass > 1e-6),
                "analysis_prediction": (
                    guidance_prediction if not reprocessing_mode else None
                ),
                "forecast_ph": forecast_ph_value if not reprocessing_mode else None,
                "target_ph": target_ph_value,
                "co2_to_target_g": co2_to_target_value,
                "fractions": {
                    "H2CO3": fractions.get("H2CO3", 0.0),
                    "HCO3-": fractions.get("HCO3-", 0.0),
                    "CO3^2-": fractions.get("CO3^2-", 0.0),
                },
                "fractions_source": fractions_source,
                "headspace_co2_mol": headspace_moles_entry,
                "headspace_co2_g": headspace_moles_entry * SOL_MW_CO2,
                "regime": regime_label
                or (
                    "pre_equivalence" if not equivalence_reached else "carbonate_buffer"
                ),
            }
        )

    assumptions = []
    if slurry_mode:
        assumptions.append(
            f"Slurry supersaturation factor applied ({supersaturation:.2f})."
        )
    if pressure_controlled:
        assumptions.append(
            "Headspace treated as pressure-controlled at the CO₂ setpoint; ΔP was converted to absorbed moles each cycle."
        )
        if planning_measured_note:
            assumptions.append(planning_measured_note)
    if equivalence_crossed_cycle is not None:
        assumptions.append(
            f"NaOH equivalence reached at cycle {equivalence_crossed_cycle}; carbonate/bicarbonate buffering applied thereafter."
        )
    final_entry = timeline[-1] if timeline else {}
    summary = {
        "timeline": timeline,
        "total_cycles": len(timeline),
        "total_added_moles": co2_added_moles,
        "total_added_mass_g": co2_added_moles * SOL_MW_CO2,
        "total_consumed_moles": co2_consumed_moles,
        "total_consumed_mass_g": co2_consumed_moles * SOL_MW_CO2,
        "total_unconsumed_moles": co2_unconsumed_moles,
        "total_unconsumed_mass_g": co2_unconsumed_moles * SOL_MW_CO2,
        "final_ph": final_entry.get("solution_ph"),
        "final_solid_mass_g": final_entry.get("solid_mass_g"),
        "headspace_co2_mol": (
            final_entry.get("headspace_co2_mol", 0.0) if timeline else 0.0
        ),
        "headspace_co2_g": final_entry.get("headspace_co2_g", 0.0) if timeline else 0.0,
        "slurry_mode": slurry_mode,
        "supersaturation_factor": supersaturation if slurry_mode else 1.0,
        "errors": errors,
        "assumptions": assumptions,
    }
    return summary


def _ledger_from_sodium_and_carbonate_fraction(
    na_total_mol: float, carbonate_fraction: float
) -> Dict[str, float]:
    """Perform ledger from sodium and carbonate fraction.
    Used to keep the workflow logic localized and testable."""

    f = max(0.0, min(float(carbonate_fraction), 0.999999))
    na_total = max(float(na_total_mol), 0.0)

    if na_total <= 0.0:
        return {
            "naoh_remaining_mol": 0.0,
            "na2co3_mol": 0.0,
            "nahco3_mol": 0.0,
            "co2_excess_mol": 0.0,
        }

    c_total = na_total / (1.0 + f)

    return {
        "naoh_remaining_mol": 0.0,
        "na2co3_mol": f * c_total,
        "nahco3_mol": (1.0 - f) * c_total,
        "co2_excess_mol": 0.0,
    }


def _ledger_state_to_solubility_inputs(
    *,
    ledger_state: Optional[Dict[str, float]],
    base_params: SolubilityInputs,
    evaluation: Optional[Dict[str, Any]] = None,
    fallback_volume_l: Optional[float] = None,
    headspace_volume_l: Optional[float] = None,
) -> Optional[SolubilityInputs]:
    """Perform ledger state to solubility inputs.
    Used to keep the workflow logic localized and testable."""
    if not ledger_state:
        return None

    carbonate_mol = max(ledger_state.get("na2co3_mol", 0.0), 0.0)
    bicarbonate_mol = max(ledger_state.get("nahco3_mol", 0.0), 0.0)
    dissolved_excess_mol = max(ledger_state.get("co2_excess_mol", 0.0), 0.0)
    total_na = (
        max(ledger_state.get("naoh_remaining_mol", 0.0), 0.0)
        + bicarbonate_mol
        + 2.0 * carbonate_mol
    )
    total_carbon = bicarbonate_mol + carbonate_mol + dissolved_excess_mol
    mode = _normalize_speciation_mode(getattr(base_params, "speciation_mode", None))
    if total_na <= 0 and total_carbon <= 0:
        return None

    treat_excess_as_headspace = False
    if evaluation and "treat_excess_as_headspace" in evaluation:
        treat_excess_as_headspace = bool(evaluation.get("treat_excess_as_headspace"))
    if mode == SPEC_MODE_FIXED_PCO2:
        treat_excess_as_headspace = False
    treat_excess_as_headspace = _should_apply_excess_headspace_handling(
        treat_excess_as_headspace=treat_excess_as_headspace,
        ledger_state=ledger_state,
    )

    volume_l: Optional[float] = None
    if evaluation and evaluation.get("volume_l") is not None:
        volume_l = evaluation.get("volume_l")
    if volume_l is None:
        volume_l = fallback_volume_l
    if volume_l is None:
        try:
            volume_l = base_params.volume_l()
        except Exception:
            volume_l = base_params.solution_volume_l
    if volume_l is None or volume_l <= 0:
        return None
    headspace_volume_value = headspace_volume_l
    if evaluation and evaluation.get("headspace_volume_l") is not None:
        headspace_volume_value = evaluation.get("headspace_volume_l")
    if headspace_volume_value is None:
        headspace_volume_value = getattr(base_params, "headspace_volume_l", None)

    temperature_c = (
        evaluation.get("temperature_c")
        if evaluation and evaluation.get("temperature_c") is not None
        else base_params.temperature_c
    )
    ionic_strength_cap = (
        evaluation.get("ionic_strength_cap")
        if evaluation and "ionic_strength_cap" in (evaluation or {})
        else base_params.ionic_strength_cap
    )
    use_temp_adjusted_constants = (
        evaluation.get("use_temp_adjusted_constants")
        if evaluation and "use_temp_adjusted_constants" in evaluation
        else base_params.use_temperature_adjusted_constants
    )
    initial_ph_guess = (
        evaluation.get("initial_ph_guess")
        if evaluation and evaluation.get("initial_ph_guess") is not None
        else base_params.initial_ph_guess
    )

    sodium_basis_mol = max(total_na, 0.0)
    mass_na_hco3_g = sodium_basis_mol * SOL_MW_NAHCO3
    headspace_pco2_atm: Optional[float] = base_params.headspace_pco2_atm
    headspace_kh_m_per_atm: Optional[float] = base_params.headspace_kh_m_per_atm
    degassed_fraction = base_params.degassed_fraction

    if sodium_basis_mol > 0 and mode == SPEC_MODE_CLOSED:
        if total_carbon + 1e-12 < total_na:
            retained = total_carbon / max(total_na, 1e-12)
            degassed_fraction = max(0.0, 1.0 - retained)
        elif total_carbon > total_na and volume_l > 0:
            if treat_excess_as_headspace:
                total_carbon = total_na
            else:
                headspace_kh_m_per_atm = None
                headspace_pco2_atm = None
    elif total_carbon > 0 and volume_l > 0 and mode == SPEC_MODE_CLOSED:
        headspace_kh_m_per_atm = 1.0
        headspace_pco2_atm = total_carbon / volume_l

    return SolubilityInputs(
        mass_na_hco3_g=mass_na_hco3_g,
        water_mass_g=None,
        solution_volume_l=volume_l,
        temperature_c=temperature_c,
        initial_ph_guess=initial_ph_guess,
        forced_ph_target=base_params.forced_ph_target,
        use_temperature_adjusted_constants=use_temp_adjusted_constants,
        ionic_strength_cap=ionic_strength_cap,
        headspace_pco2_atm=headspace_pco2_atm,
        headspace_kh_m_per_atm=headspace_kh_m_per_atm,
        degassed_fraction=degassed_fraction,
        total_inorganic_carbon_mol=total_carbon,
        headspace_volume_l=headspace_volume_value,
        speciation_mode=mode,
    )


def _estimate_highly_basic_ph(
    ledger_state: Optional[Dict[str, float]],
    *,
    volume_l: Optional[float],
    temperature_c: Optional[float],
    use_temp_adjusted_constants: bool,
) -> Optional[float]:
    """Estimate highly basic pH.
    Used to approximate highly basic pH for model workflows."""
    if ledger_state is None or volume_l is None or volume_l <= 0:
        return None
    naoh_remaining = max(ledger_state.get("naoh_remaining_mol", 0.0), 0.0)
    _, _, kw = _basic_carbonate_constants(temperature_c, use_temp_adjusted_constants)
    pkw = -math.log10(max(kw, 1e-30))
    if naoh_remaining > 0:
        # 2 OH- per NaOH remaining (fully dissociated)
        oh_conc = max(naoh_remaining * 2.0 / volume_l, 1e-12)
        ph = pkw + math.log10(oh_conc)
        return _clamp_ph_value(ph)
    na2co3 = max(ledger_state.get("na2co3_mol", 0.0), 0.0)
    nahco3 = max(ledger_state.get("nahco3_mol", 0.0), 0.0)
    if na2co3 <= 0 and nahco3 <= 0:
        return None
    pka2 = _resolve_pka2_value(temperature_c, use_temp_adjusted_constants)
    ratio = max(na2co3 / max(nahco3, 1e-12), 1e-12)
    ph = pka2 + math.log10(ratio)
    return _clamp_ph_value(ph)


class DebyeHuckelSpeciationModel:
    """Default Debye–Hückel activity-corrected speciation model."""

    key = "debye_huckel_full"
    label = "Debye–Hückel (Full)"
    description = (
        "Uses temperature-adjusted pKa relationships (Harned & Davis) with Debye–Hückel activity "
        "coefficients to resolve carbonate speciation, ionic strength, and saturation indices."
    )
    metadata = ModelMetadata(
        reference="Harned & Davis / Stumm & Morgan",
        temperature_range_c=(0.0, 80.0),
        ionic_strength_limit=None,
        notes="Best for dilute-to-moderate electrolytes where Debye–Hückel assumptions hold.",
    )

    def _normalize_options(
        self, options: Optional[ModelOptions]
    ) -> Optional[ModelOptions]:
        """Normalize options.
        Used to keep options consistent across workflows and persistence."""
        return options

    def solve(
        self,
        params: SolubilityInputs,
        *,
        model_options: Optional[ModelOptions] = None,
        math_logger: Optional[SolubilityMathLogger] = None,
        math_section: str = "Speciation",
    ) -> SolubilitySpeciationResult:
        """Solve value.
        Used to run the solver for value workflows."""
        normalized = self._normalize_options(model_options)
        constants = _resolve_solubility_constants(
            params, math_logger=math_logger, section=math_section
        )
        return solubility_solve_speciation(
            params,
            constants=constants,
            math_logger=math_logger,
            math_section=math_section,
            model_options=normalized,
        )

    def solve_forced_ph(
        self,
        params: SolubilityInputs,
        forced_ph: float,
        *,
        model_options: Optional[ModelOptions] = None,
        math_logger: Optional[SolubilityMathLogger] = None,
        math_section: str = "Forced pH Speciation",
    ) -> SolubilitySpeciationResult:
        """Solve forced pH.
        Used to run the solver for forced pH workflows."""
        normalized = self._normalize_options(model_options)
        constants = _resolve_solubility_constants(
            params, math_logger=math_logger, section=math_section
        )
        return solubility_speciation_at_forced_ph(
            params,
            forced_ph,
            constants=constants,
            math_logger=math_logger,
            math_section=math_section,
            model_options=normalized,
        )

    def generate_ph_sweep(
        self,
        params: SolubilityInputs,
        sweep_low: float,
        sweep_high: float,
        sweep_steps: int,
        *,
        model_options: Optional[ModelOptions] = None,
        math_logger: Optional[SolubilityMathLogger] = None,
    ) -> List[Dict[str, float]]:
        """Generate pH sweep.
        Used to produce pH sweep outputs for analysis or export."""
        normalized = self._normalize_options(model_options)
        constants = _resolve_solubility_constants(
            params, math_logger=math_logger, section="pH Sweep"
        )
        return solubility_generate_ph_sweep(
            params,
            constants,
            sweep_low,
            sweep_high,
            sweep_steps,
            math_logger=math_logger,
            model_options=normalized,
        )

    def generate_sensitivity_rows(
        self,
        params: SolubilityInputs,
        enabled_axes: Dict[str, bool],
        *,
        model_options: Optional[ModelOptions] = None,
        math_logger: Optional[SolubilityMathLogger] = None,
    ) -> List[Dict[str, str]]:
        """Generate sensitivity rows.
        Used to produce sensitivity rows outputs for analysis or export."""
        normalized = self._normalize_options(model_options)
        return solubility_sensitivity_analysis(
            params,
            enabled_axes,
            math_logger=math_logger,
            model_options=normalized,
        )


class DebyeHuckelCappedModel(DebyeHuckelSpeciationModel):
    """Variant that enforces an ionic strength cap suitable for dense liquors."""

    key = "debye_huckel_capped"
    label = "Debye–Hückel (Capped)"
    description = (
        "Applies a configurable ionic strength cap (default 0.5 M) before solving, highlighting when "
        "activity corrections become unreliable at high concentrations."
    )
    metadata = ModelMetadata(
        reference="Harned & Davis / Davies activity adjustments",
        temperature_range_c=(0.0, 80.0),
        ionic_strength_limit=0.5,
        notes="Automatically caps ionic strength to 0.5 M to stabilize Debye–Hückel iterations.",
    )

    def _normalize_options(
        self, options: Optional[ModelOptions]
    ) -> Optional[ModelOptions]:
        """Normalize options.
        Used to keep options consistent across workflows and persistence."""
        limit = self.metadata.ionic_strength_limit
        if limit is None:
            return options
        if options is None:
            return ModelOptions(override_ionic_strength_cap=limit)
        if options.override_ionic_strength_cap is None:
            return replace(options, override_ionic_strength_cap=limit)
        return options


class DaviesLimitedModel(DebyeHuckelSpeciationModel):
    """Davies-inspired variant with extra ionic-strength awareness."""

    key = "davies_limited"
    label = "Davies (Limited)"
    description = "Limits ionic strength to a dilute Davies regime while still emitting the full speciation output."
    metadata = ModelMetadata(
        reference="Davies (1962)",
        temperature_range_c=(0.0, 45.0),
        ionic_strength_limit=0.3,
        notes="Constrains ionic strength to 0.30 M; ideal for dilute liquor estimates.",
    )

    def _normalize_options(
        self, options: Optional[ModelOptions]
    ) -> Optional[ModelOptions]:
        """Normalize options.
        Used to keep options consistent across workflows and persistence."""
        limit = self.metadata.ionic_strength_limit
        if limit is None:
            return options
        if options is None:
            return ModelOptions(override_ionic_strength_cap=limit)
        if options.override_ionic_strength_cap is None:
            return replace(options, override_ionic_strength_cap=limit)
        return options


class PitzerLiteModel(DebyeHuckelSpeciationModel):
    """Pitzer-style activity core with a higher ionic strength ceiling."""

    key = "pitzer_lite"
    label = "Pitzer (Lite)"
    description = (
        "Simplified Pitzer corrections that tolerate higher ionic strength while still "
        "reporting the full speciation output."
    )
    metadata = ModelMetadata(
        reference="Pitzer (1980)",
        temperature_range_c=(2.0, 90.0),
        ionic_strength_limit=1.2,
        notes="Caps ionic strength at 1.2 M and uses a lightweight Pitzer activity model.",
    )

    def _normalize_options(
        self, options: Optional[ModelOptions]
    ) -> Optional[ModelOptions]:
        """Normalize options.
        Used to keep options consistent across workflows and persistence."""
        normalized = super()._normalize_options(options)
        limit = self.metadata.ionic_strength_limit
        base = normalized or ModelOptions()
        extra = dict(base.extra)
        extra["activity_model"] = "pitzer-lite"
        overrides: Dict[str, Any] = {
            "activity_model": "pitzer-lite",
            "extra": extra,
        }
        if limit is not None and base.override_ionic_strength_cap is None:
            overrides["override_ionic_strength_cap"] = limit
        return replace(base, **overrides)


_NAOH_PITZER_PARAMS = None
_NAOH_PITZER_LOAD_ERROR = None
_NAOH_PITZER_PATH = None


def _load_naoh_pitzer_params() -> Optional[Any]:
    """Load NaOH Pitzer params.
    Used when restoring NaOH Pitzer params from storage."""
    global _NAOH_PITZER_PARAMS, _NAOH_PITZER_LOAD_ERROR, _NAOH_PITZER_PATH
    if _NAOH_PITZER_PARAMS is not None:
        return _NAOH_PITZER_PARAMS
    if _NAOH_PITZER_LOAD_ERROR is not None:
        return None
    if _NAOH_PITZER_MODULE is None:
        _NAOH_PITZER_LOAD_ERROR = RuntimeError("naoh_co2_pitzer_ph_model unavailable")
        return None
    pitzer_candidates = []
    try:
        pitzer_candidates.append(Path(_NAOH_PITZER_MODULE.DEFAULT_PITZER_PATH))
    except Exception:
        pitzer_candidates = []
    pitzer_candidates.append(Path.cwd() / "pitzer.dat")
    try:
        pitzer_candidates.append(Path(__file__).resolve().parent / "pitzer.dat")
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    pitzer_path = next((p for p in pitzer_candidates if p and p.is_file()), None)
    if pitzer_path is None:
        _NAOH_PITZER_LOAD_ERROR = FileNotFoundError(
            "Pitzer database not found for NaOH-CO2 Pitzer model."
        )
        print(f"[WARN] {_NAOH_PITZER_LOAD_ERROR}")
        return None
    try:
        _NAOH_PITZER_PARAMS = _NAOH_PITZER_MODULE.read_pitzer_params(pitzer_path)
        _NAOH_PITZER_PATH = pitzer_path
    except Exception as exc:
        _NAOH_PITZER_LOAD_ERROR = exc
        print(f"[WARN] NaOH-CO2 Pitzer model failed to load parameters: {exc}")
        return None
    return _NAOH_PITZER_PARAMS


class NaohCo2PitzerHmwModel(PitzerLiteModel):
    """Focused NaOH-CO2 Pitzer (HMW/PHREEQC) planning pH model."""

    key = "naoh_co2_pitzer_hmw"
    label = "NaOH-CO2 Pitzer (HMW / PHREEQC-style Na-CO3 pairing)"
    description = (
        "Closed-system NaOH-CO2 pH model using focused PHREEQC HMW Pitzer parameters "
        "for Na+ pairing with CO3/HCO3/OH; planning pH is driven by cumulative CO2 charged."
    )
    metadata = ModelMetadata(
        reference="PHREEQC pitzer.dat (HMW) + focused NaOH-CO2 activity fit",
        temperature_range_c=(0.0, 60.0),
        ionic_strength_limit=None,
        notes="Uses the HMW Pitzer parameters for Na+, CO3^2-, HCO3-, and OH-.",
    )

    def __init__(self, pitzer_params: Any, pitzer_path: Optional[Path] = None) -> None:
        """Initialize NaohCo2PitzerHmwModel instance.
        Used at object creation to configure initial state and bindings."""
        super().__init__()
        self._pitzer_params = pitzer_params
        self._pitzer_path = pitzer_path

    def _water_ml_from_context(
        self, planning_context: Dict[str, Any]
    ) -> Optional[float]:
        """Perform water ml from context.
        Used to keep the workflow logic localized and testable."""
        volume_l = _safe_float(planning_context.get("solution_volume_l"))
        if volume_l is not None and volume_l > 0:
            return volume_l * 1000.0
        water_mass_g = _safe_float(planning_context.get("water_mass_g"))
        if water_mass_g is not None and water_mass_g > 0:
            return water_mass_g / SOL_WATER_DENSITY_25C_G_PER_ML
        return None

    def predict_planning_ph(
        self,
        *,
        planning_context: Dict[str, Any],
        cumulative_co2_moles: float,
        cycle_index: int,
    ) -> Tuple[Optional[float], Optional[Dict[str, float]]]:
        """Predict planning pH.
        Used to compute planning pH for planning workflows."""
        if _NAOH_PITZER_MODULE is None or self._pitzer_params is None:
            return None, None
        water_ml = self._water_ml_from_context(planning_context)
        if water_ml is None or water_ml <= 0:
            return None, None
        naoh_g = _safe_float(planning_context.get("naoh_mass_g"))
        if naoh_g is None or naoh_g <= 0:
            return None, None
        temperature_c = _safe_float(planning_context.get("temperature_c"))
        if temperature_c is None or not math.isfinite(temperature_c):
            temperature_c = 25.0
        headspace_l = _safe_float(planning_context.get("headspace_volume_l")) or 0.0
        p_high_psig = (
            _safe_float(planning_context.get("planning_headspace_pressure_high_psi"))
            or 0.0
        )
        delta_p_psig = (
            _safe_float(planning_context.get("planning_cycle_delta_p_psi")) or 0.0
        )
        cfg = _NAOH_PITZER_MODULE.SystemConfig(
            water_mL=water_ml,
            naoh_g=naoh_g,
            temperature_C=temperature_c,
            headspace_L=headspace_l,
            P_high_psig=p_high_psig,
            dP_psig=delta_p_psig,
            KH_m_per_kg_atm=getattr(
                _NAOH_PITZER_MODULE.SystemConfig, "KH_m_per_kg_atm", 0.034
            ),
        )
        kgw = max(cfg.water_mL / 1000.0, 1e-9)
        na_total_m = (cfg.naoh_g / SOL_MW_NAOH) / kgw
        ct_m = cumulative_co2_moles / kgw
        ph_value, comp = _NAOH_PITZER_MODULE.solve_pH_for_total_carbon(
            CT_m=ct_m, NaT_m=na_total_m, p=self._pitzer_params
        )
        species = {
            "m_OH": comp.get("OH-", 0.0),
            "m_HCO3": comp.get("HCO3-", 0.0),
            "m_CO3": comp.get("CO3-2", 0.0),
            "m_CO2": comp.get("CO2", 0.0),
        }
        return ph_value, species


def _resolve_closed_carbon_inventory(
    params: SolubilityInputs,
) -> Tuple[float, Dict[str, float]]:
    """Resolve closed carbon inventory.
    Used to compute closed carbon inventory before rendering or export."""
    volume_l = max(params.volume_l(), 1e-12)
    try:
        sodium_capacity = max(params.sodium_concentration(), 0.0)
    except Exception:
        sodium_capacity = 0.0

    headspace_target = max(params.headspace_target_h2co3() or 0.0, 0.0)
    headspace_inventory_mode = (
        params.headspace_pco2_atm is not None
        and params.headspace_pco2_atm > 0
        and params.headspace_kh_m_per_atm is not None
        and params.headspace_kh_m_per_atm >= 0.2
    )

    base_dissolved = max(params.total_carbon_concentration(), 0.0)
    explicit_total = getattr(params, "total_inorganic_carbon_mol", None)
    if explicit_total is not None:
        try:
            inventory_conc = (
                max(explicit_total, 0.0) / volume_l * params._retained_carbon_fraction()
            )
        except Exception:
            inventory_conc = base_dissolved + params.headspace_carbon_contribution()
    else:
        inventory_conc = base_dissolved + params.headspace_carbon_contribution()

    baseline_headspace_ct = 0.0 if headspace_inventory_mode else headspace_target
    capacity_conc = (
        sodium_capacity + baseline_headspace_ct
        if sodium_capacity > 0
        else baseline_headspace_ct
    )
    dissolved_conc = (
        inventory_conc if capacity_conc <= 0 else min(inventory_conc, capacity_conc)
    )
    excess_conc = max(inventory_conc - dissolved_conc, 0.0)

    kh_effective = params.headspace_kh_m_per_atm or 0.033
    base_pco2 = params.headspace_pco2_atm if not headspace_inventory_mode else 0.0
    headspace_volume = getattr(params, "headspace_volume_l", None)
    if headspace_volume is not None and headspace_volume <= 0:
        headspace_volume = None
    pco2_from_excess = 0.0
    if excess_conc > 0:
        if headspace_volume and headspace_volume > 0:
            temp_k = _clamp_temperature(params.temperature_c) + 273.15
            pco2_from_excess = (
                excess_conc
                * volume_l
                * _SOL_IDEAL_GAS_R_L_ATM_PER_MOLK
                * temp_k
                / headspace_volume
            )
        elif kh_effective > 0:
            pco2_from_excess = excess_conc / kh_effective

    dynamic_pco2 = (base_pco2 or 0.0) + pco2_from_excess
    context = {
        "inventory_conc": inventory_conc,
        "dissolved_conc": dissolved_conc,
        "capacity_conc": capacity_conc,
        "excess_conc": excess_conc,
        "headspace_inventory_mode": headspace_inventory_mode,
        "headspace_volume_l": headspace_volume,
        "pco2_from_excess": pco2_from_excess,
        "dynamic_pco2": dynamic_pco2,
        "base_pco2": base_pco2 or 0.0,
        "kh_effective": kh_effective,
        "sodium_capacity": sodium_capacity,
        "headspace_target": headspace_target,
        "solution_volume_l": volume_l,
    }
    return dissolved_conc, context


def _headspace_assumptions_from_ctx(ctx: Mapping[str, Any]) -> List[str]:
    """Perform headspace assumptions from ctx.
    Used to keep the workflow logic localized and testable."""
    if not ctx:
        return []
    assumptions: List[str] = []
    excess = ctx.get("excess_conc", 0.0) or 0.0
    dynamic_pco2 = ctx.get("dynamic_pco2")
    dissolved = ctx.get("dissolved_conc")
    volume = ctx.get("headspace_volume_l")
    if excess > 1e-9:
        capped = f"{dissolved:.3e}" if dissolved is not None else "n/a"
        assumptions.append(
            f"Excess CO2 beyond sodium equivalence diverted to headspace; dissolved CT capped at {capped} mol/L."
        )
        if dynamic_pco2 is not None:
            if volume is not None:
                assumptions.append(
                    f"Estimated headspace pCO2 rises to {dynamic_pco2:.3e} atm (headspace {volume:.3f} L)."
                )
            else:
                assumptions.append(
                    f"Estimated headspace pCO2 rises to {dynamic_pco2:.3e} atm."
                )
    else:
        inventory_mode = bool(ctx.get("headspace_inventory_mode", False))
        if inventory_mode:
            assumptions.append(
                "Headspace CO2 treated as a variable inventory once sodium equivalence is met."
            )
        elif dynamic_pco2:
            assumptions.append(
                f"Headspace boundary applied at {dynamic_pco2:.3e} atm pCO2 (Henry's law)."
            )
    return assumptions


class AqionClosedSpeciationModel:
    """
    Sodium-free closed CO2 system matching aqion.de/site/160.

    Ignores saturation, sodium balance, and headspace exchange; uses the
    closed-system charge balance plus alpha fractions for H2CO3*, HCO3-, CO3^2-.
    """

    key = "aqion_closed"
    label = "Aqion Closed CO2"
    description = (
        "Closed CO2 system (H2CO3*/HCO3-/CO3^2-) without sodium or saturation; "
        "aligns with aqion.de/site/160."
    )
    metadata = ModelMetadata(
        reference="aqion.de/site/160",
        temperature_range_c=(0.0, 80.0),
        ionic_strength_limit=None,
        notes=(
            "Closed CO2 speciation using thermodynamic constants; ignores Na+, "
            "solids, and gas exchange. Uses user temperature if enabled."
        ),
    )

    def _normalize_options(
        self, options: Optional[ModelOptions]
    ) -> Optional[ModelOptions]:
        """Normalize options.
        Used to keep options consistent across workflows and persistence."""
        return options

    @staticmethod
    def _closed_inputs(
        params: SolubilityInputs,
    ) -> Tuple[ClosedCarbonateInputs, Dict[str, Any]]:
        """Perform closed inputs.
        Used to keep the workflow logic localized and testable."""
        ka1, ka2, kw = _basic_carbonate_constants(
            params.temperature_c, params.use_temperature_adjusted_constants
        )
        dissolved_ct, headspace_ctx = _resolve_closed_carbon_inventory(params)
        closed_inputs = ClosedCarbonateInputs(
            total_inorganic_carbon_m=max(dissolved_ct, 0.0),
            temperature_c=params.temperature_c,
            ka1=ka1,
            ka2=ka2,
            kw=kw,
        )
        headspace_ctx = dict(headspace_ctx)
        headspace_ctx.update({"ka1": ka1, "ka2": ka2, "kw": kw})
        return closed_inputs, headspace_ctx

    @staticmethod
    def _species_at_ph(
        ct: float, ph: float, ka1: float, ka2: float, kw: float
    ) -> Tuple[Dict[str, float], Dict[str, float], float, float]:
        """Perform species at pH.
        Used to keep the workflow logic localized and testable."""
        h = 10.0 ** (-ph)
        denom = (h * h) + (ka1 * h) + (ka1 * ka2)
        if denom <= 0:
            denom = 1e-30
        a0 = (h * h) / denom
        a1 = (ka1 * h) / denom
        a2 = (ka1 * ka2) / denom
        h2co3 = ct * a0
        hco3 = ct * a1
        co3 = ct * a2
        oh = kw / max(h, 1e-30)
        alpha = {"a0": a0, "a1": a1, "a2": a2}
        species = {
            "H+": h,
            "H2CO3": h2co3,
            "HCO3-": hco3,
            "CO3^2-": co3,
            "OH-": oh,
        }
        return species, alpha, h, oh

    @staticmethod
    def _ionic_strength(species: Dict[str, float]) -> float:
        """Perform ionic strength.
        Used to keep the workflow logic localized and testable."""
        return 0.5 * (
            species.get("H+", 0.0)
            + species.get("HCO3-", 0.0)
            + 4.0 * species.get("CO3^2-", 0.0)
            + species.get("OH-", 0.0)
        )

    def _build_result(
        self,
        params: SolubilityInputs,
        ph: float,
        species: Dict[str, float],
        ionic_strength: float,
        solver_tag: str,
        constant_notes: Sequence[str],
        extra_assumptions: Sequence[str] = (),
    ) -> SolubilitySpeciationResult:
        """Build result.
        Used to assemble result during UI or plot setup."""
        volume = params.volume_l()
        concentrations = {
            "Na+": 0.0,
            "H+": species["H+"],
            "HCO3-": species["HCO3-"],
            "CO3^2-": species["CO3^2-"],
            "H2CO3": species["H2CO3"],
            "OH-": species["OH-"],
        }
        moles = {k: v * volume for k, v in concentrations.items()}
        fractional = _solubility_fractional_carbon(concentrations)
        mass_conc = _solubility_mass_concentrations(concentrations)
        charge_residual = _solubility_charge_balance(concentrations)
        alkalinity_meq = (
            concentrations["HCO3-"]
            + 2.0 * concentrations["CO3^2-"]
            + concentrations["OH-"]
            - concentrations["H+"]
        ) * 1000.0
        total_carbon = (
            concentrations["H2CO3"] + concentrations["HCO3-"] + concentrations["CO3^2-"]
        )
        assumptions = [
            "Closed CO2 system (no sodium or solids).",
            "Activity coefficients assumed ideal (γ = 1).",
            "Saturation indices skipped for the closed Aqion model.",
        ]
        if extra_assumptions:
            assumptions.extend(extra_assumptions)
        warnings: List[str] = []
        if abs(charge_residual) > 1e-8:
            warnings.append(
                f"Charge balance residual {charge_residual:+.2e} mol/L in closed-system solve."
            )
        warnings.extend(constant_notes)
        return SolubilitySpeciationResult(
            concentrations_m=concentrations,
            moles=moles,
            activity_coefficients={
                ion: 1.0 for ion in ("Na+", "H+", "HCO3-", "CO3^2-", "OH-")
            },
            ionic_strength=ionic_strength,
            ph=ph,
            saturation_indices={"NaHCO3": 0.0, "Na2CO3": 0.0},
            fractional_carbon=fractional,
            mass_concentrations_g_per_l=mass_conc,
            alkalinity_meq_per_l=alkalinity_meq,
            total_carbon_m=total_carbon,
            charge_balance_residual=charge_residual,
            assumptions=assumptions,
            warnings=warnings,
            carbonate_as_na2co3_wt_percent=None,
            ionic_strength_capped=False,
            dissolved_mass_na_hco3_g=None,
            undissolved_mass_na_hco3_g=None,
            dissolved_fraction=None,
        )

    def solve(
        self,
        params: SolubilityInputs,
        *,
        model_options: Optional[ModelOptions] = None,
        math_logger: Optional[SolubilityMathLogger] = None,
        math_section: str = "Speciation",
    ) -> SolubilitySpeciationResult:
        """Solve value.
        Used to run the solver for value workflows."""
        closed_inputs, headspace_ctx = self._closed_inputs(params)
        constant_notes = []
        if params.use_temperature_adjusted_constants:
            constant_notes.append(
                f"Equilibrium constants adjusted for {params.temperature_c:.1f} C."
            )
        headspace_assumptions = _headspace_assumptions_from_ctx(headspace_ctx)
        result = solve_closed_carbonate_system(closed_inputs, validate_quartic=True)
        species = {
            "H+": result.h_conc,
            "H2CO3": result.species_m.get("H2CO3", 0.0),
            "HCO3-": result.species_m.get("HCO3-", 0.0),
            "CO3^2-": result.species_m.get("CO3^2-", 0.0),
            "OH-": result.oh_conc,
        }
        if math_logger:
            math_logger.log(
                math_section,
                "Closed-system solver",
                "Root solve via charge balance",
                f"pH {result.ph:.2f} (solver={result.solver})",
                "",
                steps=(),
            )
        return self._build_result(
            params,
            result.ph,
            species,
            result.ionic_strength,
            result.solver,
            constant_notes,
            headspace_assumptions,
        )

    def solve_forced_ph(
        self,
        params: SolubilityInputs,
        forced_ph: float,
        *,
        model_options: Optional[ModelOptions] = None,
        math_logger: Optional[SolubilityMathLogger] = None,
        math_section: str = "Forced pH Speciation",
    ) -> SolubilitySpeciationResult:
        """Solve forced pH.
        Used to run the solver for forced pH workflows."""
        if forced_ph <= 0 or forced_ph >= 14:
            raise ValueError("Forced pH must be between 0 and 14.")
        closed_inputs, headspace_ctx = self._closed_inputs(params)
        headspace_assumptions = _headspace_assumptions_from_ctx(headspace_ctx)
        species, _, _, _ = self._species_at_ph(
            closed_inputs.total_inorganic_carbon_m,
            forced_ph,
            closed_inputs.ka1,
            closed_inputs.ka2,
            closed_inputs.kw,
        )
        ionic_strength = self._ionic_strength(species)
        return self._build_result(
            params,
            forced_ph,
            species,
            ionic_strength,
            "closed-alpha",
            [],
            headspace_assumptions,
        )

    def generate_ph_sweep(
        self,
        params: SolubilityInputs,
        sweep_low: float,
        sweep_high: float,
        sweep_steps: int,
        *,
        model_options: Optional[ModelOptions] = None,
        math_logger: Optional[SolubilityMathLogger] = None,
    ) -> List[Dict[str, float]]:
        """Generate pH sweep.
        Used to produce pH sweep outputs for analysis or export."""
        if sweep_steps <= 0 or sweep_high <= sweep_low:
            return []
        closed_inputs, _ = self._closed_inputs(params)
        curve = generate_closed_system_curve(
            closed_inputs,
            ph_range=(sweep_low, sweep_high),
            steps=sweep_steps,
        )
        sweep_data: List[Dict[str, float]] = []
        # Iterate over curve to apply the per-item logic.
        for row in curve:
            sweep_row = {
                "ph": row["ph"],
                "hco3_pct": row.get("alpha1", 0.0) * 100.0,
                "co3_pct": row.get("alpha2", 0.0) * 100.0,
                "h2co3_pct": row.get("alpha0", 0.0) * 100.0,
            }
            sweep_data.append(sweep_row)
        return sweep_data

    def generate_sensitivity_rows(
        self,
        params: SolubilityInputs,
        enabled_axes: Dict[str, bool],
        *,
        model_options: Optional[ModelOptions] = None,
        math_logger: Optional[SolubilityMathLogger] = None,
    ) -> List[Dict[str, str]]:
        """Generate sensitivity rows.
        Used to produce sensitivity rows outputs for analysis or export."""
        # Closed-system Aqion variant does not expose sensitivity toggles.
        return []


register_speciation_model(DebyeHuckelSpeciationModel())
register_speciation_model(DebyeHuckelCappedModel())
register_speciation_model(DaviesLimitedModel())
register_speciation_model(PitzerLiteModel())
register_speciation_model(AqionClosedSpeciationModel())
_naoh_pitzer_params = _load_naoh_pitzer_params()
if _naoh_pitzer_params is not None:
    register_speciation_model(
        NaohCo2PitzerHmwModel(_naoh_pitzer_params, pitzer_path=_NAOH_PITZER_PATH)
    )
elif _NAOH_PITZER_IMPORT_ERROR is not None or _NAOH_PITZER_LOAD_ERROR is not None:
    print("[WARN] NaOH-CO2 Pitzer model disabled; missing dependencies or data.")


def _solubility_extended_debye_huckel(
    ionic_strength: float, charge: int, ion_size_nm: float
) -> float:
    """Perform solubility extended debye huckel.
    Used to keep the workflow logic localized and testable."""
    if ionic_strength <= 1e-12 or charge == 0:
        return 1.0
    sqrt_i = math.sqrt(ionic_strength)
    denom = 1.0 + SOL_B_DEBYE * ion_size_nm * sqrt_i
    if denom == 0.0:
        denom = 1e-12
    exponent = -SOL_A_DEBYE * (charge**2) * sqrt_i / denom
    return 10.0**exponent


def _solubility_activity_coefficient(
    ionic_strength: float, charge: int, ion_size_nm: float
) -> float:
    """Perform solubility activity coefficient.
    Used to keep the workflow logic localized and testable."""

    if ionic_strength <= SOL_DAVIES_LIMIT:
        sqrt_i = math.sqrt(max(ionic_strength, 1e-12))
        log_gamma = (
            -SOL_A_DEBYE
            * (charge**2)
            * ((sqrt_i / (1.0 + sqrt_i)) - SOL_DAVIES_COEFF * ionic_strength)
        )
        return 10.0**log_gamma
    return _solubility_extended_debye_huckel(ionic_strength, charge, ion_size_nm)


def _solubility_ionic_state(
    na_conc: float,
    h_conc: float,
    hco3_conc: float,
    co3_conc: float,
    *,
    kw_value: float,
    ionic_strength_cap: Optional[float] = None,
) -> tuple[float, Dict[str, float], float]:
    """Perform solubility ionic state.
    Used to keep the workflow logic localized and testable."""
    ionic_strength = max(0.5 * (na_conc + h_conc + hco3_conc + 4.0 * co3_conc), 1e-12)
    if ionic_strength_cap is not None:
        ionic_strength = min(ionic_strength, ionic_strength_cap)
    gammas: Dict[str, float] = {}
    oh_conc = 1e-7
    # Iterate over the configured range to apply the per-item logic.
    for _ in range(24):
        gammas = {
            ion: _solubility_activity_coefficient(
                ionic_strength, SOL_ION_CHARGES[ion], SOL_ION_SIZES_NM[ion]
            )
            # Iterate to apply the per-item logic.
            for ion in ("Na", "H", "HCO3", "CO3", "OH")
        }
        oh_conc = kw_value / max(gammas["H"] * gammas["OH"] * h_conc, 1e-18)
        new_i = 0.5 * (na_conc + h_conc + hco3_conc + 4.0 * co3_conc + oh_conc)
        if ionic_strength_cap is not None:
            new_i = min(new_i, ionic_strength_cap)
        if abs(new_i - ionic_strength) < 1e-12:
            ionic_strength = new_i
            break
        ionic_strength = new_i
    return ionic_strength, gammas, oh_conc


def _solubility_solve_linear_system(
    matrix: List[List[float]], rhs: List[float]
) -> List[float]:
    """Solve linear system.
    Used by solubility workflows to solve linear system."""
    n = len(matrix)
    aug = [row[:] + [b] for row, b in zip(matrix, rhs)]
    # Iterate over the configured range to apply the per-item logic.
    for col in range(n):
        pivot_row = max(range(col, n), key=lambda r: abs(aug[r][col]))
        if abs(aug[pivot_row][col]) < 1e-14:
            raise ValueError("Singular matrix encountered in Newton step.")
        if pivot_row != col:
            aug[col], aug[pivot_row] = aug[pivot_row], aug[col]
        pivot = aug[col][col]
        # Iterate over the configured range to apply the per-item logic.
        for j in range(col, n + 1):
            aug[col][j] /= pivot
        # Iterate over the configured range to apply the per-item logic.
        for row in range(n):
            if row == col:
                continue
            factor = aug[row][col]
            # Iterate over the configured range to apply the per-item logic.
            for j in range(col, n + 1):
                aug[row][j] -= factor * aug[col][j]
    return [aug[i][n] for i in range(n)]


def _solubility_numerical_jacobian(
    func: Callable[[List[float]], List[float]],
    point: List[float],
    step_scale: float = 1e-6,
) -> List[List[float]]:
    """Perform solubility numerical jacobian.
    Used to keep the workflow logic localized and testable."""
    n = len(point)
    jacobian = [[0.0 for _ in range(n)] for _ in range(n)]
    # Iterate over the configured range to apply the per-item logic.
    for j in range(n):
        delta = step_scale * max(1.0, abs(point[j]))
        delta = max(delta, 1e-8)
        forward = point[:]
        backward = point[:]
        forward[j] += delta
        backward[j] -= delta
        fwd = func(forward)
        back = func(backward)
        # Iterate over the configured range to apply the per-item logic.
        for i in range(n):
            jacobian[i][j] = (fwd[i] - back[i]) / (2.0 * delta)
    return jacobian


def _solubility_newton_system_solve(
    func: Callable[[List[float]], List[float]],
    initial_guess: List[float],
    tol: float = 1e-12,
    max_iter: int = 60,
) -> List[float]:
    """Solve value.
    Used by solubility newton system workflows to solve value."""
    x = initial_guess[:]
    # Iterate over the configured range to apply the per-item logic.
    for _ in range(max_iter):
        residual = func(x)
        if not all(math.isfinite(val) for val in residual):
            raise RuntimeError("Non-finite residual encountered during solve.")
        if max(abs(val) for val in residual) < tol:
            return x
        jacobian = _solubility_numerical_jacobian(func, x)
        try:
            delta = _solubility_solve_linear_system(
                jacobian, [-val for val in residual]
            )
        except ValueError as exc:
            raise RuntimeError("Jacobian became singular.") from exc
        if not all(math.isfinite(val) for val in delta):
            raise RuntimeError("Non-finite Newton increment encountered.")
        x = [min(max(value + step, -25.0), 5.0) for value, step in zip(x, delta)]
        if max(abs(step) for step in delta) < tol:
            if max(abs(val) for val in func(x)) < tol:
                return x
    raise RuntimeError("Newton solver did not converge within the iteration limit.")


SPEC_MODE_FIXED_PCO2 = "fixed_pCO2"
SPEC_MODE_CLOSED = "closed_carbon"


def _normalize_speciation_mode(mode: Optional[str]) -> str:
    """Normalize speciation mode.
    Used to keep speciation mode consistent across workflows and persistence."""
    if mode == SPEC_MODE_CLOSED:
        return SPEC_MODE_CLOSED
    return SPEC_MODE_FIXED_PCO2


def _resolved_fixed_co2_boundary(
    params: SolubilityInputs,
) -> Tuple[float, List[str]]:
    """Perform resolved fixed CO2 boundary.
    Used to keep the workflow logic localized and testable."""
    notes: List[str] = []
    kh_value = params.headspace_kh_m_per_atm
    if kh_value is None or kh_value <= 0:
        kh_value = 0.033
        notes.append("Henry constant defaulted to 0.033 M/atm for CO2 dissolution.")
    pco2_value = params.headspace_pco2_atm
    if pco2_value is None or pco2_value <= 0:
        pco2_value = SOL_HEADSPACE_DEFAULT_PCO2_ATM
        notes.append(
            "No positive headspace pCO2 provided; using ambient 4.0e-4 atm as the fixed boundary."
        )
    return max(kh_value * pco2_value, 0.0), notes


def _solve_carbonate_state(
    total_carbon_m: float,
    na_conc: float,
    *,
    ka1: float,
    ka2: float,
    kw: float,
    ionic_strength_cap: Optional[float],
    initial_ph_guess: float,
    speciation_mode: Optional[str] = None,
    fixed_h2co3: Optional[float] = None,
) -> Tuple[float, float, float, float, float, Dict[str, float], float]:
    """Solve carbonate state.
    Used to run the solver for carbonate state workflows."""

    total_carbon_m = max(total_carbon_m, 1e-16)
    na_conc = max(na_conc, 0.0)
    mode = _normalize_speciation_mode(speciation_mode)
    fixed_h2co3_value = max(fixed_h2co3 or 0.0, 0.0)
    use_fixed_pco2 = mode == SPEC_MODE_FIXED_PCO2

    def build_log_vector_closed(
        pH: float, hco3_fraction: float, co3_fraction: float
    ) -> List[float]:
        """Build log vector closed.
        Used to assemble log vector closed during UI or plot setup."""
        H = 10.0 ** (-pH)
        hco3 = max(total_carbon_m * hco3_fraction, 1e-16)
        co3 = max(total_carbon_m * co3_fraction, 1e-16)
        remainder = total_carbon_m - (hco3 + co3)
        h2co3 = max(remainder if remainder > 0 else total_carbon_m * 1e-3, 1e-16)
        return [math.log10(H), math.log10(hco3), math.log10(co3), math.log10(h2co3)]

    def residuals_closed(log_vars: List[float]) -> List[float]:
        """Perform residuals closed.
        Used to keep the workflow logic localized and testable."""
        H = 10.0 ** log_vars[0]
        HCO3 = 10.0 ** log_vars[1]
        CO3 = 10.0 ** log_vars[2]
        H2CO3 = 10.0 ** log_vars[3]
        ionic_strength, gammas, OH = _solubility_ionic_state(
            na_conc,
            H,
            HCO3,
            CO3,
            kw_value=kw,
            ionic_strength_cap=ionic_strength_cap,
        )
        Ka1_actual = (gammas["H"] * gammas["HCO3"] * H * HCO3) / max(H2CO3, 1e-16)
        Ka2_actual = (gammas["H"] * gammas["CO3"] * H * CO3) / (gammas["HCO3"] * HCO3)
        eq1 = math.log10(Ka1_actual / ka1)
        eq2 = math.log10(Ka2_actual / ka2)
        eq3 = H2CO3 + HCO3 + CO3 - total_carbon_m
        eq4 = na_conc + H - HCO3 - 2.0 * CO3 - OH
        return [eq1, eq2, eq3, eq4]

    def build_log_vector_open(pH: float) -> List[float]:
        """Build log vector open.
        Used to assemble log vector open during UI or plot setup."""
        # Seed guesses from Henry's law boundary; CO2(aq) is fixed by pCO2 and KH.
        H = 10.0 ** (-pH)
        hco3_guess = max((ka1 * max(fixed_h2co3_value, 1e-16)) / max(H, 1e-16), 1e-16)
        co3_guess = max((ka2 * hco3_guess) / max(H, 1e-16), 1e-16)
        return [math.log10(H), math.log10(hco3_guess), math.log10(co3_guess)]

    def residuals_open(log_vars: List[float]) -> List[float]:
        """Open value.
        Used by residuals workflows to open value."""
        H = 10.0 ** log_vars[0]
        HCO3 = 10.0 ** log_vars[1]
        CO3 = 10.0 ** log_vars[2]
        ionic_strength, gammas, OH = _solubility_ionic_state(
            na_conc,
            H,
            HCO3,
            CO3,
            kw_value=kw,
            ionic_strength_cap=ionic_strength_cap,
        )
        Ka1_actual = (gammas["H"] * gammas["HCO3"] * H * HCO3) / max(
            fixed_h2co3_value, 1e-16
        )
        Ka2_actual = (gammas["H"] * gammas["CO3"] * H * CO3) / (gammas["HCO3"] * HCO3)
        eq1 = math.log10(Ka1_actual / ka1)
        eq2 = math.log10(Ka2_actual / ka2)
        # Charge balance (Na+ + H+) == (HCO3- + 2*CO3^2- + OH-)
        eq3 = na_conc + H - HCO3 - 2.0 * CO3 - OH
        return [eq1, eq2, eq3]

    solution: Optional[List[float]] = None
    if use_fixed_pco2:
        guess_ph_values = [
            initial_ph_guess,
            8.2,
            7.8,
            9.0,
        ]
        # Iterate over guess_ph_values to apply the per-item logic.
        for pH_guess in guess_ph_values:
            try:
                solution = _solubility_newton_system_solve(
                    residuals_open, build_log_vector_open(pH_guess)
                )
                break
            except RuntimeError:
                continue
    else:
        guess_specs = [
            (initial_ph_guess, 0.85, 0.12),
            (8.8, 0.80, 0.19),
            (7.5, 0.95, 0.03),
            (9.2, 0.70, 0.29),
        ]
        # Iterate over guess_specs to apply the per-item logic.
        for pH_guess, hco3_frac, co3_frac in guess_specs:
            try:
                solution = _solubility_newton_system_solve(
                    residuals_closed,
                    build_log_vector_closed(pH_guess, hco3_frac, co3_frac),
                )
                break
            except RuntimeError:
                continue
    if solution is None:
        raise RuntimeError(
            "Equilibrium solver did not converge. Try different inputs or adjust the initial pH guess."
        )

    if use_fixed_pco2:
        H = 10.0 ** solution[0]
        HCO3 = 10.0 ** solution[1]
        CO3 = 10.0 ** solution[2]
        H2CO3 = max(fixed_h2co3_value, 1e-16)
    else:
        H = 10.0 ** solution[0]
        HCO3 = 10.0 ** solution[1]
        CO3 = 10.0 ** solution[2]
        H2CO3 = 10.0 ** solution[3]
    ionic_strength, gammas, OH = _solubility_ionic_state(
        na_conc,
        H,
        HCO3,
        CO3,
        kw_value=kw,
        ionic_strength_cap=ionic_strength_cap,
    )
    return H, HCO3, CO3, H2CO3, OH, gammas, ionic_strength


def _solubility_speciation_for_inventory(
    params: SolubilityInputs,
    total_carbon: float,
    na_conc: float,
    constants: Tuple[float, float, float, List[str]],
    *,
    saturation_enforced: Optional[Sequence[str]] = None,
    speciation_mode: Optional[str] = None,
    fixed_h2co3: Optional[float] = None,
) -> SolubilitySpeciationResult:
    """Perform solubility speciation for inventory.
    Used to keep the workflow logic localized and testable."""
    ka1, ka2, kw, constant_notes = constants
    mode = _normalize_speciation_mode(
        speciation_mode or getattr(params, "speciation_mode", None)
    )
    fixed_h2co3_value = fixed_h2co3
    if mode == SPEC_MODE_FIXED_PCO2:
        boundary, notes = _resolved_fixed_co2_boundary(params)
        fixed_h2co3_value = boundary if fixed_h2co3_value is None else fixed_h2co3_value
        constant_notes = list(constant_notes) + notes
    (
        H,
        HCO3,
        CO3,
        H2CO3,
        OH,
        gammas,
        ionic_strength,
    ) = _solve_carbonate_state(
        total_carbon,
        na_conc,
        ka1=ka1,
        ka2=ka2,
        kw=kw,
        ionic_strength_cap=params.ionic_strength_cap,
        initial_ph_guess=params.initial_ph_guess,
        speciation_mode=mode,
        fixed_h2co3=fixed_h2co3_value,
    )
    volume = params.volume_l()
    ph = -math.log10(H)
    concentrations = {
        "Na+": na_conc,
        "H+": H,
        "HCO3-": HCO3,
        "CO3^2-": CO3,
        "H2CO3": H2CO3,
        "OH-": OH,
    }
    moles = {species: conc * volume for species, conc in concentrations.items()}
    activity_coeffs = {
        "Na+": gammas["Na"],
        "H+": gammas["H"],
        "HCO3-": gammas["HCO3"],
        "CO3^2-": gammas["CO3"],
        "OH-": gammas["OH"],
    }
    a_na = gammas["Na"] * na_conc
    a_hco3 = gammas["HCO3"] * HCO3
    a_co3 = gammas["CO3"] * CO3
    saturation_indices = {
        "NaHCO3": (a_na * a_hco3) / SOL_KSP_NAHCO3,
        "Na2CO3": (a_na**2 * a_co3) / SOL_KSP_NA2CO3,
    }
    ionic_strength_capped = (
        params.ionic_strength_cap is not None
        and ionic_strength >= params.ionic_strength_cap * 0.999
    )
    return _solubility_finalize_result(
        params=params,
        volume=volume,
        ionic_strength=ionic_strength,
        ph=ph,
        concentrations=concentrations,
        moles=moles,
        activity_coeffs=activity_coeffs,
        saturation_indices=saturation_indices,
        constant_notes=constant_notes,
        ionic_strength_capped=ionic_strength_capped,
        kw_value=kw,
        dissolved_na_moles=na_conc * volume,
        saturation_enforced=saturation_enforced,
        fixed_co2_boundary=fixed_h2co3_value if mode == SPEC_MODE_FIXED_PCO2 else None,
        speciation_mode=mode,
    )


def _solubility_within_saturation_limits(
    spec: SolubilitySpeciationResult, tol: float = SOL_SATURATION_TOL
) -> bool:
    """Perform solubility within saturation limits.
    Used to keep the workflow logic localized and testable."""
    return all(ratio <= 1.0 + tol for ratio in spec.saturation_indices.values())


def _solubility_apply_saturation_limits(
    params: SolubilityInputs,
    constants: Tuple[float, float, float, List[str]],
    sodium_conc: float,
    base_carbon_conc: float,
    headspace_conc: float,
    *,
    speciation_mode: Optional[str],
    fixed_h2co3: Optional[float],
) -> SolubilitySpeciationResult:
    """Apply saturation limits.
    Used by solubility workflows to apply saturation limits."""
    mode = _normalize_speciation_mode(
        speciation_mode or getattr(params, "speciation_mode", None)
    )
    base_total = (
        max(base_carbon_conc, 1e-12)
        if mode == SPEC_MODE_FIXED_PCO2
        else max(base_carbon_conc + headspace_conc, 1e-12)
    )
    equilibrium = _solubility_speciation_for_inventory(
        params,
        base_total,
        sodium_conc,
        constants,
        speciation_mode=mode,
        fixed_h2co3=fixed_h2co3,
    )
    limiters = [
        salt
        # Iterate to apply the per-item logic.
        for salt, ratio in equilibrium.saturation_indices.items()
        if ratio > 1.0 + SOL_SATURATION_TOL
    ]
    if not limiters:
        return equilibrium
    lo_frac = 0.0
    hi_frac = 1.0
    best_frac: Optional[float] = None
    # Iterate over the configured range to apply the per-item logic.
    for _ in range(48):
        mid = max((lo_frac + hi_frac) * 0.5, 1e-6)
        na_mid = sodium_conc * mid
        carbon_mid = (
            max(base_carbon_conc * mid, 1e-12)
            if mode == SPEC_MODE_FIXED_PCO2
            else max(base_carbon_conc * mid + headspace_conc, 1e-12)
        )
        candidate = _solubility_speciation_for_inventory(
            params,
            carbon_mid,
            na_mid,
            constants,
            speciation_mode=mode,
            fixed_h2co3=fixed_h2co3,
        )
        if _solubility_within_saturation_limits(candidate):
            best_frac = mid
            lo_frac = mid
        else:
            hi_frac = mid
    if best_frac is None:
        best_frac = max(hi_frac * 0.5, 1e-6)
    final_na = max(sodium_conc * best_frac, 1e-12)
    final_total = (
        max(base_carbon_conc * best_frac, 1e-12)
        if mode == SPEC_MODE_FIXED_PCO2
        else max(base_carbon_conc * best_frac + headspace_conc, 1e-12)
    )
    return _solubility_speciation_for_inventory(
        params,
        final_total,
        final_na,
        constants,
        speciation_mode=mode,
        fixed_h2co3=fixed_h2co3,
        saturation_enforced=limiters,
    )


def solubility_solve_speciation(
    params: SolubilityInputs,
    constants: Optional[Tuple[float, float, float, List[str]]] = None,
    math_logger: Optional[SolubilityMathLogger] = None,
    math_section: str = "Speciation",
    *,
    model_options: Optional[ModelOptions] = None,
) -> SolubilitySpeciationResult:
    """Solve speciation.
    Used by solubility workflows to solve speciation."""
    effective_params = params
    if model_options and model_options.override_ionic_strength_cap is not None:
        effective_params = replace(
            params, ionic_strength_cap=model_options.override_ionic_strength_cap
        )
    mode = _normalize_speciation_mode(
        getattr(effective_params, "speciation_mode", None)
    )
    sodium_conc = effective_params.sodium_concentration()
    if sodium_conc <= 0.0:
        raise ValueError("Computed dissolved sodium concentration must be positive.")
    base_carbon = effective_params.total_carbon_concentration()
    if base_carbon <= 0.0 and mode == SPEC_MODE_CLOSED:
        raise ValueError("Total inorganic carbon concentration must be positive.")
    headspace_conc = (
        effective_params.headspace_carbon_contribution()
        if mode == SPEC_MODE_CLOSED
        else 0.0
    )
    fixed_h2co3_value: Optional[float] = None
    if mode == SPEC_MODE_FIXED_PCO2:
        # Open-system assumption: dissolved CO2 is pinned by pCO2 via Henry's law.
        fixed_h2co3_value, _ = _resolved_fixed_co2_boundary(effective_params)
        fixed_h2co3_value = max(fixed_h2co3_value, 1e-16)
    if constants is None:
        constants = _resolve_solubility_constants(
            effective_params, math_logger=math_logger, section=math_section
        )
    result = _solubility_apply_saturation_limits(
        effective_params,
        constants,
        sodium_conc,
        base_carbon,
        headspace_conc,
        speciation_mode=mode,
        fixed_h2co3=fixed_h2co3_value,
    )
    _solubility_log_result_math(
        logger=math_logger,
        section=math_section,
        params=effective_params,
        result=result,
    )
    return result


def solubility_speciation_at_forced_ph(
    params: SolubilityInputs,
    forced_ph: float,
    constants: Optional[Tuple[float, float, float, List[str]]] = None,
    math_logger: Optional[SolubilityMathLogger] = None,
    math_section: str = "Forced pH Speciation",
    *,
    model_options: Optional[ModelOptions] = None,
) -> SolubilitySpeciationResult:
    """Perform solubility speciation at forced pH.
    Used to keep the workflow logic localized and testable."""
    if forced_ph <= 0 or forced_ph >= 14:
        raise ValueError("Forced pH must be between 0 and 14.")
    effective_params = (
        replace(params, ionic_strength_cap=model_options.override_ionic_strength_cap)
        if model_options and model_options.override_ionic_strength_cap is not None
        else params
    )
    mode = _normalize_speciation_mode(
        getattr(effective_params, "speciation_mode", None)
    )
    fixed_h2co3_value: Optional[float] = None
    boundary_notes: List[str] = []
    if mode == SPEC_MODE_FIXED_PCO2:
        fixed_h2co3_value, boundary_notes = _resolved_fixed_co2_boundary(
            effective_params
        )
        fixed_h2co3_value = max(fixed_h2co3_value, 1e-16)
    inventory_carbon = effective_params.carbon_inventory_concentration()
    total_carbon = max(inventory_carbon, fixed_h2co3_value or 1e-12)
    na_conc = effective_params.sodium_concentration()
    if constants is None:
        constants = _resolve_solubility_constants(
            effective_params, math_logger=math_logger, section=math_section
        )
    ka1, ka2, kw, constant_notes = constants
    if boundary_notes:
        constant_notes = list(constant_notes) + boundary_notes
    H = 10.0 ** (-forced_ph)
    hco3 = total_carbon * 0.9
    co3 = total_carbon * 0.05
    h2co3 = max(total_carbon - hco3 - co3, 0.0)
    max_iter = 80
    charge_residual = 0.0

    # Iterate over the configured range to apply the per-item logic.
    for _ in range(max_iter):
        ionic_strength, gammas, OH = _solubility_ionic_state(
            na_conc,
            H,
            hco3,
            co3,
            kw_value=kw,
            ionic_strength_cap=effective_params.ionic_strength_cap,
        )
        coeff_co3 = (ka2 * gammas["HCO3"]) / (gammas["H"] * gammas["CO3"] * H)
        coeff_h2co3 = (gammas["H"] * gammas["HCO3"] * H) / ka1
        denominator = 1.0 + coeff_co3 + coeff_h2co3
        if denominator <= 0:
            denominator = 1e-12
        a1 = 1.0 / denominator
        a2 = coeff_co3 / denominator
        hco3 = max(total_carbon * a1, 1e-16)
        co3 = max(total_carbon * a2, 1e-16)
        h2co3 = max(total_carbon - hco3 - co3, fixed_h2co3_value or 0.0)
        charge_residual = na_conc + H - hco3 - 2.0 * co3 - OH
        denom_charge = max(a1 + 2.0 * a2, 1e-12)
        new_total_carbon = max((na_conc + H - OH) / denom_charge, 1e-16)
        if fixed_h2co3_value is not None:
            new_total_carbon = max(new_total_carbon, fixed_h2co3_value + hco3 + co3)
        delta_ct = abs(new_total_carbon - total_carbon) / max(total_carbon, 1e-12)
        total_carbon = new_total_carbon
        if delta_ct < 1e-8 and abs(charge_residual) < 1e-8:
            break

    ionic_strength, gammas, OH = _solubility_ionic_state(
        na_conc,
        H,
        hco3,
        co3,
        kw_value=kw,
        ionic_strength_cap=effective_params.ionic_strength_cap,
    )
    volume = params.volume_l()

    concentrations = {
        "Na+": na_conc,
        "H+": H,
        "HCO3-": hco3,
        "CO3^2-": co3,
        "H2CO3": h2co3,
        "OH-": OH,
    }
    moles = {species: conc * volume for species, conc in concentrations.items()}
    activity_coeffs = {
        "Na+": gammas["Na"],
        "H+": gammas["H"],
        "HCO3-": gammas["HCO3"],
        "CO3^2-": gammas["CO3"],
        "OH-": gammas["OH"],
    }
    a_na = gammas["Na"] * na_conc
    a_hco3 = gammas["HCO3"] * hco3
    a_co3 = gammas["CO3"] * co3
    saturation_indices = {
        "NaHCO3": (a_na * a_hco3) / SOL_KSP_NAHCO3,
        "Na2CO3": (a_na**2 * a_co3) / SOL_KSP_NA2CO3,
    }
    ionic_strength_capped = (
        effective_params.ionic_strength_cap is not None
        and ionic_strength >= effective_params.ionic_strength_cap * 0.999
    )
    result = _solubility_finalize_result(
        params=effective_params,
        volume=volume,
        ionic_strength=ionic_strength,
        ph=forced_ph,
        concentrations=concentrations,
        moles=moles,
        activity_coeffs=activity_coeffs,
        saturation_indices=saturation_indices,
        constant_notes=constant_notes,
        ionic_strength_capped=ionic_strength_capped,
        kw_value=kw,
        dissolved_na_moles=na_conc * volume,
        fixed_co2_boundary=fixed_h2co3_value if mode == SPEC_MODE_FIXED_PCO2 else None,
        speciation_mode=mode,
    )
    return result


def solubility_speciation_calibrated_to_measurement(
    params: SolubilityInputs,
    measured_ph: float,
    *,
    measured_alkalinity_meq: Optional[float] = None,
    constants: Optional[Tuple[float, float, float, List[str]]] = None,
    math_logger: Optional[SolubilityMathLogger] = None,
    math_section: str = "Measurement-Calibrated Speciation",
    model_options: Optional[ModelOptions] = None,
) -> Tuple[SolubilitySpeciationResult, SolubilityInputs, float]:
    """Perform solubility speciation calibrated to measurement.
    Used to keep the workflow logic localized and testable."""

    if constants is None:
        constants = _resolve_solubility_constants(
            params, math_logger=math_logger, section=math_section
        )

    def _evaluate(scale: float) -> Tuple[SolubilitySpeciationResult, SolubilityInputs]:
        """Perform evaluate.
        Used to keep the workflow logic localized and testable."""
        retained = params._retained_carbon_fraction()
        scaled_retained = min(max(retained * scale, 1e-6), 5.0)
        scaled_degassed = 1.0 - scaled_retained
        scaled_params = replace(params, degassed_fraction=scaled_degassed)
        spec = solubility_speciation_at_forced_ph(
            scaled_params,
            measured_ph,
            constants=constants,
            math_logger=None,
            math_section=math_section,
            model_options=model_options,
        )
        return spec, scaled_params

    best_spec, best_params = _evaluate(1.0)
    best_scale = 1.0
    target_alk = measured_alkalinity_meq
    if target_alk is not None and target_alk > 0:
        target_alk = float(target_alk)
        low_scale, high_scale = 0.2, 5.0
        low_spec, low_params = _evaluate(low_scale)
        high_spec, high_params = _evaluate(high_scale)
        candidates = [
            (
                abs(best_spec.alkalinity_meq_per_l - target_alk),
                best_spec,
                best_params,
                1.0,
            ),
            (
                abs(low_spec.alkalinity_meq_per_l - target_alk),
                low_spec,
                low_params,
                low_scale,
            ),
            (
                abs(high_spec.alkalinity_meq_per_l - target_alk),
                high_spec,
                high_params,
                high_scale,
            ),
        ]
        best_diff, best_spec, best_params, best_scale = min(
            candidates, key=lambda entry: entry[0]
        )
        low_diff = low_spec.alkalinity_meq_per_l - target_alk
        high_diff = high_spec.alkalinity_meq_per_l - target_alk
        if low_diff == 0.0:
            best_spec, best_params, best_scale = low_spec, low_params, low_scale
        elif high_diff == 0.0:
            best_spec, best_params, best_scale = high_spec, high_params, high_scale
        elif low_diff * high_diff < 0:
            # Iterate over the configured range to apply the per-item logic.
            for _ in range(30):
                mid_scale = 0.5 * (low_scale + high_scale)
                mid_spec, mid_params = _evaluate(mid_scale)
                mid_diff = mid_spec.alkalinity_meq_per_l - target_alk
                if abs(mid_diff) < best_diff:
                    best_diff = abs(mid_diff)
                    best_spec, best_params, best_scale = mid_spec, mid_params, mid_scale
                if abs(mid_diff) < 0.05:
                    break
                if mid_diff > 0:
                    high_scale, high_diff = mid_scale, mid_diff
                else:
                    low_scale, low_diff = mid_scale, mid_diff
        if abs(low_diff) < best_diff:
            best_diff = abs(low_diff)
            best_spec, best_params, best_scale = low_spec, low_params, low_scale
        if abs(high_diff) < best_diff:
            best_spec, best_params, best_scale = high_spec, high_params, high_scale
    if math_logger:
        _solubility_log_result_math(
            logger=math_logger,
            section=math_section,
            params=best_params,
            result=best_spec,
        )
    return best_spec, best_params, best_scale


def _resolve_pka2_value(
    temp_c: Optional[float], use_temp_adjusted_constants: bool
) -> float:
    """Resolve pKa2 value.
    Used to compute pKa2 value before rendering or export."""
    temperature = 25.0 if temp_c is None else float(temp_c)
    if use_temp_adjusted_constants:
        return max(
            0.0, _estimate_temperature_adjusted_pka(temperature, SOL_PKA2_COEFFS)
        )
    return -math.log10(SOL_KA2)


def _clamp_ph_value(ph: float) -> float:
    """Clamp pH value.
    Used to keep pH value within safe bounds."""

    return max(0.0, min(ph, 14.3))


def _estimate_ledger_ph(
    state: Dict[str, float],
    pka2_value: float,
    *,
    solution_volume_l: Optional[float],
    temperature_c: Optional[float],
    ionic_strength_cap: Optional[float],
    use_temp_adjusted_constants: bool,
    constants: Optional[Tuple[float, float, float]] = None,
    initial_ph_guess: Optional[float] = None,
) -> float:
    """Estimate ledger pH.
    Used to approximate ledger pH for model workflows."""

    ratio = max(
        state.get("na2co3_mol", 0.0) / max(state.get("nahco3_mol", 0.0), 1e-12), 1e-12
    )
    fallback_ph = _clamp_ph_value(pka2_value + math.log10(ratio))

    if solution_volume_l is None or solution_volume_l <= 0:
        return fallback_ph

    total_na = (
        max(state.get("naoh_remaining_mol", 0.0), 0.0)
        + max(state.get("nahco3_mol", 0.0), 0.0)
        + 2.0 * max(state.get("na2co3_mol", 0.0), 0.0)
    )
    total_carbon = (
        max(state.get("nahco3_mol", 0.0), 0.0)
        + max(state.get("na2co3_mol", 0.0), 0.0)
        + max(state.get("co2_excess_mol", 0.0), 0.0)
    )
    total_na_conc = total_na / max(solution_volume_l, 1e-9)
    total_carbon_conc = total_carbon / max(solution_volume_l, 1e-9)

    if total_na_conc <= 0 and total_carbon_conc <= 0:
        return fallback_ph

    if constants is None:
        constants = _basic_carbonate_constants(
            temperature_c, use_temp_adjusted_constants
        )
    ka1, ka2, kw = constants
    pkw = -math.log10(max(kw, 1e-30))
    guess = initial_ph_guess if initial_ph_guess is not None else fallback_ph

    try:
        if total_carbon_conc <= 1e-12:
            # No carbonate inventory: treat as a simple strong base solution
            if total_na_conc <= 0:
                return _clamp_ph_value(pkw / 2.0)
            ph = pkw + math.log10(max(total_na_conc, 1e-16))
            return _clamp_ph_value(ph)

        (
            H,
            _,
            _,
            _,
            _,
            _gammas,
            _ionic_strength,
        ) = _solve_carbonate_state(
            total_carbon_conc,
            total_na_conc,
            ka1=ka1,
            ka2=ka2,
            kw=kw,
            ionic_strength_cap=ionic_strength_cap,
            initial_ph_guess=guess,
        )
        ph = -math.log10(max(H, 1e-30))
        ph = _clamp_ph_value(ph)
        if ph < 6.0 and (
            state.get("nahco3_mol", 0.0) > 0.0 or state.get("co2_excess_mol", 0.0) > 0.0
        ):
            buffer_hint = _clamp_ph_value(max(fallback_ph, pka2_value - 2.2, 8.0))
            return buffer_hint
        return ph
    except Exception:
        if state.get("nahco3_mol", 0.0) > 0.0 or state.get("co2_excess_mol", 0.0) > 0.0:
            return _clamp_ph_value(max(fallback_ph, pka2_value - 2.2, 8.0))
        return fallback_ph


def _estimate_ledger_ph_planning(
    state: Dict[str, float],
    pka2_value: float,
    *,
    solution_volume_l: Optional[float],
    temperature_c: Optional[float],
    ionic_strength_cap: Optional[float],
    use_temp_adjusted_constants: bool,
    constants: Optional[Tuple[float, float, float]] = None,
    initial_ph_guess: Optional[float] = None,
) -> float:
    """Estimate ledger pH planning.
    Used to approximate ledger pH planning for model workflows."""

    state_for_ph = dict(state)
    co3 = max(state_for_ph.get("na2co3_mol", 0.0), 0.0)
    hco3 = max(state_for_ph.get("nahco3_mol", 0.0), 0.0)
    excess = max(state_for_ph.get("co2_excess_mol", 0.0), 0.0)
    carbonate_only_equivalence = (
        state_for_ph.get("naoh_remaining_mol", 0.0) <= 1e-12
        and co3 > 0.0
        and hco3 <= 1e-12
    )
    carbon_pool = co3 + hco3
    carbonate_depleted = co3 <= PLANNING_PLATEAU_CARBONATE_THRESHOLD or (
        carbon_pool > 0
        and co3 / max(carbon_pool, 1e-12) <= PLANNING_PLATEAU_RELATIVE_THRESHOLD
    )
    state_for_ph["co2_excess_mol"] = excess
    ph_estimate = _estimate_ledger_ph(
        state_for_ph,
        pka2_value,
        solution_volume_l=solution_volume_l,
        temperature_c=temperature_c,
        ionic_strength_cap=ionic_strength_cap,
        use_temp_adjusted_constants=use_temp_adjusted_constants,
        constants=constants,
        initial_ph_guess=initial_ph_guess,
    )
    if (
        carbonate_only_equivalence
        and ph_estimate is not None
        and math.isfinite(ph_estimate)
    ):
        anchor = pka2_value if pka2_value is not None else 10.33
        ph_estimate = _clamp_ph_value(
            min(max(ph_estimate, anchor - 0.35), anchor + 0.35)
        )
    if (
        carbonate_depleted
        and (hco3 > 0 or excess > 0)
        and ph_estimate is not None
        and math.isfinite(ph_estimate)
    ):
        ph_estimate = min(
            max(ph_estimate, PLANNING_PLATEAU_PH_MIN), PLANNING_PLATEAU_PH_MAX
        )
    return ph_estimate


def _simulate_reaction_state_with_accounting(
    ledger: Dict[str, float],
    delta_mol: float,
    pka2_value: float,
    *,
    solution_volume_l: Optional[float] = None,
    temperature_c: Optional[float] = None,
    ionic_strength_cap: Optional[float] = None,
    use_temp_adjusted_constants: bool = False,
    initial_ph_guess: Optional[float] = None,
    constants: Optional[Tuple[float, float, float]] = None,
    planning_mode: bool = False,
) -> Tuple[Dict[str, float], Dict[str, float]]:
    """Perform simulate reaction state with accounting.
    Used to keep the workflow logic localized and testable."""

    extra = max(float(delta_mol), 0.0)
    naoh_free = max(ledger.get("naoh_remaining_mol", 0.0), 0.0)
    co3 = max(ledger.get("na2co3_mol", 0.0), 0.0)
    hco3 = max(ledger.get("nahco3_mol", 0.0), 0.0)
    excess = max(ledger.get("co2_excess_mol", 0.0), 0.0)

    consumed_to_carbonate = 0.0
    consumed_to_bicarbonate = 0.0

    if naoh_free > 0:
        needed = naoh_free / 2.0
        consume = min(extra, needed)
        consumed_to_carbonate = consume
        naoh_free = max(0.0, naoh_free - consume * 2.0)
        co3 += consume
        extra -= consume

    if co3 > 0 and extra > 0:
        convert = min(extra, co3)
        consumed_to_bicarbonate = convert
        co3 -= convert
        hco3 += convert * 2.0
        extra -= convert

    excess += extra
    ratio_hint = co3 / max(hco3, 1e-12)
    estimator = _estimate_ledger_ph_planning if planning_mode else _estimate_ledger_ph

    state = {
        "naoh_remaining_mol": naoh_free,
        "na2co3_mol": co3,
        "nahco3_mol": hco3,
        "co2_excess_mol": excess,
    }
    ph_value = estimator(
        state,
        pka2_value,
        solution_volume_l=solution_volume_l,
        temperature_c=temperature_c,
        ionic_strength_cap=ionic_strength_cap,
        use_temp_adjusted_constants=use_temp_adjusted_constants,
        constants=constants,
        initial_ph_guess=(
            initial_ph_guess
            if initial_ph_guess is not None
            else pka2_value + math.log10(max(ratio_hint, 1e-12))
        ),
    )
    state["ph"] = ph_value
    accounting = {
        "co2_consumed_to_carbonate_mol": consumed_to_carbonate,
        "co2_consumed_to_bicarbonate_mol": consumed_to_bicarbonate,
        "co2_consumed_total_mol": consumed_to_carbonate + consumed_to_bicarbonate,
        "co2_unconsumed_mol": max(extra, 0.0),
    }
    return state, accounting


def _simulate_reaction_state(
    ledger: Dict[str, float],
    delta_mol: float,
    pka2_value: float,
    *,
    solution_volume_l: Optional[float] = None,
    temperature_c: Optional[float] = None,
    ionic_strength_cap: Optional[float] = None,
    use_temp_adjusted_constants: bool = False,
    initial_ph_guess: Optional[float] = None,
    constants: Optional[Tuple[float, float, float]] = None,
) -> Dict[str, float]:
    """Perform simulate reaction state.
    Used to keep the workflow logic localized and testable."""
    state, _ = _simulate_reaction_state_with_accounting(
        ledger,
        delta_mol,
        pka2_value,
        solution_volume_l=solution_volume_l,
        temperature_c=temperature_c,
        ionic_strength_cap=ionic_strength_cap,
        use_temp_adjusted_constants=use_temp_adjusted_constants,
        initial_ph_guess=initial_ph_guess,
        constants=constants,
        planning_mode=False,
    )
    return state


def _regression_test_post_equivalence_ph_trends() -> None:
    """Perform regression test post equivalence pH trends.
    Used to keep the workflow logic localized and testable."""
    temp_c = 25.0
    use_temp_adjusted = False
    pka2_value = _resolve_pka2_value(temp_c, use_temp_adjusted)
    constants = _basic_carbonate_constants(temp_c, use_temp_adjusted)
    volume_l = 1.0
    sodium_basis_mol = 1.0

    # Closure captures _regression_test_post_equivalence_ph_trends local context to keep helper logic scoped and invoked directly within _regression_test_post_equivalence_ph_trends.
    def _ledger_state_for_fraction(fraction: float) -> Tuple[Dict[str, float], float]:
        """Perform ledger state for fraction.
        Used to keep the workflow logic localized and testable."""
        ledger_state = _ledger_from_sodium_and_carbonate_fraction(
            sodium_basis_mol, fraction
        )
        ph_val = _estimate_ledger_ph(
            ledger_state,
            pka2_value,
            solution_volume_l=volume_l,
            temperature_c=temp_c,
            ionic_strength_cap=None,
            use_temp_adjusted_constants=use_temp_adjusted,
            constants=constants,
        )
        if ph_val is None or not math.isfinite(ph_val):
            raise AssertionError(
                f"Ledger fraction {fraction:.3f}: pH estimation failed."
            )
        return ledger_state, ph_val

    ledger_119, baseline_ph = _ledger_state_for_fraction(0.119)
    assert abs(baseline_ph - 9.46) < 0.05, f"Expected ~9.46 pH, got {baseline_ph:.3f}"

    ledger_5, ph_5pct = _ledger_state_for_fraction(0.05)
    assert ph_5pct < 9.2, f"5% carbonate state should be <9.2 pH (got {ph_5pct:.3f})"

    ledger_2, ph_2pct = _ledger_state_for_fraction(0.02)
    assert (
        ph_2pct <= 8.65
    ), f"2% carbonate state should trend below ~8.6 pH (got {ph_2pct:.3f})"

    # Projection-style regression: consume carbonate, accumulate dissolved CO2, and approach pH ~8
    increments = [0.05] * 8
    ledger = dict(ledger_119)
    previous_carbonate = ledger["na2co3_mol"]
    previous_excess = ledger.get("co2_excess_mol", 0.0)
    co2_excess_seen = False
    ph_trace: List[float] = []
    ph_guess = baseline_ph
    # Iterate over increments to apply the per-item logic.
    for delta in increments:
        state = _simulate_reaction_state(
            ledger,
            delta,
            pka2_value,
            solution_volume_l=volume_l,
            temperature_c=temp_c,
            ionic_strength_cap=None,
            use_temp_adjusted_constants=use_temp_adjusted,
            constants=constants,
            initial_ph_guess=ph_guess,
        )
        ph_guess = state.get("ph", ph_guess)
        ph_val = state.get("ph")
        if ph_val is None or not math.isfinite(ph_val):
            raise AssertionError("Projection regression: invalid pH state.")
        ph_trace.append(ph_val)
        co3_now = state.get("na2co3_mol", 0.0)
        excess_now = state.get("co2_excess_mol", 0.0)
        assert (
            co3_now <= previous_carbonate + 1e-9
        ), "Carbonate did not decrease monotonically."
        assert (
            excess_now + 1e-9 >= previous_excess
        ), "Excess CO2 should not decrease once formed."
        co2_excess_seen = co2_excess_seen or excess_now > 0
        previous_carbonate = co3_now
        previous_excess = excess_now
        ledger = {
            "naoh_remaining_mol": max(state.get("naoh_remaining_mol", 0.0), 0.0),
            "na2co3_mol": max(co3_now, 0.0),
            "nahco3_mol": max(state.get("nahco3_mol", 0.0), 0.0),
            "co2_excess_mol": max(excess_now, 0.0),
        }

    if not any(val < 9.0 for val in ph_trace):
        raise AssertionError("Projection regression: pH did not drop below 9.0.")
    if not any(val < 8.5 for val in ph_trace):
        raise AssertionError("Projection regression: pH did not drop below 8.5.")
    if not co2_excess_seen:
        raise AssertionError("Projection regression: excess CO2 never accumulated.")
    final_ph = ph_trace[-1]
    assert (
        final_ph <= 8.3
    ), f"Projection regression: final pH should approach ~8 (got {final_ph:.3f})."

    print(
        "Post-equivalence regression:",
        f"11.9% pH={baseline_ph:.3f}",
        f"5% pH={ph_5pct:.3f}",
        f"2% pH={ph_2pct:.3f}",
        f"projection min pH={min(ph_trace):.3f}",
        f"projection final pH={final_ph:.3f}",
    )


def _planning_projection_trace(
    *,
    initial_naoh_mol: float,
    cycle_moles: float,
    volume_l: float,
    temp_c: float,
    stop_ph: float = PLANNING_DEFAULT_STOP_PH,
    stop_added_g: float = PLANNING_DEFAULT_STOP_CO2_ADDED_G,
    max_cycles: int = 240,
    respect_stop_ph: bool = True,
) -> Dict[str, Any]:
    """Perform planning projection trace.
    Used to keep the workflow logic localized and testable."""

    pka2_value = _resolve_pka2_value(temp_c, False)
    constants = _basic_carbonate_constants(temp_c, False)
    ledger = {
        "naoh_remaining_mol": initial_naoh_mol,
        "na2co3_mol": 0.0,
        "nahco3_mol": 0.0,
        "co2_excess_mol": 0.0,
    }
    ph_trace: List[float] = []
    carbonate_trace: List[float] = []
    h2co3_trace: List[float] = []
    rows: List[Dict[str, Any]] = []
    cumulative_added_moles = 0.0
    cumulative_consumed_moles = 0.0
    stop_index: Optional[int] = None
    stop_added_mass_g: Optional[float] = None
    stop_consumed_mass_g: Optional[float] = None
    depletion_index: Optional[int] = None
    added_mass_g = 0.0
    consumed_mass_g = 0.0
    # Iterate over the configured range to apply the per-item logic.
    for idx in range(1, max_cycles + 1):
        cumulative_added_moles += cycle_moles
        state, accounting = _simulate_reaction_state_with_accounting(
            ledger,
            cycle_moles,
            pka2_value,
            solution_volume_l=volume_l,
            temperature_c=temp_c,
            ionic_strength_cap=None,
            use_temp_adjusted_constants=False,
            initial_ph_guess=ph_trace[-1] if ph_trace else None,
            constants=constants,
            planning_mode=True,
        )
        ledger = {
            "naoh_remaining_mol": max(state.get("naoh_remaining_mol", 0.0), 0.0),
            "na2co3_mol": max(state.get("na2co3_mol", 0.0), 0.0),
            "nahco3_mol": max(state.get("nahco3_mol", 0.0), 0.0),
            "co2_excess_mol": max(state.get("co2_excess_mol", 0.0), 0.0),
        }
        ph_val = state.get("ph")
        if ph_val is None or not math.isfinite(ph_val):
            raise AssertionError("Planning projection produced an invalid pH value.")
        ph_trace.append(ph_val)
        carbonate_trace.append(ledger["na2co3_mol"])
        consumed_cycle = accounting.get("co2_consumed_total_mol", 0.0)
        cumulative_consumed_moles += consumed_cycle
        added_mass_g = cumulative_added_moles * SOL_MW_CO2
        consumed_mass_g = cumulative_consumed_moles * SOL_MW_CO2
        carbon_pool = (
            ledger["na2co3_mol"]
            + ledger["nahco3_mol"]
            + ledger.get("co2_excess_mol", 0.0)
        )
        h2co3_frac = (
            ledger.get("co2_excess_mol", 0.0) / carbon_pool if carbon_pool > 0 else 0.0
        )
        h2co3_trace.append(h2co3_frac)
        regime_label = "naoh_to_carbonate"
        if ledger["naoh_remaining_mol"] <= 1e-12:
            regime_label = "carbonate_to_bicarbonate"
            if ledger["na2co3_mol"] <= PLANNING_PLATEAU_CARBONATE_THRESHOLD:
                regime_label = "excess_co2"
        rows.append(
            {
                "cycle": idx,
                "delta_added_g": cycle_moles * SOL_MW_CO2,
                "cumulative_added_g": added_mass_g,
                "delta_consumed_g": consumed_cycle * SOL_MW_CO2,
                "cumulative_consumed_g": consumed_mass_g,
                "naoh_mol": ledger["naoh_remaining_mol"],
                "na2co3_mol": ledger["na2co3_mol"],
                "nahco3_mol": ledger["nahco3_mol"],
                "co2_excess_mol": ledger["co2_excess_mol"],
                "ph": ph_val,
                "regime": regime_label,
                "h2co3_fraction": h2co3_frac,
            }
        )
        if (
            depletion_index is None
            and ledger["na2co3_mol"] <= PLANNING_PLATEAU_CARBONATE_THRESHOLD
        ):
            depletion_index = idx
        if stop_index is None and ph_val <= stop_ph + 1e-12:
            stop_index = idx
            stop_added_mass_g = added_mass_g
            stop_consumed_mass_g = consumed_mass_g
        if respect_stop_ph and stop_index is not None:
            break
        if added_mass_g >= stop_added_g - 1e-12:
            break
    return {
        "rows": rows,
        "ph_trace": ph_trace,
        "carbonate_trace": carbonate_trace,
        "h2co3_trace": h2co3_trace,
        "stop_index": stop_index,
        "stop_added_mass_g": stop_added_mass_g,
        "stop_consumed_mass_g": stop_consumed_mass_g,
        "depletion_index": depletion_index,
        "final_added_mass_g": added_mass_g,
        "final_consumed_mass_g": consumed_mass_g,
    }


def _format_planning_cycle_table(
    rows: Sequence[Dict[str, float]], limit: int = 12
) -> str:
    """Format planning cycle table.
    Used to prepare planning cycle table for display or export."""
    headers = [
        "cyc",
        "Δg",
        "Σg",
        "Δrxn",
        "Σrxn",
        "NaOH",
        "CO3",
        "HCO3",
        "CO2x",
        "pH",
        "regime",
    ]
    lines = [" | ".join(f"{h:>6}" for h in headers)]
    display_rows = rows[:limit]
    if len(rows) > limit:
        display_rows.append(
            {
                "cycle": "...",
                "delta_added_g": None,
                "cumulative_added_g": None,
                "delta_consumed_g": None,
                "cumulative_consumed_g": None,
                "naoh_mol": None,
                "na2co3_mol": None,
                "nahco3_mol": None,
                "co2_excess_mol": None,
                "ph": None,
                "regime": "...",
            }
        )
    # Iterate over display_rows to apply the per-item logic.
    for row in display_rows:
        if row.get("cycle") == "...":
            lines.append(" ... (truncated)")
            continue
        lines.append(
            " | ".join(
                [
                    f"{int(row['cycle']):6d}",
                    f"{row['delta_added_g']:.2f}",
                    f"{row['cumulative_added_g']:.2f}",
                    f"{row['delta_consumed_g']:.2f}",
                    f"{row['cumulative_consumed_g']:.2f}",
                    f"{row['naoh_mol']:.3f}",
                    f"{row['na2co3_mol']:.3f}",
                    f"{row['nahco3_mol']:.3f}",
                    f"{row['co2_excess_mol']:.3f}",
                    f"{row['ph']:.3f}",
                    f"{row['regime']:>6}",
                ]
            )
        )
    return "\n".join(lines)


def _regression_test_planning_equivalence_definition() -> None:
    """Perform regression test planning equivalence definition.
    Used to keep the workflow logic localized and testable."""

    temp_c = 25.0
    use_temp_adjusted = False
    pka2_value = _resolve_pka2_value(temp_c, use_temp_adjusted)
    constants = _basic_carbonate_constants(temp_c, use_temp_adjusted)
    volume_l = 2.0
    naoh_initial_mol = 10.0
    n_eq = naoh_initial_mol / 2.0
    ledger = {
        "naoh_remaining_mol": naoh_initial_mol,
        "na2co3_mol": 0.0,
        "nahco3_mol": 0.0,
        "co2_excess_mol": 0.0,
    }
    state, accounting = _simulate_reaction_state_with_accounting(
        ledger,
        n_eq,
        pka2_value,
        solution_volume_l=volume_l,
        temperature_c=temp_c,
        ionic_strength_cap=None,
        use_temp_adjusted_constants=use_temp_adjusted,
        constants=constants,
        planning_mode=True,
    )
    ph_eq = state.get("ph")
    assert ph_eq is not None and math.isfinite(
        ph_eq
    ), "Equivalence pH estimation failed."
    assert (
        abs(accounting.get("co2_consumed_total_mol", 0.0) - n_eq) < 1e-6
    ), "Stage 1 stoichiometry failed at equivalence."
    assert (
        state.get("naoh_remaining_mol", 0.0) <= 1e-9
    ), "NaOH should be consumed at equivalence."
    assert (
        abs(state.get("na2co3_mol", 0.0) - n_eq) < 1e-6
    ), "Carbonate ledger at equivalence is incorrect."
    assert (
        abs(ph_eq - 10.33) < 0.35
    ), f"Equivalence pH should be ~10.33 (got {ph_eq:.2f})."
    print(f"Equivalence regression: n_eq={n_eq:.2f} mol, pH={ph_eq:.3f}")


def _regression_test_planning_post_equivalence_decline() -> None:
    """Perform regression test planning post equivalence decline.
    Used to keep the workflow logic localized and testable."""

    temp_c = 25.0
    volume_l = 2.5
    initial_naoh_mol = 700.0 / SOL_MW_NAOH  # default UI basis
    cycle_moles = UnifiedApp._planning_cycle_moles_from_pressure(
        None, 250.0, 1.0, temp_c
    )
    trace = _planning_projection_trace(
        initial_naoh_mol=initial_naoh_mol,
        cycle_moles=cycle_moles,
        volume_l=volume_l,
        temp_c=temp_c,
        respect_stop_ph=False,
    )
    ph_trace = trace["ph_trace"]
    carbonate_trace = trace["carbonate_trace"]
    rows = trace["rows"]
    eq_cross_idx = next(
        (i for i, row in enumerate(rows) if row["naoh_mol"] <= 1e-9), None
    )
    assert eq_cross_idx is not None, "Equivalence was never crossed in regression."
    if eq_cross_idx + 1 < len(rows):
        before = rows[eq_cross_idx]
        after = rows[eq_cross_idx + 1]
        delta_co3 = before["na2co3_mol"] - after["na2co3_mol"]
        delta_hco3 = after["nahco3_mol"] - before["nahco3_mol"]
        if delta_co3 > 1e-8:
            ratio = delta_hco3 / max(delta_co3, 1e-12)
            assert (
                1.8 <= ratio <= 2.2
            ), f"Stage 2 stoichiometry off (ratio {ratio:.3f})."
    post_eq_carbonate = carbonate_trace[eq_cross_idx:]
    # Iterate over paired elements from multiple sequences to apply the per-item logic.
    for before, after in zip(post_eq_carbonate, post_eq_carbonate[1:]):
        assert (
            after <= before + 1e-9
        ), "Carbonate did not decrease monotonically after equivalence."
    post_eq_ph = ph_trace[eq_cross_idx:]
    assert any(
        val < 9.0 for val in post_eq_ph
    ), "Post-equivalence pH never left the carbonate buffer region."
    assert (
        post_eq_ph[-1] < ph_trace[eq_cross_idx]
    ), "Post-equivalence pH did not decline."
    assert any(
        row.get("h2co3_fraction", 0.0) > 0 for row in rows[eq_cross_idx:]
    ), "H2CO3 fraction never rose post-equivalence."


def _regression_test_planning_convergence_window() -> None:
    """Perform regression test planning convergence window.
    Used to keep the workflow logic localized and testable."""

    temp_c = 25.0
    volume_l = 2.5
    initial_naoh_mol = 700.0 / SOL_MW_NAOH
    cycle_moles = UnifiedApp._planning_cycle_moles_from_pressure(
        None, 250.0, 1.0, temp_c
    )
    trace = _planning_projection_trace(
        initial_naoh_mol=initial_naoh_mol,
        cycle_moles=cycle_moles,
        volume_l=volume_l,
        temp_c=temp_c,
        respect_stop_ph=True,
    )
    stop_idx = trace.get("stop_index")
    assert stop_idx is not None, "Planning projection did not reach the pH stop."
    stop_added_mass = trace.get("stop_added_mass_g") or 0.0
    stop_consumed_mass = trace.get("stop_consumed_mass_g") or 0.0
    assert (
        stop_added_mass < PLANNING_DEFAULT_STOP_CO2_ADDED_G
    ), "pH stop exceeded the CO2 added cap."
    if not (750.0 <= stop_consumed_mass <= 1500.0):
        table = _format_planning_cycle_table(trace["rows"][:stop_idx])
        raise AssertionError(
            f"pH<=8.25 occurred after {stop_consumed_mass:.1f} g CO₂ consumed (expected 750–1500 g).\n{table}"
        )
    assert trace["ph_trace"][stop_idx - 1] <= PLANNING_DEFAULT_STOP_PH + 1e-12


def _regression_test_planning_post_carbonate_stability() -> None:
    """Perform regression test planning post carbonate stability.
    Used to keep the workflow logic localized and testable."""

    temp_c = 25.0
    volume_l = 2.5
    initial_naoh_mol = 700.0 / SOL_MW_NAOH
    cycle_moles = UnifiedApp._planning_cycle_moles_from_pressure(
        None, 250.0, 1.0, temp_c
    )
    trace = _planning_projection_trace(
        initial_naoh_mol=initial_naoh_mol,
        cycle_moles=cycle_moles,
        volume_l=volume_l,
        temp_c=temp_c,
        respect_stop_ph=False,
    )
    dep_idx = trace.get("depletion_index")
    assert dep_idx is not None, "Carbonate was never depleted in planning projection."
    tail_ph = trace["ph_trace"][dep_idx - 1 : dep_idx + 6]
    if len(tail_ph) >= 2:
        drift = max(tail_ph) - min(tail_ph)
        assert (
            drift < 0.05
        ), f"Post-carbonate pH drift exceeded tolerance ({drift:.3f})."
    else:
        raise AssertionError(
            "Insufficient post-depletion cycles to evaluate stability."
        )


def _regression_test_planning_input_wiring() -> None:
    """Perform regression test planning input wiring.
    Used to keep the workflow logic localized and testable."""

    delta_psi = 150.0
    temp_c = 25.0
    small_volume_moles = UnifiedApp._planning_cycle_moles_from_pressure(
        None, delta_psi, 1.0, temp_c
    )
    large_volume_moles = UnifiedApp._planning_cycle_moles_from_pressure(
        None, delta_psi, 2.0, temp_c
    )
    assert (
        small_volume_moles > 0
    ), "Computed moles for the small volume must be positive."
    ratio = large_volume_moles / small_volume_moles
    assert 1.9 < ratio < 2.1, f"Headspace scaling failed (ratio {ratio:.3f})."
    print(
        f"Headspace wiring regression: 1 L -> {small_volume_moles:.4f} mol, 2 L -> {large_volume_moles:.4f} mol"
    )


def _regression_test_planning_tail_ph_band() -> None:
    """Perform regression test planning tail pH band.
    Used to keep the workflow logic localized and testable."""

    temp_c = 25.0
    volume_l = 2.5
    initial_naoh_mol = 700.0 / SOL_MW_NAOH
    pka2_value = _resolve_pka2_value(temp_c, False)
    constants = _basic_carbonate_constants(temp_c, False)
    ledger = _ledger_from_sodium_and_carbonate_fraction(initial_naoh_mol, 0.02)
    ph_value = _estimate_ledger_ph_planning(
        ledger,
        pka2_value,
        solution_volume_l=volume_l,
        temperature_c=temp_c,
        ionic_strength_cap=None,
        use_temp_adjusted_constants=False,
        constants=constants,
        initial_ph_guess=8.2,
    )
    assert ph_value is not None and math.isfinite(
        ph_value
    ), "Planning tail pH solve failed."
    assert (
        8.05 <= ph_value <= 8.35
    ), f"Planning 2% carbonate pH should be ~8.1-8.3 (got {ph_value:.3f})."
    print(f"Planning tail regression: pH@2% carbonate = {ph_value:.3f}")


def _regression_test_planning_mass_balance_and_progression() -> None:
    """Perform regression test planning mass balance and progression.
    Used to keep the workflow logic localized and testable."""

    temp_c = 25.0
    volume_l = 2.5
    initial_naoh_mol = 700.0 / SOL_MW_NAOH
    cycle_moles = UnifiedApp._planning_cycle_moles_from_pressure(
        None, 250.0, 1.0, temp_c
    )
    trace = _planning_projection_trace(
        initial_naoh_mol=initial_naoh_mol,
        cycle_moles=cycle_moles,
        volume_l=volume_l,
        temp_c=temp_c,
        respect_stop_ph=True,
    )
    rows = trace["rows"]
    assert rows, "Planning projection returned no rows."
    total_added_calc = sum(row.get("delta_added_g", 0.0) for row in rows)
    cumulative_added = rows[-1].get("cumulative_added_g", 0.0)
    tol = max(1e-6 * max(cumulative_added, 1.0), 1e-3)
    assert (
        abs(total_added_calc - cumulative_added) <= tol
    ), f"CO2 bookkeeping mismatch: sum {total_added_calc:.4f} g vs cumulative {cumulative_added:.4f} g."
    eq_idx = next(
        (i for i, row in enumerate(rows) if row.get("naoh_mol", 0.0) <= 1e-9), None
    )
    assert eq_idx is not None, "Equivalence was never reached in planning projection."
    # Iterate over rows[eq_idx to apply the per-item logic.
    for row in rows[eq_idx:]:
        assert (
            row.get("naoh_mol", 0.0) <= 1e-9
        ), "NaOH should not reappear after equivalence."
    frac_series: List[float] = []
    # Iterate over rows[eq_idx to apply the per-item logic.
    for row in rows[eq_idx:]:
        pool = (
            row.get("na2co3_mol", 0.0)
            + row.get("nahco3_mol", 0.0)
            + row.get("co2_excess_mol", 0.0)
        )
        frac_series.append(
            row.get("na2co3_mol", 0.0) / max(pool, 1e-12) if pool > 0 else 0.0
        )
    # Iterate over paired elements from multiple sequences to apply the per-item logic.
    for before, after in zip(frac_series, frac_series[1:]):
        assert after <= before + 1e-9, "Carbonate fraction increased after equivalence."
    assert (
        frac_series[-1] <= 0.02
    ), f"Carbonate fraction did not approach zero (final {frac_series[-1]:.4f})."
    stop_added = (
        trace.get("stop_added_mass_g") or trace.get("final_added_mass_g") or 0.0
    )
    assert (
        stop_added <= PLANNING_DEFAULT_STOP_CO2_ADDED_G + 1e-6
    ), "Planning exceeded CO2 added cap."
    stop_idx = trace.get("stop_index") or len(trace.get("ph_trace", []))
    ph_trace = trace.get("ph_trace", [])
    if ph_trace and stop_idx > 0:
        final_ph = ph_trace[min(stop_idx, len(ph_trace)) - 1]
        assert (
            final_ph <= PLANNING_DEFAULT_STOP_PH + 1e-6
        ), "Planning pH stop not achieved within cap."
    print(
        f"Planning mass-balance regression: cycles={len(rows)}, final frac={frac_series[-1]:.4f}, "
        f"final added={stop_added:.2f} g"
    )


class _PlanningPayloadHarness:
    def __init__(self, spec_key: str, ph_key: str, use_same: bool) -> None:
        """Initialize _PlanningPayloadHarness instance.
        Used at object creation to configure initial state and bindings."""
        self._planning_use_same_model = bool(use_same)
        self._planning_spec_model_key = spec_key
        self._planning_ph_model_key = ph_key
        self._sol_model_key = spec_key
        self._normalize_speciation_model_key = (
            UnifiedApp._normalize_speciation_model_key.__get__(self, UnifiedApp)
        )
        self._resolve_planning_model_keys = (
            UnifiedApp._resolve_planning_model_keys.__get__(self, UnifiedApp)
        )
        self._canonicalize_planning_inputs = (
            UnifiedApp._canonicalize_planning_inputs.__get__(self, UnifiedApp)
        )
        self._scrub_planning_measured_fields = (
            UnifiedApp._scrub_planning_measured_fields.__get__(self, UnifiedApp)
        )
        self._planning_cycle_moles_from_pressure = (
            UnifiedApp._planning_cycle_moles_from_pressure.__get__(self, UnifiedApp)
        )
        self._generate_planning_cycle_payload = (
            UnifiedApp._generate_planning_cycle_payload.__get__(self, UnifiedApp)
        )


def _run_naoh_pitzer_internal_tests() -> None:
    """Run NaOH Pitzer internal tests.
    Used to execute NaOH Pitzer internal tests and coordinate results."""
    if _NAOH_PITZER_MODULE is None:
        raise AssertionError("NaOH-CO2 Pitzer module not available.")
    params = _load_naoh_pitzer_params()
    if params is None:
        raise AssertionError("NaOH-CO2 Pitzer parameters could not be loaded.")
    cfg = _NAOH_PITZER_MODULE.SystemConfig(
        water_mL=2200.0,
        naoh_g=700.0,
        temperature_C=25.0,
        headspace_L=10.0,
        P_high_psig=750.0,
        dP_psig=75.0,
    )
    _NAOH_PITZER_MODULE.run_internal_tests(params, cfg)


def _integration_test_planning_pitzer_smoke() -> None:
    """Perform integration test planning Pitzer smoke.
    Used to keep the workflow logic localized and testable."""
    model_key = "naoh_co2_pitzer_hmw"
    available = {model.key for model in list_speciation_models()}
    if model_key not in available:
        raise AssertionError("NaOH-CO2 Pitzer model not registered.")
    harness = _PlanningPayloadHarness(model_key, model_key, True)
    form_data = {
        "workflow_key": "Planning",
        "mass_naoh_g": 700.0,
        "water_mass_g": 2200.0,
        "solution_volume_l": 2.2,
        "temperature_c": 25.0,
        "planning_cycle_delta_p_psi": 75.0,
        "planning_headspace_volume_l": 10.0,
        "planning_headspace_pressure_high_psi": 750.0,
        "planning_cycle_co2_g": None,
        "planning_stop_co2_added_g": 2000.0,
        "planning_stop_ph": 8.25,
        "planning_spec_model_key": model_key,
        "planning_ph_model_key": model_key,
        "planning_use_same_model": True,
    }
    params = SolubilityInputs(
        mass_na_hco3_g=1.0,
        water_mass_g=2200.0,
        solution_volume_l=2.2,
        temperature_c=25.0,
        initial_ph_guess=8.35,
        forced_ph_target=None,
        use_temperature_adjusted_constants=False,
        ionic_strength_cap=None,
        headspace_pco2_atm=None,
        headspace_kh_m_per_atm=None,
        degassed_fraction=0.0,
        headspace_volume_l=10.0,
        speciation_mode=SPEC_MODE_FIXED_PCO2,
    )
    solver_inputs = SolubilitySolverInputs(
        params=params,
        forced_target=None,
        sweep_low=SOL_PH_SWEEP_DEFAULT[0],
        sweep_high=SOL_PH_SWEEP_DEFAULT[1],
        sweep_steps=SOL_PH_SWEEP_DEFAULT[2],
        reaction_naoh_mass=None,
        reaction_solution_volume=None,
        reaction_co2_g=None,
        reaction_final_ph=None,
        reaction_slurry_ph=None,
        reaction_target_ph=None,
        diagnostic_data=None,
        mode_key="nahco3_dissolution",
        model_key=model_key,
        model_options=None,
        guide_key="nahco3_dissolution",
        workflow_key="Planning",
        assumed_solution_volume_l=None,
        failing_ph=None,
        solvent_basis=None,
        solvent_basis_value=None,
    )
    payload = harness._generate_planning_cycle_payload(form_data, solver_inputs)
    if not payload:
        raise AssertionError("Planning payload generation failed.")
    cycles = payload.get("cycle_transfer") or []
    ph_values = [
        entry.get("ph_after") for entry in cycles if entry.get("ph_after") is not None
    ]
    if not ph_values:
        raise AssertionError("No planning pH values were generated.")
    first_ph = ph_values[0]
    assert first_ph >= 13.5, f"Expected initial pH >= 13.5 (got {first_ph:.3f})."
    # Iterate over paired elements from multiple sequences to apply the per-item logic.
    for prev, curr in zip(ph_values, ph_values[1:]):
        assert curr <= prev + 0.05, "Planning pH is not decreasing smoothly."
    target_entry = min(
        cycles,
        key=lambda entry: abs((entry.get("cumulative_co2_mass_g") or 0.0) - 900.0),
    )
    target_ph = target_entry.get("ph_after")
    if target_ph is None:
        raise AssertionError("Missing pH near 900 g CO2.")
    assert (
        8.0 <= target_ph <= 8.6
    ), f"Expected pH ~8.0-8.6 near 900 g CO2 (got {target_ph:.3f})."


def _dev_validate_plot_title_centering_and_labels() -> None:
    """Validate plot title centering and labels.
    Used by dev workflows to validate plot title centering and labels."""
    _dev_validate_plot_title_centering_and_labels_impl()


def _regression_test_analysis_progress_overlay() -> None:
    """Perform regression test analysis progress overlay.
    Used to keep the workflow logic localized and testable."""
    model_key = DEFAULT_SPEC_MODEL_KEY
    harness = _PlanningPayloadHarness(model_key, model_key, True)
    form_data = {
        "workflow_key": "Planning",
        "mass_naoh_g": 700.0,
        "water_mass_g": 2200.0,
        "solution_volume_l": 2.2,
        "temperature_c": 25.0,
        "planning_cycle_delta_p_psi": 75.0,
        "planning_headspace_volume_l": 10.0,
        "planning_headspace_pressure_high_psi": 750.0,
        "planning_cycle_co2_g": None,
        "planning_stop_co2_added_g": 2000.0,
        "planning_stop_ph": 8.25,
        "planning_spec_model_key": model_key,
        "planning_ph_model_key": model_key,
        "planning_use_same_model": True,
    }
    params = SolubilityInputs(
        mass_na_hco3_g=1.0,
        water_mass_g=2200.0,
        solution_volume_l=2.2,
        temperature_c=25.0,
        initial_ph_guess=8.35,
        forced_ph_target=None,
        use_temperature_adjusted_constants=False,
        ionic_strength_cap=None,
        headspace_pco2_atm=None,
        headspace_kh_m_per_atm=None,
        degassed_fraction=0.0,
        headspace_volume_l=10.0,
        speciation_mode=SPEC_MODE_FIXED_PCO2,
    )
    solver_inputs = SolubilitySolverInputs(
        params=params,
        forced_target=None,
        sweep_low=SOL_PH_SWEEP_DEFAULT[0],
        sweep_high=SOL_PH_SWEEP_DEFAULT[1],
        sweep_steps=SOL_PH_SWEEP_DEFAULT[2],
        reaction_naoh_mass=None,
        reaction_solution_volume=None,
        reaction_co2_g=None,
        reaction_final_ph=None,
        reaction_slurry_ph=None,
        reaction_target_ph=None,
        diagnostic_data=None,
        mode_key="nahco3_dissolution",
        model_key=model_key,
        model_options=None,
        guide_key=SOL_DEFAULT_SIM_MODE,
        workflow_key="Planning",
        assumed_solution_volume_l=None,
        failing_ph=None,
        solvent_basis=None,
        solvent_basis_value=None,
    )
    payload = harness._generate_planning_cycle_payload(form_data, solver_inputs)
    if not payload or not payload.get("cycle_transfer"):
        raise AssertionError("Planning payload missing from analysis overlay test.")
    cycles = payload["cycle_transfer"]
    x_series = []
    ph_series = []
    # Iterate over cycles to apply the per-item logic.
    for entry in cycles:
        x_val = _safe_float(entry.get("cumulative_co2_added_mass_g"))
        if x_val is None:
            x_val = _safe_float(entry.get("cumulative_co2_mass_g"))
        if x_val is None or not math.isfinite(x_val):
            continue
        x_series.append(x_val)
        ph_series.append(entry.get("ph_after"))
    if not x_series:
        raise AssertionError("Planning trace missing CO2 totals.")
    final_co2_g = x_series[-1]
    initial_naoh_mol = 700.0 / SOL_MW_NAOH
    eq_co2_g = (initial_naoh_mol / 2.0) * SOL_MW_CO2
    low_point = max(eq_co2_g * 0.2, x_series[0])
    high_point = min(final_co2_g, eq_co2_g * 1.2)
    mapped_low = _map_current_state_to_planning_curve(low_point, x_series, ph_series)
    mapped_high = _map_current_state_to_planning_curve(high_point, x_series, ph_series)
    if mapped_low[1] is None or not math.isfinite(mapped_low[1]):
        raise AssertionError("Analysis overlay mapping returned invalid low pH.")
    if mapped_high[1] is None or not math.isfinite(mapped_high[1]):
        raise AssertionError("Analysis overlay mapping returned invalid high pH.")
    overall_pct = max(0.0, min(low_point / max(final_co2_g, 1e-6), 1.0)) * 100.0
    eq_pct = max(0.0, min(low_point / max(eq_co2_g, 1e-6), 1.0)) * 100.0
    assert 0.0 <= overall_pct <= 100.0, "Overall completion out of bounds."
    assert 0.0 <= eq_pct <= 100.0, "Equivalence completion out of bounds."
    regime_low = _analysis_regime_label(mapped_low[1])
    regime_high = _analysis_regime_label(mapped_high[1])
    if regime_low == regime_high:
        raise AssertionError("Regime classification did not change across progression.")
    missing = _map_current_state_to_planning_curve(10.0, [], [])
    assert missing == (
        None,
        None,
        None,
    ), "Missing planning curve mapping should be safe."


def _regression_test_core_plot_render_parity() -> None:
    """Validate non-combined core plot parity with combined-style render settings."""
    sentinel = object()
    globals_snapshot: Dict[str, Any] = {
        key: globals().get(key, sentinel)
        for key in ("x", "y1", "y2", "y3", "z", "z2", "selected_columns")
    }
    settings_snapshot = copy.deepcopy(settings)
    figures: List[Figure] = []
    try:
        settings["core_plot_render_profiles"] = _normalize_core_plot_render_profiles(
            {
                "fig_pressure_temp": {
                    "x_axis_label": "Core Fig1 X Label",
                    "primary_axis_label": "Core Fig1 Pressure",
                    "right_axis_label": "Core Fig1 Temperature",
                    "title_fontsize": 15.0,
                    "suptitle_fontsize": 17.0,
                    "title_pad_pts": 16.0,
                    "suptitle_pad_pts": 13.0,
                    "suptitle_y": 0.97,
                    "label_fontsize": 12.0,
                    "tick_fontsize": 10.0,
                    "legend_wrap": True,
                    "legend_rows": 2,
                    "legend_alignment": "left",
                },
                "fig_pressure_derivative": {
                    "x_axis_label": "Core Fig2 X Label",
                    "primary_axis_label": "Core Fig2 Pressure",
                    "third_axis_label": "Core Fig2 Derivative",
                    "title_fontsize": 14.0,
                    "suptitle_fontsize": 16.0,
                    "title_pad_pts": 15.0,
                    "suptitle_pad_pts": 12.0,
                    "suptitle_y": 0.965,
                    "label_fontsize": 11.0,
                    "tick_fontsize": 9.0,
                    "legend_wrap": True,
                    "legend_rows": 3,
                    "legend_alignment": "right",
                },
            },
            seed_source=settings,
        )
        _write_legacy_core_legend_settings_from_profile(
            settings["core_plot_render_profiles"].get("fig_pressure_temp")
        )

        x_vals = pd.Series([0.0, 0.5, 1.0, 1.5, 2.0], dtype=float)
        y1_vals = pd.Series([10.0, 9.0, 8.2, 7.4, 6.8], dtype=float)
        y2_vals = pd.Series([0.0, -0.6, -0.4, 0.2, 0.5], dtype=float)
        y3_vals = pd.Series([9.8, 8.8, 8.0, 7.1, 6.6], dtype=float)
        z_vals = pd.Series([22.0, 23.5, 24.0, 25.0, 26.5], dtype=float)
        selected = {
            "x": "Elapsed Days",
            "y1": "Pressure PSI",
            "y2": "Derivative PSI/day",
            "y3": "Aux Pressure PSI",
            "z": "Temperature (°C)",
            "z2": "None",
        }
        globals().update(
            {
                "x": x_vals,
                "y1": y1_vals,
                "y2": y2_vals,
                "y3": y3_vals,
                "z": z_vals,
                "z2": None,
                "selected_columns": selected,
            }
        )
        render_ctx = RenderContext(
            data_ctx={
                "series": {
                    "x": x_vals,
                    "y1": y1_vals,
                    "y2": y2_vals,
                    "y3": y3_vals,
                    "z": z_vals,
                    "z2": None,
                },
                "selected_columns": selected,
            },
            cycle_ctx={},
            overlay_ctx={"markers": None, "cycle_legend": None, "moles_summary": None},
            gates_ctx={
                "show_cycle_markers": False,
                "show_cycle_legend": False,
                "include_moles": False,
            },
            style_ctx={
                "scatter_config": None,
                "scatter_series_configs": None,
                "font_family": settings.get("font_family"),
                "core_plot_render_profiles": copy.deepcopy(
                    settings.get("core_plot_render_profiles", {})
                ),
            },
            layout_ctx={},
            plot_elements_ctx={},
        )
        figs = main_plotting_function(
            0.0,
            2.0,
            0.0,
            12.0,
            10.0,
            40.0,
            -2.0,
            2.0,
            True,
            True,
            True,
            True,
            "Core Parity Title",
            "Core Parity Suptitle",
            0.5,
            0.25,
            2.0,
            1.0,
            5.0,
            2.5,
            1.0,
            0.5,
            True,
            True,
            0.8,
            show_cycle_markers_on_core_plots=False,
            show_cycle_legend_on_core_plots=False,
            include_moles_in_core_plot_legend=False,
            fig_size=(7.2, 4.8),
            render_ctx=render_ctx,
        )
        if not isinstance(figs, dict):
            raise AssertionError("Core parity regression did not return figure map.")
        fig1 = figs.get("fig1")
        fig2 = figs.get("fig2")
        if fig1 is None or fig2 is None:
            raise AssertionError("Core parity regression missing one or more core figures.")
        figures.extend([fig1, fig2])
        _apply_layout_profile_to_figure(fig1, "fig_pressure_temp", "display")
        _apply_layout_profile_to_figure(fig2, "fig_pressure_derivative", "display")

        def _bbox_in_figure_coords(fig_obj: Figure, artist: Any) -> Optional[Bbox]:
            """Return figure-normalized bbox for one artist."""
            if fig_obj is None or artist is None:
                return None
            if fig_obj.canvas is None:
                FigureCanvasAgg(fig_obj)
            try:
                fig_obj.canvas.draw()
                renderer = fig_obj.canvas.get_renderer()
            except Exception:
                return None
            try:
                return artist.get_window_extent(renderer=renderer).transformed(
                    fig_obj.transFigure.inverted()
                )
            except Exception:
                return None

        for fig, plot_id in (
            (fig1, "fig_pressure_temp"),
            (fig2, "fig_pressure_derivative"),
        ):
            title_artist = getattr(fig, "_gl260_title_text", None)
            suptitle_artist = getattr(fig, "_gl260_suptitle_text", None)
            xlabel_artist = getattr(fig, "_gl260_xlabel_text", None)
            if title_artist is None or not str(title_artist.get_text() or "").strip():
                raise AssertionError(f"{plot_id}: title artist missing after render.")
            if suptitle_artist is None or not str(suptitle_artist.get_text() or "").strip():
                raise AssertionError(f"{plot_id}: suptitle artist missing after render.")
            if xlabel_artist is None or not str(xlabel_artist.get_text() or "").strip():
                raise AssertionError(f"{plot_id}: figure-level x-label missing after render.")
            if getattr(title_artist, "axes", None) is None:
                raise AssertionError(
                    f"{plot_id}: title artist must be axes-bound for layout parity."
                )
            title_bbox = _bbox_in_figure_coords(fig, title_artist)
            suptitle_bbox = _bbox_in_figure_coords(fig, suptitle_artist)
            if title_bbox is None or suptitle_bbox is None:
                raise AssertionError(
                    f"{plot_id}: failed to measure title/suptitle bounding boxes."
                )
            if title_bbox.y0 > 1.001:
                raise AssertionError(
                    f"{plot_id}: title is outside figure bounds (y0={title_bbox.y0:.4f})."
                )
            if suptitle_bbox.y0 < title_bbox.y1:
                raise AssertionError(
                    f"{plot_id}: suptitle overlaps title (title_y1={title_bbox.y1:.4f}, suptitle_y0={suptitle_bbox.y0:.4f})."
                )
            data_axes = [
                axis
                for axis in fig.get_axes()
                if not getattr(axis, "_gl260_legend_only", False)
            ]
            primary_axis = next(
                (
                    axis
                    for axis in data_axes
                    if getattr(axis, "_gl260_axis_role", None) == "primary"
                ),
                data_axes[0] if data_axes else None,
            )
            if primary_axis is not None and primary_axis.get_position().y1 < 0.80:
                raise AssertionError(
                    f"{plot_id}: plot area top collapsed unexpectedly (y1={primary_axis.get_position().y1:.4f})."
                )
            expected_legend_face = _normalize_mpl_color(
                _legend_shadowbox_kwargs().get(
                    "facecolor", DEFAULT_LEGEND_SHADOWBOX_FILL_COLOR
                )
            )
            main_legends = [
                legend
                for legend in _collect_gl260_legends(fig)
                if _gl260_legend_role(legend) == "main"
            ]
            if not main_legends:
                raise AssertionError(f"{plot_id}: missing main legend for parity check.")
            for legend in main_legends:
                frame = None
                try:
                    frame = legend.get_frame()
                except Exception:
                    frame = None
                if frame is None:
                    raise AssertionError(f"{plot_id}: main legend frame missing.")
                actual_face = _normalize_mpl_color(frame.get_facecolor())
                if actual_face.lower() != expected_legend_face.lower():
                    raise AssertionError(
                        f"{plot_id}: legend frame facecolor mismatch ({actual_face} != {expected_legend_face})."
                    )

        fig1_axes = [ax for ax in fig1.get_axes() if not getattr(ax, "_gl260_legend_only", False)]
        if not fig1_axes or fig1_axes[0].get_ylabel().strip() != "Core Fig1 Pressure":
            raise AssertionError("fig_pressure_temp: primary y-label override did not apply.")
        if str(getattr(fig1, "_gl260_xlabel_text").get_text()).strip() != "Core Fig1 X Label":
            raise AssertionError("fig_pressure_temp: x-label override did not apply.")

        fig2_axes = [ax for ax in fig2.get_axes() if not getattr(ax, "_gl260_legend_only", False)]
        if not fig2_axes or fig2_axes[0].get_ylabel().strip() != "Core Fig2 Pressure":
            raise AssertionError("fig_pressure_derivative: primary y-label override did not apply.")
        if len(fig2_axes) > 1 and fig2_axes[1].get_ylabel().strip() != "Core Fig2 Derivative":
            raise AssertionError("fig_pressure_derivative: derivative y-label override did not apply.")
        if str(getattr(fig2, "_gl260_xlabel_text").get_text()).strip() != "Core Fig2 X Label":
            raise AssertionError("fig_pressure_derivative: x-label override did not apply.")
    finally:
        for fig in figures:
            try:
                plt.close(fig)
            except Exception:
                pass
        settings.clear()
        settings.update(settings_snapshot)
        for key, original in globals_snapshot.items():
            if original is sentinel:
                globals().pop(key, None)
            else:
                globals()[key] = original


REGRESSION_TESTS: List[Tuple[str, Callable[[], None]]] = [
    (
        "Planning equivalence definition",
        _regression_test_planning_equivalence_definition,
    ),
    (
        "Planning post-equivalence decline",
        _regression_test_planning_post_equivalence_decline,
    ),
    ("Planning convergence window", _regression_test_planning_convergence_window),
    (
        "Planning post-carbonate stability",
        _regression_test_planning_post_carbonate_stability,
    ),
    ("Planning tail pH band", _regression_test_planning_tail_ph_band),
    ("Planning mass balance", _regression_test_planning_mass_balance_and_progression),
    ("Planning input wiring", _regression_test_planning_input_wiring),
    ("Post-equivalence pH trends", _regression_test_post_equivalence_ph_trends),
    ("Analysis overlay progress mapping", _regression_test_analysis_progress_overlay),
    ("Core plot render parity", _regression_test_core_plot_render_parity),
    ("NaOH-CO2 Pitzer internal tests", _run_naoh_pitzer_internal_tests),
    ("Planning Pitzer smoke test", _integration_test_planning_pitzer_smoke),
    (
        "Plot title centering and label fonts (dev)",
        _dev_validate_plot_title_centering_and_labels,
    ),
]


def _log_co2_dosing_math(
    math_logger: SolubilityMathLogger,
    *,
    naoh_mass_g: float,
    naoh_mol: float,
    co2_mass_g: float,
    co2_mol: float,
    stage1_co2: float,
    stage2_co2: float,
    na2co3_from_stage1: float,
    naoh_after_stage1: float,
    na2co3_remaining: float,
    nahco3_produced: float,
    co2_excess: float,
    co2_after_stage1: float,
    co3_current: float,
    hco3_current: float,
    measurement_label: Optional[str],
    measurement_value: Optional[float],
    ratio_estimate: Optional[float],
    pka2_value: float,
    desired_ph: float,
    ratio_target: float,
    co2_for_ratio: float,
    co2_for_naoh: float,
    total_extra_mol: float,
    total_extra_g: float,
) -> None:
    """Perform log CO2 dosing math.
    Used to keep the workflow logic localized and testable."""
    section = "CO2 Dosing"
    math_logger.log(
        section,
        "NaOH charge (mol)",
        f"{naoh_mass_g:.2f} g / {SOL_MW_NAOH:.3f} g/mol",
        f"{naoh_mol:.4f}",
        units="mol",
        steps=(
            SolubilityMathStep(
                title="Mass to moles",
                expression="n = m / MW",
                latex=r"n = \frac{m}{MW}",
                detail="Convert NaOH mass into moles.",
            ),
            SolubilityMathStep(
                title="Substitute",
                expression=f"n = {naoh_mass_g:.2f} / {SOL_MW_NAOH:.3f}",
                latex=rf"n = \frac{{{naoh_mass_g:.2f}}}{{{SOL_MW_NAOH:.3f}}}",
            ),
            SolubilityMathStep(
                title="Evaluate",
                expression=f"n = {naoh_mol:.4f} mol",
            ),
        ),
    )
    math_logger.log(
        section,
        "CO2 added (mol)",
        f"{co2_mass_g:.2f} g / {SOL_MW_CO2:.4f} g/mol",
        f"{co2_mol:.4f}",
        units="mol",
        steps=(
            SolubilityMathStep(
                title="Mass to moles",
                expression="n = m / MW",
                latex=r"n = \frac{m}{MW}",
                detail="Convert charged CO2 mass into moles.",
            ),
            SolubilityMathStep(
                title="Substitute",
                expression=f"n = {co2_mass_g:.2f} / {SOL_MW_CO2:.4f}",
                latex=rf"n = \frac{{{co2_mass_g:.2f}}}{{{SOL_MW_CO2:.4f}}}",
            ),
            SolubilityMathStep(
                title="Evaluate",
                expression=f"n = {co2_mol:.4f} mol",
            ),
        ),
    )
    naoh_half = naoh_mol / 2.0
    math_logger.log(
        section,
        "Stage 1: 2 NaOH + CO2 -> Na2CO3",
        f"min({co2_mol:.4f}, {naoh_half:.4f})",
        f"{stage1_co2:.4f}",
        units="mol",
        steps=(
            SolubilityMathStep(
                title="Stoichiometry",
                expression="2 NaOH + CO2 -> Na2CO3 + H2O",
                latex=r"2\,NaOH + CO_2 \rightarrow Na_2CO_3 + H_2O",
                detail="Two moles of NaOH consume one mole of CO2.",
            ),
            SolubilityMathStep(
                title="Limiting reagent",
                expression=(
                    f"n_CO2 = {co2_mol:.4f} mol; " f"n_NaOH/2 = {naoh_half:.4f} mol"
                ),
            ),
            SolubilityMathStep(
                title="Extent",
                expression=(
                    f"min({co2_mol:.4f}, {naoh_half:.4f}) = {stage1_co2:.4f} mol"
                ),
            ),
        ),
    )
    math_logger.log(
        section,
        "Stage 2: Na2CO3 + CO2 -> 2 NaHCO3",
        f"min({co2_after_stage1:.4f}, {na2co3_from_stage1:.4f})",
        f"{stage2_co2:.4f}",
        units="mol",
        steps=(
            SolubilityMathStep(
                title="Stoichiometry",
                expression="Na2CO3 + CO2 + H2O -> 2 NaHCO3",
                latex=r"Na_2CO_3 + CO_2 + H_2O \rightarrow 2\,NaHCO_3",
                detail="Each mole of Na2CO3 converts with one mole of CO2.",
            ),
            SolubilityMathStep(
                title="Remaining feed",
                expression=(
                    f"CO2 remaining = {co2_after_stage1:.4f} mol; "
                    f"Na2CO3 = {na2co3_from_stage1:.4f} mol"
                ),
            ),
            SolubilityMathStep(
                title="Extent",
                expression=(
                    f"min({co2_after_stage1:.4f}, {na2co3_from_stage1:.4f}) = "
                    f"{stage2_co2:.4f} mol"
                ),
            ),
        ),
    )
    buffer_carbon = na2co3_remaining + nahco3_produced
    current_ratio = co3_current / max(hco3_current, 1e-12)
    math_logger.log(
        section,
        "Carbonate ledger",
        "Na2CO3 + NaHCO3",
        f"{buffer_carbon:.4f} mol",
        units="mol",
        steps=(
            SolubilityMathStep(
                title="Na2CO3",
                expression=f"{na2co3_remaining:.4f} mol remain",
            ),
            SolubilityMathStep(
                title="NaHCO3",
                expression=f"{nahco3_produced:.4f} mol produced",
            ),
            SolubilityMathStep(
                title="Dissolved CO2",
                expression=f"{co2_excess:.4f} mol excess",
            ),
        ),
    )
    math_logger.log(
        section,
        "Current carbonate ratio",
        "[CO3]/[HCO3]",
        f"{current_ratio:.4f}",
        steps=(
            SolubilityMathStep(
                title="Ledger split",
                expression=f"[CO3] = {co3_current:.4f} mol",
            ),
            SolubilityMathStep(
                title="Ledger split",
                expression=f"[HCO3] = {hco3_current:.4f} mol",
            ),
            SolubilityMathStep(
                title="Ratio",
                expression=(
                    f"{co3_current:.4f} / {max(hco3_current,1e-12):.4f} = "
                    f"{current_ratio:.4f}"
                ),
            ),
        ),
    )
    if measurement_value is not None and ratio_estimate is not None:
        label = measurement_label or "Measurement"
        math_logger.log(
            section,
            f"{label} ratio estimate",
            f"10^({measurement_value:.2f} - {pka2_value:.2f})",
            f"{ratio_estimate:.4f}",
            steps=(
                SolubilityMathStep(
                    title="Henderson-Hasselbalch",
                    expression="pH = pKa2 + log10([CO3]/[HCO3])",
                    latex=r"pH = pK_{a2} + \log_{10}\frac{[CO_3^{2-}]}{[HCO_3^-]}",
                    detail="Rearrange to solve for the carbonate ratio at the measured pH.",
                ),
                SolubilityMathStep(
                    title="Solve for ratio",
                    expression=(
                        f"[CO3]/[HCO3] = 10^({measurement_value:.2f} - {pka2_value:.2f})"
                    ),
                    latex=(
                        rf"\frac{{[CO_3^{{2-}}]}}{{[HCO_3^-]}} = "
                        rf"10^{{({measurement_value:.2f} - {pka2_value:.2f})}}"
                    ),
                ),
                SolubilityMathStep(
                    title="Evaluate",
                    expression=f"ratio = {ratio_estimate:.4f}",
                ),
                SolubilityMathStep(
                    title="Interpret ratio",
                    expression=">1 carbonate-rich, <1 bicarbonate-rich",
                    detail="Shows how the measured pH skews the CO3^2-/HCO3^- balance.",
                ),
            ),
        )
    math_logger.log(
        section,
        "Target ratio",
        f"10^({desired_ph:.2f} - {pka2_value:.2f})",
        f"{ratio_target:.4f}",
        steps=(
            SolubilityMathStep(
                title="Henderson-Hasselbalch",
                expression="pH = pKa2 + log10([CO3]/[HCO3])",
                latex=r"pH = pK_{a2} + \log_{10}\frac{[CO_3^{2-}]}{[HCO_3^-]}",
                detail="Solve for the desired carbonate ratio at the target pH.",
            ),
            SolubilityMathStep(
                title="Solve for ratio",
                expression=(f"[CO3]/[HCO3] = 10^({desired_ph:.2f} - {pka2_value:.2f})"),
                latex=(
                    rf"\frac{{[CO_3^{{2-}}]}}{{[HCO_3^-]}} = "
                    rf"10^{{({desired_ph:.2f} - {pka2_value:.2f})}}"
                ),
            ),
            SolubilityMathStep(
                title="Evaluate",
                expression=f"ratio = {ratio_target:.4f}",
            ),
        ),
    )
    math_logger.log(
        section,
        "CO2 for ratio shift",
        "(CO3 - R * HCO3) / (1 + 2R)",
        f"{co2_for_ratio:.4f}",
        units="mol",
        steps=(
            SolubilityMathStep(
                title="Formula",
                expression="n = (CO3 - R * HCO3) / (1 + 2R)",
                latex=r"n_{\text{ratio}} = \frac{[CO_3^{2-}] - R[HCO_3^-]}{1 + 2R}",
                detail="Add CO2 until the carbonate ratio reaches R = [CO3]/[HCO3].",
            ),
            SolubilityMathStep(
                title="Substitute",
                expression=(
                    f"({co3_current:.4f} - {ratio_target:.4f} * {hco3_current:.4f}) "
                    f"/ (1 + 2*{ratio_target:.4f})"
                ),
            ),
            SolubilityMathStep(
                title="Evaluate",
                expression=f"n = {co2_for_ratio:.4f} mol",
            ),
        ),
    )
    math_logger.log(
        section,
        "CO2 for residual NaOH",
        "n = n_NaOH_remaining / 2",
        f"{co2_for_naoh:.4f}",
        units="mol",
        steps=(
            SolubilityMathStep(
                title="Definition",
                expression="2 NaOH + CO2 -> Na2CO3 + H2O",
                latex=r"2\,NaOH + CO_2 \rightarrow Na_2CO_3 + H_2O",
                detail="Each mole of CO2 neutralizes two moles of NaOH.",
            ),
            SolubilityMathStep(
                title="Remaining NaOH",
                expression=f"n_NaOH = {naoh_after_stage1:.4e} mol",
            ),
            SolubilityMathStep(
                title="Required CO2",
                expression=f"{naoh_after_stage1:.4e} / 2 = {co2_for_naoh:.4f} mol",
            ),
        ),
    )
    math_logger.log(
        section,
        "Total CO2 recommendation (mol)",
        "n_total = n_ratio + n_NaOH",
        f"{total_extra_mol:.4f}",
        units="mol",
        steps=(
            SolubilityMathStep(
                title="Ratio adjustment",
                expression=f"n_ratio = {co2_for_ratio:.4f} mol",
            ),
            SolubilityMathStep(
                title="NaOH neutralization",
                expression=f"n_NaOH = {co2_for_naoh:.4f} mol",
            ),
            SolubilityMathStep(
                title="Sum",
                expression=(
                    f"{co2_for_ratio:.4f} + {co2_for_naoh:.4f} = {total_extra_mol:.4f} mol"
                ),
                latex=r"n_{\text{total}} = n_{\text{ratio}} + n_{\text{NaOH}}",
            ),
        ),
    )
    math_logger.log(
        section,
        "Total CO2 recommendation (g)",
        f"{total_extra_mol:.4f} mol * {SOL_MW_CO2:.4f} g/mol",
        f"{total_extra_g:.2f}",
        units="g",
        steps=(
            SolubilityMathStep(
                title="Convert to mass",
                expression="m = n * MW",
                latex=r"m = n \times MW",
            ),
            SolubilityMathStep(
                title="Substitute",
                expression=(
                    f"{total_extra_mol:.4f} * {SOL_MW_CO2:.4f} = {total_extra_g:.2f} g"
                ),
            ),
        ),
    )


def _log_reaction_tracker_math(
    math_logger: Optional[SolubilityMathLogger],
    entries: Sequence[Dict[str, Any]],
) -> None:
    """Perform log reaction tracker math.
    Used to keep the workflow logic localized and testable."""
    if not math_logger or not math_logger.enabled:
        return
    section = "Reaction Progress Tracker"
    prev_total = 0.0
    # Iterate over indexed elements from entries, 1 to apply the per-item logic.
    for idx, entry in enumerate(entries, 1):
        total_mass = _safe_float(entry.get("co2_g"))
        if total_mass is None or not math.isfinite(total_mass):
            continue
        timestamp = str(entry.get("timestamp") or f"Entry {idx}")
        notes = str(entry.get("notes") or "").strip()
        ph_value = _safe_float(entry.get("ph"))
        delta_mass = total_mass - prev_total
        steps: List[SolubilityMathStep] = [
            SolubilityMathStep(
                title="Mass basis",
                expression=f"m_CO2 = {total_mass:.2f} g",
                latex=rf"m_{{\mathrm{{CO_2}}}} = {total_mass:.2f}\,\mathrm{{g}}",
                detail=notes or "Logged measurement",
            ),
            SolubilityMathStep(
                title="Incremental CO2",
                expression=f"Delta m = {total_mass:.2f} - {prev_total:.2f} = {delta_mass:.2f} g",
                latex=rf"\Delta m = {total_mass:.2f} - {prev_total:.2f} = {delta_mass:.2f}",
            ),
            SolubilityMathStep(
                title="Convert to moles",
                expression=f"n = {total_mass:.2f} / {SOL_MW_CO2:.4f}",
                latex=rf"n = \frac{{{total_mass:.2f}}}{{{SOL_MW_CO2:.4f}}}",
                units="mol",
            ),
        ]
        if ph_value is not None and math.isfinite(ph_value):
            steps.append(
                SolubilityMathStep(
                    title="Measured pH",
                    expression=f"pH = {ph_value:.2f}",
                    latex=rf"\mathrm{{pH}} = {ph_value:.2f}",
                )
            )
        total_moles = total_mass / SOL_MW_CO2
        math_logger.log(
            section,
            f"Tracker entry #{idx} ({timestamp})",
            r"n_{\mathrm{CO_2}} = \frac{m_{\mathrm{CO_2}}}{MW_{\mathrm{CO_2}}}",
            f"{total_moles:.4f}",
            units="mol",
            steps=tuple(steps),
        )
        prev_total = total_mass


def _log_cycle_timeline_math(
    math_logger: Optional[SolubilityMathLogger],
    cycle_summary: Optional[Dict[str, Any]],
) -> None:
    """Perform log cycle timeline math.
    Used to keep the workflow logic localized and testable."""

    if not math_logger or not math_logger.enabled:
        return
    summary = cycle_summary or {}
    timeline = summary.get("timeline") or []
    if not timeline:
        return
    section = "Cycle Timeline"
    supersat_factor = _safe_float(summary.get("supersaturation_factor"))
    if supersat_factor is not None and math.isfinite(supersat_factor):
        math_logger.log(
            section,
            "Supersaturation factor",
            "",
            f"{supersat_factor:.2f}",
            units="ratio",
        )
    headspace_g = _safe_float(summary.get("headspace_co2_g"))
    if headspace_g is not None and math.isfinite(headspace_g):
        math_logger.log(
            section,
            "Headspace CO₂ (summary)",
            "",
            f"{headspace_g:.2f}",
            units="g",
        )
    # Iterate over indexed elements from timeline, 1 to apply the per-item logic.
    for idx, entry in enumerate(timeline, 1):
        cycle_id = entry.get("cycle_id", idx)
        if entry.get("error"):
            math_logger.log(
                section,
                f"Cycle {cycle_id}",
                "Error",
                str(entry.get("error")),
            )
            continue
        delta_moles = _safe_float(entry.get("co2_moles"))
        delta_mass = (
            delta_moles * SOL_MW_CO2
            if delta_moles is not None and math.isfinite(delta_moles)
            else None
        )
        cumulative_mass = _safe_float(entry.get("co2_g"))
        cumulative_moles = _safe_float(entry.get("co2_total_moles"))
        solution_ph = _safe_float(entry.get("solution_ph"))
        forecast_ph = _safe_float(entry.get("forecast_ph"))
        target_ph = _safe_float(entry.get("target_ph"))
        co2_to_target = _safe_float(entry.get("co2_to_target_g"))
        pco2_atm = _safe_float(entry.get("pco2_atm"))
        solid_na2co3 = _safe_float(entry.get("solid_na2co3_g"))
        solid_nahco3 = _safe_float(entry.get("solid_nahco3_g"))
        fractions = entry.get("fractions") or {}
        frac_h2co3 = fractions.get("H2CO3", 0.0) * 100.0
        frac_hco3 = fractions.get("HCO3-", 0.0) * 100.0
        frac_co3 = fractions.get("CO3^2-", 0.0) * 100.0
        steps: List[SolubilityMathStep] = []
        if delta_moles is not None and math.isfinite(delta_moles):
            steps.append(
                SolubilityMathStep(
                    title="Cycle CO₂ dose",
                    expression=(
                        f"Δn = {delta_moles:.4f} mol"
                        + (
                            f" ({delta_mass:.2f} g)"
                            if delta_mass is not None and math.isfinite(delta_mass)
                            else ""
                        )
                    ),
                    units="mol",
                )
            )
        if cumulative_moles is not None and math.isfinite(cumulative_moles):
            steps.append(
                SolubilityMathStep(
                    title="Cumulative CO₂",
                    expression=f"n_total = {cumulative_moles:.4f} mol",
                    detail=(
                        f"m_total = {cumulative_mass:.2f} g"
                        if cumulative_mass is not None
                        and math.isfinite(cumulative_mass)
                        else ""
                    ),
                    units="mol",
                )
            )
        if solution_ph is not None and math.isfinite(solution_ph):
            steps.append(
                SolubilityMathStep(
                    title="Predicted pH",
                    expression=f"pH ≈ {solution_ph:.2f}",
                    units="pH",
                )
            )
        if forecast_ph is not None and math.isfinite(forecast_ph):
            steps.append(
                SolubilityMathStep(
                    title="Forecast pH",
                    expression=f"{forecast_ph:.2f} (ledger prediction)",
                    units="pH",
                )
            )
        if target_ph is not None and math.isfinite(target_ph):
            steps.append(
                SolubilityMathStep(
                    title="Target pH reference",
                    expression=f"{target_ph:.2f}",
                    units="pH",
                )
            )
        if co2_to_target is not None and math.isfinite(co2_to_target):
            steps.append(
                SolubilityMathStep(
                    title="CO₂ to target",
                    expression=f"{co2_to_target:.2f} g remaining",
                    units="g",
                )
            )
        steps.append(
            SolubilityMathStep(
                title="Carbon species share",
                expression=(
                    f"H₂CO₃/HCO₃⁻/CO₃²⁻ = {frac_h2co3:.1f}% / {frac_hco3:.1f}% / {frac_co3:.1f}%"
                ),
                units="%",
            )
        )
        steps.append(
            SolubilityMathStep(
                title="Solids and headspace",
                expression=(
                    f"Na₂CO₃ {solid_na2co3 or 0.0:.2f} g, "
                    f"NaHCO₃ {solid_nahco3 or 0.0:.2f} g"
                ),
                detail=(
                    f"pCO₂ ≈ {pco2_atm:.3g} atm"
                    if pco2_atm is not None and math.isfinite(pco2_atm)
                    else "pCO₂ not estimated"
                ),
            )
        )
        math_logger.log(
            section,
            f"Cycle {cycle_id}",
            (
                f"ΔCO₂ {delta_mass:.2f} g"
                if delta_mass is not None and math.isfinite(delta_mass)
                else "ΔCO₂ n/a"
            ),
            (
                f"pH {solution_ph:.2f}"
                if solution_ph is not None and math.isfinite(solution_ph)
                else "pH n/a"
            ),
            steps=steps,
        )


def analyze_bicarbonate_reaction(
    *,
    naoh_mass_g: Optional[float],
    co2_charged_g: Optional[float],
    solution_volume_l: Optional[float],
    measured_ph: Optional[float],
    slurry_ph: Optional[float],
    target_ph: Optional[float],
    temperature_c: Optional[float],
    use_temp_adjusted_constants: bool,
    ionic_strength_cap: Optional[float] = None,
    math_logger: Optional[SolubilityMathLogger] = None,
) -> Optional[Dict[str, Any]]:
    """Analyze bicarbonate reaction.
    Used to produce bicarbonate reaction diagnostics or summaries."""

    if (
        naoh_mass_g is None
        or co2_charged_g is None
        or naoh_mass_g <= 0
        or co2_charged_g < 0
    ):
        return None

    naoh_mol = naoh_mass_g / SOL_MW_NAOH
    co2_mol = co2_charged_g / SOL_MW_CO2
    if naoh_mol <= 0:
        return None

    stage1_co2 = min(co2_mol, naoh_mol / 2.0)
    naoh_after_stage1 = max(0.0, naoh_mol - stage1_co2 * 2.0)
    na2co3_from_stage1 = stage1_co2
    co2_after_stage1 = max(0.0, co2_mol - stage1_co2)

    stage2_co2 = min(co2_after_stage1, na2co3_from_stage1)
    na2co3_remaining = max(0.0, na2co3_from_stage1 - stage2_co2)
    nahco3_produced = max(0.0, stage2_co2 * 2.0)
    co2_excess = max(0.0, co2_after_stage1 - stage2_co2)
    buffer_carbon = na2co3_remaining + nahco3_produced

    pka2_value = _resolve_pka2_value(temperature_c, use_temp_adjusted_constants)
    measurement_label = None
    measurement_value = None
    if measured_ph is not None:
        measurement_label = "Final product pH"
        measurement_value = measured_ph
    elif slurry_ph is not None:
        measurement_label = "Slurry pH"
        measurement_value = slurry_ph

    ratio_estimate = (
        10 ** (measurement_value - pka2_value)
        if measurement_value is not None
        else None
    )
    if buffer_carbon > 0 and ratio_estimate is not None:
        frac_co3 = ratio_estimate / (1.0 + ratio_estimate)
        co3_current = buffer_carbon * frac_co3
        hco3_current = max(0.0, buffer_carbon - co3_current)
    else:
        co3_current = na2co3_remaining
        hco3_current = nahco3_produced

    desired_ph = target_ph if target_ph is not None else 8.0
    ratio_target = 10 ** (desired_ph - pka2_value)
    numerator = co3_current - ratio_target * hco3_current
    denom = 1.0 + 2.0 * ratio_target
    co2_for_ratio = 0.0
    if denom > 0 and numerator > 0:
        co2_for_ratio = min(numerator / denom, max(co3_current, 0.0))

    co2_for_naoh = naoh_after_stage1 / 2.0
    total_extra_mol = max(0.0, co2_for_ratio) + max(0.0, co2_for_naoh)
    total_extra_g = total_extra_mol * SOL_MW_CO2

    ledger = {
        "naoh_initial_mol": naoh_mol,
        "co2_added_mol": co2_mol,
        "co2_stage1_mol": stage1_co2,
        "co2_stage2_mol": stage2_co2,
        "naoh_remaining_mol": naoh_after_stage1,
        "na2co3_mol": na2co3_remaining,
        "nahco3_mol": nahco3_produced,
        "co2_excess_mol": co2_excess,
        "buffer_carbon_mol": buffer_carbon,
    }

    eq_constants = _basic_carbonate_constants(
        temperature_c, use_temp_adjusted_constants
    )
    initial_guess = measurement_value if measurement_value is not None else desired_ph
    predicted_after = _simulate_reaction_state(
        ledger,
        total_extra_mol,
        pka2_value,
        solution_volume_l=solution_volume_l,
        temperature_c=temperature_c,
        ionic_strength_cap=ionic_strength_cap,
        use_temp_adjusted_constants=use_temp_adjusted_constants,
        initial_ph_guess=initial_guess,
        constants=eq_constants,
    )
    predicted_ph = predicted_after["ph"]
    slider_max_g = max(total_extra_g * 1.6, 2.0)
    simulation_curve: List[Dict[str, float]] = []
    steps = 12
    step_guess = initial_guess
    # Iterate over the configured range to apply the per-item logic.
    for idx in range(steps + 1):
        delta_g = slider_max_g * (idx / steps)
        delta_mol = delta_g / SOL_MW_CO2
        state = _simulate_reaction_state(
            ledger,
            delta_mol,
            pka2_value,
            solution_volume_l=solution_volume_l,
            temperature_c=temperature_c,
            ionic_strength_cap=ionic_strength_cap,
            use_temp_adjusted_constants=use_temp_adjusted_constants,
            initial_ph_guess=step_guess,
            constants=eq_constants,
        )
        step_guess = state.get("ph", step_guess)
        simulation_curve.append(
            {
                "delta_g": delta_g,
                "total_co2_g": co2_charged_g + delta_g,
                "ph": state["ph"],
                "na2co3_mol": state["na2co3_mol"],
                "nahco3_mol": state["nahco3_mol"],
            }
        )

    warnings: List[str] = []
    notes: List[str] = []
    if measurement_value is None:
        warnings.append("No measured pH provided; relying on ledger ratios.")
    elif measurement_value <= desired_ph + 0.02:
        warnings.append(
            f"{measurement_label or 'Measurement'} ({measurement_value:.2f}) is already near the target pH."
        )
    if naoh_after_stage1 > 1e-4:
        warnings.append("Residual NaOH detected; neutralize remaining caustic first.")
    if solution_volume_l and solution_volume_l > 0:
        notes.append(f"Reaction volume basis: {solution_volume_l:.2f} L.")
    if co2_excess > 0:
        notes.append("Carbon ledger includes dissolved CO2 beyond solid conversions.")
    if ratio_estimate is not None:
        label = measurement_label or "Measured pH"
        notes.append(
            f"{label} implies [CO3]/[HCO3] ≈ {ratio_estimate:.3f} "
            "(>1 carbonate-rich buffer, <1 bicarbonate-rich)."
        )

    measurement_point = {
        "label": measurement_label or "Estimated pH",
        "ph": (
            measurement_value
            if measurement_value is not None
            else pka2_value
            + math.log10(max(co3_current / max(hco3_current, 1e-12), 1e-12))
        ),
        "co2_g": co2_charged_g,
    }

    math_lines = [
        f"n(NaOH) = {naoh_mass_g:.2f} g / {SOL_MW_NAOH:.3f} g/mol = {naoh_mol:.4f} mol",
        f"n(CO2) fed = {co2_charged_g:.2f} g / {SOL_MW_CO2:.4f} g/mol = {co2_mol:.4f} mol",
        f"Stage 1 (2 NaOH + CO2 -> Na2CO3): {stage1_co2:.4f} mol Na2CO3 generated",
        f"Stage 2 (Na2CO3 + CO2 -> 2 NaHCO3): {stage2_co2:.4f} mol converted",
        f"Residuals -> NaOH {naoh_after_stage1:.4e} mol, Na2CO3 {na2co3_remaining:.4f} mol, NaHCO3 {nahco3_produced:.4f} mol",
        f"Henderson-Hasselbalch with pKa2 = {pka2_value:.3f} informs CO3/HCO3 ratios.",
        f"CO2 for ratio shift = {co2_for_ratio:.4f} mol; for NaOH neutralization = {co2_for_naoh:.4f} mol",
        f"Total CO2 recommendation = {total_extra_mol:.4f} mol ({total_extra_g:.2f} g)",
    ]

    summary_lines = [
        f"Initial NaOH charge: {naoh_mass_g:.1f} g ({naoh_mol:.4f} mol)",
        f"CO2 absorbed to date: {co2_charged_g:.1f} g ({co2_mol:.4f} mol)",
        f"Ledger -> Na2CO3 {na2co3_remaining:.4f} mol, NaHCO3 {nahco3_produced:.4f} mol, dissolved CO2 {co2_excess:.4f} mol",
    ]
    if total_extra_g <= 0.02:
        summary_lines.append(
            f"System already meets the target pH ~= {desired_ph:.2f}; monitor for drift."
        )
    else:
        summary_lines.append(
            f"Add {total_extra_g:.2f} g CO2 ({total_extra_mol:.4f} mol) to approach pH {desired_ph:.2f} "
            f"(predicted ~= {predicted_ph:.2f})."
        )

    if math_logger:
        _log_co2_dosing_math(
            math_logger,
            naoh_mass_g=naoh_mass_g,
            naoh_mol=naoh_mol,
            co2_mass_g=co2_charged_g,
            co2_mol=co2_mol,
            stage1_co2=stage1_co2,
            stage2_co2=stage2_co2,
            na2co3_from_stage1=na2co3_from_stage1,
            naoh_after_stage1=naoh_after_stage1,
            na2co3_remaining=na2co3_remaining,
            nahco3_produced=nahco3_produced,
            co2_excess=co2_excess,
            co2_after_stage1=co2_after_stage1,
            co3_current=co3_current,
            hco3_current=hco3_current,
            measurement_label=measurement_label,
            measurement_value=measurement_value,
            ratio_estimate=ratio_estimate,
            pka2_value=pka2_value,
            desired_ph=desired_ph,
            ratio_target=ratio_target,
            co2_for_ratio=co2_for_ratio,
            co2_for_naoh=co2_for_naoh,
            total_extra_mol=total_extra_mol,
            total_extra_g=total_extra_g,
        )
        math_logger.extend_lines("CO2 Dosing", math_lines)

    return {
        "summary": "\n".join(summary_lines),
        "warnings": warnings,
        "notes": notes,
        "math_lines": math_lines,
        "ledger": ledger,
        "measurement": {
            "label": measurement_label or "Estimated pH",
            "value": measurement_value,
        },
        "target_ph": desired_ph,
        "recommended_co2_g": total_extra_g,
        "recommended_co2_mol": total_extra_mol,
        "predicted_ph_after": predicted_ph,
        "slider_max_g": slider_max_g,
        "base_co2_g": co2_charged_g,
        "simulation_curve": simulation_curve,
        "pka2": pka2_value,
        "measurement_point": measurement_point,
        "equilibrium_constants": {
            "ka1": eq_constants[0],
            "ka2": eq_constants[1],
            "kw": eq_constants[2],
        },
        "delta_components": {
            "neutralize_naoh_mol": co2_for_naoh,
            "carbonate_conversion_mol": co2_for_ratio,
        },
        "evaluation": {
            "ledger": ledger,
            "pka2": pka2_value,
            "base_co2_g": co2_charged_g,
            "volume_l": solution_volume_l,
            "temperature_c": temperature_c,
            "ionic_strength_cap": ionic_strength_cap,
            "use_temp_adjusted_constants": use_temp_adjusted_constants,
            "constants": eq_constants,
            "initial_ph_guess": predicted_ph,
        },
        "solution_volume_l": solution_volume_l,
        "temperature_c": temperature_c,
        "ionic_strength_cap": ionic_strength_cap,
        "use_temp_adjusted_constants": use_temp_adjusted_constants,
    }


def analyze_contaminated_bicarb_diagnostic(
    *,
    params: SolubilityInputs,
    result: SolubilitySpeciationResult,
    forced_result: Optional[SolubilitySpeciationResult],
    diagnostic: Optional[Dict[str, Any]],
    math_logger: Optional[SolubilityMathLogger] = None,
) -> Optional[Dict[str, Any]]:
    """Analyze contaminated bicarb diagnostic.
    Used to produce contaminated bicarb diagnostic diagnostics or summaries."""
    if not diagnostic:
        return None
    dried_ph = diagnostic.get("dried_ph")
    slurry_ph = diagnostic.get("slurry_ph")
    target_ph = diagnostic.get("target_ph") or 8.0
    sample_mass = diagnostic.get("sample_mass_g") or params.mass_na_hco3_g
    assumed_water = diagnostic.get("assumed_water_mass_g")
    used_slurry = slurry_ph is not None
    measured_alk = diagnostic.get("slurry_alk_meq_l")
    degas_fraction = diagnostic.get("degassed_fraction") or 0.0
    measurement_label = (
        "Atmospheric slurry pH" if slurry_ph is not None else "Dried sample pH"
    )
    measurement_value = (
        float(slurry_ph)
        if slurry_ph is not None
        else (float(dried_ph) if dried_ph is not None else result.ph)
    )
    volume = max(params.volume_l(), 1e-9)
    carbonate_moles = max(result.moles.get("CO3^2-", 0.0), 0.0)
    neutralize_mol = max(0.0, carbonate_moles)
    neutralize_g = neutralize_mol * SOL_MW_CO2
    current_total_mol = max(result.total_carbon_m, 0.0) * volume
    target_total_mol = current_total_mol
    predicted_ph = result.ph
    if forced_result is not None:
        target_total_mol = max(forced_result.total_carbon_m, 0.0) * volume
        predicted_ph = forced_result.ph
    total_needed_mol = max(0.0, target_total_mol - current_total_mol)
    neutralize_mol = min(neutralize_mol, total_needed_mol)
    polish_mol = max(0.0, total_needed_mol - neutralize_mol)
    total_needed_g = total_needed_mol * SOL_MW_CO2
    polish_g = polish_mol * SOL_MW_CO2
    sample_line = f"Sample mass evaluated: {sample_mass:.3f} g"
    if assumed_water:
        sample_line += f"; assumed {assumed_water:.1f} g water for dissolution"
    elif used_slurry:
        sample_line += "; slurry pH measured at atmosphere"
    summary_lines = [
        sample_line,
        f"{measurement_label}: {measurement_value:.2f} pH",
        f"Total CO2 recommendation: {total_needed_g:.2f} g -> predicted pH {predicted_ph:.2f}",
    ]
    warnings: List[str] = []
    notes: List[str] = []
    if forced_result is None:
        warnings.append("Forced pH calculation unavailable; slider preview disabled.")
    if slurry_ph is None:
        notes.append(
            "No slurry pH provided; dried-sample pH was used for the diagnostic seed."
        )
    else:
        notes.append(
            "Slurry pH measurement supplied at standard atmospheric conditions."
        )
    if measured_alk:
        notes.append(f"Measured slurry alkalinity = {measured_alk:.1f} meq/L.")
    if assumed_water:
        notes.append(
            f"Water basis auto-assumed at {assumed_water:.1f} g to dissolve the dried sample."
        )
    if degas_fraction:
        notes.append(
            f"Solver assumed {degas_fraction*100:.1f}% inorganic carbon vented prior to measurement."
        )
    notes.append(
        "Charge neutrality is solved implicitly; review the charge residual warning if it deviates from zero."
    )
    simulation_curve = [
        {"total_co2_g": 0.0, "ph": result.ph},
        {"total_co2_g": total_needed_g, "ph": predicted_ph},
    ]
    slider_max_g = max(total_needed_g * 1.5, 1.0) if total_needed_g > 0 else 0.0
    measurement_point = {
        "label": measurement_label,
        "ph": measurement_value,
        "co2_g": 0.0,
    }
    math_lines = [
        f"Sample mass = {sample_mass:.3f} g",
        f"Measurement ({measurement_label}) = {measurement_value:.2f} pH",
        f"Neutralize carbonate: {neutralize_mol:.4f} mol CO2 ({neutralize_g:.2f} g)",
        f"Polish to pH {target_ph:.2f}: {polish_mol:.4f} mol CO2 ({polish_g:.2f} g)",
        f"Total CO2 addition = {total_needed_mol:.4f} mol ({total_needed_g:.2f} g)",
    ]
    if math_logger:
        section = "Contaminated NaHCO3 Diagnostic"
        math_logger.extend_lines(section, math_lines)
    return {
        "summary": "\n".join(summary_lines),
        "warnings": warnings,
        "notes": notes,
        "math_lines": math_lines,
        "measurement": {"label": measurement_label, "value": measurement_value},
        "target_ph": target_ph,
        "recommended_co2_g": total_needed_g,
        "recommended_co2_mol": total_needed_mol,
        "predicted_ph_after": predicted_ph,
        "slider_max_g": slider_max_g,
        "base_co2_g": 0.0,
        "simulation_curve": simulation_curve if slider_max_g > 0 else [],
        "measurement_point": measurement_point,
        "delta_components": {
            "neutralize_naoh_mol": 0.0,
            "carbonate_conversion_mol": neutralize_mol,
            "polish_to_target_mol": polish_mol,
        },
        "evaluation": None,
        "sample_mass_g": sample_mass,
        "assumed_water_mass_g": assumed_water,
        "used_slurry": used_slurry,
    }


def _reprocessing_charge_basis(
    params: SolubilityInputs, measured_alk_meq: Optional[float]
) -> Tuple[float, str]:
    """Perform reprocessing charge basis.
    Used to keep the workflow logic localized and testable."""
    if measured_alk_meq is not None:
        try:
            alk = float(measured_alk_meq)
            if math.isfinite(alk) and alk > 0:
                return alk / 1000.0, "measured slurry alkalinity"
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
    try:
        basis = max(params.sodium_concentration(), 0.0)
    except Exception:
        basis = 0.0
    return basis, "sodium charge balance"


def _reprocessing_speciation_from_ph(
    params: SolubilityInputs,
    ph: float,
    *,
    constants: Optional[Tuple[float, float, float, List[str]]] = None,
    charge_basis_m: Optional[float] = None,
    measured_alk_meq: Optional[float] = None,
    math_logger: Optional[SolubilityMathLogger] = None,
    math_section: str = "Reprocessing equilibrium",
    basis_label: Optional[str] = None,
) -> Tuple[SolubilitySpeciationResult, float]:
    """Perform reprocessing speciation from pH.
    Used to keep the workflow logic localized and testable."""
    if ph is None or not math.isfinite(ph):
        raise ValueError("Reprocessing speciation requires a finite pH value.")
    resolved_constants = (
        constants
        if constants is not None
        else _resolve_solubility_constants(
            params, math_logger=math_logger, section=math_section
        )
    )
    basis_m, resolved_basis_label = _reprocessing_charge_basis(params, measured_alk_meq)
    if charge_basis_m is not None:
        basis_m = max(charge_basis_m, 0.0)
    if basis_label:
        resolved_basis_label = basis_label
    spec_params = replace(params, speciation_mode=SPEC_MODE_FIXED_PCO2)
    try:
        volume_l = spec_params.volume_l()
    except Exception:
        volume_l = 0.0
    if volume_l > 0 and basis_m > 0:
        sodium_mol = basis_m * volume_l
        spec_params = replace(spec_params, mass_na_hco3_g=sodium_mol * SOL_MW_NAHCO3)
    spec = solubility_speciation_at_forced_ph(
        spec_params,
        ph,
        constants=resolved_constants,
        math_logger=math_logger,
        math_section=math_section,
        model_options=ModelOptions(
            override_ionic_strength_cap=spec_params.ionic_strength_cap
        ),
    )
    if math_logger:
        math_logger.extend_lines(
            math_section,
            [
                f"Charge basis ({resolved_basis_label}) = {basis_m:.6f} M",
                "Open-system, fixed-pCO2 equilibrium enforced for reprocessing.",
            ],
        )
    return spec, max(spec.total_carbon_m, 0.0)


def _apply_measured_headspace(
    params: SolubilityInputs,
    measured_headspace_pco2_atm: Optional[float],
) -> SolubilityInputs:
    """Apply measured headspace.
    Used to apply measured headspace changes to live state."""
    if (
        measured_headspace_pco2_atm is None
        or not math.isfinite(measured_headspace_pco2_atm)
        or measured_headspace_pco2_atm <= 0
    ):
        return params
    kh_value = params.headspace_kh_m_per_atm
    if kh_value is None or not math.isfinite(kh_value) or kh_value <= 0:
        kh_value = 0.033
    return replace(
        params,
        headspace_pco2_atm=measured_headspace_pco2_atm,
        headspace_kh_m_per_atm=kh_value,
    )


def simulate_reprocessing_co2_demand(
    *,
    params: SolubilityInputs,
    initial_spec: SolubilitySpeciationResult,
    target_ph: Optional[float],
    math_logger: Optional[SolubilityMathLogger] = None,
    carbonates_to_neutralize_mol: Optional[float] = None,
    failing_ph: Optional[float] = None,
    measured_alk_meq: Optional[float] = None,
    measured_headspace_pco2_atm: Optional[float] = None,
    charge_basis_m: Optional[float] = None,
    basis_label: Optional[str] = None,
    constants: Optional[Tuple[float, float, float, List[str]]] = None,
    ph_tolerance: float = 1e-3,
) -> Dict[str, Any]:
    """Perform simulate reprocessing CO2 demand.
    Used to keep the workflow logic localized and testable."""

    volume = max(params.volume_l(), 1e-9)
    if target_ph is None or not math.isfinite(target_ph):
        return {
            "initial_ph": initial_spec.ph,
            "initial_total_carbon_m": initial_spec.total_carbon_m,
            "target_total_carbon_m": initial_spec.total_carbon_m,
            "added_co2_mol": carbonates_to_neutralize_mol or 0.0,
            "added_co2_g": (carbonates_to_neutralize_mol or 0.0) * SOL_MW_CO2,
            "target_ph": initial_spec.ph,
            "target_spec": initial_spec,
            "limit_reached": False,
            "target_ph_error": 0.0,
            "neutralize_mol": carbonates_to_neutralize_mol or 0.0,
            "polish_mol": 0.0,
        }

    basis_m, basis_origin = _reprocessing_charge_basis(params, measured_alk_meq)
    if basis_label:
        basis_origin = basis_label
    constants = (
        constants
        if constants is not None
        else _resolve_solubility_constants(
            params, math_logger=math_logger, section="Reprocessing equilibrium"
        )
    )

    carbonate_moles = max(
        (
            carbonates_to_neutralize_mol
            if carbonates_to_neutralize_mol is not None
            else initial_spec.moles.get("CO3^2-", 0.0)
        ),
        0.0,
    )
    neutralize_mol = carbonate_moles
    baseline_spec = initial_spec
    baseline_carbon = max(initial_spec.total_carbon_m, 0.0)
    initial_ph = (
        failing_ph
        if failing_ph is not None and math.isfinite(failing_ph)
        else initial_spec.ph
    )
    try:
        if initial_ph is not None and math.isfinite(initial_ph):
            baseline_spec, baseline_carbon = _reprocessing_speciation_from_ph(
                params,
                initial_ph,
                constants=constants,
                charge_basis_m=basis_m,
                measured_alk_meq=measured_alk_meq,
                math_logger=math_logger,
                math_section="Reprocessing baseline speciation",
                basis_label=basis_origin,
            )
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    if math_logger and neutralize_mol > 0:
        math_logger.log(
            "Reprocessing workflow",
            "Neutralize carbonate",
            f"CO2 needed = {neutralize_mol:.4f} mol",
            f"{neutralize_mol * SOL_MW_CO2:.2f}",
            units="g",
        )

    try:
        target_spec, target_carbon = _reprocessing_speciation_from_ph(
            params,
            target_ph,
            constants=constants,
            charge_basis_m=basis_m,
            measured_alk_meq=measured_alk_meq,
            math_logger=math_logger,
            math_section="Reprocessing target speciation",
            basis_label=basis_origin,
        )
    except Exception:
        target_spec = baseline_spec
        target_carbon = baseline_carbon

    delta_total = max(0.0, target_carbon - baseline_carbon)
    added_moles = max(delta_total * volume, neutralize_mol)
    polish_mol = max(0.0, added_moles - neutralize_mol)
    final_ph = (
        target_spec.ph
        if target_spec.ph is not None and math.isfinite(target_spec.ph)
        else target_ph
    )
    target_error = (final_ph - target_ph) if final_ph is not None else None
    limit_reached = (
        target_carbon <= 0.0
        or basis_m <= 0.0
        or (target_error is not None and abs(target_error) > ph_tolerance)
    )
    return {
        "initial_ph": initial_ph,
        "initial_total_carbon_m": baseline_carbon,
        "target_total_carbon_m": target_carbon,
        "added_co2_mol": added_moles,
        "added_co2_g": added_moles * SOL_MW_CO2,
        "target_ph": final_ph,
        "target_spec": target_spec,
        "limit_reached": limit_reached,
        "target_ph_error": target_error,
        "neutralize_mol": neutralize_mol,
        "polish_mol": polish_mol,
    }


def analyze_reprocessing_workflow(
    *,
    params: SolubilityInputs,
    result: SolubilitySpeciationResult,
    forced_result: Optional[SolubilitySpeciationResult],
    failing_ph: Optional[float],
    forced_ph: Optional[float],
    solvent_basis: Optional[str],
    solvent_basis_value: Optional[float],
    diagnostic_data: Optional[Dict[str, Any]] = None,
    math_logger: Optional[SolubilityMathLogger] = None,
    model_options: Optional[ModelOptions] = None,
    measured_headspace_pco2_atm: Optional[float] = None,
    measured_headspace_pressure_psi: Optional[float] = None,
) -> Optional[Dict[str, Any]]:
    """Analyze reprocessing workflow.
    Used to produce reprocessing workflow diagnostics or summaries."""
    if failing_ph is None:
        return None
    baseline_spec = result
    baseline_carbon = max(baseline_spec.total_carbon_m, 0.0)
    warnings: List[str] = []
    constants: Optional[Tuple[float, float, float, List[str]]] = None
    measured_alk_meq = None
    if diagnostic_data:
        measured_alk_meq = diagnostic_data.get("slurry_alk_meq_l")
    params = _apply_measured_headspace(params, measured_headspace_pco2_atm)
    basis_m, basis_label = _reprocessing_charge_basis(params, measured_alk_meq)
    try:
        constants = _resolve_solubility_constants(
            params, math_logger=math_logger, section="Reprocessing baseline"
        )
        baseline_spec, baseline_carbon = _reprocessing_speciation_from_ph(
            params,
            failing_ph,
            constants=constants,
            charge_basis_m=basis_m,
            measured_alk_meq=measured_alk_meq,
            math_logger=math_logger,
            math_section="Reprocessing baseline speciation",
            basis_label=basis_label,
        )
    except Exception as exc:
        warnings.append(
            f"Baseline speciation at failing pH fell back to the measured run: {exc}"
        )
        baseline_spec = result
        baseline_carbon = max(baseline_spec.total_carbon_m, 0.0)
    try:
        volume = max(params.volume_l(), 1e-9)
    except Exception:
        volume = max(params.solution_volume_l or 1e-9, 1e-9)
    current_total_mol = baseline_carbon * volume
    target_ph_value = (
        forced_ph
        if forced_ph is not None
        else (forced_result.ph if forced_result is not None else None)
    )
    carbonate_moles = max(baseline_spec.moles.get("CO3^2-", 0.0), 0.0)
    target_state = simulate_reprocessing_co2_demand(
        params=params,
        initial_spec=baseline_spec,
        target_ph=target_ph_value,
        math_logger=math_logger,
        carbonates_to_neutralize_mol=carbonate_moles,
        failing_ph=failing_ph,
        measured_alk_meq=measured_alk_meq,
        charge_basis_m=basis_m,
        basis_label=basis_label,
        constants=constants,
        measured_headspace_pco2_atm=measured_headspace_pco2_atm,
    )
    total_needed_mol = max(0.0, target_state.get("added_co2_mol", 0.0))
    total_needed_g = max(0.0, target_state.get("added_co2_g", 0.0))
    predicted_ph = target_state.get("target_ph") or result.ph
    target_total_mol = target_state.get("target_total_carbon_m", 0.0) * volume
    frac = baseline_spec.fractional_carbon
    hco3_pct = frac.get("HCO3-", 0.0) * 100.0
    co3_pct = frac.get("CO3^2-", 0.0) * 100.0
    h2co3_pct = frac.get("H2CO3", 0.0) * 100.0
    if solvent_basis == "water_mass" and solvent_basis_value is not None:
        solvent_summary = f"{solvent_basis_value:.1f} g water"
    elif solvent_basis == "solution_volume" and solvent_basis_value is not None:
        solvent_summary = f"{solvent_basis_value:.2f} L liquor"
    else:
        solvent_summary = f"{volume:.2f} L liquor"
    summary_lines = [
        f"{params.mass_na_hco3_g:.1f} g NaHCO3 in {solvent_summary}.",
        f"Failing slurry pH: {failing_ph:.2f}.",
        f"Speciation at failing pH: HCO3- {hco3_pct:.1f}%, CO3^2- {co3_pct:.1f}%, H2CO3 {h2co3_pct:.1f}%.",
        (
            f"CO2 needed for pH {target_ph_value:.2f}: {total_needed_g:.2f} g ({total_needed_mol:.4f} mol)."
            if target_ph_value is not None
            else f"CO2 delta: {total_needed_g:.2f} g ({total_needed_mol:.4f} mol)."
        ),
        f"Predicted pH after dosing: {predicted_ph:.2f}.",
    ]
    warnings.append("No NaOH basis; carbonate inferred from failing pH measurement.")
    warnings.append(f"Solvent basis assumed: {solvent_summary}.")
    if total_needed_g <= 0:
        warnings.append(
            "Current speciation already meets or exceeds the target pH; no extra CO2 required."
        )
    if target_state.get("limit_reached"):
        warnings.append(
            "Target pH may require more CO2 than the modeled inventory allows; treat the guidance as a minimum."
        )
    if forced_result is None:
        warnings.append("Slider preview unavailable; forced-pH result not computed.")
    notes: List[str] = []
    notes.append(
        f"Reprocessing charge basis: {basis_label} ({basis_m*1000:.2f} meq/L)."
    )
    measurement_note: Optional[str] = None
    if (
        measured_headspace_pressure_psi is not None
        and measured_headspace_pco2_atm is not None
    ):
        measurement_note = (
            f"Headspace measurement: {measured_headspace_pressure_psi:.2f} PSI "
            f"(~{measured_headspace_pco2_atm:.3f} atm pCO₂)."
        )
    elif measured_headspace_pco2_atm is not None:
        measurement_note = (
            f"Headspace pCO₂ anchored to {measured_headspace_pco2_atm:.3f} atm."
        )
    if measurement_note:
        notes.append(measurement_note)
    math_lines = [
        f"Total dissolved carbon (current) = {current_total_mol:.4f} mol",
        f"Total dissolved carbon (target) = {target_total_mol:.4f} mol",
        f"Additional CO2 needed = {total_needed_mol:.4f} mol ({total_needed_g:.2f} g)",
    ]
    if math_logger:
        math_logger.extend_lines("Reprocessing workflow", math_lines)
    neutralize_mol = max(target_state.get("neutralize_mol", carbonate_moles), 0.0)
    polish_mol = max(
        target_state.get("polish_mol", total_needed_mol - neutralize_mol), 0.0
    )
    measurement_point = {
        "label": "Reprocessing measurement",
        "ph": baseline_spec.ph,
        "co2_g": 0.0,
    }
    simulation_curve = [
        {"total_co2_g": 0.0, "ph": baseline_spec.ph},
        {"total_co2_g": total_needed_g, "ph": predicted_ph},
    ]
    slider_max_g = max(total_needed_g * 1.5, 1.0) if total_needed_g > 0 else 0.0
    return {
        "summary": "\n".join([line for line in summary_lines if line]),
        "warnings": warnings,
        "notes": notes,
        "math_lines": math_lines,
        "target_ph": target_ph_value,
        "recommended_co2_g": total_needed_g,
        "recommended_co2_mol": total_needed_mol,
        "predicted_ph_after": predicted_ph,
        "volume_l": volume,
        "solvent_basis": solvent_basis,
        "solvent_basis_value": solvent_basis_value,
        "failing_ph": failing_ph,
        "hco3_pct": hco3_pct,
        "co3_pct": co3_pct,
        "h2co3_pct": h2co3_pct,
        "measurement_point": measurement_point,
        "baseline_spec": baseline_spec,
        "baseline_carbon_m": baseline_carbon,
        "simulation_curve": simulation_curve if slider_max_g > 0 else [],
        "slider_max_g": slider_max_g,
        "delta_components": {
            "neutralize_mol": neutralize_mol,
            "polish_mol": polish_mol,
        },
        "target_spec": target_state.get("target_spec"),
        "dissolved_limit_moles": total_needed_mol,
        "limit_reached": target_state.get("limit_reached"),
        "target_ph_error": target_state.get("target_ph_error"),
    }


def format_solubility_summary(
    params: SolubilityInputs,
    result: SolubilitySpeciationResult,
    forced_result: Optional[SolubilitySpeciationResult] = None,
    forced_error: Optional[str] = None,
    sweep_summary: Optional[List[Dict[str, float]]] = None,
    sensitivity_rows: Optional[List[Dict[str, Any]]] = None,
    mode_context: Optional[Dict[str, str]] = None,
) -> str:
    """Format solubility summary.
    Used to prepare solubility summary for display or export."""
    volume = params.volume_l()
    lines = [
        "=== Advanced Sodium Bicarbonate Speciation ===",
        f"Mass NaHCO3          : {params.mass_na_hco3_g:.4f} g",
    ]
    if result.dissolved_mass_na_hco3_g is not None:
        lines.append(f"Dissolved NaHCO3      : {result.dissolved_mass_na_hco3_g:.4f} g")
    if result.undissolved_mass_na_hco3_g is not None:
        lines.append(
            f"Undissolved NaHCO3    : {result.undissolved_mass_na_hco3_g:.4f} g"
        )
    if mode_context:
        label = mode_context.get("label")
        if label:
            lines.append(f"Simulation basis     : {label}")
        starting = mode_context.get("starting")
        if starting:
            lines.append(f"Starting point       : {starting}")
        goal = mode_context.get("goal")
        if goal:
            lines.append(f"Solver goal          : {goal}")
        assumption = mode_context.get("assumption")
        if assumption:
            lines.append(f"Key assumption       : {assumption}")
        lines.append("")
    if params.water_mass_g is not None:
        lines.append(f"Water mass           : {params.water_mass_g:.4f} g")
    if params.solution_volume_l is not None:
        lines.append(f"User volume          : {params.solution_volume_l:.4f} L")
    if params.headspace_pco2_atm is not None:
        lines.append(f"Headspace CO2        : {params.headspace_pco2_atm:.2e} atm")
    temp_note = (
        "temperature-adjusted constants"
        if params.use_temperature_adjusted_constants
        else "constants fixed at 25 C"
    )
    lines.extend(
        [
            f"Resolved volume      : {volume:.6f} L",
            f"Temperature          : {params.temperature_c:.2f} deg C ({temp_note})",
            f"Initial pH guess     : {params.initial_ph_guess:.2f}",
            (
                f"Forced pH target     : {params.forced_ph_target:.2f}"
                if params.forced_ph_target is not None
                else "Forced pH target     : not specified"
            ),
            "",
        ]
    )

    def render_block(title: str, spec: SolubilitySpeciationResult) -> None:
        """Render block.
        Used to draw block for preview or export workflows."""
        lines.extend(
            [
                f"--- {title} ---",
                f"pH                   : {spec.ph:.4f}",
                f"Ionic strength (I)   : {spec.ionic_strength:.6e} M",
            ]
        )
        total_carbon = spec.total_carbon_m
        lines.append(
            "Total inorganic C    : "
            f"{total_carbon:.6e} mol/L (target {params.total_carbon_with_headspace():.6e} mol/L)"
        )
        lines.append(f"Alkalinity           : {spec.alkalinity_meq_per_l:.2f} meq/L")
        if spec.dissolved_fraction is not None:
            lines.append(
                "Dissolved fraction    : "
                f"{spec.dissolved_fraction*100:.2f}% of charged NaHCO3"
            )
        if spec.warnings:
            lines.append("Warnings             :")
            # Iterate over spec.warnings to apply the per-item logic.
            for warn in spec.warnings:
                lines.append(f"  - {warn}")
        lines.extend(
            [
                "",
                "Carbon speciation (% of inorganic C):",
            ]
        )
        # Iterate over ("H2CO3", "HCO3-", "CO3^2-") to apply the per-item logic.
        for species in ("H2CO3", "HCO3-", "CO3^2-"):
            frac = spec.fractional_carbon.get(species, 0.0) * 100.0
            lines.append(f"  {species:<6s}: {frac:6.2f}%")
        lines.extend(
            [
                "",
                "Species concentrations, mass loading, and moles:",
                f"{'Species':<10s}{'[C] / M':>16s}{'g/L':>12s}{'n / mol':>16s}{'gamma':>10s}",
                "-" * 66,
            ]
        )
        ordered = ["Na+", "H+", "HCO3-", "CO3^2-", "H2CO3", "OH-"]
        # Iterate over ordered to apply the per-item logic.
        for species in ordered:
            conc = spec.concentrations_m.get(species, 0.0)
            moles_val = spec.moles.get(species, 0.0)
            mass_g_l = spec.mass_concentrations_g_per_l.get(species, 0.0)
            gamma = spec.activity_coefficients.get(species, 1.0)
            lines.append(
                f"{species:<10s}{conc:>16.6e}{mass_g_l:>12.6e}{moles_val:>16.6e}{gamma:>10.4f}"
            )
        lines.extend(["", "Saturation indices (ionic product / Ksp):"])
        # Iterate over items from spec.saturation_indices to apply the per-item logic.
        for salt, ratio in spec.saturation_indices.items():
            flag = " > 1 (supersaturated)" if ratio > 1.0 else ""
            lines.append(f"{salt:<10s}{ratio:>16.6f}{flag}")
        left_charge = spec.concentrations_m["Na+"] + spec.concentrations_m["H+"]
        right_charge = (
            spec.concentrations_m["HCO3-"]
            + 2.0 * spec.concentrations_m["CO3^2-"]
            + spec.concentrations_m["OH-"]
        )
        lines.append(
            f"\nCharge balance residual : {left_charge - right_charge:+.3e} mol/L"
        )
        lines.append("")

    render_block("Equilibrium solution", result)

    if forced_result is not None:
        render_block(
            f"Speciation at user-specified pH ({forced_result.ph:.2f})",
            forced_result,
        )

    if forced_error:
        lines.extend(["", f"[warning] {forced_error}"])

    if sensitivity_rows:
        lines.extend(
            [
                "",
                "Sensitivity snapshots (perturb parameter → pH / Ionic Strength / Na2CO3 SI):",
            ]
        )
        # Iterate over sensitivity_rows to apply the per-item logic.
        for row in sensitivity_rows:
            lines.append(
                f"  {row['label']:<24s} : {row['ph']:>6} / {row['ionic_strength']:>10} / {row['na2co3_si']:>8}"
            )

    if sweep_summary:
        lines.extend(
            [
                "",
                "pH sweep (% HCO\u2083\u207b / % CO\u2083\u00b2\u207b / % H\u2082CO\u2083):",
            ]
        )
        # Iterate over sweep_summary to apply the per-item logic.
        for row in sweep_summary:
            lines.append(
                f"  pH {row['ph']:>4.2f} : {row['hco3_pct']:>6.2f}% / "
                f"{row['co3_pct']:>6.2f}% / {row['h2co3_pct']:>6.2f}%"
            )

    if result.assumptions:
        lines.extend(["", "Assumptions & notes:"])
        # Iterate over result.assumptions to apply the per-item logic.
        for note in result.assumptions:
            lines.append(f"  - {note}")

    return "\n".join(line.rstrip() for line in lines).rstrip()


def carbonate_pkw_from_temp(temp_c: float) -> float:
    """Perform carbonate pkw from temp.
    Used to keep the workflow logic localized and testable."""

    a, b, c = (20.795999999999985, -0.0639999999999997, 0.00031999999999999987)
    return a + b * temp_c + c * (temp_c**2)


def compute_carbonate_contamination(inputs: CarbonateInputs) -> CarbonateResults:
    """Compute carbonate contamination.
    Used to derive carbonate contamination for analysis or plotting."""

    mw_naoh = 39.997  # g/mol
    mw_na2co3 = 105.9888  # g/mol

    eff_mass_naoh = inputs.mass_naoh_g * (inputs.purity_wt_percent / 100.0)
    sodium_moles = eff_mass_naoh / mw_naoh

    pellet_na2co3_mass = 0.0
    pellet_na2co3_moles = 0.0
    if inputs.naoh_carbonate_wt_percent is not None:
        pellet_na2co3_mass = inputs.mass_naoh_g * (
            inputs.naoh_carbonate_wt_percent / 100.0
        )
        pellet_na2co3_moles = pellet_na2co3_mass / mw_na2co3

    ratio = 10.0 ** (inputs.ph - inputs.pka2)

    pkw = carbonate_pkw_from_temp(inputs.temp_c)
    h_conc = 10.0 ** (-inputs.ph)
    oh_conc = 10.0 ** (-(pkw - inputs.ph))

    hydrogen_moles = h_conc * inputs.final_volume_l
    hydroxide_moles = oh_conc * inputs.final_volume_l

    bicarbonate_moles = (sodium_moles + hydrogen_moles - hydroxide_moles) / (
        1.0 + 2.0 * ratio
    )
    carbonate_moles = ratio * bicarbonate_moles

    sodium_bicarbonate_moles = bicarbonate_moles
    sodium_carbonate_moles = carbonate_moles
    sodium_carbonate_mass = sodium_carbonate_moles * mw_na2co3

    return CarbonateResults(
        sodium_moles=sodium_moles,
        ratio=ratio,
        hydrogen_moles=hydrogen_moles,
        hydroxide_moles=hydroxide_moles,
        bicarbonate_moles=bicarbonate_moles,
        carbonate_moles=carbonate_moles,
        sodium_bicarbonate_moles=sodium_bicarbonate_moles,
        sodium_carbonate_moles=sodium_carbonate_moles,
        sodium_carbonate_mass_g=sodium_carbonate_mass,
        pellet_sodium_carbonate_moles=pellet_na2co3_moles,
        pellet_sodium_carbonate_mass_g=pellet_na2co3_mass,
    )


def _carbonate_speciation_at_fixed_ph(
    inputs: CarbonateInputs,
    pka2: float,
    sodium_moles_dissolved: float,
    ph_value: float,
):
    """Perform carbonate speciation at fixed pH.
    Used to keep the workflow logic localized and testable."""

    ratio = 10.0 ** (ph_value - pka2)
    pkw = carbonate_pkw_from_temp(inputs.temp_c)
    hydrogen_conc = 10.0 ** (-ph_value)
    hydroxide_conc = 10.0 ** (-(pkw - ph_value))

    hydrogen_moles = hydrogen_conc * inputs.final_volume_l
    hydroxide_moles = hydroxide_conc * inputs.final_volume_l

    denominator = 1.0 + 2.0 * ratio
    bicarbonate_moles = (
        sodium_moles_dissolved + hydrogen_moles - hydroxide_moles
    ) / denominator
    carbonate_moles = ratio * bicarbonate_moles

    return bicarbonate_moles, carbonate_moles, hydrogen_moles, hydroxide_moles


def compute_carbonate_contamination_augmented(
    inputs: CarbonateInputs, options: CarbonateEquilibriumOptions
) -> CarbonateAugmentedResults:
    """Compute carbonate contamination augmented.
    Used to derive carbonate contamination augmented for analysis or plotting."""

    baseline = compute_carbonate_contamination(inputs)

    mw_na2co3 = 105.9888  # g/mol
    mw_nahco3 = 84.0066  # g/mol

    ph_effective = options.slurry_ph if options.slurry_ph is not None else inputs.ph

    sodium_total = baseline.sodium_moles
    sodium_dissolved = sodium_total

    (
        bicarbonate_aq,
        carbonate_aq,
        _,
        _,
    ) = _carbonate_speciation_at_fixed_ph(
        inputs, inputs.pka2, sodium_dissolved, ph_effective
    )

    sodium_bicarbonate_solid = 0.0
    sodium_carbonate_solid = 0.0

    # Iterate over the configured range to apply the per-item logic.
    for iteration in range(1, options.max_iter + 1):
        precip_hco3 = 0.0
        precip_co3 = 0.0

        if options.s_hco3_max_m is not None:
            cap_hco3 = options.s_hco3_max_m * inputs.final_volume_l
            if bicarbonate_aq > cap_hco3:
                precip_hco3 = bicarbonate_aq - cap_hco3
                bicarbonate_aq = cap_hco3

        if options.s_co3_max_m is not None:
            cap_co3 = options.s_co3_max_m * inputs.final_volume_l
            if carbonate_aq > cap_co3:
                precip_co3 = carbonate_aq - cap_co3
                carbonate_aq = cap_co3

        sodium_removed = precip_hco3 + 2.0 * precip_co3
        if sodium_removed < options.tol_mol:
            iterations = iteration
            break

        sodium_bicarbonate_solid += precip_hco3
        sodium_carbonate_solid += precip_co3
        sodium_dissolved = max(sodium_dissolved - sodium_removed, 0.0)

        (
            bicarbonate_aq,
            carbonate_aq,
            _,
            _,
        ) = _carbonate_speciation_at_fixed_ph(
            inputs, inputs.pka2, sodium_dissolved, ph_effective
        )
    else:
        iterations = options.max_iter

    sodium_bicarbonate_solid_mass = sodium_bicarbonate_solid * mw_nahco3
    sodium_carbonate_solid_mass = sodium_carbonate_solid * mw_na2co3
    solid_total_mass = sodium_bicarbonate_solid_mass + sodium_carbonate_solid_mass
    solid_naco3_fraction = (
        sodium_carbonate_solid_mass / solid_total_mass if solid_total_mass > 0 else 0.0
    )

    if inputs.final_volume_l > 0:
        ratio_hco3_co2 = 10.0 ** (ph_effective - options.pka1)
        if ratio_hco3_co2 > 0:
            co2_conc = (bicarbonate_aq / inputs.final_volume_l) / ratio_hco3_co2
            co2star_moles = co2_conc * inputs.final_volume_l
        else:
            co2star_moles = 0.0
    else:
        co2star_moles = 0.0

    dic_moles = co2star_moles + bicarbonate_aq + carbonate_aq

    co2star_henry = None
    co2star_ratio = None
    if options.pco2_atm is not None and inputs.final_volume_l > 0:
        effective_kh = max(options.kh_co2_m_per_atm, 0.0)
        effective_pco2 = max(options.pco2_atm, 0.0)
        co2star_henry = effective_kh * effective_pco2 * inputs.final_volume_l
        if co2star_henry > 0.0:
            co2star_ratio = co2star_moles / co2star_henry

    return CarbonateAugmentedResults(
        baseline=baseline,
        co2star_moles=co2star_moles,
        dic_moles=dic_moles,
        co2star_henry_moles=co2star_henry,
        co2star_consistency_ratio=co2star_ratio,
        iterations=iterations,
        sodium_dissolved_moles=sodium_dissolved,
        bicarbonate_aqueous_moles=bicarbonate_aq,
        carbonate_aqueous_moles=carbonate_aq,
        sodium_bicarbonate_solid_moles=sodium_bicarbonate_solid,
        sodium_carbonate_solid_moles=sodium_carbonate_solid,
        sodium_bicarbonate_solid_mass_g=sodium_bicarbonate_solid_mass,
        sodium_carbonate_solid_mass_g=sodium_carbonate_solid_mass,
        solid_total_mass_g=solid_total_mass,
        solid_sodium_carbonate_mass_fraction=solid_naco3_fraction,
    )


def carbonate_literature_caps_stp() -> CarbonateEquilibriumOptions:
    """Perform carbonate literature caps stp.
    Used to keep the workflow logic localized and testable."""

    return CarbonateEquilibriumOptions(s_hco3_max_m=1.10, s_co3_max_m=2.00)


def _normalize_cached_cycle_markers(data):
    """Normalize cached cycle markers.
    Used to keep cached cycle markers consistent across workflows and persistence."""
    if not isinstance(data, dict):
        return None
    try:
        file_path = str(data.get("file", "")).strip()
        sheet = str(data.get("sheet", "")).strip()
        columns = data.get("columns") or {}
        x_col = columns.get("x")
        y1_col = columns.get("y1")
        data_len = int(data.get("data_len", -1))
        mask_true = data.get("mask_true")
        mask_true = int(mask_true) if mask_true is not None else None
        peaks = [int(p) for p in data.get("peaks", [])]
        troughs = [int(t) for t in data.get("troughs", [])]
        params = data.get("peak_params") or {}
        peak_prominence = float(params.get("prominence", 0.0))
        peak_distance = int(params.get("distance", 1))
        peak_width = int(params.get("width", 1))
        min_cycle_drop = float(data.get("min_cycle_drop", 0.0))
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None

    return {
        "file": file_path,
        "sheet": sheet,
        "columns": {"x": x_col, "y1": y1_col},
        "data_len": data_len,
        "mask_true": mask_true,
        "peaks": peaks,
        "troughs": troughs,
        "peak_params": {
            "prominence": peak_prominence,
            "distance": peak_distance,
            "width": peak_width,
        },
        "min_cycle_drop": min_cycle_drop,
        "timestamp": float(data.get("timestamp", 0.0)),
    }


def _fallback_find_peaks(
    values,
    *,
    prominence: float = 0.0,
    distance: int = 1,
    width: int = 1,
):
    """Perform fallback find peaks.
    Used to keep the workflow logic localized and testable."""

    arr = np.asarray(values, dtype=float)

    if arr.size == 0:

        return np.array([], dtype=int), {}

    prom = max(float(prominence), 0.0)

    dist = max(int(distance), 1)

    def _coerce_min_width(value):
        """Coerce min width.
        Used to force min width into a safe type or range."""

        try:

            if isinstance(value, (tuple, list)):

                if len(value) == 0:

                    return 1

                candidate = float(value[0])

            elif isinstance(value, np.ndarray):

                if value.size == 0:

                    return 1

                candidate = float(value.flat[0])

            else:

                candidate = float(value)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return 1

        if not math.isfinite(candidate):

            return 1

        return max(int(math.ceil(candidate)), 1)

    min_width = _coerce_min_width(width)

    peaks = []

    widths = []

    last_idx = -dist

    n = arr.size

    # Iterate over the configured range to apply the per-item logic.
    for idx in range(1, n - 1):

        if idx - last_idx < dist:

            continue

        center = arr[idx]

        left = arr[idx - 1]

        right = arr[idx + 1]

        if not (np.isfinite(center) and np.isfinite(left) and np.isfinite(right)):

            continue

        if center >= left and center >= right:

            local_prom = center - min(left, right)

            if local_prom + 1e-12 >= prom:  # tolerate minor FP error

                est_width = 1

                if min_width > 1:

                    half_level = center - max(local_prom, 0.0) / 2.0

                    left_idx = idx

                    # Repeat while left_idx > 0 and arr[left_idx - 1] >= half_level to advance the looped workflow.
                    while left_idx > 0 and arr[left_idx - 1] >= half_level:

                        left_idx -= 1

                    right_idx = idx

                    # Repeat while right_idx < n - 1 and arr[right_idx + 1] >= half_level to advance the looped workflow.
                    while right_idx < n - 1 and arr[right_idx + 1] >= half_level:

                        right_idx += 1

                    est_width = right_idx - left_idx + 1

                if est_width >= min_width:

                    peaks.append(idx)

                    widths.append(est_width)

                    last_idx = idx

    props = {}

    if widths:

        props["widths"] = np.asarray(widths, dtype=float)

    return np.array(peaks, dtype=int), props


_FALLBACK_FIND_PEAKS = None if find_peaks is not None else _fallback_find_peaks


def _scipy_missing_message(feature: str) -> str:
    """Perform scipy missing message.
    Used to keep the workflow logic localized and testable."""

    base = (
        f"SciPy is required for {feature}, but it could not be imported.\n"
        "Install SciPy with 'pip install scipy' and restart the application for the "
        "most accurate results."
    )

    if _FALLBACK_FIND_PEAKS is not None:

        base += (
            "\n\nThe app will fall back to a basic built-in peak detection so you can still "
            "continue working, but installing SciPy is highly recommended."
        )

    if _SCIPY_IMPORT_ERROR is not None:

        base += f"\n\nImport error: {_SCIPY_IMPORT_ERROR}"

    return base


_SCIPY_WARNED_FEATURES = set()


def _warn_missing_scipy(feature: str, *, parent=None, kind: str = "warning") -> None:
    """Perform warn missing scipy.
    Used to keep the workflow logic localized and testable."""

    key = feature.lower()

    if key in _SCIPY_WARNED_FEATURES:

        return

    _SCIPY_WARNED_FEATURES.add(key)

    msg = _scipy_missing_message(feature)

    if parent is None:

        try:

            if kind == "error":

                messagebox.showerror("SciPy Required", msg)

            else:

                messagebox.showwarning("SciPy Required", msg)

        except Exception:

            print(msg, file=sys.stderr)

        return

    try:

        if kind == "error":

            messagebox.showerror("SciPy Required", msg, parent=parent)

        else:

            messagebox.showwarning("SciPy Required", msg, parent=parent)

    except Exception:

        print(msg, file=sys.stderr)


def _make_legend_draggable(
    legend,
    enabled: bool = True,
    *,
    update_mode: str = "loc",
):
    """Set legend draggability through one normalized helper path.

    Purpose:
        Enable or disable drag behavior for a Matplotlib legend artist.
    Why:
        Centralizing drag-state wiring keeps legend behavior consistent across
        combined and non-combined plot builders.

    Args:
        legend: Matplotlib Legend to update. None is accepted and ignored.
        enabled: True to enable drag, False to disable drag.
        update_mode: Matplotlib drag update mode ("loc" or "bbox") used when
            enabling drag. Invalid values fall back to "loc".

    Returns:
        The original legend reference, or None when legend is None.

    Side Effects:
        Calls legend.set_draggable(...) and may create or disconnect internal
        Matplotlib drag callbacks on the legend's canvas.

    Exceptions:
        Errors are swallowed to avoid interrupting UI workflows.
    """
    if legend is None:
        return legend
    if update_mode not in {"loc", "bbox"}:
        update_mode = "loc"
    try:
        if enabled:
            try:
                legend.set_draggable(True, update=update_mode)
            except TypeError:
                # Matplotlib variants that do not expose the update kwarg.
                legend.set_draggable(True)
        else:
            legend.set_draggable(False)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    return legend


def _legend_shadowbox_kwargs() -> Dict[str, Any]:
    """Perform legend shadowbox kwargs.
    Used to keep the workflow logic localized and testable."""
    fill_color_default = "#FFFFFF"
    fill_color = fill_color_default
    try:
        settings_map = globals().get("settings", {})
        raw_value = None
        if isinstance(settings_map, dict):
            raw_value = settings_map.get("combined_legend_shadowbox_fill_color")
        try:
            from matplotlib.colors import to_rgba  # type: ignore

            candidate = str(raw_value or "").strip()
            if candidate:
                to_rgba(candidate)
                fill_color = candidate
        except Exception:
            fill_color = fill_color_default
    except Exception:
        fill_color = fill_color_default
    return {
        "frameon": True,
        "facecolor": fill_color,
        "edgecolor": "#444",
        "fancybox": True,
        "shadow": True,
        "framealpha": 0.9,
    }


# Common style

subplottitle_fontsize = 16

label_fontsize = 13

suptitle_fontsize = 18

suptitle_yposition = 0.975

tick_labelsize = 12

yaxis_labelpad_amount = 3

twinyaxis_labelpad_amount = 15

xaxis_labelpad_amount = 5

linewidth_thickness = 0.75

plot_linestyle = "-"

plot_marker = ","

plot_markersize = 0.75


DEFAULT_COMBINED_LEGEND_GAP_PTS = 18.0
DEFAULT_COMBINED_LEGEND_MARGIN_PTS = 8.0
DEFAULT_LEGEND_SHADOWBOX_FILL_COLOR = "#FFFFFF"
MIN_COMBINED_LEGEND_GAP_PTS = 6.0
MAX_COMBINED_LEGEND_GAP_PTS = 120.0
MIN_COMBINED_LEGEND_MARGIN_PTS = 2.0
MAX_COMBINED_LEGEND_MARGIN_PTS = 72.0
DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS = 10.0
MIN_COMBINED_XLABEL_TICK_GAP_PTS = 0.0
MAX_COMBINED_XLABEL_TICK_GAP_PTS = 50.0
DEFAULT_COMBINED_EXPORT_PAD_PTS = 6.0
MIN_COMBINED_EXPORT_PAD_PTS = 0.0
MAX_COMBINED_EXPORT_PAD_PTS = 36.0
DEFAULT_COMBINED_LEFT_PAD_PCT = 1.0
DEFAULT_COMBINED_RIGHT_PAD_PCT = 6.0
MIN_COMBINED_SIDE_PAD_PCT = 0.0
MAX_COMBINED_SIDE_PAD_PCT = 35.0
DEFAULT_COMBINED_TITLE_PAD_PTS = 6.0
DEFAULT_COMBINED_SUPTITLE_PAD_PTS = 0.0
DEFAULT_COMBINED_SUPTITLE_Y = 0.975
DEFAULT_COMBINED_TOP_MARGIN_PCT = 8.0
MIN_COMBINED_TITLE_PAD_PTS = 0.0
MAX_COMBINED_TITLE_PAD_PTS = 120.0
MIN_COMBINED_SUPTITLE_PAD_PTS = -40.0
MAX_COMBINED_SUPTITLE_PAD_PTS = 120.0
MIN_COMBINED_SUPTITLE_Y = 0.6
MAX_COMBINED_SUPTITLE_Y = 1.05
MIN_COMBINED_TOP_MARGIN_PCT = 0.0
MAX_COMBINED_TOP_MARGIN_PCT = 28.0
DEFAULT_COMBINED_SUPTITLE_FONTSIZE = 18.0
DEFAULT_COMBINED_TITLE_FONTSIZE = 16.0
DEFAULT_COMBINED_LABEL_FONTSIZE = 13.0
DEFAULT_COMBINED_TICK_FONTSIZE = 12.0
DEFAULT_COMBINED_LEGEND_FONTSIZE = 12.0
MIN_COMBINED_FONT_SIZE = 6.0
MAX_COMBINED_FONT_SIZE = 48.0
DEFAULT_COMBINED_FONT_FAMILY = _PREFERRED_PLOT_FONT
COMBINED_CYCLE_REF_AXIS_CHOICES = ("main", "right", "deriv")
COMBINED_CYCLE_REF_CORNER_CHOICES = (
    "upper right",
    "upper left",
    "lower right",
    "lower left",
    "center",
)


DEFAULT_AXIS_AUTO_RANGE = {
    "time": True,
    "pressure": True,
    "temperature": True,
    "derivative": True,
}


def _sanitize_axis_auto_range_settings(value):
    """Sanitize axis auto range settings.
    Used to strip or normalize axis auto range settings before use."""
    merged = dict(DEFAULT_AXIS_AUTO_RANGE)
    if isinstance(value, dict):
        # Iterate over merged to apply the per-item logic.
        for key in merged:
            raw = value.get(key)
            if isinstance(raw, bool):
                merged[key] = raw
                continue
            if isinstance(raw, str):
                lowered = raw.strip().lower()
                if lowered in ("true", "1", "yes", "on"):
                    merged[key] = True
                    continue
                if lowered in ("false", "0", "no", "off"):
                    merged[key] = False
                    continue
            try:
                merged[key] = bool(int(raw))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
    return merged


def _sanitize_spacing_value(
    value: Optional[float],
    default: float,
    minimum: float,
    maximum: float,
) -> float:
    """Sanitize spacing value.
    Used to strip or normalize spacing value before use."""
    try:
        parsed = float(value)
    except (TypeError, ValueError):
        parsed = default
    return max(minimum, min(parsed, maximum))


def _legacy_panel_height_to_spacing(
    panel_height: Optional[float],
) -> Tuple[float, float]:
    """Perform legacy panel height to spacing.
    Used to keep the workflow logic localized and testable."""

    try:
        fraction = float(panel_height)
    except (TypeError, ValueError):
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return (DEFAULT_COMBINED_LEGEND_GAP_PTS, DEFAULT_COMBINED_LEGEND_MARGIN_PTS)
    clamped = max(0.05, min(fraction, 0.25))
    total_points = clamped * 8.5 * 72.0
    gap = max(DEFAULT_COMBINED_LEGEND_GAP_PTS, total_points * 0.55)
    margin = max(DEFAULT_COMBINED_LEGEND_MARGIN_PTS, total_points * 0.25)
    return (gap, margin)


DEFAULT_SCATTER_SETTINGS = {
    "enabled": False,
    "marker": "o",
    "size": 20.0,
    "color": "",
    "alpha": 1.0,
    "edgecolor": "",
    "linewidth": 0.0,
    "linestyle": "",
}

scatter_config = dict(DEFAULT_SCATTER_SETTINGS)
SCATTER_SERIES_KEYS = ("y1", "y3", "y2", "z", "z2")
scatter_series_configs = {}

DEFAULT_CYCLE_TRACE_SETTINGS = {
    "line_color": "#1f77b4",
    "line_style": "solid",
    "line_width": 0.8,
    "peak_color": "#2ca02c",
    "trough_color": "#d62728",
    "peak_marker": "^",
    "trough_marker": "v",
    "marker_size": 28.0,
}
cycle_trace_settings = dict(DEFAULT_CYCLE_TRACE_SETTINGS)


SCATTER_MARKER_CHOICES = [
    "o",
    "s",
    "D",
    "^",
    "v",
    "<",
    ">",
    "x",
    "+",
    ".",
    "*",
    "p",
    "h",
]

DATA_TRACE_ZORDER_PRIORITY = OrderedDict(
    [
        ("Background", 1.0),
        ("Normal", 2.0),
        ("Foreground", 3.0),
        ("Hero", 5.0),
    ]
)
DATA_TRACE_ZORDER_CHOICES = ["Inherit"] + list(DATA_TRACE_ZORDER_PRIORITY.keys())
CYCLE_MARKER_MIN_ZORDER = 10.0
CYCLE_MARKER_ZORDER_PAD = 1.0


def _compute_top_overlay_zorder(
    ax: Axes,
    *,
    min_z: float = CYCLE_MARKER_MIN_ZORDER,
    pad: float = CYCLE_MARKER_ZORDER_PAD,
) -> float:
    """Compute a guaranteed top-layer zorder for cycle marker overlays.

    Purpose:
        Resolve a safe zorder that keeps cycle peak/trough markers above all
        existing artists on an axes.
    Why:
        Per-trace zorder overrides can raise data traces above fixed marker
        zorders, so overlays need a dynamic top-of-stack value.
    Args:
        ax: Target Matplotlib axes that will receive cycle markers.
        min_z: Minimum floor zorder applied when axes artists are sparse.
        pad: Positive spacing added above the current maximum axes zorder.
    Returns:
        Float zorder value for cycle marker overlays.
    Side Effects:
        None.
    Exceptions:
        None. Non-finite artist zorders are ignored.
    """
    max_zorder = None
    # Scan existing artists so overlays sit above any trace priority/override mix.
    for artist in ax.get_children():
        getter = getattr(artist, "get_zorder", None)
        if not callable(getter):
            continue
        try:
            z_value = float(getter())
        except (TypeError, ValueError):
            continue
        if not math.isfinite(z_value):
            continue
        max_zorder = z_value if max_zorder is None else max(max_zorder, z_value)

    try:
        min_floor = float(min_z)
    except (TypeError, ValueError):
        min_floor = float(CYCLE_MARKER_MIN_ZORDER)
    if not math.isfinite(min_floor):
        min_floor = float(CYCLE_MARKER_MIN_ZORDER)

    try:
        pad_value = float(pad)
    except (TypeError, ValueError):
        pad_value = float(CYCLE_MARKER_ZORDER_PAD)
    if not math.isfinite(pad_value) or pad_value < 0.0:
        pad_value = float(CYCLE_MARKER_ZORDER_PAD)

    if max_zorder is None:
        return min_floor
    return max(min_floor, float(max_zorder + pad_value))


def _ensure_combined_derivative_zero_line(
    fig: Optional[Figure],
    ax_overlay: Optional[Axes],
    ax_deriv: Optional[Axes],
    *,
    visible: bool,
    zorder: float = 6.0,
) -> Optional[Line2D]:
    """Ensure the Combined derivative y=0 dashed line lives on the overlay axis.

    Purpose:
        Create or update the Combined derivative reference line at y=0.
    Why:
        X-span artists can target different data axes, so artist z-order alone
        cannot guarantee that the derivative zero-line stays above spans. Keeping
        the line on the dedicated overlay axis makes the layering deterministic.
    Inputs:
        fig: Combined figure storing the cached zero-line handle.
        ax_overlay: Combined overlay axis used for top-layer reference artists.
        ax_deriv: Active derivative axis that defines y-data coordinates.
        visible: Whether the zero-line should be shown for this render pass.
        zorder: Artist z-order for the zero-line on the overlay axis.
    Outputs:
        The zero-line artist when available; otherwise None.
    Side Effects:
        Creates/removes/reuses a Line2D artist and stores it on
        `fig._gl260_combined_deriv_zero_line`.
    Exceptions:
        Best-effort behavior; invalid artists or transforms are ignored.
    """
    if fig is None:
        return None
    existing = getattr(fig, "_gl260_combined_deriv_zero_line", None)
    line = existing if isinstance(existing, Line2D) else None
    if ax_overlay is None:
        if line is not None:
            try:
                line.set_visible(False)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        return line
    if line is not None and getattr(line, "axes", None) is not ax_overlay:
        try:
            line.remove()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        line = None
    if line is None:
        try:
            line = Line2D(
                [0.0, 1.0],
                [0.0, 0.0],
                color="black",
                linestyle="--",
                linewidth=1.0,
                zorder=float(zorder),
            )
            ax_overlay.add_line(line)
            fig._gl260_combined_deriv_zero_line = line  # type: ignore[attr-defined]
        except Exception:
            return None
    y_axis = ax_deriv if ax_deriv is not None else ax_overlay
    try:
        line.set_transform(
            blended_transform_factory(ax_overlay.transAxes, y_axis.transData)
        )
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    try:
        line.set_data([0.0, 1.0], [0.0, 0.0])
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    try:
        line.set_zorder(float(zorder))
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    try:
        line.set_visible(bool(visible and ax_deriv is not None))
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    return line


LINE_STYLE_MAP = OrderedDict(
    [
        ("solid", "solid"),
        ("dashed", "dashed"),
        ("dashdot", "dashdot"),
        ("dotted", "dotted"),
        ("loosely dotted", (0, (1, 10))),
        ("dotted (spacing 5)", (0, (1, 5))),
        ("densely dotted", (0, (1, 1))),
        ("long dash with offset", (5, (10, 3))),
        ("loosely dashed", (0, (5, 10))),
        ("dashed (equal gaps)", (0, (5, 5))),
        ("densely dashed", (0, (5, 1))),
        ("loosely dashdotted", (0, (3, 10, 1, 10))),
        ("dashdotted (equal pattern)", (0, (3, 5, 1, 5))),
        ("densely dashdotted", (0, (3, 1, 1, 1))),
        ("dashdotdotted", (0, (3, 5, 1, 5, 1, 5))),
        ("loosely dashdotdotted", (0, (3, 10, 1, 10, 1, 10))),
        ("densely dashdotdotted", (0, (3, 1, 1, 1, 1, 1))),
        ("None", "None"),
    ]
)

LINE_STYLE_CHOICES = ["Default"] + list(LINE_STYLE_MAP.keys())

_LINESTYLE_ALIAS_MAP = {
    "": "",
    "default": "",
    "-": "solid",
    "--": "dashed",
    "-.": "dashdot",
    ":": "dotted",
    "none": "None",
    "null": "None",
    " ": "None",
    "solid": "solid",
    "dashed": "dashed",
    "dashdot": "dashdot",
    "dotted": "dotted",
    "loosely dotted": "loosely dotted",
    "dotted (spacing 5)": "dotted (spacing 5)",
    "densely dotted": "densely dotted",
    "long dash with offset": "long dash with offset",
    "loosely dashed": "loosely dashed",
    "dashed (equal gaps)": "dashed (equal gaps)",
    "densely dashed": "densely dashed",
    "loosely dashdotted": "loosely dashdotted",
    "dashdotted": "dashdotted (equal pattern)",
    "dashdotted (equal pattern)": "dashdotted (equal pattern)",
    "densely dashdotted": "densely dashdotted",
    "dashdotdotted": "dashdotdotted",
    "loosely dashdotdotted": "loosely dashdotdotted",
    "densely dashdotdotted": "densely dashdotdotted",
}


def _normalize_dash_pattern(value):
    """Normalize dash pattern.
    Used to keep dash pattern consistent across workflows and persistence."""
    if isinstance(value, (list, tuple)):
        return tuple(_normalize_dash_pattern(item) for item in value)
    return value


def _canonicalize_linestyle_name(value):
    """Perform canonicalize linestyle name.
    Used to keep the workflow logic localized and testable."""
    if value is None:
        return ""
    if isinstance(value, list):
        value = _normalize_dash_pattern(value)
    if isinstance(value, tuple):
        value = _normalize_dash_pattern(value)
        # Iterate over items from LINE_STYLE_MAP to apply the per-item logic.
        for label, pattern in LINE_STYLE_MAP.items():
            if isinstance(pattern, tuple) and _normalize_dash_pattern(pattern) == value:
                return label
        return ""
    value_str = str(value).strip()
    if not value_str:
        return ""
    lookup = _LINESTYLE_ALIAS_MAP.get(value_str.lower())
    if lookup is not None:
        return lookup
    # Iterate over keys from LINE_STYLE_MAP to apply the per-item logic.
    for label in LINE_STYLE_MAP.keys():
        if value_str.lower() == label.lower():
            return label
    return value_str


def _resolve_linestyle_value(label):
    """Resolve linestyle value.
    Used to compute linestyle value before rendering or export."""
    if not label:
        return ""
    if label not in LINE_STYLE_MAP:
        return label
    return LINE_STYLE_MAP[label]


def _normalize_color(value, default):
    """Normalize color.
    Used to keep color consistent across workflows and persistence."""
    candidate = (value or "").strip()
    if not candidate:
        return default
    try:
        from matplotlib.colors import to_rgba  # type: ignore

        to_rgba(candidate)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return default
    return candidate


def get_cycle_trace_style():
    """Return cycle trace style.
    Used to retrieve cycle trace style for downstream logic."""
    style = dict(DEFAULT_CYCLE_TRACE_SETTINGS)
    style.update(dict(cycle_trace_settings))

    line_style_label = _canonicalize_linestyle_name(style.get("line_style"))
    if not line_style_label:
        line_style_label = DEFAULT_CYCLE_TRACE_SETTINGS["line_style"]
    resolved_linestyle = _resolve_linestyle_value(line_style_label)
    if not resolved_linestyle:
        resolved_linestyle = _resolve_linestyle_value(
            DEFAULT_CYCLE_TRACE_SETTINGS["line_style"]
        )

    try:
        line_width = float(style.get("line_width"))
    except Exception:
        line_width = DEFAULT_CYCLE_TRACE_SETTINGS["line_width"]
    if not (math.isfinite(line_width) and line_width > 0.0):
        line_width = DEFAULT_CYCLE_TRACE_SETTINGS["line_width"]

    try:
        marker_size = float(style.get("marker_size"))
    except Exception:
        marker_size = DEFAULT_CYCLE_TRACE_SETTINGS["marker_size"]
    if not (math.isfinite(marker_size) and marker_size > 0.0):
        marker_size = DEFAULT_CYCLE_TRACE_SETTINGS["marker_size"]

    # Closure captures get_cycle_trace_style local context to keep helper logic scoped and invoked directly within get_cycle_trace_style.
    def _normalize_marker(value: Any, default: str) -> str:
        """Normalize marker.
        Used to keep marker consistent across workflows and persistence."""
        if not isinstance(value, str):
            return default
        candidate = value.strip()
        if not candidate:
            return default
        if candidate not in SCATTER_MARKER_CHOICES and len(candidate) > 1:
            return default
        return candidate

    peak_marker = _normalize_marker(
        style.get("peak_marker"), DEFAULT_CYCLE_TRACE_SETTINGS["peak_marker"]
    )
    trough_marker = _normalize_marker(
        style.get("trough_marker"), DEFAULT_CYCLE_TRACE_SETTINGS["trough_marker"]
    )

    style["line_style"] = line_style_label
    style["resolved_linestyle"] = resolved_linestyle
    style["line_width"] = line_width
    style["marker_size"] = marker_size
    style["peak_marker"] = peak_marker
    style["trough_marker"] = trough_marker
    style["line_color"] = _normalize_color(
        style.get("line_color"), DEFAULT_CYCLE_TRACE_SETTINGS["line_color"]
    )
    style["peak_color"] = _normalize_color(
        style.get("peak_color"), DEFAULT_CYCLE_TRACE_SETTINGS["peak_color"]
    )
    style["trough_color"] = _normalize_color(
        style.get("trough_color"), DEFAULT_CYCLE_TRACE_SETTINGS["trough_color"]
    )
    return style


def _get_scatter_config(
    series_key=None,
    *,
    scatter_config: Optional[Dict[str, Any]] = None,
    scatter_series_configs: Optional[Dict[str, Any]] = None,
):
    """Return scatter config.
    Used to retrieve scatter config for downstream logic."""
    cfg = scatter_config if isinstance(scatter_config, dict) else globals().get(
        "scatter_config"
    )
    merged = dict(DEFAULT_SCATTER_SETTINGS)
    overrides = {key: False for key in DEFAULT_SCATTER_SETTINGS}
    if isinstance(cfg, dict):
        # Iterate over merged to apply the per-item logic.
        for key in merged:
            if key in cfg:
                if key == "linestyle":
                    canonical = _canonicalize_linestyle_name(cfg[key])
                    merged[key] = canonical
                    if canonical:
                        overrides[key] = True
                    continue
                merged[key] = cfg[key]
                if cfg[key] != DEFAULT_SCATTER_SETTINGS.get(key):
                    overrides[key] = True

    if series_key:
        series_cfgs = (
            scatter_series_configs
            if isinstance(scatter_series_configs, dict)
            else (globals().get("scatter_series_configs") or {})
        )
        per_series = series_cfgs.get(series_key)
        if isinstance(per_series, dict):
            # Iterate over items from per_series to apply the per-item logic.
            for key, value in per_series.items():
                if key not in merged:
                    continue
                if key == "size":
                    try:
                        size_val = float(value)
                    except Exception:
                        continue
                    if not (math.isfinite(size_val) and size_val > 0.0):
                        continue
                    merged[key] = size_val
                    overrides[key] = True
                elif key == "alpha":
                    try:
                        alpha_val = float(value)
                    except Exception:
                        continue
                    if not math.isfinite(alpha_val):
                        continue
                    merged[key] = max(0.0, min(alpha_val, 1.0))
                    overrides[key] = True
                else:
                    if key == "linestyle":
                        canonical = _canonicalize_linestyle_name(value)
                        if not canonical:
                            continue
                        merged[key] = canonical
                        overrides[key] = True
                        continue
                    if value in (None, ""):
                        continue
                    merged[key] = value
                    overrides[key] = True

    merged["_overrides"] = overrides
    return merged


def _resolve_effective_trace_zorder(
    default_zorder: float,
    *,
    series_key: Optional[str] = None,
    scatter_series_configs: Optional[Dict[str, Any]] = None,
) -> float:
    """Resolve the effective z-order for a trace.

    Purpose:
        Convert default trace layering plus optional per-series override settings
        into one deterministic z-order value.
    Why:
        Combined and non-combined render paths need the same priority/override
        resolution logic so trace layering behavior stays consistent.
    Inputs:
        default_zorder: Baseline z-order for the series when no override exists.
        series_key: Optional per-series settings key (for example "y1" or "z2").
        scatter_series_configs: Optional per-series style mapping from settings.
    Outputs:
        Float z-order used for all artists produced by the series.
    Side Effects:
        None.
    Exceptions:
        Invalid overrides are ignored and the default value is returned.
    """
    try:
        resolved_zorder = float(default_zorder)
    except Exception:
        resolved_zorder = 2.0
    if not math.isfinite(resolved_zorder):
        resolved_zorder = 2.0

    if not series_key:
        return resolved_zorder

    series_cfgs = (
        scatter_series_configs
        if isinstance(scatter_series_configs, dict)
        else (globals().get("scatter_series_configs") or {})
    )
    per_series = series_cfgs.get(series_key)
    if not isinstance(per_series, dict):
        return resolved_zorder

    zorder_override = _coerce_float(per_series.get("zorder"))
    if zorder_override is None or not math.isfinite(zorder_override):
        return resolved_zorder
    return float(zorder_override)


def _plot_series(
    ax,
    x_values,
    y_values,
    *,
    label,
    color=None,
    zorder=2,
    line_style=plot_linestyle,
    line_marker=plot_marker,
    line_markersize=plot_markersize,
    linewidth=linewidth_thickness,
    force_line=False,
    series_key=None,
    scatter_config: Optional[Dict[str, Any]] = None,
    scatter_series_configs: Optional[Dict[str, Any]] = None,
):
    """Plot a single data series with optional per-series overrides.

    Purpose:
        Render a line or scatter series with the correct style precedence.
    Why:
        Centralizes per-trace styling so all plot modes stay consistent.
    Args:
        ax: Matplotlib Axes receiving the series.
        x_values: X-axis numeric values.
        y_values: Y-axis numeric values.
        label: Legend label for the series.
        color: Base color for the series when no override is supplied.
        zorder: Default z-order for the series.
        line_style: Base line style for line rendering.
        line_marker: Base marker style for line rendering.
        line_markersize: Base marker size for line rendering.
        linewidth: Base line width for line rendering.
        force_line: When True, force line rendering even if scatter is enabled.
        series_key: Optional series identifier for per-series overrides.
        scatter_config: Optional global scatter settings overrides.
        scatter_series_configs: Optional per-series overrides map.
    Returns:
        The Matplotlib artist created for the series.
    Side Effects:
        Adds line/scatter artists to the provided Axes.
    Exceptions:
        Errors are guarded internally; invalid style inputs fall back to defaults.
    """

    cfg = _get_scatter_config(
        series_key,
        scatter_config=scatter_config,
        scatter_series_configs=scatter_series_configs,
    )
    overrides = cfg.get("_overrides", {})

    def _coerce_float(value, default):
        """Coerce float.
        Used to force float into a safe type or range."""
        try:
            return float(value)
        except (TypeError, ValueError):
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return default

    series_zorder = _resolve_effective_trace_zorder(
        zorder,
        series_key=series_key,
        scatter_series_configs=scatter_series_configs,
    )

    def _tag_series_artist(artist: Any) -> Any:
        """Attach the normalized trace key onto one rendered artist.
        Used so behavior filters can reliably target traces across all plot tabs."""
        normalized_series_key = _normalize_trace_series_key(series_key, default="")
        if not normalized_series_key:
            return artist
        try:
            artist._gl260_series_key = normalized_series_key
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return artist

    if force_line or not cfg.get("enabled"):
        marker_style = line_marker
        cfg_marker = cfg.get("marker")
        if overrides.get("marker") and cfg_marker:
            marker_style = cfg_marker

        linestyle_style = line_style
        cfg_linestyle = cfg.get("linestyle")
        canonical_linestyle = _canonicalize_linestyle_name(cfg_linestyle)
        if overrides.get("linestyle") and canonical_linestyle:
            if canonical_linestyle == "None":
                linestyle_style = "None"
            else:
                linestyle_style = _resolve_linestyle_value(canonical_linestyle)

        color_style = color
        cfg_color = (cfg.get("color") or "").strip()
        if overrides.get("color") and cfg_color:
            color_style = cfg_color

        markersize_style = line_markersize
        if overrides.get("size"):
            size_value = max(
                1.0,
                _coerce_float(cfg.get("size"), DEFAULT_SCATTER_SETTINGS["size"]),
            )
            markersize_style = math.sqrt(size_value)

        linewidth_style = linewidth
        if overrides.get("linewidth"):
            lw_value = _coerce_float(
                cfg.get("linewidth"), DEFAULT_SCATTER_SETTINGS["linewidth"]
            )
            if math.isfinite(lw_value) and lw_value > 0.0:
                linewidth_style = lw_value

        alpha_value = None
        if overrides.get("alpha"):
            alpha_candidate = _coerce_float(
                cfg.get("alpha"), DEFAULT_SCATTER_SETTINGS["alpha"]
            )
            if math.isfinite(alpha_candidate):
                alpha_value = max(0.0, min(alpha_candidate, 1.0))

        line_kwargs = {}
        if alpha_value is not None:
            line_kwargs["alpha"] = alpha_value

        (artist,) = ax.plot(
            x_values,
            y_values,
            linestyle=linestyle_style,
            color=color_style,
            linewidth=linewidth_style,
            marker=marker_style,
            markersize=markersize_style,
            zorder=series_zorder,
            label=label,
            **line_kwargs,
        )
        return _tag_series_artist(artist)

    marker = cfg.get("marker") or DEFAULT_SCATTER_SETTINGS["marker"]

    size_value = max(
        1.0,
        _coerce_float(cfg.get("size"), DEFAULT_SCATTER_SETTINGS["size"]),
    )
    alpha_value = _coerce_float(cfg.get("alpha"), DEFAULT_SCATTER_SETTINGS["alpha"])
    alpha_value = max(0.0, min(alpha_value, 1.0))
    linewidth_value = _coerce_float(
        cfg.get("linewidth"), DEFAULT_SCATTER_SETTINGS["linewidth"]
    )

    scatter_kwargs = {
        "marker": marker,
        "s": size_value,
        "alpha": alpha_value,
        "zorder": series_zorder,
        "label": label,
    }

    face_color = (cfg.get("color") or "").strip()
    if face_color:
        scatter_kwargs["color"] = face_color
    elif color is not None:
        scatter_kwargs["color"] = color

    edge_color = (cfg.get("edgecolor") or "").strip()
    if edge_color:
        scatter_kwargs["edgecolors"] = edge_color
    else:
        scatter_kwargs["edgecolors"] = "none"

    if linewidth_value > 0.0:
        scatter_kwargs["linewidths"] = linewidth_value

    artist = ax.scatter(x_values, y_values, **scatter_kwargs)
    return _tag_series_artist(artist)


DEFAULT_STARTING_MATERIAL_NAME = ""
DEFAULT_STARTING_MATERIAL_FORMULA = ""
DEFAULT_STARTING_MATERIAL_DISPLAY_NAME = ""
DEFAULT_STARTING_MATERIAL_DISPLAY_NOTE = ""
DEFAULT_STARTING_MATERIAL_MOLAR_MASS = 0.0
DEFAULT_STOICH_MOL_GAS_PER_MOL_STARTING = 0.0

# Legacy aliases (avoid CO2 defaults for generic starting material settings)
DEFAULT_PRODUCT_NAME = DEFAULT_STARTING_MATERIAL_NAME
DEFAULT_PRODUCT_FORMULA = DEFAULT_STARTING_MATERIAL_FORMULA
DEFAULT_PRODUCT_MOLAR_MASS = DEFAULT_STARTING_MATERIAL_MOLAR_MASS
DEFAULT_GAS_MOLAR_MASS = 45.002
gas_molar_mass = DEFAULT_GAS_MOLAR_MASS

PRODUCT_PRESETS = OrderedDict(
    [
        ("Custom", None),
    ]
)


# JSON LOADING

# Load saved settings if they exist

SETTINGS_FILE = "settings.json"
_SETTINGS_LOAD_ERROR = None
_SETTINGS_BACKUP_PATH = None

settings = {}
_SETTINGS_LOCK = threading.RLock()
DISPLAY_MODE_REGULAR = "regular"
DISPLAY_MODE_DARK = "dark"
DISPLAY_MODE_OPTIONS = {DISPLAY_MODE_REGULAR, DISPLAY_MODE_DARK}
PLOT_SETTINGS_CARD_ORDER_DEFAULT = [
    "titles",
    "ticks",
    "cycle_integration_legend",
    "combined_axis",
    "peak_trough",
    "gas_model",
    "starting_material",
]
PLOT_SETTINGS_CARD_ORDER_MIGRATION = {
    "cycle_integration": "cycle_integration_legend",
    "cycle_legend": "cycle_integration_legend",
    # Axis controls were merged into the fixed first "Axis & Range" card.
    "axes": "",
}


def _normalize_ui_display_mode(value: Any) -> str:
    """Normalize display mode for persistence.

    Purpose:
        Coerce stored UI display mode values into a known set.
    Why:
        Keeps startup behavior stable when settings contain legacy or invalid
        mode values.
    Args:
        value: Incoming settings value for the UI display mode.
    Returns:
        str: One of `"regular"` or `"dark"`.
    Side Effects:
        None.
    Exceptions:
        Falls back to `"regular"` for invalid or missing values.
    """
    normalized = str(value or "").strip().lower()
    if normalized not in DISPLAY_MODE_OPTIONS:
        return DISPLAY_MODE_REGULAR
    return normalized


def _normalize_plot_settings_card_order(value: Any) -> List[str]:
    """Normalize Plot Settings accordion order for persistence.

    Purpose:
        Coerce stored card-order payloads into the canonical stage-two key list.
    Why:
        Drag-reorder persistence must survive schema evolution, including the
        merge from separate cycle cards to one combined cycle card.
    Args:
        value: Incoming settings value for `plot_settings_card_order`.
    Returns:
        List[str]: De-duplicated, valid card keys in render order.
    Side Effects:
        None.
    Exceptions:
        Falls back to `PLOT_SETTINGS_CARD_ORDER_DEFAULT` for invalid payloads.
    """
    normalized: List[str] = []
    seen: Set[str] = set()
    raw_items = value if isinstance(value, list) else []
    # Iterate over stored items so legacy keys can be migrated deterministically.
    for raw_item in raw_items:
        key = str(raw_item or "").strip()
        if not key:
            continue
        migrated = PLOT_SETTINGS_CARD_ORDER_MIGRATION.get(key, key)
        if not migrated:
            continue
        if migrated not in PLOT_SETTINGS_CARD_ORDER_DEFAULT:
            continue
        if migrated in seen:
            continue
        normalized.append(migrated)
        seen.add(migrated)
    # Append missing defaults to keep future cards reachable after upgrades.
    for default_key in PLOT_SETTINGS_CARD_ORDER_DEFAULT:
        if default_key in seen:
            continue
        normalized.append(default_key)
        seen.add(default_key)
    return normalized


def _normalize_debug_categories(value: Any) -> Dict[str, bool]:
    """Normalize debug categories for persistence.

    Purpose:
        Coerce the stored debug category map into a full, known-key dictionary.
    Why:
        Keeps debug toggle persistence stable across upgrades and prevents
        missing keys from breaking Developer Tools toggles.
    Args:
        value: Incoming settings value, expected to be a dict[str, bool].
    Returns:
        Dict[str, bool] containing all DEBUG_CATEGORIES with boolean values.
    Side Effects:
        None.
    Exceptions:
        Falls back to defaults when input types are invalid.
    """
    normalized: Dict[str, bool] = {}
    if isinstance(value, dict):
        # Iterate over DEBUG_CATEGORIES to apply the per-item logic.
        for name in DEBUG_CATEGORIES:
            normalized[name] = bool(value.get(name, False))
    else:
        for name in DEBUG_CATEGORIES:
            normalized[name] = False
    return normalized

if os.path.exists(SETTINGS_FILE):

    loaded_settings = None

    try:

        with open(SETTINGS_FILE, "r", encoding="utf-8") as f:

            loaded_settings = json.load(f)

        if not isinstance(loaded_settings, dict):

            raise ValueError("Settings file must contain a JSON object.")

    except Exception as exc:

        _SETTINGS_LOAD_ERROR = exc

        try:

            timestamp = time.strftime("%Y%m%d-%H%M%S")

            backup_name = f"{SETTINGS_FILE}.corrupt-{timestamp}"

            shutil.move(SETTINGS_FILE, backup_name)

            _SETTINGS_BACKUP_PATH = backup_name

        except Exception:

            _SETTINGS_BACKUP_PATH = None

        settings = {}

    else:

        settings = loaded_settings

    settings["debug_enabled"] = bool(settings.get("debug_enabled", False))
    settings["debug_categories"] = _normalize_debug_categories(
        settings.get("debug_categories")
    )
    settings["debug_file_logging_enabled"] = bool(
        settings.get("debug_file_logging_enabled", False)
    )

    def _coerce_setting_float(value, fallback):
        """Coerce setting float.
        Used to force setting float into a safe type or range."""
        try:
            candidate = float(value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return fallback
        if not math.isfinite(candidate):
            return fallback
        return candidate

    _starting_material_key_map = {
        "product_preset": "starting_material_preset",
        "product_name": "starting_material_name",
        "product_formula": "starting_material_formula",
        "product_molar_mass": "starting_material_mw_g_mol",
        "starting_mass": "starting_material_mass_g",
    }
    # Iterate over items from _starting_material_key_map to apply the per-item logic.
    for old_key, new_key in _starting_material_key_map.items():
        if new_key not in settings and old_key in settings:
            settings[new_key] = settings.get(old_key)

    raw_name = settings.get("starting_material_name")
    if not isinstance(raw_name, str):
        settings["starting_material_name"] = DEFAULT_STARTING_MATERIAL_NAME

    raw_formula = settings.get("starting_material_formula")
    if not isinstance(raw_formula, str):
        settings["starting_material_formula"] = DEFAULT_STARTING_MATERIAL_FORMULA

    raw_display_name = settings.get("starting_material_display_name")
    if not isinstance(raw_display_name, str):
        settings["starting_material_display_name"] = DEFAULT_STARTING_MATERIAL_DISPLAY_NAME

    raw_display_note = settings.get("starting_material_display_note")
    if not isinstance(raw_display_note, str):
        settings["starting_material_display_note"] = DEFAULT_STARTING_MATERIAL_DISPLAY_NOTE

    settings["starting_material_mw_g_mol"] = _coerce_setting_float(
        settings.get("starting_material_mw_g_mol"),
        DEFAULT_STARTING_MATERIAL_MOLAR_MASS,
    )
    settings["starting_material_mass_g"] = _coerce_setting_float(
        settings.get("starting_material_mass_g"),
        settings.get("starting_mass", settings.get("naoh_mass", 0.0)),
    )
    settings["stoich_mol_gas_per_mol_starting"] = _coerce_setting_float(
        settings.get("stoich_mol_gas_per_mol_starting"),
        DEFAULT_STOICH_MOL_GAS_PER_MOL_STARTING,
    )

    settings["summary_compact"] = bool(settings.get("summary_compact", True))
    settings["summary_include_diagnostics"] = bool(
        settings.get("summary_include_diagnostics", False)
    )
    settings["summary_include_per_cycle_gas_mass"] = bool(
        settings.get("summary_include_per_cycle_gas_mass", False)
    )
    settings["summary_include_conversion_estimate"] = bool(
        settings.get("summary_include_conversion_estimate", False)
    )

    # Ranges

    initial_min = settings.get("min_time", -0.05)

    initial_max = settings.get("max_time", 0.93)

    initial_y_min = settings.get("min_y", 0)

    initial_y_max = settings.get("max_y", 1050)

    initial_twin_y_min = settings.get("twin_y_min", 0)

    initial_twin_y_max = settings.get("twin_y_max", 40)

    initial_deriv_y_min = settings.get("deriv_y_min", -1000)

    initial_deriv_y_max = settings.get("deriv_y_max", 1000)

    # Titles

    initial_title = settings.get("title_text", "Day 0 Pressure Test 8/14 - 8/15")

    initial_suptitle = settings.get("suptitle_text", "PR-20332 CLM-11873-0 Synthesis")

    # Auto title

    auto_title_enabled = bool(settings.get("auto_title_enabled", False))
    settings["auto_title_enabled"] = auto_title_enabled

    auto_title_template = settings.get(
        "auto_title_template", DEFAULT_AUTO_TITLE_TEMPLATE
    )
    if not isinstance(auto_title_template, str) or not auto_title_template.strip():
        auto_title_template = DEFAULT_AUTO_TITLE_TEMPLATE
    settings["auto_title_template"] = auto_title_template

    auto_title_source = settings.get("auto_title_source", AUTO_TITLE_SOURCE_FULL)
    if auto_title_source not in AUTO_TITLE_SOURCES:
        auto_title_source = AUTO_TITLE_SOURCE_FULL
    settings["auto_title_source"] = auto_title_source

    auto_title_day_mode = settings.get("auto_title_day_mode", AUTO_TITLE_DAY_DIFF)
    if auto_title_day_mode not in AUTO_TITLE_DAY_MODES:
        auto_title_day_mode = AUTO_TITLE_DAY_DIFF
    settings["auto_title_day_mode"] = auto_title_day_mode

    title_types = _normalize_title_type_list(settings.get("title_data_types"))
    settings["title_data_types"] = list(title_types)

    selected_type = settings.get("title_selected_type", title_types[0])
    selected_type = str(selected_type).strip() if selected_type is not None else ""
    matched_type = None
    if selected_type:
        # Iterate over title_types to apply the per-item logic.
        for entry in title_types:
            if entry.casefold() == selected_type.casefold():
                matched_type = entry
                break
    if matched_type is None:
        matched_type = title_types[0]
    settings["title_selected_type"] = matched_type

    initial_auto_title_enabled = settings["auto_title_enabled"]
    initial_auto_title_template = settings["auto_title_template"]
    initial_auto_title_source = settings["auto_title_source"]
    initial_auto_title_day_mode = settings["auto_title_day_mode"]
    initial_title_types = list(settings["title_data_types"])
    initial_title_selected_type = settings["title_selected_type"]

    # Columns

    initial_columns = settings.get("columns", {})
    per_sheet_column_map = settings.get("per_sheet_column_map", {})
    if not isinstance(per_sheet_column_map, dict):
        per_sheet_column_map = {}
    settings["per_sheet_column_map"] = per_sheet_column_map

    initial_elapsed_time_unit = _normalize_elapsed_time_unit(
        settings.get("elapsed_time_unit")
    )
    settings["elapsed_time_unit"] = initial_elapsed_time_unit

    # Auto tick checkboxes

    initial_auto_time_ticks = settings.get("auto_time_ticks", False)

    initial_auto_y_ticks = settings.get("auto_y_ticks", False)

    initial_auto_temp_ticks = settings.get("auto_temp_ticks", False)

    initial_auto_deriv_ticks = settings.get("auto_deriv_ticks", False)

    # Manual tick values (used if corresponding auto tick is False)

    initial_xmaj_tick = settings.get("x_major_tick", 0.2)

    initial_xmin_tick = settings.get("x_minor_tick", 0.05)

    initial_ymaj_tick = settings.get("y_major_tick", 50)

    initial_ymin_tick = settings.get("y_minor_tick", 5)

    initial_temp_maj_tick = settings.get("temp_major_tick", 5)

    initial_temp_min_tick = settings.get("temp_minor_tick", 2.5)

    initial_deriv_maj_tick = settings.get("deriv_major_tick", 200)

    initial_deriv_min_tick = settings.get("deriv_minor_tick", 100)

    initial_combined_deriv_axis_offset = settings.get(
        "combined_deriv_axis_offset", 1.12
    )

    initial_combined_primary_axis_label = settings.get(
        "combined_primary_axis_label", ""
    )
    initial_combined_deriv_axis_label = settings.get("combined_deriv_axis_label", "")
    initial_combined_temp_axis_label = settings.get("combined_temp_axis_label", "")
    initial_combined_x_axis_label = settings.get("combined_x_axis_label", "")
    initial_combined_primary_labelpad = settings.get(
        "combined_primary_labelpad", yaxis_labelpad_amount
    )
    initial_combined_temp_labelpad = settings.get(
        "combined_temp_labelpad", twinyaxis_labelpad_amount
    )
    initial_combined_deriv_labelpad = settings.get(
        "combined_deriv_labelpad", twinyaxis_labelpad_amount
    )
    initial_combined_left_pad_pct = _sanitize_spacing_value(
        settings.get("combined_left_pad_pct", DEFAULT_COMBINED_LEFT_PAD_PCT),
        DEFAULT_COMBINED_LEFT_PAD_PCT,
        MIN_COMBINED_SIDE_PAD_PCT,
        MAX_COMBINED_SIDE_PAD_PCT,
    )
    initial_combined_right_pad_pct = _sanitize_spacing_value(
        settings.get("combined_right_pad_pct", DEFAULT_COMBINED_RIGHT_PAD_PCT),
        DEFAULT_COMBINED_RIGHT_PAD_PCT,
        MIN_COMBINED_SIDE_PAD_PCT,
        MAX_COMBINED_SIDE_PAD_PCT,
    )
    initial_combined_export_pad_pts = _sanitize_spacing_value(
        settings.get("combined_export_pad_pts", DEFAULT_COMBINED_EXPORT_PAD_PTS),
        DEFAULT_COMBINED_EXPORT_PAD_PTS,
        MIN_COMBINED_EXPORT_PAD_PTS,
        MAX_COMBINED_EXPORT_PAD_PTS,
    )
    initial_combined_title_pad_pts = _sanitize_spacing_value(
        settings.get("combined_title_pad_pts", DEFAULT_COMBINED_TITLE_PAD_PTS),
        DEFAULT_COMBINED_TITLE_PAD_PTS,
        MIN_COMBINED_TITLE_PAD_PTS,
        MAX_COMBINED_TITLE_PAD_PTS,
    )
    initial_combined_suptitle_pad_pts = _sanitize_spacing_value(
        settings.get("combined_suptitle_pad_pts", DEFAULT_COMBINED_SUPTITLE_PAD_PTS),
        DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
        MIN_COMBINED_SUPTITLE_PAD_PTS,
        MAX_COMBINED_SUPTITLE_PAD_PTS,
    )
    initial_combined_suptitle_y = _sanitize_spacing_value(
        settings.get("combined_suptitle_y", DEFAULT_COMBINED_SUPTITLE_Y),
        DEFAULT_COMBINED_SUPTITLE_Y,
        MIN_COMBINED_SUPTITLE_Y,
        MAX_COMBINED_SUPTITLE_Y,
    )
    initial_combined_top_margin_pct = _sanitize_spacing_value(
        settings.get("combined_top_margin_pct", DEFAULT_COMBINED_TOP_MARGIN_PCT),
        DEFAULT_COMBINED_TOP_MARGIN_PCT,
        MIN_COMBINED_TOP_MARGIN_PCT,
        MAX_COMBINED_TOP_MARGIN_PCT,
    )
    initial_combined_suptitle_fontsize = _sanitize_spacing_value(
        settings.get("combined_suptitle_fontsize", DEFAULT_COMBINED_SUPTITLE_FONTSIZE),
        DEFAULT_COMBINED_SUPTITLE_FONTSIZE,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    initial_combined_title_fontsize = _sanitize_spacing_value(
        settings.get("combined_title_fontsize", DEFAULT_COMBINED_TITLE_FONTSIZE),
        DEFAULT_COMBINED_TITLE_FONTSIZE,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    initial_combined_label_fontsize = _sanitize_spacing_value(
        settings.get("combined_label_fontsize", DEFAULT_COMBINED_LABEL_FONTSIZE),
        DEFAULT_COMBINED_LABEL_FONTSIZE,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    initial_combined_tick_fontsize = _sanitize_spacing_value(
        settings.get("combined_tick_fontsize", DEFAULT_COMBINED_TICK_FONTSIZE),
        DEFAULT_COMBINED_TICK_FONTSIZE,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    initial_combined_legend_fontsize = _sanitize_spacing_value(
        settings.get("combined_legend_fontsize", DEFAULT_COMBINED_LEGEND_FONTSIZE),
        DEFAULT_COMBINED_LEGEND_FONTSIZE,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    initial_combined_cycle_legend_fontsize = _sanitize_spacing_value(
        settings.get("combined_cycle_legend_fontsize", initial_combined_legend_fontsize),
        initial_combined_legend_fontsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    settings["combined_cycle_legend_fontsize"] = initial_combined_cycle_legend_fontsize
    initial_combined_font_family = (
        settings.get("combined_font_family", DEFAULT_COMBINED_FONT_FAMILY) or ""
    )
    initial_font_family = (settings.get("font_family", "") or "").strip()
    settings["font_family"] = initial_font_family

    initial_combined_legend_wrap = bool(settings.get("combined_legend_wrap", False))
    initial_combined_legend_rows = settings.get("combined_legend_rows", 2)
    raw_legend_gap = settings.get("combined_legend_gap_pts")
    raw_legend_margin = settings.get("combined_legend_bottom_margin_pts")
    raw_xlabel_tick_gap = settings.get("combined_xlabel_tick_gap_pts")

    legacy_panel_hint = settings.get("combined_legend_panel_height")
    if legacy_panel_hint is None:
        legacy_panel_hint = settings.get("combined_legend_spacing")
    if legacy_panel_hint is None:
        legacy_top = settings.get("combined_legend_top")
        if legacy_top is not None:
            try:
                lt = float(legacy_top)
                if lt < 0.3:
                    legacy_panel_hint = 0.08
                elif lt < 0.5:
                    legacy_panel_hint = 0.12
                else:
                    legacy_panel_hint = 0.18
            except Exception:
                legacy_panel_hint = None

    legacy_gap = legacy_margin = None
    if legacy_panel_hint is not None:
        legacy_gap, legacy_margin = _legacy_panel_height_to_spacing(legacy_panel_hint)

    if raw_legend_gap is not None:
        initial_combined_legend_gap_pts = _sanitize_spacing_value(
            raw_legend_gap,
            DEFAULT_COMBINED_LEGEND_GAP_PTS,
            MIN_COMBINED_LEGEND_GAP_PTS,
            MAX_COMBINED_LEGEND_GAP_PTS,
        )
    elif legacy_gap is not None:
        initial_combined_legend_gap_pts = legacy_gap
    else:
        initial_combined_legend_gap_pts = DEFAULT_COMBINED_LEGEND_GAP_PTS

    if raw_legend_margin is not None:
        initial_combined_legend_margin_pts = _sanitize_spacing_value(
            raw_legend_margin,
            DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
            MIN_COMBINED_LEGEND_MARGIN_PTS,
            MAX_COMBINED_LEGEND_MARGIN_PTS,
        )
    elif legacy_margin is not None:
        initial_combined_legend_margin_pts = legacy_margin
    else:
        initial_combined_legend_margin_pts = DEFAULT_COMBINED_LEGEND_MARGIN_PTS

    if raw_xlabel_tick_gap is not None:
        initial_combined_xlabel_tick_gap_pts = _sanitize_spacing_value(
            raw_xlabel_tick_gap,
            DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS,
            MIN_COMBINED_XLABEL_TICK_GAP_PTS,
            MAX_COMBINED_XLABEL_TICK_GAP_PTS,
        )
    else:
        initial_combined_xlabel_tick_gap_pts = DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS
    settings["combined_xlabel_tick_gap_pts"] = initial_combined_xlabel_tick_gap_pts

    initial_combined_legend_alignment = settings.get(
        "combined_legend_alignment", "center"
    )
    initial_combined_legend_shadowbox_fill_color = _normalize_color(
        settings.get("combined_legend_shadowbox_fill_color"),
        DEFAULT_LEGEND_SHADOWBOX_FILL_COLOR,
    )
    settings["combined_legend_shadowbox_fill_color"] = (
        initial_combined_legend_shadowbox_fill_color
    )
    cycle_loc_choices = {
        "upper right",
        "upper left",
        "lower right",
        "lower left",
        "center right",
        "center left",
        "upper center",
        "lower center",
        "center",
    }
    raw_cycle_loc_choice = settings.get(
        "combined_cycle_legend_loc_choice", "upper right"
    )
    if isinstance(raw_cycle_loc_choice, str):
        cycle_loc_choice_value = raw_cycle_loc_choice.strip().lower()
    else:
        cycle_loc_choice_value = str(raw_cycle_loc_choice).strip().lower()
    if cycle_loc_choice_value not in cycle_loc_choices:
        cycle_loc_choice_value = "upper right"
    initial_combined_cycle_legend_loc_choice = cycle_loc_choice_value
    settings["combined_cycle_legend_loc_choice"] = cycle_loc_choice_value
    initial_combined_cycle_legend_ref_axis = _normalize_combined_cycle_ref_axis(
        settings.get("combined_cycle_legend_ref_axis")
    )
    settings["combined_cycle_legend_ref_axis"] = initial_combined_cycle_legend_ref_axis
    initial_combined_cycle_legend_ref_corner = _normalize_combined_cycle_ref_corner(
        settings.get("combined_cycle_legend_ref_corner")
    )
    settings[
        "combined_cycle_legend_ref_corner"
    ] = initial_combined_cycle_legend_ref_corner
    combined_cycle_ref_dx = _coerce_float(settings.get("combined_cycle_legend_ref_dx_px"))
    combined_cycle_ref_dy = _coerce_float(settings.get("combined_cycle_legend_ref_dy_px"))
    if combined_cycle_ref_dx is not None:
        settings["combined_cycle_legend_ref_dx_px"] = combined_cycle_ref_dx
    if combined_cycle_ref_dy is not None:
        settings["combined_cycle_legend_ref_dy_px"] = combined_cycle_ref_dy
    anchor_mode_value = settings.get("combined_cycle_legend_anchor_mode")
    normalized_cycle_loc = _normalize_legend_loc_value(
        settings.get("combined_cycle_legend_loc")
    )
    if isinstance(normalized_cycle_loc, tuple):
        anchor_mode_value = "loc_tuple"
    elif combined_cycle_ref_dx is not None and combined_cycle_ref_dy is not None:
        anchor_mode_value = "axis_offset"
    else:
        anchor_mode_value = "legacy_anchor"
    settings["combined_cycle_legend_anchor_mode"] = anchor_mode_value
    initial_combined_cycle_legend_enable_drag = bool(
        settings.get("combined_cycle_legend_enable_drag", True)
    )
    settings["combined_cycle_legend_enable_drag"] = (
        initial_combined_cycle_legend_enable_drag
    )
    initial_combined_cycle_legend_lock_position = bool(
        settings.get("combined_cycle_legend_lock_position", False)
    )
    settings["combined_cycle_legend_lock_position"] = (
        initial_combined_cycle_legend_lock_position
    )
    initial_combined_cycle_legend_persist_position = bool(
        settings.get("combined_cycle_legend_persist_position", True)
    )
    settings["combined_cycle_legend_persist_position"] = (
        initial_combined_cycle_legend_persist_position
    )
    initial_combined_cycle_legend_clamp_to_axes = bool(
        settings.get("combined_cycle_legend_clamp_to_axes", True)
    )
    settings["combined_cycle_legend_clamp_to_axes"] = (
        initial_combined_cycle_legend_clamp_to_axes
    )
    initial_combined_main_legend_enable_drag = bool(
        settings.get("combined_main_legend_enable_drag", False)
    )
    settings["combined_main_legend_enable_drag"] = (
        initial_combined_main_legend_enable_drag
    )
    initial_combined_center_plot_legend = bool(
        settings.get("combined_center_plot_legend", False)
    )
    if not isinstance(initial_combined_legend_rows, int):
        try:
            initial_combined_legend_rows = int(initial_combined_legend_rows)
        except Exception:
            initial_combined_legend_rows = 1
    if initial_combined_legend_rows <= 0:
        initial_combined_legend_rows = 1

    # Enable/disable axis checkbuttons

    initial_enable_temp_axis = settings.get("enable_temp_axis", True)

    initial_enable_deriv_axis = settings.get("enable_deriv_axis", True)

    # Load Van der Waals constants

    initial_volume = settings.get("vessel_volume", 1.0)

    initial_a = settings.get("vdw_a", 1.39)  # Default for N2

    initial_b = settings.get("vdw_b", 0.0391)  # Default for N2

    initial_gas_molar_mass = settings.get("vdw_gas_molar_mass", DEFAULT_GAS_MOLAR_MASS)

    initial_gas_preset_overrides = settings.get("gas_preset_overrides", {})
    if not isinstance(initial_gas_preset_overrides, dict):
        initial_gas_preset_overrides = {}
        settings["gas_preset_overrides"] = {}

    initial_sheet_name = settings.get(
        "last_sheet_name", None
    )  # load the saved sheet name

    initial_multi_sheet_enabled = bool(settings.get("multi_sheet_enabled", False))
    raw_selected_sheets = settings.get("selected_sheets", [])
    initial_selected_sheets = []
    if isinstance(raw_selected_sheets, list):
        seen = set()
        # Iterate over raw_selected_sheets to apply the per-item logic.
        for item in raw_selected_sheets:
            if not isinstance(item, str):
                continue
            name = item.strip()
            if name and name not in seen:
                initial_selected_sheets.append(name)
                seen.add(name)
    settings["multi_sheet_enabled"] = initial_multi_sheet_enabled
    settings["selected_sheets"] = list(initial_selected_sheets)

    initial_min_cycle_drop = settings.get("min_cycle_drop", 60)

    initial_include_moles_legend = settings.get("include_moles_legend", False)
    initial_show_cycle_markers_on_core = settings.get(
        "show_cycle_markers_on_core_plots", False
    )
    initial_show_cycle_legend_on_core = settings.get(
        "show_cycle_legend_on_core_plots", False
    )
    initial_include_moles_core_legend = settings.get(
        "include_moles_in_core_plot_legend", False
    )
    initial_core_legend_fontsize = _sanitize_spacing_value(
        settings.get("core_legend_fontsize", label_fontsize),
        label_fontsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    initial_core_cycle_legend_fontsize = _sanitize_spacing_value(
        settings.get("core_cycle_legend_fontsize", initial_core_legend_fontsize),
        initial_core_legend_fontsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    settings["core_legend_fontsize"] = initial_core_legend_fontsize
    settings["core_cycle_legend_fontsize"] = initial_core_cycle_legend_fontsize

    initial_combined_left_key = settings.get("combined_y_left_key", "y1")
    initial_combined_right_key = settings.get("combined_y_right_key", "z")
    initial_combined_third_key = settings.get("combined_y_third_key", "y2")

    initial_starting_material_preset = settings.get(
        "starting_material_preset",
        settings.get("product_preset", next(iter(PRODUCT_PRESETS))),
    )

    initial_starting_material_name = settings.get(
        "starting_material_name", DEFAULT_STARTING_MATERIAL_NAME
    )

    initial_starting_material_display_name = settings.get(
        "starting_material_display_name", DEFAULT_STARTING_MATERIAL_DISPLAY_NAME
    )
    initial_starting_material_display_note = settings.get(
        "starting_material_display_note", DEFAULT_STARTING_MATERIAL_DISPLAY_NOTE
    )

    initial_starting_material_mw = settings.get(
        "starting_material_mw_g_mol", DEFAULT_STARTING_MATERIAL_MOLAR_MASS
    )

    initial_starting_mass = settings.get(
        "starting_material_mass_g",
        settings.get("starting_mass", settings.get("naoh_mass", 0.0)),
    )

    initial_starting_stoich = settings.get(
        "stoich_mol_gas_per_mol_starting",
        DEFAULT_STOICH_MOL_GAS_PER_MOL_STARTING,
    )

    initial_summary_compact = settings.get("summary_compact", True)
    initial_summary_include_diagnostics = settings.get(
        "summary_include_diagnostics", False
    )
    initial_summary_include_per_cycle_gas_mass = settings.get(
        "summary_include_per_cycle_gas_mass", False
    )
    initial_summary_include_conversion_estimate = settings.get(
        "summary_include_conversion_estimate", False
    )

    # Peak/Trough detection (UI defaults)

    initial_peak_prominence = settings.get("peak_prominence", 1.0)

    initial_peak_distance = settings.get("peak_distance", 1)  # samples

    initial_peak_width = settings.get("peak_width", 1)  # samples


else:

    # No saved settings; use defaults

    settings = {}
    settings["debug_enabled"] = False
    settings["debug_categories"] = _normalize_debug_categories({})
    settings["debug_file_logging_enabled"] = False

    # Ranges

    initial_min = -0.05

    initial_max = 0.93

    initial_y_min = 0

    initial_y_max = 1050

    initial_twin_y_min = 0

    initial_twin_y_max = 40

    initial_deriv_y_min = -1000

    initial_deriv_y_max = 1000

    initial_combined_deriv_axis_offset = 1.12

    initial_combined_primary_axis_label = ""
    initial_combined_deriv_axis_label = ""
    initial_combined_temp_axis_label = ""
    initial_combined_x_axis_label = ""
    initial_combined_primary_labelpad = yaxis_labelpad_amount
    initial_combined_temp_labelpad = twinyaxis_labelpad_amount
    initial_combined_deriv_labelpad = twinyaxis_labelpad_amount
    initial_combined_left_pad_pct = DEFAULT_COMBINED_LEFT_PAD_PCT
    initial_combined_right_pad_pct = DEFAULT_COMBINED_RIGHT_PAD_PCT
    initial_combined_export_pad_pts = DEFAULT_COMBINED_EXPORT_PAD_PTS
    initial_combined_title_pad_pts = DEFAULT_COMBINED_TITLE_PAD_PTS
    initial_combined_suptitle_pad_pts = DEFAULT_COMBINED_SUPTITLE_PAD_PTS
    initial_combined_suptitle_y = DEFAULT_COMBINED_SUPTITLE_Y
    initial_combined_top_margin_pct = DEFAULT_COMBINED_TOP_MARGIN_PCT
    initial_combined_suptitle_fontsize = DEFAULT_COMBINED_SUPTITLE_FONTSIZE
    initial_combined_title_fontsize = DEFAULT_COMBINED_TITLE_FONTSIZE
    initial_combined_label_fontsize = DEFAULT_COMBINED_LABEL_FONTSIZE
    initial_combined_tick_fontsize = DEFAULT_COMBINED_TICK_FONTSIZE
    initial_combined_legend_fontsize = DEFAULT_COMBINED_LEGEND_FONTSIZE
    initial_combined_cycle_legend_fontsize = initial_combined_legend_fontsize
    initial_combined_font_family = DEFAULT_COMBINED_FONT_FAMILY
    initial_font_family = ""
    settings["font_family"] = initial_font_family
    initial_combined_xlabel_tick_gap_pts = DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS
    settings["combined_xlabel_tick_gap_pts"] = initial_combined_xlabel_tick_gap_pts
    initial_combined_legend_wrap = False
    initial_combined_legend_rows = 2
    initial_combined_legend_gap_pts = DEFAULT_COMBINED_LEGEND_GAP_PTS
    initial_combined_legend_margin_pts = DEFAULT_COMBINED_LEGEND_MARGIN_PTS
    initial_combined_legend_alignment = "center"
    initial_combined_legend_shadowbox_fill_color = (
        DEFAULT_LEGEND_SHADOWBOX_FILL_COLOR
    )
    settings["combined_legend_shadowbox_fill_color"] = (
        initial_combined_legend_shadowbox_fill_color
    )
    initial_combined_cycle_legend_loc_choice = "upper right"
    settings["combined_cycle_legend_loc_choice"] = (
        initial_combined_cycle_legend_loc_choice
    )
    settings["combined_cycle_legend_fontsize"] = initial_combined_cycle_legend_fontsize
    initial_combined_cycle_legend_ref_axis = "main"
    settings["combined_cycle_legend_ref_axis"] = initial_combined_cycle_legend_ref_axis
    initial_combined_cycle_legend_ref_corner = "upper right"
    settings[
        "combined_cycle_legend_ref_corner"
    ] = initial_combined_cycle_legend_ref_corner
    settings["combined_cycle_legend_anchor_mode"] = "legacy_anchor"
    initial_combined_cycle_legend_enable_drag = True
    settings["combined_cycle_legend_enable_drag"] = initial_combined_cycle_legend_enable_drag
    initial_combined_cycle_legend_lock_position = False
    settings["combined_cycle_legend_lock_position"] = (
        initial_combined_cycle_legend_lock_position
    )
    initial_combined_cycle_legend_persist_position = True
    settings["combined_cycle_legend_persist_position"] = (
        initial_combined_cycle_legend_persist_position
    )
    initial_combined_cycle_legend_clamp_to_axes = True
    settings["combined_cycle_legend_clamp_to_axes"] = (
        initial_combined_cycle_legend_clamp_to_axes
    )
    initial_combined_main_legend_enable_drag = False
    settings["combined_main_legend_enable_drag"] = (
        initial_combined_main_legend_enable_drag
    )
    initial_combined_center_plot_legend = False

    # Titles

    initial_title = "Day 0 Pressure Test 8/14— 8/15"

    initial_suptitle = "PR-20332 CLM-11873-0 Synthesis"

    # Columns

    initial_columns = {}
    settings["per_sheet_column_map"] = {}

    initial_elapsed_time_unit = DEFAULT_ELAPSED_TIME_UNIT
    settings["elapsed_time_unit"] = initial_elapsed_time_unit

    # Auto tick checkboxes

    initial_auto_time_ticks = False

    initial_auto_y_ticks = False

    initial_auto_temp_ticks = False

    initial_auto_deriv_ticks = False

    # Manual tick defaults

    initial_xmaj_tick = 0.2

    initial_xmin_tick = 0.05

    initial_ymaj_tick = 50

    initial_ymin_tick = 5

    initial_temp_maj_tick = 5

    initial_temp_min_tick = 2.5

    initial_deriv_maj_tick = 200

    initial_deriv_min_tick = 100

    # Enable/disable axis checkbuttons

    initial_enable_temp_axis = True

    initial_enable_deriv_axis = True

    # Default Van der Waals constants

    initial_volume = 1.0

    initial_a = 3.606788

    initial_b = 0.0391

    initial_gas_molar_mass = DEFAULT_GAS_MOLAR_MASS

    initial_gas_preset_overrides = {}

    initial_sheet_name = None

    initial_multi_sheet_enabled = False
    initial_selected_sheets = []
    settings["multi_sheet_enabled"] = initial_multi_sheet_enabled
    settings["selected_sheets"] = list(initial_selected_sheets)

    # Default Min Cycle Drop Pressure

    initial_min_cycle_drop = 60

    initial_include_moles_legend = False
    initial_show_cycle_markers_on_core = False
    initial_show_cycle_legend_on_core = False
    initial_include_moles_core_legend = False
    initial_core_legend_fontsize = label_fontsize
    initial_core_cycle_legend_fontsize = initial_core_legend_fontsize
    settings["core_legend_fontsize"] = initial_core_legend_fontsize
    settings["core_cycle_legend_fontsize"] = initial_core_cycle_legend_fontsize

    initial_combined_left_key = "y1"
    initial_combined_right_key = "z"
    initial_combined_third_key = "y2"

    initial_starting_material_preset = next(iter(PRODUCT_PRESETS))

    initial_starting_material_name = DEFAULT_STARTING_MATERIAL_NAME
    initial_starting_material_display_name = DEFAULT_STARTING_MATERIAL_DISPLAY_NAME
    initial_starting_material_display_note = DEFAULT_STARTING_MATERIAL_DISPLAY_NOTE

    initial_starting_material_mw = DEFAULT_STARTING_MATERIAL_MOLAR_MASS

    initial_starting_mass = 0.0

    initial_starting_stoich = DEFAULT_STOICH_MOL_GAS_PER_MOL_STARTING

    initial_summary_compact = True
    initial_summary_include_diagnostics = False
    initial_summary_include_per_cycle_gas_mass = False
    initial_summary_include_conversion_estimate = False

    settings["starting_material_preset"] = initial_starting_material_preset
    settings["starting_material_name"] = initial_starting_material_name
    settings["starting_material_display_name"] = initial_starting_material_display_name
    settings["starting_material_display_note"] = initial_starting_material_display_note
    settings["starting_material_formula"] = DEFAULT_STARTING_MATERIAL_FORMULA
    settings["starting_material_mw_g_mol"] = initial_starting_material_mw
    settings["starting_material_mass_g"] = initial_starting_mass
    settings["stoich_mol_gas_per_mol_starting"] = initial_starting_stoich

    settings["summary_compact"] = initial_summary_compact
    settings["summary_include_diagnostics"] = initial_summary_include_diagnostics
    settings["summary_include_per_cycle_gas_mass"] = (
        initial_summary_include_per_cycle_gas_mass
    )
    settings["summary_include_conversion_estimate"] = (
        initial_summary_include_conversion_estimate
    )

    # Peak/Trough detection (UI defaults)

    initial_peak_prominence = 1.0

    initial_peak_distance = 1  # samples

    initial_peak_width = 1  # samples


_apply_csv_import_settings_defaults(settings)

settings["plot_elements"] = _normalize_plot_elements(settings.get("plot_elements"))
settings["annotations_ui"] = _normalize_annotations_ui(settings.get("annotations_ui"))
settings["combined_disable_second_refresh"] = bool(
    settings.get("combined_disable_second_refresh", False)
)
settings["dev_disable_startup_tab_cycling"] = bool(
    settings.get("dev_disable_startup_tab_cycling", True)
)
settings["layout_profiles"] = _normalize_layout_profiles(
    settings.get("layout_profiles")
)
settings["core_plot_render_profiles"] = _normalize_core_plot_render_profiles(
    settings.get("core_plot_render_profiles"),
    seed_source=settings,
)
_default_core_profile_for_legacy = settings["core_plot_render_profiles"].get(
    CORE_RENDER_PROFILE_PLOT_IDS[0]
)
_write_legacy_core_legend_settings_from_profile(_default_core_profile_for_legacy)
initial_core_legend_fontsize = _sanitize_spacing_value(
    settings.get("core_legend_fontsize", initial_core_legend_fontsize),
    label_fontsize,
    MIN_COMBINED_FONT_SIZE,
    MAX_COMBINED_FONT_SIZE,
)
initial_core_cycle_legend_fontsize = _sanitize_spacing_value(
    settings.get("core_cycle_legend_fontsize", initial_core_legend_fontsize),
    initial_core_legend_fontsize,
    MIN_COMBINED_FONT_SIZE,
    MAX_COMBINED_FONT_SIZE,
)


initial_cached_markers = _normalize_cached_cycle_markers(
    settings.get("cycle_cached_markers")
)

cycle_trace_settings.clear()
cycle_trace_settings.update(DEFAULT_CYCLE_TRACE_SETTINGS)
_saved_cycle_trace = settings.get("cycle_trace")
if isinstance(_saved_cycle_trace, dict):
    sanitized_cycle_trace = {}
    # Iterate over items from DEFAULT_CYCLE_TRACE_SETTINGS to apply the per-item logic.
    for key, default in DEFAULT_CYCLE_TRACE_SETTINGS.items():
        value = _saved_cycle_trace.get(key)
        if key in ("line_width", "marker_size"):
            try:
                numeric_value = float(value)
            except (TypeError, ValueError):
                continue
            if math.isfinite(numeric_value) and numeric_value > 0.0:
                sanitized_cycle_trace[key] = numeric_value
        elif key == "line_style":
            canonical = _canonicalize_linestyle_name(value)
            if canonical:
                sanitized_cycle_trace[key] = canonical
        elif value is not None:
            string_value = str(value).strip()
            if string_value:
                sanitized_cycle_trace[key] = string_value
    cycle_trace_settings.update(sanitized_cycle_trace)
settings["cycle_trace"] = {
    key: cycle_trace_settings[key] for key in DEFAULT_CYCLE_TRACE_SETTINGS
}

_final_report_presets = settings.get("final_report_presets")
if not isinstance(_final_report_presets, dict):
    settings["final_report_presets"] = {}

_final_report_state = settings.get("final_report")
if not isinstance(_final_report_state, dict):
    _final_report_state = {}
    settings["final_report"] = _final_report_state

_default_sections = _normalize_final_report_section_order(
    FINAL_REPORT_DEFAULT_STATE.get("selected_sections", [])
)
_current_sections = _final_report_state.get("selected_sections")
if isinstance(_current_sections, list):
    _normalized_sections = []
    # Iterate over _current_sections to apply the per-item logic.
    for section_id in _current_sections:
        if isinstance(section_id, str) and section_id not in _normalized_sections:
            _normalized_sections.append(section_id)
else:
    _normalized_sections = list(_default_sections)

# One-time migration: combined_plot was omitted from the default order list in
# older settings, so older selected_sections never included it.
_combined_plot_migrated = bool(
    _final_report_state.get("combined_plot_migrated_v2_0_4")
)
if not _combined_plot_migrated and "combined_plot" in FINAL_REPORT_SECTION_METADATA:
    if "combined_plot" not in _normalized_sections:
        if "fig2" in _normalized_sections:
            insert_at = _normalized_sections.index("fig2") + 1
            _normalized_sections.insert(insert_at, "combined_plot")
        else:
            _normalized_sections.append("combined_plot")
    _combined_plot_migrated = True

if FINAL_REPORT_EXCLUDED_SECTIONS:
    _normalized_sections = [
        section_id
        # Iterate to apply the per-item logic.
        for section_id in _normalized_sections
        if section_id not in FINAL_REPORT_EXCLUDED_SECTIONS
    ]

_final_report_state["selected_sections"] = _normalized_sections
if _combined_plot_migrated:
    _final_report_state["combined_plot_migrated_v2_0_4"] = True
_state_section_order = _final_report_state.get("section_order")
if isinstance(_state_section_order, list):
    _final_report_state["section_order"] = _normalize_final_report_section_order(
        _state_section_order
    )
else:
    _final_report_state["section_order"] = _normalize_final_report_section_order(
        _normalized_sections,
        warn_missing=False,
    )

_final_report_state.setdefault("title", FINAL_REPORT_DEFAULT_STATE["title"])
_final_report_state.setdefault(
    "global_layout_mode", FINAL_REPORT_DEFAULT_STATE["global_layout_mode"]
)
_final_report_state.setdefault("fit_mode", FINAL_REPORT_DEFAULT_STATE["fit_mode"])
_final_report_state.setdefault("font_scale", FINAL_REPORT_DEFAULT_STATE["font_scale"])
_final_report_state.setdefault("margin_in", FINAL_REPORT_DEFAULT_STATE["margin_in"])
_final_report_state.setdefault(
    "safe_margin_preset", FINAL_REPORT_DEFAULT_STATE["safe_margin_preset"]
)
_final_report_state.setdefault(
    "show_page_numbers", FINAL_REPORT_DEFAULT_STATE["show_page_numbers"]
)
_final_report_state.setdefault(
    "show_section_headers", FINAL_REPORT_DEFAULT_STATE["show_section_headers"]
)
_final_report_state.setdefault(
    "table_style_preset", FINAL_REPORT_DEFAULT_STATE["table_style_preset"]
)
_final_report_state.setdefault("narrative", FINAL_REPORT_DEFAULT_STATE["narrative"])
_final_report_state.setdefault("profile_key", FINAL_REPORT_DEFAULT_STATE["profile_key"])

section_header_state = _final_report_state.setdefault("section_header_enabled", {})
# Iterate over FINAL_REPORT_DEFAULT_STATE["section_header_enabled"] to apply the per-item logic.
for section_id, header_enabled in FINAL_REPORT_DEFAULT_STATE[
    "section_header_enabled"
].items():
    section_header_state.setdefault(section_id, bool(header_enabled))

section_caption_state = _final_report_state.setdefault("section_caption_enabled", {})
# Iterate over FINAL_REPORT_DEFAULT_STATE["section_caption_enabled"] to apply the per-item logic.
for section_id, caption_enabled in FINAL_REPORT_DEFAULT_STATE[
    "section_caption_enabled"
].items():
    section_caption_state.setdefault(section_id, bool(caption_enabled))

section_caption_place_state = _final_report_state.setdefault(
    "section_caption_placement", {}
)
# Iterate over FINAL_REPORT_DEFAULT_STATE["section_caption_placement"] to apply the per-item logic.
for section_id, placement in FINAL_REPORT_DEFAULT_STATE[
    "section_caption_placement"
].items():
    section_caption_place_state.setdefault(section_id, placement)

orientation_state = _final_report_state.setdefault("section_orientation", {})
# Iterate to apply the per-item logic.
for section_id, orientation_value in FINAL_REPORT_DEFAULT_STATE[
    "section_orientation"
].items():
    orientation_state.setdefault(section_id, orientation_value)

_plot_selection_state = settings.get("plot_generation_selection")
if not isinstance(_plot_selection_state, dict):
    _plot_selection_state = {}
    settings["plot_generation_selection"] = _plot_selection_state
_plot_selection_state.setdefault("fig1", False)
_plot_selection_state.setdefault("fig2", False)
_plot_selection_state.setdefault("fig_combined", True)


CYCLE_TEMP_DEFAULT_LABEL = "Default (25 C)"


# GET_ALL_INPUTS Popup window

R = 0.08206  # L*atm/(mol*K)


def _normalize_gas_name(value: Optional[str]) -> str:
    """Normalize gas name.
    Used to keep gas name consistent across workflows and persistence."""
    if not isinstance(value, str):
        return ""
    normalized = unicodedata.normalize("NFKD", value)
    return "".join(ch for ch in normalized if ch.isalnum()).lower()


# Van der Waals presets (L^2*atm/mol^2 for a, L/mol for b)

BASE_GAS_PRESETS = OrderedDict(
    [
        ("Custom", None),
        ("NaHCO₃ (a=1.390, b=0.0391)", {"a": 1.390, "b": 0.0391, "formula": "NaHCO₃"}),
        ("CO₂ (a=3.592, b=0.0427)", {"a": 3.592, "b": 0.0427, "formula": "CO₂"}),
        ("CO (a=1.4514, b=0.03948)", {"a": 1.4514, "b": 0.03948, "formula": "CO"}),
        (
            "Hydrogen (a=0.24186, b=0.02651)",
            {"a": 0.24186, "b": 0.02651, "formula": "H₂"},
        ),
        (
            "Ethanol (a=12.38416, b=0.08710)",
            {"a": 12.38416, "b": 0.08710, "formula": "C₂H₆O"},
        ),
    ]
)

CUSTOM_GAS_PRESETS = OrderedDict()
GAS_PRESETS = OrderedDict(BASE_GAS_PRESETS)

_BASE_GAS_PRESET_NORMALIZED_NAMES = {
    _normalize_gas_name(name) for name in BASE_GAS_PRESETS.keys()
}


def _merge_gas_preset_sources():
    """Merge gas preset sources.
    Used to combine gas preset sources into a single result."""
    global GAS_PRESETS
    GAS_PRESETS = OrderedDict(BASE_GAS_PRESETS)


def _match_saved_gas_name(saved_name: Optional[str]) -> Optional[str]:
    """Perform match saved gas name.
    Used to keep the workflow logic localized and testable."""
    normalized = _normalize_gas_name(saved_name)
    if not normalized:
        return None
    # Iterate over keys from GAS_PRESETS to apply the per-item logic.
    for preset_name in GAS_PRESETS.keys():
        if _normalize_gas_name(preset_name) == normalized:
            return preset_name
    return None


def _normalize_gas_preset_entry(name, data):
    """Normalize gas preset entry.
    Used to keep gas preset entry consistent across workflows and persistence."""
    if not isinstance(name, str) or not name.strip():
        return None
    if not isinstance(data, dict):
        return None
    try:
        a_val = float(data.get("a"))
        b_val = float(data.get("b"))
    except (TypeError, ValueError):
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None
    if not math.isfinite(a_val) or a_val <= 0.0:
        return None
    if not math.isfinite(b_val):
        return None
    entry = {"a": float(a_val), "b": float(b_val)}
    formula = data.get("formula")
    if isinstance(formula, str) and formula.strip():
        entry["formula"] = formula.strip()
    molar = data.get("molar_mass")
    try:
        molar_val = float(molar)
    except (TypeError, ValueError):
        molar_val = None
    if molar_val is not None and math.isfinite(molar_val) and molar_val > 0.0:
        entry["molar_mass"] = float(molar_val)
    return entry


# Load custom gas presets after helper utilities are defined
_saved_custom_presets = settings.get("custom_gas_presets", {})
if not isinstance(_saved_custom_presets, dict):
    _saved_custom_presets = {}
    settings["custom_gas_presets"] = {}
CUSTOM_GAS_PRESETS.clear()
settings["custom_gas_presets"] = {}
_merge_gas_preset_sources()

_custom_preset_normalized_names = {
    _normalize_gas_name(name) for name in CUSTOM_GAS_PRESETS.keys()
}

_saved_vdw_name = settings.get("vdw_gas")
_matched_preset = _match_saved_gas_name(_saved_vdw_name)

if _matched_preset is not None:
    settings["vdw_gas"] = _matched_preset
elif _normalize_gas_name(_saved_vdw_name) in _custom_preset_normalized_names:
    pass
else:
    settings["vdw_gas"] = "Custom"

settings["ui_display_mode"] = _normalize_ui_display_mode(
    settings.get("ui_display_mode")
)
settings["plot_settings_card_order"] = _normalize_plot_settings_card_order(
    settings.get("plot_settings_card_order")
)


def _save_settings_to_disk() -> None:
    """Save settings to disk.
    Used when persisting settings to disk to storage."""
    with _SETTINGS_LOCK:
        settings_dir = os.path.dirname(os.path.abspath(SETTINGS_FILE)) or "."
        fd, tmp_path = tempfile.mkstemp(
            prefix=f"{os.path.basename(SETTINGS_FILE)}.", dir=settings_dir
        )
        try:
            with os.fdopen(fd, "w", encoding="utf-8") as handle:
                json.dump(settings, handle, indent=2, ensure_ascii=False)
                handle.flush()
                os.fsync(handle.fileno())
            os.replace(tmp_path, SETTINGS_FILE)
        finally:
            try:
                if os.path.exists(tmp_path):
                    os.unlink(tmp_path)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass


def prominence_safe(x):
    """Perform prominence safe.
    Used to keep the workflow logic localized and testable."""

    try:

        return max(float(x), 0.0)

    except Exception:

        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return 0.0


def _nearest_index(x_array, x_val):
    """Perform nearest index.
    Used to keep the workflow logic localized and testable."""

    import numpy as np

    x_array = np.asarray(x_array, dtype=float)

    return int(np.argmin(np.abs(x_array - float(x_val))))


def _build_cycles_from_markers(peaks_idx, troughs_idx, y_values):
    """Build cycles from markers.
    Used to assemble cycles from markers during UI or plot setup."""

    import numpy as np

    y = np.asarray(y_values, dtype=float)

    peaks = sorted(set(int(i) for i in peaks_idx))

    troughs = sorted(set(int(i) for i in troughs_idx))

    cycles = []

    t_ptr = 0

    # Iterate over peaks to apply the per-item logic.
    for pk in peaks:

        # advance trough pointer until trough > peak

        # Repeat while t_ptr < len(troughs) and troughs[t_ptr] <= pk to advance the looped workflow.
        while t_ptr < len(troughs) and troughs[t_ptr] <= pk:

            t_ptr += 1

        if t_ptr >= len(troughs):

            break

        tr = troughs[t_ptr]

        dP = float(y[pk] - y[tr])

        cycles.append(
            {
                "peak_idx": pk,
                "trough_idx": tr,
                "peak": float(y[pk]),
                "trough": float(y[tr]),
                "delta_P": float(dP),
            }
        )

    return cycles


def _mean_temp_C_between(temp_array_or_series, i, j, default_C: float = 25.0):
    """Perform mean temp c between.
    Used to keep the workflow logic localized and testable."""

    import numpy as np

    if temp_array_or_series is None:

        return float(default_C), True

    t = np.asarray(temp_array_or_series, dtype=float)

    lo, hi = (int(i), int(j)) if i <= j else (int(j), int(i))

    lo = max(lo, 0)

    hi = min(hi, t.size - 1)

    if hi < lo or t.size == 0:

        return float(default_C), True

    seg = t[lo : hi + 1]

    if seg.size and np.isfinite(seg).any():

        return float(np.nanmean(seg)), False

    return float(default_C), True


# =============================

# Analysis + Plotting functions

# =============================


def calculate_moles_ideal_from_deltaP(deltaP_atm, V_L, T_K):
    """Perform calculate moles ideal from deltap.
    Used to keep the workflow logic localized and testable."""

    try:

        return max((deltaP_atm * V_L) / (R * T_K), 0.0)

    except Exception as e:

        print(
            f"Warning: Ideal gas calc failed for Delta P={deltaP_atm:.4f} atm. Error: {e}"
        )

        return np.nan


def calculate_moles_vdw_from_deltaP(deltaP_atm, V_L, T_K, a, b):
    """Perform calculate moles VDW from deltap.
    Used to keep the workflow logic localized and testable."""

    if fsolve is None:

        return np.nan

    # Closure captures calculate_moles_vdw_from_deltaP local context to keep helper logic scoped and invoked directly within calculate_moles_vdw_from_deltaP.
    def vdw_equation(n, delta_p, V, T, a_, b_):
        """Perform VDW equation.
        Used to keep the workflow logic localized and testable."""

        return (delta_p + a_ * (n / V) ** 2) * (V - n * b_) - n * R * T

    initial_guess_n = (deltaP_atm * V_L) / (R * T_K)

    try:

        moles = fsolve(vdw_equation, initial_guess_n, args=(deltaP_atm, V_L, T_K, a, b))

        return max(float(moles[0]), 0.0)

    except Exception as e:

        print(
            f"Warning: Could not solve VDW for Delta P={deltaP_atm:.4f} atm. Error: {e}"
        )

        return np.nan


def _sanitize_non_negative(value):
    """Sanitize non negative.
    Used to strip or normalize non negative before use."""

    try:

        val = float(value)

    except Exception:

        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return float("nan")

    if not math.isfinite(val):

        return float("nan")

    if val < 0:

        if abs(val) < 1e-9:

            return 0.0

        return float("nan")

    return val


def calculate_moles_from_mass(mass_g, molar_mass):
    """Perform calculate moles from mass.
    Used to keep the workflow logic localized and testable."""

    mass = _sanitize_non_negative(mass_g)

    molar = _sanitize_non_negative(molar_mass)

    if (
        not math.isfinite(mass)
        or not math.isfinite(molar)
        or molar == 0.0
        or mass == 0.0
    ):

        return float("nan")

    return mass / molar


def mass_from_moles(moles, molar_mass):
    """Perform mass from moles.
    Used to keep the workflow logic localized and testable."""

    amount = _sanitize_non_negative(moles)

    molar = _sanitize_non_negative(molar_mass)

    if not math.isfinite(amount) or not math.isfinite(molar) or molar == 0.0:

        return float("nan")

    return amount * molar


def reaction_completion_percentage(actual_moles, theoretical_moles):
    """Perform reaction completion percentage.
    Used to keep the workflow logic localized and testable."""

    actual = _sanitize_non_negative(actual_moles)

    theoretical = _sanitize_non_negative(theoretical_moles)

    if (
        not math.isfinite(actual)
        or not math.isfinite(theoretical)
        or theoretical == 0.0
    ):

        return float("nan")

    return (actual / theoretical) * 100.0


def reaction_completion_ratio(theoretical_moles, actual_moles):
    """Perform reaction completion ratio.
    Used to keep the workflow logic localized and testable."""
    theoretical = _sanitize_non_negative(theoretical_moles)
    actual = _sanitize_non_negative(actual_moles)

    if not math.isfinite(theoretical) or not math.isfinite(actual) or actual == 0.0:
        return float("nan")

    return theoretical / actual


def compute_reagent_metrics(
    total_moles_ideal,
    total_moles_vdw,
    *,
    vdw_available,
    starting_mass_g,
    starting_molar_mass,
    product_name,
    product_formula,
    product_output_molar_mass,
):
    """Compute reagent metrics.
    Used to derive reagent metrics for analysis or plotting."""
    # Deprecated for Cycle Analysis Summary; retained for backward compatibility.
    start_molar_value = _sanitize_non_negative(starting_molar_mass)
    if not math.isfinite(start_molar_value) or start_molar_value == 0.0:
        start_molar_value = float("nan")

    product_molar_value = _sanitize_non_negative(product_output_molar_mass)
    if not math.isfinite(product_molar_value) or product_molar_value == 0.0:
        product_molar_value = float("nan")

    starting_mass_value = _sanitize_non_negative(starting_mass_g)

    theoretical_moles = calculate_moles_from_mass(
        starting_mass_value, start_molar_value
    )

    expected_mass = mass_from_moles(theoretical_moles, product_molar_value)

    completion_ratio_ideal = reaction_completion_ratio(
        theoretical_moles, total_moles_ideal
    )

    completion_percent_ideal = reaction_completion_percentage(
        total_moles_ideal, theoretical_moles
    )

    if vdw_available:
        completion_ratio_vdw = reaction_completion_ratio(
            theoretical_moles, total_moles_vdw
        )
        completion_percent_vdw = reaction_completion_percentage(
            total_moles_vdw, theoretical_moles
        )
    else:
        completion_ratio_vdw = float("nan")
        completion_percent_vdw = float("nan")

    return {
        "product_name": str(product_name) if product_name else DEFAULT_PRODUCT_NAME,
        "product_formula": (
            str(product_formula) if product_formula else DEFAULT_PRODUCT_FORMULA
        ),
        "starting_molar_mass": start_molar_value,
        "product_output_molar_mass": product_molar_value,
        "starting_mass_g": starting_mass_value,
        "theoretical_moles": theoretical_moles,
        "expected_mass_g": expected_mass,
        "completion_ratio_ideal": completion_ratio_ideal,
        "completion_ratio_vdw": completion_ratio_vdw,
        "completion_percent_ideal": completion_percent_ideal,
        "completion_percent_vdw": completion_percent_vdw,
        "vdw_available": bool(vdw_available),
    }


def format_reagent_consumption_lines(metrics):
    """Format reagent consumption lines.
    Used to prepare reagent consumption lines for display or export."""
    # Deprecated for Cycle Analysis Summary; retained for backward compatibility.
    lines = []

    name = metrics.get("product_name") or DEFAULT_PRODUCT_NAME
    formula = metrics.get("product_formula") or DEFAULT_PRODUCT_FORMULA
    theoretical = metrics.get("theoretical_moles", math.nan)
    expected_mass = metrics.get("expected_mass_g", math.nan)
    ratio_ideal = metrics.get("completion_ratio_ideal", math.nan)
    pct_ideal = metrics.get("completion_percent_ideal", math.nan)
    ratio_vdw = metrics.get("completion_ratio_vdw", math.nan)
    pct_vdw = metrics.get("completion_percent_vdw", math.nan)
    vdw_available = metrics.get("vdw_available", False)
    start_molar_mass = metrics.get("starting_molar_mass", math.nan)
    product_output_molar_mass = metrics.get("product_output_molar_mass", math.nan)
    starting_mass = metrics.get("starting_mass_g", math.nan)

    lines.append(f"--- Gaseous Reagent Consumption ({name}) ---")

    if math.isfinite(theoretical):
        lines.append(f"Theoretical moles required: {theoretical:.6f} mol")
    else:
        lines.append(
            "Theoretical moles required: unavailable (provide starting material mass and molar mass)."
        )

    if math.isfinite(expected_mass):
        lines.append(
            f"Expected mass of {formula} to be consumed: {expected_mass:.2f} g"
        )
    else:
        lines.append(
            "Expected mass of {formula} to be consumed: unavailable (provide starting material mass and molar mass).".format(
                formula=formula
            )
        )

    if math.isfinite(ratio_ideal) and ratio_ideal > 0.0 and math.isfinite(pct_ideal):
        lines.append(
            f"Reaction completion (Ideal): theoretical/measured = {pct_ideal:.2f}% of theoretical"
        )
    else:
        lines.append("Reaction completion (Ideal): N/A")

    if vdw_available:
        if math.isfinite(ratio_vdw) and ratio_vdw > 0.0 and math.isfinite(pct_vdw):
            lines.append(
                f"Reaction completion (VDW): theoretical/measured = {pct_vdw:.2f}% of theoretical"
            )
        else:
            lines.append("Reaction completion (VDW): N/A")
    else:
        lines.append("Reaction completion (VDW): N/A (SciPy not installed)")

    lines.append("")
    lines.append("--- Gaseous Reagent Inputs ---")
    lines.append(f"Gaseous reagent preset: {name}")

    molar_label = f"Gaseous Reagent ({formula})" if formula else "Gaseous Reagent"
    if math.isfinite(product_output_molar_mass):
        lines.append(
            f"{molar_label} molar mass used: {product_output_molar_mass:.4f} g/mol"
        )
    else:
        lines.append(f"{molar_label} molar mass used: not available")

    if math.isfinite(start_molar_mass):
        lines.append(f"Starting material molar mass: {start_molar_mass:.4f} g/mol")
    else:
        lines.append("Starting material molar mass: not provided")

    if math.isfinite(starting_mass):
        lines.append(f"Starting material mass: {starting_mass:.4f} g")
    else:
        lines.append("Starting material mass: not provided")

    return lines


@dataclass(frozen=True)
class CycleSummaryOptions:
    compact: bool = True
    include_diagnostics: bool = False
    include_per_cycle_gas_mass: bool = False
    include_conversion_estimate: bool = False


@dataclass(frozen=True)
class ResolvedCycleSummaryInputs:
    selection_mode: str
    min_cycle_drop_psi: float
    ignore_min_cycle_drop: bool
    peak_prominence: Optional[float]
    peak_distance: Optional[int]
    peak_width: Optional[int]
    temp_column_label: str
    default_temp_value_c: float
    default_temp_count: int
    volume_l: float
    vdw_a: float
    vdw_b: float
    vdw_gas_label: str
    gas_molar_mass_g_mol: Optional[float]
    mw_override_active: bool
    ab_override_active: bool
    scipy_available: bool
    vdw_computed: bool
    starting_material_name: str
    starting_material_formula: str
    starting_material_mass_g: Optional[float]
    starting_material_mw_g_mol: Optional[float]
    stoich_mol_gas_per_mol_starting: Optional[float]


def resolve_cycle_summary_options(settings: Mapping[str, Any]) -> CycleSummaryOptions:
    """Resolve cycle summary options.
    Used to compute cycle summary options before rendering or export."""
    return CycleSummaryOptions(
        compact=bool(settings.get("summary_compact", True)),
        include_diagnostics=bool(settings.get("summary_include_diagnostics", False)),
        include_per_cycle_gas_mass=bool(
            settings.get("summary_include_per_cycle_gas_mass", False)
        ),
        include_conversion_estimate=bool(
            settings.get("summary_include_conversion_estimate", False)
        ),
    )


def resolve_cycle_summary_inputs(
    settings: Mapping[str, Any],
    *,
    globals_fallback: Mapping[str, Any],
    context: Optional[Dict[str, Any]] = None,
) -> ResolvedCycleSummaryInputs:
    """Resolve cycle summary inputs.
    Used to compute cycle summary inputs before rendering or export."""
    ctx = context or {}

    def _float_or_none(value):
        """Perform float or none.
        Used to keep the workflow logic localized and testable."""
        try:
            candidate = float(value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        if not math.isfinite(candidate):
            return None
        return candidate

    def _int_or_none(value):
        """Perform int or none.
        Used to keep the workflow logic localized and testable."""
        try:
            return int(value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None

    selection_mode = str(ctx.get("selection_mode") or "Auto")
    min_cycle_drop = _float_or_none(
        ctx.get("min_cycle_drop_psi", ctx.get("min_cycle_drop", settings.get("min_cycle_drop")))
    )
    if min_cycle_drop is None:
        min_cycle_drop = 0.0
    ignore_min_cycle_drop = bool(ctx.get("ignore_min_drop", False))

    peak_prominence = _float_or_none(
        ctx.get("peak_prominence", settings.get("peak_prominence"))
    )
    peak_distance = _int_or_none(ctx.get("peak_distance", settings.get("peak_distance")))
    peak_width = _int_or_none(ctx.get("peak_width", settings.get("peak_width")))

    temp_column = ctx.get("temp_column_label", settings.get("cycle_temp_column"))
    temp_column = temp_column or CYCLE_TEMP_DEFAULT_LABEL
    per_cycle = ctx.get("per_cycle") or []
    default_temp_count = 0
    # Iterate over per_cycle to apply the per-item logic.
    for row in per_cycle:
        if row.get("used_default"):
            default_temp_count += 1

    volume_l = _float_or_none(
        ctx.get("volume", ctx.get("volume_l", settings.get("vessel_volume")))
    )
    if volume_l is None:
        volume_l = _float_or_none(globals_fallback.get("volume")) or 1.0

    vdw_a = _float_or_none(ctx.get("a_const", settings.get("vdw_a")))
    if vdw_a is None:
        vdw_a = _float_or_none(globals_fallback.get("a_const")) or 1.39

    vdw_b = _float_or_none(ctx.get("b_const", settings.get("vdw_b")))
    if vdw_b is None:
        vdw_b = _float_or_none(globals_fallback.get("b_const")) or 0.0391

    vdw_gas_label = str(settings.get("vdw_gas") or "Custom")
    preset = GAS_PRESETS.get(vdw_gas_label)
    preset_a = preset.get("a") if isinstance(preset, dict) else None
    preset_b = preset.get("b") if isinstance(preset, dict) else None
    preset_mw = preset.get("molar_mass") if isinstance(preset, dict) else None
    overrides = settings.get("gas_preset_overrides", {})
    if not isinstance(overrides, dict):
        overrides = {}
    override_entry = overrides.get(vdw_gas_label) if isinstance(overrides, dict) else None
    override_mw = None
    if isinstance(override_entry, dict):
        override_mw = override_entry.get("molar_mass")

    gas_molar_mass = _float_or_none(
        ctx.get("gas_molar_mass", settings.get("vdw_gas_molar_mass"))
    )
    if gas_molar_mass is None:
        gas_molar_mass = _float_or_none(override_mw)
    if gas_molar_mass is None:
        gas_molar_mass = _float_or_none(preset_mw)

    mw_override_active = False
    if _float_or_none(override_mw) is not None:
        mw_override_active = True
    elif preset_mw is not None and gas_molar_mass is not None:
        try:
            mw_override_active = abs(float(gas_molar_mass) - float(preset_mw)) > 1e-6
        except Exception:
            mw_override_active = False
    elif vdw_gas_label.lower() == "custom" and gas_molar_mass is not None:
        mw_override_active = True

    ab_override_active = False
    if preset_a is not None and preset_b is not None:
        try:
            ab_override_active = (
                abs(float(vdw_a) - float(preset_a)) > 1e-6
                or abs(float(vdw_b) - float(preset_b)) > 1e-6
            )
        except Exception:
            ab_override_active = False
    elif vdw_gas_label.lower() == "custom":
        ab_override_active = True

    scipy_available = bool(ctx.get("scipy_available", fsolve is not None))
    vdw_computed = bool(ctx.get("vdw_computed", ctx.get("vdw_used", False)))

    display_name = settings.get("starting_material_display_name")
    if isinstance(display_name, str):
        display_name = display_name.strip()
    else:
        display_name = ""
    legacy_name = str(
        settings.get("starting_material_name", settings.get("product_name", ""))
        or ""
    ).strip()
    legacy_formula = str(
        settings.get(
            "starting_material_formula",
            settings.get("product_formula", DEFAULT_STARTING_MATERIAL_FORMULA),
        )
        or ""
    ).strip()
    if not display_name:
        display_name = legacy_name or legacy_formula
    starting_material_name = display_name
    starting_material_formula = legacy_formula
    starting_material_mass_g = _float_or_none(
        settings.get(
            "starting_material_mass_g",
            settings.get("starting_mass", globals_fallback.get("starting_mass_g")),
        )
    )
    starting_material_mw_g_mol = _float_or_none(
        settings.get(
            "starting_material_mw_g_mol",
            settings.get("product_molar_mass", globals_fallback.get("product_molar_mass")),
        )
    )
    stoich_mol_gas_per_mol_starting = _float_or_none(
        settings.get("stoich_mol_gas_per_mol_starting")
    )

    return ResolvedCycleSummaryInputs(
        selection_mode=selection_mode,
        min_cycle_drop_psi=float(min_cycle_drop),
        ignore_min_cycle_drop=bool(ignore_min_cycle_drop),
        peak_prominence=peak_prominence,
        peak_distance=peak_distance,
        peak_width=peak_width,
        temp_column_label=str(temp_column),
        default_temp_value_c=25.0,
        default_temp_count=int(default_temp_count),
        volume_l=float(volume_l),
        vdw_a=float(vdw_a),
        vdw_b=float(vdw_b),
        vdw_gas_label=str(vdw_gas_label),
        gas_molar_mass_g_mol=gas_molar_mass,
        mw_override_active=bool(mw_override_active),
        ab_override_active=bool(ab_override_active),
        scipy_available=bool(scipy_available),
        vdw_computed=bool(vdw_computed),
        starting_material_name=starting_material_name,
        starting_material_formula=starting_material_formula,
        starting_material_mass_g=starting_material_mass_g,
        starting_material_mw_g_mol=starting_material_mw_g_mol,
        stoich_mol_gas_per_mol_starting=stoich_mol_gas_per_mol_starting,
    )


def compute_gas_mass_from_moles(
    n_moles: Optional[float], mw_g_mol: Optional[float]
) -> Optional[float]:
    """Compute gas mass from moles.
    Used to derive gas mass from moles for analysis or plotting."""
    try:
        moles_val = float(n_moles)
        mw_val = float(mw_g_mol)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None
    if not math.isfinite(moles_val) or not math.isfinite(mw_val):
        return None
    if mw_val <= 0.0:
        return None
    return moles_val * mw_val


def compute_conversion_estimate(
    n_gas: Optional[float],
    starting_mass_g: Optional[float],
    starting_mw_g_mol: Optional[float],
    stoich_mol_gas_per_mol_starting: Optional[float],
) -> Tuple[Optional[float], Optional[float]]:
    """Compute conversion estimate.
    Used to derive conversion estimate for analysis or plotting."""
    starting_moles = calculate_moles_from_mass(
        starting_mass_g, starting_mw_g_mol
    )
    stoich_val = _sanitize_non_negative(stoich_mol_gas_per_mol_starting)
    if not math.isfinite(stoich_val) or stoich_val <= 0.0:
        return None, None
    if not math.isfinite(starting_moles) or starting_moles <= 0.0:
        return None, None
    theoretical_moles = starting_moles * stoich_val
    if not math.isfinite(theoretical_moles) or theoretical_moles <= 0.0:
        return None, None
    actual = _sanitize_non_negative(n_gas)
    if not math.isfinite(actual):
        return theoretical_moles, None
    return theoretical_moles, actual / theoretical_moles


def build_cycle_analysis_summary(
    cycles,
    per_cycle,
    total_drop_psi: Optional[float],
    total_moles_ideal: Optional[float],
    total_moles_vdw: Optional[float],
    *,
    vdw_used: bool,
    scipy_available: bool,
    resolved_inputs: ResolvedCycleSummaryInputs,
    options: CycleSummaryOptions,
) -> str:
    """Build cycle analysis summary.
    Used to assemble cycle analysis summary during UI or plot setup."""
    cycles = list(cycles or [])
    per_cycle_rows = list(per_cycle or [])
    cycle_count = len(cycles) if cycles else len(per_cycle_rows)

    def _fmt(value, fmt, na="N/A"):
        """Perform fmt.
        Used to keep the workflow logic localized and testable."""
        try:
            val = float(value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return na
        if not math.isfinite(val):
            return na
        return f"{val:{fmt}}"

    def _fmt_pct(value, na="N/A"):
        """Perform fmt pct.
        Used to keep the workflow logic localized and testable."""
        return _fmt(value, ".2f", na=na) + "%"

    vdw_total_ok = math.isfinite(_safe_float(total_moles_vdw, float("nan")))
    vdw_available = bool(vdw_used and scipy_available and vdw_total_ok)
    gas_mw = resolved_inputs.gas_molar_mass_g_mol
    has_gas_mw = gas_mw is not None and math.isfinite(gas_mw) and gas_mw > 0.0

    lines: List[str] = []
    if not options.compact:
        lines.append("Cycle Analysis Summary")

    def _section(title: str, *, leading_blank: bool = True) -> None:
        """Perform section.
        Used to keep the workflow logic localized and testable."""
        if leading_blank:
            lines.append("")
        if options.compact:
            lines.append(title)
        else:
            lines.append(f"=== {title} ===")

    _section("Inputs used", leading_blank=bool(lines))
    lines.append(f"Mode: {resolved_inputs.selection_mode}")
    lines.append(f"Valid cycles: {cycle_count}")
    lines.append(
        f"Threshold: min dP = {_fmt(resolved_inputs.min_cycle_drop_psi, '.2f')} PSI"
    )
    if resolved_inputs.ignore_min_cycle_drop:
        lines.append("Note: minimum dP threshold ignored for this analysis.")
    lines.append(f"Total uptake: dP_total = {_fmt(total_drop_psi, '.2f')} PSI")

    if resolved_inputs.peak_prominence is not None:
        prom_text = _fmt(resolved_inputs.peak_prominence, ".2f")
        dist_text = (
            str(resolved_inputs.peak_distance)
            if resolved_inputs.peak_distance is not None
            else "N/A"
        )
        width_text = (
            str(resolved_inputs.peak_width)
            if resolved_inputs.peak_width is not None
            else "N/A"
        )
        lines.append(
            f"Peak detection: prominence={prom_text}, distance={dist_text}, width={width_text}"
        )

    temp_label = resolved_inputs.temp_column_label or CYCLE_TEMP_DEFAULT_LABEL
    if cycle_count > 0:
        default_count = resolved_inputs.default_temp_count
        if temp_label == CYCLE_TEMP_DEFAULT_LABEL:
            lines.append(
                f"Temp basis: {temp_label} (used {default_count}/{cycle_count} cycles)"
            )
        else:
            if default_count:
                lines.append(
                    "Temp basis: "
                    f"{temp_label} (default 25 C used {default_count}/{cycle_count})"
                )
            else:
                lines.append(f"Temp basis: {temp_label} (no defaults used)")
    else:
        lines.append(f"Temp basis: {temp_label}")

    _section("Gas model inputs used")
    lines.append(f"Preset: {resolved_inputs.vdw_gas_label}")
    lines.append(f"Vessel volume: {_fmt(resolved_inputs.volume_l, '.3f')} L")
    lines.append(
        f"VDW a: {_fmt(resolved_inputs.vdw_a, '.4f')}, b: {_fmt(resolved_inputs.vdw_b, '.4f')}"
    )

    if has_gas_mw:
        mw_note = " (override)" if resolved_inputs.mw_override_active else ""
        if resolved_inputs.vdw_gas_label.lower() == "custom" and not mw_note:
            mw_note = " (custom)"
        lines.append(
            f"Gas MW: {_fmt(resolved_inputs.gas_molar_mass_g_mol, '.4f')} g/mol{mw_note}"
        )
    else:
        lines.append("Gas MW: N/A")

    if resolved_inputs.ab_override_active:
        lines.append("VDW preset override: a/b")

    lines.append(f"SciPy available: {'Yes' if scipy_available else 'No'}")
    vdw_text = "Yes" if vdw_used and scipy_available else "No"
    if not scipy_available:
        vdw_text = "No (SciPy unavailable)"
    lines.append(f"VDW computed: {vdw_text}")

    _section("Gas uptake totals")
    lines.append(
        f"Total moles (Ideal): {_fmt(total_moles_ideal, '.6f')} mol"
    )
    if vdw_available:
        lines.append(f"Total moles (VDW): {_fmt(total_moles_vdw, '.6f')} mol")
    elif not scipy_available:
        lines.append("Total moles (VDW): N/A (SciPy not installed)")
    else:
        lines.append("Total moles (VDW): N/A")

    if has_gas_mw:
        mass_ideal = compute_gas_mass_from_moles(total_moles_ideal, gas_mw)
        lines.append(
            f"Total gas mass (Ideal): {_fmt(mass_ideal, '.4f')} g"
        )
        if vdw_available:
            mass_vdw = compute_gas_mass_from_moles(total_moles_vdw, gas_mw)
            lines.append(
                f"Total gas mass (VDW): {_fmt(mass_vdw, '.4f')} g"
            )
        elif not scipy_available:
            lines.append("Total gas mass (VDW): N/A (SciPy not installed)")
        else:
            lines.append("Total gas mass (VDW): N/A")
    else:
        lines.append("Total gas mass (Ideal): N/A (gas MW not set)")
        if not scipy_available:
            lines.append("Total gas mass (VDW): N/A (SciPy not installed)")
        else:
            lines.append("Total gas mass (VDW): N/A")

    if vdw_available and math.isfinite(_safe_float(total_moles_ideal, float("nan"))):
        if float(total_moles_ideal) != 0.0:
            pct = abs(
                100.0
                * (float(total_moles_vdw) - float(total_moles_ideal))
                / float(total_moles_ideal)
            )
            lines.append(f"VDW vs Ideal difference: {_fmt(pct, '.2f')}%")
        else:
            lines.append("VDW vs Ideal difference: N/A (no valid Ideal moles)")
    elif not scipy_available:
        lines.append("VDW vs Ideal difference: N/A (SciPy not installed)")

    if cycle_count:
        _section("Per-cycle uptake")
        # Iterate over indexed elements from per_cycle_rows, 1 to apply the per-item logic.
        for idx, row in enumerate(per_cycle_rows, 1):
            delta_psi = row.get("deltaP", float("nan"))
            mean_temp = row.get("T_mean_C", float("nan"))
            used_default = bool(row.get("used_default"))
            ideal_moles = row.get("n_ideal", float("nan"))
            vdw_moles = row.get("n_vdw", float("nan"))
            delta_text = _fmt(delta_psi, ".2f")
            temp_text = _fmt(mean_temp, ".2f")
            ideal_text = _fmt(ideal_moles, ".6f")
            vdw_text = _fmt(vdw_moles, ".6f")
            suffix = " (default T)" if used_default else ""
            line = (
                f"Cycle {idx}: dP={delta_text} PSI, T_mean={temp_text} C{suffix}, "
                f"n_ideal={ideal_text} mol"
            )
            if vdw_available:
                line += f", n_vdw={vdw_text} mol"
            elif math.isfinite(_safe_float(vdw_moles, float("nan"))):
                line += f", n_vdw={vdw_text} mol"
            else:
                line += ", n_vdw=N/A"

            if options.include_per_cycle_gas_mass and has_gas_mw:
                mass_ideal = compute_gas_mass_from_moles(ideal_moles, gas_mw)
                if mass_ideal is not None:
                    line += f", m_ideal={_fmt(mass_ideal, '.4f')} g"
                if vdw_available:
                    mass_vdw = compute_gas_mass_from_moles(vdw_moles, gas_mw)
                    if mass_vdw is not None:
                        line += f", m_vdw={_fmt(mass_vdw, '.4f')} g"
            lines.append(line)
    else:
        _section("Per-cycle uptake")
        lines.append("No valid cycles.")

    if options.include_diagnostics:
        _section("Diagnostics")
        if not cycle_count:
            lines.append("No cycles available.")
        else:
            lines.append(
                "Default temp usage: "
                f"{resolved_inputs.default_temp_count}/{cycle_count} cycles "
                f"at {resolved_inputs.default_temp_value_c:.0f} C"
            )
            # Iterate over indexed elements from per_cycle_rows, 1 to apply the per-item logic.
            for idx, row in enumerate(per_cycle_rows, 1):
                peak_val = row.get("peak", float("nan"))
                trough_val = row.get("trough", float("nan"))
                used_default = bool(row.get("used_default"))
                peak_text = _fmt(peak_val, ".2f")
                trough_text = _fmt(trough_val, ".2f")
                default_text = "Yes" if used_default else "No"
                lines.append(
                    f"Cycle {idx}: peak={peak_text} PSI, trough={trough_text} PSI, "
                    f"default T used={default_text}"
                )

    missing_fields: List[str] = []
    if (
        resolved_inputs.starting_material_mass_g is None
        or resolved_inputs.starting_material_mass_g <= 0.0
    ):
        missing_fields.append("starting_material_mass_g")
    if (
        resolved_inputs.starting_material_mw_g_mol is None
        or resolved_inputs.starting_material_mw_g_mol <= 0.0
    ):
        missing_fields.append("starting_material_mw_g_mol")
    if (
        resolved_inputs.stoich_mol_gas_per_mol_starting is None
        or resolved_inputs.stoich_mol_gas_per_mol_starting <= 0.0
    ):
        missing_fields.append("stoich_mol_gas_per_mol_starting")

    if options.include_conversion_estimate and not missing_fields:
        _section("Conversion estimate")
        lines.append(f"Gas used for uptake: {resolved_inputs.vdw_gas_label}")
        name = (resolved_inputs.starting_material_name or "").strip()
        lines.append(f"Starting material: {name}")
        lines.append(
            "Starting material mass: "
            f"{_fmt(resolved_inputs.starting_material_mass_g, '.4f')} g"
        )
        lines.append(
            "Starting material MW: "
            f"{_fmt(resolved_inputs.starting_material_mw_g_mol, '.4f')} g/mol"
        )
        lines.append(
            "Stoichiometry: "
            f"{_fmt(resolved_inputs.stoich_mol_gas_per_mol_starting, '.4f')} mol gas/mol starting"
        )

        theoretical, completion_ideal = compute_conversion_estimate(
            total_moles_ideal,
            resolved_inputs.starting_material_mass_g,
            resolved_inputs.starting_material_mw_g_mol,
            resolved_inputs.stoich_mol_gas_per_mol_starting,
        )
        lines.append(f"Theoretical gas moles: {_fmt(theoretical, '.6f')} mol")
        if completion_ideal is not None and math.isfinite(completion_ideal):
            lines.append(f"Completion (Ideal): {_fmt_pct(completion_ideal * 100.0)}")
        else:
            lines.append("Completion (Ideal): N/A")

        if vdw_available:
            _, completion_vdw = compute_conversion_estimate(
                total_moles_vdw,
                resolved_inputs.starting_material_mass_g,
                resolved_inputs.starting_material_mw_g_mol,
                resolved_inputs.stoich_mol_gas_per_mol_starting,
            )
            if completion_vdw is not None and math.isfinite(completion_vdw):
                lines.append(
                    f"Completion (VDW): {_fmt_pct(completion_vdw * 100.0)}"
                )
            else:
                lines.append("Completion (VDW): N/A")
        elif not scipy_available:
            lines.append("Completion (VDW): N/A (SciPy not installed)")
        else:
            lines.append("Completion (VDW): N/A")

    return "\n".join([line for line in lines if line is not None])


def _get_peak_finder():
    """Return peak finder.
    Used to retrieve peak finder for downstream logic."""

    if find_peaks is not None:

        return find_peaks

    return _FALLBACK_FIND_PEAKS


def _suggest_max_workers(task_count: int, *, hard_cap: int = 32) -> int:
    """Perform suggest max workers.
    Used to keep the workflow logic localized and testable."""

    try:

        count = int(task_count)

    except Exception:

        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return 1

    if count <= 1:

        return 1

    cpu_total = os.cpu_count() or 1

    return max(1, min(count, cpu_total, int(hard_cap)))


def _compute_cycle_metrics_single(
    cycle,
    *,
    z_array,
    V_L: float,
    a_c: float,
    b_c: float,
    compute_vdw: bool,
):
    """Compute cycle metrics single.
    Used to derive cycle metrics single for analysis or plotting."""

    dP_psi = float(cycle.get("delta_P", 0.0))

    dP_atm = dP_psi / 14.696

    peak_idx = cycle.get("peak_idx")

    trough_idx = cycle.get("trough_idx")

    T_mean_C, used_default = _mean_temp_C_between(
        z_array, peak_idx, trough_idx, default_C=25.0
    )

    T_K = T_mean_C + 273.15

    n_ideal = calculate_moles_ideal_from_deltaP(dP_atm, V_L, T_K)

    if compute_vdw:

        n_vdw = calculate_moles_vdw_from_deltaP(dP_atm, V_L, T_K, a_c, b_c)

    else:

        n_vdw = np.nan

    return (
        dict(
            peak=float(cycle.get("peak", np.nan)),
            trough=float(cycle.get("trough", np.nan)),
            deltaP=dP_psi,
            T_mean_C=float(T_mean_C),
            used_default=bool(used_default),
            n_ideal=float(n_ideal),
            n_vdw=float(n_vdw) if np.isfinite(n_vdw) else float("nan"),
        ),
        float(n_ideal),
        float(n_vdw),
    )


def _compute_cycle_statistics(
    cycles,
    temp_values,
    volume,
    a_const,
    b_const,
    *,
    allow_threads: bool = True,
    force_vdw: bool = False,
):
    """Compute cycle statistics.
    Used to derive cycle statistics for analysis or plotting."""

    cycles = list(cycles or [])

    if not cycles:

        scipy_available = fsolve is not None

        return [], 0.0, 0.0, scipy_available, False

    if temp_values is None:

        z_array = None

    elif isinstance(temp_values, np.ndarray):

        z_array = temp_values

    else:

        z_array = np.asarray(temp_values, dtype=float)

    try:

        V_L = float(volume)

    except Exception:

        V_L = 1.0

    try:

        a_c = float(a_const)

    except Exception:

        a_c = 1.39

    try:

        b_c = float(b_const)

    except Exception:

        b_c = 0.0391

    scipy_available = fsolve is not None

    compute_vdw = force_vdw or scipy_available

    compute = partial(
        _compute_cycle_metrics_single,
        z_array=z_array,
        V_L=V_L,
        a_c=a_c,
        b_c=b_c,
        compute_vdw=compute_vdw,
    )

    totals_ideal = []

    totals_vdw = []

    per_cycle = []

    worker_count = _suggest_max_workers(len(cycles)) if allow_threads else 1

    if worker_count <= 1:

        iterator = map(compute, cycles)

        # Iterate over iterator to apply the per-item logic.
        for per_cycle_entry, n_ideal, n_vdw in iterator:

            per_cycle.append(per_cycle_entry)

            totals_ideal.append(float(n_ideal))

            if compute_vdw:

                totals_vdw.append(float(n_vdw))

    else:

        with ThreadPoolExecutor(max_workers=worker_count) as executor:

            # Iterate over executor.map(compute, cycles) to apply the per-item logic.
            for per_cycle_entry, n_ideal, n_vdw in executor.map(compute, cycles):

                per_cycle.append(per_cycle_entry)

                totals_ideal.append(float(n_ideal))

                if compute_vdw:

                    totals_vdw.append(float(n_vdw))

    total_moles_ideal = float(math.fsum(totals_ideal))

    total_moles_vdw = float(math.fsum(totals_vdw)) if compute_vdw else 0.0

    return per_cycle, total_moles_ideal, total_moles_vdw, scipy_available, compute_vdw


def _simulate_large_cycle_dataset(
    num_points: int = 500_000,
    *,
    cycles: int = 120,
    noise: float = 0.35,
    base_pressure: float = 800.0,
    seed=None,
):
    """Perform simulate large cycle dataset.
    Used to keep the workflow logic localized and testable."""

    num_points = max(int(num_points), 10)

    cycles = max(int(cycles), 1)

    rng = np.random.default_rng(seed)

    idx = np.arange(num_points, dtype=float)

    cycle_length = max(num_points // cycles, 2)

    # Simulate a gradually decaying pressure with sinusoidal cycles and noise

    trend = np.linspace(0.0, -75.0, num_points)

    signal = 35.0 * np.sin(2 * np.pi * idx / cycle_length)

    harmonics = 5.0 * np.sin(4 * np.pi * idx / cycle_length)

    pressure = base_pressure + trend + signal + harmonics

    pressure += rng.normal(0.0, float(noise), size=num_points)

    # Temperatures oscillate more slowly with low noise

    temp_signal = 3.0 * np.sin(2 * np.pi * idx / (cycle_length * 3))

    temperature = 25.0 + temp_signal + rng.normal(0.0, 0.25, size=num_points)

    # Simulated elapsed time in days

    elapsed_days = idx / 1440.0  # assume one sample per minute

    return (
        pd.Series(pressure),
        pd.Series(temperature),
        pd.Series(elapsed_days),
    )


def _run_cycle_benchmark(num_points=500_000, cycles=120, noise=0.35) -> None:
    """Run cycle benchmark.
    Used to execute cycle benchmark and coordinate results."""

    pressure, temperature, elapsed = _simulate_large_cycle_dataset(
        num_points,
        cycles=cycles,
        noise=noise,
    )

    start = time.perf_counter()

    result = analyze_pressure_cycles(
        pressure_series=pressure,
        temp_series=temperature,
        volume=globals().get("volume", 1.0),
        a_const=globals().get("a_const", 1.39),
        b_const=globals().get("b_const", 0.0391),
        min_cycle_drop=5.0,
        make_figure=False,
        x_series=elapsed,
        auto_time_ticks=True,
        auto_y_ticks=True,
    )

    elapsed_s = time.perf_counter() - start

    summary = result[1] if isinstance(result, tuple) and len(result) > 1 else ""

    print(
        "Synthetic benchmark complete:",
        f"{int(num_points)} samples across {int(cycles)} cycles in {elapsed_s:.2f} s",
    )

    if summary:

        print("Summary excerpt:")

        # Iterate over str(summary).splitlines()[ to apply the per-item logic.
        for line in str(summary).splitlines()[:6]:

            print(f"  {line}")


def _maybe_run_cli_benchmark(argv) -> bool:
    """Run cli benchmark.
    Used by maybe workflows to run cli benchmark."""

    if not argv:

        return False

    run = False

    params = dict(num_points=500_000, cycles=120, noise=0.35)

    # Iterate over argv to apply the per-item logic.
    for arg in argv:

        if arg == "--benchmark":

            run = True

        elif arg.startswith("--points="):

            try:

                params["num_points"] = max(10, int(float(arg.split("=", 1)[1])))

            except ValueError:

                print(f"Ignoring invalid --points value: {arg}")

        elif arg.startswith("--cycles="):

            try:

                params["cycles"] = max(1, int(float(arg.split("=", 1)[1])))

            except ValueError:

                print(f"Ignoring invalid --cycles value: {arg}")

        elif arg.startswith("--noise="):

            try:

                params["noise"] = max(0.0, float(arg.split("=", 1)[1]))

            except ValueError:

                print(f"Ignoring invalid --noise value: {arg}")

    if not run:

        return False

    print("Running synthetic multi-threaded benchmark with parameters:", params)

    _run_cycle_benchmark(**params)

    return True


def detect_valid_cycles(
    pressure_series, min_cycle_drop, *, prominence=1.0, distance=1, width=1
):
    """Detect valid cycles.
    Used to decide runtime capabilities or configuration."""

    peak_finder = _get_peak_finder()

    if peak_finder is None:

        raise ModuleNotFoundError(_scipy_missing_message("automatic cycle detection"))

    p = np.asarray(pressure_series, dtype=float)

    # Find peaks (maxima) and troughs (minima via -p) using user-tunable params

    peak_idx, _ = peak_finder(p, prominence=prominence, distance=distance, width=width)

    trough_idx, _ = peak_finder(
        -p, prominence=prominence, distance=distance, width=width
    )

    peak_idx.sort()

    trough_idx.sort()

    cycles = []

    total_drop = 0.0

    # Iterate over peak_idx to apply the per-item logic.
    for pk in peak_idx:

        nxt = trough_idx[trough_idx > pk]

        if len(nxt) == 0:

            t = len(p) - 1

            if p[pk] - p[t] < min_cycle_drop:

                continue

        else:

            t = int(nxt[0])

        dP = p[pk] - p[t]

        if dP >= min_cycle_drop:

            cycles.append(
                {
                    "peak_idx": pk,
                    "trough_idx": t,
                    "peak": p[pk],
                    "trough": p[t],
                    "delta_P": float(dP),
                }
            )

            total_drop += float(dP)

    return cycles, total_drop


def _read_excel_sheet_names(path):
    """Perform read excel sheet names.
    Used to keep the workflow logic localized and testable."""

    try:
        _gil_before_openpyxl = _current_gil_status()
        import openpyxl  # type: ignore

        _note_gil_reenable("openpyxl", _gil_before_openpyxl)

    except Exception:

        openpyxl = None  # type: ignore

    if openpyxl is not None:

        try:

            wb = openpyxl.load_workbook(path, read_only=True, data_only=True)

        except Exception:

            wb = None

        else:

            try:

                return list(wb.sheetnames)

            finally:

                wb.close()

    # Fall back to pandas which will surface any underlying dependency issues

    xls = pd.ExcelFile(path, engine="openpyxl")

    return list(xls.sheet_names)


def _read_excel_dataframe(path, sheet_name):
    """Perform read excel dataframe.
    Used to keep the workflow logic localized and testable."""

    return pd.read_excel(path, sheet_name=sheet_name, engine="openpyxl")


def _sanitize_excel_sheet_name(name: str, fallback: str = "GL260 Import") -> str:
    """Sanitize excel sheet name.
    Used to strip or normalize excel sheet name before use."""
    if name is None:
        name = ""
    name = str(name).strip()
    if not name:
        name = fallback
    cleaned = re.sub(r"[:\\/?*\\[\\]]", "_", name)
    cleaned = re.sub(r"\\s+", " ", cleaned).strip()
    if not cleaned:
        cleaned = fallback
    return cleaned[:31]


def _gl260_row_has_values(row: Sequence[Any]) -> bool:
    """Check whether it has values.
    Used by gl260 row workflows to check values."""
    return any(str(cell).strip() for cell in row)


def _gl260_row_is_data_marker(row: Sequence[Any]) -> bool:
    """Check whether it is data marker.
    Used by gl260 row workflows to check data marker."""
    # Iterate over row to apply the per-item logic.
    for cell in row:
        if str(cell).strip().lower() == "data":
            return True
    return False


def _normalize_gl260_header(row: Sequence[Any]) -> List[str]:
    """Normalize gl260 header.
    Used to keep gl260 header consistent across workflows and persistence."""
    names: List[str] = []
    seen: Dict[str, int] = {}
    # Iterate over indexed elements from row to apply the per-item logic.
    for idx, cell in enumerate(row):
        raw = str(cell).strip()
        name = raw if raw else f"Column {idx + 1}"
        count = seen.get(name, 0) + 1
        seen[name] = count
        if count > 1:
            name = f"{name} ({count})"
        names.append(name)
    return names


def _parse_gl260_csv_table(
    path: str, *, max_rows: Optional[int] = None
) -> Tuple[List[str], List[List[str]]]:
    """Parse gl260 CSV table.
    Used to interpret gl260 CSV table inputs safely."""
    encodings = ("utf-8-sig", "utf-8", "cp1252", "latin-1")
    last_exc: Optional[Exception] = None
    # Iterate over encodings to apply the per-item logic.
    for encoding in encodings:
        try:
            with open(path, "r", encoding=encoding, newline="") as handle:
                reader = csv.reader(handle)
                return _extract_gl260_csv_table(reader, max_rows=max_rows)
        except UnicodeDecodeError as exc:
            last_exc = exc
            continue
    raise ValueError("Unable to decode CSV file.") from last_exc


def _extract_gl260_csv_table(
    reader: Iterable[Sequence[Any]], *, max_rows: Optional[int] = None
) -> Tuple[List[str], List[List[str]]]:
    """Perform extract gl260 CSV table.
    Used to keep the workflow logic localized and testable."""
    header: Optional[List[str]] = None
    data_rows: List[List[str]] = []
    data_marker_found = False
    units_skipped = False
    # Iterate over reader to apply the per-item logic.
    for row in reader:
        if not data_marker_found:
            if _gl260_row_is_data_marker(row):
                data_marker_found = True
            continue
        if header is None:
            if _gl260_row_has_values(row):
                header = _normalize_gl260_header(row)
            continue
        if not units_skipped:
            if _gl260_row_has_values(row):
                units_skipped = True
            continue
        if not _gl260_row_has_values(row):
            continue
        normalized = [str(cell).strip() for cell in row]
        if len(normalized) < len(header):
            normalized.extend([""] * (len(header) - len(normalized)))
        elif len(normalized) > len(header):
            normalized = normalized[: len(header)]
        data_rows.append(normalized)
        if max_rows is not None and len(data_rows) >= max_rows:
            break
    if header is None:
        raise ValueError("Could not locate the data header row in the CSV file.")
    return header, data_rows


def _detect_gl260_datetime_column(columns: Sequence[str]) -> Optional[str]:
    """Detect gl260 datetime column.
    Used to decide runtime capabilities or configuration."""
    # Iterate over columns to apply the per-item logic.
    for name in columns:
        normalized = name.strip().lower().replace(" ", "")
        if "date" in normalized and "time" in normalized:
            return name
        if normalized in ("datetime", "date&time", "date/time"):
            return name
    return None


def _detect_gl260_channel_columns(
    columns: Sequence[str], dt_column: Optional[str]
) -> List[str]:
    """Detect gl260 channel columns.
    Used to decide runtime capabilities or configuration."""
    blocked = {"no", "no.", "#", "index"}
    if dt_column:
        blocked.add(dt_column.strip().lower())
    candidates = []
    # Iterate over columns to apply the per-item logic.
    for name in columns:
        if not name:
            continue
        lowered = name.strip().lower()
        if lowered in blocked:
            continue
        candidates.append(name)
    channel_cols = [
        name
        # Iterate to apply the per-item logic.
        for name in candidates
        if re.match(r"(?i)^ch\\d+", name.strip()) is not None
    ]
    return channel_cols if channel_cols else candidates


def _sanitize_csv_numeric(value: Any) -> Optional[float]:
    """Sanitize CSV numeric.
    Used to strip or normalize CSV numeric before use."""
    if value is None:
        return None
    if isinstance(value, (int, float)):
        try:
            numeric = float(value)
        except (TypeError, ValueError):
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        return numeric if math.isfinite(numeric) else None
    text = str(value).strip()
    if not text:
        return None
    if text.startswith("+"):
        text = text[1:].strip()
    if text in ("+", "-"):
        return None
    try:
        numeric = float(text)
    except (TypeError, ValueError):
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None
    return numeric if math.isfinite(numeric) else None


def _numeric_series_from_column(
    frame: pd.DataFrame, column_name: Optional[str]
) -> pd.Series:
    """Perform numeric series from column.
    Used to keep the workflow logic localized and testable."""
    if not column_name or column_name not in frame.columns:
        return pd.Series([np.nan] * len(frame), dtype=float)
    series = frame[column_name].apply(_sanitize_csv_numeric)
    return pd.Series(series, dtype=float)


def _build_gl260_output_dataframe(
    frame: pd.DataFrame,
    dt_column: str,
    mapping: Dict[str, str],
    derivative_source: str,
    dampening: float,
    window: int,
) -> pd.DataFrame:
    """Build gl260 output dataframe.
    Used to assemble gl260 output dataframe during UI or plot setup."""
    if dt_column not in frame.columns:
        raise ValueError("Date & Time column not found in CSV data.")
    dt_series = pd.to_datetime(frame[dt_column], errors="coerce")
    valid_dt = dt_series.dropna()
    if valid_dt.empty:
        raise ValueError("No valid Date & Time values found in the CSV data.")
    t0 = valid_dt.iloc[0]
    elapsed_seconds = (dt_series - t0).dt.total_seconds()
    elapsed_days = elapsed_seconds / 86400.0
    elapsed_hours = elapsed_seconds / 3600.0
    elapsed_minutes = elapsed_seconds / 60.0

    reactor_series = _numeric_series_from_column(
        frame, mapping.get("reactor_pressure")
    )
    manifold_series = _numeric_series_from_column(
        frame, mapping.get("manifold_pressure")
    )
    external_temp_series = _numeric_series_from_column(
        frame, mapping.get("external_temp")
    )
    internal_temp_series = _numeric_series_from_column(
        frame, mapping.get("internal_temp")
    )

    pressure_source = (
        reactor_series if derivative_source == "reactor" else manifold_series
    )
    elapsed_hours_values = np.asarray(elapsed_hours, dtype=float)
    pressure_values = np.asarray(pressure_source, dtype=float)
    deriv = np.zeros(len(frame), dtype=float)
    # Iterate over the configured range to apply the per-item logic.
    for idx in range(1, len(frame)):
        dt_hours = elapsed_hours_values[idx] - elapsed_hours_values[idx - 1]
        if not math.isfinite(dt_hours) or dt_hours <= 0.0:
            deriv[idx] = 0.0
            continue
        prev_val = pressure_values[idx - 1]
        curr_val = pressure_values[idx]
        if not math.isfinite(prev_val) or not math.isfinite(curr_val):
            deriv[idx] = 0.0
            continue
        deriv[idx] = (curr_val - prev_val) / dt_hours

    dampening = max(0.0, min(float(dampening), 0.999999))
    alpha = 1.0 - dampening
    smooth = np.zeros(len(frame), dtype=float)
    if len(frame) > 0:
        smooth[0] = deriv[0]
    if len(frame) > 1:
        smooth[1] = deriv[0]
    # Iterate over the configured range to apply the per-item logic.
    for idx in range(2, len(frame)):
        smooth[idx] = alpha * deriv[idx - 1] + dampening * smooth[idx - 1]

    window = max(1, int(window))
    smooth_series = pd.Series(smooth, dtype=float)
    moving_avg = smooth_series.rolling(window=window, min_periods=window).mean()

    output = pd.DataFrame(
        {
            "Date & Time": dt_series,
            "Elapsed Time (days)": elapsed_days,
            "Elapsed Time (hours)": elapsed_hours,
            "Elapsed Time (minutes)": elapsed_minutes,
            "Elapsed Time (seconds)": elapsed_seconds,
            "Reactor Pressure (PSI)": reactor_series,
            "Manifold Pressure (PSI)": manifold_series,
            "External Reactor Temperature": external_temp_series,
            "Internal Reactor Temperature": internal_temp_series,
            "First Derivative (ΔPSI/Δhour)": pd.Series(deriv, dtype=float),
            "Smoothed First Derivative": smooth_series,
            "First Derivative Moving Average": moving_avg,
        }
    )
    return output[CSV_IMPORT_OUTPUT_COLUMNS]


def _write_gl260_output_sheet(
    workbook_path: str, sheet_name: str, output: pd.DataFrame, exists_mode: str
) -> str:
    """Perform write gl260 output sheet.
    Used to keep the workflow logic localized and testable."""
    try:
        import openpyxl  # type: ignore
        from openpyxl.utils.dataframe import dataframe_to_rows  # type: ignore
    except Exception as exc:
        raise RuntimeError("openpyxl is required for CSV import.") from exc

    workbook = openpyxl.load_workbook(workbook_path)
    resolved_name = _sanitize_excel_sheet_name(sheet_name or "GL260 Import")
    existing = set(workbook.sheetnames)

    mode = (exists_mode or CSV_IMPORT_DEFAULT_SHEET_EXISTS_MODE).strip().lower()
    if mode not in CSV_IMPORT_SHEET_EXISTS_MODES:
        mode = CSV_IMPORT_DEFAULT_SHEET_EXISTS_MODE

    if resolved_name in existing:
        if mode == "error":
            raise ValueError(
                f"Sheet '{resolved_name}' already exists in the workbook."
            )
        if mode == "overwrite":
            workbook.remove(workbook[resolved_name])
            existing.discard(resolved_name)
        if mode == "autosuffix":
            base = resolved_name
            counter = 1
            # Repeat while resolved_name in existing to advance the looped workflow.
            while resolved_name in existing:
                suffix = f"_{counter}"
                trimmed = base
                if len(base) + len(suffix) > 31:
                    trimmed = base[: 31 - len(suffix)]
                resolved_name = f"{trimmed}{suffix}"
                counter += 1

    worksheet = workbook.create_sheet(title=resolved_name)
    # Iterate over dataframe_to_rows(output, index=False, header=True) to apply the per-item logic.
    for row in dataframe_to_rows(output, index=False, header=True):
        worksheet.append(row)
    worksheet.freeze_panes = "A2"
    workbook.save(workbook_path)
    workbook.close()
    return resolved_name


def analyze_pressure_cycles(
    pressure_series,
    temp_series,
    volume,
    a_const,
    b_const,
    min_cycle_drop,
    make_figure=True,
    *,
    x_series=None,
    x_label="Elapsed Time (days)",
    time_range=None,  # (min_time, max_time) or None
    y_lim=None,  # (min_y, max_y) or None
    auto_time_ticks=False,  # sync with main
    auto_y_ticks=False,  # sync with main
    xmaj_tick=0.2,
    xmin_tick=0.05,  # manual tick intervals
    ymaj_tick=50,
    ymin_tick=5,
    suptitle_text=None,  # optional, for consistency
    peak_prominence=1.0,
    peak_distance=1,
    peak_width=1,
    fig_size=None,
):
    """Analyze pressure cycles and optionally build a peak/trough figure.

    Purpose:
        Detect peak-to-trough cycles, compute cycle summary metrics, and produce
        optional cycle marker visual output.
    Why:
        Cycle identification and visibility are required for downstream moles
        calculations, overlays, and user-facing diagnostics.
    Inputs:
        pressure_series: Pressure values used for peak/trough detection.
        temp_series: Temperature values used for cycle temperature statistics.
        volume: Reactor volume used in moles calculations.
        a_const: Van der Waals a constant used by gas model calculations.
        b_const: Van der Waals b constant used by gas model calculations.
        min_cycle_drop: Minimum valid pressure drop threshold per cycle (psi).
        make_figure: Whether to generate a dedicated cycle figure.
        x_series: Optional x-axis values for figure rendering.
        x_label: X-axis label for the optional figure.
        time_range: Optional x-axis limits tuple.
        y_lim: Optional y-axis limits tuple.
        auto_time_ticks: Enable auto x-axis ticks when True.
        auto_y_ticks: Enable auto y-axis ticks when True.
        xmaj_tick/xmin_tick/ymaj_tick/ymin_tick: Manual tick spacing values.
        suptitle_text: Optional suptitle for the cycle figure.
        peak_prominence/peak_distance/peak_width: Peak detector parameters.
        fig_size: Optional figure size override.
    Outputs:
        Tuple of (figure_or_none, summary_text).
    Side Effects:
        Emits summary log lines and adds artists to the generated figure when enabled.
    Exceptions:
        Uses guarded fallbacks and returns a message when inputs are insufficient.
    """

    import matplotlib.pyplot as plt

    from matplotlib.ticker import MultipleLocator, AutoMinorLocator, AutoLocator

    from matplotlib.lines import Line2D

    import matplotlib.patches as mpatches

    if pressure_series is None or len(pressure_series) == 0:
        msg = "No valid pressure data for cycle-by-cycle calculation."

        print(msg)

        return (None, msg)

    # Collect lines for the summary pane (and echo to terminal)

    log_lines = []

    def log(msg=""):
        """Perform log.
        Used to keep the workflow logic localized and testable."""

        msg = str(msg)

        log_lines.append(msg)

        print(msg)

    # Detect cycles on PSI series

    try:

        cycles, total_drop = detect_valid_cycles(
            pressure_series,
            min_cycle_drop=min_cycle_drop,
            prominence=peak_prominence,
            distance=peak_distance,
            width=peak_width,
        )

    except ModuleNotFoundError as exc:

        msg = _scipy_missing_message("automatic cycle detection")

        log(msg)

        log(str(exc))

        return (None, msg)

    tvals = np.asarray(temp_series, dtype=float) if temp_series is not None else None

    (
        per_cycle_rows,
        total_moles_ideal,
        total_moles_vdw,
        scipy_available,
        vdw_used,
    ) = _compute_cycle_statistics(
        cycles,
        tvals,
        volume,
        a_const,
        b_const,
        allow_threads=True,
        force_vdw=False,
    )

    gas_molar_mass = globals().get(
        "gas_molar_mass",
        settings.get("vdw_gas_molar_mass", DEFAULT_GAS_MOLAR_MASS),
    )
    try:
        gas_molar_mass = float(gas_molar_mass)
        if not math.isfinite(gas_molar_mass) or gas_molar_mass <= 0:
            raise ValueError
    except Exception:
        gas_molar_mass = DEFAULT_GAS_MOLAR_MASS

    summary_context = {
        "selection_mode": "Auto",
        "min_cycle_drop_psi": float(min_cycle_drop),
        "ignore_min_drop": False,
        "peak_prominence": float(peak_prominence),
        "peak_distance": int(peak_distance),
        "peak_width": int(peak_width),
        "temp_column_label": settings.get(
            "cycle_temp_column", CYCLE_TEMP_DEFAULT_LABEL
        ),
        "per_cycle": per_cycle_rows,
        "volume_l": volume,
        "a_const": a_const,
        "b_const": b_const,
        "gas_molar_mass": gas_molar_mass,
        "scipy_available": scipy_available,
        "vdw_used": vdw_used,
    }

    resolved_inputs = resolve_cycle_summary_inputs(
        settings, globals_fallback=globals(), context=summary_context
    )
    options = resolve_cycle_summary_options(settings)
    summary = build_cycle_analysis_summary(
        cycles,
        per_cycle_rows,
        total_drop,
        total_moles_ideal,
        total_moles_vdw,
        vdw_used=vdw_used,
        scipy_available=scipy_available,
        resolved_inputs=resolved_inputs,
        options=options,
    )

    # Iterate over summary.splitlines() to apply the per-item logic.
    for line in summary.splitlines():
        log(line)

    # Build a figure with peaks/troughs annotated

    target_figsize = tuple(fig_size) if fig_size else (11, 8.5)
    font_family = (settings.get("font_family") or "").strip()

    fig_peaks = None

    if make_figure:

        fig_peaks, ax = plt.subplots(figsize=target_figsize)
        try:
            ax._gl260_axis_role = "primary"
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        fig_peaks.subplots_adjust(left=0.076, right=0.97, bottom=0.079, top=0.914)

        # Use provided x_series if available; else fall back to Series index

        if x_series is not None:
            x_vals = np.asarray(x_series, dtype=float)

        else:
            x_vals = np.asarray(pressure_series.index, dtype=float)

        y_vals = np.asarray(pressure_series.values, dtype=float)

        style = get_cycle_trace_style()

        _plot_series(
            ax,
            x_vals,
            y_vals,
            label="Pressure (PSI)",
            color=style["line_color"],
            zorder=2,
            series_key="y1",
            line_style=style["resolved_linestyle"],
            linewidth=style["line_width"],
        )

        ax.set_xlabel(x_label, fontsize=label_fontsize)

        # Annotate peaks/troughs

        cycle_marker_zorder = _compute_top_overlay_zorder(
            ax, min_z=CYCLE_MARKER_MIN_ZORDER, pad=CYCLE_MARKER_ZORDER_PAD
        )
        peak_label_added = False
        trough_label_added = False

        # Iterate over cycles to apply the per-item logic.
        for c in cycles:
            peak_label = "Peak" if not peak_label_added else ""
            ax.scatter(
                x_vals[c["peak_idx"]],
                c["peak"],
                marker=style["peak_marker"],
                s=style["marker_size"],
                c=style["peak_color"],
                zorder=cycle_marker_zorder,
                label=peak_label,
            )
            peak_label_added = peak_label_added or bool(peak_label)

            ax.annotate(
                f"{c['peak']:.1f}",
                (x_vals[c["peak_idx"]], c["peak"]),
                textcoords="offset points",
                xytext=(0, 10),
                ha="center",
                fontsize=label_fontsize,
                color=style["peak_color"],
            )

            trough_label = "Trough" if not trough_label_added else ""
            ax.scatter(
                x_vals[c["trough_idx"]],
                c["trough"],
                marker=style["trough_marker"],
                s=style["marker_size"],
                c=style["trough_color"],
                zorder=cycle_marker_zorder,
                label=trough_label,
            )
            trough_label_added = trough_label_added or bool(trough_label)

            ax.annotate(
                f'{c["trough"]:.1f}',
                (x_vals[c["trough_idx"]], c["trough"]),
                textcoords="offset points",
                xytext=(0, -15),
                ha="center",
                fontsize=label_fontsize,
                color=style["trough_color"],
            )

        # Limits (match main plots)

        if time_range is not None:

            ax.set_xlim(*time_range)

        if y_lim is not None:

            ax.set_ylim(*y_lim)

        # Tick locators (match main plots)

        if auto_time_ticks:

            ax.xaxis.set_major_locator(AutoLocator())

            ax.xaxis.set_minor_locator(AutoMinorLocator())

        else:

            ax.xaxis.set_major_locator(MultipleLocator(xmaj_tick))

            ax.xaxis.set_minor_locator(MultipleLocator(xmin_tick))

        if auto_y_ticks:

            ax.yaxis.set_major_locator(AutoLocator())

            ax.yaxis.set_minor_locator(AutoMinorLocator())

        else:

            ax.yaxis.set_major_locator(MultipleLocator(ymaj_tick))

            ax.yaxis.set_minor_locator(MultipleLocator(ymin_tick))

        ax.minorticks_on()

        ax.tick_params(axis="both", which="major", labelsize=tick_labelsize)

        ax.set_ylabel("Pressure (PSI)", fontsize=label_fontsize)
        font_family = (settings.get("font_family") or "").strip()
        _enforce_axis_text_style(
            ax,
            font_family=font_family,
            tick_fontsize=tick_labelsize,
            label_fontsize=label_fontsize,
        )
        title_text = f"Pressure vs Time with Detected Cycles ( ΔP {min_cycle_drop} PSI)"
        _center_titles_to_axes_union(
            fig_peaks,
            [ax],
            title_text,
            suptitle_text,
            subplottitle_fontsize,
            suptitle_fontsize,
            font_family,
            float(plt.rcParams.get("axes.titlepad", 6.0)),
            0.0,
            suptitle_y=suptitle_yposition,
        )

        # Collect current handles and labels

        handles, labels = ax.get_legend_handles_labels()

        # Add Cycles: N as a dummy handle (legend-only text)

        handles.append(Line2D([], [], color="none"))

        labels.append(f"Cycles: {len(cycles)}")

        # Add Total  ΔP as a proxy Patch (label-only row)

        handles.append(mpatches.Patch(color="none"))

        labels.append(f"Total ΔP: {total_drop:.2f} PSI")

        # Add Min  ΔP threshold as another proxy row

        handles.append(mpatches.Patch(color="none"))

        labels.append(f"Min  ΔP threshold: {min_cycle_drop:.2f} PSI")

        # Recreate the legend (AFTER adding the proxies)

        leg = ax.legend(
            handles,
            labels,
            loc="lower right",
            bbox_to_anchor=(0.98, 0.02),
            bbox_transform=ax.transAxes,
            **_legend_shadowbox_kwargs(),
        )

        _make_legend_draggable(leg)

        summary_text = "\n".join(log_lines)

        return fig_peaks, summary_text


def _format_axis_label(label: Any) -> str:
    """Format axis label.
    Used to prepare axis label for display or export."""
    return str(label).replace("_", " ").replace(" (Â°C)", "")


def _is_selected(value: Any) -> bool:
    """Check whether it is selected.
    Used to gate conditional behavior in the workflow."""
    if value is None:
        return False
    if isinstance(value, str):
        cleaned = value.strip()
        if not cleaned:
            return False
        if cleaned.lower() == "none":
            return False
    return True


def _filter_none_legend_entries(
    handles: Sequence[Any], labels: Sequence[str]
) -> Tuple[List[Any], List[str]]:
    """Filter none legend entries.
    Used to remove non-relevant entries from none legend entries."""
    filtered_handles: List[Any] = []
    filtered_labels: List[str] = []
    # Iterate over paired elements from multiple sequences to apply the per-item logic.
    for handle, label in zip(handles, labels):
        if handle is None:
            continue
        if not _is_selected(label):
            continue
        filtered_handles.append(handle)
        filtered_labels.append(label)
    return filtered_handles, filtered_labels


def main_plotting_function(
    min_time,
    max_time,
    min_y,
    max_y,
    twin_y_min,
    twin_y_max,
    deriv_y_min,
    deriv_y_max,
    auto_time_ticks,
    auto_y_ticks,
    auto_temp_ticks,
    auto_deriv_ticks,
    title_text,
    suptitle_text,
    xmaj_tick,
    xmin_tick,
    ymaj_tick,
    ymin_tick,
    twin_maj_tick,
    twin_min_tick,
    deriv_maj_tick,
    deriv_min_tick,
    enable_temp_axis,
    enable_deriv_axis,
    min_cycle_drop,
    peak_prominence=1.0,
    peak_distance=1,
    peak_width=1,
    show_cycle_markers_on_core_plots=False,
    show_cycle_legend_on_core_plots=False,
    include_moles_in_core_plot_legend=False,
    fig_size=None,
    render_ctx: Optional[RenderContext] = None,
):
    """Generate the core GL-260 figures using live settings and render context.

    Purpose:
        Build Figure 1, Figure 2, and optional cycle-related outputs in one
        coordinated plotting pass.
    Why:
        Centralizing figure generation keeps plot layering, legends, and export
        behavior consistent across display and file outputs.
    Inputs:
        Axis ranges, tick controls, title text, plot toggles, cycle controls,
        and an optional render context payload.
    Outputs:
        Mapping containing generated figures (`fig1`, `fig2`, and optional
        cycle figure keys).
    Side Effects:
        Adds artists/legends to figures and tags figure metadata for downstream UI.
    Exceptions:
        Guarded branches keep rendering resilient when optional inputs are absent.
    """

    import matplotlib.pyplot as plt

    from matplotlib.ticker import MultipleLocator, AutoMinorLocator, AutoLocator

    _apply_default_plot_fonts(settings.get("font_family"))

    target_figsize = tuple(fig_size) if fig_size else (11, 8.5)

    data_ctx = render_ctx.data_ctx if render_ctx else {}
    style_ctx = render_ctx.style_ctx if render_ctx else {}
    gates_ctx = render_ctx.gates_ctx if render_ctx else {}
    overlay_ctx = render_ctx.overlay_ctx if render_ctx else {}
    font_family = (style_ctx.get("font_family") or settings.get("font_family") or "").strip()
    raw_core_profiles = style_ctx.get("core_plot_render_profiles")
    if isinstance(raw_core_profiles, dict):
        core_render_profiles = _normalize_core_plot_render_profiles(
            raw_core_profiles,
            seed_source=settings,
        )
    else:
        core_render_profiles = _get_core_plot_render_profiles()
    fig1_core_profile = core_render_profiles.get(
        "fig_pressure_temp",
        _get_core_plot_render_profile("fig_pressure_temp"),
    )
    fig2_core_profile = core_render_profiles.get(
        "fig_pressure_derivative",
        _get_core_plot_render_profile("fig_pressure_derivative"),
    )
    _write_legacy_core_legend_settings_from_profile(fig1_core_profile)

    show_cycle_markers_on_core_plots = bool(
        gates_ctx.get("show_cycle_markers", show_cycle_markers_on_core_plots)
    )
    show_cycle_legend_on_core_plots = bool(
        gates_ctx.get("show_cycle_legend", show_cycle_legend_on_core_plots)
    )
    include_moles_in_core_plot_legend = bool(
        gates_ctx.get("include_moles", include_moles_in_core_plot_legend)
    )

    scatter_config = style_ctx.get("scatter_config")
    scatter_series_configs = style_ctx.get("scatter_series_configs")

    series_map = data_ctx.get("series") or {}
    selected_columns = data_ctx.get("selected_columns") or globals().get(
        "selected_columns", {}
    )
    fig1_font_family = (
        str(fig1_core_profile.get("font_family") or "").strip() or font_family
    )
    fig2_font_family = (
        str(fig2_core_profile.get("font_family") or "").strip() or font_family
    )
    fig1_label_fontsize = _sanitize_spacing_value(
        _coerce_float(fig1_core_profile.get("label_fontsize")),
        label_fontsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig1_tick_fontsize = _sanitize_spacing_value(
        _coerce_float(fig1_core_profile.get("tick_fontsize")),
        tick_labelsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig1_title_fontsize = _sanitize_spacing_value(
        _coerce_float(fig1_core_profile.get("title_fontsize")),
        subplottitle_fontsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig1_suptitle_fontsize = _sanitize_spacing_value(
        _coerce_float(fig1_core_profile.get("suptitle_fontsize")),
        suptitle_fontsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig1_title_pad_pts = _sanitize_spacing_value(
        _coerce_float(fig1_core_profile.get("title_pad_pts")),
        DEFAULT_COMBINED_TITLE_PAD_PTS,
        MIN_COMBINED_TITLE_PAD_PTS,
        MAX_COMBINED_TITLE_PAD_PTS,
    )
    fig1_suptitle_pad_pts = _sanitize_spacing_value(
        _coerce_float(fig1_core_profile.get("suptitle_pad_pts")),
        DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
        MIN_COMBINED_SUPTITLE_PAD_PTS,
        MAX_COMBINED_SUPTITLE_PAD_PTS,
    )
    fig1_suptitle_y = _sanitize_spacing_value(
        _coerce_float(fig1_core_profile.get("suptitle_y")),
        DEFAULT_COMBINED_SUPTITLE_Y,
        MIN_COMBINED_SUPTITLE_Y,
        MAX_COMBINED_SUPTITLE_Y,
    )
    fig1_primary_labelpad = _coerce_float(fig1_core_profile.get("primary_labelpad"))
    if fig1_primary_labelpad is None:
        fig1_primary_labelpad = yaxis_labelpad_amount
    fig1_temp_labelpad = _coerce_float(fig1_core_profile.get("right_labelpad"))
    if fig1_temp_labelpad is None:
        fig1_temp_labelpad = twinyaxis_labelpad_amount
    fig1_legend_fontsize = _sanitize_spacing_value(
        _coerce_float(fig1_core_profile.get("legend_fontsize")),
        settings.get("core_legend_fontsize", label_fontsize),
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig1_cycle_legend_fontsize = _sanitize_spacing_value(
        _coerce_float(fig1_core_profile.get("cycle_legend_fontsize")),
        settings.get("core_cycle_legend_fontsize", fig1_legend_fontsize),
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig1_legend_alignment = _normalize_legend_alignment(
        str(fig1_core_profile.get("legend_alignment") or "center")
    )
    fig1_legend_wrap = bool(fig1_core_profile.get("legend_wrap", False))
    try:
        fig1_legend_rows = max(1, int(fig1_core_profile.get("legend_rows", 2)))
    except Exception:
        fig1_legend_rows = 2
    fig1_base_legend_font = max(1.0, float(fig1_label_fontsize or label_fontsize or 1.0))
    fig1_legend_markerscale = fig1_legend_fontsize / fig1_base_legend_font
    fig1_cycle_legend_markerscale = fig1_cycle_legend_fontsize / fig1_base_legend_font
    fig1_x_label_text = str(
        fig1_core_profile.get("x_axis_label")
        or _format_axis_label(selected_columns.get("x", "Time"))
    )
    fig1_primary_label_text = str(
        fig1_core_profile.get("primary_axis_label")
        or _format_axis_label(selected_columns.get("y1", "Pressure"))
    )
    fig1_temp_label_text = str(
        fig1_core_profile.get("right_axis_label") or "Temperature (°C)"
    )

    fig2_label_fontsize = _sanitize_spacing_value(
        _coerce_float(fig2_core_profile.get("label_fontsize")),
        label_fontsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig2_tick_fontsize = _sanitize_spacing_value(
        _coerce_float(fig2_core_profile.get("tick_fontsize")),
        tick_labelsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig2_title_fontsize = _sanitize_spacing_value(
        _coerce_float(fig2_core_profile.get("title_fontsize")),
        subplottitle_fontsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig2_suptitle_fontsize = _sanitize_spacing_value(
        _coerce_float(fig2_core_profile.get("suptitle_fontsize")),
        suptitle_fontsize,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig2_title_pad_pts = _sanitize_spacing_value(
        _coerce_float(fig2_core_profile.get("title_pad_pts")),
        DEFAULT_COMBINED_TITLE_PAD_PTS,
        MIN_COMBINED_TITLE_PAD_PTS,
        MAX_COMBINED_TITLE_PAD_PTS,
    )
    fig2_suptitle_pad_pts = _sanitize_spacing_value(
        _coerce_float(fig2_core_profile.get("suptitle_pad_pts")),
        DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
        MIN_COMBINED_SUPTITLE_PAD_PTS,
        MAX_COMBINED_SUPTITLE_PAD_PTS,
    )
    fig2_suptitle_y = _sanitize_spacing_value(
        _coerce_float(fig2_core_profile.get("suptitle_y")),
        DEFAULT_COMBINED_SUPTITLE_Y,
        MIN_COMBINED_SUPTITLE_Y,
        MAX_COMBINED_SUPTITLE_Y,
    )
    fig2_primary_labelpad = _coerce_float(fig2_core_profile.get("primary_labelpad"))
    if fig2_primary_labelpad is None:
        fig2_primary_labelpad = yaxis_labelpad_amount
    fig2_deriv_labelpad = _coerce_float(fig2_core_profile.get("third_labelpad"))
    if fig2_deriv_labelpad is None:
        fig2_deriv_labelpad = twinyaxis_labelpad_amount
    fig2_legend_fontsize = _sanitize_spacing_value(
        _coerce_float(fig2_core_profile.get("legend_fontsize")),
        settings.get("core_legend_fontsize", label_fontsize),
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig2_cycle_legend_fontsize = _sanitize_spacing_value(
        _coerce_float(fig2_core_profile.get("cycle_legend_fontsize")),
        settings.get("core_cycle_legend_fontsize", fig2_legend_fontsize),
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    fig2_legend_alignment = _normalize_legend_alignment(
        str(fig2_core_profile.get("legend_alignment") or "center")
    )
    fig2_legend_wrap = bool(fig2_core_profile.get("legend_wrap", False))
    try:
        fig2_legend_rows = max(1, int(fig2_core_profile.get("legend_rows", 2)))
    except Exception:
        fig2_legend_rows = 2
    fig2_base_legend_font = max(1.0, float(fig2_label_fontsize or label_fontsize or 1.0))
    fig2_legend_markerscale = fig2_legend_fontsize / fig2_base_legend_font
    fig2_cycle_legend_markerscale = fig2_cycle_legend_fontsize / fig2_base_legend_font
    fig2_x_label_text = str(
        fig2_core_profile.get("x_axis_label")
        or _format_axis_label(selected_columns.get("x", "Time"))
    )
    fig2_primary_label_text = str(
        fig2_core_profile.get("primary_axis_label")
        or _format_axis_label(selected_columns.get("y1", "Pressure"))
    )
    fig2_deriv_label_text = str(
        fig2_core_profile.get("third_axis_label")
        or _format_axis_label(selected_columns.get("y2", "Derivative"))
    )

    # Pull series/globals up front (needed for both paths)

    x = series_map.get("x", globals().get("x"))

    y1 = series_map.get("y1", globals().get("y1"))

    y2 = series_map.get("y2", globals().get("y2"))

    y3 = series_map.get("y3", globals().get("y3"))

    z = series_map.get("z", globals().get("z"))

    z2 = series_map.get("z2", globals().get("z2"))

    fig_peaks = None  # will hold the cycle analysis figure if created

    fmt = _format_axis_label
    svg_safe = _svg_safe_text

    def _text_safe(value: Any) -> str:
        """Perform text safe.
        Used to keep the workflow logic localized and testable."""
        return svg_safe(value)

    # X-axis label for the cycle plot, wired to the selected X column

    xcol = selected_columns.get("x") or "Elapsed Time (days)"

    x_label_for_cycles = fmt(xcol)

    # Normal (full) plotting with cycle analysis

    if y1 is not None and _is_selected(selected_columns.get("y1", "y1")):

        # mask to keep x & y1 aligned (avoid NaNs mismatch)

        mask = (~pd.isna(x)) & (~pd.isna(y1))

        if mask.sum() == 0:

            msg = "No valid X/Y1 points after masking; skipping cycle analysis."

            print(msg)

            cb = globals().get("update_cycle_summary_callback")

            if callable(cb):

                cb(msg)

        else:

            cycle_temp_series = data_ctx.get("cycle_temp_series")
            if cycle_temp_series is None:
                cycle_temp_series = globals().get("cycle_temp_series")

            if cycle_temp_series is not None:

                try:

                    if hasattr(cycle_temp_series, "reset_index"):

                        temp_series = cycle_temp_series[mask].reset_index(drop=True)

                    else:

                        temp_series = pd.Series(
                            np.asarray(cycle_temp_series)[mask]
                        ).reset_index(drop=True)

                except Exception:

                    temp_series = None

            else:

                temp_series = None

            fig_peaks, summary_text = analyze_pressure_cycles(
                pressure_series=y1[mask].reset_index(drop=True),
                temp_series=temp_series,
                volume=data_ctx.get("volume", globals().get("volume", 1.0)),
                a_const=data_ctx.get("a_const", globals().get("a_const", 1.39)),
                b_const=data_ctx.get("b_const", globals().get("b_const", 0.0391)),
                min_cycle_drop=min_cycle_drop,
                make_figure=True,
                x_series=x[mask].reset_index(drop=True),
                x_label=x_label_for_cycles,
                time_range=(min_time, max_time),
                y_lim=(min_y, max_y),
                auto_time_ticks=auto_time_ticks,
                auto_y_ticks=auto_y_ticks,
                xmaj_tick=xmaj_tick,
                xmin_tick=xmin_tick,
                ymaj_tick=ymaj_tick,
                ymin_tick=ymin_tick,
                suptitle_text=suptitle_text,
                peak_prominence=peak_prominence,
                peak_distance=peak_distance,
                peak_width=peak_width,
                fig_size=target_figsize,
            )

            # Push the summary through the shared callback

            cb = globals().get("update_cycle_summary_callback")

            if callable(cb):
                cb(summary_text)

    def fmt(label):
        """Perform fmt.
        Used to keep the workflow logic localized and testable."""

        return str(label).replace("_", " ").replace(" (°C)", "")

    # Cycle overlays and moles summaries are optional enrichments layered on top
    # of the base plot; they are gated to keep preview responsive when absent.
    cycle_overlay = overlay_ctx.get("cycle_overlay")
    markers_overlay = overlay_ctx.get("markers", cycle_overlay)
    legend_overlay = overlay_ctx.get("cycle_legend", cycle_overlay)
    cycle_style = (
        get_cycle_trace_style() if (markers_overlay or legend_overlay) else None
    )
    import matplotlib.patches as mpatches  # localized import to avoid circulars

    moles_lines = overlay_ctx.get("moles_summary")
    if moles_lines is None and isinstance(cycle_overlay, dict):
        moles_lines = cycle_overlay.get("moles_lines")

    def _marker_artist(marker, color):
        """Perform marker artist.
        Used to keep the workflow logic localized and testable."""
        size_val = None
        try:
            size_val = max(4.0, math.sqrt(float(cycle_style["marker_size"])))
        except Exception:
            size_val = 6.0
        return Line2D(
            [], [], linestyle="None", marker=marker, color=color, markersize=size_val
        )

    def _draw_cycle_markers(ax_target):
        """Render cycle peak/trough markers as top-layer overlays on a target axes.

        Purpose:
            Draw cached cycle peak and trough points for core plot overlays.
        Why:
            Cycle markers must remain visually dominant regardless of trace zorder
            overrides so cycle interpretation stays reliable.
        Inputs:
            ax_target: Axes receiving cycle marker scatter artists.
        Outputs:
            Tuple of (peak_artist, trough_artist), each possibly None.
        Side Effects:
            Adds scatter artists to the supplied axes.
        Exceptions:
            Returns (None, None) when cycle overlay data is unavailable.
        """
        if not (show_cycle_markers_on_core_plots and markers_overlay and cycle_style):
            return (None, None)
        cycle_marker_zorder = _compute_top_overlay_zorder(
            ax_target, min_z=CYCLE_MARKER_MIN_ZORDER, pad=CYCLE_MARKER_ZORDER_PAD
        )
        peak_artist = trough_artist = None
        peaks = markers_overlay.get("peak_points") or []
        troughs = markers_overlay.get("trough_points") or []
        if peaks:
            px, py = zip(*peaks)
            peak_artist = ax_target.scatter(
                px,
                py,
                marker=cycle_style["peak_marker"],
                s=cycle_style["marker_size"],
                c=cycle_style["peak_color"],
                zorder=cycle_marker_zorder,
                label=_text_safe("Peak"),
            )
        if troughs:
            tx, ty = zip(*troughs)
            trough_artist = ax_target.scatter(
                tx,
                ty,
                marker=cycle_style["trough_marker"],
                s=cycle_style["marker_size"],
                c=cycle_style["trough_color"],
                zorder=cycle_marker_zorder,
                label=_text_safe("Trough"),
            )
        return peak_artist, trough_artist

    def _add_cycle_legend(
        ax_target,
        peak_artist,
        trough_artist,
        *,
        core_profile: Mapping[str, Any],
        base_legend_font: float,
    ):
        """Perform add cycle legend.
        Used to keep the workflow logic localized and testable."""
        if not (show_cycle_legend_on_core_plots and legend_overlay):
            return None
        cycle_fontsize_value = _sanitize_spacing_value(
            _coerce_float(core_profile.get("cycle_legend_fontsize")),
            settings.get("core_cycle_legend_fontsize", settings.get("core_legend_fontsize", label_fontsize)),
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        safe_base_legend_font = max(1.0, float(base_legend_font or 1.0))
        cycle_markerscale_value = cycle_fontsize_value / safe_base_legend_font
        cycle_loc_value = (
            str(core_profile.get("cycle_legend_loc_choice", "upper right") or "upper right")
            .strip()
            .lower()
        )
        if cycle_loc_value not in {
            "upper right",
            "upper left",
            "lower right",
            "lower left",
            "center right",
            "center left",
            "upper center",
            "lower center",
            "center",
        }:
            cycle_loc_value = "upper right"
        handles: List[Any] = []
        labels: List[str] = []
        if peak_artist is not None:
            handles.append(peak_artist)
            labels.append("Peak")
        elif cycle_style:
            handles.append(
                _marker_artist(cycle_style["peak_marker"], cycle_style["peak_color"])
            )
            labels.append("Peak")
        if trough_artist is not None:
            handles.append(trough_artist)
            labels.append("Trough")
        elif cycle_style:
            handles.append(
                _marker_artist(cycle_style["trough_marker"], cycle_style["trough_color"])
            )
            labels.append("Trough")
        cycles_list = legend_overlay.get("cycles") or []
        total_drop_val = legend_overlay.get("total_drop", 0.0)
        try:
            total_drop_val = float(total_drop_val)
        except Exception:
            total_drop_val = 0.0
        handles.append(Line2D([], [], color="none"))
        labels.append(f"Cycles: {len(cycles_list)}")
        handles.append(mpatches.Patch(color="none"))
        labels.append(f"Total ΔP: {total_drop_val:.2f} PSI")
        # Moles summary lines are appended to the cycle legend so the plot carries
        # mass-balance context without adding a separate annotation layer.
        if include_moles_in_core_plot_legend:
            # Iterate over moles_lines or [] to apply the per-item logic.
            for line in moles_lines or []:
                handles.append(mpatches.Patch(color="none"))
                labels.append(line)
        legend = ax_target.legend(
            handles,
            labels,
            loc=cycle_loc_value,
            fontsize=cycle_fontsize_value,
            markerscale=cycle_markerscale_value,
            **_legend_shadowbox_kwargs(),
        )
        try:
            legend._cycle_overlay_legend = True  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            legend._gl260_legend_role = "cycle"  # type: ignore[attr-defined]
            legend._gl260_markerscale = cycle_markerscale_value  # type: ignore[attr-defined]
            legend._gl260_markerscale_base_font = safe_base_legend_font  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        _make_legend_draggable(legend)
        return legend

    # Ranges

    time_range = (min_time, max_time)

    y_lim = (min_y, max_y)

    twin_y_lim = (twin_y_min, twin_y_max)

    x = series_map.get("x", globals().get("x"))

    y1 = series_map.get("y1", globals().get("y1"))

    y2 = series_map.get("y2", globals().get("y2"))

    y3 = series_map.get("y3", globals().get("y3"))

    z = series_map.get("z", globals().get("z"))

    z2 = series_map.get("z2", globals().get("z2"))

    selected_columns = data_ctx.get("selected_columns") or globals().get(
        "selected_columns", {}
    )

    # Figure 1: pressure + optional temps

    fig1, ax = plt.subplots(figsize=target_figsize)
    try:
        ax._gl260_axis_role = "primary"
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    fig1.subplots_adjust(bottom=0.175, top=0.91, left=0.071, right=0.924)

    handles = []

    if y1 is not None and _is_selected(selected_columns.get("y1", "y1")):

        artist = _plot_series(
            ax,
            x,
            y1,
            label=fmt(selected_columns.get("y1", "y1")),
            color="blue",
            zorder=2,
            series_key="y1",
            scatter_config=scatter_config,
            scatter_series_configs=scatter_series_configs,
        )

        handles.append(artist)

    if y3 is not None and _is_selected(selected_columns.get("y3", "y3")):

        artist = _plot_series(
            ax,
            x,
            y3,
            label=fmt(selected_columns.get("y3", "y3")),
            color="green",
            zorder=1,
            series_key="y3",
            scatter_config=scatter_config,
            scatter_series_configs=scatter_series_configs,
        )

        handles.append(artist)

    ax.set_xlim(*time_range)

    ax.set_ylim(*y_lim)

    ax.set_xlabel("")

    ax.set_ylabel(
        fig1_primary_label_text,
        fontsize=fig1_label_fontsize,
        labelpad=fig1_primary_labelpad,
    )

    temp_axis_selected = (
        (z is not None and _is_selected(selected_columns.get("z", "Temp")))
        or (z2 is not None and _is_selected(selected_columns.get("z2", "Temp 2")))
    )
    deriv_axis_selected = y2 is not None and _is_selected(
        selected_columns.get("y2", "Derivative")
    )
    if enable_temp_axis and temp_axis_selected:

        ax2 = ax.twinx()
        try:
            ax2._gl260_axis_role = "right"
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if z is not None and _is_selected(selected_columns.get("z", "Temp")):

            artist = _plot_series(
                ax2,
                x,
                z,
                label=fmt(selected_columns.get("z", "Temp")),
                color="red",
                zorder=3,
                series_key="z",
                scatter_config=scatter_config,
                scatter_series_configs=scatter_series_configs,
            )

            handles.append(artist)

        if z2 is not None and _is_selected(selected_columns.get("z2", "Temp 2")):

            artist = _plot_series(
                ax2,
                x,
                z2,
                label=fmt(selected_columns.get("z2", "Temp 2")),
                color="orange",
                zorder=3,
                line_style="--",
                series_key="z2",
                scatter_config=scatter_config,
                scatter_series_configs=scatter_series_configs,
            )

            handles.append(artist)

        ax2.set_ylim(*twin_y_lim)

        ax2.set_ylabel(
            fig1_temp_label_text,
            color="black",
            rotation=-90,
            labelpad=fig1_temp_labelpad,
            fontsize=fig1_label_fontsize,
        )

        ax2.tick_params(axis="y", labelcolor="black", labelsize=fig1_tick_fontsize)

        ax2.spines["right"].set_color("black")

        ax2.set_zorder(ax.get_zorder() - 1)

        ax.patch.set_visible(False)

        if auto_temp_ticks:

            ax2.yaxis.set_major_locator(AutoLocator())

            ax2.yaxis.set_minor_locator(AutoMinorLocator())

        else:

            ax2.yaxis.set_major_locator(MultipleLocator(twin_maj_tick))

            ax2.yaxis.set_minor_locator(MultipleLocator(twin_min_tick))

        fig1.subplots_adjust(
            bottom=0.164 if (z is not None and z2 is not None) else 0.143
        )

    # ticks for fig1

    if auto_time_ticks:

        ax.xaxis.set_major_locator(AutoLocator())

        ax.xaxis.set_minor_locator(AutoMinorLocator())

    else:

        ax.xaxis.set_major_locator(MultipleLocator(xmaj_tick))

        ax.xaxis.set_minor_locator(MultipleLocator(xmin_tick))

    if auto_y_ticks:

        ax.yaxis.set_major_locator(AutoLocator())

        ax.yaxis.set_minor_locator(AutoMinorLocator())

    else:

        ax.yaxis.set_major_locator(MultipleLocator(ymaj_tick))

        ax.yaxis.set_minor_locator(MultipleLocator(ymin_tick))

    ax.minorticks_on()

    ax.tick_params(
        axis="both", which="major", labelcolor="black", labelsize=fig1_tick_fontsize
    )
    _enforce_axis_text_style(
        ax,
        font_family=fig1_font_family,
        tick_fontsize=fig1_tick_fontsize,
        label_fontsize=fig1_label_fontsize,
    )
    if enable_temp_axis and temp_axis_selected:
        _enforce_axis_text_style(
            ax2,
            font_family=fig1_font_family,
            tick_fontsize=fig1_tick_fontsize,
            label_fontsize=fig1_label_fontsize,
        )

    fig1_peak_artist, fig1_trough_artist = _draw_cycle_markers(ax)

    axes_for_title = (
        [ax, ax2] if enable_temp_axis and temp_axis_selected else [ax]
    )
    _center_titles_to_axes_union(
        fig1,
        axes_for_title,
        title_text,
        suptitle_text,
        fig1_title_fontsize,
        fig1_suptitle_fontsize,
        fig1_font_family,
        fig1_title_pad_pts,
        fig1_suptitle_pad_pts,
        suptitle_y=fig1_suptitle_y,
    )
    fig1_center_x = 0.5
    try:
        axes_union = Bbox.union([axis.get_position() for axis in axes_for_title if axis is not None])
        fig1_center_x = (axes_union.x0 + axes_union.x1) / 2.0
    except Exception:
        fig1_center_x = 0.5
    fig1_xlabel_artist = fig1.supxlabel(
        fig1_x_label_text,
        fontsize=fig1_label_fontsize,
        fontfamily=fig1_font_family if fig1_font_family else None,
        x=fig1_center_x,
    )
    try:
        fig1._gl260_xlabel_text = fig1_xlabel_artist  # type: ignore[attr-defined]
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    handles_filtered, labels_filtered = _filter_none_legend_entries(
        handles, [handle.get_label() for handle in handles]
    )
    if (
        handles_filtered
        and include_moles_in_core_plot_legend
        and not show_cycle_legend_on_core_plots
        and moles_lines
    ):
        # Iterate over moles_lines to apply the per-item logic.
        for line in moles_lines:
            handles_filtered.append(mpatches.Patch(color="none"))
            labels_filtered.append(line)
    if handles_filtered:
        if fig1_legend_wrap:
            ncol_fig1 = max(1, math.ceil(len(handles_filtered) / max(1, fig1_legend_rows)))
        else:
            ncol_fig1 = min(3, len(handles_filtered))
        labels_filtered = [_wrap_legend_label(label) for label in labels_filtered]
        if fig1_legend_alignment == "left":
            fig1_legend_loc = "lower left"
            fig1_legend_anchor = (0.02, 0.02)
        elif fig1_legend_alignment == "right":
            fig1_legend_loc = "lower right"
            fig1_legend_anchor = (0.98, 0.02)
        else:
            fig1_legend_loc = "lower center"
            fig1_legend_anchor = (0.5, 0.02)
        leg_fig1 = fig1.legend(
            handles=handles_filtered,
            labels=labels_filtered,
            loc=fig1_legend_loc,
            bbox_to_anchor=fig1_legend_anchor,
            ncol=ncol_fig1,
            fontsize=fig1_legend_fontsize,
            markerscale=fig1_legend_markerscale,
            **_legend_shadowbox_kwargs(),
        )

        try:
            leg_fig1._gl260_legend_role = "main"  # type: ignore[attr-defined]
            leg_fig1._gl260_markerscale = fig1_legend_markerscale  # type: ignore[attr-defined]
            leg_fig1._gl260_markerscale_base_font = fig1_base_legend_font  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        _make_legend_draggable(leg_fig1)
    _add_cycle_legend(
        ax,
        fig1_peak_artist,
        fig1_trough_artist,
        core_profile=fig1_core_profile,
        base_legend_font=fig1_base_legend_font,
    )

    # Figure 2: pressure + derivative

    fig2, ax_two = plt.subplots(figsize=target_figsize)
    try:
        ax_two._gl260_axis_role = "primary"
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    fig2.subplots_adjust(bottom=0.143, top=0.91, left=0.071, right=0.924)

    handles2 = []

    if y1 is not None and _is_selected(selected_columns.get("y1", "y1")):

        artist = _plot_series(
            ax_two,
            x,
            y1,
            label=fmt(selected_columns.get("y1", "y1")),
            color="blue",
            zorder=2,
            series_key="y1",
            scatter_config=scatter_config,
            scatter_series_configs=scatter_series_configs,
        )

        handles2.append(artist)

    if y3 is not None and _is_selected(selected_columns.get("y3", "y3")):

        artist = _plot_series(
            ax_two,
            x,
            y3,
            label=fmt(selected_columns.get("y3", "y3")),
            color="green",
            zorder=1,
            series_key="y3",
            scatter_config=scatter_config,
            scatter_series_configs=scatter_series_configs,
        )

        handles2.append(artist)

    ax_two.set_xlim(*time_range)

    ax_two.set_ylim(*y_lim)

    ax_two.set_xlabel("")

    ax_two.set_ylabel(
        fig2_primary_label_text,
        fontsize=fig2_label_fontsize,
        labelpad=fig2_primary_labelpad,
    )

    if enable_deriv_axis and deriv_axis_selected:

        ax3 = ax_two.twinx()
        try:
            ax3._gl260_axis_role = "right"
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        artist = _plot_series(
            ax3,
            x,
            y2,
            label=fmt(selected_columns.get("y2", "Derivative")),
            color="red",
            zorder=3,
            series_key="y2",
            scatter_config=scatter_config,
            scatter_series_configs=scatter_series_configs,
        )

        ax3.set_ylim(deriv_y_min, deriv_y_max)

        ax3.set_ylabel(
            fig2_deriv_label_text,
            color="black",
            rotation=-90,
            labelpad=fig2_deriv_labelpad,
            fontsize=fig2_label_fontsize,
        )

        ax3.tick_params(axis="y", labelcolor="black", labelsize=fig2_tick_fontsize)

        ax3.spines["right"].set_color("black")

        ax3.set_zorder(ax_two.get_zorder() - 1)

        ax_two.patch.set_visible(False)

        handles2.append(artist)

        ax3.axhline(y=0, color="black", linestyle="--", linewidth=1, zorder=4)

        if auto_deriv_ticks:

            ax3.yaxis.set_major_locator(AutoLocator())

            ax3.yaxis.set_minor_locator(AutoMinorLocator())

        else:

            ax3.yaxis.set_major_locator(MultipleLocator(deriv_maj_tick))

            ax3.yaxis.set_minor_locator(MultipleLocator(deriv_min_tick))

    # ticks for fig2

    if auto_time_ticks:

        ax_two.xaxis.set_major_locator(AutoLocator())

        ax_two.xaxis.set_minor_locator(AutoMinorLocator())

    else:

        ax_two.xaxis.set_major_locator(MultipleLocator(xmaj_tick))

        ax_two.xaxis.set_minor_locator(MultipleLocator(xmin_tick))

    if auto_y_ticks:

        ax_two.yaxis.set_major_locator(AutoLocator())

        ax_two.yaxis.set_minor_locator(AutoMinorLocator())

    else:

        ax_two.yaxis.set_major_locator(MultipleLocator(ymaj_tick))

        ax_two.yaxis.set_minor_locator(MultipleLocator(ymin_tick))

    ax_two.minorticks_on()

    ax_two.tick_params(
        axis="both", which="major", labelcolor="black", labelsize=fig2_tick_fontsize
    )
    _enforce_axis_text_style(
        ax_two,
        font_family=fig2_font_family,
        tick_fontsize=fig2_tick_fontsize,
        label_fontsize=fig2_label_fontsize,
    )
    if enable_deriv_axis and deriv_axis_selected:
        _enforce_axis_text_style(
            ax3,
            font_family=fig2_font_family,
            tick_fontsize=fig2_tick_fontsize,
            label_fontsize=fig2_label_fontsize,
        )

    fig2_peak_artist, fig2_trough_artist = _draw_cycle_markers(ax_two)

    axes_two_for_title = (
        [ax_two, ax3] if enable_deriv_axis and deriv_axis_selected else [ax_two]
    )
    _center_titles_to_axes_union(
        fig2,
        axes_two_for_title,
        title_text,
        suptitle_text,
        fig2_title_fontsize,
        fig2_suptitle_fontsize,
        fig2_font_family,
        fig2_title_pad_pts,
        fig2_suptitle_pad_pts,
        suptitle_y=fig2_suptitle_y,
    )
    fig2_center_x = 0.5
    try:
        axes_two_union = Bbox.union(
            [axis.get_position() for axis in axes_two_for_title if axis is not None]
        )
        fig2_center_x = (axes_two_union.x0 + axes_two_union.x1) / 2.0
    except Exception:
        fig2_center_x = 0.5
    fig2_xlabel_artist = fig2.supxlabel(
        fig2_x_label_text,
        fontsize=fig2_label_fontsize,
        fontfamily=fig2_font_family if fig2_font_family else None,
        x=fig2_center_x,
    )
    try:
        fig2._gl260_xlabel_text = fig2_xlabel_artist  # type: ignore[attr-defined]
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    handles2_filtered, labels2_filtered = _filter_none_legend_entries(
        handles2, [handle.get_label() for handle in handles2]
    )
    if (
        handles2_filtered
        and include_moles_in_core_plot_legend
        and not show_cycle_legend_on_core_plots
        and moles_lines
    ):
        # Iterate over moles_lines to apply the per-item logic.
        for line in moles_lines:
            handles2_filtered.append(mpatches.Patch(color="none"))
            labels2_filtered.append(line)
    if handles2_filtered:
        if fig2_legend_wrap:
            ncol_fig2 = max(1, math.ceil(len(handles2_filtered) / max(1, fig2_legend_rows)))
        else:
            ncol_fig2 = min(3, len(handles2_filtered))
        labels2_filtered = [_wrap_legend_label(label) for label in labels2_filtered]
        if fig2_legend_alignment == "left":
            fig2_legend_loc = "lower left"
            fig2_legend_anchor = (0.02, 0.02)
        elif fig2_legend_alignment == "right":
            fig2_legend_loc = "lower right"
            fig2_legend_anchor = (0.98, 0.02)
        else:
            fig2_legend_loc = "lower center"
            fig2_legend_anchor = (0.5, 0.02)
        leg_fig2 = fig2.legend(
            handles=handles2_filtered,
            labels=labels2_filtered,
            loc=fig2_legend_loc,
            bbox_to_anchor=fig2_legend_anchor,
            ncol=ncol_fig2,
            fontsize=fig2_legend_fontsize,
            markerscale=fig2_legend_markerscale,
            **_legend_shadowbox_kwargs(),
        )

        try:
            leg_fig2._gl260_legend_role = "main"  # type: ignore[attr-defined]
            leg_fig2._gl260_markerscale = fig2_legend_markerscale  # type: ignore[attr-defined]
            leg_fig2._gl260_markerscale_base_font = fig2_base_legend_font  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        _make_legend_draggable(leg_fig2)
    _add_cycle_legend(
        ax_two,
        fig2_peak_artist,
        fig2_trough_artist,
        core_profile=fig2_core_profile,
        base_legend_font=fig2_base_legend_font,
    )

    try:
        _enforce_gl260_legend_sizing(
            fig1,
            fig1_legend_fontsize,
            fig1_cycle_legend_fontsize,
            font_family=fig1_font_family,
        )
        _enforce_gl260_legend_sizing(
            fig2,
            fig2_legend_fontsize,
            fig2_cycle_legend_fontsize,
            font_family=fig2_font_family,
        )
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    return {"fig1": fig1, "fig2": fig2, "fig_peaks": fig_peaks}


def _collect_gl260_legends(fig: Optional[Figure]) -> List[Any]:
    """Collect gl260 legends.
    Used to gather gl260 legends into a structured payload."""
    if fig is None:
        return []
    legends: List[Any] = []
    seen = set()
    try:
        from matplotlib.legend import Legend
    except Exception:
        Legend = None

    # Closure captures _collect_gl260_legends local context to keep helper logic scoped and invoked directly within _collect_gl260_legends.
    def _is_legend(obj: Any) -> bool:
        """Check whether it is legend.
        Used to gate conditional behavior in the workflow."""
        if obj is None:
            return False
        if Legend is not None:
            return isinstance(obj, Legend)
        return obj.__class__.__name__ == "Legend"

    # Closure captures _collect_gl260_legends local context to keep helper logic scoped and invoked directly within _collect_gl260_legends.
    def _add_legend(obj: Any) -> None:
        """Perform add legend.
        Used to keep the workflow logic localized and testable."""
        if not _is_legend(obj):
            return
        obj_id = id(obj)
        if obj_id in seen:
            return
        seen.add(obj_id)
        legends.append(obj)

    try:
        # Iterate over getattr(fig, "legends", []) or [] to apply the per-item logic.
        for lg in getattr(fig, "legends", []) or []:
            _add_legend(lg)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    try:
        # Iterate over getattr(fig, "axes", []) or [] to apply the per-item logic.
        for ax in getattr(fig, "axes", []) or []:
            try:
                _add_legend(ax.get_legend())
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                # Iterate over ax.get_children() to apply the per-item logic.
                for child in ax.get_children():
                    _add_legend(child)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    try:
        # Iterate over fig.get_children() to apply the per-item logic.
        for child in fig.get_children():
            _add_legend(child)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    return legends


def _gl260_legend_role(legend: Any) -> Optional[str]:
    """Perform gl260 legend role.
    Used to keep the workflow logic localized and testable."""
    role = getattr(legend, "_gl260_legend_role", None)
    if isinstance(role, str):
        role_value = role.strip().lower()
        if role_value in {"main", "cycle"}:
            return role_value
    if getattr(legend, "_combined_main_legend", False):
        return "main"
    if getattr(legend, "_cycle_overlay_legend", False) or getattr(
        legend, "_combined_cycle_legend", False
    ):
        return "cycle"
    return None


def _legend_text_fontsize(legend: Any) -> Optional[float]:
    """Perform legend text fontsize.
    Used to keep the workflow logic localized and testable."""
    if legend is None:
        return None
    try:
        # Iterate over legend.get_texts() or [] to apply the per-item logic.
        for text in legend.get_texts() or []:
            try:
                size = float(text.get_fontsize())
            except Exception:
                continue
            if math.isfinite(size) and size > 0:
                return size
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    try:
        title = legend.get_title()
    except Exception:
        title = None
    if title:
        try:
            size = float(title.get_fontsize())
        except Exception:
            size = None
        if size is not None and math.isfinite(size) and size > 0:
            return size
    return None


def _legend_markerscale_value(legend: Any) -> Optional[float]:
    """Perform legend markerscale value.
    Used to keep the workflow logic localized and testable."""
    if legend is None:
        return None
    scale = getattr(legend, "_gl260_markerscale", None)
    if scale is None:
        getter = getattr(legend, "get_markerscale", None)
        if callable(getter):
            try:
                scale = getter()
            except Exception:
                scale = None
    if scale is None:
        scale = getattr(legend, "_markerscale", None)
    try:
        scale = float(scale)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None
    if not math.isfinite(scale) or scale <= 0:
        return None
    return scale


def _apply_legend_markerscale(legend: Any, target_scale: float) -> None:
    """Apply legend markerscale.
    Used to apply legend markerscale changes to live state."""
    if legend is None:
        return
    try:
        target_scale = float(target_scale)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return
    if not math.isfinite(target_scale) or target_scale <= 0:
        return
    prev_scale = _legend_markerscale_value(legend)
    if prev_scale is None or not math.isfinite(prev_scale) or prev_scale <= 0:
        prev_scale = 1.0
    ratio = target_scale / prev_scale
    if abs(ratio - 1.0) < 1e-3:
        try:
            legend._gl260_markerscale = target_scale  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            if hasattr(legend, "set_markerscale"):
                legend.set_markerscale(target_scale)
            elif hasattr(legend, "_markerscale"):
                legend._markerscale = target_scale  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return
    # Iterate over getattr(legend, "legendHandles", []) or [] to apply the per-item logic.
    for handle in getattr(legend, "legendHandles", []) or []:
        if handle is None:
            continue
        if hasattr(handle, "get_markersize") and hasattr(handle, "set_markersize"):
            try:
                handle.set_markersize(handle.get_markersize() * ratio)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        elif hasattr(handle, "get_sizes") and hasattr(handle, "set_sizes"):
            try:
                sizes = handle.get_sizes()
            except Exception:
                sizes = None
            if sizes is None:
                continue
            try:
                handle.set_sizes([float(s) * (ratio * ratio) for s in sizes])
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
    try:
        legend._gl260_markerscale = target_scale  # type: ignore[attr-defined]
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    try:
        if hasattr(legend, "set_markerscale"):
            legend.set_markerscale(target_scale)
        elif hasattr(legend, "_markerscale"):
            legend._markerscale = target_scale  # type: ignore[attr-defined]
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass


def _resolve_gl260_markerscale(
    legend: Any, target_fontsize: float, prev_fontsize: Optional[float]
) -> Optional[float]:
    """Resolve gl260 markerscale.
    Used to compute gl260 markerscale before rendering or export."""
    if legend is None:
        return None
    if getattr(legend, "_combined_main_legend", False):
        override = _coerce_float(settings.get("combined_legend_markerscale"))
        if override is not None:
            return override
    if getattr(legend, "_combined_cycle_legend", False):
        override = _coerce_float(settings.get("combined_cycle_legend_markerscale"))
        if override is not None:
            return override
    base_font = getattr(legend, "_gl260_markerscale_base_font", None)
    try:
        base_font = float(base_font)
    except Exception:
        base_font = None
    if base_font is not None and math.isfinite(base_font) and base_font > 0:
        return target_fontsize / base_font
    prev_scale = _legend_markerscale_value(legend)
    if prev_scale is None or not math.isfinite(prev_scale) or prev_scale <= 0:
        prev_scale = 1.0
    if prev_fontsize is None or not math.isfinite(prev_fontsize) or prev_fontsize <= 0:
        prev_fontsize = target_fontsize
    if not math.isfinite(target_fontsize) or target_fontsize <= 0:
        return prev_scale
    return prev_scale * (target_fontsize / prev_fontsize)


def _enforce_gl260_legend_sizing(
    fig: Optional[Figure],
    main_fontsize: float,
    cycle_fontsize: float,
    *,
    font_family: Optional[str] = None,
) -> None:
    """Perform enforce gl260 legend sizing.
    Used to keep the workflow logic localized and testable."""
    if fig is None:
        return
    try:
        main_fontsize = float(main_fontsize)
        cycle_fontsize = float(cycle_fontsize)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return
    if not math.isfinite(main_fontsize) or not math.isfinite(cycle_fontsize):
        return
    legends = _collect_gl260_legends(fig)
    if not legends:
        return
    family_value = (font_family or "").strip()
    prop_main = (
        font_manager.FontProperties(size=main_fontsize, family=family_value)
        if family_value
        else font_manager.FontProperties(size=main_fontsize)
    )
    prop_cycle = (
        font_manager.FontProperties(size=cycle_fontsize, family=family_value)
        if family_value
        else font_manager.FontProperties(size=cycle_fontsize)
    )
    legend_frame_kwargs = _legend_shadowbox_kwargs()
    legend_facecolor = legend_frame_kwargs.get("facecolor", DEFAULT_LEGEND_SHADOWBOX_FILL_COLOR)
    legend_edgecolor = legend_frame_kwargs.get("edgecolor", "#444")
    legend_alpha = _coerce_float(legend_frame_kwargs.get("framealpha"))
    if legend_alpha is None or not math.isfinite(legend_alpha):
        legend_alpha = 0.9
    # Iterate over legends to apply the per-item logic.
    for legend in legends:
        try:
            frame = legend.get_frame()
            if frame is not None:
                frame.set_facecolor(legend_facecolor)
                frame.set_edgecolor(legend_edgecolor)
                frame.set_alpha(legend_alpha)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        role = _gl260_legend_role(legend)
        if role == "main":
            target_fontsize = main_fontsize
            legend_prop = prop_main
        elif role == "cycle":
            target_fontsize = cycle_fontsize
            legend_prop = prop_cycle
        else:
            continue
        prev_fontsize = _legend_text_fontsize(legend)
        try:
            # Iterate over legend.get_texts() or [] to apply the per-item logic.
            for txt in legend.get_texts() or []:
                txt.set_fontsize(target_fontsize)
                if legend_prop is not None:
                    txt.set_fontproperties(legend_prop)
            title = legend.get_title()
            if title:
                title.set_fontsize(target_fontsize)
                if legend_prop is not None:
                    title.set_fontproperties(legend_prop)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        target_scale = _resolve_gl260_markerscale(
            legend, target_fontsize, prev_fontsize
        )
        if target_scale is not None:
            _apply_legend_markerscale(legend, target_scale)


def _wrap_legend_label(label: str, max_chars: int = 20) -> str:
    """Wrap legend label.
    Used to format legend label to fit display constraints."""

    if not label:
        return ""
    if not label:
        return ""
    trimmed = label.strip()
    if len(trimmed) <= max_chars:
        return trimmed
    return textwrap.fill(
        trimmed,
        width=max_chars,
        break_long_words=False,
        replace_whitespace=False,
    )


def _normalize_legend_alignment(alignment: Optional[str]) -> str:
    """Normalize legend alignment.
    Used to keep legend alignment consistent across workflows and persistence."""

    candidate = (alignment or "").strip().lower()
    if candidate not in {"left", "center", "right"}:
        return "center"
    return candidate


def _measure_axis_label_extension(axis: Optional[Axes], renderer) -> float:
    """Perform measure axis label extension.
    Used to keep the workflow logic localized and testable."""

    if axis is None:
        return 0.0
    try:
        label = axis.yaxis.get_label()
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return 0.0
    if label is None:
        return 0.0
    try:
        bbox = label.get_window_extent(renderer=renderer)
        if bbox is None:
            return 0.0
        fig_bbox = bbox.transformed(axis.figure.transFigure.inverted())
        axis_bottom = axis.get_position().y0
        return max(0.0, axis_bottom - fig_bbox.y0)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return 0.0


def _apply_legend_anchor_to_artist(
    legend_obj,
    anchor_values,
    *,
    target_ax: Optional[Axes] = None,
    transform=None,
    loc_override=None,
) -> bool:
    """Apply legend anchor to artist.
    Used to apply legend anchor to artist changes to live state."""
    if legend_obj is None:
        return False
    resolved_loc = _normalize_legend_loc_value(loc_override)
    if isinstance(resolved_loc, tuple):
        try:
            legend_obj.set_loc(resolved_loc)
        except Exception:
            try:
                legend_obj._loc = resolved_loc  # type: ignore[attr-defined]
            except Exception:
                pass
        return True
    anchor_pair = _validated_anchor_pair(anchor_values)
    if anchor_pair is None:
        return False
    if transform is None and target_ax is not None:
        transform = target_ax.transAxes
    if transform is None:
        try:
            transform = legend_obj.figure.transFigure
        except Exception:
            transform = None
    try:
        if transform is None:
            legend_obj.set_bbox_to_anchor(anchor_pair)
        else:
            legend_obj.set_bbox_to_anchor(anchor_pair, transform=transform)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return False
    if resolved_loc is not None:
        try:
            legend_obj.set_loc(resolved_loc)
        except Exception:
            try:
                legend_obj._loc = resolved_loc  # type: ignore[attr-defined]
            except Exception:
                pass
    return True


def _resolve_combined_cycle_ref_axis(
    fig: Optional[Figure],
    ax_main: Optional[Axes] = None,
    ax_right: Optional[Axes] = None,
    ax_deriv: Optional[Axes] = None,
    ref_axis_key: Optional[str] = None,
) -> Optional[Axes]:
    """Resolve combined cycle ref axis.
    Used to compute combined cycle ref axis before rendering or export."""
    ref_axis = _normalize_combined_cycle_ref_axis(ref_axis_key)
    if ref_axis == "main" and ax_main is not None:
        return ax_main
    if ref_axis == "right" and ax_right is not None:
        return ax_right
    if ref_axis == "deriv" and ax_deriv is not None:
        return ax_deriv
    if fig is None:
        return ax_main or ax_right or ax_deriv
    axes = []
    # Iterate over getattr(fig, "axes", []) or [] to apply the per-item logic.
    for axis in getattr(fig, "axes", []) or []:
        if axis is None:
            continue
        if getattr(axis, "_gl260_legend_only", False):
            continue
        axes.append(axis)
    role_map = {"main": "primary", "right": "right", "deriv": "third"}
    desired_role = role_map.get(ref_axis)
    if desired_role:
        # Iterate over axes to apply the per-item logic.
        for axis in axes:
            if getattr(axis, "_gl260_axis_role", None) == desired_role:
                return axis
    if ax_main is not None:
        return ax_main
    return axes[0] if axes else None


def _legend_loc_text(loc_value: Any) -> Optional[str]:
    """Perform legend loc text.
    Used to keep the workflow logic localized and testable."""
    loc_map = {
        0: "best",
        1: "upper right",
        2: "upper left",
        3: "lower left",
        4: "lower right",
        5: "right",
        6: "center left",
        7: "center right",
        8: "lower center",
        9: "upper center",
        10: "center",
    }
    normalized = _normalize_legend_loc_value(loc_value)
    if isinstance(normalized, tuple):
        return None
    if isinstance(normalized, int):
        loc_text = loc_map.get(normalized, "upper right")
    elif isinstance(normalized, str):
        loc_text = normalized.strip().lower() or "upper right"
    else:
        loc_text = "upper right"
    if loc_text == "best":
        loc_text = "upper right"
    return loc_text


def _axis_anchor_point_display(
    axis: Optional[Axes], corner: Optional[str], renderer
) -> Optional[Tuple[float, float]]:
    """Perform axis anchor point display.
    Used to keep the workflow logic localized and testable."""
    if axis is None:
        return None
    try:
        bbox = axis.get_window_extent(renderer=renderer)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None
    if bbox is None:
        return None
    corner_key = _normalize_combined_cycle_ref_corner(corner)
    if corner_key == "upper right":
        return (bbox.x1, bbox.y1)
    if corner_key == "upper left":
        return (bbox.x0, bbox.y1)
    if corner_key == "lower right":
        return (bbox.x1, bbox.y0)
    if corner_key == "lower left":
        return (bbox.x0, bbox.y0)
    return ((bbox.x0 + bbox.x1) / 2.0, (bbox.y0 + bbox.y1) / 2.0)


def _legend_anchor_point_display(legend: Any, loc_value: Any, renderer) -> Optional[
    Tuple[float, float]
]:
    """Perform legend anchor point display.
    Used to keep the workflow logic localized and testable."""
    if legend is None:
        return None
    loc_text = _legend_loc_text(loc_value)
    if loc_text is None:
        return None
    try:
        bbox = legend.get_window_extent(renderer=renderer)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None
    if bbox is None:
        return None
    x0, y0, x1, y1 = bbox.x0, bbox.y0, bbox.x1, bbox.y1
    cx = x0 + ((x1 - x0) / 2.0)
    cy = y0 + ((y1 - y0) / 2.0)
    if loc_text in {"upper left", "ul"}:
        return (x0, y1)
    if loc_text in {"upper center", "uc"}:
        return (cx, y1)
    if loc_text in {"upper right", "ur"}:
        return (x1, y1)
    if loc_text in {"lower left", "ll"}:
        return (x0, y0)
    if loc_text in {"lower center", "lc"}:
        return (cx, y0)
    if loc_text in {"lower right", "lr"}:
        return (x1, y0)
    if loc_text in {"center left", "cl", "left"}:
        return (x0, cy)
    if loc_text in {"center right", "cr", "right"}:
        return (x1, cy)
    return (cx, cy)


def _combined_cycle_axis_offset_values() -> tuple[float, float] | None:
    """Return combined cycle legend axis offsets.

    Purpose:
        Load persisted axis-offset values for the combined cycle legend.
    Why:
        Axis offsets reapply drag placement without introducing extra layout
        passes or altering the export pipeline.

    Args:
        None.

    Returns:
        Tuple of (dx, dy) offsets in pixels, or None when persistence is
        disabled or offsets are missing.

    Side Effects:
        None.

    Exceptions:
        Errors are handled internally and return None.
    """
    try:
        if settings.get("combined_cycle_legend_anchor_mode") == "loc_tuple":
            return None
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None
    if not bool(settings.get("combined_cycle_legend_persist_position", True)):
        # Persistence disabled: ignore stored offsets so refresh/rebuild uses defaults.
        return None
    dx = _coerce_float(settings.get("combined_cycle_legend_ref_dx_px"))
    dy = _coerce_float(settings.get("combined_cycle_legend_ref_dy_px"))
    if dx is None or dy is None:
        return None
    return (dx, dy)


def _resolve_combined_cycle_legend_loc() -> Optional[Union[str, int, Tuple[float, float]]]:
    """Resolve combined cycle legend loc.
    Used to compute combined cycle legend loc before rendering or export."""
    loc_value = _normalize_legend_loc_value(settings.get("combined_cycle_legend_loc"))
    if loc_value is not None:
        return loc_value
    loc_choice = settings.get("combined_cycle_legend_loc_choice", "upper right")
    loc_choice_value = _normalize_legend_loc_value(loc_choice)
    return loc_choice_value or "upper right"


def _compute_cycle_legend_offsets_px(
    legend: Any,
    ref_axis: Optional[Axes],
    ref_corner: Optional[str],
    loc_value: Any,
    renderer,
) -> Optional[Tuple[float, float]]:
    """Compute cycle legend offsets px.
    Used to derive cycle legend offsets px for analysis or plotting."""
    ref_point = _axis_anchor_point_display(ref_axis, ref_corner, renderer)
    legend_point = _legend_anchor_point_display(legend, loc_value, renderer)
    if ref_point is None or legend_point is None:
        return None
    dx = legend_point[0] - ref_point[0]
    dy = legend_point[1] - ref_point[1]
    if not (math.isfinite(dx) and math.isfinite(dy)):
        return None
    return (dx, dy)


def _apply_cycle_legend_axis_offset(
    fig: Figure,
    legend: Any,
    ref_axis: Optional[Axes],
    ref_corner: Optional[str],
    dx: float,
    dy: float,
    loc_value: Any,
    *,
    allow_draw: bool = True,
) -> bool:
    """Apply cycle legend axis offset.
    Used to apply cycle legend axis offset changes to live state."""
    if fig is None or legend is None or ref_axis is None:
        return False
    if fig.canvas is None:
        FigureCanvasAgg(fig)
    if allow_draw:
        try:
            fig.canvas.draw()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
    try:
        renderer = fig.canvas.get_renderer()
    except Exception:
        renderer = None
    if renderer is None:
        return False
    ref_point = _axis_anchor_point_display(ref_axis, ref_corner, renderer)
    if ref_point is None:
        return False
    target_display = (ref_point[0] + dx, ref_point[1] + dy)
    try:
        target_axes = ref_axis.transAxes.inverted().transform(target_display)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return False
    loc_text = _legend_loc_text(loc_value)
    if loc_text is None:
        return False
    return _apply_legend_anchor_to_artist(
        legend,
        target_axes,
        transform=ref_axis.transAxes,
        loc_override=loc_text,
    )


def _position_combined_legend(
    fig: Figure,
    ax: Axes,
    legend_ax: Axes,
    legend,
    label_gap_points: float,
    bottom_margin_points: float,
    extra_axes: Optional[Sequence[Axes]] = None,
) -> None:
    """Perform position combined legend.
    Used to keep the workflow logic localized and testable."""

    fig_size = fig.get_size_inches()
    fig_height_in = max(float(fig_size[1]), 1.0)
    fig_height_px = max(fig_height_in * fig.dpi, 1.0)
    fig_height_pts = fig_height_in * 72.0
    gap_frac = (
        _sanitize_spacing_value(
            label_gap_points,
            DEFAULT_COMBINED_LEGEND_GAP_PTS,
            MIN_COMBINED_LEGEND_GAP_PTS,
            MAX_COMBINED_LEGEND_GAP_PTS,
        )
        / fig_height_pts
    )
    bottom_margin_frac = (
        _sanitize_spacing_value(
            bottom_margin_points,
            DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
            MIN_COMBINED_LEGEND_MARGIN_PTS,
            MAX_COMBINED_LEGEND_MARGIN_PTS,
        )
        / fig_height_pts
    )

    renderer = None
    measured_fraction = 0.08
    try:
        canvas = FigureCanvasAgg(fig)
        canvas.draw()
        renderer = canvas.get_renderer()
        legend_bbox = legend.get_window_extent(renderer=renderer)
        measured_fraction = legend_bbox.height / fig_height_px
    except Exception:
        renderer = None
    legend_height = max(0.02, measured_fraction + 0.01)

    axes_to_measure: List[Axes] = [ax]
    if extra_axes:
        axes_to_measure.extend([extra for extra in extra_axes if extra is not None])
    max_label_extension = 0.0
    if renderer is not None:
        # Iterate over axes_to_measure to apply the per-item logic.
        for axis in axes_to_measure:
            max_label_extension = max(
                max_label_extension, _measure_axis_label_extension(axis, renderer)
            )

    main_pos = ax.get_position()
    total_available = max(main_pos.y1 - bottom_margin_frac, 0.3)
    min_main_height = 0.25
    remaining_height = total_available - (
        legend_height + gap_frac + max_label_extension
    )
    if remaining_height < min_main_height:
        deficit = min_main_height - remaining_height
        shrinkable = max(legend_height - 0.02, 0.0)
        reduction = min(deficit, shrinkable)
        legend_height -= reduction
        deficit -= reduction
        remaining_height = total_available - (
            legend_height + gap_frac + max_label_extension
        )
        if deficit > 0 and remaining_height < min_main_height:
            min_gap_frac = (
                (MIN_COMBINED_LEGEND_GAP_PTS / fig_height_pts)
                if fig_height_pts
                else 0.0
            )
            gap_reduction = min(deficit, max(gap_frac - min_gap_frac, 0.0))
            gap_frac = max(gap_frac - gap_reduction, min_gap_frac or 0.0)
            remaining_height = total_available - (
                legend_height + gap_frac + max_label_extension
            )
    main_height = max(remaining_height, 0.12)

    legend_bottom = bottom_margin_frac
    legend_ax.set_position([main_pos.x0, legend_bottom, main_pos.width, legend_height])
    legend_top = legend_bottom + legend_height
    ax_bottom = legend_top + gap_frac + max_label_extension
    ax_height = max(main_pos.y1 - ax_bottom, main_height)
    ax.set_position([main_pos.x0, ax_bottom, main_pos.width, ax_height])

    if extra_axes:
        new_pos = ax.get_position()
        # Iterate over extra_axes to apply the per-item logic.
        for axis in extra_axes:
            if axis is not None:
                axis.set_position(new_pos)


def _apply_combined_horizontal_padding(
    fig: Figure,
    primary_ax: Axes,
    legend_ax: Axes,
    extra_axes: Optional[Sequence[Axes]],
    left_pad_pct: float,
    right_pad_pct: float,
    export_pad_pts: float,
) -> None:
    """Apply combined horizontal padding.
    Used to apply combined horizontal padding changes to live state."""

    extra_axes = list(extra_axes) if extra_axes else []
    try:
        left_pad = max(float(left_pad_pct), 0.0) / 100.0
    except Exception:
        left_pad = 0.0
    try:
        right_pad = max(float(right_pad_pct), 0.0) / 100.0
    except Exception:
        right_pad = 0.0
    try:
        pad_pts = max(float(export_pad_pts), 0.0)
    except Exception:
        pad_pts = DEFAULT_COMBINED_EXPORT_PAD_PTS

    fig_w_in, fig_h_in = fig.get_size_inches()
    pad_frac_x = (pad_pts / 72.0) / fig_w_in if fig_w_in else 0.0
    pad_frac_y = (pad_pts / 72.0) / fig_h_in if fig_h_in else 0.0

    target_left = min(0.98, max(0.0, left_pad + pad_frac_x))
    target_right = max(0.02, min(1.0, 1.0 - right_pad - pad_frac_x))
    target_bottom = max(0.0, pad_frac_y)
    target_top = min(1.0, 1.0 - pad_frac_y)

    overflow_left = overflow_right = 0.0
    overflow_top = overflow_bottom = 0.0
    renderer = None
    try:
        canvas = FigureCanvasAgg(fig)
        canvas.draw()
        renderer = canvas.get_renderer()
    except Exception:
        renderer = None
    if renderer is not None:
        axes_to_check: List[Axes] = [primary_ax, legend_ax, *extra_axes]
        # Iterate over axes_to_check to apply the per-item logic.
        for axis in axes_to_check:
            if axis is None:
                continue
            try:
                tight_bbox = axis.get_tightbbox(renderer)
                if tight_bbox is None:
                    continue
                bbox_fig = tight_bbox.transformed(fig.transFigure.inverted())
                overflow_left = max(overflow_left, max(target_left - bbox_fig.x0, 0.0))
                overflow_right = max(
                    overflow_right, max(bbox_fig.x1 - target_right, 0.0)
                )
                overflow_bottom = max(
                    overflow_bottom, max(target_bottom - bbox_fig.y0, 0.0)
                )
                overflow_top = max(overflow_top, max(bbox_fig.y1 - target_top, 0.0))
            except Exception:
                continue
        title_artists = []
        # Iterate over ("_gl260_title_text", "_gl260_suptitle_text", "_suptitle") to apply the per-item logic.
        for attr in ("_gl260_title_text", "_gl260_suptitle_text", "_suptitle"):
            artist = getattr(fig, attr, None)
            if artist is None or artist in title_artists:
                continue
            title_artists.append(artist)
        # Iterate over title_artists to apply the per-item logic.
        for artist in title_artists:
            try:
                bbox = artist.get_window_extent(renderer=renderer)
                if bbox is None:
                    continue
                bbox_fig = bbox.transformed(fig.transFigure.inverted())
                overflow_left = max(overflow_left, max(target_left - bbox_fig.x0, 0.0))
                overflow_right = max(
                    overflow_right, max(bbox_fig.x1 - target_right, 0.0)
                )
                overflow_bottom = max(
                    overflow_bottom, max(target_bottom - bbox_fig.y0, 0.0)
                )
                overflow_top = max(overflow_top, max(bbox_fig.y1 - target_top, 0.0))
            except Exception:
                continue

    main_pos = primary_ax.get_position()
    legend_pos = legend_ax.get_position()
    total_left = overflow_left + left_pad
    total_right = overflow_right + right_pad
    min_width = 0.32
    target_width = max(main_pos.width - (total_left + total_right), min_width)
    max_x0 = max(target_left, target_right - target_width)
    new_x0 = min(max(main_pos.x0 + total_left - overflow_right, target_left), max_x0)

    min_height = 0.25
    target_height = max(main_pos.height - (overflow_bottom + overflow_top), min_height)
    max_y0 = max(target_bottom, target_top - target_height)
    new_y0 = min(
        max(main_pos.y0 + overflow_bottom - overflow_top, target_bottom), max_y0
    )

    primary_ax.set_position([new_x0, new_y0, target_width, target_height])
    legend_ax.set_position(
        [
            new_x0,
            legend_pos.y0 + overflow_bottom - overflow_top,
            target_width,
            legend_pos.height,
        ]
    )
    if extra_axes:
        # Iterate over extra_axes to apply the per-item logic.
        for axis in extra_axes:
            if axis is None:
                continue
            axis.set_position([new_x0, new_y0, target_width, target_height])


class PlotLayoutManager:
    """Deterministic layout solver for combined triple-axis figures."""

    def __init__(
        self,
        fig: Figure,
        *,
        mode: str = "display",
        baseline_margins: Optional[Mapping[str, float]] = None,
        left_pad_pct: float = 0.0,
        right_pad_pct: float = 0.0,
        export_pad_pts: float = 0.0,
        legend_gap_pts: float = DEFAULT_COMBINED_LEGEND_GAP_PTS,
        xlabel_tick_gap_pts: float = DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS,
        legend_margin_pts: float = DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
        title_pad_pts: float = DEFAULT_COMBINED_TITLE_PAD_PTS,
        suptitle_pad_pts: float = DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
        suptitle_y: float = DEFAULT_COMBINED_SUPTITLE_Y,
        top_margin_pct: float = DEFAULT_COMBINED_TOP_MARGIN_PCT,
        legend_anchor: Optional[Tuple[float, float]] = None,
        legend_anchor_y: Optional[float] = None,
        xlabel_pad_pts: float = 0.0,
    ) -> None:
        """Initialize PlotLayoutManager instance.
        Used at object creation to configure initial state and bindings."""
        self.fig = fig
        self.mode = "export" if str(mode).lower() == "export" else "display"
        if baseline_margins is None:
            baseline_margins = {}
        self._baseline_left = None
        self._baseline_right = None
        self._baseline_top = None
        self._baseline_bottom = None
        # Iterate to apply the per-item logic.
        for key, attr in (
            ("left", "_baseline_left"),
            ("right", "_baseline_right"),
            ("top", "_baseline_top"),
            ("bottom", "_baseline_bottom"),
        ):
            try:
                raw = float(baseline_margins.get(key))
            except Exception:
                raw = None
            if raw is not None and math.isfinite(raw):
                setattr(self, attr, max(0.0, min(1.0, raw)))
        self.left_pad_pct = float(left_pad_pct or 0.0)
        self.right_pad_pct = float(right_pad_pct or 0.0)
        self.export_pad_pts = float(export_pad_pts or 0.0)
        self.legend_gap_pts = float(legend_gap_pts or 0.0)
        self.xlabel_tick_gap_pts = float(xlabel_tick_gap_pts or 0.0)
        self.legend_margin_pts = float(legend_margin_pts or 0.0)
        self.title_pad_pts = float(title_pad_pts or 0.0)
        self.suptitle_pad_pts = float(suptitle_pad_pts or 0.0)
        self.suptitle_y = float(suptitle_y or DEFAULT_COMBINED_SUPTITLE_Y)
        self.top_margin_pct = float(top_margin_pct or DEFAULT_COMBINED_TOP_MARGIN_PCT)
        self.legend_anchor = _validated_anchor_pair(legend_anchor)
        self.legend_anchor_y = None
        if legend_anchor_y is not None:
            try:
                anchor_value = float(legend_anchor_y)
            except Exception:
                anchor_value = None
            if anchor_value is not None and math.isfinite(anchor_value):
                self.legend_anchor_y = max(-0.1, min(1.1, anchor_value))
        self.xlabel_pad_pts = float(xlabel_pad_pts or 0.0)
        self.legend_alignment = "center"
        self._axes: List[Axes] = []
        self._artists: Dict[str, Any] = {}

    def register_axes(self, *axes: Optional[Axes]) -> None:
        """Perform register axes.
        Used to keep the workflow logic localized and testable."""
        self._axes = [ax for ax in axes if ax is not None and ax.get_visible()]

    def register_artist(self, key: str, artist: Any) -> None:
        """Perform register artist.
        Used to keep the workflow logic localized and testable."""
        if artist is None:
            return
        self._artists[key] = artist

    def set_legend_alignment(self, alignment: str) -> None:
        """Set legend alignment.
        Used to persist legend alignment into the current state."""
        self.legend_alignment = _normalize_legend_alignment(alignment)

    def _get_renderer(self, allow_draw: bool = True):
        """Return renderer.
        Used to retrieve renderer for downstream logic."""
        canvas = self.fig.canvas
        if canvas is None:
            canvas = FigureCanvasAgg(self.fig)
            try:
                self.fig.set_canvas(canvas)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if allow_draw:
            try:
                canvas.draw()
            except Exception:
                try:
                    canvas.draw_idle()
                    canvas.draw()
                except Exception:
                    pass
        try:
            return canvas.get_renderer()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None

    def _bbox_in_fig(self, artist: Any, renderer) -> Optional[Bbox]:
        """Perform bbox in fig.
        Used to keep the workflow logic localized and testable."""
        if artist is None or renderer is None:
            return None
        try:
            bbox = artist.get_window_extent(renderer=renderer)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        if bbox is None:
            return None
        try:
            return bbox.transformed(self.fig.transFigure.inverted())
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None

    def _axes_union_position(self) -> Optional[Bbox]:
        """Perform axes union position.
        Used to keep the workflow logic localized and testable."""
        positions = []
        # Iterate over self._axes to apply the per-item logic.
        for ax in self._axes:
            try:
                if not ax.get_visible():
                    continue
                positions.append(ax.get_position())
            except Exception:
                continue
        if not positions:
            return None
        try:
            return Bbox.union(positions)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None

    def _axes_tight_union(self, renderer) -> Optional[Bbox]:
        """Perform axes tight union.
        Used to keep the workflow logic localized and testable."""
        bboxes = []
        # Iterate over self._axes to apply the per-item logic.
        for ax in self._axes:
            try:
                if not ax.get_visible():
                    continue
                tight = ax.get_tightbbox(renderer)
            except Exception:
                tight = None
            if tight is None:
                continue
            try:
                bboxes.append(tight.transformed(self.fig.transFigure.inverted()))
            except Exception:
                continue
        if not bboxes:
            return None
        try:
            return Bbox.union(bboxes)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None

    def _legend_anchor(
        self, pad: float, center_x: Optional[float] = None
    ) -> Tuple[str, float]:
        """Perform legend anchor.
        Used to keep the workflow logic localized and testable."""
        alignment = _normalize_legend_alignment(self.legend_alignment)
        if alignment == "left":
            return ("lower left", pad)
        if alignment == "right":
            return ("lower right", 1.0 - pad)
        if center_x is None:
            center_x = self.fig.subplotpars.left + (
                (self.fig.subplotpars.right - self.fig.subplotpars.left) / 2.0
            )
        return ("lower center", center_x)

    def solve(self, *, max_passes: int = 3, allow_draw: bool = True) -> None:
        """Solve value.
        Used to run the solver for value workflows."""
        if not self._axes:
            return
        # Conservative margins: prioritize visibility over tightness.

        fig_w_in, fig_h_in = self.fig.get_size_inches()
        fig_w_in = max(float(fig_w_in), 1.0)
        fig_h_in = max(float(fig_h_in), 1.0)
        fig_h_pts = max(fig_h_in * 72.0, 1.0)

        pad_frac_x = 0.0
        pad_frac_y = 0.0
        if self.mode == "export":
            pad_frac_x = (self.export_pad_pts / 72.0) / fig_w_in
            pad_frac_y = (self.export_pad_pts / 72.0) / fig_h_in

        legend_xlabel_gap_frac = max(self.legend_gap_pts / fig_h_pts, 0.0)
        xlabel_tick_gap_frac = max(self.xlabel_tick_gap_pts / fig_h_pts, 0.0)
        legend_margin_frac = max(self.legend_margin_pts / fig_h_pts, 0.006)
        title_gap_frac = max(self.title_pad_pts / fig_h_pts, 0.01)
        suptitle_gap_frac = max(self.suptitle_pad_pts / fig_h_pts, 0.01)
        epsilon_frac = 3.0 / fig_h_pts
        xlabel_pad_frac = self.xlabel_pad_pts / fig_h_pts

        base_left = (
            self._baseline_left
            if self._baseline_left is not None
            else self.fig.subplotpars.left
        )
        base_right = (
            self._baseline_right
            if self._baseline_right is not None
            else self.fig.subplotpars.right
        )
        base_bottom = (
            self._baseline_bottom
            if self._baseline_bottom is not None
            else self.fig.subplotpars.bottom
        )
        base_top = (
            self._baseline_top
            if self._baseline_top is not None
            else self.fig.subplotpars.top
        )
        left = max(
            base_left,
            self.left_pad_pct / 100.0 + pad_frac_x,
            0.08,
        )
        right = min(
            base_right,
            1.0 - self.right_pad_pct / 100.0 - pad_frac_x,
            0.98,
        )
        bottom = max(base_bottom, pad_frac_y, 0.1)
        top = min(
            base_top,
            max(0.6, 1.0 - (self.top_margin_pct / 100.0) - pad_frac_y),
        )
        last_state = None

        title = self._artists.get("title")
        suptitle = self._artists.get("suptitle")
        xlabel = self._artists.get("xlabel")
        legend = self._artists.get("plot_legend")
        cycle_legend = self._artists.get("cycle_legend")
        primary_axis = self._axes[0] if self._axes else None

        # Iterate over the configured range to apply the per-item logic.
        for _ in range(max_passes):
            self.fig.subplots_adjust(left=left, right=right, bottom=bottom, top=top)
            renderer = self._get_renderer(allow_draw)
            axes_bbox = self._axes_union_position()
            main_center_x = None
            if primary_axis is not None:
                try:
                    pos = primary_axis.get_position()
                    main_center_x = pos.x0 + (pos.width / 2.0)
                except Exception:
                    main_center_x = None

            if title is not None and axes_bbox is not None and axes_bbox.height > 0:
                title_bbox = self._bbox_in_fig(title, renderer)
                if title_bbox is not None:
                    desired_bottom = axes_bbox.y1 + title_gap_frac
                    desired_center = desired_bottom + (title_bbox.height / 2.0)
                    axes_y = (desired_center - axes_bbox.y0) / axes_bbox.height
                    try:
                        title.set_position((0.5, max(1.0, axes_y)))
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            if suptitle is not None:
                base_y = max(0.85, min(0.98, self.suptitle_y))
                try:
                    suptitle.set_y(base_y)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                if main_center_x is not None:
                    try:
                        suptitle.set_x(main_center_x)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            anchor_x = None
            anchor_y = None
            if self.legend_anchor is not None:
                anchor_x, anchor_y = self.legend_anchor
            legend_anchor_y = max(legend_margin_frac, pad_frac_y)
            if anchor_y is not None:
                legend_anchor_y = max(legend_anchor_y, anchor_y)
            if self.legend_anchor_y is not None:
                legend_anchor_y = max(legend_anchor_y, self.legend_anchor_y)
            if legend is not None:
                loc = None
                if anchor_x is None:
                    loc, anchor_x = self._legend_anchor(
                        max(0.0, pad_frac_x), main_center_x
                    )
                try:
                    if loc is not None:
                        legend.set_loc(loc)
                    legend.set_bbox_to_anchor(
                        (anchor_x, legend_anchor_y),
                        transform=self.fig.transFigure,
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

            renderer = self._get_renderer(allow_draw)
            legend_bbox = self._bbox_in_fig(legend, renderer) if legend else None
            if legend is not None and legend_bbox is not None:
                if legend_bbox.y0 < legend_anchor_y:
                    shift = legend_anchor_y - legend_bbox.y0
                    if anchor_x is None:
                        loc, anchor_x = self._legend_anchor(
                            max(0.0, pad_frac_x), main_center_x
                        )
                    try:
                        legend.set_bbox_to_anchor(
                            (anchor_x, legend_bbox.y0 + shift),
                            transform=self.fig.transFigure,
                        )
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            renderer = self._get_renderer(allow_draw)
            data_axes_tight = self._axes_tight_union(renderer)
            legend_bbox = self._bbox_in_fig(legend, renderer) if legend else None
            xlabel_bbox = self._bbox_in_fig(xlabel, renderer) if xlabel else None
            xlabel_anchor_x = None
            if xlabel is not None:
                xlabel_height = xlabel_bbox.height if xlabel_bbox is not None else 0.02
                axes_ref = data_axes_tight if data_axes_tight is not None else axes_bbox
                if axes_ref is None:
                    baseline = (
                        legend_bbox.y1 if legend_bbox is not None else legend_anchor_y
                    )
                    desired_y = baseline + legend_xlabel_gap_frac + (xlabel_height / 2.0)
                    desired_y += xlabel_pad_frac
                else:
                    desired_y = (
                        axes_ref.y0 - xlabel_tick_gap_frac - (xlabel_height / 2.0)
                    )
                    desired_y += xlabel_pad_frac
                if legend_bbox is not None:
                    min_center = (
                        legend_bbox.y1
                        + legend_xlabel_gap_frac
                        + (xlabel_height / 2.0)
                    )
                    if desired_y < min_center:
                        desired_y = min_center
                try:
                    xlabel_anchor_x = main_center_x
                    if xlabel_anchor_x is None:
                        xlabel_anchor_x = self.fig.subplotpars.left + (
                            (self.fig.subplotpars.right - self.fig.subplotpars.left)
                            / 2.0
                        )
                    xlabel.set_position((xlabel_anchor_x, desired_y))
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

            renderer = self._get_renderer(allow_draw)
            legend_bbox = self._bbox_in_fig(legend, renderer) if legend else None
            xlabel_bbox = self._bbox_in_fig(xlabel, renderer) if xlabel else None
            if xlabel_bbox is not None:
                bottom = max(bottom, xlabel_bbox.y1 + xlabel_tick_gap_frac)
            if legend_bbox is not None and xlabel_bbox is not None:
                gap = xlabel_bbox.y0 - legend_bbox.y1
                if gap < legend_xlabel_gap_frac:
                    shift = (legend_xlabel_gap_frac - gap) + epsilon_frac
                    try:
                        if xlabel_anchor_x is None:
                            xlabel_anchor_x = main_center_x
                            if xlabel_anchor_x is None:
                                xlabel_anchor_x = self.fig.subplotpars.left + (
                                    (
                                        self.fig.subplotpars.right
                                        - self.fig.subplotpars.left
                                    )
                                    / 2.0
                                )
                        xlabel.set_position(
                            (xlabel_anchor_x, xlabel.get_position()[1] + shift)
                        )
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                    renderer = self._get_renderer(allow_draw)
                    xlabel_bbox = (
                        self._bbox_in_fig(xlabel, renderer) if xlabel else None
                    )
                    if xlabel_bbox is not None:
                        bottom = max(bottom, xlabel_bbox.y1 + xlabel_tick_gap_frac)
            renderer = self._get_renderer(allow_draw)
            title_bbox = self._bbox_in_fig(title, renderer) if title else None
            suptitle_bbox = self._bbox_in_fig(suptitle, renderer) if suptitle else None

            if suptitle is not None and suptitle_bbox is not None:
                if suptitle_bbox.y1 > 1.0 - pad_frac_y:
                    try:
                        suptitle.set_y(
                            suptitle.get_position()[1]
                            - (suptitle_bbox.y1 - (1.0 - pad_frac_y))
                        )
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            renderer = self._get_renderer(allow_draw)
            suptitle_bbox = self._bbox_in_fig(suptitle, renderer) if suptitle else None

            if (
                cycle_legend is not None
                and primary_axis is not None
                and axes_bbox is not None
            ):
                cycle_anchor_setting = _validated_anchor_pair(
                    settings.get("combined_cycle_legend_anchor")
                )
                if cycle_anchor_setting is None:
                    cycle_loc_choice = settings.get(
                        "combined_cycle_legend_loc_choice", "upper right"
                    )
                    normalized_cycle_loc = _normalize_legend_loc_value(cycle_loc_choice)
                    if normalized_cycle_loc is None:
                        normalized_cycle_loc = "upper right"
                    try:
                        if normalized_cycle_loc is not None:
                            cycle_legend.set_loc(normalized_cycle_loc)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            renderer = self._get_renderer(allow_draw)
            data_axes_tight = self._axes_tight_union(renderer)
            if cycle_legend is not None:
                cycle_bbox = self._bbox_in_fig(cycle_legend, renderer)
            else:
                cycle_bbox = None
            if data_axes_tight is not None and cycle_bbox is not None:
                union_lr = Bbox.union([data_axes_tight, cycle_bbox])
            else:
                union_lr = data_axes_tight if data_axes_tight is not None else cycle_bbox

            if union_lr is not None:
                if union_lr.x0 < max(0.0, pad_frac_x):
                    left = min(
                        right - 0.1,
                        max(left + (max(0.0, pad_frac_x) - union_lr.x0), 0.05),
                    )
                if union_lr.x1 > 1.0 - max(0.0, pad_frac_x):
                    right = max(
                        left + 0.1,
                        min(
                            right - (union_lr.x1 - (1.0 - max(0.0, pad_frac_x))),
                            0.98,
                        ),
                    )
            if data_axes_tight is not None and xlabel_bbox is not None:
                min_axes_bottom = xlabel_bbox.y1 + xlabel_tick_gap_frac
                if data_axes_tight.y0 < min_axes_bottom:
                    bottom = max(
                        bottom, bottom + (min_axes_bottom - data_axes_tight.y0)
                    )

            if (
                suptitle_bbox is not None
                and title_bbox is not None
                and suptitle_bbox.y0 < title_bbox.y1 + suptitle_gap_frac
            ):
                overlap = (title_bbox.y1 + suptitle_gap_frac) - suptitle_bbox.y0
                top = max(bottom + 0.2, top - overlap)

            new_state = (
                round(left, 4),
                round(right, 4),
                round(bottom, 4),
                round(top, 4),
            )
            if new_state == last_state:
                break
            last_state = new_state


def build_combined_triple_axis_figure(
    min_time,
    max_time,
    min_y,
    max_y,
    twin_y_min,
    twin_y_max,
    deriv_y_min,
    deriv_y_max,
    auto_time_ticks,
    auto_y_ticks,
    auto_temp_ticks,
    auto_deriv_ticks,
    title_text,
    suptitle_text,
    xmaj_tick,
    xmin_tick,
    ymaj_tick,
    ymin_tick,
    twin_maj_tick,
    twin_min_tick,
    deriv_maj_tick,
    deriv_min_tick,
    enable_temp_axis,
    enable_deriv_axis,
    deriv_axis_offset,
    legend_wrap=False,
    legend_rows=None,
    legend_alignment="center",
    legend_label_gap_pts=DEFAULT_COMBINED_LEGEND_GAP_PTS,
    xlabel_tick_gap_pts=DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS,
    legend_bottom_margin_pts=DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
    left_pad_pct=DEFAULT_COMBINED_LEFT_PAD_PCT,
    right_pad_pct=DEFAULT_COMBINED_RIGHT_PAD_PCT,
    export_pad_pts=DEFAULT_COMBINED_EXPORT_PAD_PTS,
    suptitle_fontsize=DEFAULT_COMBINED_SUPTITLE_FONTSIZE,
    title_fontsize=DEFAULT_COMBINED_TITLE_FONTSIZE,
    label_fontsize_override=DEFAULT_COMBINED_LABEL_FONTSIZE,
    tick_fontsize_override=DEFAULT_COMBINED_TICK_FONTSIZE,
    legend_fontsize_override=DEFAULT_COMBINED_LEGEND_FONTSIZE,
    cycle_legend_fontsize_override=None,
    font_family: str = DEFAULT_COMBINED_FONT_FAMILY,
    title_pad_pts=DEFAULT_COMBINED_TITLE_PAD_PTS,
    suptitle_pad_pts=DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
    suptitle_y=DEFAULT_COMBINED_SUPTITLE_Y,
    top_margin_pct=DEFAULT_COMBINED_TOP_MARGIN_PCT,
    baseline_margins=None,
    legend_anchor_y=None,
    xlabel_pad_pts=None,
    axis_label_overrides=None,
    labelpad_overrides=None,
    left_dataset_key="y1",
    right_dataset_key="z",
    third_dataset_key="y2",
    show_cycle_markers_on_core_plots=False,
    show_cycle_legend_on_core_plots=False,
    include_moles_in_core_plot_legend=False,
    legend_anchor=None,
    cycle_legend_anchor=None,
    legend_loc=None,
    cycle_legend_loc=None,
    cycle_legend_anchor_space=None,
    mode: str = "display",
    fig_size=None,
    render_ctx: Optional[RenderContext] = None,
):
    """Build the combined triple-axis figure for display/export workflows.

    Purpose:
        Assemble the combined triple-axis plot with legends, overlays, and layout
        rules that keep the interactive display and export pipeline aligned.
    Why:
        The combined plot is the authoritative multi-axis view; rebuilding it in
        one routine preserves consistent legend placement and export geometry.

    Args:
        min_time/max_time/etc.: Numeric axis limits and tick settings in data
            units; tick spacing values are floats.
        legend_anchor/cycle_legend_anchor: (x, y) tuple in normalized figure or
            axes fraction coordinates (0-1 with small tolerance).
        cycle_legend_anchor_space: "figure" or "axes" to interpret the anchor.
        mode: "display" or "export" to control layout solving behavior.
        fig_size: Optional (width, height) in inches for display rendering.
        render_ctx: Optional RenderContext payload for prepared data/overlays.

    Returns:
        Matplotlib Figure configured with axes, legends, and layout manager.

    Side Effects:
        Writes legend/axis metadata onto the Figure and may update settings when
        cycle legend offsets are migrated for export consistency.

    Exceptions:
        Internal rendering errors are caught and ignored to keep UI flows alive.
    """
    # Combined triple-axis pipeline: one primary axis shares the x-scale with
    # optional temperature/derivative axes, so preview and export stay aligned
    # while supporting detached right-side spines and overlay annotations.
    from matplotlib.ticker import AutoLocator, AutoMinorLocator, MultipleLocator

    mode_value = (mode or "display").strip().lower()
    if mode_value not in {"display", "export"}:
        mode_value = "display"

    if mode_value == "export":
        target_figsize = (11.0, 8.5)
    else:
        target_figsize = tuple(fig_size) if fig_size else (11.0, 8.5)

    # Display/export separation: display follows the live canvas, export uses a
    # fixed size to avoid layout drift between preview and saved artifacts.
    fig = Figure(figsize=target_figsize)
    if mode_value == "export":
        fig.set_size_inches(target_figsize, forward=True)

    # Detached derivative axis uses an offset spine so the second right axis does
    # not collide with temperature labels or legends.
    try:
        offset_val = float(deriv_axis_offset or 1.12)
    except Exception:
        offset_val = 1.12
    if not math.isfinite(offset_val):
        offset_val = 1.12
    deriv_spine_offset = max(1.10, offset_val)

    ax = fig.add_subplot(1, 1, 1)
    try:
        ax._gl260_axis_role = "primary"
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    data_ctx = render_ctx.data_ctx if render_ctx else {}
    style_ctx = render_ctx.style_ctx if render_ctx else {}
    gates_ctx = render_ctx.gates_ctx if render_ctx else {}
    overlay_ctx = render_ctx.overlay_ctx if render_ctx else {}

    show_cycle_markers_on_core_plots = bool(
        gates_ctx.get("show_cycle_markers", show_cycle_markers_on_core_plots)
    )
    show_cycle_legend_on_core_plots = bool(
        gates_ctx.get("show_cycle_legend", show_cycle_legend_on_core_plots)
    )
    include_moles_in_core_plot_legend = bool(
        gates_ctx.get("include_moles", include_moles_in_core_plot_legend)
    )

    scatter_config = style_ctx.get("scatter_config")
    scatter_series_configs = style_ctx.get("scatter_series_configs")

    series_map = data_ctx.get("series") or {}
    series_np = data_ctx.get("series_np") or {}
    selected_columns = data_ctx.get("selected_columns") or globals().get(
        "selected_columns", {}
    )

    x = series_np.get("x", series_map.get("x", globals().get("x")))
    y1 = series_np.get("y1", series_map.get("y1", globals().get("y1")))
    y2 = series_np.get("y2", series_map.get("y2", globals().get("y2")))
    y3 = series_np.get("y3", series_map.get("y3", globals().get("y3")))
    z = series_np.get("z", series_map.get("z", globals().get("z")))
    z2 = series_np.get("z2", series_map.get("z2", globals().get("z2")))
    fmt = _format_axis_label
    svg_safe = _svg_safe_text
    handles = []
    line_map: Dict[str, Any] = {}
    time_range = (min_time, max_time)
    ax_temp: Optional[Axes] = None
    ax_deriv: Optional[Axes] = None
    ax_overlay: Optional[Axes] = None
    label_overrides = (
        axis_label_overrides if isinstance(axis_label_overrides, dict) else {}
    )
    pad_overrides = labelpad_overrides if isinstance(labelpad_overrides, dict) else {}
    family_value = (font_family or "").strip()
    label_fontsize = _sanitize_spacing_value(
        label_fontsize_override,
        DEFAULT_COMBINED_LABEL_FONTSIZE,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    tick_fontsize = _sanitize_spacing_value(
        tick_fontsize_override,
        DEFAULT_COMBINED_TICK_FONTSIZE,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    suptitle_fontsize_value = _sanitize_spacing_value(
        suptitle_fontsize,
        DEFAULT_COMBINED_SUPTITLE_FONTSIZE,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    title_fontsize_value = _sanitize_spacing_value(
        title_fontsize,
        DEFAULT_COMBINED_TITLE_FONTSIZE,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    legend_fontsize_value = _sanitize_spacing_value(
        legend_fontsize_override,
        DEFAULT_COMBINED_LEGEND_FONTSIZE,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    if cycle_legend_fontsize_override is None:
        cycle_legend_fontsize_override = legend_fontsize_value
    cycle_legend_fontsize_value = _sanitize_spacing_value(
        cycle_legend_fontsize_override,
        legend_fontsize_value,
        MIN_COMBINED_FONT_SIZE,
        MAX_COMBINED_FONT_SIZE,
    )
    legend_markerscale = _coerce_float(settings.get("combined_legend_markerscale"))
    if legend_markerscale is None:
        legend_markerscale = legend_fontsize_value / DEFAULT_COMBINED_LEGEND_FONTSIZE
    cycle_legend_markerscale = _coerce_float(
        settings.get("combined_cycle_legend_markerscale")
    )
    if cycle_legend_markerscale is None:
        cycle_legend_markerscale = (
            cycle_legend_fontsize_value / DEFAULT_COMBINED_LEGEND_FONTSIZE
        )

    def _fmt_safe(value: Any) -> str:
        """Perform fmt safe.
        Used to keep the workflow logic localized and testable."""
        return svg_safe(fmt(value))

    def _text_safe(value: Any) -> str:
        """Perform text safe.
        Used to keep the workflow logic localized and testable."""
        return svg_safe(value)

    def _label_or_default(key: str, default: str) -> str:
        """Return default value.
        Used by label or workflows to return value."""
        raw = label_overrides.get(key)
        if raw is None:
            return default
        text = str(raw).strip()
        return _fmt_safe(text) if text else default

    def _pad_or_default(key: str, default: float) -> float:
        """Pad or default.
        Used to add spacing to or default for layout alignment."""
        try:
            candidate = float(pad_overrides.get(key))
            if math.isfinite(candidate):
                return candidate
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return default

    default_x_label = _fmt_safe(selected_columns.get("x", "Time"))
    x_label_text = _label_or_default("x", default_x_label)
    primary_labelpad = _pad_or_default("primary", yaxis_labelpad_amount)
    temp_labelpad = _pad_or_default("temperature", twinyaxis_labelpad_amount)
    deriv_labelpad = _pad_or_default("derivative", 15)
    left_pad_value = _sanitize_spacing_value(
        left_pad_pct,
        DEFAULT_COMBINED_LEFT_PAD_PCT,
        MIN_COMBINED_SIDE_PAD_PCT,
        MAX_COMBINED_SIDE_PAD_PCT,
    )
    right_pad_value = _sanitize_spacing_value(
        right_pad_pct,
        DEFAULT_COMBINED_RIGHT_PAD_PCT,
        MIN_COMBINED_SIDE_PAD_PCT,
        MAX_COMBINED_SIDE_PAD_PCT,
    )
    title_pad_value = _sanitize_spacing_value(
        title_pad_pts,
        DEFAULT_COMBINED_TITLE_PAD_PTS,
        MIN_COMBINED_TITLE_PAD_PTS,
        MAX_COMBINED_TITLE_PAD_PTS,
    )
    suptitle_pad_value = _sanitize_spacing_value(
        suptitle_pad_pts,
        DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
        MIN_COMBINED_SUPTITLE_PAD_PTS,
        MAX_COMBINED_SUPTITLE_PAD_PTS,
    )
    suptitle_y_value = _sanitize_spacing_value(
        suptitle_y,
        DEFAULT_COMBINED_SUPTITLE_Y,
        MIN_COMBINED_SUPTITLE_Y,
        MAX_COMBINED_SUPTITLE_Y,
    )
    top_margin_value = _sanitize_spacing_value(
        top_margin_pct,
        DEFAULT_COMBINED_TOP_MARGIN_PCT,
        MIN_COMBINED_TOP_MARGIN_PCT,
        MAX_COMBINED_TOP_MARGIN_PCT,
    )
    try:
        xlabel_pad_value = float(xlabel_pad_pts) if xlabel_pad_pts is not None else 0.0
    except Exception:
        xlabel_pad_value = 0.0
    if not math.isfinite(xlabel_pad_value):
        xlabel_pad_value = 0.0

    def _apply_axis_ticks(axis, auto_flag, major_tick, minor_tick):
        """Apply axis ticks.
        Used to apply axis ticks changes to live state."""
        if auto_flag:
            axis.yaxis.set_major_locator(AutoLocator())
            axis.yaxis.set_minor_locator(AutoMinorLocator())
        else:
            axis.yaxis.set_major_locator(MultipleLocator(major_tick))
            axis.yaxis.set_minor_locator(MultipleLocator(minor_tick))
        axis.minorticks_on()
        axis.tick_params(
            axis="y", which="major", labelcolor="black", labelsize=tick_fontsize
        )

    def _apply_tick_font(axis):
        """Apply tick font.
        Used to apply tick font changes to live state."""
        if not family_value:
            return
        try:
            labels = list(axis.get_xticklabels()) + list(axis.get_yticklabels())
            # Iterate over labels to apply the per-item logic.
            for lbl in labels:
                lbl.set_fontfamily(family_value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _position_extra_axis(axis, location):
        """Perform position extra axis.
        Used to keep the workflow logic localized and testable."""
        axis.set_frame_on(True)
        axis.patch.set_visible(False)
        # Iterate over values from axis.spines to apply the per-item logic.
        for spine in axis.spines.values():
            spine.set_visible(False)
        right_spine = axis.spines["right"]
        right_spine.set_visible(True)
        right_spine.set_position(("axes", location))
        right_spine.set_color("black")

    def _combined_render_debug(message: str, *args: Any) -> None:
        """Emit combined render debug logs when plotting.render is enabled.

        Purpose:
            Write deterministic verification logs for combined layering behavior.
        Why:
            Layering bugs are difficult to inspect without runtime logs showing
            axis order and per-artist z-order resolution.
        Inputs:
            message: Logger format string.
            *args: Format arguments consumed by the logger.
        Outputs:
            None.
        Side Effects:
            Writes to the module debug logger when debug/category gates are on.
        Exceptions:
            Logging errors are suppressed to preserve render stability.
        """
        try:
            if not bool(settings.get("debug_enabled", False)):
                return
            categories = settings.get("debug_categories")
            if not isinstance(categories, dict):
                return
            if not bool(categories.get("plotting.render", False)):
                return
            _GL260_LOGGER.debug("[plotting.render] " + message, *args)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _iter_artist_handles(artist_obj: Any) -> List[Any]:
        """Return a flat list of artist handles from one or many artist objects.

        Purpose:
            Normalize artist return values so z-order enforcement can apply to
            single artists and multi-artist series payloads.
        Why:
            Some render paths can evolve to return grouped artists; layering must
            still be enforced on every created artist.
        Inputs:
            artist_obj: One artist or a collection of artists.
        Outputs:
            Flat list of artist objects supporting matplotlib artist APIs.
        Side Effects:
            None.
        Exceptions:
            Non-iterable or unsupported values are safely ignored.
        """
        if artist_obj is None:
            return []
        if isinstance(artist_obj, (list, tuple, set)):
            artists: List[Any] = []
            # Iterate over artist_obj to flatten nested artist groups.
            for item in artist_obj:
                artists.extend(_iter_artist_handles(item))
            return artists
        return [artist_obj]

    def _apply_artist_zorder(artist_obj: Any, z_value: float) -> None:
        """Apply one z-order value to every artist associated with a series.

        Purpose:
            Enforce resolved trace layering on all artists created for a series.
        Why:
            Series can contain more than one artist, and each one must carry the
            same resolved z-order for deterministic stacking behavior.
        Inputs:
            artist_obj: One or many matplotlib artists for the series.
            z_value: Resolved z-order to apply.
        Outputs:
            None.
        Side Effects:
            Mutates artist z-order state.
        Exceptions:
            Artists without set_zorder are skipped.
        """
        # Iterate over flattened handles so every artist gets the resolved zorder.
        for artist_handle in _iter_artist_handles(artist_obj):
            setter = getattr(artist_handle, "set_zorder", None)
            if callable(setter):
                setter(z_value)

    label_y1 = _fmt_safe(selected_columns.get("y1", "y1"))
    label_y3 = _fmt_safe(selected_columns.get("y3", "y3"))
    label_y2 = _fmt_safe(selected_columns.get("y2", "Derivative"))
    label_z = _fmt_safe(selected_columns.get("z", "Temp"))
    label_z2 = _fmt_safe(selected_columns.get("z2", "Temp 2"))

    selected_map = {
        "y1": _is_selected(selected_columns.get("y1", "y1")),
        "y3": _is_selected(selected_columns.get("y3", "y3")),
        "y2": _is_selected(selected_columns.get("y2", "Derivative")),
        "z": _is_selected(selected_columns.get("z", "Temp")),
        "z2": _is_selected(selected_columns.get("z2", "Temp 2")),
    }

    dataset_meta = {
        "y1": {
            "series": y1,
            "label": label_y1,
            "color": "blue",
            "series_key": "y1",
            "axis_type": "primary",
            "selected": selected_map["y1"],
        },
        "y3": {
            "series": y3,
            "label": label_y3,
            "color": "green",
            "series_key": "y3",
            "axis_type": "primary",
            "selected": selected_map["y3"],
        },
        "y2": {
            "series": y2,
            "label": label_y2,
            "color": "red",
            "series_key": "y2",
            "axis_type": "derivative",
            "selected": selected_map["y2"],
        },
        "z": {
            "series": z,
            "label": label_z,
            "color": "red",
            "series_key": "z",
            "axis_type": "temperature",
            "selected": selected_map["z"],
        },
        "z2": {
            "series": z2,
            "label": label_z2,
            "color": "orange",
            "series_key": "z2",
            "axis_type": "temperature",
            "selected": selected_map["z2"],
        },
    }

    valid_dataset_keys: Set[str] = set(dataset_meta.keys())

    def _is_available(meta: Mapping[str, Any]) -> bool:
        """Check whether it is available.
        Used to gate conditional behavior in the workflow."""
        return bool(meta.get("series") is not None and meta.get("selected"))

    temp_axis_active = bool(enable_temp_axis) and (
        _is_available(dataset_meta["z"]) or _is_available(dataset_meta["z2"])
    )
    deriv_axis_active = bool(enable_deriv_axis) and _is_available(dataset_meta["y2"])

    def _resolve_dataset_key(value: Any, default_key: str) -> str:
        """Resolve dataset key.
        Used to compute dataset key before rendering or export."""
        if value is None:
            return default_key
        candidate = str(value).strip().lower()
        return candidate if candidate in valid_dataset_keys else default_key

    left_key = _resolve_dataset_key(left_dataset_key, "y1")
    right_key = _resolve_dataset_key(right_dataset_key, "z")
    third_key = _resolve_dataset_key(third_dataset_key, "y2")

    def _axis_settings(meta: Mapping[str, Any]) -> Dict[str, Any]:
        """Perform axis settings.
        Used to keep the workflow logic localized and testable."""
        axis_kind = meta.get("axis_type", "primary")
        if axis_kind == "temperature":
            return {
                "ylim": (twin_y_min, twin_y_max),
                "auto": auto_temp_ticks,
                "maj": twin_maj_tick,
                "min": twin_min_tick,
                "label_key": "temperature",
                "labelpad": temp_labelpad,
            }
        if axis_kind == "derivative":
            return {
                "ylim": (deriv_y_min, deriv_y_max),
                "auto": auto_deriv_ticks,
                "maj": deriv_maj_tick,
                "min": deriv_min_tick,
                "label_key": "derivative",
                "labelpad": deriv_labelpad,
            }
        return {
            "ylim": (min_y, max_y),
            "auto": auto_y_ticks,
            "maj": ymaj_tick,
            "min": ymin_tick,
            "label_key": "primary",
            "labelpad": primary_labelpad,
        }

    def _axis_enabled(meta: Mapping[str, Any]) -> bool:
        """Perform axis enabled.
        Used to keep the workflow logic localized and testable."""
        axis_kind = meta.get("axis_type", "primary")
        has_series = meta.get("series") is not None
        if not has_series or not meta.get("selected"):
            return False
        if axis_kind == "temperature":
            return temp_axis_active
        if axis_kind == "derivative":
            return deriv_axis_active
        return True

    default_zorders = {"y1": 2, "y3": 1, "y2": 3, "z": 3, "z2": 3}
    resolved_trace_zorders: Dict[str, float] = {}
    # Iterate over default_zorders to resolve effective z-order per trace key.
    for series_key, default_z in default_zorders.items():
        resolved_trace_zorders[series_key] = _resolve_effective_trace_zorder(
            default_z,
            series_key=series_key,
            scatter_series_configs=scatter_series_configs,
        )

    def _plot_dataset(
        ax_target: Axes, meta: Mapping[str, Any], *, axis_role: str
    ) -> Optional[Any]:
        """Render one dataset on its assigned combined-axis role.

        Purpose:
            Plot one selected data series and persist its artist for refresh and
            legend workflows.
        Why:
            Combined layering requires each trace to resolve one deterministic
            z-order and apply it consistently on every artist.
        Inputs:
            ax_target: Target Axes receiving the series artist(s).
            meta: Dataset metadata including series values, label, and series_key.
            axis_role: Combined-axis role name ("left", "right", or "third").
        Outputs:
            Primary artist handle for the rendered series, or None when skipped.
        Side Effects:
            Adds artists to the target Axes and updates line_map for reuse.
        Exceptions:
            Missing/invalid series data returns None without raising.
        """
        series = meta.get("series")
        if series is None or not meta.get("selected"):
            return None
        series_key = meta.get("series_key")
        resolved_zorder = resolved_trace_zorders.get(
            series_key, float(default_zorders.get(series_key, 2))
        )
        style_kwargs: Dict[str, Any] = {
            "zorder": resolved_zorder,
            "series_key": series_key,
        }
        if series_key == "z2":
            style_kwargs["line_style"] = "--"
        artist = _plot_series(
            ax_target,
            x,
            series,
            label=meta.get("label", ""),
            color=meta.get("color"),
            scatter_config=scatter_config,
            scatter_series_configs=scatter_series_configs,
            **style_kwargs,
        )
        if artist is None:
            return None
        _apply_artist_zorder(artist, resolved_zorder)
        artist_handles = _iter_artist_handles(artist)
        if not artist_handles:
            return None
        # Emit one verification log per artist so trace layering can be audited.
        for idx, artist_handle in enumerate(artist_handles):
            actual_zorder = None
            getter = getattr(artist_handle, "get_zorder", None)
            if callable(getter):
                try:
                    actual_zorder = float(getter())
                except Exception:
                    actual_zorder = None
            actual_text = (
                f"{actual_zorder:.6g}"
                if actual_zorder is not None and math.isfinite(actual_zorder)
                else "None"
            )
            _combined_render_debug(
                "Combined trace artist series=%s axis_role=%s intended_z=%s actual_z=%s artist_index=%s",
                series_key,
                axis_role,
                f"{resolved_zorder:.6g}",
                actual_text,
                idx,
            )
        primary_artist = artist_handles[0]
        if series_key:
            try:
                primary_artist._gl260_series_key = series_key
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            line_map[series_key] = primary_artist
        return primary_artist

    primary_meta = dataset_meta.get(left_key, dataset_meta["y1"])
    right_meta = dataset_meta.get(right_key, dataset_meta["z"])
    third_meta = dataset_meta.get(third_key, dataset_meta["y2"])
    temp_available = _is_available(dataset_meta["z"]) or _is_available(dataset_meta["z2"])
    deriv_available = _is_available(dataset_meta["y2"])

    def _temperature_meta() -> Mapping[str, Any]:
        """Perform temperature meta.
        Used to keep the workflow logic localized and testable."""
        if _is_available(dataset_meta["z"]):
            return dataset_meta["z"]
        if _is_available(dataset_meta["z2"]):
            return dataset_meta["z2"]
        return dataset_meta["z"]

    right_role = right_meta.get("axis_type", "primary")
    third_role = third_meta.get("axis_type", "primary")

    if temp_available and "temperature" not in {right_role, third_role}:
        right_meta = _temperature_meta()
        right_role = right_meta.get("axis_type", "primary")

    if deriv_available and "derivative" not in {right_role, third_role}:
        if third_role != "temperature":
            third_meta = dataset_meta["y2"]
        else:
            if temp_available:
                right_meta = _temperature_meta()
                right_role = right_meta.get("axis_type", "primary")
            third_meta = dataset_meta["y2"]
        third_role = third_meta.get("axis_type", "primary")

    right_role = right_meta.get("axis_type", "primary")
    third_role = third_meta.get("axis_type", "primary")
    if temp_available and "temperature" not in {right_role, third_role}:
        right_meta = _temperature_meta()
        right_role = right_meta.get("axis_type", "primary")
    if temp_available and right_role == "temperature" and not _is_available(right_meta):
        right_meta = _temperature_meta()
        right_role = right_meta.get("axis_type", "primary")
    if temp_available and third_role == "temperature" and not _is_available(third_meta):
        third_meta = _temperature_meta()
        third_role = third_meta.get("axis_type", "primary")

    def _axis_role_layer_zorder(
        series_keys: Sequence[str], role_bias: float, fallback: float
    ) -> float:
        """Resolve one combined-axis z-order from the role's active trace z-orders.

        Purpose:
            Compute deterministic axis-level draw order from effective per-trace
            z-order values for that axis role.
        Why:
            Matplotlib draws by Axes first, so cross-axis trace priority must
            influence each axis z-order to make foreground/background overrides
            consistent when traces live on different axes.
        Inputs:
            series_keys: Trace keys assigned to one axis role.
            role_bias: Small positive tie-breaker to keep equal-z axes stable.
            fallback: Fallback z-order when no active traces exist for the role.
        Outputs:
            Float axis z-order value for the role.
        Side Effects:
            None.
        Exceptions:
            Invalid/non-finite trace z-orders are ignored.
        """
        z_values: List[float] = []
        # Iterate over series_keys and collect active trace z-order values.
        for trace_key in series_keys:
            meta = dataset_meta.get(trace_key, {})
            if not _is_available(meta):
                continue
            candidate = resolved_trace_zorders.get(trace_key)
            if candidate is not None and math.isfinite(candidate):
                z_values.append(float(candidate))
        base_value = max(z_values) if z_values else float(fallback)
        return float(base_value + role_bias)

    axis_layer_zorders = {
        "left": _axis_role_layer_zorder(("y1", "y3"), role_bias=0.01, fallback=0.0),
        "right": _axis_role_layer_zorder(("z", "z2"), role_bias=0.02, fallback=0.0),
        "third": _axis_role_layer_zorder(("y2",), role_bias=0.03, fallback=0.0),
    }
    axis_layer_zorders["overlay"] = max(axis_layer_zorders.values()) + 1000.0
    legend_layer_zorder = float(axis_layer_zorders["overlay"] + 1000.0)

    def _apply_combined_legend_layer(legend_obj: Any) -> None:
        """Force one combined-plot legend above all combined axes.

        Purpose:
            Apply a deterministic top-layer z-order to a combined plot legend.
        Why:
            Combined axes z-orders can exceed Matplotlib's default legend z-order,
            so legends must be explicitly lifted to stay visible.
        Inputs:
            legend_obj: Figure or axis legend artist to update.
        Outputs:
            None.
        Side Effects:
            Mutates legend z-order state when the artist supports set_zorder.
        Exceptions:
            Unsupported legend-like objects are ignored without raising.
        """
        if legend_obj is None:
            return
        setter = getattr(legend_obj, "set_zorder", None)
        if callable(setter):
            try:
                setter(legend_layer_zorder)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    cycle_overlay = overlay_ctx.get("cycle_overlay")
    markers_overlay = overlay_ctx.get("markers", cycle_overlay)
    legend_overlay = overlay_ctx.get("cycle_legend", cycle_overlay)
    cycle_style = (
        get_cycle_trace_style() if (markers_overlay or legend_overlay) else None
    )
    moles_lines = overlay_ctx.get("moles_summary")
    if moles_lines is None and isinstance(cycle_overlay, dict):
        moles_lines = cycle_overlay.get("moles_lines")

    try:
        overlay_has_data = False
        if isinstance(cycle_overlay, dict):
            overlay_has_data = bool(
                cycle_overlay.get("peak_points")
                or cycle_overlay.get("trough_points")
                or cycle_overlay.get("cycles")
            )
        fig._gl260_cycle_overlay_present = overlay_has_data  # type: ignore[attr-defined]
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    def _cycle_marker_artist(marker, color):
        """Perform cycle marker artist.
        Used to keep the workflow logic localized and testable."""
        size_val = None
        try:
            size_val = max(4.0, math.sqrt(float(cycle_style["marker_size"])))
        except Exception:
            size_val = 6.0
        return Line2D(
            [], [], linestyle="None", marker=marker, color=color, markersize=size_val
        )

    def _draw_cycle_markers(ax_target):
        """Render cycle markers on the dedicated combined overlay axis.

        Purpose:
            Draw cached cycle peak and trough points for combined plot overlays.
        Why:
            Overlay-axis rendering guarantees peak/trough markers stay above all
            data traces regardless of per-trace priority or numeric overrides.
        Inputs:
            ax_target: Overlay Axes receiving cycle marker scatter artists.
        Outputs:
            Tuple of (peak_artist, trough_artist), each possibly None.
        Side Effects:
            Adds marker scatter artists to the overlay axis.
        Exceptions:
            Returns (None, None) when cycle overlay data is unavailable.
        """
        if not (show_cycle_markers_on_core_plots and markers_overlay and cycle_style):
            return (None, None)
        cycle_marker_zorder = _compute_top_overlay_zorder(
            ax_target, min_z=CYCLE_MARKER_MIN_ZORDER, pad=CYCLE_MARKER_ZORDER_PAD
        )
        peak_artist = trough_artist = None
        peaks = markers_overlay.get("peak_points") or []
        troughs = markers_overlay.get("trough_points") or []
        if peaks:
            px, py = zip(*peaks)
            peak_artist = ax_target.scatter(
                px,
                py,
                marker=cycle_style["peak_marker"],
                s=cycle_style["marker_size"],
                c=cycle_style["peak_color"],
                zorder=cycle_marker_zorder,
                label=_text_safe("Peak"),
            )
        if troughs:
            tx, ty = zip(*troughs)
            trough_artist = ax_target.scatter(
                tx,
                ty,
                marker=cycle_style["trough_marker"],
                s=cycle_style["marker_size"],
                c=cycle_style["trough_color"],
                zorder=cycle_marker_zorder,
                label=_text_safe("Trough"),
            )
        return peak_artist, trough_artist

    def _add_cycle_legend(
        ax_target,
        peak_artist,
        trough_artist,
        anchor=None,
        loc_override=None,
        anchor_space=None,
    ):
        """Perform add cycle legend.
        Used to keep the workflow logic localized and testable."""
        if not (show_cycle_legend_on_core_plots and legend_overlay):
            return None
        handles_cycle: List[Any] = []
        labels_cycle: List[str] = []
        if peak_artist is not None:
            handles_cycle.append(peak_artist)
            labels_cycle.append(_text_safe("Peak"))
        elif cycle_style:
            handles_cycle.append(
                _cycle_marker_artist(
                    cycle_style["peak_marker"], cycle_style["peak_color"]
                )
            )
            labels_cycle.append(_text_safe("Peak"))
        if trough_artist is not None:
            handles_cycle.append(trough_artist)
            labels_cycle.append(_text_safe("Trough"))
        elif cycle_style:
            handles_cycle.append(
                _cycle_marker_artist(
                    cycle_style["trough_marker"], cycle_style["trough_color"]
                )
            )
            labels_cycle.append(_text_safe("Trough"))
        cycles_list = legend_overlay.get("cycles") or []
        total_drop_val = legend_overlay.get("total_drop", 0.0)
        try:
            total_drop_val = float(total_drop_val)
        except Exception:
            total_drop_val = 0.0
        handles_cycle.append(Line2D([], [], color="none"))
        labels_cycle.append(_text_safe(f"Cycles: {len(cycles_list)}"))
        import matplotlib.patches as mpatches

        handles_cycle.append(mpatches.Patch(color="none"))
        labels_cycle.append(_text_safe(f"Total ΔP: {total_drop_val:.2f} PSI"))
        if include_moles_in_core_plot_legend:
            # Iterate over moles_lines or [] to apply the per-item logic.
            for line in moles_lines or []:
                handles_cycle.append(mpatches.Patch(color="none"))
                labels_cycle.append(_text_safe(line))
        legend_kwargs = {
            "fontsize": cycle_legend_fontsize_value,
            "prop": {"family": family_value, "size": cycle_legend_fontsize_value},
            "markerscale": cycle_legend_markerscale,
            **_legend_shadowbox_kwargs(),
        }
        loc_value = None
        if loc_override is not None:
            loc_value = _normalize_legend_loc_value(loc_override)
        if loc_value is None:
            loc_value = "upper right"
        if loc_value is not None:
            legend_kwargs["loc"] = loc_value
        anchor_value = _validated_anchor_pair(anchor)
        if anchor_value is None and isinstance(loc_value, str):
            loc_key = loc_value.strip().lower()
            anchor_map = {
                "upper right": (0.98, 0.98),
                "upper left": (0.02, 0.98),
                "lower right": (0.98, 0.02),
                "lower left": (0.02, 0.02),
                "center right": (0.98, 0.5),
                "center left": (0.02, 0.5),
                "upper center": (0.5, 0.98),
                "lower center": (0.5, 0.02),
                "center": (0.5, 0.5),
            }
            anchor_value = anchor_map.get(loc_key, (0.98, 0.98))
        if anchor_value is not None:
            legend_kwargs["bbox_to_anchor"] = anchor_value
        legend = fig.legend(handles_cycle, labels_cycle, **legend_kwargs)
        if anchor_value is not None:
            try:
                transform = None
                if anchor_space == "axes" and ax_target is not None:
                    transform = ax_target.transAxes
                elif anchor_space in {"figure", None}:
                    transform = fig.transFigure
                if transform is None:
                    legend.set_bbox_to_anchor(anchor_value)
                else:
                    legend.set_bbox_to_anchor(anchor_value, transform=transform)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            legend._cycle_overlay_legend = True  # type: ignore[attr-defined]
            # Tag combined cycle legend so capture logic can identify it reliably.
            legend._combined_cycle_legend = True  # type: ignore[attr-defined]
            legend._gl260_legend_role = "cycle"  # type: ignore[attr-defined]
            legend._gl260_markerscale = cycle_legend_markerscale  # type: ignore[attr-defined]
            legend._gl260_markerscale_base_font = (  # type: ignore[attr-defined]
                DEFAULT_COMBINED_LEGEND_FONTSIZE
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        _apply_combined_legend_layer(legend)
        _make_legend_draggable(legend)
        return legend

    primary_settings = _axis_settings(dataset_meta["y1"])

    # Iterate over ("y1", "y3") to apply the per-item logic.
    for key in ("y1", "y3"):
        artist = _plot_dataset(ax, dataset_meta[key], axis_role="left")
        if artist is not None:
            handles.append(artist)

    ax.set_xlim(*time_range)
    ax.set_ylim(*primary_settings["ylim"])
    ax.set_zorder(axis_layer_zorders["left"])
    # Keep the primary axes background transparent so high-z primary layers never
    # occlude right/third-axis traces after dynamic axis z-order updates.
    ax.patch.set_visible(False)
    ax.set_facecolor("none")
    font_kwargs = {"fontsize": label_fontsize}
    if family_value:
        font_kwargs["fontfamily"] = family_value

    ax.set_ylabel(
        _label_or_default(primary_settings["label_key"], primary_meta.get("label", "")),
        labelpad=primary_settings["labelpad"],
        **font_kwargs,
    )
    title_display = _text_safe(title_text)

    axis_for_role: Dict[str, Axes] = {"primary": ax}
    show_derivative_zero_line = False

    # Axis role mapping decides which datasets populate the right-side axes so
    # overlays, legends, and layout rules can target consistent roles.
    temp_meta = None
    deriv_meta = None
    if right_role == "temperature":
        temp_meta = right_meta
    if third_role == "temperature" and temp_meta is None:
        temp_meta = third_meta
    if right_role == "derivative":
        deriv_meta = right_meta
    if third_role == "derivative" and deriv_meta is None:
        deriv_meta = third_meta

    # Temperature axis is rendered as a twinned right spine on the primary axis.
    if temp_meta is not None and _axis_enabled(temp_meta):
        ax_temp = ax.twinx()
        try:
            ax_temp._gl260_axis_role = "right"
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        _position_extra_axis(ax_temp, 1.0)
        ax_temp.tick_params(axis="x", which="both", bottom=False, labelbottom=False)

        temp_settings = _axis_settings(temp_meta)

        ax_temp.set_ylim(*temp_settings["ylim"])
        temp_kwargs = {
            "color": "black",
            "rotation": -90,
            "labelpad": temp_settings["labelpad"],
            "fontsize": label_fontsize,
        }
        if family_value:
            temp_kwargs["fontfamily"] = family_value
        ax_temp.set_ylabel(
            _label_or_default(temp_settings["label_key"], temp_meta.get("label", "")),
            **temp_kwargs,
        )
        ax_temp.tick_params(axis="y", labelcolor="black", labelsize=tick_fontsize)
        _apply_tick_font(ax_temp)
        _apply_axis_ticks(
            ax_temp,
            temp_settings["auto"],
            temp_settings["maj"],
            temp_settings["min"],
        )
        ax_temp.set_zorder(axis_layer_zorders["right"])
        ax_temp.patch.set_visible(False)
        ax_temp.set_facecolor("none")
        axis_for_role.setdefault("temperature", ax_temp)

    # Derivative axis is a second detached right spine to preserve readability.
    if deriv_meta is not None and _axis_enabled(deriv_meta):
        ax_deriv = ax.twinx()
        try:
            ax_deriv._gl260_axis_role = "third"
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        # Offset the derivative spine to keep it clear of the temperature axis.
        _position_extra_axis(ax_deriv, deriv_spine_offset)
        ax_deriv.tick_params(axis="x", which="both", bottom=False, labelbottom=False)

        deriv_settings = _axis_settings(deriv_meta)

        ax_deriv.set_ylim(*deriv_settings["ylim"])
        deriv_kwargs = {
            "color": "black",
            "rotation": -90,
            "labelpad": deriv_settings["labelpad"],
            "fontsize": label_fontsize,
        }
        if family_value:
            deriv_kwargs["fontfamily"] = family_value
        ax_deriv.set_ylabel(
            _label_or_default(deriv_settings["label_key"], deriv_meta.get("label", "")),
            **deriv_kwargs,
        )
        ax_deriv.tick_params(axis="y", labelcolor="black", labelsize=tick_fontsize)
        _apply_tick_font(ax_deriv)
        _apply_axis_ticks(
            ax_deriv,
            deriv_settings["auto"],
            deriv_settings["maj"],
            deriv_settings["min"],
        )
        if deriv_settings["label_key"] == "derivative":
            show_derivative_zero_line = True
        ax_deriv.set_zorder(axis_layer_zorders["third"])
        ax_deriv.patch.set_visible(False)
        ax_deriv.set_facecolor("none")
        axis_for_role.setdefault("derivative", ax_deriv)

    # Overlay axis carries only cycle markers and must render above all data axes.
    ax_overlay = ax.twinx()
    try:
        ax_overlay._gl260_axis_role = "overlay"
        ax_overlay._gl260_legend_only = True
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    ax_overlay.set_zorder(axis_layer_zorders["overlay"])
    ax_overlay.set_ylim(*ax.get_ylim())
    ax_overlay.set_autoscaley_on(False)
    ax_overlay.patch.set_visible(False)
    ax_overlay.set_facecolor("none")
    ax_overlay.set_frame_on(False)
    ax_overlay.tick_params(
        axis="both",
        which="both",
        left=False,
        right=False,
        bottom=False,
        top=False,
        labelleft=False,
        labelright=False,
        labelbottom=False,
        labeltop=False,
    )
    # Hide all overlay spines so only marker artists render on this axis.
    for spine in ax_overlay.spines.values():
        spine.set_visible(False)
    ax_overlay.yaxis.set_visible(False)
    ax_overlay.xaxis.set_visible(False)
    _ensure_combined_derivative_zero_line(
        fig,
        ax_overlay,
        ax_deriv,
        visible=show_derivative_zero_line,
        zorder=6.0,
    )

    def _axis_zorder_text(axis: Optional[Axes]) -> str:
        """Return a debug-safe axis z-order string for logging.

        Purpose:
            Normalize axis z-order values into stable text for debug traces.
        Why:
            Layering verification logs should remain readable even when an axis
            is absent or reports non-finite values.
        Inputs:
            axis: Axis to inspect, or None when that axis is disabled.
        Outputs:
            String representation of the axis z-order.
        Side Effects:
            None.
        Exceptions:
            Returns "None" when the axis cannot provide a finite z-order.
        """
        if axis is None:
            return "None"
        try:
            z_value = float(axis.get_zorder())
        except Exception:
            return "None"
        if not math.isfinite(z_value):
            return "None"
        return f"{z_value:.6g}"

    _combined_render_debug(
        "Combined axes z-orders left=%s right=%s third=%s overlay=%s",
        _axis_zorder_text(ax),
        _axis_zorder_text(ax_temp),
        _axis_zorder_text(ax_deriv),
        _axis_zorder_text(ax_overlay),
    )

    temp_axis = axis_for_role.get("temperature")
    if temp_axis is not None:
        # Iterate over ("z", "z2") to apply the per-item logic.
        for key in ("z", "z2"):
            artist = _plot_dataset(temp_axis, dataset_meta[key], axis_role="right")
            if artist is not None:
                handles.append(artist)

    deriv_axis = axis_for_role.get("derivative")
    if deriv_axis is not None:
        artist = _plot_dataset(deriv_axis, dataset_meta["y2"], axis_role="third")
        if artist is not None:
            handles.append(artist)

    if auto_time_ticks:
        ax.xaxis.set_major_locator(AutoLocator())
        ax.xaxis.set_minor_locator(AutoMinorLocator())
    else:
        ax.xaxis.set_major_locator(MultipleLocator(xmaj_tick))
        ax.xaxis.set_minor_locator(MultipleLocator(xmin_tick))

    _apply_axis_ticks(
        ax,
        primary_settings["auto"],
        primary_settings["maj"],
        primary_settings["min"],
    )
    ax.tick_params(
        axis="both", which="major", labelcolor="black", labelsize=tick_fontsize
    )
    _apply_tick_font(ax)
    combined_peak_artist, combined_trough_artist = _draw_cycle_markers(ax_overlay)
    try:
        fig._gl260_cycle_marker_artists = {  # type: ignore[attr-defined]
            "peak": combined_peak_artist,
            "trough": combined_trough_artist,
        }
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    suptitle_display = _text_safe(suptitle_text)
    main_center_x = fig.subplotpars.left + (
        (fig.subplotpars.right - fig.subplotpars.left) / 2.0
    )
    try:
        pos = ax.get_position()
        main_center_x = pos.x0 + (pos.width / 2.0)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    suptitle_artist = fig.suptitle(
        suptitle_display,
        fontsize=suptitle_fontsize_value,
        fontfamily=family_value if family_value else None,
        x=main_center_x,
    )
    title_artist = ax.set_title(
        title_display,
        fontsize=title_fontsize_value,
        pad=title_pad_value,
        fontfamily=family_value if family_value else None,
    )
    try:
        fig._gl260_title_text = title_artist  # type: ignore[attr-defined]
        fig._gl260_suptitle_text = suptitle_artist  # type: ignore[attr-defined]
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    # Figure-level xlabel keeps the legend pinned to the bottom zone.
    supxlabel = fig.supxlabel(
        x_label_text,
        fontsize=label_fontsize,
        fontfamily=family_value if family_value else None,
        x=main_center_x,
    )
    try:
        fig._gl260_xlabel_text = supxlabel  # type: ignore[attr-defined]
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    legend_labels = [_text_safe(handle.get_label()) for handle in handles]
    handles_filtered, labels_filtered = _filter_none_legend_entries(
        handles, legend_labels
    )
    if (
        handles_filtered
        and include_moles_in_core_plot_legend
        and not show_cycle_legend_on_core_plots
        and moles_lines
    ):
        import matplotlib.patches as mpatches

        # Iterate over moles_lines to apply the per-item logic.
        for line in moles_lines:
            handles_filtered.append(mpatches.Patch(color="none"))
            labels_filtered.append(_text_safe(line))
    legend_size = len(handles_filtered)
    main_legend = None
    if legend_size:
        if bool(legend_wrap):
            rows_value = 2 if legend_rows is None else legend_rows
            try:
                rows_value = int(rows_value)
            except (TypeError, ValueError):
                rows_value = 1
            rows_value = max(1, rows_value)
            ncol = max(1, math.ceil(legend_size / rows_value))
        else:
            ncol = min(4, legend_size)
        wrapped_labels = [_wrap_legend_label(label) for label in labels_filtered]
        main_legend = fig.legend(
            handles=handles_filtered,
            labels=wrapped_labels,
            loc="lower center",
            bbox_to_anchor=(main_center_x, 0.0),
            columnspacing=1.0,
            handletextpad=0.5,
            fontsize=legend_fontsize_value,
            prop={"family": family_value, "size": legend_fontsize_value},
            markerscale=legend_markerscale,
            ncol=ncol,
            **_legend_shadowbox_kwargs(),
        )
        try:
            main_legend._combined_main_legend = True  # type: ignore[attr-defined]
            main_legend._gl260_markerscale = legend_markerscale  # type: ignore[attr-defined]
            main_legend._gl260_legend_role = "main"  # type: ignore[attr-defined]
            main_legend._gl260_markerscale_base_font = (  # type: ignore[attr-defined]
                DEFAULT_COMBINED_LEGEND_FONTSIZE
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        _apply_combined_legend_layer(main_legend)
        if legend_anchor is not None:
            _apply_legend_anchor_to_artist(
                main_legend,
                legend_anchor,
                transform=fig.transFigure,
                loc_override=legend_loc,
            )
        elif legend_loc is not None:
            try:
                main_legend.set_loc(_normalize_legend_loc_value(legend_loc))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    cycle_loc_choices = {
        "upper right",
        "upper left",
        "lower right",
        "lower left",
        "center right",
        "center left",
        "upper center",
        "lower center",
        "center",
    }
    raw_cycle_loc_choice = settings.get(
        "combined_cycle_legend_loc_choice", "upper right"
    )
    if isinstance(raw_cycle_loc_choice, str):
        cycle_loc_choice = raw_cycle_loc_choice.strip().lower()
    else:
        cycle_loc_choice = str(raw_cycle_loc_choice).strip().lower()
    if cycle_loc_choice not in cycle_loc_choices:
        cycle_loc_choice = "upper right"

    # Cycle legend anchoring has two modes: direct anchor placement or axis-offset
    # capture for detached right spines. Offset mode wins to keep legend alignment
    # stable when the third axis is shifted.
    axis_offset_values = _combined_cycle_axis_offset_values()
    has_cycle_anchor = cycle_legend_anchor is not None and axis_offset_values is None
    cycle_anchor = cycle_legend_anchor if has_cycle_anchor else None
    cycle_loc_override = cycle_legend_loc if cycle_legend_loc is not None else cycle_loc_choice
    cycle_anchor_ref_axis = None
    if cycle_legend_anchor_space == "axes":
        # Preserve axis-space anchors by applying them against the configured
        # reference axis, matching export preview behavior.
        cycle_anchor_ref_axis = _resolve_combined_cycle_ref_axis(
            fig,
            ax_main=ax,
            ax_right=ax_temp,
            ax_deriv=ax_deriv,
            ref_axis_key=settings.get("combined_cycle_legend_ref_axis"),
        )
        if cycle_anchor_ref_axis is None:
            cycle_anchor_ref_axis = ax
    cycle_anchor_axis = cycle_anchor_ref_axis or ax
    cycle_legend = _add_cycle_legend(
        cycle_anchor_axis,
        combined_peak_artist,
        combined_trough_artist,
        anchor=cycle_anchor,
        loc_override=cycle_loc_override,
        anchor_space=cycle_legend_anchor_space,
    )
    if cycle_legend is not None and has_cycle_anchor:
        legend_transform = fig.transFigure
        if (
            cycle_legend_anchor_space == "axes"
            and cycle_anchor_ref_axis is not None
        ):
            legend_transform = cycle_anchor_ref_axis.transAxes
        _apply_legend_anchor_to_artist(
            cycle_legend,
            cycle_legend_anchor,
            transform=legend_transform,
            loc_override=cycle_loc_override,
        )
    if axis_offset_values is not None and cycle_legend is not None:
        try:
            # Apply offsets before layout solve so legend bboxes reflect drag placement.
            ref_axis = _resolve_combined_cycle_ref_axis(
                fig,
                ax_main=ax,
                ax_right=ax_temp,
                ax_deriv=ax_deriv,
                ref_axis_key=settings.get("combined_cycle_legend_ref_axis"),
            )
            loc_value = _resolve_combined_cycle_legend_loc()
            _apply_cycle_legend_axis_offset(
                fig,
                cycle_legend,
                ref_axis,
                settings.get("combined_cycle_legend_ref_corner"),
                axis_offset_values[0],
                axis_offset_values[1],
                loc_value,
                allow_draw=False,
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
    # Enforce the final legend layer for both newly created and reused legend artists.
    # Iterate over _collect_gl260_legends(fig) to apply the per-item logic.
    for legend_artist in _collect_gl260_legends(fig):
        _apply_combined_legend_layer(legend_artist)

    # Layout solve: measure bboxes + adjust margins in a deterministic pass.
    layout_manager = PlotLayoutManager(
        fig,
        mode=mode_value,
        baseline_margins=baseline_margins,
        left_pad_pct=left_pad_value,
        right_pad_pct=right_pad_value,
        export_pad_pts=export_pad_pts,
        legend_gap_pts=legend_label_gap_pts,
        xlabel_tick_gap_pts=xlabel_tick_gap_pts,
        legend_margin_pts=legend_bottom_margin_pts,
        title_pad_pts=title_pad_value,
        suptitle_pad_pts=suptitle_pad_value,
        suptitle_y=suptitle_y_value,
        top_margin_pct=top_margin_value,
        legend_anchor=legend_anchor,
        legend_anchor_y=legend_anchor_y,
        xlabel_pad_pts=xlabel_pad_value,
    )
    layout_manager.register_axes(ax, ax_temp, ax_deriv)
    layout_manager.register_artist("title", title_artist)
    layout_manager.register_artist("suptitle", suptitle_artist)
    layout_manager.register_artist("xlabel", supxlabel)
    layout_manager.register_artist("plot_legend", main_legend)
    layout_manager.register_artist("cycle_legend", cycle_legend)
    layout_manager.set_legend_alignment(legend_alignment)
    # Export mode resolves full layout to lock bounding boxes; preview uses a
    # single-pass solve to avoid UI jitter while still honoring margins.
    if mode_value == "export":
        layout_manager.solve()
    else:
        layout_manager.solve(max_passes=1, allow_draw=False)
    fig._gl260_layout_manager = layout_manager  # type: ignore[attr-defined]
    fig._gl260_title_state = {
        "suptitle": suptitle_display,
        "title_fs": title_fontsize_value,
        "suptitle_fs": suptitle_fontsize_value,
        "font_family": family_value,
        "title_pad_pts": title_pad_value,
        "suptitle_pad_pts": suptitle_pad_value,
        "suptitle_y": suptitle_y_value,
    }

    if fig.canvas is None:
        FigureCanvasAgg(fig)
    try:
        if mode_value == "export":
            fig.canvas.draw()
        else:
            fig.canvas.draw_idle()
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    # Cycle legend offsets are normalized against a reference axis so detached
    # spines export consistently across DPI and canvas sizes.
    if cycle_legend is not None:
        ref_axis = _resolve_combined_cycle_ref_axis(
            fig,
            ax_main=ax,
            ax_right=ax_temp,
            ax_deriv=ax_deriv,
            ref_axis_key=settings.get("combined_cycle_legend_ref_axis"),
        )
        loc_value = _resolve_combined_cycle_legend_loc()
        # New axis-offset mode: apply precomputed offsets tied to the chosen
        # reference axis/corner to avoid drift between preview and export.
        if axis_offset_values is not None:
            _apply_cycle_legend_axis_offset(
                fig,
                cycle_legend,
                ref_axis,
                settings.get("combined_cycle_legend_ref_corner"),
                axis_offset_values[0],
                axis_offset_values[1],
                loc_value,
                allow_draw=(mode_value == "export"),
            )
        else:
            # Legacy anchor mode: capture offsets once and persist for stability.
            legacy_anchor = _validated_anchor_pair(
                settings.get("combined_cycle_legend_anchor")
            )
            if legacy_anchor is not None:
                try:
                    renderer = fig.canvas.get_renderer()
                except Exception:
                    renderer = None
                offsets = _compute_cycle_legend_offsets_px(
                    cycle_legend,
                    ref_axis,
                    settings.get("combined_cycle_legend_ref_corner"),
                    loc_value,
                    renderer,
                )
                if offsets is not None:
                    settings["combined_cycle_legend_ref_dx_px"] = offsets[0]
                    settings["combined_cycle_legend_ref_dy_px"] = offsets[1]
                    settings["combined_cycle_legend_anchor_mode"] = "axis_offset"
                    axis_offset_values = offsets
                    _apply_cycle_legend_axis_offset(
                        fig,
                        cycle_legend,
                        ref_axis,
                        settings.get("combined_cycle_legend_ref_corner"),
                        offsets[0],
                        offsets[1],
                        loc_value,
                        allow_draw=(mode_value == "export"),
                    )
                    try:
                        _save_settings_to_disk()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

    # Iterate over (ax, ax_temp, ax_deriv) to apply the per-item logic.
    for axis in (ax, ax_temp, ax_deriv):
        if axis is None:
            continue
        _enforce_axis_text_style(
            axis,
            font_family=family_value,
            tick_fontsize=tick_fontsize,
            label_fontsize=label_fontsize,
        )

    # Final pass: enforce y-axis label font family/size after all positioning.
    try:
        if mode_value == "export":
            fig.canvas.draw()
        else:
            fig.canvas.draw_idle()
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass
    y_label_sizes: List[float] = []
    # Iterate over (ax, ax_temp, ax_deriv) to apply the per-item logic.
    for axis in (ax, ax_temp, ax_deriv):
        if axis is None:
            continue
        try:
            label_obj = axis.yaxis.label
        except Exception:
            continue
        try:
            label_text = label_obj.get_text()
            if label_text and "°" in label_text and mathtext.is_math_text(label_text):
                label_obj.set_text(label_text.replace("$", ""))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            label_obj.set_fontsize(label_fontsize)
            if family_value:
                label_obj.set_fontfamily(family_value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            y_label_sizes.append(float(label_obj.get_fontsize()))
        except Exception:
            continue
    if y_label_sizes:
        try:
            min_size = min(y_label_sizes)
            max_size = max(y_label_sizes)
            if abs(max_size - min_size) > 0.01:
                print(
                    "[WARN] Combined axis y-label font sizes mismatch:",
                    [round(val, 2) for val in y_label_sizes],
                )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _axis_tick_sizes(axis: Optional[Axes]) -> Set[float]:
        """Perform axis tick sizes.
        Used to keep the workflow logic localized and testable."""
        if axis is None:
            return set()
        sizes: Set[float] = set()
        # Iterate over axis.get_yticklabels() to apply the per-item logic.
        for tick in axis.get_yticklabels():
            text = tick.get_text()
            if not text or not text.strip():
                continue
            try:
                sizes.add(round(float(tick.get_fontsize()), 2))
            except Exception:
                continue
        return sizes

    def _axis_tick_families(axis: Optional[Axes]) -> Set[str]:
        """Perform axis tick families.
        Used to keep the workflow logic localized and testable."""
        if axis is None:
            return set()
        families: Set[str] = set()
        # Iterate over axis.get_yticklabels() to apply the per-item logic.
        for tick in axis.get_yticklabels():
            text = tick.get_text()
            if not text or not text.strip():
                continue
            try:
                family = tick.get_fontfamily()
            except Exception:
                continue
            if isinstance(family, (list, tuple)):
                if family:
                    families.add(str(family[0]))
            elif family:
                families.add(str(family))
        return families

    axes_to_check = [axis for axis in (ax, ax_temp, ax_deriv) if axis is not None]
    size_sets = [vals for vals in (_axis_tick_sizes(a) for a in axes_to_check) if vals]
    if len(size_sets) >= 2 and len({frozenset(vals) for vals in size_sets}) > 1:
        print(
            "[WARN] Combined axis tick font sizes mismatch:",
            [sorted(vals) for vals in size_sets],
        )
    family_sets = [
        vals for vals in (_axis_tick_families(a) for a in axes_to_check) if vals
    ]
    if len(family_sets) >= 2 and len({frozenset(vals) for vals in family_sets}) > 1:
        print(
            "[WARN] Combined axis tick font families mismatch:",
            [sorted(vals) for vals in family_sets],
        )

    try:
        fig._gl260_combined_line_map = line_map  # type: ignore[attr-defined]
        fig._gl260_combined_axes_map = {  # type: ignore[attr-defined]
            "primary": ax,
            "right": ax_temp,
            "third": ax_deriv,
            "overlay": ax_overlay,
        }
        fig._gl260_combined_axis_keys = {  # type: ignore[attr-defined]
            "left": left_key,
            "right": right_key,
            "third": third_key,
        }
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        pass

    return fig


def _debug_validate_svg_export(output_path: Optional[str] = None) -> Tuple[bool, str]:
    """Validate SVG export.
    Used by debug workflows to validate SVG export."""

    import xml.etree.ElementTree as ET

    target_path = output_path or os.path.join(
        tempfile.gettempdir(), "gl260_combined_svg_validation.svg"
    )
    sentinel = object()
    globals_snapshot: Dict[str, Any] = {
        key: globals().get(key, sentinel)
        # Iterate to apply the per-item logic.
        for key in (
            "x",
            "y1",
            "y2",
            "y3",
            "z",
            "z2",
            "selected_columns",
            "core_cycle_overlay",
        )
    }
    fig: Optional[Figure] = None
    try:
        globals().update(
            {
                "x": np.array([0.0, 1.0, 2.0]),
                "y1": np.array([1.0, 2.0, 3.0]),
                "y3": np.array([3.0, 2.0, 1.0]),
                "y2": np.array([0.0, -0.5, 0.5]),
                "z": np.array([25.0, 30.0, 28.0]),
                "z2": np.array([24.0, 29.0, 27.0]),
                "selected_columns": {
                    "x": "Elapsed Time & seconds",
                    "y1": "NaOH & CO2",
                    "y3": "Aux < Pressure >",
                    "y2": "dP/dt \"Rate\" 'Calc'",
                    "z": 'Temp "C" & Rising',
                    "z2": "Temp' Aux <Run>",
                },
                "core_cycle_overlay": None,
            }
        )
        fig = build_combined_triple_axis_figure(
            0.0,
            2.0,
            0.0,
            4.0,
            20.0,
            40.0,
            -2.0,
            2.0,
            True,
            True,
            True,
            True,
            'Validation Title & Check <Run> "Demo"',
            "Suptitle 'Quick' & Overview",
            1.0,
            0.5,
            1.0,
            0.5,
            5.0,
            1.0,
            0.5,
            0.25,
            True,
            True,
            1.1,
        )
        fig.savefig(target_path, format="svg")
        ET.parse(target_path)
        return True, target_path
    except Exception as exc:
        raise RuntimeError(f"SVG validation failed for {target_path}: {exc}") from exc
    finally:
        if fig is not None:
            try:
                plt.close(fig)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        # Iterate over items from globals_snapshot to apply the per-item logic.
        for key, original in globals_snapshot.items():
            if original is sentinel:
                globals().pop(key, None)
            else:
                globals()[key] = original


def _debug_with_fresh_settings(func):
    """Perform debug with fresh settings.
    Used to keep the workflow logic localized and testable."""
    settings_path = os.path.abspath(SETTINGS_FILE)
    backup_path = None
    if os.path.exists(settings_path):
        backup_path = f"{settings_path}.debug-backup"
        counter = 1
        # Repeat while os.path.exists(backup_path) to advance the looped workflow.
        while os.path.exists(backup_path):
            backup_path = f"{settings_path}.debug-backup-{counter}"
            counter += 1
        shutil.move(settings_path, backup_path)
    settings_snapshot = dict(settings)
    settings.clear()
    try:
        return func()
    finally:
        settings.clear()
        settings.update(settings_snapshot)
        if backup_path:
            try:
                if os.path.exists(settings_path):
                    created_path = f"{settings_path}.debug-created"
                    counter = 1
                    # Repeat while os.path.exists(created_path) to advance the looped workflow.
                    while os.path.exists(created_path):
                        created_path = f"{settings_path}.debug-created-{counter}"
                        counter += 1
                    shutil.move(settings_path, created_path)
                shutil.move(backup_path, settings_path)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass


def _debug_set_sol_value(app, key: str, value: Optional[float]) -> None:
    """Set sol value.
    Used by debug workflows to set sol value."""
    vars_map = getattr(app, "_solubility_vars", None)
    if not isinstance(vars_map, dict):
        raise RuntimeError("Solubility inputs are not initialized.")
    var = vars_map.get(key)
    if var is None:
        var = app._create_persistent_solubility_var(key, "")
        vars_map[key] = var
        app._solubility_vars = vars_map
    var.set("" if value is None else str(value))


def _debug_clear_sol_inputs(app) -> None:
    """Clear sol inputs.
    Used by debug workflows to clear sol inputs."""
    vars_map = getattr(app, "_solubility_vars", None)
    if not isinstance(vars_map, dict):
        raise RuntimeError("Solubility inputs are not initialized.")
    # Iterate over values from vars_map to apply the per-item logic.
    for var in vars_map.values():
        try:
            var.set("")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass


def _debug_assert_scoped_none(form_data: Dict[str, Any], keys: Sequence[str]) -> None:
    """Perform debug assert scoped none.
    Used to keep the workflow logic localized and testable."""
    # Iterate over keys to apply the per-item logic.
    for key in keys:
        if form_data.get(key) not in (None, ""):
            raise AssertionError(f"Expected {key} to be None in scoped form data.")


def _debug_test_defaults_planning_scoped(app) -> Dict[str, Any]:
    """Perform debug test defaults planning scoped.
    Used to keep the workflow logic localized and testable."""
    # Closure captures _debug_test_defaults_planning_scoped local context to keep helper logic scoped and invoked directly within _debug_test_defaults_planning_scoped.
    def _run():
        """Run value.
        Used to execute value and coordinate results."""
        _debug_clear_sol_inputs(app)
        mode_var = getattr(app, "_sol_mode_var", None)
        if mode_var is not None:
            mode_var.set("nahco3_dissolution")
        try:
            app._select_sol_workflow_tab("Planning")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        include_headspace_var = getattr(app, "_sol_include_headspace_var", None)
        if include_headspace_var is not None:
            include_headspace_var.set(True)
        limit_ionic_var = getattr(app, "_sol_limit_ionic_var", None)
        if limit_ionic_var is not None:
            limit_ionic_var.set(False)

        required_values = {
            "mass_naoh_g": 100.0,
            "water_mass_g": 1000.0,
            "temperature_c": 25.0,
            "planning_cycle_delta_p_psi": 250.0,
            "planning_headspace_pressure_high_psi": 750.0,
            "planning_headspace_volume_l": 1.0,
            "headspace_pco2_atm": 0.1,
            "headspace_kh_m_per_atm": 0.033,
        }
        # Iterate over items from required_values to apply the per-item logic.
        for key, value in required_values.items():
            _debug_set_sol_value(app, key, value)

        try:
            form_data = app._collect_solubility_form_data()
        except Exception as exc:
            raise AssertionError(f"Planning scoped test failed: {exc}") from exc
        _debug_assert_scoped_none(
            form_data,
            [
                "reaction_naoh_mass",
                "reaction_solution_volume",
                "reaction_co2_g",
                "reaction_final_ph",
                "reaction_slurry_ph",
                "reaction_target_ph",
                "failing_ph",
            ],
        )
        diagnostic_data = form_data.get("diagnostic_data") or {}
        _debug_assert_scoped_none(
            diagnostic_data,
            [
                "dried_ph",
                "slurry_ph",
                "target_ph",
                "sample_mass_g",
            ],
        )
        return form_data

    return _debug_with_fresh_settings(_run)


def _debug_test_defaults_analysis_scoped(app) -> Dict[str, Any]:
    """Perform debug test defaults analysis scoped.
    Used to keep the workflow logic localized and testable."""
    # Closure captures _debug_test_defaults_analysis_scoped local context to keep helper logic scoped and invoked directly within _debug_test_defaults_analysis_scoped.
    def _run():
        """Run value.
        Used to execute value and coordinate results."""
        _debug_clear_sol_inputs(app)
        mode_var = getattr(app, "_sol_mode_var", None)
        if mode_var is not None:
            mode_var.set("naoh_reaction")
        try:
            app._select_sol_workflow_tab("Analysis")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        include_headspace_var = getattr(app, "_sol_include_headspace_var", None)
        if include_headspace_var is not None:
            include_headspace_var.set(False)
        limit_ionic_var = getattr(app, "_sol_limit_ionic_var", None)
        if limit_ionic_var is not None:
            limit_ionic_var.set(False)

        required_values = {
            "mass_na_hco3_g": 100.0,
            "water_mass_g": 1000.0,
            "temperature_c": 25.0,
            "reaction_naoh_mass_g": 50.0,
            "reaction_solution_volume_l": 1.0,
            "reaction_co2_charged_g": 0.0,
            "analysis_headspace_volume_l": 1.0,
        }
        # Iterate over items from required_values to apply the per-item logic.
        for key, value in required_values.items():
            _debug_set_sol_value(app, key, value)

        try:
            form_data = app._collect_solubility_form_data()
        except Exception as exc:
            raise AssertionError(f"Analysis scoped test failed: {exc}") from exc
        _debug_assert_scoped_none(
            form_data,
            [
                "planning_cycle_delta_p_psi",
                "planning_headspace_pressure_high_psi",
                "planning_cycle_co2_g",
                "planning_stop_co2_added_g",
                "planning_stop_ph",
                "failing_ph",
            ],
        )
        diagnostic_data = form_data.get("diagnostic_data") or {}
        _debug_assert_scoped_none(
            diagnostic_data,
            [
                "dried_ph",
                "slurry_ph",
                "target_ph",
                "sample_mass_g",
            ],
        )
        return form_data

    return _debug_with_fresh_settings(_run)


def _debug_test_defaults_reprocessing_scoped(app) -> Dict[str, Any]:
    """Perform debug test defaults reprocessing scoped.
    Used to keep the workflow logic localized and testable."""
    # Closure captures _debug_test_defaults_reprocessing_scoped local context to keep helper logic scoped and invoked directly within _debug_test_defaults_reprocessing_scoped.
    def _run():
        """Run value.
        Used to execute value and coordinate results."""
        _debug_clear_sol_inputs(app)
        mode_var = getattr(app, "_sol_mode_var", None)
        if mode_var is not None:
            mode_var.set("contaminated_bicarb_diagnostic")
        try:
            app._select_sol_workflow_tab("Reprocessing")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        include_headspace_var = getattr(app, "_sol_include_headspace_var", None)
        if include_headspace_var is not None:
            include_headspace_var.set(False)
        limit_ionic_var = getattr(app, "_sol_limit_ionic_var", None)
        if limit_ionic_var is not None:
            limit_ionic_var.set(False)

        required_values = {
            "mass_na_hco3_g": 100.0,
            "solution_volume_l": 2.5,
            "temperature_c": 25.0,
            "diag_slurry_ph": 9.0,
            "diag_target_ph": 8.0,
        }
        # Iterate over items from required_values to apply the per-item logic.
        for key, value in required_values.items():
            _debug_set_sol_value(app, key, value)

        try:
            form_data = app._collect_solubility_form_data()
        except Exception as exc:
            raise AssertionError(f"Reprocessing scoped test failed: {exc}") from exc
        _debug_assert_scoped_none(
            form_data,
            [
                "reaction_naoh_mass",
                "reaction_solution_volume",
                "reaction_co2_g",
                "reaction_final_ph",
                "reaction_slurry_ph",
                "reaction_target_ph",
            ],
        )
        return form_data

    return _debug_with_fresh_settings(_run)


def _dev_validate_plot_title_centering_and_labels_impl() -> None:
    """Validate plot title centering and labels impl.
    Used by dev workflows to validate plot title centering and labels impl."""

    # Closure captures _dev_validate_plot_title_centering_and_labels_impl local context to keep helper logic scoped and invoked directly within _dev_validate_plot_title_centering_and_labels_impl.
    def _iter_data_axes(fig: Figure) -> List[Axes]:
        """Perform iter data axes.
        Used to keep the workflow logic localized and testable."""
        axes: List[Axes] = []
        # Iterate over fig.get_axes() to apply the per-item logic.
        for axis in fig.get_axes():
            if axis is None:
                continue
            try:
                if not axis.get_visible():
                    continue
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if getattr(axis, "_gl260_legend_only", False):
                continue
            axes.append(axis)
        return axes

    # Closure captures _dev_validate_plot_title_centering_and_labels_impl local context to keep helper logic scoped and invoked directly within _dev_validate_plot_title_centering_and_labels_impl.
    def _axes_union_center(axes: Sequence[Axes]) -> float:
        """Center value.
        Used by axes union workflows to center value."""
        try:
            bbox = Bbox.union([axis.get_position() for axis in axes])
            return (bbox.x0 + bbox.x1) / 2.0
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return 0.5

    # Closure captures _dev_validate_plot_title_centering_and_labels_impl local context to keep helper logic scoped and invoked directly within _dev_validate_plot_title_centering_and_labels_impl.
    def _warn(message: str) -> None:
        """Perform warn.
        Used to keep the workflow logic localized and testable."""
        print(f"[WARN] {message}")

    # Closure captures _dev_validate_plot_title_centering_and_labels_impl local context to keep helper logic scoped and invoked directly within _dev_validate_plot_title_centering_and_labels_impl.
    def _check_figure(label: str, fig: Figure, axes: Sequence[Axes]) -> None:
        """Perform check figure.
        Used to keep the workflow logic localized and testable."""
        axes = [axis for axis in axes if axis is not None]
        if not axes:
            _warn(f"{label}: no axes found for validation.")
            return
        label_sizes = []
        # Iterate over axes to apply the per-item logic.
        for axis in axes:
            try:
                label_sizes.append(float(axis.yaxis.label.get_fontsize()))
            except Exception:
                continue
        if label_sizes:
            if max(label_sizes) - min(label_sizes) > 0.01:
                _warn(f"{label}: y-label font sizes mismatch {label_sizes}.")

        def _artist_x_in_figure(artist: Any) -> Optional[float]:
            """Map artist x-position into figure coordinates for center checks."""
            if artist is None:
                return None
            try:
                pos = artist.get_position()
            except Exception:
                return None
            try:
                transform = artist.get_transform()
                display_xy = transform.transform(pos)
                fig_xy = fig.transFigure.inverted().transform(display_xy)
                return float(fig_xy[0])
            except Exception:
                try:
                    return float(pos[0])
                except Exception:
                    return None

        def _bbox_in_fig(artist: Any) -> Optional[Bbox]:
            """Measure one artist in figure coordinates."""
            if artist is None:
                return None
            try:
                if fig.canvas is None:
                    FigureCanvasAgg(fig)
                fig.canvas.draw()
                renderer = fig.canvas.get_renderer()
            except Exception:
                return None
            try:
                return artist.get_window_extent(renderer=renderer).transformed(
                    fig.transFigure.inverted()
                )
            except Exception:
                return None

        title_artist = getattr(fig, "_gl260_title_text", None)
        if title_artist is not None and getattr(title_artist, "axes", None) is None:
            _warn(
                f"{label}: title artist is figure-level; expected axes-bound title for parity."
            )

        center_x = _axes_union_center(axes)
        tol = 0.002
        # Iterate to apply the per-item logic.
        for tag, attr in (
            ("title", "_gl260_title_text"),
            ("suptitle", "_gl260_suptitle_text"),
        ):
            artist = getattr(fig, attr, None)
            if artist is None:
                continue
            artist_x = _artist_x_in_figure(artist)
            if artist_x is None:
                continue
            if abs(artist_x - center_x) > tol:
                _warn(
                    f"{label}: {tag} x={artist_x:.4f} does not match center {center_x:.4f}."
                )

        suptitle_artist = getattr(fig, "_gl260_suptitle_text", None)
        title_bbox = _bbox_in_fig(title_artist)
        suptitle_bbox = _bbox_in_fig(suptitle_artist)
        if title_bbox is not None and title_bbox.y0 > 1.001:
            _warn(f"{label}: title appears off-canvas (y0={title_bbox.y0:.4f}).")
        if (
            title_bbox is not None
            and suptitle_bbox is not None
            and suptitle_bbox.y0 < title_bbox.y1
        ):
            _warn(
                f"{label}: suptitle overlaps title (title_y1={title_bbox.y1:.4f}, suptitle_y0={suptitle_bbox.y0:.4f})."
            )

    sentinel = object()
    globals_snapshot: Dict[str, Any] = {
        key: globals().get(key, sentinel)
        # Iterate to apply the per-item logic.
        for key in (
            "x",
            "y1",
            "y2",
            "y3",
            "z",
            "z2",
            "selected_columns",
            "core_cycle_overlay",
        )
    }
    figures: List[Figure] = []
    try:
        font_family = (settings.get("font_family") or "").strip()
        # Single-axis
        fig_single, ax_single = plt.subplots(figsize=(6.0, 4.0))
        ax_single.plot([0, 1, 2], [1, 2, 3], color="blue")
        ax_single.set_xlabel("Time", fontsize=label_fontsize)
        ax_single.set_ylabel("Pressure (PSI)", fontsize=label_fontsize)
        _enforce_axis_text_style(
            ax_single,
            font_family=font_family,
            tick_fontsize=tick_labelsize,
            label_fontsize=label_fontsize,
        )
        _center_titles_to_axes_union(
            fig_single,
            [ax_single],
            "Single Axis Title",
            "Single Axis Suptitle",
            subplottitle_fontsize,
            suptitle_fontsize,
            font_family,
            float(plt.rcParams.get("axes.titlepad", 6.0)),
            0.0,
            suptitle_y=suptitle_yposition,
        )
        figures.append(fig_single)

        # Dual-axis
        fig_dual, ax_left = plt.subplots(figsize=(6.0, 4.0))
        ax_right = ax_left.twinx()
        ax_left.plot([0, 1, 2], [1, 2, 3], color="blue")
        ax_right.plot([0, 1, 2], [10, 12, 11], color="red")
        ax_left.set_xlabel("Time", fontsize=label_fontsize)
        ax_left.set_ylabel("Pressure (PSI)", fontsize=label_fontsize)
        ax_right.set_ylabel("Temperature (°C)", fontsize=label_fontsize, rotation=-90)
        _enforce_axis_text_style(
            ax_left,
            font_family=font_family,
            tick_fontsize=tick_labelsize,
            label_fontsize=label_fontsize,
        )
        _enforce_axis_text_style(
            ax_right,
            font_family=font_family,
            tick_fontsize=tick_labelsize,
            label_fontsize=label_fontsize,
        )
        _center_titles_to_axes_union(
            fig_dual,
            [ax_left, ax_right],
            "Dual Axis Title",
            "Dual Axis Suptitle",
            subplottitle_fontsize,
            suptitle_fontsize,
            font_family,
            float(plt.rcParams.get("axes.titlepad", 6.0)),
            0.0,
            suptitle_y=suptitle_yposition,
        )
        figures.append(fig_dual)

        # Triple-axis
        globals().update(
            {
                "x": np.array([0.0, 1.0, 2.0]),
                "y1": np.array([1.0, 2.0, 3.0]),
                "y3": np.array([2.0, 1.5, 2.5]),
                "y2": np.array([0.2, -0.1, 0.3]),
                "z": np.array([25.0, 30.0, 28.0]),
                "z2": None,
                "selected_columns": {
                    "x": "Elapsed Time",
                    "y1": "Pressure",
                    "y3": "Aux Pressure",
                    "y2": "Derivative",
                    "z": "Temperature (°C)",
                },
                "core_cycle_overlay": None,
            }
        )
        fig_triple = build_combined_triple_axis_figure(
            0.0,
            2.0,
            0.0,
            4.0,
            20.0,
            40.0,
            -2.0,
            2.0,
            True,
            True,
            True,
            True,
            "Triple Axis Title",
            "Triple Axis Suptitle",
            1.0,
            0.5,
            1.0,
            0.5,
            5.0,
            1.0,
            0.5,
            0.25,
            True,
            True,
            1.1,
            font_family=font_family or DEFAULT_COMBINED_FONT_FAMILY,
            label_fontsize_override=label_fontsize,
            tick_fontsize_override=tick_labelsize,
            title_fontsize=subplottitle_fontsize,
            suptitle_fontsize=suptitle_fontsize,
        )
        figures.append(fig_triple)

        checks = [
            ("Single-axis", fig_single, _iter_data_axes(fig_single)),
            ("Dual-axis", fig_dual, _iter_data_axes(fig_dual)),
            ("Triple-axis", fig_triple, _iter_data_axes(fig_triple)),
        ]
        # Iterate over checks to apply the per-item logic.
        for label, fig, axes in checks:
            _check_figure(label, fig, axes)
    except Exception as exc:
        _warn(f"Dev plot validation failed: {exc}")
    finally:
        # Iterate over figures to apply the per-item logic.
        for fig in figures:
            try:
                plt.close(fig)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        # Iterate over items from globals_snapshot to apply the per-item logic.
        for key, original in globals_snapshot.items():
            if original is sentinel:
                globals().pop(key, None)
            else:
                globals()[key] = original


def _dev_test_timeline_table_export() -> Tuple[bool, Path, List[Path], List[str]]:
    """Export value.
    Used by dev test timeline table workflows to export value."""

    headers = [
        "Cycle",
        "Species",
        "Phase",
        "CO2 added (g)",
        "Predicted pH",
        "pCO2 (atm)",
        "HCO3- %",
        "CO3^2- %",
        "Notes",
    ]
    column_ids = [
        "cycle",
        "species",
        "phase",
        "co2_added_g",
        "predicted_ph",
        "pco2_atm",
        "hco3_pct",
        "co3_pct",
        "warnings",
    ]
    numeric_specs: Dict[str, Union[int, str]] = {
        "Cycle": 0,
        "CO2 added (g)": 2,
        "Predicted pH": 2,
        "pCO2 (atm)": "sig3",
        "HCO3- %": 1,
        "CO3^2- %": 1,
    }
    species_labels = [
        "CO\u2082",
        "H\u2082CO\u2083",
        "HCO\u2083\u207b",
        "CO\u2083\u00b2\u207b",
        "Na\u2082CO\u2083",
        "NaHCO\u2083",
        "Na\u207a",
        "pCO\u2082",
    ]
    rows: List[List[Any]] = []
    # Iterate over the configured range to apply the per-item logic.
    for idx in range(1, 111):
        species = species_labels[idx % len(species_labels)]
        phase = "aq" if idx % 3 else "solid"
        notes = (
            f"Cycle {idx}: extended notes for layout testing with Unicode "
            f"species ({species}) and repeated commentary on dosing alignment, "
            "sampling cadence, and headspace stability to force wrapping and truncation."
        )
        rows.append(
            [
                idx,
                species,
                phase,
                0.45 * idx,
                7.4 + 0.01 * idx,
                0.0005 * idx,
                max(0.0, 65.0 - 0.3 * idx),
                min(35.0, 20.0 + 0.2 * idx),
                notes,
            ]
        )

    title = CYCLE_TIMELINE_EXPORT_DEFAULT_TITLE
    subtitle = "Workflow: Dev Test | Speciation model: Unicode smoke"
    dpi = 200
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    out_dir = Path(tempfile.gettempdir()) / f"gl260_timeline_table_export_{timestamp}"
    out_dir.mkdir(parents=True, exist_ok=True)
    outputs: List[Path] = []
    errors: List[str] = []

    # Closure captures _dev_test_timeline_table_export local context to keep helper logic scoped and invoked directly within _dev_test_timeline_table_export.
    def _render_and_save(orientation: str) -> None:
        """Render and save.
        Used to draw and save for preview or export workflows."""
        label = orientation.lower()
        try:
            figures = _render_timeline_table_matplotlib_pages(
                headers,
                rows,
                numeric_specs,
                title,
                subtitle,
                dpi,
                orientation=label,
                column_ids=column_ids,
                font_family=settings.get("font_family"),
            )
        except Exception as exc:
            errors.append(f"{orientation} render failed: {exc}")
            return
        if not figures:
            errors.append(f"{orientation} render failed: no pages generated.")
            return
        pdf_path = out_dir / f"timeline_table_{label}.pdf"
        png_base = out_dir / f"timeline_table_{label}.png"
        png_paths: List[Path] = []
        try:
            multi_page = len(figures) > 1
            with PdfPages(pdf_path) as pdf:
                # Iterate over indexed elements from figures, start=1 to apply the per-item logic.
                for page_idx, fig in enumerate(figures, start=1):
                    pdf.savefig(fig)
                    if multi_page:
                        stem = png_base.with_suffix("")
                        page_path = stem.parent / f"{stem.name}_p{page_idx:02d}.png"
                    else:
                        page_path = png_base
                    fig.savefig(page_path, dpi=dpi)
                    png_paths.append(page_path)
                    plt.close(fig)
        except Exception as exc:
            errors.append(f"{orientation} save failed: {exc}")
            # Iterate over figures to apply the per-item logic.
            for fig in figures:
                try:
                    plt.close(fig)
                except Exception:
                    pass
            return
        if not pdf_path.exists() or pdf_path.stat().st_size <= 0:
            errors.append(f"{orientation} PDF missing or empty: {pdf_path}")
        else:
            outputs.append(pdf_path)
        # Iterate over png_paths to apply the per-item logic.
        for png_path in png_paths:
            if not png_path.exists() or png_path.stat().st_size <= 0:
                errors.append(f"{orientation} PNG missing or empty: {png_path}")
            else:
                outputs.append(png_path)

    _render_and_save("portrait")
    _render_and_save("landscape")
    success = not errors
    return success, out_dir, outputs, errors


# ---------- Global styling ----------
_apply_default_plot_fonts(settings.get("font_family"))

SUBPLOT_TITLE_FONTSIZE = 14
LABEL_FONTSIZE = 12
SUPTITLE_FONTSIZE = 18
SUPTITLE_Y = 0.975
TICK_LABELSIZE = 11

LINESTYLE_DEFAULT = "-"
MARKER_DEFAULT = "."
LINEWIDTH_DEFAULT = 1.0
MARKERSIZE_DEFAULT = 2.0
MARKER_CHOICES = [
    "",
    ".",
    "o",
    "v",
    "^",
    "<",
    ">",
    "s",
    "p",
    "*",
    "x",
    "D",
    "h",
    "+",
    "1",
    "2",
    "3",
    "4",
]

# Resizable-left-column defaults
LEFT_COL_INIT = 520  # initial width of the left pane (drag the sash to resize)
LEFT_COL_MIN = 360  # don't let it shrink below this (keeps controls readable)
SCROLLBAR_FALLBACK_WIDTH = 18  # used only before the real width is known


def _safe_float(v, default=None):
    """Perform safe float.
    Used to keep the workflow logic localized and testable."""
    try:
        return float(v)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return default


def _pressure_psi_to_atm(psi: Optional[float]) -> Optional[float]:
    """Perform pressure psi to atm.
    Used to keep the workflow logic localized and testable."""
    if psi is None:
        return None
    try:
        psi_value = float(psi)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return None
    if not math.isfinite(psi_value):
        return None
    return psi_value / 14.696


def _cycle_headspace_pressure_psi(cycle: Mapping[str, Any]) -> Optional[float]:
    """Perform cycle headspace pressure psi.
    Used to keep the workflow logic localized and testable."""
    # Iterate over ("headspace_pressure_psi", "peak_pressure_psi", "trough_pressure_psi") to apply the per-item logic.
    for key in ("headspace_pressure_psi", "peak_pressure_psi", "trough_pressure_psi"):
        candidate = _safe_float(cycle.get(key))
        if candidate is not None:
            return candidate
    return None


def _timeline_headspace_measurement(
    timeline: Sequence[Dict[str, Any]],
) -> Tuple[Optional[float], Optional[float]]:
    """Perform timeline headspace measurement.
    Used to keep the workflow logic localized and testable."""
    # Iterate over timeline or [] to apply the per-item logic.
    for entry in timeline or []:
        psi = _cycle_headspace_pressure_psi(entry)
        if psi is not None:
            return psi, _pressure_psi_to_atm(psi)
        pco2 = entry.get("pco2_atm")
        if pco2 is not None:
            try:
                value = float(pco2)
                if math.isfinite(value) and value > 0:
                    return None, value
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
    return None, None


def _format_thousands(v, _):
    """Format thousands.
    Used to prepare thousands for display or export."""
    try:
        v = float(v)
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return ""
    abs_v = abs(v)
    if abs_v >= 1_000_000_000:
        return f"{v/1_000_000_000:.2f}B"
    if abs_v >= 1_000_000:
        return f"{v/1_000_000:.2f}M"
    if abs_v >= 1_000:
        return f"{v/1_000:.2f}k"
    return f"{v:.0f}"


def _percent_fmt(v, _):
    """Perform percent fmt.
    Used to keep the workflow logic localized and testable."""
    try:
        return f"{100*float(v):.0f}%"
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return ""


def _make_legends_draggable(fig):
    """Perform make legends draggable.
    Used to keep the workflow logic localized and testable."""
    if fig is None:
        return
    seen = set()
    # Iterate over getattr(fig, "legends", []) to apply the per-item logic.
    for legend in getattr(fig, "legends", []):
        if legend is None:
            continue
        _make_legend_draggable(legend)
        seen.add(id(legend))
    # Iterate over getattr(fig, "axes", []) to apply the per-item logic.
    for ax in getattr(fig, "axes", []):
        legend = ax.get_legend()
        if legend is None or id(legend) in seen:
            continue
        _make_legend_draggable(legend)


def _resolve_right_label(custom, fallback):
    """Resolve right label.
    Used to compute right label before rendering or export."""
    custom = (custom or "").strip()
    if custom:
        return custom
    return fallback or ""


def _apply_theme(theme_key: str):
    """Apply theme.
    Used to apply theme changes to live state."""
    if theme_key == "classic":
        plt.rcParams.update(
            {
                "axes.grid": False,
                "figure.facecolor": "white",
                "axes.facecolor": "white",
                "text.color": "black",
                "axes.labelcolor": "black",
                "xtick.color": "black",
                "ytick.color": "black",
            }
        )
    elif theme_key == "minimal":
        plt.rcParams.update(
            {
                "axes.grid": True,
                "grid.alpha": 0.25,
                "figure.facecolor": "white",
                "axes.facecolor": "white",
                "text.color": "black",
                "axes.labelcolor": "black",
                "xtick.color": "black",
                "ytick.color": "black",
            }
        )
    elif theme_key == "dark":
        plt.rcParams.update(
            {
                "axes.grid": True,
                "grid.color": "#888",
                "figure.facecolor": "#111",
                "axes.facecolor": "#111",
                "text.color": "white",
                "axes.labelcolor": "white",
                "xtick.color": "white",
                "ytick.color": "white",
            }
        )
    elif theme_key == "journal":
        plt.rcParams.update(
            {
                "axes.grid": True,
                "grid.linestyle": ":",
                "grid.alpha": 0.35,
                "figure.facecolor": "white",
                "axes.facecolor": "white",
                "text.color": "black",
                "axes.labelcolor": "black",
                "xtick.color": "black",
                "ytick.color": "black",
            }
        )


def _apply_formatter_to_axis(axis, fmt_key: str):
    """Apply formatter to axis.
    Used to apply formatter to axis changes to live state."""
    if fmt_key == "plain":
        axis.set_major_formatter(ScalarFormatter(useMathText=False))
    elif fmt_key == "sci":
        sf = ScalarFormatter(useMathText=True)
        sf.set_powerlimits((-3, 3))
        axis.set_major_formatter(sf)
    elif fmt_key == "percent":
        axis.set_major_formatter(FuncFormatter(_percent_fmt))
    elif fmt_key == "thousands":
        axis.set_major_formatter(FuncFormatter(_format_thousands))


def _safe_color_dialog(initial="#1f77b4"):
    """Perform safe color dialog.
    Used to keep the workflow logic localized and testable."""
    try:
        c = colorchooser.askcolor(color=initial)[1]
        return c or initial
    except Exception:
        # Best-effort guard; ignore failures to avoid interrupting the workflow.
        return initial


class CsvImportDialog:
    def __init__(
        self, app: tk.Tk, *, on_close: Optional[Callable[[], None]] = None
    ) -> None:
        """Initialize the CSV import dialog state and window shell.

        Purpose:
            Prepare dialog variables, mapping state, and widget references used by
            the GL-260 CSV import workflow.
        Why:
            The dialog reuses persisted defaults and needs deterministic startup
            state before controls are rendered and callbacks fire.
        Args:
            app: Parent application window that owns this modal dialog.
            on_close: Optional callback invoked after the dialog closes.
        Returns:
            None.
        Side Effects:
            Creates a modal `tk.Toplevel`, configures geometry and bindings, and
            initializes Tk variables for import settings.
        Exceptions:
            Best-effort guards in downstream helpers prevent UI setup failures
            from interrupting the parent workflow.
        """
        self.app = app
        self._on_close = on_close
        self._preview_task_id: Optional[int] = None
        self._import_task_id: Optional[int] = None
        self._detected_columns: List[str] = []
        self._datetime_column: Optional[str] = None
        self._ignored_columns: Set[str] = set()
        self._last_suggested_sheet = ""

        settings_dict = settings
        csv_path = settings_dict.get("csv_import_last_csv_path", "")
        if not isinstance(csv_path, str):
            csv_path = ""
        workbook_path = settings_dict.get("csv_import_last_workbook_path", "")
        if not isinstance(workbook_path, str):
            workbook_path = ""
        if not workbook_path:
            workbook_path = getattr(app, "file_path", "") or settings_dict.get(
                "last_file_path", ""
            )
        sheet_name = settings_dict.get("csv_import_last_sheet_name", "")
        if not isinstance(sheet_name, str):
            sheet_name = ""

        self._csv_path_var = tk.StringVar(value=csv_path)
        self._workbook_path_var = tk.StringVar(value=workbook_path)
        self._sheet_name_var = tk.StringVar(value=sheet_name)
        self._status_var = tk.StringVar(value="Select a CSV file to begin.")
        self._detected_columns_var = tk.StringVar(value="Detected columns: none")
        self._datetime_column_var = tk.StringVar(value="Date & Time column: n/a")

        self._mapping_vars: Dict[str, tk.StringVar] = {}
        saved_mapping = settings_dict.get("csv_import_mapping", {})
        # Iterate over keys from CSV_IMPORT_MAPPING_FIELDS to apply the per-item logic.
        for key in CSV_IMPORT_MAPPING_FIELDS.keys():
            value = saved_mapping.get(key, "") if isinstance(saved_mapping, dict) else ""
            if not isinstance(value, str):
                value = ""
            self._mapping_vars[key] = tk.StringVar(value=value)

        source_key = settings_dict.get(
            "csv_import_derivative_source", CSV_IMPORT_DEFAULT_DERIVATIVE_SOURCE
        )
        source_label = CSV_IMPORT_DERIVATIVE_SOURCE_LABELS.get(
            source_key,
            CSV_IMPORT_DERIVATIVE_SOURCE_LABELS[CSV_IMPORT_DEFAULT_DERIVATIVE_SOURCE],
        )
        self._derivative_source_display_map = {
            label: key for key, label in CSV_IMPORT_DERIVATIVE_SOURCE_LABELS.items()
        }
        self._derivative_source_var = tk.StringVar(value=source_label)

        sheet_mode_key = settings_dict.get(
            "csv_import_sheet_exists_mode", CSV_IMPORT_DEFAULT_SHEET_EXISTS_MODE
        )
        sheet_mode_label = CSV_IMPORT_SHEET_MODE_LABELS.get(
            sheet_mode_key,
            CSV_IMPORT_SHEET_MODE_LABELS[CSV_IMPORT_DEFAULT_SHEET_EXISTS_MODE],
        )
        self._sheet_mode_display_map = {
            label: key for key, label in CSV_IMPORT_SHEET_MODE_LABELS.items()
        }
        self._sheet_mode_var = tk.StringVar(value=sheet_mode_label)

        dampening = settings_dict.get(
            "csv_import_smoothing_factor", CSV_IMPORT_DEFAULT_DAMPENING
        )
        if not isinstance(dampening, (int, float)):
            dampening = CSV_IMPORT_DEFAULT_DAMPENING
        self._dampening_var = tk.StringVar(value=f"{float(dampening):.3f}")

        window = settings_dict.get(
            "csv_import_moving_average_window", CSV_IMPORT_DEFAULT_MOVING_AVG_WINDOW
        )
        if not isinstance(window, int):
            try:
                window = int(window)
            except (TypeError, ValueError):
                window = CSV_IMPORT_DEFAULT_MOVING_AVG_WINDOW
        self._window_var = tk.StringVar(value=str(window))

        self.window = tk.Toplevel(app)
        self.window.title("Import GL-260 CSV")
        self.window.transient(app)
        self.window.resizable(True, True)
        self.window.protocol("WM_DELETE_WINDOW", self._close)
        self.window.bind("<Escape>", lambda _event: self._close())
        self.window.grab_set()

        self._mapping_combos: Dict[str, Any] = {}
        self._ignore_listbox: Optional[tk.Listbox] = None
        self._preview_text: Optional[scrolledtext.ScrolledText] = None
        self._import_button: Optional[Any] = None
        self._close_button: Optional[Any] = None
        self._content_canvas: Optional[tk.Canvas] = None
        self._content_window_id: Optional[int] = None
        self._content_container: Optional[ttk.Frame] = None

        self._configure_dialog_geometry()
        self._build_ui()
        self._suggest_sheet_name(force=not bool(sheet_name))
        if csv_path and os.path.exists(csv_path):
            self._refresh_preview()

    def _scale_length(self, value: int) -> int:
        """Perform scale length.
        Used to keep the workflow logic localized and testable."""
        scaler = getattr(self.app, "_scale_length", None)
        if callable(scaler):
            try:
                return int(scaler(value))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return int(value)
        return int(value)

    def _configure_dialog_geometry(self) -> None:
        """Apply compact, screen-safe geometry defaults for the import dialog.

        Purpose:
            Size and position the import popup for typical laptop displays while
            preserving resize support for larger workflows.
        Why:
            The legacy dialog opened too tall for constrained screens, which could
            hide action buttons and block the import flow.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Updates dialog geometry, minimum size, and initial on-screen position.
        Exceptions:
            Uses best-effort guards so geometry issues do not prevent dialog open.
        """
        min_width = self._scale_length(720)
        min_height = self._scale_length(520)
        preferred_width = self._scale_length(940)
        preferred_height = self._scale_length(700)
        try:
            self.app.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        parent_width = int(getattr(self.app, "winfo_width", lambda: 0)() or 0)
        parent_height = int(getattr(self.app, "winfo_height", lambda: 0)() or 0)
        if parent_width <= 0:
            parent_width = int(self.window.winfo_screenwidth() * 0.9)
        if parent_height <= 0:
            parent_height = int(self.window.winfo_screenheight() * 0.9)
        max_width = max(min_width, int(parent_width * 0.95))
        max_height = max(min_height, int(parent_height * 0.92))
        dialog_width = max(min_width, min(preferred_width, max_width))
        dialog_height = max(min_height, min(preferred_height, max_height))
        try:
            root_x = int(self.app.winfo_rootx())
            root_y = int(self.app.winfo_rooty())
            parent_width_px = int(self.app.winfo_width() or dialog_width)
            parent_height_px = int(self.app.winfo_height() or dialog_height)
            pos_x = root_x + max((parent_width_px - dialog_width) // 2, 0)
            pos_y = root_y + max((parent_height_px - dialog_height) // 2, 0)
            self.window.geometry(f"{dialog_width}x{dialog_height}+{pos_x}+{pos_y}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            self.window.geometry(f"{dialog_width}x{dialog_height}")
        try:
            self.window.minsize(min_width, min_height)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _refresh_dialog_scrollregion(self, _event: Optional[Any] = None) -> None:
        """Sync the dialog canvas scrollregion to the content frame bounds.

        Purpose:
            Keep vertical scrolling accurate as sections expand, collapse, or
            repopulate with preview and mapping content.
        Why:
            Canvas-backed dialog bodies require explicit scrollregion updates or
            lower controls can become unreachable.
        Args:
            _event: Optional Tk configure event triggering the refresh.
        Returns:
            None.
        Side Effects:
            Recomputes `scrollregion` on the import-dialog content canvas.
        Exceptions:
            Uses best-effort guards to avoid UI interruptions during resize events.
        """
        canvas = self._content_canvas
        if canvas is None:
            return
        try:
            canvas.configure(scrollregion=canvas.bbox("all"))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _expand_dialog_content_width(self, event: Any) -> None:
        """Expand the canvas window item so content tracks the visible width.

        Purpose:
            Make the inner content frame match the current canvas width.
        Why:
            Without width synchronization, sections can clip or leave dead space
            when users resize the import dialog.
        Args:
            event: Tk configure event from the canvas widget.
        Returns:
            None.
        Side Effects:
            Updates the embedded canvas window width for the scrollable body.
        Exceptions:
            Uses best-effort guards for resize timing edge cases.
        """
        canvas = self._content_canvas
        content_window_id = self._content_window_id
        if canvas is None or content_window_id is None:
            return
        try:
            canvas.itemconfigure(content_window_id, width=event.width)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _widget_owns_vertical_scroll(self, widget: Any) -> bool:
        """Check whether a widget should keep its own mousewheel behavior.

        Purpose:
            Detect controls that already provide native vertical scrolling.
        Why:
            The dialog body should scroll globally, but text/list widgets must keep
            direct wheel control so selection and preview browsing stay intuitive.
        Args:
            widget: Event target widget from mousewheel callbacks.
        Returns:
            True when wheel events should not be redirected to the dialog canvas.
        Side Effects:
            None.
        Exceptions:
            Returns False when widget inspection fails.
        """
        if widget is None:
            return False
        if isinstance(widget, (tk.Text, tk.Listbox, ttk.Treeview)):
            return True
        try:
            widget_class = str(widget.winfo_class()).strip().lower()
        except Exception:
            return False
        return widget_class in {"text", "listbox", "treeview"}

    def _on_dialog_mousewheel(self, event: Any) -> Optional[str]:
        """Route mousewheel input to the scrollable dialog body when appropriate.

        Purpose:
            Provide consistent wheel scrolling across all controls in the import
            settings area.
        Why:
            Users need to navigate long forms quickly, but controls with local
            scrolling should retain their native behavior.
        Args:
            event: Mousewheel or button-scroll event from Tk.
        Returns:
            `"break"` when the event is consumed by the dialog canvas; otherwise
            `None` so widget-local scrolling can proceed.
        Side Effects:
            Scrolls the import dialog content canvas in unit steps.
        Exceptions:
            Best-effort guards suppress event-handler failures.
        """
        canvas = self._content_canvas
        if canvas is None:
            return None
        if self._widget_owns_vertical_scroll(getattr(event, "widget", None)):
            return None
        delta = int(getattr(event, "delta", 0) or 0)
        step = 0
        if delta != 0:
            step = -1 if delta > 0 else 1
            if abs(delta) >= 120:
                step = int(-delta / 120)
        else:
            num = int(getattr(event, "num", 0) or 0)
            if num == 4:
                step = -1
            elif num == 5:
                step = 1
        if step == 0:
            return None
        try:
            canvas.yview_scroll(step, "units")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        return "break"

    def _bind_dialog_mousewheel_recursive(self, widget: Any) -> None:
        """Bind wheel events recursively so the form scrolls from any child control.

        Purpose:
            Attach cross-platform wheel handlers to the content tree.
        Why:
            Canvas scrolling in Tkinter only responds when bound widgets receive
            events; recursive binding avoids dead areas in a dense form.
        Args:
            widget: Root widget whose subtree should receive wheel bindings.
        Returns:
            None.
        Side Effects:
            Registers `<MouseWheel>`, `<Button-4>`, and `<Button-5>` handlers on
            the provided widget and all descendants.
        Exceptions:
            Best-effort guards skip widgets that reject event bindings.
        """
        if widget is None:
            return
        try:
            widget.bind("<MouseWheel>", self._on_dialog_mousewheel, add="+")
            widget.bind("<Button-4>", self._on_dialog_mousewheel, add="+")
            widget.bind("<Button-5>", self._on_dialog_mousewheel, add="+")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        children_getter = getattr(widget, "winfo_children", None)
        if not callable(children_getter):
            return
        # Recursively bind descendants so wheel gestures work across nested sections.
        for child in children_getter():
            self._bind_dialog_mousewheel_recursive(child)

    def _build_ui(self) -> None:
        """Build the CSV import dialog UI with scrollable content and fixed footer.

        Purpose:
            Assemble all import workflow controls, preview widgets, and action
            buttons for GL-260 CSV ingestion.
        Why:
            The import form can exceed available window height, so the settings
            body must scroll independently while action buttons remain visible.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Creates Tk widgets, configures canvas scrolling, stores control
            references, and binds wheel handlers for the form content.
        Exceptions:
            Widget construction uses best-effort guards in helper callbacks.
        """
        self.window.grid_rowconfigure(0, weight=1)
        self.window.grid_rowconfigure(1, weight=0)
        self.window.grid_columnconfigure(0, weight=1)

        scroll_shell = ttk.Frame(self.window, padding=(12, 12, 12, 0))
        scroll_shell.grid(row=0, column=0, sticky="nsew")
        scroll_shell.grid_rowconfigure(0, weight=1)
        scroll_shell.grid_columnconfigure(0, weight=1)

        canvas = tk.Canvas(scroll_shell, borderwidth=0, highlightthickness=0)
        vscroll = _ui_scrollbar(scroll_shell, orient="vertical", command=canvas.yview)
        canvas.configure(yscrollcommand=vscroll.set)
        canvas.grid(row=0, column=0, sticky="nsew")
        vscroll.grid(row=0, column=1, sticky="ns", padx=(8, 0))

        container = ttk.Frame(canvas)
        container_id = canvas.create_window((0, 0), window=container, anchor="nw")
        container.grid_columnconfigure(0, weight=1)
        self._content_canvas = canvas
        self._content_window_id = container_id
        self._content_container = container
        container.bind("<Configure>", self._refresh_dialog_scrollregion)
        canvas.bind("<Configure>", self._expand_dialog_content_width)
        self.window.after_idle(lambda: self._bind_dialog_mousewheel_recursive(container))
        self.window.after_idle(self._refresh_dialog_scrollregion)

        input_frame = ttk.Labelframe(container, text="Input / Output")
        input_frame.grid(row=0, column=0, sticky="ew", pady=(0, 10))
        input_frame.grid_columnconfigure(1, weight=1)

        ttk.Label(input_frame, text="CSV file").grid(
            row=0, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(input_frame, textvariable=self._csv_path_var).grid(
            row=0, column=1, sticky="ew", padx=6, pady=4
        )
        _ui_button(input_frame, text="Browse...", command=self._browse_csv).grid(
            row=0, column=2, padx=6, pady=4
        )
        _ui_button(input_frame, text="Preview", command=self._refresh_preview).grid(
            row=0, column=3, padx=6, pady=4
        )

        ttk.Label(input_frame, text="Excel workbook").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(input_frame, textvariable=self._workbook_path_var).grid(
            row=1, column=1, sticky="ew", padx=6, pady=4
        )
        _ui_button(input_frame, text="Browse...", command=self._browse_workbook).grid(
            row=1, column=2, padx=6, pady=4
        )

        ttk.Label(input_frame, text="New sheet name").grid(
            row=2, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(input_frame, textvariable=self._sheet_name_var).grid(
            row=2, column=1, sticky="ew", padx=6, pady=4
        )

        ttk.Label(input_frame, text="If sheet exists").grid(
            row=3, column=0, sticky="w", padx=6, pady=4
        )
        _ui_combobox(
            input_frame,
            textvariable=self._sheet_mode_var,
            values=list(CSV_IMPORT_SHEET_MODE_LABELS.values()),
            state="readonly",
        ).grid(row=3, column=1, sticky="w", padx=6, pady=4)

        preview_frame = ttk.Labelframe(container, text="CSV Parsing")
        preview_frame.grid(row=1, column=0, sticky="ew", pady=(0, 10))
        preview_frame.grid_columnconfigure(0, weight=1)

        ttk.Label(
            preview_frame,
            textvariable=self._detected_columns_var,
            wraplength=self._scale_length(720),
        ).grid(row=0, column=0, sticky="w", padx=6, pady=(4, 2))
        ttk.Label(
            preview_frame,
            textvariable=self._datetime_column_var,
        ).grid(row=1, column=0, sticky="w", padx=6, pady=(0, 4))

        preview_text = scrolledtext.ScrolledText(
            preview_frame, height=6, wrap="none"
        )
        preview_text.grid(row=2, column=0, sticky="nsew", padx=6, pady=(0, 6))
        preview_text.configure(state="disabled")
        self._preview_text = preview_text

        mapping_frame = ttk.Labelframe(container, text="Channel Mapping")
        mapping_frame.grid(row=2, column=0, sticky="ew", pady=(0, 10))
        mapping_frame.grid_columnconfigure(1, weight=1)

        row = 0
        # Iterate over items from CSV_IMPORT_MAPPING_FIELDS to apply the per-item logic.
        for key, label in CSV_IMPORT_MAPPING_FIELDS.items():
            ttk.Label(mapping_frame, text=label).grid(
                row=row, column=0, sticky="w", padx=6, pady=3
            )
            combo = _ui_combobox(
                mapping_frame, textvariable=self._mapping_vars[key], state="readonly"
            )
            combo.grid(row=row, column=1, sticky="ew", padx=6, pady=3)
            self._mapping_combos[key] = combo
            row += 1

        ttk.Label(mapping_frame, text="Ignore columns (optional)").grid(
            row=row, column=0, sticky="nw", padx=6, pady=(6, 4)
        )
        mapping_frame.grid_rowconfigure(row, weight=1)
        ignore_frame = ttk.Frame(mapping_frame)
        ignore_frame.grid(row=row, column=1, sticky="nsew", padx=6, pady=(6, 4))
        ignore_frame.grid_rowconfigure(0, weight=1)
        ignore_frame.grid_columnconfigure(0, weight=1)
        listbox = tk.Listbox(
            ignore_frame,
            selectmode="multiple",
            height=6,
            exportselection=False,
        )
        listbox.grid(row=0, column=0, sticky="nsew")
        scroll = _ui_scrollbar(ignore_frame, orient="vertical", command=listbox.yview)
        scroll.grid(row=0, column=1, sticky="ns")
        listbox.configure(yscrollcommand=scroll.set)
        listbox.bind("<<ListboxSelect>>", lambda _e: self._on_ignore_change())
        self._ignore_listbox = listbox

        calc_frame = ttk.Labelframe(container, text="Calculation Settings")
        calc_frame.grid(row=3, column=0, sticky="ew", pady=(0, 10))
        calc_frame.grid_columnconfigure(1, weight=1)

        ttk.Label(calc_frame, text="Derivative source").grid(
            row=0, column=0, sticky="w", padx=6, pady=4
        )
        _ui_combobox(
            calc_frame,
            textvariable=self._derivative_source_var,
            values=list(CSV_IMPORT_DERIVATIVE_SOURCE_LABELS.values()),
            state="readonly",
        ).grid(row=0, column=1, sticky="w", padx=6, pady=4)

        ttk.Label(calc_frame, text="Smoothing dampening factor").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(calc_frame, textvariable=self._dampening_var, width=12).grid(
            row=1, column=1, sticky="w", padx=6, pady=4
        )

        ttk.Label(calc_frame, text="Moving average window (points)").grid(
            row=2, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(calc_frame, textvariable=self._window_var, width=12).grid(
            row=2, column=1, sticky="w", padx=6, pady=4
        )

        output_frame = ttk.Labelframe(container, text="Output Schema")
        output_frame.grid(row=4, column=0, sticky="ew", pady=(0, 10))
        output_frame.grid_columnconfigure(0, weight=1)
        ttk.Label(output_frame, text="Fixed column names (default):").grid(
            row=0, column=0, sticky="w", padx=6, pady=(4, 2)
        )
        ttk.Label(
            output_frame,
            text="\n".join(CSV_IMPORT_OUTPUT_COLUMNS),
            justify="left",
        ).grid(row=1, column=0, sticky="w", padx=6, pady=(0, 6))

        footer = ttk.Frame(self.window, padding=(12, 8, 12, 10))
        footer.grid(row=1, column=0, sticky="ew")
        footer.grid_columnconfigure(0, weight=1)
        ttk.Label(footer, textvariable=self._status_var).grid(
            row=0, column=0, sticky="w", padx=(0, 8)
        )
        button_frame = ttk.Frame(footer)
        button_frame.grid(row=0, column=1, sticky="e")
        import_button = _ui_button(
            button_frame, text="Import", command=self._start_import
        )
        import_button.pack(side="right")
        close_button = _ui_button(button_frame, text="Close", command=self._close)
        close_button.pack(side="right", padx=(0, 8))
        self._import_button = import_button
        self._close_button = close_button

    def _set_status(self, message: str) -> None:
        """Set status.
        Used to persist status into the current state."""
        self._status_var.set(message)

    def _set_busy(self, busy: bool) -> None:
        """Set busy.
        Used to persist busy into the current state."""
        state = "disabled" if busy else "normal"
        if self._import_button is not None:
            self._import_button.configure(state=state)
        if self._close_button is not None:
            self._close_button.configure(state=("disabled" if busy else "normal"))

    def _set_combined_render_busy(self, busy: bool) -> None:
        """Set combined render busy.
        Used to apply a lightweight render-in-progress indicator."""
        if busy and not self._combined_render_busy:
            self._combined_render_busy = True
            try:
                self._combined_render_cursor = self.cget("cursor")
            except Exception:
                self._combined_render_cursor = None
            try:
                self.configure(cursor="watch")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        if not busy and self._combined_render_busy:
            self._combined_render_busy = False
            try:
                cursor = self._combined_render_cursor
                self.configure(cursor=cursor if cursor is not None else "")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._combined_render_cursor = None

    def _browse_csv(self) -> None:
        """Open a file dialog to select a CSV input.

        Purpose:
            Allow users to choose a CSV file for import.
        Why:
            Provides a UI pathway to load CSV data into the import workflow.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Updates the CSV path variable and refreshes the preview.
        Exceptions:
            Best-effort guards suppress dialog or preview errors.
        """
        path = filedialog.askopenfilename(
            title="Select GL-260 CSV",
            filetypes=[("CSV File", "*.csv")],
        )
        if not path:
            return
        try:
            self.app._dbg("io.files", "CSV browse selected path=%s", path)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._csv_path_var.set(path)
        self._suggest_sheet_name(force=False)
        self._refresh_preview()

    def _browse_workbook(self) -> None:
        """Open a file dialog to select an Excel workbook.

        Purpose:
            Allow users to choose an Excel file for CSV import output.
        Why:
            Supports routing CSV imports into a target workbook.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Updates the workbook path variable.
        Exceptions:
            Best-effort guards suppress dialog errors.
        """
        path = filedialog.askopenfilename(
            title="Select Excel File", filetypes=[("Excel Files", "*.xlsx *.xls")]
        )
        if not path:
            return
        try:
            self.app._dbg("io.excel", "Workbook browse selected path=%s", path)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._workbook_path_var.set(path)

    def _suggest_sheet_name(self, *, force: bool) -> None:
        """Perform suggest sheet name.
        Used to keep the workflow logic localized and testable."""
        current = self._sheet_name_var.get().strip()
        if current and not force and current != self._last_suggested_sheet:
            return
        path = self._csv_path_var.get().strip()
        if path:
            suggestion = _sanitize_excel_sheet_name(Path(path).stem)
        else:
            suggestion = _sanitize_excel_sheet_name(current or "GL260 Import")
        self._last_suggested_sheet = suggestion
        if force or not current:
            self._sheet_name_var.set(suggestion)

    def _refresh_preview(self) -> None:
        """Refresh preview.
        Used to sync preview with current settings."""
        path = self._csv_path_var.get().strip()
        if not path or not os.path.exists(path):
            self._set_status("Select a valid CSV file to preview.")
            return
        self._set_status("Scanning CSV preview...")

        # Closure captures _refresh_preview state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _refresh_preview.
        def _worker() -> Tuple[List[str], List[List[str]]]:
            """Perform worker.
            Used to keep the workflow logic localized and testable."""
            return _parse_gl260_csv_table(path, max_rows=8)

        # Closure captures _refresh_preview state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _refresh_preview.
        def _on_ok(result: Tuple[List[str], List[List[str]]]) -> None:
            """Handle ok.
            Used as an event callback for ok."""
            columns, rows = result
            self._detected_columns = columns
            self._datetime_column = _detect_gl260_datetime_column(columns)
            self._populate_ignore_columns(columns)
            self._update_mapping_choices()
            self._apply_saved_mapping()
            self._update_preview_text(columns, rows)
            dt_label = self._datetime_column or "Not detected"
            self._datetime_column_var.set(f"Date & Time column: {dt_label}")
            preview_hint = ", ".join(columns[:8])
            if len(columns) > 8:
                preview_hint += ", ..."
            self._detected_columns_var.set(
                f"Detected columns ({len(columns)}): {preview_hint}"
            )
            self._set_status("Preview loaded.")

        # Closure captures _refresh_preview state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _refresh_preview.
        def _on_err(exc: BaseException) -> None:
            """Handle err.
            Used as an event callback for err."""
            self._set_status(f"Preview failed: {exc}")
            messagebox.showerror("CSV Preview Error", f"Could not read CSV:\n{exc}")

        self._preview_task_id = self.app._task_runner.submit(
            "csv_import_preview", _worker, _on_ok, _on_err
        )

    def _populate_ignore_columns(self, columns: Sequence[str]) -> None:
        """Perform populate ignore columns.
        Used to keep the workflow logic localized and testable."""
        listbox = self._ignore_listbox
        if listbox is None:
            return
        listbox.delete(0, tk.END)
        # Iterate over columns to apply the per-item logic.
        for name in columns:
            listbox.insert(tk.END, name)
        self._ignored_columns = set()

    def _update_preview_text(self, columns: Sequence[str], rows: Sequence[Sequence[str]]):
        """Update preview text.
        Used to keep preview text in sync with current state."""
        preview = self._preview_text
        if preview is None:
            return
        preview.configure(state="normal")
        preview.delete("1.0", "end")
        preview.insert("end", " | ".join(columns) + "\n")
        # Iterate over rows[ to apply the per-item logic.
        for row in rows[:5]:
            preview.insert("end", " | ".join(row) + "\n")
        preview.configure(state="disabled")

    def _on_ignore_change(self) -> None:
        """Handle ignore change.
        Used as an event callback for ignore change."""
        listbox = self._ignore_listbox
        if listbox is None:
            return
        selections = listbox.curselection()
        self._ignored_columns = {listbox.get(idx) for idx in selections}
        self._update_mapping_choices()

    def _available_mapping_columns(self) -> List[str]:
        """Perform available mapping columns.
        Used to keep the workflow logic localized and testable."""
        if not self._detected_columns:
            return []
        channel_cols = _detect_gl260_channel_columns(
            self._detected_columns, self._datetime_column
        )
        return [col for col in channel_cols if col not in self._ignored_columns]

    def _update_mapping_choices(self) -> None:
        """Refresh available channel-mapping options after preview changes.

        Purpose:
            Recompute dropdown choices for each mapping field.
        Why:
            The Date & Time channel has different source candidates than pressure/
            temperature channels, and ignored columns must be removed dynamically.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Updates combobox value lists and clears now-invalid selections.
        Exceptions:
            None.
        """
        available = self._available_mapping_columns()
        datetime_options = list(self._detected_columns)
        # Iterate over items from self._mapping_combos to apply the per-item logic.
        for key, combo in self._mapping_combos.items():
            if key == "date_time":
                values = list(datetime_options)
            else:
                values = list(available)
            if key not in {"reactor_pressure", "date_time"}:
                values = ["(None)"] + values
            combo.configure(values=values)
            current = self._mapping_vars[key].get()
            if current not in values:
                self._mapping_vars[key].set("")

    def _apply_saved_mapping(self) -> None:
        """Apply persisted or auto-detected channel mappings to empty fields.

        Purpose:
            Pre-populate mapping inputs from settings and heuristics.
        Why:
            Reduces repetitive manual mapping work across repeated imports.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Writes candidate values into `self._mapping_vars`.
        Exceptions:
            None.
        """
        saved_mapping = settings.get("csv_import_mapping", {})
        # Iterate over items from self._mapping_vars to apply the per-item logic.
        for key, var in self._mapping_vars.items():
            if var.get().strip():
                continue
            if key == "date_time":
                available = set(self._detected_columns)
            else:
                available = set(self._available_mapping_columns())
            candidate = ""
            if isinstance(saved_mapping, dict):
                saved_value = saved_mapping.get(key, "")
                if isinstance(saved_value, str) and saved_value in available:
                    candidate = saved_value
            if not candidate:
                candidate = self._auto_match_column(key, available)
            if candidate:
                var.set(candidate)

    def _auto_match_column(self, key: str, columns: Set[str]) -> str:
        """Infer the best column match for one logical channel key.

        Purpose:
            Select a likely CSV column when the user has not mapped one manually.
        Why:
            Auto-matching accelerates imports while preserving explicit overrides.
        Args:
            key: Logical mapping key (for example `date_time` or `reactor_pressure`).
            columns: Candidate column names currently available for that key.
        Returns:
            str: The matched column name, or an empty string when no match is found.
        Side Effects:
            None.
        Exceptions:
            None.
        """
        if key == "date_time":
            detected = _detect_gl260_datetime_column(list(columns))
            return detected or ""
        # Iterate over columns to apply the per-item logic.
        for name in columns:
            lowered = name.lower()
            if key == "reactor_pressure":
                if "reactor" in lowered and ("press" in lowered or "psi" in lowered):
                    return name
            elif key == "manifold_pressure":
                if "manifold" in lowered and ("press" in lowered or "psi" in lowered):
                    return name
            elif key == "external_temp":
                if "external" in lowered and ("temp" in lowered or "temperature" in lowered):
                    return name
            elif key == "internal_temp":
                if "internal" in lowered and ("temp" in lowered or "temperature" in lowered):
                    return name
        return ""

    def _gather_mapping(self) -> Dict[str, str]:
        """Collect the current mapping selections from dialog variables.

        Purpose:
            Convert combobox selections into a normalized mapping payload.
        Why:
            Import execution and settings persistence require one canonical dict.
        Args:
            None.
        Returns:
            Dict[str, str]: Mapping key to selected CSV column name (or empty string).
        Side Effects:
            None.
        Exceptions:
            None.
        """
        mapping = {}
        # Iterate over items from self._mapping_vars to apply the per-item logic.
        for key, var in self._mapping_vars.items():
            value = (var.get() or "").strip()
            if value == "(None)":
                value = ""
            mapping[key] = value
        return mapping

    def _start_import(self) -> None:
        """Validate dialog inputs and launch asynchronous CSV import.

        Purpose:
            Start the end-to-end CSV-to-workbook conversion job.
        Why:
            Imports can be expensive; this method validates inputs up front and
            delegates heavy processing to the shared task runner.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Updates status text, toggles busy UI state, and submits a background
            task that can write rows into the target workbook.
        Exceptions:
            Validation failures show message boxes and return early; worker errors
            are surfaced through the async error callback.
        """
        if self._import_task_id is not None:
            self._set_status("Import already in progress...")
            return
        csv_path = self._csv_path_var.get().strip()
        if not csv_path or not os.path.exists(csv_path):
            messagebox.showerror("Missing CSV", "Select a valid CSV file to import.")
            return
        workbook_path = self._workbook_path_var.get().strip()
        if not workbook_path or not os.path.exists(workbook_path):
            messagebox.showerror(
                "Missing Workbook", "Select an existing Excel workbook."
            )
            return
        sheet_name_input = self._sheet_name_var.get().strip()
        if not sheet_name_input:
            messagebox.showerror("Missing Sheet Name", "Enter a sheet name.")
            return
        mapping = self._gather_mapping()
        if not mapping.get("reactor_pressure"):
            messagebox.showerror(
                "Missing Mapping", "Select a Reactor Pressure column."
            )
            return
        derivative_label = self._derivative_source_var.get()
        derivative_source = self._derivative_source_display_map.get(
            derivative_label, CSV_IMPORT_DEFAULT_DERIVATIVE_SOURCE
        )
        if (
            derivative_source == "manifold"
            and not mapping.get("manifold_pressure")
        ):
            messagebox.showerror(
                "Missing Mapping",
                "Select a Manifold Pressure column for the derivative source.",
            )
            return
        try:
            dampening_value = float(self._dampening_var.get())
        except (TypeError, ValueError):
            messagebox.showerror(
                "Invalid Value", "Enter a numeric dampening factor."
            )
            return
        if not (0.0 <= dampening_value < 1.0):
            messagebox.showerror(
                "Invalid Value",
                "Dampening factor must be between 0 and 1 (non-inclusive).",
            )
            return
        try:
            window_value = int(self._window_var.get())
        except (TypeError, ValueError):
            messagebox.showerror("Invalid Value", "Enter an integer window size.")
            return
        if window_value < 1:
            messagebox.showerror("Invalid Value", "Window size must be at least 1.")
            return

        sheet_mode_label = self._sheet_mode_var.get()
        sheet_mode = self._sheet_mode_display_map.get(
            sheet_mode_label, CSV_IMPORT_DEFAULT_SHEET_EXISTS_MODE
        )
        self._set_status("Importing CSV...")
        self._set_busy(True)

        mapping_snapshot = dict(mapping)
        dampening_snapshot = float(dampening_value)
        window_snapshot = int(window_value)
        derivative_snapshot = derivative_source
        sheet_name_snapshot = sheet_name_input
        sheet_mode_snapshot = sheet_mode

        # Closure captures _start_import state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _start_import.
        def _worker() -> Dict[str, Any]:
            """Perform worker.
            Used to keep the workflow logic localized and testable."""
            columns, rows = _parse_gl260_csv_table(csv_path)
            mapped_dt = (mapping_snapshot.get("date_time") or "").strip()
            dt_column = mapped_dt or _detect_gl260_datetime_column(columns)
            if mapped_dt and mapped_dt not in columns:
                raise ValueError(
                    f"Mapped Date & Time column '{mapped_dt}' was not found in the CSV."
                )
            if not dt_column:
                raise ValueError("Date & Time column not detected in CSV.")
            frame = pd.DataFrame(rows, columns=columns)
            output = _build_gl260_output_dataframe(
                frame,
                dt_column,
                mapping_snapshot,
                derivative_snapshot,
                dampening_snapshot,
                window_snapshot,
            )
            resolved_name = _write_gl260_output_sheet(
                workbook_path, sheet_name_snapshot, output, sheet_mode_snapshot
            )
            return {
                "sheet_name": resolved_name,
                "workbook_path": workbook_path,
                "row_count": len(output),
            }

        # Closure captures _start_import state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _start_import.
        def _on_ok(result: Dict[str, Any]) -> None:
            """Handle ok.
            Used as an event callback for ok."""
            self._import_task_id = None
            self._set_busy(False)
            sheet_name = result.get("sheet_name", "")
            row_count = result.get("row_count", 0)
            self._set_status(f"Import complete: {sheet_name} ({row_count} rows).")
            self._persist_settings(
                csv_path,
                workbook_path,
                sheet_name,
                mapping_snapshot,
                derivative_snapshot,
                dampening_snapshot,
                window_snapshot,
                sheet_mode_snapshot,
            )
            self._update_app_after_import(workbook_path, sheet_name)

        # Closure captures _start_import state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _start_import.
        def _on_err(exc: BaseException) -> None:
            """Handle err.
            Used as an event callback for err."""
            self._import_task_id = None
            self._set_busy(False)
            self._set_status(f"Import failed: {exc}")
            messagebox.showerror("CSV Import Error", f"Import failed:\n{exc}")

        self._import_task_id = self.app._task_runner.submit(
            "csv_import", _worker, _on_ok, _on_err
        )

    def _persist_settings(
        self,
        csv_path: str,
        workbook_path: str,
        sheet_name: str,
        mapping: Dict[str, str],
        derivative_source: str,
        dampening: float,
        window: int,
        sheet_mode: str,
    ) -> None:
        """Persist CSV import dialog choices to global settings storage.

        Purpose:
            Save the latest import paths/options for future sessions.
        Why:
            Reusing prior mappings and defaults reduces repetitive setup work.
        Args:
            csv_path: Source CSV path selected by the user.
            workbook_path: Destination workbook path.
            sheet_name: Final sheet name used for the import output.
            mapping: Channel-to-column mapping payload.
            derivative_source: Selected pressure source for derivative calculation.
            dampening: Exponential smoothing factor in [0, 1).
            window: Moving-average window size in rows.
            sheet_mode: Conflict behavior when the sheet already exists.
        Returns:
            None.
        Side Effects:
            Mutates `settings` keys and requests a disk save.
        Exceptions:
            Save failures are swallowed to avoid interrupting the UI workflow.
        """
        settings["csv_import_last_csv_path"] = csv_path
        settings["csv_import_last_workbook_path"] = workbook_path
        settings["csv_import_last_sheet_name"] = sheet_name
        settings["csv_import_mapping"] = dict(mapping)
        settings["csv_import_derivative_source"] = derivative_source
        settings["csv_import_smoothing_factor"] = dampening
        settings["csv_import_moving_average_window"] = window
        settings["csv_import_sheet_exists_mode"] = sheet_mode
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _update_app_after_import(self, workbook_path: str, sheet_name: str) -> None:
        """Synchronize the main app state after a successful CSV import.

        Purpose:
            Point the app at the updated workbook and refresh sheet/column context.
        Why:
            Users typically continue directly into sheet loading and stitching after
            import, so workbook/file state must be updated immediately.
        Args:
            workbook_path: Workbook that received imported data.
            sheet_name: Sheet name resolved by the import flow.
        Returns:
            None.
        Side Effects:
            Updates file-path UI, reloads sheet names, selects the imported sheet,
            persists `last_file_path`, and defaults `columns["dt"]` to
            `"Date & Time"` when unset to keep stitching ready.
        Exceptions:
            Uses best-effort guards; partial failures are ignored safely.
        """
        try:
            self.app.file_path = workbook_path
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        entry = getattr(self.app, "e_file", None)
        if entry is not None:
            try:
                entry.delete(0, tk.END)
                entry.insert(0, workbook_path)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        settings["last_file_path"] = workbook_path
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self.app._load_sheet_names()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        try:
            self.app.selected_sheet.set(sheet_name)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            columns_map = (
                self.app.columns if isinstance(getattr(self.app, "columns", None), dict) else {}
            )
            dt_value = str(columns_map.get("dt", "") or "").strip()
            if not dt_value:
                columns_map["dt"] = "Date & Time"
                self.app.columns = columns_map
                settings["columns"] = dict(columns_map)
                _save_settings_to_disk()
                if getattr(self.app, "columns_frame", None) is not None:
                    self.app._refresh_columns_ui()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _close(self) -> None:
        """Close value.
        Used by UI actions to close value safely."""
        if self._import_task_id is not None:
            messagebox.showinfo(
                "Import Running", "Please wait for the import to finish."
            )
            return
        try:
            self.window.grab_release()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self.window.destroy()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if self._on_close is not None:
            try:
                self._on_close()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass


# ----------------------------------------

# Unified Window (one UI to rule them all)

# ----------------------------------------


class UnifiedApp(tk.Tk):

    def __init__(self):
        """Initialize UnifiedApp instance.

        Purpose:
            Construct the main application window and initialize shared state.
        Why:
            Centralizes UI setup, settings wiring, and developer tooling so
            workflows share a consistent runtime configuration.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Builds Tk widgets, binds menus, seeds settings defaults, and
            configures debug/performance instrumentation.
        Exceptions:
            Initialization uses best-effort guards to avoid crashing the UI.
        """

        super().__init__()

        self._startup_loading_overlay = None
        self._startup_loading_label = None
        self._startup_loading_progress_var = None
        self._startup_loading_bar = None
        self._startup_loading_progress_label = None
        self._startup_loading_progress_value = 0.0
        self._startup_loading_poll_after_id = None
        self._startup_ui_built = False
        self._startup_plot_stage_two_ready = False
        self._startup_cycle_ready = False
        self._startup_tab_warmup_done = False
        self._startup_tab_readiness_reason = ""
        self._startup_restore_state = "pending"
        self._install_startup_loading_splash(
            message="Initializing startup...", progress=2.0
        )

        # Persisted settings wiring:
        # Prior callbacks wrote to getattr(self, "settings", {}) which returned a fresh
        # empty dict because self.settings was never set. Model selections and workflow
        # toggles were therefore not saved or restored when switching workflows/restarting.
        # Bind the shared module-level settings dict up front so all setters hit the
        # correct container and survive tab changes or app restarts.
        self.settings = settings
        self._data_lock = threading.RLock()
        self._settings_lock = threading.RLock()
        global _SETTINGS_LOCK
        _SETTINGS_LOCK = self._settings_lock

        self._registered_menus: List[tk.Menu] = []

        display_mode_default = _normalize_ui_display_mode(
            settings.get("ui_display_mode")
        )
        settings["ui_display_mode"] = display_mode_default
        self._display_mode_var = tk.StringVar(value=display_mode_default)
        self._apply_display_mode(display_mode_default, persist=False)

        self._ui_scale = 1.0
        self._initial_ui_scale = self._initialize_ui_scaling()

        self._default_font_size = 10
        base_font_size = self._resolve_base_font_size()
        self._apply_accessible_fonts(base_size=base_font_size)

        self._ui_zoom_var = tk.DoubleVar(value=self._ui_scale)

        dev_request_gil_disabled = bool(settings.get("dev_request_gil_disabled", False))
        settings["dev_request_gil_disabled"] = dev_request_gil_disabled
        dev_worker_threads = max(1, int(settings.get("dev_worker_threads", 1)))
        settings["dev_worker_threads"] = dev_worker_threads
        dev_parallel_enabled = bool(settings.get("dev_enable_parallel_compute", False))
        settings["dev_enable_parallel_compute"] = dev_parallel_enabled
        dev_disable_startup_tab_cycling = bool(
            settings.get("dev_disable_startup_tab_cycling", True)
        )
        settings["dev_disable_startup_tab_cycling"] = dev_disable_startup_tab_cycling
        self._dev_request_gil_var = tk.BooleanVar(value=dev_request_gil_disabled)
        self._dev_worker_threads_var = tk.IntVar(value=dev_worker_threads)
        self._dev_parallel_compute_var = tk.BooleanVar(value=dev_parallel_enabled)
        self._dev_disable_startup_tab_cycling_var = tk.BooleanVar(
            value=dev_disable_startup_tab_cycling
        )
        task_workers = dev_worker_threads if dev_parallel_enabled else 1
        self._task_runner = TkTaskRunner(self, max_workers=task_workers)
        self._combined_render_runner = TkTaskRunner(self, max_workers=1)
        self._core_render_task_id: Optional[int] = None
        self._combined_render_task_id: Optional[int] = None
        self._combined_render_busy = False
        self._combined_render_cursor = None
        self._perf_diag_enabled_var = tk.BooleanVar(value=False)
        self._perf_diag_dialog = None
        self._perf_diag_output = None
        self._perf_diag_last_run: Optional[Dict[str, Any]] = None
        self._perf_diag_active_run: Optional[Dict[str, Any]] = None
        self._debug_state_lock = threading.Lock()
        self._debug_enabled = bool(settings.get("debug_enabled", False))
        self._debug_categories = _normalize_debug_categories(
            settings.get("debug_categories")
        )
        self._debug_file_logging_enabled = bool(
            settings.get("debug_file_logging_enabled", False)
        )
        settings["debug_enabled"] = self._debug_enabled
        settings["debug_categories"] = dict(self._debug_categories)
        settings["debug_file_logging_enabled"] = self._debug_file_logging_enabled
        self._debug_enabled_var = tk.BooleanVar(value=self._debug_enabled)
        self._debug_file_logging_var = tk.BooleanVar(
            value=self._debug_file_logging_enabled
        )
        self._debug_category_vars = {
            name: tk.BooleanVar(value=bool(self._debug_categories.get(name, False)))
            for name in DEBUG_CATEGORIES
        }
        self._debug_once: Set[Tuple[str, Any]] = set()
        self._perf_stats: Dict[Tuple[str, str], Dict[str, float]] = {}
        self._perf_stats_lock = threading.Lock()
        self._debug_log_handler = None
        self._debug_file_handler = None
        self._perf_noop = contextlib.nullcontext()
        self._configure_debug_logging()
        self._gil_import_warning_shown = False
        self._dependency_audit_dialog = None
        self._dependency_audit_report = None
        self._free_threading_dialog = None
        self._concurrency_control_dialog = None

        self._solvent_sync_lock = False
        self._forced_slider_lock = False
        self._sol_last_structured = None
        self._sol_last_result = None
        self._sol_glossary_window = None
        self._sol_math_sections: List[Dict[str, Any]] = []
        self._sol_math_window = None
        self._sol_math_section_list = None
        self._planning_mass_lock = False
        self._sol_math_view_text = None
        self._init_solubility_styles()
        self._cycle_last_transfer_payload: Optional[Dict[str, Any]] = None
        self._cycle_marker_undo_stack: List[Dict[str, Any]] = []
        self._cycle_marker_redo_stack: List[Dict[str, Any]] = []
        self._cycle_marker_undo_lock = False
        self._final_report_cycle_snapshot: Optional[Dict[str, Any]] = None
        self._sol_cycle_payloads: Dict[str, Optional[Dict[str, Any]]] = {}
        self._sol_cycle_results_map: Dict[str, Optional[Dict[str, Any]]] = {}
        self._analysis_overlay_marker: Optional[Dict[str, Any]] = None
        self._analysis_reference_trace: Optional[Dict[str, Any]] = None
        self._analysis_progress_pct_var: Optional[tk.StringVar] = None
        self._analysis_regime_var: Optional[tk.StringVar] = None
        self._analysis_co2_g_var: Optional[tk.StringVar] = None
        self._analysis_co2_mol_var: Optional[tk.StringVar] = None
        self._analysis_mapped_ph_var: Optional[tk.StringVar] = None
        self._analysis_equivalence_pct_var: Optional[tk.StringVar] = None
        self._analysis_planning_final_co2_g_var: Optional[tk.StringVar] = None
        self._analysis_planning_completion_var: Optional[tk.StringVar] = None

        self._var_defaults = {}
        self._apply_columns_indicator_state = "idle"
        self._apply_indicator_canvases = []
        self._apply_vdw_indicator_state = "success"
        self._apply_vdw_indicator_canvases = []
        self._apply_columns_buttons = []
        self._last_applied_columns = None
        self._vdw_trace_ids = []

        # Track contamination tab preference and bind it to the menu toggle
        self._contamination_tab_title = "Contamination Calculator"
        self._contamination_tab_visible = bool(
            settings.get("show_contamination_tab", True)
        )
        if "show_contamination_tab" not in settings:
            settings["show_contamination_tab"] = self._contamination_tab_visible
        self._solubility_tab_title = "Legacy Speciation Tab"
        self._solubility_new_tab_title = "Advanced Speciation & Equilibrium Engine"
        self._solubility_tab_visible = bool(settings.get("show_solubility_tab", True))
        if "show_solubility_tab" not in settings:
            settings["show_solubility_tab"] = self._solubility_tab_visible
        self._solubility_new_tab_visible = bool(
            settings.get("show_solubility_new_tab", True)
        )
        if "show_solubility_new_tab" not in settings:
            settings["show_solubility_new_tab"] = self._solubility_new_tab_visible
        helper_pref = settings.get("sol_show_helper")
        if helper_pref is None:
            helper_pref = True
            settings["sol_show_helper"] = True
        self._sol_helper_pref_var = tk.BooleanVar(value=bool(helper_pref))
        self._sol_helper_visible = bool(helper_pref)
        model_key = settings.get("solubility_model_key", DEFAULT_SPEC_MODEL_KEY)
        available_models = {model.key for model in list_speciation_models()}
        if model_key not in available_models:
            aqion_key = "aqion_closed"
            model_key = (
                aqion_key if aqion_key in available_models else DEFAULT_SPEC_MODEL_KEY
            )
        settings["solubility_model_key"] = model_key
        self._sol_model_key = model_key
        planning_spec_key = settings.get("sol_planning_spec_model_key", model_key)
        planning_ph_key = settings.get("sol_planning_ph_model_key", planning_spec_key)
        planning_use_same = settings.get("sol_planning_use_same_model")
        if planning_use_same is None:
            planning_use_same = True
            settings["sol_planning_use_same_model"] = True
        if planning_spec_key not in available_models:
            planning_spec_key = (
                model_key if model_key in available_models else DEFAULT_SPEC_MODEL_KEY
            )
        if planning_ph_key not in available_models:
            planning_ph_key = planning_spec_key
        settings["sol_planning_spec_model_key"] = planning_spec_key
        settings["sol_planning_ph_model_key"] = planning_ph_key
        self._planning_spec_model_key = planning_spec_key
        self._planning_ph_model_key = planning_ph_key
        self._planning_use_same_model = bool(planning_use_same)
        analysis_spec_key = settings.get("sol_analysis_spec_model_key", model_key)
        analysis_ph_key = settings.get("sol_analysis_ph_model_key", analysis_spec_key)
        analysis_use_same = settings.get("sol_analysis_use_same_model")
        if analysis_use_same is None:
            analysis_use_same = True
            settings["sol_analysis_use_same_model"] = True
        if analysis_spec_key not in available_models:
            analysis_spec_key = (
                model_key if model_key in available_models else DEFAULT_SPEC_MODEL_KEY
            )
        if analysis_ph_key not in available_models:
            analysis_ph_key = analysis_spec_key
        settings["sol_analysis_spec_model_key"] = analysis_spec_key
        settings["sol_analysis_ph_model_key"] = analysis_ph_key
        self._analysis_spec_model_key = analysis_spec_key
        self._analysis_ph_model_key = analysis_ph_key
        self._analysis_use_same_model = bool(analysis_use_same)
        reprocessing_spec_key = settings.get(
            "sol_reprocessing_spec_model_key", model_key
        )
        reprocessing_ph_key = settings.get(
            "sol_reprocessing_ph_model_key", reprocessing_spec_key
        )
        reprocessing_use_same = settings.get("sol_reprocessing_use_same_model")
        if reprocessing_use_same is None:
            reprocessing_use_same = True
            settings["sol_reprocessing_use_same_model"] = True
        if reprocessing_spec_key not in available_models:
            reprocessing_spec_key = (
                model_key if model_key in available_models else DEFAULT_SPEC_MODEL_KEY
            )
        if reprocessing_ph_key not in available_models:
            reprocessing_ph_key = reprocessing_spec_key
        settings["sol_reprocessing_spec_model_key"] = reprocessing_spec_key
        settings["sol_reprocessing_ph_model_key"] = reprocessing_ph_key
        self._reprocessing_spec_model_key = reprocessing_spec_key
        self._reprocessing_ph_model_key = reprocessing_ph_key
        self._reprocessing_use_same_model = bool(reprocessing_use_same)
        default_cycle_plot_prefs = {
            "species_min": None,
            "species_max": None,
            "ph_min": None,
            "ph_max": None,
            "show_legend": False,
            "export_title": CYCLE_TIMELINE_EXPORT_DEFAULT_TITLE,
        }
        stored_cycle_plot_prefs = settings.get("cycle_plot_prefs", {})
        merged_cycle_plot_prefs = dict(default_cycle_plot_prefs)
        if isinstance(stored_cycle_plot_prefs, dict):
            merged_cycle_plot_prefs.update(
                {
                    k: stored_cycle_plot_prefs.get(k, v)
                    # Iterate to apply the per-item logic.
                    for k, v in default_cycle_plot_prefs.items()
                }
            )
        settings["cycle_plot_prefs"] = merged_cycle_plot_prefs
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._cycle_plot_prefs = merged_cycle_plot_prefs
        auto_jump_pref = settings.get("jump_to_plot_after_apply")
        if auto_jump_pref is None:
            auto_jump_pref = True
            settings["jump_to_plot_after_apply"] = True
        self._auto_jump_plot_var = tk.BooleanVar(value=bool(auto_jump_pref))
        if not isinstance(settings.get("solubility_inputs"), dict):
            settings["solubility_inputs"] = {}

        self._visible_tabs_window = None
        self._tab_layout_window = None
        self._tab_order_listbox: Optional[tk.Listbox] = None
        self._tab_order_listbox_keys: List[str] = []
        self._tab_order_up_button: Optional[ttk.Button] = None
        self._tab_order_down_button: Optional[ttk.Button] = None
        self._final_report_preview_window: Optional[tk.Toplevel] = None
        self._final_report_preview_pages: List[Dict[str, Any]] = []
        self._final_report_preview_index = 0
        raw_zoom = settings.get("final_report_preview_zoom", 100)
        try:
            zoom_pref = int(raw_zoom)
        except Exception:
            zoom_pref = 100
        self._final_report_preview_zoom_value = max(25, min(400, zoom_pref))
        self._final_report_preview_photo: Optional[tk.PhotoImage] = None
        self._final_report_preview_canvas: Optional[tk.Canvas] = None
        self._final_report_preview_nav_prev: Optional[ttk.Button] = None
        self._final_report_preview_nav_next: Optional[ttk.Button] = None
        self._final_report_preview_page_label_widget: Optional[ttk.Label] = None
        self._final_report_preview_caption_label: Optional[ttk.Label] = None
        self._final_report_preview_zoom_combo_var: Optional[tk.StringVar] = None
        self._final_report_preview_save_button: Optional[ttk.Button] = None
        self._final_report_preview_needs_initial_geometry = False
        self._final_report_preview_after_id: Optional[str] = None
        self._final_report_combined_failure_reason: Optional[str] = None
        self._combined_export_artifact: Optional[Dict[str, Any]] = None
        self._combined_plot_preview_fig: Optional[Figure] = None
        self._combined_plot_preview_window: Optional[tk.Toplevel] = None
        self._combined_plot_preview_host: Optional[ttk.Frame] = None
        self._combined_plot_preview_content: Optional[ttk.Frame] = None
        self._combined_plot_preview_overlay: Optional[tk.Frame] = None
        self._combined_plot_preview_overlay_label: Optional[ttk.Label] = None
        self._combined_plot_preview_overlay_progress_var: Optional[tk.DoubleVar] = None
        self._combined_plot_preview_overlay_progress_label: Optional[ttk.Label] = None
        self._combined_plot_preview_canvas: Optional[FigureCanvasTkAgg] = None
        self._combined_plot_preview_toolbar: Optional[NavigationToolbar2Tk] = None
        self._combined_plot_preview_resize_after_id: Optional[str] = None
        self._combined_plot_preview_task_id: Optional[int] = None
        self._combined_plot_preview_request_token = 0
        self._combined_plot_preview_progress_value = 0.0
        self._combined_plot_preview_closing = False
        self._combined_plot_state: Optional[Dict[str, Any]] = None
        self._combined_layout_state: Optional[Tuple[Any, ...]] = None
        self._combined_layout_dirty = True
        stored_combined_anchor = settings.get("combined_legend_anchor")
        if (
            isinstance(stored_combined_anchor, (list, tuple))
            and len(stored_combined_anchor) >= 2
        ):
            try:
                x0 = float(stored_combined_anchor[0])
                y0 = float(stored_combined_anchor[1])
                if -0.05 <= x0 <= 1.05 and -0.05 <= y0 <= 1.05:
                    self._combined_legend_anchor = (x0, y0)
                else:
                    self._combined_legend_anchor = None
            except Exception:
                self._combined_legend_anchor = None
        else:
            self._combined_legend_anchor = None
        stored_combined_loc = settings.get("combined_legend_loc")
        self._combined_legend_loc = (
            _normalize_legend_loc_value(stored_combined_loc)
            if self._combined_legend_anchor is not None
            else None
        )
        stored_cycle_anchor = settings.get("combined_cycle_legend_anchor")
        if (
            isinstance(stored_cycle_anchor, (list, tuple))
            and len(stored_cycle_anchor) >= 2
        ):
            try:
                cx = float(stored_cycle_anchor[0])
                cy = float(stored_cycle_anchor[1])
                if -0.05 <= cx <= 1.05 and -0.05 <= cy <= 1.05:
                    self._combined_cycle_legend_anchor = (cx, cy)
                else:
                    self._combined_cycle_legend_anchor = None
            except Exception:
                self._combined_cycle_legend_anchor = None
        else:
            self._combined_cycle_legend_anchor = None
        stored_cycle_loc = settings.get("combined_cycle_legend_loc")
        self._combined_cycle_legend_loc = (
            _normalize_legend_loc_value(stored_cycle_loc)
            if self._combined_cycle_legend_anchor is not None
            else None
        )
        stored_cycle_anchor_space = settings.get("combined_cycle_legend_anchor_space")
        if stored_cycle_anchor_space in {"figure", "axes"}:
            self._combined_cycle_legend_anchor_space = stored_cycle_anchor_space
        elif self._combined_cycle_legend_anchor is not None:
            self._combined_cycle_legend_anchor_space = "figure"
        else:
            self._combined_cycle_legend_anchor_space = None
        self._combined_legend_cid = None
        self._visible_tabs_var = tk.BooleanVar(value=self._contamination_tab_visible)
        self._solubility_visible_var = tk.BooleanVar(value=self._solubility_tab_visible)
        self._solubility_new_visible_var = tk.BooleanVar(
            value=self._solubility_new_tab_visible
        )

        # Scatter plot preferences
        scatter_enabled_default = bool(
            settings.get("scatter_enabled", DEFAULT_SCATTER_SETTINGS["enabled"])
        )
        self.scatter_enabled = tk.BooleanVar(value=scatter_enabled_default)
        self._register_var_default(self.scatter_enabled, scatter_enabled_default)
        scatter_marker_default = settings.get(
            "scatter_marker", DEFAULT_SCATTER_SETTINGS["marker"]
        )
        self.scatter_marker = tk.StringVar(value=scatter_marker_default)
        self._register_var_default(self.scatter_marker, scatter_marker_default)
        scatter_size_default = settings.get(
            "scatter_size", DEFAULT_SCATTER_SETTINGS["size"]
        )
        self.scatter_size = tk.DoubleVar(value=scatter_size_default)
        self._register_var_default(self.scatter_size, scatter_size_default)
        scatter_color_default = settings.get(
            "scatter_color", DEFAULT_SCATTER_SETTINGS["color"]
        )
        self.scatter_color = tk.StringVar(value=scatter_color_default)
        self._register_var_default(self.scatter_color, scatter_color_default)
        scatter_alpha_default = settings.get(
            "scatter_alpha", DEFAULT_SCATTER_SETTINGS["alpha"]
        )
        self.scatter_alpha = tk.DoubleVar(value=scatter_alpha_default)
        self._register_var_default(self.scatter_alpha, scatter_alpha_default)
        scatter_edgecolor_default = settings.get(
            "scatter_edgecolor", DEFAULT_SCATTER_SETTINGS["edgecolor"]
        )
        self.scatter_edgecolor = tk.StringVar(value=scatter_edgecolor_default)
        self._register_var_default(self.scatter_edgecolor, scatter_edgecolor_default)
        scatter_linewidth_default = settings.get(
            "scatter_linewidth", DEFAULT_SCATTER_SETTINGS["linewidth"]
        )
        self.scatter_linewidth = tk.DoubleVar(value=scatter_linewidth_default)
        self._register_var_default(self.scatter_linewidth, scatter_linewidth_default)
        self._scatter_pref_window = None
        self._data_columns_pref_window = None
        self._data_trace_settings_window = None
        self._combined_disable_second_refresh_var = tk.BooleanVar(
            value=bool(settings.get("combined_disable_second_refresh", False))
        )
        self._plot_render_settings_window = None
        self._per_sheet_mapping_window = None
        self._per_sheet_column_map_cache = None
        self._annotation_store = AnnotationStore(settings)
        self._annotation_renderer = AnnotationRenderer()
        self._plot_elements = settings.get("plot_elements", {})
        self._plot_annotation_controllers: Dict[str, PlotAnnotationsController] = {}
        self._plot_annotation_panels: Dict[str, AnnotationsPanel] = {}
        self._plot_element_windows: Dict[str, tk.Toplevel] = {}
        self._plot_element_editors: Dict[str, Dict[str, Any]] = {}
        self._layout_editor_windows: Dict[str, tk.Toplevel] = {}
        self._layout_editor_states: Dict[str, Dict[str, Any]] = {}
        self._plot_dirty_flags: Dict[str, Dict[str, bool]] = {}
        self._render_cache = RenderCacheManager()
        self._last_render_cache_status: Optional[str] = None
        self._cycle_manual_revision = 0
        raw_series_settings = settings.get("scatter_series", {})
        self._stored_scatter_series = self._sanitize_series_settings_dict(
            raw_series_settings
        )
        self.scatter_series_vars = {}
        self._series_label_map = {}
        self._update_scatter_globals()

        self.cycle_line_color = tk.StringVar(
            value=cycle_trace_settings.get(
                "line_color", DEFAULT_CYCLE_TRACE_SETTINGS["line_color"]
            )
        )
        self.cycle_line_style = tk.StringVar(
            value=cycle_trace_settings.get(
                "line_style", DEFAULT_CYCLE_TRACE_SETTINGS["line_style"]
            )
        )
        self.cycle_line_width = tk.DoubleVar(
            value=cycle_trace_settings.get(
                "line_width", DEFAULT_CYCLE_TRACE_SETTINGS["line_width"]
            )
        )
        self.cycle_peak_color = tk.StringVar(
            value=cycle_trace_settings.get(
                "peak_color", DEFAULT_CYCLE_TRACE_SETTINGS["peak_color"]
            )
        )
        self.cycle_trough_color = tk.StringVar(
            value=cycle_trace_settings.get(
                "trough_color", DEFAULT_CYCLE_TRACE_SETTINGS["trough_color"]
            )
        )
        self.cycle_peak_marker = tk.StringVar(
            value=cycle_trace_settings.get(
                "peak_marker", DEFAULT_CYCLE_TRACE_SETTINGS["peak_marker"]
            )
        )
        self.cycle_trough_marker = tk.StringVar(
            value=cycle_trace_settings.get(
                "trough_marker", DEFAULT_CYCLE_TRACE_SETTINGS["trough_marker"]
            )
        )
        self.cycle_marker_size = tk.DoubleVar(
            value=cycle_trace_settings.get(
                "marker_size", DEFAULT_CYCLE_TRACE_SETTINGS["marker_size"]
            )
        )
        self._cycle_trace_window = None
        sanitized_profiles = _sanitize_output_profile_dict(
            settings.get("output_size_profiles")
        )
        self._output_profiles = copy.deepcopy(sanitized_profiles)
        settings["output_size_profiles"] = copy.deepcopy(sanitized_profiles)
        initial_export_dpi = _sanitize_export_dpi_value(settings.get("export_dpi"))
        settings["export_dpi"] = initial_export_dpi
        self._export_dpi_var = tk.IntVar(value=initial_export_dpi)
        self._output_pref_window = None
        self._output_profile_form_vars: Dict[str, tk.StringVar] = {}
        self._output_profile_entries: Dict[str, Any] = {}
        self._output_profile_listbox: Optional[tk.Listbox] = None
        self._output_profile_title_var = tk.StringVar(value="")
        self._output_profile_keys = list(DEFAULT_OUTPUT_PROFILE_SETTINGS.keys())
        self._output_profile_selected = (
            self._output_profile_keys[0] if self._output_profile_keys else None
        )
        self._export_dpi_entry_var: Optional[tk.StringVar] = None
        self._profile_manager_window: Optional[tk.Toplevel] = None
        self._profile_manager_listbox: Optional[tk.Listbox] = None
        self._profile_include_path_var = tk.BooleanVar(value=True)
        self._profile_keep_plot_settings_var = tk.BooleanVar(value=True)
        self._profile_restore_pending: Optional[Dict[str, Any]] = None
        self._sol_regression_task_id: Optional[int] = None
        self._regression_dialog: Optional[tk.Toplevel] = None
        self._regression_output: Optional[scrolledtext.ScrolledText] = None
        self._regression_listbox: Optional[tk.Listbox] = None
        self._regression_status_var: Optional[tk.StringVar] = None
        self._last_plot_args: Optional[Tuple[Any, ...]] = None
        self._plot_settings_window: Optional[tk.Toplevel] = None
        self._plot_settings_target_id: Optional[str] = None
        self._plot_settings_apply_callback: Optional[Callable[..., bool]] = None
        self._plot_settings_has_pending_changes_callback: Optional[Callable[[], bool]] = (
            None
        )
        self._axis_range_pref_window: Optional[tk.Toplevel] = None
        self._font_family_window: Optional[tk.Toplevel] = None
        self._csv_import_dialog: Optional[CsvImportDialog] = None

        self._menubar = self._register_menu(tk.Menu(self))
        file_menu = self._register_menu(tk.Menu(self._menubar, tearoff=0))
        file_menu.add_command(label="Open Excel...", command=self._browse_file)
        file_menu.add_command(
            label="Rescan File", command=self._load_sheets_from_current_path
        )
        file_menu.add_command(
            label="Import GL-260 CSV...", command=self._open_csv_import_dialog
        )
        file_menu.add_separator()
        file_menu.add_command(label="Save Settings", command=self.save_settings)
        file_menu.add_command(
            label="Font Family...", command=self._open_font_family_dialog
        )
        file_menu.add_separator()

        preferences_menu = self._register_menu(tk.Menu(file_menu, tearoff=0))
        preferences_menu.add_checkbutton(
            label="Show Contamination Calculator Tab",
            variable=self._visible_tabs_var,
            command=lambda: self._set_contamination_tab_visible(
                self._visible_tabs_var.get()
            ),
        )
        preferences_menu.add_checkbutton(
            label="Show Legacy Speciation Tab",
            variable=self._solubility_visible_var,
            command=lambda: self._set_solubility_tab_visible(
                self._solubility_visible_var.get()
            ),
        )
        preferences_menu.add_checkbutton(
            label="Show Advanced Speciation & Equilibrium Engine Tab",
            variable=self._solubility_new_visible_var,
            command=lambda: self._set_solubility_new_tab_visible(
                self._solubility_new_visible_var.get()
            ),
        )
        preferences_menu.add_command(
            label="Tab Layout...",
            command=self._open_tab_layout_preferences,
        )
        preferences_menu.add_command(
            label="Data & Columns...",
            command=self._open_data_columns_settings_dialog,
        )
        preferences_menu.add_checkbutton(
            label="Show Solubility Input Helper",
            variable=self._sol_helper_pref_var,
            command=self._on_toggle_sol_helper_pref,
        )
        preferences_menu.add_checkbutton(
            label="Jump to Plot tab after Apply Column Selection",
            variable=self._auto_jump_plot_var,
            command=self._update_auto_jump_plot_pref,
        )
        display_mode_menu = self._register_menu(tk.Menu(preferences_menu, tearoff=0))
        display_mode_menu.add_radiobutton(
            label="Regular",
            variable=self._display_mode_var,
            value=DISPLAY_MODE_REGULAR,
            command=self._on_display_mode_changed,
        )
        display_mode_menu.add_radiobutton(
            label="Dark",
            variable=self._display_mode_var,
            value=DISPLAY_MODE_DARK,
            command=self._on_display_mode_changed,
        )
        preferences_menu.add_cascade(label="Display Mode", menu=display_mode_menu)
        preferences_menu.add_separator()
        preferences_menu.add_command(
            label="Scatter Plot Settings...", command=self._open_scatter_preferences
        )
        preferences_menu.add_command(
            label="Cycle Analysis Plot Settings...",
            command=self._open_cycle_trace_settings,
        )
        preferences_menu.add_command(
            label="Saved Output Options...",
            command=self._open_saved_output_preferences,
        )
        preferences_menu.add_command(
            label="Plot Settings...",
            command=self._open_plot_settings_for_active_tab,
        )
        preferences_menu.add_command(
            label="Plot Render Settings...",
            command=self._open_plot_render_settings_dialog,
        )
        preferences_menu.add_command(
            label="Axis Auto-Range Settings...",
            command=self._open_axis_range_preferences,
        )
        preferences_menu.add_separator()
        preferences_menu.add_command(
            label="Optimize Layout for Current Display...",
            command=self._optimize_for_current_display,
        )
        preferences_menu.add_command(
            label="Run Solubility Regression...",
            command=self._run_solubility_regression,
        )
        file_menu.add_cascade(label="Preferences", menu=preferences_menu)

        file_menu.add_separator()
        file_menu.add_command(label="Exit", command=self.save_and_close)
        self._menubar.add_cascade(label="File", menu=file_menu)

        view_menu = self._register_menu(tk.Menu(self._menubar, tearoff=0))
        self._build_view_menu(view_menu)
        self._menubar.add_cascade(label="View", menu=view_menu)

        profiles_menu = self._register_menu(tk.Menu(self._menubar, tearoff=0))
        profiles_menu.add_command(
            label="Manage Profiles...", command=self._open_profile_manager
        )
        self._menubar.add_cascade(label="Profiles", menu=profiles_menu)

        tools_menu = self._register_menu(tk.Menu(self._menubar, tearoff=0))
        developer_menu = self._register_menu(tk.Menu(tools_menu, tearoff=0))
        developer_menu.add_checkbutton(
            label="Enable Debug Logging",
            variable=self._debug_enabled_var,
            command=lambda: self._set_debug_enabled(self._debug_enabled_var.get()),
        )
        developer_menu.add_checkbutton(
            label="Enable Debug File Logging",
            variable=self._debug_file_logging_var,
            command=lambda: self._set_debug_file_logging_enabled(
                self._debug_file_logging_var.get()
            ),
        )
        developer_menu.add_checkbutton(
            label="Disable Startup Tab Cycling During Splash",
            variable=self._dev_disable_startup_tab_cycling_var,
            command=lambda: self._set_disable_startup_tab_cycling(
                self._dev_disable_startup_tab_cycling_var.get()
            ),
        )
        debug_categories_menu = self._register_menu(
            tk.Menu(developer_menu, tearoff=0)
        )
        # Iterate over DEBUG_CATEGORIES to apply the per-item logic.
        for category in DEBUG_CATEGORIES:
            var = self._debug_category_vars.get(category)
            if var is None:
                continue
            label = DEBUG_CATEGORY_LABELS.get(category, category)
            debug_categories_menu.add_checkbutton(
                label=label,
                variable=var,
                command=lambda key=category: self._set_debug_category_enabled(
                    key, self._debug_category_vars[key].get()
                ),
            )
        developer_menu.add_cascade(label="Debug Categories", menu=debug_categories_menu)
        developer_menu.add_command(
            label="Dump Debug Settings", command=self._dump_debug_settings
        )
        developer_menu.add_command(
            label="Clear Debug Once-Guards", command=self._clear_debug_once_guards
        )
        developer_menu.add_command(
            label="Dump Performance Stats", command=self._dump_performance_stats
        )
        developer_menu.add_separator()
        developer_menu.add_command(
            label="Free-Threading & GIL...",
            command=self._open_free_threading_dialog,
        )
        developer_menu.add_command(
            label="Dependency Free-Threading Audit...",
            command=self._open_dependency_audit_dialog,
        )
        developer_menu.add_command(
            label="Concurrency Controls...",
            command=self._open_concurrency_controls_dialog,
        )
        developer_menu.add_command(
            label="Performance Diagnostics...",
            command=self._open_performance_diagnostics_dialog,
        )
        developer_menu.add_separator()
        developer_menu.add_command(
            label="Validate Timeline Table Export (PDF/PNG)",
            command=self._run_timeline_table_export_validation,
        )
        developer_menu.add_command(
            label="Regression checks", command=self._open_regression_checks_dialog
        )
        tools_menu.add_cascade(label="Developer Tools", menu=developer_menu)
        self._menubar.add_cascade(label="Tools", menu=tools_menu)

        self.config(menu=self._menubar)
        self._apply_display_mode(self._display_mode_var.get(), persist=False)
        self._refresh_menu_fonts()

        # Start at last saved normal size (fallback to a scaled default)
        stored_geometry = settings.get("window_geometry")
        if stored_geometry and self._geometry_fits_screen(stored_geometry):
            self._last_normal_geometry = stored_geometry
        else:
            predicted_w, predicted_h = self._predict_geometry_for_scale(self._ui_scale)
            self._last_normal_geometry = f"{predicted_w}x{predicted_h}+50+50"

        self.geometry(self._last_normal_geometry)  # start in normal state at that size

        # Track the last normal geometry so it's what you get after "Restore Down"

        self.bind("<Configure>", self._remember_normal_geometry)

        self.title(
            f"GL-260 Data Analysis & Processing Engine {APP_VERSION}. Written & Maintained by Mike Moheban, M.S."
        )

        self.minsize(
            self._scale_length(1400), self._scale_length(900)
        )  # keep buttons visible on smaller displays

        # Keyboard shortcuts for adjustable UI zoom scaling
        self.bind_all("<Control-plus>", self._handle_font_increase, add="+")
        self.bind_all("<Control-KP_Add>", self._handle_font_increase, add="+")
        self.bind_all("<Control-equal>", self._handle_font_increase, add="+")
        self.bind_all("<Control-minus>", self._handle_font_decrease, add="+")
        self.bind_all("<Control-underscore>", self._handle_font_decrease, add="+")
        self.bind_all("<Control-KP_Subtract>", self._handle_font_decrease, add="+")
        self.bind_all("<Control-0>", self._handle_font_reset, add="+")
        self.bind_all("<Control-KP_0>", self._handle_font_reset, add="+")

        # State

        self.df = None

        self.file_path = None

        self.sheet_names = []

        self.selected_sheet = tk.StringVar(value=settings.get("last_sheet_name", ""))

        self.multi_sheet_enabled = bool(
            settings.get("multi_sheet_enabled", initial_multi_sheet_enabled)
        )
        raw_selected_sheets = settings.get(
            "selected_sheets", list(initial_selected_sheets)
        )
        normalized_selected_sheets: List[str] = []
        if isinstance(raw_selected_sheets, list):
            seen = set()
            # Iterate over raw_selected_sheets to apply the per-item logic.
            for item in raw_selected_sheets:
                if not isinstance(item, str):
                    continue
                name = item.strip()
                if name and name not in seen:
                    normalized_selected_sheets.append(name)
                    seen.add(name)
        self.selected_sheets = normalized_selected_sheets
        settings["multi_sheet_enabled"] = self.multi_sheet_enabled
        settings["selected_sheets"] = list(self.selected_sheets)
        self._sheet_names_loaded = False
        self.sheet_dfs = {}
        self._elapsed_time_unit = _normalize_elapsed_time_unit(
            settings.get("elapsed_time_unit")
        )
        self._stitched_x_col = "__GL260_ELAPSED_DAYS_STITCHED__"
        self._stitched_hms_col = "__GL260_ELAPSED_HMS__"
        self._stitched_dt_col = "__GL260_DATETIME__"
        self._multi_sheet_mode_var = tk.StringVar(
            value="multiple" if self.multi_sheet_enabled else "single"
        )
        self._available_sheets_listbox = None
        self._included_sheets_listbox = None

        self.columns = settings.get("columns", {})
        self._columns_schema_preview: List[str] = []
        self._columns_schema_preview_sheet: Optional[str] = None
        self._columns_schema_preview_path: Optional[str] = None

        self._columns_applied = (
            False  # only populate Cycle Analysis after explicit apply
        )
        self._is_applying_columns = False

        self.volume = settings.get("vessel_volume", initial_volume)

        self.a_const = settings.get("vdw_a", initial_a)

        self.b_const = settings.get("vdw_b", initial_b)

        # Cache numeric conversions for DataFrame columns to avoid repeated

        # pd.to_numeric work when recomputing ranges/plots.

        self._numeric_cache = {}

        # Van der Waals (use DoubleVars so changes auto-propagate)

        self.v_volume = tk.DoubleVar(
            value=settings.get("vessel_volume", initial_volume)
        )

        self.v_a = tk.DoubleVar(value=settings.get("vdw_a", initial_a))

        self.v_b = tk.DoubleVar(value=settings.get("vdw_b", initial_b))

        product_preset = settings.get(
            "starting_material_preset",
            settings.get("product_preset", initial_starting_material_preset),
        )

        if product_preset not in PRODUCT_PRESETS:

            product_preset = next(iter(PRODUCT_PRESETS))

        self.v_product_preset = tk.StringVar(value=product_preset)

        preset_info = PRODUCT_PRESETS.get(product_preset) or {}

        if "starting_material_formula" not in settings:
            settings["starting_material_formula"] = DEFAULT_STARTING_MATERIAL_FORMULA

        if preset_info:

            default_product_name = preset_info.get(
                "name", DEFAULT_STARTING_MATERIAL_NAME
            )

            default_product_molar_mass = preset_info.get(
                "molar_mass", DEFAULT_STARTING_MATERIAL_MOLAR_MASS
            )

        else:

            default_product_name = initial_starting_material_name

            default_product_molar_mass = initial_starting_material_mw

        stored_product_name = settings.get(
            "starting_material_name", initial_starting_material_name
        )

        stored_product_molar_mass = settings.get(
            "starting_material_mw_g_mol", initial_starting_material_mw
        )

        self.v_product_name = tk.StringVar(
            value=default_product_name if preset_info else stored_product_name
        )

        stored_display_name = settings.get(
            "starting_material_display_name", initial_starting_material_display_name
        )
        if not stored_display_name:
            stored_display_name = settings.get(
                "starting_material_name", initial_starting_material_name
            )

        stored_display_note = settings.get(
            "starting_material_display_note", initial_starting_material_display_note
        )

        self.v_starting_material_display_name = tk.StringVar(
            value=stored_display_name
        )
        self.v_starting_material_display_note = tk.StringVar(
            value=stored_display_note
        )

        self.v_product_molar_mass = tk.DoubleVar(
            value=(
                default_product_molar_mass if preset_info else stored_product_molar_mass
            )
        )

        self.v_starting_mass = tk.DoubleVar(
            value=settings.get("starting_material_mass_g", initial_starting_mass)
        )

        self.v_starting_stoich = tk.DoubleVar(
            value=settings.get(
                "stoich_mol_gas_per_mol_starting", initial_starting_stoich
            )
        )

        self.v_gas_molar_mass = tk.DoubleVar(
            value=settings.get("vdw_gas_molar_mass", initial_gas_molar_mass)
        )

        self._gas_preset_overrides = {
            key: dict(value) if isinstance(value, dict) else {}
            # Iterate to apply the per-item logic.
            for key, value in initial_gas_preset_overrides.items()
        }

        self.v_gas = tk.StringVar(value=settings.get("vdw_gas", "Custom"))
        self._refresh_gas_preset_choices()
        self._bind_vdw_dirty_traces()

        # Plot settings state (seed from loaded settings / defaults)

        min_time_default = settings.get("min_time", initial_min)
        self.min_time = tk.DoubleVar(value=min_time_default)
        self._register_var_default(self.min_time, min_time_default)

        max_time_default = settings.get("max_time", initial_max)
        self.max_time = tk.DoubleVar(value=max_time_default)
        self._register_var_default(self.max_time, max_time_default)

        min_y_default = settings.get("min_y", initial_y_min)
        self.min_y = tk.DoubleVar(value=min_y_default)
        self._register_var_default(self.min_y, min_y_default)

        max_y_default = settings.get("max_y", initial_y_max)
        self.max_y = tk.DoubleVar(value=max_y_default)
        self._register_var_default(self.max_y, max_y_default)

        twin_y_min_default = settings.get("twin_y_min", initial_twin_y_min)
        self.twin_y_min = tk.DoubleVar(value=twin_y_min_default)
        self._register_var_default(self.twin_y_min, twin_y_min_default)

        twin_y_max_default = settings.get("twin_y_max", initial_twin_y_max)
        self.twin_y_max = tk.DoubleVar(value=twin_y_max_default)
        self._register_var_default(self.twin_y_max, twin_y_max_default)

        deriv_y_min_default = settings.get("deriv_y_min", initial_deriv_y_min)
        self.deriv_y_min = tk.DoubleVar(value=deriv_y_min_default)
        self._register_var_default(self.deriv_y_min, deriv_y_min_default)

        deriv_y_max_default = settings.get("deriv_y_max", initial_deriv_y_max)
        self.deriv_y_max = tk.DoubleVar(value=deriv_y_max_default)
        self._register_var_default(self.deriv_y_max, deriv_y_max_default)

        auto_time_default = settings.get("auto_time_ticks", initial_auto_time_ticks)
        self.auto_time_ticks = tk.BooleanVar(value=auto_time_default)
        self._register_var_default(self.auto_time_ticks, auto_time_default)

        auto_y_default = settings.get("auto_y_ticks", initial_auto_y_ticks)
        self.auto_y_ticks = tk.BooleanVar(value=auto_y_default)
        self._register_var_default(self.auto_y_ticks, auto_y_default)

        auto_temp_default = settings.get("auto_temp_ticks", initial_auto_temp_ticks)
        self.auto_temp_ticks = tk.BooleanVar(value=auto_temp_default)
        self._register_var_default(self.auto_temp_ticks, auto_temp_default)

        auto_deriv_default = settings.get("auto_deriv_ticks", initial_auto_deriv_ticks)
        self.auto_deriv_ticks = tk.BooleanVar(value=auto_deriv_default)
        self._register_var_default(self.auto_deriv_ticks, auto_deriv_default)

        self._pending_cycle_tab_focus = False
        self._cycle_focus_after_id = None

        # Figure 3 legend option (Cycle tab)

        self.include_moles_legend = tk.BooleanVar(
            value=settings.get("include_moles_legend", initial_include_moles_legend)
        )
        show_cycle_markers_default = settings.get(
            "show_cycle_markers_on_core_plots",
            initial_show_cycle_markers_on_core,
        )
        self.show_cycle_markers_on_core = tk.BooleanVar(
            value=show_cycle_markers_default
        )
        self._register_var_default(
            self.show_cycle_markers_on_core, show_cycle_markers_default
        )
        show_cycle_legend_default = settings.get(
            "show_cycle_legend_on_core_plots", initial_show_cycle_legend_on_core
        )
        self.show_cycle_legend_on_core = tk.BooleanVar(
            value=show_cycle_legend_default
        )
        self._register_var_default(
            self.show_cycle_legend_on_core, show_cycle_legend_default
        )
        include_moles_default = settings.get(
            "include_moles_in_core_plot_legend",
            initial_include_moles_core_legend,
        )
        self.include_moles_core_legend = tk.BooleanVar(
            value=include_moles_default
        )
        self._register_var_default(
            self.include_moles_core_legend, include_moles_default
        )
        self.core_legend_fontsize = tk.DoubleVar(
            value=initial_core_legend_fontsize
        )
        self.core_cycle_legend_fontsize = tk.DoubleVar(
            value=initial_core_cycle_legend_fontsize
        )

        (
            left_key,
            right_key,
            third_key,
        ) = self._sanitize_combined_axis_keys(
            settings.get("combined_y_left_key", initial_combined_left_key),
            settings.get("combined_y_right_key", initial_combined_right_key),
            settings.get("combined_y_third_key", initial_combined_third_key),
        )
        self.combined_y_left_key = tk.StringVar(value=left_key)
        self._register_var_default(self.combined_y_left_key, left_key)
        self.combined_y_right_key = tk.StringVar(value=right_key)
        self._register_var_default(self.combined_y_right_key, right_key)
        self.combined_y_third_key = tk.StringVar(value=third_key)
        self._register_var_default(self.combined_y_third_key, third_key)
        self._combined_left_display_var = tk.StringVar()
        self._combined_right_display_var = tk.StringVar()
        self._combined_third_display_var = tk.StringVar()
        self._combined_axis_last_values = {
            "left": left_key,
            "right": right_key,
            "third": third_key,
        }
        self._combined_legend_cid = None
        self._combined_axis_display_map: Dict[str, str] = {}

        self.auto_detect_cycles = tk.BooleanVar(
            value=settings.get("cycle_auto_detect_enabled", True)
        )

        self.cycle_temp_column = tk.StringVar(
            value=settings.get("cycle_temp_column", CYCLE_TEMP_DEFAULT_LABEL)
        )
        self._requested_cycle_temp_column = self.cycle_temp_column.get()

        self._cycle_temp_combo = None
        self._gas_combo = None

        self.summary_compact = tk.BooleanVar()
        self._bind_setting_var(
            self.summary_compact,
            "summary_compact",
            default=initial_summary_compact,
            on_change=self._on_cycle_summary_formatting_changed,
        )
        self.summary_include_diagnostics = tk.BooleanVar()
        self._bind_setting_var(
            self.summary_include_diagnostics,
            "summary_include_diagnostics",
            default=initial_summary_include_diagnostics,
            on_change=self._on_cycle_summary_formatting_changed,
        )
        self.summary_include_per_cycle_gas_mass = tk.BooleanVar()
        self._bind_setting_var(
            self.summary_include_per_cycle_gas_mass,
            "summary_include_per_cycle_gas_mass",
            default=initial_summary_include_per_cycle_gas_mass,
            on_change=self._on_cycle_summary_formatting_changed,
        )
        self.summary_include_conversion_estimate = tk.BooleanVar()
        self._bind_setting_var(
            self.summary_include_conversion_estimate,
            "summary_include_conversion_estimate",
            default=initial_summary_include_conversion_estimate,
            on_change=self._on_cycle_summary_formatting_changed,
        )
        self._cycle_summary_conversion_status = tk.StringVar(value="")
        self._summary_include_conversion_chk = None

        # When True, suppress automatic regeneration of Figure 3 from cycle recomputes

        self._suspend_cycle_fig3_refresh = False

        # Track pending Figure 3 refresh requests (populated by the Cycle tab buttons)

        self._pending_fig3_update = None
        self._pending_cycle_recompute = None

        self._cycle_placeholder_indicator = None

        # Background worker handle for Apply Column Selection

        self._apply_columns_task_id = None

        # Tracks whether the most recent cycle analysis used automated detection
        self._cycle_last_auto_detect = False

        # When True, skip the automatic cycle analysis that normally runs on column apply

        self._suspend_cycle_autorun = False

        xmaj_default = settings.get("x_major_tick", initial_xmaj_tick)
        self.xmaj_tick = tk.DoubleVar(value=xmaj_default)
        self._register_var_default(self.xmaj_tick, xmaj_default)

        xmin_default = settings.get("x_minor_tick", initial_xmin_tick)
        self.xmin_tick = tk.DoubleVar(value=xmin_default)
        self._register_var_default(self.xmin_tick, xmin_default)

        ymaj_default = settings.get("y_major_tick", initial_ymaj_tick)
        self.ymaj_tick = tk.DoubleVar(value=ymaj_default)
        self._register_var_default(self.ymaj_tick, ymaj_default)

        ymin_default = settings.get("y_minor_tick", initial_ymin_tick)
        self.ymin_tick = tk.DoubleVar(value=ymin_default)
        self._register_var_default(self.ymin_tick, ymin_default)

        temp_maj_default = settings.get("temp_major_tick", initial_temp_maj_tick)
        self.temp_maj_tick = tk.DoubleVar(value=temp_maj_default)
        self._register_var_default(self.temp_maj_tick, temp_maj_default)

        temp_min_default = settings.get("temp_minor_tick", initial_temp_min_tick)
        self.temp_min_tick = tk.DoubleVar(value=temp_min_default)
        self._register_var_default(self.temp_min_tick, temp_min_default)

        deriv_maj_default = settings.get("deriv_major_tick", initial_deriv_maj_tick)
        self.deriv_maj_tick = tk.DoubleVar(value=deriv_maj_default)
        self._register_var_default(self.deriv_maj_tick, deriv_maj_default)

        deriv_min_default = settings.get("deriv_minor_tick", initial_deriv_min_tick)
        self.deriv_min_tick = tk.DoubleVar(value=deriv_min_default)
        self._register_var_default(self.deriv_min_tick, deriv_min_default)

        enable_temp_default = settings.get(
            "enable_temp_axis", initial_enable_temp_axis
        )
        self.enable_temp_axis = tk.BooleanVar(value=enable_temp_default)
        self._register_var_default(self.enable_temp_axis, enable_temp_default)

        enable_deriv_default = settings.get(
            "enable_deriv_axis", initial_enable_deriv_axis
        )
        self.enable_deriv_axis = tk.BooleanVar(value=enable_deriv_default)
        self._register_var_default(self.enable_deriv_axis, enable_deriv_default)

        self.combined_deriv_axis_offset = tk.DoubleVar(
            value=initial_combined_deriv_axis_offset
        )

        self.combined_primary_axis_label = tk.StringVar(
            value=initial_combined_primary_axis_label
        )
        self.combined_deriv_axis_label = tk.StringVar(
            value=initial_combined_deriv_axis_label
        )
        self.combined_temp_axis_label = tk.StringVar(
            value=initial_combined_temp_axis_label
        )
        self.combined_x_axis_label = tk.StringVar(value=initial_combined_x_axis_label)
        self.combined_primary_labelpad = tk.DoubleVar(
            value=initial_combined_primary_labelpad
        )
        self.combined_temp_labelpad = tk.DoubleVar(value=initial_combined_temp_labelpad)
        self.combined_deriv_labelpad = tk.DoubleVar(
            value=initial_combined_deriv_labelpad
        )
        self.combined_left_padding_pct = tk.DoubleVar(
            value=initial_combined_left_pad_pct
        )
        self.combined_right_padding_pct = tk.DoubleVar(
            value=initial_combined_right_pad_pct
        )
        self.combined_export_pad_pts = tk.DoubleVar(
            value=initial_combined_export_pad_pts
        )
        self.combined_title_pad_pts = tk.DoubleVar(value=initial_combined_title_pad_pts)
        self.combined_suptitle_pad_pts = tk.DoubleVar(
            value=initial_combined_suptitle_pad_pts
        )
        self.combined_suptitle_y = tk.DoubleVar(value=initial_combined_suptitle_y)
        self.combined_top_margin_pct = tk.DoubleVar(
            value=initial_combined_top_margin_pct
        )
        self.combined_suptitle_fontsize = tk.DoubleVar(
            value=initial_combined_suptitle_fontsize
        )
        self.combined_title_fontsize = tk.DoubleVar(
            value=initial_combined_title_fontsize
        )
        self.combined_label_fontsize = tk.DoubleVar(
            value=initial_combined_label_fontsize
        )
        self.combined_tick_fontsize = tk.DoubleVar(value=initial_combined_tick_fontsize)
        self.combined_legend_fontsize = tk.DoubleVar(
            value=initial_combined_legend_fontsize
        )
        self.combined_cycle_legend_fontsize = tk.DoubleVar(
            value=initial_combined_cycle_legend_fontsize
        )
        self.combined_font_family = tk.StringVar(value=initial_combined_font_family)
        self.combined_legend_wrap = tk.BooleanVar(value=initial_combined_legend_wrap)
        self._register_var_default(
            self.combined_legend_wrap, initial_combined_legend_wrap
        )
        self.combined_legend_rows = tk.IntVar(value=initial_combined_legend_rows)
        self.combined_legend_label_gap = tk.DoubleVar(
            value=initial_combined_legend_gap_pts
        )
        self.combined_xlabel_tick_gap = tk.DoubleVar(
            value=initial_combined_xlabel_tick_gap_pts
        )
        self.combined_legend_bottom_margin = tk.DoubleVar(
            value=initial_combined_legend_margin_pts
        )
        self.combined_legend_alignment = tk.StringVar(
            value=initial_combined_legend_alignment
        )
        self.combined_legend_shadowbox_fill_color = tk.StringVar(
            value=initial_combined_legend_shadowbox_fill_color
        )
        self.combined_cycle_legend_loc_choice = tk.StringVar(
            value=initial_combined_cycle_legend_loc_choice
        )
        self.combined_cycle_legend_ref_axis = tk.StringVar(
            value=initial_combined_cycle_legend_ref_axis
        )
        self.combined_cycle_legend_ref_corner = tk.StringVar(
            value=initial_combined_cycle_legend_ref_corner
        )
        self.center_combined_plot_legend = tk.BooleanVar(
            value=initial_combined_center_plot_legend
        )
        self._register_var_default(
            self.center_combined_plot_legend, initial_combined_center_plot_legend
        )
        self.combined_cycle_legend_enable_drag = tk.BooleanVar(
            value=initial_combined_cycle_legend_enable_drag
        )
        self.combined_cycle_legend_lock_position = tk.BooleanVar(
            value=initial_combined_cycle_legend_lock_position
        )
        self.combined_cycle_legend_persist_position = tk.BooleanVar(
            value=initial_combined_cycle_legend_persist_position
        )
        self.combined_cycle_legend_clamp_to_axes = tk.BooleanVar(
            value=initial_combined_cycle_legend_clamp_to_axes
        )
        self.combined_main_legend_enable_drag = tk.BooleanVar(
            value=initial_combined_main_legend_enable_drag
        )

        self._register_var_default(
            self.combined_primary_labelpad, initial_combined_primary_labelpad
        )
        self._register_var_default(
            self.combined_temp_labelpad, initial_combined_temp_labelpad
        )
        self._register_var_default(
            self.combined_deriv_labelpad, initial_combined_deriv_labelpad
        )
        self._register_var_default(
            self.combined_left_padding_pct, initial_combined_left_pad_pct
        )
        self._register_var_default(
            self.combined_right_padding_pct, initial_combined_right_pad_pct
        )
        self._register_var_default(
            self.combined_export_pad_pts, initial_combined_export_pad_pts
        )
        self._register_var_default(
            self.combined_title_pad_pts, initial_combined_title_pad_pts
        )
        self._register_var_default(
            self.combined_suptitle_pad_pts, initial_combined_suptitle_pad_pts
        )
        self._register_var_default(
            self.combined_suptitle_y, initial_combined_suptitle_y
        )
        self._register_var_default(
            self.combined_top_margin_pct, initial_combined_top_margin_pct
        )
        self._register_var_default(
            self.combined_suptitle_fontsize, initial_combined_suptitle_fontsize
        )
        self._register_var_default(
            self.combined_title_fontsize, initial_combined_title_fontsize
        )
        self._register_var_default(
            self.combined_label_fontsize, initial_combined_label_fontsize
        )
        self._register_var_default(
            self.combined_tick_fontsize, initial_combined_tick_fontsize
        )
        self._register_var_default(
            self.combined_legend_fontsize, initial_combined_legend_fontsize
        )
        self._register_var_default(
            self.combined_cycle_legend_fontsize, initial_combined_cycle_legend_fontsize
        )
        self._register_var_default(
            self.combined_font_family, initial_combined_font_family
        )
        self._register_var_default(
            self.core_legend_fontsize, initial_core_legend_fontsize
        )
        self._register_var_default(
            self.core_cycle_legend_fontsize, initial_core_cycle_legend_fontsize
        )
        self._register_var_default(
            self.combined_legend_rows, initial_combined_legend_rows
        )
        self._register_var_default(
            self.combined_legend_label_gap, initial_combined_legend_gap_pts
        )
        self._register_var_default(
            self.combined_xlabel_tick_gap, initial_combined_xlabel_tick_gap_pts
        )
        self._register_var_default(
            self.combined_legend_bottom_margin, initial_combined_legend_margin_pts
        )
        self._register_var_default(
            self.combined_legend_alignment, initial_combined_legend_alignment
        )
        self._register_var_default(
            self.combined_legend_shadowbox_fill_color,
            initial_combined_legend_shadowbox_fill_color,
        )
        self._register_var_default(
            self.combined_cycle_legend_loc_choice,
            initial_combined_cycle_legend_loc_choice,
        )
        self._register_var_default(
            self.combined_cycle_legend_ref_axis,
            initial_combined_cycle_legend_ref_axis,
        )
        self._register_var_default(
            self.combined_cycle_legend_ref_corner,
            initial_combined_cycle_legend_ref_corner,
        )
        self._register_var_default(
            self.combined_cycle_legend_enable_drag,
            initial_combined_cycle_legend_enable_drag,
        )
        self._register_var_default(
            self.combined_cycle_legend_lock_position,
            initial_combined_cycle_legend_lock_position,
        )
        self._register_var_default(
            self.combined_cycle_legend_persist_position,
            initial_combined_cycle_legend_persist_position,
        )
        self._register_var_default(
            self.combined_cycle_legend_clamp_to_axes,
            initial_combined_cycle_legend_clamp_to_axes,
        )
        self._register_var_default(
            self.combined_main_legend_enable_drag,
            initial_combined_main_legend_enable_drag,
        )

        title_default = settings.get("title_text", initial_title)
        self.title_text = tk.StringVar(value=title_default)
        self._register_var_default(self.title_text, title_default)

        suptitle_default = settings.get("suptitle_text", initial_suptitle)
        self.suptitle_text = tk.StringVar(value=suptitle_default)
        self._register_var_default(self.suptitle_text, suptitle_default)

        self.auto_title_enabled_var = tk.BooleanVar(
            value=initial_auto_title_enabled
        )
        self.auto_title_source_var = tk.StringVar(value=initial_auto_title_source)
        self.auto_title_template_var = tk.StringVar(
            value=initial_auto_title_template
        )
        self.auto_title_day_mode_var = tk.StringVar(
            value=initial_auto_title_day_mode
        )
        self.title_data_type_var = tk.StringVar(value=initial_title_selected_type)
        self._auto_title_preview_var = tk.StringVar(value="")
        self._auto_title_warning_cache: Set[str] = set()
        self._auto_title_view_cache: Dict[Any, Any] = {}

        min_cycle_default = settings.get("min_cycle_drop", initial_min_cycle_drop)
        self.min_cycle_drop = tk.DoubleVar(value=min_cycle_default)
        self._register_var_default(self.min_cycle_drop, min_cycle_default)

        # Peak/Trough detection (TkVars)

        pk_prom_default = settings.get("peak_prominence", initial_peak_prominence)
        self.pk_prominence = tk.DoubleVar(value=pk_prom_default)
        self._register_var_default(self.pk_prominence, pk_prom_default)

        pk_dist_default = settings.get("peak_distance", initial_peak_distance)
        self.pk_distance = tk.IntVar(value=pk_dist_default)
        self._register_var_default(self.pk_distance, pk_dist_default)

        pk_width_default = settings.get("peak_width", initial_peak_width)
        self.pk_width = tk.IntVar(value=pk_width_default)
        self._register_var_default(self.pk_width, pk_width_default)

        # Span padding percent (applies to Y axes)

        axis_pad_default = settings.get("axis_pad_pct", 5.0)
        self.axis_pad_pct = tk.DoubleVar(value=axis_pad_default)
        self._register_var_default(self.axis_pad_pct, axis_pad_default)

        axis_auto_defaults = _sanitize_axis_auto_range_settings(
            settings.get("axis_auto_range")
        )
        settings["axis_auto_range"] = dict(axis_auto_defaults)
        self.axis_auto_time = tk.BooleanVar(value=axis_auto_defaults["time"])
        self.axis_auto_pressure = tk.BooleanVar(value=axis_auto_defaults["pressure"])
        self.axis_auto_temp = tk.BooleanVar(value=axis_auto_defaults["temperature"])
        self.axis_auto_deriv = tk.BooleanVar(value=axis_auto_defaults["derivative"])
        self._register_var_default(self.axis_auto_time, axis_auto_defaults["time"])
        self._register_var_default(
            self.axis_auto_pressure, axis_auto_defaults["pressure"]
        )
        self._register_var_default(self.axis_auto_temp, axis_auto_defaults["temperature"])
        self._register_var_default(
            self.axis_auto_deriv, axis_auto_defaults["derivative"]
        )

        self._register_var_default(
            self.combined_deriv_axis_offset, initial_combined_deriv_axis_offset
        )

        # NEW: cache any previously saved manual marker edits (needed before building tabs)

        self._preload_cycle_markers = {
            "add_peaks": settings.get("cycle_manual_add_peaks", []),
            "add_troughs": settings.get("cycle_manual_add_troughs", []),
            "rm_peaks": settings.get("cycle_manual_remove_peaks", []),
            "rm_troughs": settings.get("cycle_manual_remove_troughs", []),
        }

        # Persisted legend anchor for Cycle Analysis (axes fraction coords)

        _anchor = settings.get("cycle_legend_anchor")

        self._cycle_legend_anchor = (
            tuple(_anchor)
            if isinstance(_anchor, (list, tuple)) and len(_anchor) == 2
            else None
        )

        self._cycle_legend_obj = None

        # Background worker coordination for cycle analysis

        self._cycle_job_lock = threading.Lock()

        self._cycle_job_counter = 0

        self._cycle_active_job = 0

        # Startup restoration task handle

        self._startup_restore_task_id = None

        self._startup_restore_path = None

        # Cached cycle markers state
        self._cached_cycle_markers = initial_cached_markers
        self._preloaded_cycle_markers = None
        self._markers_seeded_from_cache = False

        # Cycle tab build helpers
        self._cycle_build_gen = None
        self._cycle_loading_frame = None
        self._cycle_loading_label = None
        self._cycle_build_ctx = {}
        self._cycle_loading_active = False
        self._cycle_loading_after = None
        self._cycle_loading_bar = None
        self._cycle_placeholder_default_text = ""
        self._cycle_tab_added = False

        # Build UI

        self._update_startup_loading_splash_progress(
            progress=12.0,
            message="Building application interface...",
        )
        self._build_ui()

        fig1_var = getattr(self, "_plot_select_fig1_var", None)
        if fig1_var is not None:
            self._register_var_default(fig1_var, bool(fig1_var.get()))
        fig2_var = getattr(self, "_plot_select_fig2_var", None)
        if fig2_var is not None:
            self._register_var_default(fig2_var, bool(fig2_var.get()))
        combined_var = getattr(self, "_plot_select_combined_var", None)
        if combined_var is not None:
            self._register_var_default(combined_var, bool(combined_var.get()))

        self._startup_profile_plot_settings = (
            self._capture_startup_profile_plot_settings()
        )

        self._initial_tab_shown = False
        self._initial_tab_after_id = None
        self._initial_tab_map_bind_id = None

        try:
            self.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:
            self._initial_tab_after_id = self.after(
                200, self._ensure_initial_data_tab_visible
            )
        except Exception:
            self._initial_tab_after_id = None

        try:
            self._initial_tab_map_bind_id = self.bind(
                "<Map>", self._ensure_initial_data_tab_visible, add="+"
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            self._initial_tab_map_bind_id = None

        # Allow plotting functions to push summary text here

        globals()["update_cycle_summary_callback"] = self._set_cycle_summary_text

        self._pending_cycle_summary = "No cycle analysis available yet."

        self.protocol("WM_DELETE_WINDOW", self.save_and_close)

        if _SCIPY_IMPORT_ERROR is not None:

            self.after(
                250,
                lambda: _warn_missing_scipy(
                    "cycle analysis and Van der Waals calculations",
                    parent=self,
                    kind="warning",
                ),
            )

        # Kick off last-session restoration without blocking the window from showing

        self._mark_startup_restore_state("pending")
        self.after(200, self._restore_last_session_async)
        self.after(400, self._maybe_warn_gil_reenabled_import)
        try:
            self._startup_loading_poll_after_id = self.after(
                120, self._poll_startup_loading_completion
            )
        except Exception:
            self._startup_loading_poll_after_id = None

        if _SETTINGS_LOAD_ERROR is not None:

            # Closure captures __init__ local context to keep helper logic scoped and invoked directly within __init__.
            def _notify_settings_reset():
                """Perform notify settings reset.
                Used to keep the workflow logic localized and testable."""

                error_text = str(_SETTINGS_LOAD_ERROR)

                lines = [
                    "Saved settings could not be loaded. Defaults were used for this session.",
                    f"Details: {error_text}",
                ]

                if _SETTINGS_BACKUP_PATH:

                    backup_path = os.path.abspath(_SETTINGS_BACKUP_PATH)

                    lines.append(f"Backup saved to: {backup_path}")

                messagebox.showwarning("Settings Reset", "\n".join(lines), parent=self)

            self.after(300, _notify_settings_reset)

    @property
    def root(self) -> Self:
        """Return the Tk root for UI helpers.

        Purpose:
            Provide a stable root alias for helper utilities that expect self.root.
        Why:
            Some shared UI helpers are written to reference a root attribute, so this
            property keeps those helpers compatible without changing their logic.
        Inputs:
            None.
        Outputs:
            The UnifiedApp instance (Tk root).
        Side Effects:
            None.
        Exceptions:
            None.
        """
        return self

    def _with_loading_cursor(self, fn, *, widget=None):
        """Run a function with a loading cursor and temporarily disabled UI controls.

        Purpose:
            Wrap render work so the cursor and control states reflect in-progress work.
        Why:
            Ensures the cursor is visible before heavy rendering begins and provides
            explicit feedback while the deferred render completes.
        Inputs:
            fn: Callable to execute once the UI is idle.
            widget: Optional Tk widget to scope the cursor change (defaults to root).
        Outputs:
            None.
        Side Effects:
            Disables render controls, sets a watch cursor, schedules fn on idle, and
            restores cursor/control state afterward.
        Exceptions:
            Cursor update failures are swallowed; controls are restored in a finally.
        """
        root = self.root
        w = widget if widget is not None else root
        prev = w.cget("cursor") if "cursor" in w.keys() else ""

        def _run():
            try:
                fn()
            finally:
                try:
                    w.configure(cursor=prev)
                except Exception:
                    pass
                self._set_render_controls_enabled(True)

        try:
            w.configure(cursor="watch")
        except Exception:
            pass

        self._set_render_controls_enabled(False)
        root.update_idletasks()
        root.after_idle(_run)

    def _set_render_controls_enabled(self, enabled: bool) -> None:
        """Enable or disable render-related UI controls.

        Purpose:
            Temporarily lock render controls during combined plot rendering.
        Why:
            Disabling controls prevents overlapping render requests and ensures
            loading feedback remains consistent.
        Inputs:
            enabled: True to enable controls, False to disable them.
        Outputs:
            None.
        Side Effects:
            Updates widget state for render-related controls and tracks what was
            disabled so pre-disabled controls are restored accurately.
        Exceptions:
            Widget lookup and state changes are guarded to avoid UI interruption.
        """
        enabled = bool(enabled)
        if enabled:
            disabled_controls = list(
                getattr(self, "_render_controls_disabled", []) or []
            )
            self._render_controls_disabled = []
            # Iterate over disabled_controls to restore only what we changed.
            for widget in disabled_controls:
                try:
                    if widget is None or not widget.winfo_exists():
                        continue
                except Exception:
                    continue
                try:
                    if hasattr(widget, "state"):
                        widget.state(["!disabled"])
                    else:
                        widget.configure(state="normal")
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass
            return

        controls: list[Any] = []
        generate_btn = getattr(self, "_plot_select_generate_btn", None)
        if generate_btn is not None:
            controls.append(generate_btn)

        tabs = list(getattr(self, "_plot_tabs", []) or [])
        seen_controls: set[int] = set()
        for tab in tabs:
            if getattr(tab, "_plot_key", None) != "fig_combined" and getattr(
                tab, "_plot_id", None
            ) != "fig_combined_triple_axis":
                continue
            pending = []
            try:
                pending = list(tab.winfo_children())
            except Exception:
                pending = []
            # Walk tab descendants to capture toolbar buttons and toggles.
            while pending:
                widget = pending.pop()
                try:
                    pending.extend(widget.winfo_children())
                except Exception:
                    pass
                if not isinstance(
                    widget,
                    (
                        ttk.Button,
                        ttk.Checkbutton,
                        ttk.Radiobutton,
                        tk.Button,
                        tk.Checkbutton,
                        tk.Radiobutton,
                    ),
                ):
                    continue
                widget_id = id(widget)
                if widget_id in seen_controls:
                    continue
                seen_controls.add(widget_id)
                controls.append(widget)
            break

        disabled_controls = []
        # Iterate over controls to disable only those currently enabled.
        for widget in controls:
            try:
                if widget is None or not widget.winfo_exists():
                    continue
            except Exception:
                continue
            is_disabled = False
            try:
                if hasattr(widget, "instate"):
                    is_disabled = bool(widget.instate(["disabled"]))
                else:
                    is_disabled = str(widget.cget("state")) == "disabled"
            except Exception:
                is_disabled = False
            if is_disabled:
                continue
            try:
                if hasattr(widget, "state"):
                    widget.state(["disabled"])
                else:
                    widget.configure(state="disabled")
                disabled_controls.append(widget)
            except Exception:
                # Best-effort guard; ignore failures.
                pass
        self._render_controls_disabled = disabled_controls

    def _set_combined_render_busy(self, busy: bool) -> None:
        """Set combined render busy state.
        Purpose: Apply a lightweight UI busy indicator during combined plot renders.
        Why: Combined renders run async, so the UI needs safe re-entry blocking and feedback.
        Inputs: busy (bool) to mark busy or clear busy state.
        Outputs: None.
        Side effects: Updates combined render state, cursor, and Generate Plot button state.
        Exceptions: Marshals to the Tk thread if called off-thread; guards widget updates.
        """
        if threading.current_thread() is not threading.main_thread():
            # Marshal to the Tk thread to avoid cross-thread widget access.
            try:
                self.after(0, self._set_combined_render_busy, busy)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        busy = bool(busy)
        self._combined_render_busy = busy

        state = "disabled" if busy else "normal"
        generate_btn = getattr(self, "_plot_select_generate_btn", None)
        if generate_btn is not None:
            try:
                generate_btn.configure(state=state)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if busy:
            if self._combined_render_cursor is None:
                try:
                    self._combined_render_cursor = self.cget("cursor")
                except Exception:
                    self._combined_render_cursor = None
            try:
                self.configure(cursor="watch")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        try:
            cursor = self._combined_render_cursor
            # Restore the cursor that was active before the combined render began.
            self.configure(cursor=cursor if cursor is not None else "")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._combined_render_cursor = None

    def _install_startup_loading_splash(
        self,
        *,
        message: str = "Starting GL-260...",
        progress: float = 0.0,
    ) -> None:
        """Create or refresh the startup splash overlay window.

        Purpose:
            Display a determinate startup splash while launch tasks complete.
        Why:
            Startup can involve expensive UI construction and workbook restore, so
            users need immediate progress feedback instead of an apparently frozen app.
        Inputs:
            message: Splash status text shown under the title.
            progress: Initial progress value in the 0..100 range.
        Outputs:
            None.
        Side Effects:
            Creates a top-level splash window, initializes progress widgets, and
            stores widget references on the app instance for later updates.
        Exceptions:
            Best-effort guards avoid interrupting startup if splash creation fails.
        """
        overlay = getattr(self, "_startup_loading_overlay", None)
        if overlay is not None:
            try:
                if overlay.winfo_exists():
                    overlay.lift()
                    self._update_startup_loading_splash_progress(
                        progress=progress,
                        message=message,
                        reset=True,
                    )
                    return
            except Exception:
                overlay = None

        try:
            overlay = tk.Toplevel(self)
        except Exception:
            return
        try:
            overlay.title("Starting GL-260")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            overlay.resizable(False, False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            overlay.transient(self)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            overlay.attributes("-topmost", True)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            overlay.protocol("WM_DELETE_WINDOW", lambda: None)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        width = 420
        height = 165
        try:
            screen_w = int(self.winfo_screenwidth())
            screen_h = int(self.winfo_screenheight())
            pos_x = max(0, int((screen_w - width) / 2))
            pos_y = max(0, int((screen_h - height) / 2))
            overlay.geometry(f"{width}x{height}+{pos_x}+{pos_y}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        label = None
        progress_var = None
        progress_bar = None
        progress_label = None
        try:
            body = ttk.Frame(overlay, padding=14)
            body.pack(fill="both", expand=True)
            ttk.Label(
                body,
                text=f"GL-260 Data Analysis & Processing Engine {APP_VERSION}",
                anchor="w",
            ).pack(fill="x", pady=(0, 8))
            label = ttk.Label(
                body, text=str(message or "Starting GL-260..."), anchor="w"
            )
            label.pack(fill="x")
            progress_var = tk.DoubleVar(master=overlay, value=0.0)
            progress_bar = ttk.Progressbar(
                body,
                mode="determinate",
                maximum=100.0,
                variable=progress_var,
                length=360,
            )
            progress_bar.pack(fill="x", pady=(10, 0))
            progress_label = ttk.Label(body, text="0%", anchor="e")
            progress_label.pack(fill="x", pady=(6, 0))
        except Exception:
            label = None
            progress_var = None
            progress_bar = None
            progress_label = None

        self._startup_loading_overlay = overlay
        self._startup_loading_label = label
        self._startup_loading_progress_var = progress_var
        self._startup_loading_bar = progress_bar
        self._startup_loading_progress_label = progress_label
        self._startup_loading_progress_value = 0.0
        self._update_startup_loading_splash_progress(
            progress=progress,
            message=message,
            reset=True,
        )
        try:
            # Force the first splash frame to paint before startup-heavy work begins.
            overlay.update_idletasks()
            overlay.update()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _update_startup_loading_splash_progress(
        self,
        *,
        progress: Optional[float] = None,
        message: Optional[str] = None,
        reset: bool = False,
    ) -> None:
        """Update startup splash message and determinate progress value.

        Purpose:
            Keep startup splash progress synchronized with launch milestones.
        Why:
            Startup operations can complete out of order; monotonic updates prevent
            visible regressions while still surfacing useful status messages.
        Inputs:
            progress: Optional new progress value in the 0..100 range.
            message: Optional status message shown on the splash.
            reset: When True, reset tracked progress before applying updates.
        Outputs:
            None.
        Side Effects:
            Mutates splash labels/progress bar and updates cached progress state.
        Exceptions:
            Missing/destroyed splash widgets are ignored by best-effort guards.
        """
        overlay = getattr(self, "_startup_loading_overlay", None)
        if overlay is None:
            return
        try:
            if not overlay.winfo_exists():
                return
        except Exception:
            return

        if reset:
            self._startup_loading_progress_value = 0.0

        current_value = getattr(self, "_startup_loading_progress_value", 0.0)
        try:
            current_value = float(current_value)
        except Exception:
            current_value = 0.0
        if not math.isfinite(current_value):
            current_value = 0.0
        target_value = current_value
        if progress is not None:
            try:
                candidate = float(progress)
            except Exception:
                candidate = current_value
            if not math.isfinite(candidate):
                candidate = current_value
            candidate = max(0.0, min(100.0, candidate))
            target_value = candidate if reset else max(current_value, candidate)

        label = getattr(self, "_startup_loading_label", None)
        if label is not None and message is not None:
            try:
                label.configure(text=str(message))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        progress_var = getattr(self, "_startup_loading_progress_var", None)
        if progress_var is not None:
            try:
                progress_var.set(float(target_value))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        progress_bar = getattr(self, "_startup_loading_bar", None)
        if progress_bar is not None:
            try:
                progress_bar.configure(value=float(target_value), maximum=100.0)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        progress_label = getattr(self, "_startup_loading_progress_label", None)
        if progress_label is not None:
            try:
                progress_label.configure(text=f"{int(round(target_value))}%")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        self._startup_loading_progress_value = float(target_value)
        try:
            overlay.lift()
            overlay.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _clear_startup_loading_splash(self) -> None:
        """Destroy startup splash widgets and cancel pending splash timers.

        Purpose:
            Remove startup splash UI once launch completion gates are satisfied.
        Why:
            Splash teardown must be deterministic to avoid leaked top-level windows
            or orphaned timer callbacks after startup completion.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Cancels splash polling timer, destroys splash window, and clears all
            cached startup-splash widget references.
        Exceptions:
            Best-effort guards swallow teardown errors so startup can proceed.
        """
        after_id = getattr(self, "_startup_loading_poll_after_id", None)
        if after_id is not None:
            try:
                self.after_cancel(after_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._startup_loading_poll_after_id = None

        overlay = getattr(self, "_startup_loading_overlay", None)
        if overlay is not None:
            try:
                overlay.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        self._startup_loading_overlay = None
        self._startup_loading_label = None
        self._startup_loading_progress_var = None
        self._startup_loading_bar = None
        self._startup_loading_progress_label = None
        self._startup_loading_progress_value = 0.0

    def _startup_visible_tab_widgets(self) -> List[ttk.Frame]:
        """Return notebook-visible startup tab frames in display order.

        Purpose:
            Resolve the notebook tabs that should participate in startup readiness.
        Why:
            Startup readiness should use the notebook's actual attached tabs rather
            than inferring visibility from settings that may be stale during launch.
        Inputs:
            None.
        Outputs:
            List[ttk.Frame]: Notebook-attached tab frames ordered by notebook index.
        Side Effects:
            None.
        Exceptions:
            Missing notebook/widgets short-circuit to an empty list.
        """
        nb = getattr(self, "nb", None)
        if nb is None or not getattr(nb, "winfo_exists", lambda: False)():
            return []
        try:
            tab_ids = list(nb.tabs())
        except Exception:
            return []

        resolved_tabs: List[ttk.Frame] = []
        # Resolve notebook tab IDs to widgets so readiness only checks attached tabs.
        for tab_id in tab_ids:
            try:
                tab_obj = nb.nametowidget(tab_id)
            except Exception:
                continue
            if not isinstance(tab_obj, ttk.Frame):
                continue
            resolved_tabs.append(tab_obj)
        return resolved_tabs

    def _startup_tab_readiness_message(self) -> str:
        """Return splash status text for tab readiness verification.

        Purpose:
            Build deterministic readiness messaging for splash progress updates.
        Why:
            Keeping the current blocking reason in the message helps diagnose
            startup stalls without requiring external logs.
        Inputs:
            None.
        Outputs:
            str: Human-readable readiness message for the startup splash.
        Side Effects:
            None.
        Exceptions:
            Missing readiness-reason state falls back to a generic message.
        """
        reason = str(getattr(self, "_startup_tab_readiness_reason", "") or "").strip()
        if not reason:
            return "Verifying startup tab readiness..."
        return f"Verifying startup tab readiness ({reason})..."

    def _set_startup_tab_readiness_failure(self, reason: str) -> bool:
        """Record startup tab readiness failure reason and return False.

        Purpose:
            Capture the current blocking reason for startup tab readiness checks.
        Why:
            Polling logic needs a deterministic reason string for splash messaging
            and diagnostics when readiness remains incomplete.
        Inputs:
            reason: Human-readable summary of the first failing readiness condition.
        Outputs:
            bool: Always `False` so callers can return directly from guard checks.
        Side Effects:
            Updates `_startup_tab_readiness_reason` on the app instance.
        Exceptions:
            Non-string inputs are normalized to a safe string representation.
        """
        self._startup_tab_readiness_reason = str(reason or "").strip()
        return False

    def _startup_visible_tabs_ready_for_interaction(self) -> bool:
        """Check whether required startup tabs are initialized for interaction.

        Purpose:
            Provide a splash-completion gate that validates required startup tabs
            are attached and interactive without cycling notebook selection.
        Why:
            When startup tab cycling is disabled, splash teardown still needs a
            deterministic readiness check that covers the fixed startup tab set.
        Inputs:
            None.
        Outputs:
            bool: True when required startup tabs are attached and cycle-specific
                interaction prerequisites are satisfied; False otherwise.
        Side Effects:
            Flushes pending idle layout tasks as a best-effort readiness settle
            step and updates `_startup_tab_readiness_reason` when checks fail.
        Exceptions:
            Missing widgets or transient Tk errors fail closed by returning False.
        """
        if not bool(getattr(self, "_startup_ui_built", False)):
            return self._set_startup_tab_readiness_failure("main interface not ready")
        if not bool(getattr(self, "_startup_plot_stage_two_ready", False)):
            return self._set_startup_tab_readiness_failure("plot controls not ready")
        if not bool(getattr(self, "_startup_cycle_ready", False)):
            return self._set_startup_tab_readiness_failure("cycle tab not ready")
        if not bool(getattr(self, "_cycle_ui_built", False)):
            return self._set_startup_tab_readiness_failure(
                "cycle tab build pending"
            )

        nb = getattr(self, "nb", None)
        if nb is None or not getattr(nb, "winfo_exists", lambda: False)():
            return self._set_startup_tab_readiness_failure("notebook unavailable")

        try:
            self.update_idletasks()
            nb.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:
            notebook_tabs = set(nb.tabs())
        except Exception:
            return self._set_startup_tab_readiness_failure(
                "notebook tabs unavailable"
            )

        # Validate the fixed startup tab set so splash gating is deterministic.
        for key in STARTUP_REQUIRED_TAB_KEYS:
            tab_obj = self._tab_frame_for_key(key)
            tab_label = self._tab_label_for_key(key)
            if tab_obj is None:
                return self._set_startup_tab_readiness_failure(
                    f"{tab_label} tab frame missing"
                )
            if not getattr(tab_obj, "winfo_exists", lambda: False)():
                return self._set_startup_tab_readiness_failure(
                    f"{tab_label} tab widget unavailable"
                )
            if str(tab_obj) not in notebook_tabs:
                return self._set_startup_tab_readiness_failure(
                    f"{tab_label} tab not attached"
                )

        cycle_tab = getattr(self, "tab_cycle", None)
        if cycle_tab is not None and str(cycle_tab) in notebook_tabs:
            if not bool(getattr(self, "_cycle_ui_built", False)):
                return self._set_startup_tab_readiness_failure(
                    "cycle tab build pending"
                )
            cycle_canvas = getattr(self, "_cycle_canvas", None)
            if cycle_canvas is None:
                return self._set_startup_tab_readiness_failure(
                    "cycle canvas not initialized"
                )
            try:
                cycle_widget = cycle_canvas.get_tk_widget()
            except Exception:
                cycle_widget = None
            if cycle_widget is None or not getattr(
                cycle_widget, "winfo_exists", lambda: False
            )():
                return self._set_startup_tab_readiness_failure(
                    "cycle canvas widget unavailable"
                )
        self._startup_tab_readiness_reason = ""
        return True

    def _poll_startup_loading_completion(self) -> None:
        """Evaluate startup completion gates and close splash when fully ready.

        Purpose:
            Keep startup splash open until the workspace is interaction-ready.
        Why:
            Auto-restore can continue in the background, but tabs/listboxes should
            not become interactive only after delayed focus or tab-cycling events.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Updates splash progress/message, reschedules itself while readiness is
            pending, and clears splash once interaction readiness is verified.
        Exceptions:
            Missing splash state short-circuits safely without raising.
        """
        self._startup_loading_poll_after_id = None
        overlay = getattr(self, "_startup_loading_overlay", None)
        if overlay is None:
            return
        try:
            if not overlay.winfo_exists():
                return
        except Exception:
            return

        restore_state = str(
            getattr(self, "_startup_restore_state", "pending") or "pending"
        )
        ui_ready = bool(getattr(self, "_startup_ui_built", False))
        tab_warmup_ready = bool(getattr(self, "_startup_tab_warmup_done", False))
        restore_ready = restore_state in {"success", "failed", "skipped"}
        toggle_var = getattr(self, "_dev_disable_startup_tab_cycling_var", None)
        if toggle_var is not None:
            try:
                disable_tab_cycling = bool(toggle_var.get())
            except Exception:
                disable_tab_cycling = bool(
                    settings.get("dev_disable_startup_tab_cycling", True)
                )
        else:
            disable_tab_cycling = bool(
                settings.get("dev_disable_startup_tab_cycling", True)
            )

        progress_target = 8.0
        if ui_ready:
            progress_target = 62.0
        if restore_ready:
            progress_target = 94.0
        if tab_warmup_ready:
            progress_target = 98.0

        if ui_ready and not tab_warmup_ready:
            if disable_tab_cycling:
                self._update_startup_loading_splash_progress(
                    progress=96.0,
                    message=self._startup_tab_readiness_message(),
                )
                tab_warmup_ready = self._startup_visible_tabs_ready_for_interaction()
                if tab_warmup_ready:
                    self._startup_tab_warmup_done = True
            else:
                self._update_startup_loading_splash_progress(
                    progress=96.0,
                    message="Warming startup tabs...",
                )
                self._run_startup_tab_warmup_under_splash()
                tab_warmup_ready = bool(
                    getattr(self, "_startup_tab_warmup_done", False)
                )
                if tab_warmup_ready:
                    tab_warmup_ready = (
                        self._startup_visible_tabs_ready_for_interaction()
                    )
                    self._startup_tab_warmup_done = bool(tab_warmup_ready)
        if tab_warmup_ready and not disable_tab_cycling:
            tab_warmup_ready = self._startup_visible_tabs_ready_for_interaction()
            self._startup_tab_warmup_done = bool(tab_warmup_ready)

        if ui_ready and tab_warmup_ready:
            interaction_ready = self._startup_visible_tabs_ready_for_interaction()
            if interaction_ready:
                # Explicit startup invariant: splash can close only after readiness.
                self._startup_tab_warmup_done = True
                self._finalize_startup_to_data_tab()
                completion_message = "Startup complete. Opening workspace..."
                if restore_state == "running":
                    completion_message = (
                        "Workspace ready. Restoring last session in background..."
                    )
                self._update_startup_loading_splash_progress(
                    progress=100.0,
                    message=completion_message,
                )
                try:
                    overlay.after(60, self._clear_startup_loading_splash)
                except Exception:
                    self._clear_startup_loading_splash()
                return
            tab_warmup_ready = False
            self._startup_tab_warmup_done = False

        if not ui_ready:
            message = "Building main interface..."
        elif not tab_warmup_ready:
            if disable_tab_cycling or bool(
                getattr(self, "_startup_tab_warmup_done", False)
            ):
                message = self._startup_tab_readiness_message()
            else:
                message = "Warming startup tabs..."
        elif not restore_ready:
            if restore_state == "running":
                message = "Workspace ready. Restoring last session in background..."
            else:
                message = "Finalizing startup restore..."
        else:
            message = "Finalizing startup checks..."
        self._update_startup_loading_splash_progress(
            progress=progress_target,
            message=message,
        )
        try:
            self._startup_loading_poll_after_id = self.after(
                90, self._poll_startup_loading_completion
            )
        except Exception:
            self._startup_loading_poll_after_id = None

    def _run_startup_tab_warmup_under_splash(self) -> None:
        """Warm all startup tabs once while splash is visible.

        Purpose:
            Prebuild notebook tab layouts during startup without exposing tab changes.
        Why:
            Selecting each major tab once avoids first-click render delays while the
            splash is still on screen, so users do not see tab cycling.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Iterates notebook tab selection, performs idle layout updates, restores
            Data tab selection, and marks startup warmup completion state.
        Exceptions:
            Missing notebook/widgets short-circuit safely; per-tab failures are ignored.
        """
        toggle_var = getattr(self, "_dev_disable_startup_tab_cycling_var", None)
        disable_tab_cycling = bool(
            toggle_var.get()
            if toggle_var is not None
            else settings.get("dev_disable_startup_tab_cycling", True)
        )
        if disable_tab_cycling:
            return
        if bool(getattr(self, "_startup_tab_warmup_done", False)):
            return

        nb = getattr(self, "nb", None)
        data_tab = getattr(self, "tab_data", None)
        if (
            nb is None
            or data_tab is None
            or not getattr(nb, "winfo_exists", lambda: False)()
        ):
            return

        try:
            current_tab = nb.select()
        except Exception:
            current_tab = None

        # Use visible-tab order so warmup matches current notebook visibility settings.
        warm_tabs = self._startup_visible_tab_widgets()

        for tab_obj in warm_tabs:
            try:
                nb.select(tab_obj)
                nb.update_idletasks()
                tab_obj.update_idletasks()
            except Exception:
                continue

        target_tab = data_tab or current_tab
        if target_tab is not None:
            try:
                nb.select(target_tab)
            except Exception:
                if current_tab is not None:
                    try:
                        nb.select(current_tab)
                    except Exception:
                        pass

        try:
            nb.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._startup_tab_warmup_done = True

    def _finalize_startup_to_data_tab(self) -> None:
        """Force a stable, interactive Data-tab state at startup completion.

        Purpose:
            Ensure Data is selected and focusable when startup is declared complete.
        Why:
            Users should not need extra tab interactions after splash dismissal.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Cancels pending initial-tab timers, selects Data, flushes idle geometry,
            and sets keyboard focus on a stable Data-tab widget when possible.
        Exceptions:
            Best-effort guards prevent focus/selection issues from blocking startup.
        """
        after_id = getattr(self, "_initial_tab_after_id", None)
        if after_id is not None:
            try:
                self.after_cancel(after_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._initial_tab_after_id = None

        nb = getattr(self, "nb", None)
        data_tab = getattr(self, "tab_data", None)
        if (
            nb is not None
            and data_tab is not None
            and getattr(nb, "winfo_exists", lambda: False)()
        ):
            try:
                nb.select(data_tab)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                nb.update_idletasks()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        try:
            self.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        focus_widget = getattr(self, "e_file", None)
        if (
            focus_widget is not None
            and getattr(focus_widget, "winfo_exists", lambda: False)()
        ):
            try:
                focus_widget.focus_set()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        elif (
            data_tab is not None and getattr(data_tab, "winfo_exists", lambda: False)()
        ):
            try:
                data_tab.focus_set()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        self._initial_tab_shown = True
        map_bind_id = getattr(self, "_initial_tab_map_bind_id", None)
        if map_bind_id is not None:
            try:
                # Startup `<Map>` enforcement is one-shot to avoid focus churn.
                self.unbind("<Map>", map_bind_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._initial_tab_map_bind_id = None

    def _mark_startup_restore_state(
        self,
        state: str,
        *,
        path: Optional[str] = None,
        error: Optional[BaseException] = None,
    ) -> None:
        """Record startup restore state and publish splash progress milestones.

        Purpose:
            Centralize startup-restore status updates for poll-gated splash logic.
        Why:
            Restore can be skipped, running, successful, or failed; a single setter
            keeps progress messaging and completion gating deterministic.
        Inputs:
            state: Restore state value (`pending`, `running`, `success`, `failed`,
                or `skipped`).
            path: Optional workbook path associated with the state transition.
            error: Optional exception used for failure diagnostics/log messaging.
        Outputs:
            None.
        Side Effects:
            Updates startup restore state and splash message/progress milestones.
        Exceptions:
            Invalid states are normalized to `pending`; widget updates are best-effort.
        """
        normalized_state = str(state or "").strip().lower()
        if normalized_state not in {"pending", "running", "success", "failed", "skipped"}:
            normalized_state = "pending"
        self._startup_restore_state = normalized_state

        if normalized_state == "pending":
            self._update_startup_loading_splash_progress(
                progress=40.0,
                message="Preparing startup restore...",
            )
            return
        if normalized_state == "running":
            filename = ""
            try:
                filename = os.path.basename(path or "")
            except Exception:
                filename = ""
            message = (
                f"Restoring last session from {filename}..."
                if filename
                else "Restoring last session workbook..."
            )
            self._update_startup_loading_splash_progress(
                progress=70.0,
                message=message,
            )
            return
        if normalized_state == "success":
            self._update_startup_loading_splash_progress(
                progress=90.0,
                message="Last session restored.",
            )
            return
        if normalized_state == "failed":
            _ = error
            self._update_startup_loading_splash_progress(
                progress=90.0,
                message="Restore failed. Continuing startup...",
            )
            return
        self._update_startup_loading_splash_progress(
            progress=90.0,
            message="No previous session to restore.",
        )

    def _restore_last_session_async(self):
        """Start asynchronous workbook restore for the previous session.

        Purpose:
            Restore the most recently used workbook/sheet without blocking launch.
        Why:
            Reading workbook metadata/data can be expensive and should run in a
            background worker while the startup splash remains responsive.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Updates startup restore state, seeds file entry/status UI, and submits
            the restore worker to `TkTaskRunner`.
        Exceptions:
            Missing or malformed file paths short-circuit to a skipped restore
            state; unexpected preflight errors are marked failed so startup can
            continue without a stuck pending gate.
        """
        path_snapshot = ""
        last_sheet_snapshot = ""
        try:
            raw_path = settings.get("last_file_path")
            path_candidate = ""
            if raw_path is not None:
                try:
                    path_candidate = os.fspath(raw_path)
                except TypeError:
                    path_candidate = ""
            if isinstance(path_candidate, bytes):
                path_candidate = os.fsdecode(path_candidate)
            path = str(path_candidate or "").strip()
            if not path or not os.path.exists(path):
                self._mark_startup_restore_state("skipped")
                return

            # Snapshot inputs on the UI thread for thread safety/no-GIL readiness.
            path_snapshot = path
            last_sheet_snapshot = str(settings.get("last_sheet_name", "") or "")

            self._mark_startup_restore_state("running", path=path_snapshot)
            self._startup_restore_path = path_snapshot
            self.file_path = path_snapshot

            try:
                self.e_file.delete(0, tk.END)
                self.e_file.insert(0, path_snapshot)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            try:
                status_text = (
                    "Restoring last session from "
                    f"{os.path.basename(path_snapshot)}..."
                )
                self.lbl_status.config(text=status_text)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        except Exception as exc:
            self._startup_restore_task_id = None
            self._startup_restore_path = None
            self._mark_startup_restore_state(
                "failed",
                path=(path_snapshot or None),
                error=exc,
            )
            try:
                self.lbl_status.config(text="Ready. Select a file to begin.")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        # Closure captures _restore_last_session_async state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _restore_last_session_async.
        def _worker():
            """Perform worker.
            Used to keep the workflow logic localized and testable."""
            sheet_names = _read_excel_sheet_names(path_snapshot)
            target_sheet = (
                last_sheet_snapshot
                if last_sheet_snapshot and last_sheet_snapshot in sheet_names
                else (sheet_names[0] if sheet_names else "")
            )
            df = None
            df_error = None
            if target_sheet:
                try:
                    df = _read_excel_dataframe(path_snapshot, target_sheet)
                except Exception as exc:
                    df_error = exc
            return {
                "path": path_snapshot,
                "sheet_names": sheet_names,
                "target_sheet": target_sheet,
                "df": df,
                "df_error": df_error,
            }

        # Closure captures _restore_last_session_async state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _restore_last_session_async.
        def _on_ok(payload):
            """Handle ok.
            Used as an event callback for ok."""
            self._finish_restore_last_session(
                payload["path"],
                payload["sheet_names"],
                payload["target_sheet"],
                payload["df"],
                payload["df_error"],
            )

        # Closure captures _restore_last_session_async state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _restore_last_session_async.
        def _on_err(exc):
            """Handle err.
            Used as an event callback for err."""
            self._handle_restore_failure(path_snapshot, exc)

        try:
            self._startup_restore_task_id = self._task_runner.submit(
                "restore_session", _worker, _on_ok, _on_err
            )
        except Exception as exc:
            self._startup_restore_task_id = None
            self._startup_restore_path = path_snapshot
            self._mark_startup_restore_state("failed", path=path_snapshot, error=exc)
            self._handle_restore_failure(path_snapshot, exc)

    def _handle_restore_failure(self, path, exc):
        """Handle startup restore worker failure on the UI thread.

        Purpose:
            Finalize restore state and inform the user when auto-restore fails.
        Why:
            Failed startup restore should not block launch, but users need clear
            context about what file failed and why.
        Inputs:
            path: Workbook path associated with the failing restore request.
            exc: Exception raised by the background restore task.
        Outputs:
            None.
        Side Effects:
            Clears restore task tracking, updates splash/status text, and shows a
            warning dialog describing the restore failure.
        Exceptions:
            Path mismatches are ignored to avoid stale callback side effects.
        """

        if path != self._startup_restore_path:

            return

        self._startup_restore_task_id = None

        self._startup_restore_path = None
        self._mark_startup_restore_state("failed", path=path, error=exc)

        self.lbl_status.config(text="Ready. Select a file to begin.")

        messagebox.showwarning(
            "Auto-Load Failed",
            "The previously used workbook could not be opened.\n"
            f"Path: {path}\nError: {exc}",
        )

    def _finish_restore_last_session(
        self, path, sheet_names, selected_sheet, dataframe, dataframe_error
    ):
        """Finalize startup restore results on the UI thread.

        Purpose:
            Apply restore worker outputs to workbook/sheet/data UI state.
        Why:
            Worker threads must not touch Tk widgets directly, so completion logic
            runs on the main thread after worker success.
        Inputs:
            path: Workbook path used by the completed restore task.
            sheet_names: Resolved worksheet names from the workbook.
            selected_sheet: Sheet name selected for initial dataframe load.
            dataframe: Optional dataframe loaded for `selected_sheet`.
            dataframe_error: Optional exception from dataframe loading step.
        Outputs:
            None.
        Side Effects:
            Updates sheet selectors, cached dataframe state, persisted settings, and
            marks the startup restore state as completed.
        Exceptions:
            Stale callbacks (path mismatch) are ignored.
        """

        if path != self._startup_restore_path:

            return

        self._startup_restore_task_id = None

        self._startup_restore_path = None
        self._mark_startup_restore_state("success", path=path)

        self.sheet_names = list(sheet_names)
        self._sheet_names_loaded = True

        try:

            self.om_sheet.configure(values=self.sheet_names)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if self.sheet_names:

            status = (
                f"Loaded {os.path.basename(path)}. "
                f"{len(self.sheet_names)} sheet(s) found."
            )

        else:

            status = f"Loaded {os.path.basename(path)} (no sheets found)."

        self.lbl_status.config(text=status)

        if selected_sheet and not (self.multi_sheet_enabled and self.selected_sheets):
            self.selected_sheet.set(selected_sheet)

        self._sync_selected_sheets(persist=True)
        self._refresh_multi_sheet_lists()

        settings["last_file_path"] = path

        if self.multi_sheet_enabled:
            dt_col = (self.columns or {}).get("dt")
            if self.selected_sheets and dt_col and dt_col != "None":
                try:
                    self._build_stitched_dataframe(self.selected_sheets, dt_col)
                    self.lbl_status.config(
                        text=(
                            f"Sheets loaded: {len(self.selected_sheets)} "
                            f"({len(self.df)} rows)."
                        )
                    )
                    settings["selected_sheets"] = list(self.selected_sheets)
                    try:
                        _save_settings_to_disk()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                    self._refresh_columns_ui()
                    self._mark_columns_dirty(reason="session restore")
                except Exception:
                    self.df = None
                    self._clear_numeric_cache()
            else:
                self.df = None
                self._clear_numeric_cache()
            return

        if dataframe is not None:

            self.df = dataframe

            self._clear_numeric_cache()

            self.lbl_status.config(
                text=f"Sheet loaded: {selected_sheet} ({len(self.df)} rows)."
            )

            settings["last_sheet_name"] = selected_sheet

            try:

                _save_settings_to_disk()

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            self._refresh_columns_ui()

            self._mark_columns_dirty(reason="session restore")

        else:

            self.df = None

            self._clear_numeric_cache()

            if dataframe_error is not None:

                messagebox.showwarning(
                    "Auto-Load Incomplete",
                    "The workbook opened but the saved sheet could not be "
                    "restored automatically.\n"
                    f"Error: {dataframe_error}",
                )

    def _load_sheets_from_current_path(self):
        """Load sheets from current path.
        Used when restoring sheets from current path from storage."""

        path = self.e_file.get().strip() or settings.get("last_file_path", "")

        if not path or not os.path.exists(path):

            messagebox.showerror(
                "Missing File", "Enter/browse to a valid Excel file first."
            )

            return

        self.file_path = path  # make sure the class has the path

        settings["last_file_path"] = self.file_path

        try:

            _save_settings_to_disk()

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        self._load_sheet_names()

    def _remember_normal_geometry(self, event=None):
        """Perform remember normal geometry.
        Used to keep the workflow logic localized and testable."""

        # Only record geometry when not maximized

        if self.state() == "normal":

            self._last_normal_geometry = self.geometry()

    def _register_menu(self, menu: tk.Menu) -> tk.Menu:
        """Perform register menu.
        Used to keep the workflow logic localized and testable."""

        menus = getattr(self, "_registered_menus", None)
        if menus is None:
            menus = []
            self._registered_menus = menus
        menus.append(menu)
        return menu

    def _refresh_menu_fonts(self):
        """Refresh menu fonts.
        Used to sync menu fonts with current settings."""

        menus = getattr(self, "_registered_menus", [])
        family = getattr(self, "_ui_font_family", "Verdana")
        size = getattr(
            self, "_effective_font_size", getattr(self, "_default_font_size", 10)
        )
        menu_font = (family, size)
        try:
            self.option_add("*Menu.Font", menu_font)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        # Iterate over menus to apply the per-item logic.
        for menu in menus:
            try:
                menu.configure(font=menu_font)
            except Exception:
                continue

    def _resolve_base_font_size(self) -> int:
        """Resolve base font size.
        Used to compute base font size before rendering or export."""

        requested_font_size = settings.get("ui_font_size", self._default_font_size)
        try:
            base_font_size = int(requested_font_size)
        except (TypeError, ValueError):
            base_font_size = self._default_font_size
        return max(8, min(base_font_size, 24))

    def _zoom_presets(self) -> List[Tuple[str, float]]:
        """Perform zoom presets.
        Used to keep the workflow logic localized and testable."""

        return [
            ("90%", 0.9),
            ("100%", 1.0),
            ("110%", 1.1),
            ("125%", 1.25),
            ("150%", 1.5),
            ("175%", 1.75),
            ("200%", 2.0),
        ]

    def _build_view_menu(self, view_menu: tk.Menu):
        """Build view menu.
        Used to assemble view menu during UI or plot setup."""

        view_menu.add_command(
            label="Zoom In (Ctrl +)",
            command=lambda: self._adjust_ui_zoom(0.1),
        )
        view_menu.add_command(
            label="Zoom Out (Ctrl -)",
            command=lambda: self._adjust_ui_zoom(-0.1),
        )
        view_menu.add_command(
            label="Reset Zoom (Ctrl 0)",
            command=lambda: self._set_global_scale(
                getattr(self, "_initial_ui_scale", 1.0), reflow=False
            ),
        )
        view_menu.add_separator()
        zoom_menu = self._register_menu(tk.Menu(view_menu, tearoff=0))
        # Iterate over self._zoom_presets() to apply the per-item logic.
        for label, ratio in self._zoom_presets():
            zoom_menu.add_radiobutton(
                label=label,
                variable=self._ui_zoom_var,
                value=ratio,
                command=lambda r=ratio: self._set_global_scale(r, reflow=False),
            )
        view_menu.add_cascade(label="Zoom Presets", menu=zoom_menu)
        view_menu.add_separator()
        view_menu.add_command(
            label="Optimize Layout for Current Display...",
            command=self._optimize_for_current_display,
        )

    def _initialize_ui_scaling(self) -> float:
        """Perform initialize UI scaling.
        Used to keep the workflow logic localized and testable."""

        try:
            self.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        scale = self._compute_ui_scale()
        self._ui_scale = scale
        settings["ui_scale_ratio"] = round(scale, 3)
        self._apply_tk_scaling(scale)
        return scale

    def _compute_ui_scale(self, explicit: Optional[float] = None) -> float:
        """Compute UI scale.
        Used to derive UI scale for analysis or plotting."""

        override = explicit
        if override is None:
            stored = settings.get("ui_scale_ratio")
            if isinstance(stored, (int, float)) and math.isfinite(stored):
                override = float(stored)
        detected = self._detect_display_scale()
        try:
            screen_w = float(self.winfo_screenwidth())
            screen_h = float(self.winfo_screenheight())
            base_w, base_h = 1920.0, 1080.0
            resolution_hint = min(screen_w / base_w, screen_h / base_h)
        except Exception:
            resolution_hint = 1.0
        candidate = override or detected or resolution_hint or 1.0
        return max(MIN_UI_SCALE, min(float(candidate), MAX_UI_SCALE))

    def _detect_display_scale(self) -> Optional[float]:
        """Detect display scale.
        Used to decide runtime capabilities or configuration."""

        hwnd = None
        try:
            hwnd = int(self.winfo_id())
        except Exception:
            hwnd = None
        return _detect_windows_scale(hwnd)

    def _apply_tk_scaling(self, scale: float):
        """Apply Tk scaling.
        Used to apply Tk scaling changes to live state."""

        clamped = max(MIN_UI_SCALE, min(scale, MAX_UI_SCALE))
        try:
            self.tk.call("tk", "scaling", clamped)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _predict_geometry_for_scale(
        self,
        scale: float,
        screen_w: Optional[int] = None,
        screen_h: Optional[int] = None,
    ) -> Tuple[int, int]:
        """Predict geometry for scale.
        Used to compute geometry for scale for planning workflows."""

        scale = max(MIN_UI_SCALE, min(scale, MAX_UI_SCALE))

        if screen_w is None or screen_h is None:
            try:
                screen_w = max(800, int(self.winfo_screenwidth()))
                screen_h = max(600, int(self.winfo_screenheight()))
            except Exception:
                screen_w, screen_h = 1600, 900

        def _scale_len(value: float) -> int:
            """Perform scale len.
            Used to keep the workflow logic localized and testable."""
            numeric = float(value)
            scaled = int(round(numeric * scale))
            if numeric <= 0:
                return 0
            return max(scaled, 1)

        width = min(
            screen_w - _scale_len(40),
            max(_scale_len(1280), int(screen_w * 0.9)),
        )
        height = min(
            screen_h - _scale_len(40),
            max(_scale_len(860), int(screen_h * 0.9)),
        )
        width = max(width, _scale_len(1100))
        height = max(height, _scale_len(720))
        return width, height

    def _resize_for_active_display(self, scale: Optional[float] = None):
        """Perform resize for active display.
        Used to keep the workflow logic localized and testable."""

        target_scale = scale if scale is not None else getattr(self, "_ui_scale", 1.0)
        width, height = self._predict_geometry_for_scale(target_scale)
        geometry = f"{width}x{height}+20+20"
        try:
            self.geometry(geometry)
            self._last_normal_geometry = geometry
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _set_global_scale(
        self, ratio: float, *, reflow: bool = False, persist: bool = True
    ):
        """Set global scale.
        Used to persist global scale into the current state."""

        try:
            candidate = float(ratio)
        except (TypeError, ValueError):
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return

        clamped = max(MIN_UI_SCALE, min(candidate, MAX_UI_SCALE))
        previous = getattr(self, "_ui_scale", 1.0)
        if abs(clamped - previous) < 0.01:
            self._apply_tk_scaling(clamped)
            self._sync_zoom_indicator()
            return

        self._ui_scale = clamped
        if persist:
            settings["ui_scale_ratio"] = round(clamped, 3)
        self._apply_tk_scaling(clamped)

        requested_size = settings.get(
            "ui_font_size", getattr(self, "_default_font_size", 10)
        )
        self._apply_accessible_fonts(base_size=requested_size)
        self._apply_toolbar_scaling(getattr(self, "_cycle_toolbar", None))

        if reflow:
            self._resize_for_active_display(clamped)

        self._sync_zoom_indicator()

        try:
            self.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _adjust_ui_zoom(self, delta: float):
        """Perform adjust UI zoom.
        Used to keep the workflow logic localized and testable."""

        base = getattr(self, "_ui_scale", 1.0)
        step = float(delta or 0.0)
        self._set_global_scale(base + step, reflow=False)

    def _sync_zoom_indicator(self):
        """Perform sync zoom indicator.
        Used to keep the workflow logic localized and testable."""

        var = getattr(self, "_ui_zoom_var", None)
        if var is None:
            return
        try:
            var.set(round(getattr(self, "_ui_scale", 1.0), 3))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _scale_length(self, value):
        """Perform scale length.
        Used to keep the workflow logic localized and testable."""
        scale = getattr(self, "_ui_scale", 1.0) or 1.0
        numeric = float(value)
        scaled = int(round(numeric * scale))
        if numeric <= 0:
            return 0
        return max(scaled, 1)

    def _scale_padding(self, pad):
        """Perform scale padding.
        Used to keep the workflow logic localized and testable."""
        if pad is None:
            return None
        if isinstance(pad, tuple):
            return tuple(self._scale_length(v) for v in pad)
        return self._scale_length(pad)

    def _cycle_plot_font_sizes(self):
        """Perform cycle plot font sizes.
        Used to keep the workflow logic localized and testable."""
        base = getattr(
            self, "_effective_font_size", getattr(self, "_default_font_size", 10)
        )
        axis = max(9, min(int(round(base * 1.05)), 26))
        tick = max(8, min(int(round(base * 0.95)), axis))
        title = min(axis + 2, 30)
        legend = max(8, min(int(round(base)), 24))
        return {"axis": axis, "tick": tick, "title": title, "legend": legend}

    def _apply_plot_selection_nan_mask(
        self,
        x: np.ndarray,
        y: np.ndarray,
        mask_arr: Optional[np.ndarray],
    ) -> Tuple[np.ndarray, np.ndarray]:
        """Apply plot selection nan mask.
        Used to apply plot selection nan mask changes to live state."""
        if mask_arr is None:
            return x, y
        try:
            mask = np.asarray(mask_arr, dtype=bool)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return x, y
        if mask.shape[0] != x.shape[0] or mask.shape[0] != y.shape[0]:
            return x, y
        x_plot = np.array(x, dtype=float, copy=True)
        y_plot = np.array(y, dtype=float, copy=True)
        x_plot[~mask] = np.nan
        y_plot[~mask] = np.nan
        return x_plot, y_plot

    def _apply_cycle_axis_style(self, ax=None):
        """Apply cycle axis style.
        Used to apply cycle axis style changes to live state."""
        ax = ax or getattr(self, "_cycle_ax", None)
        if ax is None:
            return
        sizes = self._cycle_plot_font_sizes()
        font_family = (settings.get("font_family") or "").strip()
        _enforce_axis_text_style(
            ax,
            font_family=font_family,
            tick_fontsize=sizes["tick"],
            label_fontsize=sizes["axis"],
        )
        try:
            ax.title.set_fontsize(sizes["title"])
            if font_family:
                ax.title.set_fontfamily(font_family)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _apply_cycle_legend_style(self, legend):
        """Apply cycle legend style.
        Used to apply cycle legend style changes to live state."""
        if legend is None:
            return
        sizes = self._cycle_plot_font_sizes()
        font_family = (settings.get("font_family") or "").strip()
        # Iterate over legend.get_texts() to apply the per-item logic.
        for text in legend.get_texts():
            try:
                if font_family:
                    text.set_fontfamily(font_family)
                text.set_fontsize(sizes["legend"])
            except Exception:
                continue

    def _enforce_legend_text_style(
        self,
        legend,
        legend_prop: Optional[font_manager.FontProperties],
        legend_fontsize_value: float,
    ) -> None:
        """Perform enforce legend text style.
        Used to keep the workflow logic localized and testable."""
        if legend is None:
            return
        try:
            # Iterate over legend.get_texts() to apply the per-item logic.
            for txt in legend.get_texts():
                txt.set_fontsize(legend_fontsize_value)
                if legend_prop is not None:
                    txt.set_fontproperties(legend_prop)
            title = legend.get_title()
            if title:
                title.set_fontsize(legend_fontsize_value)
                if legend_prop is not None:
                    title.set_fontproperties(legend_prop)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _apply_gl260_legend_sizing(
        self,
        fig: Optional[Figure],
        *,
        plot_id: Optional[str] = None,
        plot_key: Optional[str] = None,
        main_fontsize: Optional[float] = None,
        cycle_fontsize: Optional[float] = None,
        font_family: Optional[str] = None,
    ) -> None:
        """Apply gl260 legend sizing.
        Used to apply gl260 legend sizing changes to live state."""
        if fig is None:
            return
        core_plot_id = plot_id
        if core_plot_id not in CORE_RENDER_PROFILE_PLOT_IDS:
            core_plot_id = {
                "fig1": "fig_pressure_temp",
                "fig2": "fig_pressure_derivative",
            }.get((plot_key or "").strip().lower())
        is_combined = False
        if plot_id == "fig_combined_triple_axis" or plot_key == "fig_combined":
            is_combined = True
        if main_fontsize is None or cycle_fontsize is None:
            if is_combined:
                main_fontsize = _sanitize_spacing_value(
                    settings.get("combined_legend_fontsize", DEFAULT_COMBINED_LEGEND_FONTSIZE),
                    DEFAULT_COMBINED_LEGEND_FONTSIZE,
                    MIN_COMBINED_FONT_SIZE,
                    MAX_COMBINED_FONT_SIZE,
                )
                cycle_fontsize = _sanitize_spacing_value(
                    settings.get("combined_cycle_legend_fontsize", main_fontsize),
                    main_fontsize,
                    MIN_COMBINED_FONT_SIZE,
                    MAX_COMBINED_FONT_SIZE,
                )
                if font_family is None:
                    font_family = (settings.get("combined_font_family") or "").strip()
            elif core_plot_id in CORE_RENDER_PROFILE_PLOT_IDS:
                profile = _get_core_plot_render_profile(core_plot_id)
                main_fontsize = _sanitize_spacing_value(
                    profile.get("legend_fontsize", settings.get("core_legend_fontsize", label_fontsize)),
                    settings.get("core_legend_fontsize", label_fontsize),
                    MIN_COMBINED_FONT_SIZE,
                    MAX_COMBINED_FONT_SIZE,
                )
                cycle_fontsize = _sanitize_spacing_value(
                    profile.get("cycle_legend_fontsize", settings.get("core_cycle_legend_fontsize", main_fontsize)),
                    main_fontsize,
                    MIN_COMBINED_FONT_SIZE,
                    MAX_COMBINED_FONT_SIZE,
                )
                if font_family is None:
                    font_family = (
                        (profile.get("font_family") or "").strip()
                        or (settings.get("font_family") or "").strip()
                    )
            else:
                main_fontsize = _sanitize_spacing_value(
                    settings.get("core_legend_fontsize", label_fontsize),
                    label_fontsize,
                    MIN_COMBINED_FONT_SIZE,
                    MAX_COMBINED_FONT_SIZE,
                )
                cycle_fontsize = _sanitize_spacing_value(
                    settings.get("core_cycle_legend_fontsize", main_fontsize),
                    main_fontsize,
                    MIN_COMBINED_FONT_SIZE,
                    MAX_COMBINED_FONT_SIZE,
                )
                if font_family is None:
                    font_family = (settings.get("font_family") or "").strip()
        if main_fontsize is None or cycle_fontsize is None:
            return
        try:
            _enforce_gl260_legend_sizing(
                fig,
                main_fontsize,
                cycle_fontsize,
                font_family=font_family,
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _apply_toolbar_scaling(self, toolbar):
        """Apply toolbar scaling.
        Used to apply toolbar scaling changes to live state."""
        if toolbar is None:
            return
        try:
            if hasattr(toolbar, "winfo_exists") and not toolbar.winfo_exists():
                return
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return

        try:
            base_font = tkfont.nametofont("TkDefaultFont")
        except Exception:
            base_font = tkfont.Font(family="Verdana", size=10)

        sizes = self._cycle_plot_font_sizes()
        toolbar_font = tkfont.Font(font=base_font)
        toolbar_font.configure(size=max(8, min(sizes["axis"], 18)))
        self._cycle_toolbar_font = toolbar_font

        pad_x = self._scale_length(4)
        pad_y = self._scale_length(2)

        # Iterate over toolbar.winfo_children() to apply the per-item logic.
        for child in toolbar.winfo_children():
            try:
                if isinstance(child, (tk.Button, ttk.Button)):
                    child.configure(font=toolbar_font, padx=pad_x, pady=pad_y)
                elif isinstance(child, tk.Entry):
                    child.configure(font=toolbar_font)
            except Exception:
                continue

    def _optimize_for_current_display(self):
        """Return current display.
        Used by optimize for workflows to return display."""

        try:
            self.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        detected_scale = self._detect_display_scale()
        fallback_scale = self._compute_ui_scale()
        current_scale = getattr(self, "_ui_scale", fallback_scale)
        starting_value = max(MIN_UI_SCALE, min(current_scale, MAX_UI_SCALE))
        suggested = detected_scale or fallback_scale or starting_value

        dialog = tk.Toplevel(self)
        dialog.title("Optimize Layout for Current Display")
        dialog.transient(self)
        dialog.resizable(False, False)
        dialog.grab_set()

        slider_value = tk.DoubleVar(value=starting_value)
        preview_text = tk.StringVar()
        geometry_text = tk.StringVar()

        ttk.Label(
            dialog,
            text="Choose a UI zoom level that keeps controls large without wasting space.",
        ).pack(padx=20, pady=(15, 5))

        slider = ttk.Scale(
            dialog,
            from_=MIN_UI_SCALE,
            to=MAX_UI_SCALE,
            orient="horizontal",
            variable=slider_value,
        )
        slider.pack(fill="x", padx=20, pady=(0, 5))

        ttk.Label(dialog, textvariable=preview_text, font=("Verdana", 11, "bold")).pack(
            padx=20, pady=(0, 2)
        )
        ttk.Label(dialog, textvariable=geometry_text).pack(padx=20, pady=(0, 10))

        # Closure captures _optimize_for_current_display state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _optimize_for_current_display.
        def _update_preview():
            """Update preview.
            Used to keep preview in sync with current state."""
            ratio = max(MIN_UI_SCALE, min(slider_value.get(), MAX_UI_SCALE))
            preview_text.set(f"{ratio:.2f}x ({int(round(ratio * 100))}%)")
            width, height = self._predict_geometry_for_scale(ratio)
            geometry_text.set(f"Projected window: {width} x {height} px")

        slider.configure(command=lambda _value: _update_preview())
        _update_preview()

        button_frame = ttk.Frame(dialog)
        button_frame.pack(fill="x", padx=20, pady=(5, 15))

        # Closure captures _optimize_for_current_display state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _optimize_for_current_display.
        def _apply_and_close():
            """Apply and close.
            Used to apply and close changes to live state."""
            dialog.grab_release()
            dialog.destroy()
            self._set_global_scale(slider_value.get(), reflow=True)

        # Closure captures _optimize_for_current_display state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _optimize_for_current_display.
        def _cancel():
            """Perform cancel.
            Used to keep the workflow logic localized and testable."""
            dialog.grab_release()
            dialog.destroy()

        apply_btn = ttk.Button(button_frame, text="Apply", command=_apply_and_close)
        apply_btn.pack(side="right")
        ttk.Button(button_frame, text="Cancel", command=_cancel).pack(
            side="right", padx=(0, 8)
        )

        if suggested:

            # Closure captures _optimize_for_current_display local context to keep helper logic scoped and invoked directly within _optimize_for_current_display.
            def _use_suggested():
                """Perform use suggested.
                Used to keep the workflow logic localized and testable."""
                slider_value.set(suggested)
                _update_preview()

            ttk.Button(
                button_frame,
                text="Use Suggested",
                command=_use_suggested,
            ).pack(side="left")

        dialog.bind("<Return>", lambda _event: _apply_and_close())
        dialog.bind("<Escape>", lambda _event: _cancel())
        dialog.wait_window(dialog)

    def _append_regression_output(self, message: str) -> None:
        """Perform append regression output.
        Used to keep the workflow logic localized and testable."""
        widget = getattr(self, "_regression_output", None)
        if widget is None or not widget.winfo_exists():
            return
        widget.configure(state="normal")
        widget.insert("end", message.rstrip() + "\n")
        widget.configure(state="disabled")
        widget.see("end")

    def _clear_regression_output(self) -> None:
        """Clear regression output.
        Used to reset regression output state safely."""
        widget = getattr(self, "_regression_output", None)
        if widget is None or not widget.winfo_exists():
            return
        widget.configure(state="normal")
        widget.delete("1.0", "end")
        widget.configure(state="disabled")

    def _selected_regression_tests(self) -> List[Tuple[str, Callable[[], None]]]:
        """Perform selected regression tests.
        Used to keep the workflow logic localized and testable."""
        listbox = getattr(self, "_regression_listbox", None)
        if listbox is None or not listbox.winfo_exists():
            return []
        selections = listbox.curselection()
        tests: List[Tuple[str, Callable[[], None]]] = []
        # Iterate over selections to apply the per-item logic.
        for idx in selections:
            try:
                tests.append(REGRESSION_TESTS[int(idx)])
            except Exception:
                continue
        return tests

    def _run_registered_regressions(
        self, tests: Sequence[Tuple[str, Callable[[], None]]]
    ) -> None:
        """Run registered regressions.
        Used to execute registered regressions and coordinate results."""
        if not tests:
            try:
                messagebox.showinfo(
                    "Regression Checks", "Select at least one regression to run."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        if getattr(self, "_sol_regression_task_id", None) is not None:
            try:
                messagebox.showinfo(
                    "Regression Checks",
                    "A regression run is already in progress. Please wait for it to finish.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        status_var = getattr(self, "_regression_status_var", None)
        if status_var is not None:
            status_var.set(f"Running {len(tests)} regression(s)...")
        self._append_regression_output(
            f"Running {len(tests)} regression(s): "
            + ", ".join(name for name, _ in tests)
        )

        tests_snapshot = list(tests)

        def _worker() -> List[Tuple[str, bool, str]]:
            """Perform worker.
            Used to keep the workflow logic localized and testable."""
            results: List[Tuple[str, bool, str]] = []
            # Iterate over tests_snapshot to apply the per-item logic.
            for name, fn in tests_snapshot:
                try:
                    fn()
                    results.append((name, True, ""))
                except Exception:
                    results.append((name, False, traceback.format_exc()))
            return results

        def _on_ok(results):
            """Handle ok.
            Used as an event callback for ok."""
            self._on_regression_run_complete(results, status_var=status_var)

        def _on_err(exc):
            """Handle err.
            Used as an event callback for err."""
            failure = [("Regression runner", False, str(exc))]
            self._on_regression_run_complete(failure, status_var=status_var)

        self._sol_regression_task_id = self._task_runner.submit(
            "regression_checks", _worker, _on_ok, _on_err
        )

    def _on_regression_run_complete(
        self,
        results: Sequence[Tuple[str, bool, str]],
        status_var: Optional[tk.StringVar],
    ) -> None:
        """Handle regression run complete.
        Used as an event callback for regression run complete."""
        any_fail = False
        # Iterate over results to apply the per-item logic.
        for name, success, tb_text in results:
            if success:
                self._append_regression_output(f"[PASS] {name}")
            else:
                any_fail = True
                detail = tb_text.strip() or "No traceback available."
                self._append_regression_output(f"[FAIL] {name}\n{detail}")
        if status_var is not None:
            status_var.set("Completed with failures." if any_fail else "Completed.")
        self._sol_regression_task_id = None

    def _close_regression_dialog(self) -> None:
        """Close regression dialog.
        Used by UI actions to close regression dialog safely."""
        dialog = getattr(self, "_regression_dialog", None)
        if dialog is not None and dialog.winfo_exists():
            dialog.destroy()
        self._regression_dialog = None
        self._regression_output = None
        self._regression_listbox = None
        self._regression_status_var = None

    def _open_regression_checks_dialog(self) -> None:
        """Open regression checks dialog.
        Used by UI actions to open regression checks dialog."""
        existing = getattr(self, "_regression_dialog", None)
        if existing is not None and existing.winfo_exists():
            existing.deiconify()
            existing.lift()
            return
        dialog = tk.Toplevel(self)
        dialog.title("Regression Checks")
        dialog.geometry("780x520")
        dialog.transient(self)
        dialog.columnconfigure(1, weight=1)
        dialog.rowconfigure(1, weight=1)
        dialog.protocol("WM_DELETE_WINDOW", self._close_regression_dialog)
        self._regression_dialog = dialog

        ttk.Label(dialog, text="Select regression tests to run:").grid(
            row=0, column=0, sticky="w", padx=(10, 4), pady=(10, 2)
        )
        listbox = tk.Listbox(
            dialog, selectmode="extended", exportselection=False, height=6
        )
        # Iterate over indexed elements from REGRESSION_TESTS to apply the per-item logic.
        for idx, (name, _fn) in enumerate(REGRESSION_TESTS):
            listbox.insert(idx, name)
        listbox.grid(row=1, column=0, sticky="nsw", padx=(10, 4), pady=(0, 4))
        self._regression_listbox = listbox

        button_frame = ttk.Frame(dialog)
        button_frame.grid(row=0, column=1, sticky="e", padx=(4, 10), pady=(10, 2))
        ttk.Button(
            button_frame,
            text="Run selected",
            command=lambda: self._run_registered_regressions(
                self._selected_regression_tests()
            ),
        ).grid(row=0, column=0, padx=4)
        ttk.Button(
            button_frame,
            text="Run all",
            command=lambda: self._run_registered_regressions(REGRESSION_TESTS),
        ).grid(row=0, column=1, padx=4)
        ttk.Button(
            button_frame,
            text="Clear log",
            command=self._clear_regression_output,
        ).grid(row=0, column=2, padx=4)
        ttk.Button(
            button_frame, text="Close", command=self._close_regression_dialog
        ).grid(row=0, column=3, padx=4)

        output = scrolledtext.ScrolledText(dialog, wrap="word", state="disabled")
        output.grid(row=1, column=1, sticky="nsew", padx=(4, 10), pady=(0, 4))
        self._enable_text_mousewheel(output)
        self._regression_output = output
        status_var = tk.StringVar(value="Idle")
        self._regression_status_var = status_var
        ttk.Label(dialog, textvariable=status_var).grid(
            row=2, column=0, columnspan=2, sticky="w", padx=10, pady=(0, 8)
        )

    def _maybe_warn_gil_reenabled_import(self) -> None:
        """Import value.
        Used by maybe warn GIL reenabled workflows to import value."""
        if self._gil_import_warning_shown:
            return
        if not _supports_free_threading_build():
            return
        if _STARTUP_GIL_STATUS is not False:
            return
        if not _GIL_IMPORT_REENABLES:
            return
        module_name = _GIL_IMPORT_REENABLES[0]
        try:
            messagebox.showwarning(
                "Free-Threading Warning",
                "Free-threading was disabled after importing "
                f"{module_name}. See Developer Tools -> Dependency Free-Threading Audit.",
                parent=self,
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._gil_import_warning_shown = True

    def _open_free_threading_dialog(self) -> None:
        """Open free threading dialog.
        Used by UI actions to open free threading dialog."""
        existing = getattr(self, "_free_threading_dialog", None)
        if existing is not None and existing.winfo_exists():
            existing.deiconify()
            existing.lift()
            self._refresh_free_threading_status()
            return

        dialog = tk.Toplevel(self)
        dialog.title("Free-Threading & GIL")
        dialog.transient(self)
        dialog.resizable(False, False)
        dialog.grab_set()

        # Closure captures _open_free_threading_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_free_threading_dialog.
        def _close_dialog() -> None:
            """Close dialog.
            Used by UI actions to close dialog safely."""
            try:
                dialog.grab_release()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                dialog.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._free_threading_dialog = None

        dialog.protocol("WM_DELETE_WINDOW", _close_dialog)
        self._free_threading_dialog = dialog

        runtime_frame = ttk.LabelFrame(dialog, text="Current Runtime")
        runtime_frame.grid(row=0, column=0, sticky="nsew", padx=10, pady=(10, 6))
        dialog.columnconfigure(0, weight=1)

        status_vars = {
            "python_version": tk.StringVar(value=""),
            "executable": tk.StringVar(value=""),
            "supports_free_threading": tk.StringVar(value=""),
            "gil_enabled": tk.StringVar(value=""),
        }
        self._free_threading_status_vars = status_vars

        runtime_rows = [
            ("Python version", "python_version"),
            ("sys.executable", "executable"),
            ("Free-threading capable?", "supports_free_threading"),
            ("Current GIL enabled?", "gil_enabled"),
        ]
        # Iterate over indexed elements from runtime_rows to apply the per-item logic.
        for row_idx, (label_text, key) in enumerate(runtime_rows):
            ttk.Label(runtime_frame, text=f"{label_text}:").grid(
                row=row_idx, column=0, sticky="w", padx=8, pady=3
            )
            ttk.Label(
                runtime_frame,
                textvariable=status_vars[key],
                wraplength=self._scale_length(520),
                justify="left",
            ).grid(row=row_idx, column=1, sticky="w", padx=8, pady=3)

        intent_frame = ttk.LabelFrame(dialog, text="User Intent Control")
        intent_frame.grid(row=1, column=0, sticky="nsew", padx=10, pady=(6, 10))
        intent_frame.columnconfigure(0, weight=1)

        ttk.Checkbutton(
            intent_frame,
            text="Request GIL-disabled (free-threaded) mode",
            variable=self._dev_request_gil_var,
            command=self._on_request_gil_toggle,
        ).grid(row=0, column=0, sticky="w", padx=8, pady=(6, 4))

        self._free_threading_status_var = tk.StringVar(value="")
        status_label = ttk.Label(
            intent_frame,
            textvariable=self._free_threading_status_var,
            wraplength=self._scale_length(520),
            justify="left",
        )
        status_label.grid(row=1, column=0, sticky="w", padx=8, pady=(0, 6))

        self._free_threading_restart_btn = ttk.Button(
            intent_frame,
            text="Restart with GIL disabled",
            command=self._restart_with_gil_disabled,
        )
        self._free_threading_restart_btn.grid(
            row=2, column=0, sticky="w", padx=8, pady=(0, 8)
        )

        self._refresh_free_threading_status()

    def _refresh_free_threading_status(self) -> None:
        """Refresh free threading status.
        Used to sync free threading status with current settings."""
        status_vars = getattr(self, "_free_threading_status_vars", None)
        if not isinstance(status_vars, dict):
            return
        status_vars["python_version"].set(platform.python_version())
        status_vars["executable"].set(sys.executable or "")
        supports = _supports_free_threading_build()
        status_vars["supports_free_threading"].set("Yes" if supports else "No")
        gil_status = _current_gil_status()
        if gil_status is None:
            status_vars["gil_enabled"].set("Unknown")
        else:
            status_vars["gil_enabled"].set("Yes" if gil_status else "No")

        status_var = getattr(self, "_free_threading_status_var", None)
        restart_btn = getattr(self, "_free_threading_restart_btn", None)
        if not isinstance(status_var, tk.StringVar):
            return
        if not bool(self._dev_request_gil_var.get()):
            status_var.set("")
            if restart_btn is not None:
                restart_btn.configure(state="disabled")
            return
        if not supports:
            status_var.set(
                "This interpreter does not support free-threading. Use a "
                "free-threaded Python 3.14 build."
            )
            if restart_btn is not None:
                restart_btn.configure(state="disabled")
            return
        if gil_status is None:
            status_var.set("GIL status unavailable on this interpreter.")
            if restart_btn is not None:
                restart_btn.configure(state="disabled")
            return
        if gil_status:
            status_var.set(
                "This interpreter supports free-threading, but the GIL is currently enabled."
            )
            if restart_btn is not None:
                restart_btn.configure(state="normal")
        else:
            status_var.set("Already running with GIL disabled.")
            if restart_btn is not None:
                restart_btn.configure(state="disabled")

    def _on_request_gil_toggle(self) -> None:
        """Handle request GIL toggle.
        Used as an event callback for request GIL toggle."""
        enabled = bool(self._dev_request_gil_var.get())
        settings["dev_request_gil_disabled"] = enabled
        self._schedule_save_settings()
        if not enabled:
            self._refresh_free_threading_status()
            return
        supports = _supports_free_threading_build()
        self._refresh_free_threading_status()
        if not supports:
            self._show_vscode_interpreter_prompt()
            return

    def _restart_with_gil_disabled(self) -> None:
        """Perform restart with GIL disabled.
        Used to keep the workflow logic localized and testable."""
        if not _supports_free_threading_build():
            try:
                messagebox.showerror(
                    "Restart",
                    "This interpreter does not support free-threading.",
                    parent=self,
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        exe = sys.executable
        if not exe:
            try:
                messagebox.showerror(
                    "Restart",
                    "Unable to determine the current Python executable.",
                    parent=self,
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        argv = list(sys.argv)
        gil_flag_present = False
        # Iterate over indexed elements from argv[1 to apply the per-item logic.
        for idx, arg in enumerate(argv[1:], start=1):
            if arg.startswith("-Xgil=") or arg == "-Xgil=0":
                gil_flag_present = True
                break
            if arg == "-X" and idx + 1 < len(argv):
                if argv[idx + 1].startswith("gil="):
                    gil_flag_present = True
                    break

        new_args = [exe]
        if not gil_flag_present:
            new_args.extend(["-X", "gil=0"])
        new_args.extend(argv[1:])

        try:
            self.save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        os.environ["PYTHON_GIL"] = "0"
        try:
            os.execv(exe, new_args)
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Restart",
                    f"Failed to restart with GIL disabled:\n{exc}",
                    parent=self,
                )
            except Exception:
                pass

    def _show_vscode_interpreter_prompt(self) -> None:
        """Perform show vscode interpreter prompt.
        Used to keep the workflow logic localized and testable."""
        dialog = tk.Toplevel(self)
        dialog.title("Action Required: Switch Python Interpreter in VS Code")
        dialog.transient(self)
        dialog.resizable(False, False)
        dialog.grab_set()

        steps = "\n".join(
            [
                "1. Open the Command Palette in VS Code (Ctrl+Shift+P)",
                '2. Select "Python: Select Interpreter"',
                "3. Choose the Python 3.14 free-threaded interpreter "
                "(often marked with a 't' or \"free-threading\")",
                "4. Run this program again from VS Code",
            ]
        )
        if not _is_running_under_vscode():
            steps = (
                steps
                + "\n"
                + "If you are not launching this program from VS Code, you must "
                + "instead run it using a free-threaded python.exe directly."
            )

        body_lines = [
            "This program is currently running on a standard Python interpreter.",
            "Disabling the GIL requires a free-threaded Python 3.14 build.",
            "Select the free-threaded interpreter in VS Code using these steps:",
            "",
            steps,
        ]

        message = tk.Label(
            dialog,
            text="\n".join(body_lines),
            justify="left",
            wraplength=self._scale_length(520),
        )
        message.grid(row=0, column=0, columnspan=3, sticky="w", padx=12, pady=(12, 8))

        # Closure captures _show_vscode_interpreter_prompt local context to keep helper logic scoped and invoked directly within _show_vscode_interpreter_prompt.
        def _copy_steps() -> None:
            """Perform copy steps.
            Used to keep the workflow logic localized and testable."""
            try:
                self.clipboard_clear()
                self.clipboard_append(steps)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Closure captures _show_vscode_interpreter_prompt local context to keep helper logic scoped and invoked directly within _show_vscode_interpreter_prompt.
        def _quit_now() -> None:
            """Perform quit now.
            Used to keep the workflow logic localized and testable."""
            try:
                self.save_and_close()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Closure captures _show_vscode_interpreter_prompt state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _show_vscode_interpreter_prompt.
        def _cancel() -> None:
            """Perform cancel.
            Used to keep the workflow logic localized and testable."""
            try:
                dialog.grab_release()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                dialog.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        ttk.Button(dialog, text="Copy Steps", command=_copy_steps).grid(
            row=1, column=0, sticky="w", padx=12, pady=(0, 12)
        )
        ttk.Button(
            dialog,
            text="Quit Now (I'll relaunch from VS Code)",
            command=_quit_now,
        ).grid(row=1, column=1, padx=6, pady=(0, 12))
        ttk.Button(dialog, text="Cancel", command=_cancel).grid(
            row=1, column=2, sticky="e", padx=12, pady=(0, 12)
        )

        dialog.protocol("WM_DELETE_WINDOW", _cancel)
        dialog.wait_window(dialog)

    def _open_dependency_audit_dialog(self) -> None:
        """Open dependency audit dialog.
        Used by UI actions to open dependency audit dialog."""
        existing = getattr(self, "_dependency_audit_dialog", None)
        if existing is not None and existing.winfo_exists():
            existing.deiconify()
            existing.lift()
            return

        dialog = tk.Toplevel(self)
        dialog.title("Dependency Free-Threading Audit")
        dialog.geometry("760x520")
        dialog.transient(self)
        dialog.columnconfigure(0, weight=1)
        dialog.rowconfigure(1, weight=1)
        self._dependency_audit_dialog = dialog

        header = ttk.Label(
            dialog,
            text="Audit imported dependencies for free-threading compatibility.",
        )
        header.grid(row=0, column=0, sticky="w", padx=10, pady=(10, 6))

        output = scrolledtext.ScrolledText(dialog, wrap="word", state="disabled")
        output.grid(row=1, column=0, sticky="nsew", padx=10, pady=(0, 8))
        self._dependency_audit_output = output

        button_frame = ttk.Frame(dialog)
        button_frame.grid(row=2, column=0, sticky="e", padx=10, pady=(0, 10))
        ttk.Button(
            button_frame, text="Run Audit", command=self._run_dependency_audit_async
        ).grid(row=0, column=0, padx=4)
        copy_btn = ttk.Button(
            button_frame,
            text="Copy Report (JSON)",
            command=self._copy_dependency_audit_report,
            state="disabled",
        )
        copy_btn.grid(row=0, column=1, padx=4)
        self._dependency_audit_copy_btn = copy_btn

    def _run_dependency_audit_async(self) -> None:
        """Run dependency audit async.
        Used to execute dependency audit async and coordinate results."""
        output = getattr(self, "_dependency_audit_output", None)
        if output is not None and output.winfo_exists():
            output.configure(state="normal")
            output.delete("1.0", tk.END)
            output.insert("end", "Running dependency audit...\n")
            output.configure(state="disabled")

        # Closure captures _run_dependency_audit_async state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _run_dependency_audit_async.
        def _worker():
            """Perform worker.
            Used to keep the workflow logic localized and testable."""
            return _run_dependency_audit()

        # Closure captures _run_dependency_audit_async state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _run_dependency_audit_async.
        def _on_ok(report):
            """Handle ok.
            Used as an event callback for ok."""
            self._dependency_audit_report = report
            self._render_dependency_audit_report(report)
            copy_btn = getattr(self, "_dependency_audit_copy_btn", None)
            if copy_btn is not None and copy_btn.winfo_exists():
                copy_btn.configure(state="normal")

            if not self._gil_import_warning_shown and _supports_free_threading_build():
                if _STARTUP_GIL_STATUS is False:
                    # Iterate over report.get("dependencies", []) to apply the per-item logic.
                    for entry in report.get("dependencies", []):
                        if entry.get("gil_changed"):
                            try:
                                messagebox.showwarning(
                                    "Free-Threading Warning",
                                    "Free-threading was disabled after importing "
                                    f"{entry.get('name')}. See Developer Tools -> Dependency Free-Threading Audit.",
                                    parent=self,
                                )
                            except Exception:
                                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                                pass
                            self._gil_import_warning_shown = True
                            break

        # Closure captures _run_dependency_audit_async state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _run_dependency_audit_async.
        def _on_err(exc):
            """Handle err.
            Used as an event callback for err."""
            output = getattr(self, "_dependency_audit_output", None)
            if output is None or not output.winfo_exists():
                return
            output.configure(state="normal")
            output.delete("1.0", tk.END)
            output.insert("end", f"Dependency audit failed: {exc}\n")
            output.configure(state="disabled")

        self._task_runner.submit("dependency_audit", _worker, _on_ok, _on_err)

    def _render_dependency_audit_report(self, report: Dict[str, Any]) -> None:
        """Render dependency audit report.
        Used to draw dependency audit report for preview or export workflows."""
        output = getattr(self, "_dependency_audit_output", None)
        if output is None or not output.winfo_exists():
            return
        output.configure(state="normal")
        output.delete("1.0", tk.END)
        output.insert("end", "Dependency Free-Threading Audit\n")
        output.insert("end", f"Timestamp: {report.get('timestamp')}\n")
        output.insert("end", f"Python: {report.get('python_version')}\n")
        output.insert("end", f"Platform: {report.get('platform')}\n")
        output.insert("end", f"GIL status: {report.get('gil_status')}\n")
        output.insert(
            "end",
            f"Free-threading supported: {report.get('free_threading_supported')}\n",
        )
        output.insert("end", "\n")
        # Iterate over report.get("dependencies", []) to apply the per-item logic.
        for entry in report.get("dependencies", []):
            name = entry.get("name")
            imported = bool(entry.get("imported"))
            version = entry.get("version")
            error = entry.get("error")
            status = "PASS"
            if not imported:
                status = "FAIL"
            elif entry.get("gil_changed"):
                status = "WARN"
            line = f"{status} - {name}"
            if version:
                line += f" ({version})"
            output.insert("end", line + "\n")
            if error:
                output.insert("end", f"    Error: {error}\n")
        output.configure(state="disabled")

    def _copy_dependency_audit_report(self) -> None:
        """Perform copy dependency audit report.
        Used to keep the workflow logic localized and testable."""
        report = getattr(self, "_dependency_audit_report", None)
        if not isinstance(report, dict):
            return
        try:
            payload = json.dumps(report, indent=2, ensure_ascii=False)
            self.clipboard_clear()
            self.clipboard_append(payload)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _open_concurrency_controls_dialog(self) -> None:
        """Open concurrency controls dialog.
        Used by UI actions to open concurrency controls dialog."""
        existing = getattr(self, "_concurrency_control_dialog", None)
        if existing is not None and existing.winfo_exists():
            existing.deiconify()
            existing.lift()
            return

        dialog = tk.Toplevel(self)
        dialog.title("Concurrency Controls")
        dialog.geometry("420x220")
        dialog.transient(self)
        dialog.columnconfigure(0, weight=1)
        self._concurrency_control_dialog = dialog

        ttk.Label(
            dialog, text="Developer-only settings for the background task runner."
        ).grid(row=0, column=0, sticky="w", padx=10, pady=(10, 6))

        row_frame = ttk.Frame(dialog)
        row_frame.grid(row=1, column=0, sticky="w", padx=10, pady=(0, 6))
        ttk.Label(row_frame, text="Worker threads:").grid(row=0, column=0, sticky="w")
        spin = ttk.Spinbox(
            row_frame,
            from_=1,
            to=32,
            textvariable=self._dev_worker_threads_var,
            width=6,
            command=self._apply_concurrency_controls,
        )
        spin.grid(row=0, column=1, padx=(6, 0))

        ttk.Checkbutton(
            dialog,
            text="Enable parallel compute (developer option)",
            variable=self._dev_parallel_compute_var,
            command=self._apply_concurrency_controls,
        ).grid(row=2, column=0, sticky="w", padx=10, pady=(0, 6))

        ttk.Label(
            dialog,
            text="Defaults remain single-threaded unless you opt in here.",
            wraplength=self._scale_length(380),
            justify="left",
        ).grid(row=3, column=0, sticky="w", padx=10, pady=(0, 10))

    def _open_performance_diagnostics_dialog(self) -> None:
        """Open performance diagnostics dialog.
        Used by UI actions to open performance diagnostics dialog."""
        existing = getattr(self, "_perf_diag_dialog", None)
        if existing is not None and existing.winfo_exists():
            existing.deiconify()
            existing.lift()
            self._refresh_performance_diagnostics()
            return

        dialog = tk.Toplevel(self)
        dialog.title("Performance Diagnostics")
        dialog.geometry("720x420")
        dialog.transient(self)
        dialog.columnconfigure(0, weight=1)
        dialog.rowconfigure(2, weight=1)
        self._perf_diag_dialog = dialog

        ttk.Label(
            dialog,
            text="Capture timing diagnostics for render and embed stages.",
        ).grid(row=0, column=0, sticky="w", padx=10, pady=(10, 6))

        ttk.Checkbutton(
            dialog,
            text="Enable diagnostics (session only)",
            variable=self._perf_diag_enabled_var,
            command=self._refresh_performance_diagnostics,
        ).grid(row=1, column=0, sticky="w", padx=10, pady=(0, 6))

        output = scrolledtext.ScrolledText(dialog, wrap="word", state="disabled")
        output.grid(row=2, column=0, sticky="nsew", padx=10, pady=(0, 8))
        self._perf_diag_output = output

        button_frame = ttk.Frame(dialog)
        button_frame.grid(row=3, column=0, sticky="e", padx=10, pady=(0, 10))
        ttk.Button(
            button_frame, text="Close", command=dialog.destroy
        ).grid(row=0, column=0, padx=4)

        self._refresh_performance_diagnostics()

    def _refresh_performance_diagnostics(self) -> None:
        """Refresh performance diagnostics.
        Used to sync performance diagnostics display with current state."""
        output = getattr(self, "_perf_diag_output", None)
        if output is None or not output.winfo_exists():
            return
        enabled = bool(self._perf_diag_enabled_var.get())
        report = self._perf_diag_last_run
        if not enabled:
            body = "Diagnostics disabled."
        elif not report:
            body = "No diagnostics captured yet."
        else:
            body = self._format_performance_report(report)
        output.configure(state="normal")
        output.delete("1.0", tk.END)
        output.insert("end", body + "\n")
        output.configure(state="disabled")

    def _format_performance_report(self, report: Dict[str, Any]) -> str:
        """Format performance report.
        Used to format performance diagnostics for display."""
        lines = []
        plot_kind = report.get("plot_kind") or "unknown"
        target = report.get("target") or "display"
        timestamp = report.get("timestamp") or ""
        lines.append(f"Plot: {plot_kind}")
        lines.append(f"Target: {target}")
        if timestamp:
            lines.append(f"Timestamp: {timestamp}")
        stages = report.get("stages") or {}
        lines.append("")
        for key in ("prepared", "cycle", "combined", "embed"):
            entry = stages.get(key)
            if not isinstance(entry, dict):
                continue
            ms = entry.get("ms")
            cache = entry.get("cache")
            path = entry.get("path")
            extra = entry.get("extra")
            if ms is None:
                continue
            line = f"{key}: {ms:.2f} ms"
            if cache:
                line += f" ({cache})"
            if path:
                line += f" [{path}]"
            if extra:
                line += f" {extra}"
            lines.append(line)
            if key == "combined" and entry.get("layout_ms") is not None:
                lines.append(f"layout: {entry['layout_ms']:.2f} ms")
        return "\n".join(lines)

    def _record_performance_run(self, report: Dict[str, Any]) -> None:
        """Record performance run.
        Used to persist a performance diagnostics snapshot."""
        self._perf_diag_last_run = report
        self._refresh_performance_diagnostics()

    def _configure_debug_logging(self) -> None:
        """Configure debug logging handlers and levels.

        Purpose:
            Ensure logging output is wired consistently for debug categories.
        Why:
            Keeps debug output centralized and toggled via Developer Tools.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Adds/removes logging handlers and updates logger levels.
        Exceptions:
            Best-effort guards prevent logging setup from crashing the UI.
        """
        try:
            logger = _GL260_LOGGER
            enabled = bool(self._debug_enabled)
            file_enabled = bool(self._debug_file_logging_enabled)
            level = logging.DEBUG if enabled else logging.WARNING
            logger.setLevel(level)

            if self._debug_log_handler is None:
                handler = logging.StreamHandler()
                handler.setFormatter(
                    logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
                )
                self._debug_log_handler = handler
                logger.addHandler(handler)
            if self._debug_log_handler is not None:
                self._debug_log_handler.setLevel(level)

            if file_enabled:
                if self._debug_file_handler is None:
                    settings_dir = os.path.dirname(os.path.abspath(SETTINGS_FILE)) or "."
                    log_path = os.path.join(settings_dir, DEBUG_LOG_FILE)
                    handler = RotatingFileHandler(
                        log_path, maxBytes=1_000_000, backupCount=3, encoding="utf-8"
                    )
                    handler.setFormatter(
                        logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
                    )
                    self._debug_file_handler = handler
                    logger.addHandler(handler)
                if self._debug_file_handler is not None:
                    self._debug_file_handler.setLevel(level)
            elif self._debug_file_handler is not None:
                try:
                    logger.removeHandler(self._debug_file_handler)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                try:
                    self._debug_file_handler.close()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                self._debug_file_handler = None
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _persist_debug_settings(self) -> None:
        """Persist debug settings to disk.

        Purpose:
            Save debug-related settings immediately after a toggle change.
        Why:
            Ensures Developer Tools choices persist across restarts.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Writes to settings.json via the existing save pathway.
        Exceptions:
            Best-effort guard suppresses persistence errors.
        """
        settings["debug_enabled"] = bool(self._debug_enabled)
        settings["debug_categories"] = dict(self._debug_categories)
        settings["debug_file_logging_enabled"] = bool(
            self._debug_file_logging_enabled
        )
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _set_disable_startup_tab_cycling(self, enabled: bool) -> None:
        """Apply startup tab-cycling preference and persist it.

        Purpose:
            Update the Developer Tools toggle that controls startup warmup
            tab cycling.
        Why:
            Developers need a persistent way to keep startup splash visible while
            readiness is verified without notebook tab-selection churn.
        Inputs:
            enabled: True to disable startup tab cycling; False to keep warmup
                cycling.
        Outputs:
            None.
        Side Effects:
            Updates the Tk variable, writes
            `settings["dev_disable_startup_tab_cycling"]`, persists settings to
            disk, and emits a debug log message.
        Exceptions:
            Persistence and widget updates are guarded so toggle changes do not
            interrupt runtime interactions.
        """
        normalized_enabled = bool(enabled)
        settings["dev_disable_startup_tab_cycling"] = normalized_enabled
        toggle_var = getattr(self, "_dev_disable_startup_tab_cycling_var", None)
        if toggle_var is not None:
            try:
                toggle_var.set(normalized_enabled)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._dbg(
            "ui.events",
            "Startup tab cycling preference updated: disabled=%s",
            normalized_enabled,
            once_key=None,
        )

    def _set_debug_enabled(self, enabled: bool) -> None:
        """Apply the global debug enable toggle.

        Purpose:
            Update global debug state from the Developer Tools menu.
        Why:
            Centralizes gating for all debug logging and perf instrumentation.
        Args:
            enabled: True to enable debug logging; False to disable it.
        Returns:
            None.
        Side Effects:
            Updates settings, logging configuration, and cached debug state.
        Exceptions:
            Best-effort guards prevent UI failures on invalid state.
        """
        self._debug_enabled = bool(enabled)
        if self._debug_enabled_var is not None:
            try:
                self._debug_enabled_var.set(self._debug_enabled)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._configure_debug_logging()
        self._persist_debug_settings()

    def _set_debug_file_logging_enabled(self, enabled: bool) -> None:
        """Apply the debug file logging toggle.

        Purpose:
            Enable or disable the rotating file handler for debug logs.
        Why:
            Lets developers capture debug output without console spam.
        Args:
            enabled: True to enable file logging; False to disable it.
        Returns:
            None.
        Side Effects:
            Updates settings and reconfigures logging handlers.
        Exceptions:
            Best-effort guards prevent UI failures on invalid state.
        """
        self._debug_file_logging_enabled = bool(enabled)
        if self._debug_file_logging_var is not None:
            try:
                self._debug_file_logging_var.set(self._debug_file_logging_enabled)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._configure_debug_logging()
        self._persist_debug_settings()

    def _set_debug_category_enabled(self, category: str, enabled: bool) -> None:
        """Apply a per-category debug toggle.

        Purpose:
            Update a single debug category based on the menu toggle state.
        Why:
            Allows selective debug output without enabling all categories.
        Args:
            category: Category key to update.
            enabled: True to enable the category; False to disable it.
        Returns:
            None.
        Side Effects:
            Updates settings and in-memory category state.
        Exceptions:
            Best-effort guards prevent UI failures on invalid input.
        """
        if category not in DEBUG_CATEGORIES:
            return
        self._debug_categories[category] = bool(enabled)
        var = self._debug_category_vars.get(category)
        if var is not None:
            try:
                var.set(bool(enabled))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._persist_debug_settings()

    def _is_debug_category_enabled(self, category: str) -> bool:
        """Return whether a debug category is active.

        Purpose:
            Provide a cheap gate before emitting debug output.
        Why:
            Ensures debug logging is disabled by default and cheap when off.
        Args:
            category: Category key to evaluate.
        Returns:
            True when global debug and the category are enabled.
        Side Effects:
            None.
        Exceptions:
            None.
        """
        if not self._debug_enabled:
            return False
        return bool(self._debug_categories.get(category, False))

    def _log(
        self,
        category: str,
        level: int,
        msg: str,
        *args: Any,
        once_key: Optional[str] = None,
    ) -> None:
        """Emit a structured log message for a debug category.

        Purpose:
            Route debug output through the centralized logging backend.
        Why:
            Keeps debug output consistent and lazy-formatted across the app.
        Args:
            category: Category key that gates the log output.
            level: Logging level (e.g., logging.DEBUG).
            msg: Log message template using %-style placeholders.
            *args: Arguments for lazy formatting.
            once_key: Optional token for one-shot logging suppression.
        Returns:
            None.
        Side Effects:
            Writes to the configured logger when enabled.
        Exceptions:
            Best-effort guards suppress logging failures.
        """
        if not self._is_debug_category_enabled(category):
            return
        if once_key:
            token = (category, once_key)
            if token in self._debug_once:
                return
            self._debug_once.add(token)
        try:
            _GL260_LOGGER.log(level, "[%s] " + msg, category, *args)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _dbg(
        self, category: str, msg: str, *args: Any, once_key: Optional[str] = None
    ) -> None:
        """Emit a debug-level log for a category.

        Purpose:
            Provide a convenience wrapper for debug logging.
        Why:
            Keeps call sites concise while enforcing gating rules.
        Args:
            category: Category key that gates the log output.
            msg: Log message template using %-style placeholders.
            *args: Arguments for lazy formatting.
            once_key: Optional token for one-shot logging suppression.
        Returns:
            None.
        Side Effects:
            Writes to the configured logger when enabled.
        Exceptions:
            Best-effort guards suppress logging failures.
        """
        self._log(category, logging.DEBUG, msg, *args, once_key=once_key)

    def _dbg_exc(
        self, category: str, msg: str, exc: Optional[BaseException] = None
    ) -> None:
        """Emit a debug-level exception log for a category.

        Purpose:
            Capture exceptions with context when debug logging is enabled.
        Why:
            Helps diagnose failures without interrupting workflows.
        Args:
            category: Category key that gates the log output.
            msg: Message describing the exception context.
            exc: Optional exception to include; uses current traceback if None.
        Returns:
            None.
        Side Effects:
            Writes to the configured logger when enabled.
        Exceptions:
            Best-effort guards suppress logging failures.
        """
        if not self._is_debug_category_enabled(category):
            return
        try:
            if exc is not None:
                _GL260_LOGGER.exception("[%s] %s: %s", category, msg, exc)
            else:
                _GL260_LOGGER.exception("[%s] %s", category, msg)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _perf_record(self, category: str, label: str, value: float) -> None:
        """Record a performance metric sample.

        Purpose:
            Aggregate timing or counter values for later inspection.
        Why:
            Provides cheap profiling while avoiding per-event log spam.
        Args:
            category: Category key used for gating and grouping.
            label: Human-readable metric label.
            value: Sample value (seconds for timers, count for counters).
        Returns:
            None.
        Side Effects:
            Updates in-memory performance stats.
        Exceptions:
            Best-effort guards suppress aggregation failures.
        """
        if not self._debug_enabled:
            return
        if not (
            self._debug_categories.get("perf.timing", False)
            or self._debug_categories.get(category, False)
        ):
            return
        try:
            with self._perf_stats_lock:
                key = (category, label)
                stats = self._perf_stats.get(key)
                if stats is None:
                    stats = {"count": 0, "total": 0.0, "min": value, "max": value}
                    self._perf_stats[key] = stats
                stats["count"] = int(stats.get("count", 0)) + 1
                stats["total"] = float(stats.get("total", 0.0)) + float(value)
                stats["min"] = (
                    float(value)
                    if stats.get("min") is None
                    else min(float(stats["min"]), float(value))
                )
                stats["max"] = (
                    float(value)
                    if stats.get("max") is None
                    else max(float(stats["max"]), float(value))
                )
                stats["last"] = float(value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _perf_count(self, category: str, label: str, delta: float = 1.0) -> None:
        """Record a counter increment for performance stats.

        Purpose:
            Aggregate hit/miss or event counters without logging each event.
        Why:
            Keeps cache and workflow stats cheap when enabled.
        Args:
            category: Category key used for gating and grouping.
            label: Human-readable metric label.
            delta: Amount to add to the counter.
        Returns:
            None.
        Side Effects:
            Updates in-memory performance stats.
        Exceptions:
            Best-effort guards suppress aggregation failures.
        """
        self._perf_record(category, label, float(delta))

    def _perf_time(
        self, category: str, label: str, once_key: Optional[str] = None
    ) -> Any:
        """Return a context manager that records elapsed time.

        Purpose:
            Time a code block when performance instrumentation is enabled.
        Why:
            Provides cheap timing without overhead when disabled.
        Args:
            category: Category key used for gating and grouping.
            label: Human-readable metric label.
            once_key: Optional token for one-shot timing suppression.
        Returns:
            A context manager that records elapsed time when enabled.
        Side Effects:
            Updates in-memory performance stats when enabled.
        Exceptions:
            Best-effort guards suppress timing failures.
        """
        if not self._debug_enabled:
            return self._perf_noop
        if not (
            self._debug_categories.get("perf.timing", False)
            or self._debug_categories.get(category, False)
        ):
            return self._perf_noop
        if once_key:
            token = (category, once_key)
            if token in self._debug_once:
                return self._perf_noop
            self._debug_once.add(token)

        class _PerfTimer:
            def __init__(self, app: "UnifiedApp", cat: str, lab: str) -> None:
                """Initialize the timer context.

                Purpose:
                    Store the timer context parameters for later recording.
                Why:
                    Keeps the timing logic encapsulated for perf tracking.
                Args:
                    app: UnifiedApp instance that receives the perf record.
                    cat: Category key for the perf stats.
                    lab: Label for the perf stats entry.
                Returns:
                    None.
                Side Effects:
                    Stores references to app and timing metadata.
                Exceptions:
                    None.
                """
                self._app = app
                self._cat = cat
                self._lab = lab
                self._start = None

            def __enter__(self):
                """Start timing the context block.

                Purpose:
                    Capture the start timestamp for elapsed time measurement.
                Why:
                    Allows consistent timing with minimal caller overhead.
                Args:
                    None.
                Returns:
                    Self, enabling 'as' usage in context managers.
                Side Effects:
                    Records the start time.
                Exceptions:
                    None.
                """
                self._start = time.perf_counter()
                return self

            def __exit__(self, exc_type, exc, tb):
                """Stop timing and record the elapsed duration.

                Purpose:
                    Finalize the timing and store the sample in perf stats.
                Why:
                    Ensures timers are aggregated without leaking exceptions.
                Args:
                    exc_type: Exception type if raised in the context block.
                    exc: Exception instance if raised in the context block.
                    tb: Traceback if raised in the context block.
                Returns:
                    False to propagate exceptions from the context block.
                Side Effects:
                    Updates performance stats with the elapsed duration.
                Exceptions:
                    None.
                """
                if self._start is None:
                    return False
                elapsed = time.perf_counter() - self._start
                self._app._perf_record(self._cat, self._lab, elapsed)
                return False

        return _PerfTimer(self, category, label)

    def _format_performance_stats(self) -> str:
        """Format aggregated performance stats for display.

        Purpose:
            Render the current performance counters/timers as readable text.
        Why:
            Supports the Developer Tools "Dump Performance Stats" action.
        Args:
            None.
        Returns:
            Multi-line string of formatted performance stats.
        Side Effects:
            None.
        Exceptions:
            Best-effort guards suppress formatting failures.
        """
        try:
            with self._perf_stats_lock:
                items = list(self._perf_stats.items())
        except Exception:
            items = []
        if not items:
            return "No performance stats captured."
        lines = []
        # Iterate over sorted items to apply the per-item logic.
        for (category, label), stats in sorted(items, key=lambda item: item[0]):
            count = int(stats.get("count", 0))
            total = float(stats.get("total", 0.0))
            min_val = stats.get("min")
            max_val = stats.get("max")
            last_val = stats.get("last")
            lines.append(
                f"{category} | {label}: "
                f"count={count} total={total:.6f} "
                f"min={min_val:.6f} max={max_val:.6f} last={last_val:.6f}"
            )
        return "\n".join(lines)

    def _dump_performance_stats(self) -> None:
        """Dump performance stats to the debug logger and UI.

        Purpose:
            Provide a quick snapshot of aggregated perf counters/timers.
        Why:
            Supports the Developer Tools action for performance inspection.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Logs to the debug logger and shows a messagebox summary.
        Exceptions:
            Best-effort guards suppress UI failures.
        """
        body = self._format_performance_stats()
        self._dbg("perf.timing", "Performance stats dump:\n%s", body, once_key=None)
        try:
            messagebox.showinfo("Performance Stats", body)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _dump_debug_settings(self) -> None:
        """Dump debug settings to the debug logger and UI.

        Purpose:
            Show the current debug enable state and category toggles.
        Why:
            Helps developers confirm which categories are active.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Logs to the debug logger and shows a messagebox summary.
        Exceptions:
            Best-effort guards suppress UI failures.
        """
        categories = [
            f"{name}={bool(self._debug_categories.get(name, False))}"
            for name in DEBUG_CATEGORIES
        ]
        lines = [
            f"debug_enabled={bool(self._debug_enabled)}",
            f"debug_file_logging_enabled={bool(self._debug_file_logging_enabled)}",
            "categories: " + ", ".join(categories),
        ]
        body = "\n".join(lines)
        self._dbg("ui.events", "Debug settings dump:\n%s", body, once_key=None)
        try:
            messagebox.showinfo("Debug Settings", body)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _clear_debug_once_guards(self) -> None:
        """Clear one-shot debug suppression tokens.

        Purpose:
            Reset the once-only debug guard cache for renewed logging.
        Why:
            Allows repeated debug output after it was suppressed once.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Clears the in-memory once-key cache.
        Exceptions:
            Best-effort guards suppress UI failures.
        """
        try:
            self._debug_once.clear()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._dbg("ui.events", "Debug once-guards cleared.")

    def _apply_concurrency_controls(self) -> None:
        """Apply concurrency controls.
        Used to apply concurrency controls changes to live state."""
        try:
            threads = int(self._dev_worker_threads_var.get())
        except Exception:
            threads = 1
        threads = max(1, threads)
        enabled = bool(self._dev_parallel_compute_var.get())
        settings["dev_worker_threads"] = threads
        settings["dev_enable_parallel_compute"] = enabled
        self._dev_worker_threads_var.set(threads)
        self._task_runner.set_max_workers(threads if enabled else 1)
        self._schedule_save_settings()

    def _run_timeline_table_export_validation(self) -> None:
        """Run timeline table export validation.
        Used to execute timeline table export validation and coordinate results."""
        try:
            success, out_dir, outputs, errors = _dev_test_timeline_table_export()
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Timeline Table Export Validation",
                    f"Validation crashed: {exc}",
                )
            except Exception:
                pass
            return
        files_text = "\n".join(str(path) for path in outputs) or "None"
        errors_text = "\n".join(errors) or "None"
        summary = (
            "Output folder:\n"
            f"{out_dir}\n\n"
            "Generated files:\n"
            f"{files_text}\n\n"
            "Failures:\n"
            f"{errors_text}"
        )
        title = "Timeline Table Export Validation"
        try:
            if success:
                messagebox.showinfo(title, summary)
            else:
                messagebox.showwarning(title, summary)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _run_solubility_regression(self) -> None:
        """Run solubility regression.
        Used to execute solubility regression and coordinate results."""

        self._open_regression_checks_dialog()

    def _on_solubility_regression_complete(self, success: bool, message: str) -> None:
        """Handle solubility regression complete.
        Used as an event callback for solubility regression complete."""

        self._sol_regression_task_id = None
        summary = (message or "").strip()
        if len(summary) > 2000:
            summary = summary[:2000].rstrip() + "\n… (output truncated)"
        if success:
            title = "Solubility Regression Completed"
            body = summary or "Regression checks completed successfully."
            try:
                messagebox.showinfo(title, body)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        else:
            title = "Solubility Regression Failed"
            body = summary or "See console output for additional details."
            try:
                messagebox.showerror(title, body)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _screen_font_multiplier(self):
        """Perform screen font multiplier.
        Used to keep the workflow logic localized and testable."""
        scale = getattr(self, "_ui_scale", 1.0) or 1.0
        if scale >= 1.0:
            return min(scale * 1.1, 2.5)
        return max(0.75, 1.0 - (1.0 - scale) * 0.4)

    def _geometry_fits_screen(self, geometry):
        """Perform geometry fits screen.
        Used to keep the workflow logic localized and testable."""
        if not geometry:
            return False
        try:
            size_part = geometry.split("+", 1)[0]
            width_str, height_str = size_part.split("x", 1)
            width = int(width_str)
            height = int(height_str)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return False
        try:
            screen_w = self.winfo_screenwidth()
            screen_h = self.winfo_screenheight()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return True
        return width <= screen_w and height <= screen_h

    def _apply_plot_elements_editor_geometry(
        self, editor: tk.Toplevel, ui_state: Mapping[str, Any]
    ) -> None:
        """Apply screen-safe geometry defaults for the Plot Elements editor.

        Purpose:
            Normalize persisted Plot Elements editor geometry before opening.
        Why:
            Persisted geometry can become oversized or partially off-screen after
            monitor/layout changes, which can hide key controls.
        Args:
            editor: Plot Elements toplevel window receiving geometry updates.
            ui_state: Persisted per-plot annotations UI state dictionary.
        Returns:
            None.
        Side Effects:
            Updates editor geometry and initial on-screen position.
        Exceptions:
            Uses best-effort guards so geometry issues do not block editor open.
        """
        min_w = int(self._scale_length(960))
        min_h = int(self._scale_length(620))
        preferred_w = int(self._scale_length(1160))
        preferred_h = int(self._scale_length(740))

        try:
            screen_w = int(editor.winfo_screenwidth())
            screen_h = int(editor.winfo_screenheight())
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            screen_w = 0
            screen_h = 0

        max_w = max(
            min_w, int(screen_w * 0.92) if screen_w > 0 else int(preferred_w)
        )
        max_h = max(
            min_h, int(screen_h * 0.90) if screen_h > 0 else int(preferred_h)
        )
        fallback_w = max(min_w, min(preferred_w, max_w))
        fallback_h = max(min_h, min(preferred_h, max_h))

        raw_geometry = (
            ui_state.get("editor_geometry") if isinstance(ui_state, Mapping) else None
        )
        parsed_width: Optional[int] = None
        parsed_height: Optional[int] = None
        parsed_x: Optional[int] = None
        parsed_y: Optional[int] = None
        if isinstance(raw_geometry, str):
            match = re.match(
                r"^\s*(\d+)x(\d+)(?:\+(-?\d+)\+(-?\d+))?\s*$", raw_geometry.strip()
            )
            if match is not None:
                try:
                    parsed_width = int(match.group(1))
                    parsed_height = int(match.group(2))
                    if match.group(3) is not None and match.group(4) is not None:
                        parsed_x = int(match.group(3))
                        parsed_y = int(match.group(4))
                except Exception:
                    parsed_width = None
                    parsed_height = None
                    parsed_x = None
                    parsed_y = None

        width = (
            fallback_w
            if parsed_width is None
            else max(min_w, min(max_w, int(parsed_width)))
        )
        height = (
            fallback_h
            if parsed_height is None
            else max(min_h, min(max_h, int(parsed_height)))
        )

        # Keep restored origin visible; otherwise center defaults for first open.
        if screen_w > 0 and screen_h > 0:
            max_x = max(0, screen_w - width)
            max_y = max(0, screen_h - height)
            if parsed_x is None or parsed_y is None:
                pos_x = max(0, int((screen_w - width) / 2))
                pos_y = max(0, int((screen_h - height) / 2))
            else:
                pos_x = max(0, min(max_x, int(parsed_x)))
                pos_y = max(0, min(max_y, int(parsed_y)))
        else:
            pos_x = 60 if parsed_x is None else max(0, int(parsed_x))
            pos_y = 60 if parsed_y is None else max(0, int(parsed_y))

        try:
            editor.geometry(f"{width}x{height}+{pos_x}+{pos_y}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            try:
                editor.geometry(f"{width}x{height}")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _apply_accessible_fonts(self, base_size=10, tab_bold=True):
        """Apply global accessible font settings and refresh dependent styles.

        Purpose:
            Recompute the active UI font family/size and apply them to ttk defaults.
        Why:
            The app supports zoom/font scaling and must keep text sizing coherent
            across controls, menus, toolbars, and notebook tabs.
        Inputs:
            base_size: Requested base font size before display scaling.
            tab_bold: Legacy flag for callers that previously preferred bold tabs.
                Main tabs now intentionally follow button-style typography.
        Outputs:
            None.
        Side Effects:
            Updates Tk named fonts, ttk styles, settings persistence, menu fonts,
            cycle button fonts, toolbar scaling, and main notebook tab styling.
        Exceptions:
            Best-effort guards avoid runtime interruption when toolkit operations fail.
        """
        PREFERRED_FONTS = [
            "Lexend Deca",
            "Atkinson Hyperlegible",
            "Verdana",
            "Tahoma",
            "Arial",
        ]

        try:
            available = set(tkfont.families(self))
        except Exception:
            available = set(tkfont.families())

        chosen = next((f for f in PREFERRED_FONTS if f in available), "Verdana")

        self._base_font_size = max(8, min(int(base_size), 24))
        self._ui_font_family = chosen
        multiplier = self._screen_font_multiplier()
        effective_size = max(8, min(int(round(self._base_font_size * multiplier)), 28))
        self._effective_font_size = effective_size
        self._tab_font_size = max(effective_size - 2, 8)

        base = tkfont.nametofont("TkDefaultFont")
        base.configure(family=chosen, size=effective_size)

        # Iterate to apply the per-item logic.
        for name in (
            "TkTextFont",
            "TkFixedFont",
            "TkMenuFont",
            "TkHeadingFont",
            "TkCaptionFont",
            "TkSmallCaptionFont",
            "TkIconFont",
            "TkTooltipFont",
        ):
            try:
                tkfont.nametofont(name).configure(family=chosen, size=effective_size)
            except tk.TclError:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        style = ttk.Style(self)
        style.configure(".", font=base)
        button_padding = (
            self._scale_length(10),
            self._scale_length(6),
        )
        button_font_size = max(effective_size - 1, 8)
        style.configure(
            "TButton", font=(chosen, button_font_size), padding=button_padding
        )
        style.configure(
            "TMenubutton", font=(chosen, button_font_size), padding=button_padding
        )
        style.configure("TEntry", font=(chosen, effective_size))
        combo_font_size = max(effective_size - 1, 9)
        style.configure("TCombobox", font=(chosen, combo_font_size))

        style.configure("TLabelFrame.Label", font=(chosen, effective_size, "bold"))
        style.configure("Cycle.TButton", font=(chosen, self._tab_font_size))
        style.configure("CycleHint.TLabel", font=(chosen, self._tab_font_size))
        row_height = self._scale_length(28)
        style.configure(
            "Treeview",
            font=(chosen, max(effective_size - 2, 8)),
            rowheight=row_height,
        )
        style.configure(
            "Treeview.Heading",
            font=(chosen, max(effective_size - 1, 9)),
        )
        scrollbar_arrow = self._scale_length(14)
        style.configure("Vertical.TScrollbar", arrowsize=scrollbar_arrow)
        style.configure("Horizontal.TScrollbar", arrowsize=scrollbar_arrow)

        try:
            self.option_add("*TCombobox*Listbox.font", (chosen, combo_font_size))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        settings["ui_font_size"] = self._base_font_size
        self._apply_main_notebook_style(style=style)

        self._refresh_cycle_button_fonts()
        self._refresh_menu_fonts()
        self._apply_toolbar_scaling(getattr(self, "_cycle_toolbar", None))

    def _apply_main_notebook_style(self, style: Optional[ttk.Style] = None) -> None:
        """Apply typography and spacing for the top-level notebook tabs only.

        Purpose:
            Keep main app tab labels visually aligned with CTk-era button typography.
        Why:
            Stage UI migration introduced compact CTk button text sizing; top-level
            tab names should mirror that system without affecting nested notebooks.
        Inputs:
            style: Optional ttk style object to reuse; when omitted, a new instance is
                created for this app context.
        Outputs:
            None.
        Side Effects:
            Configures `Main.TNotebook` / `Main.TNotebook.Tab` style definitions and
            stores style-name attributes used when creating the main notebook widget.
        Exceptions:
            Best-effort guards protect against style/font resolution failures.
        """
        if style is None:
            style = ttk.Style(self)
        base_font = tkfont.nametofont("TkDefaultFont")
        tab_family = getattr(self, "_ui_font_family", base_font.actual("family"))
        effective_size = getattr(
            self, "_effective_font_size", max(int(base_font.actual("size")), 8)
        )
        button_text_size = max(int(effective_size) - 1, 8)
        tab_style_name = getattr(self, "_main_notebook_tab_style", "Main.TNotebook.Tab")
        notebook_style_name = getattr(self, "_main_notebook_style", "Main.TNotebook")
        self._main_notebook_tab_style = tab_style_name
        self._main_notebook_style = notebook_style_name
        tab_padding = (
            self._scale_length(8),
            self._scale_length(4),
            self._scale_length(8),
            self._scale_length(4),
        )
        tab_margins = tuple(self._scale_length(v) for v in (2, 2, 2, 0))
        style.configure(
            tab_style_name,
            font=(tab_family, button_text_size),
            padding=tab_padding,
        )
        style.configure(notebook_style_name, tabmargins=tab_margins)

    def _refresh_cycle_button_fonts(self):
        """Refresh cycle button fonts.
        Used to sync cycle button fonts with current settings."""
        btn_family = getattr(self, "_ui_font_family", "Verdana")
        default_base = getattr(self, "_default_font_size", 10)
        btn_size = getattr(self, "_tab_font_size", max(default_base - 2, 8))
        # Iterate over getattr(self, "_cycle_button_fonts", []) to apply the per-item logic.
        for font_obj in getattr(self, "_cycle_button_fonts", []):
            try:
                current = font_obj.actual()
                font_obj.configure(
                    family=btn_family,
                    size=btn_size,
                    weight=current.get("weight", "normal"),
                    slant=current.get("slant", "roman"),
                )
            except Exception:
                continue

    def _ensure_initial_data_tab_visible(self, _event=None):
        """Finalize Data-tab visibility once startup sequencing is complete.

        Purpose:
            Keep the Data tab selected and interactive after startup transitions.
        Why:
            Startup warmup now runs under splash gating, so this callback should
            only retry while splash is present and avoid visible tab cycling.
        Inputs:
            _event: Optional Tk event payload from `<Map>` or timer callbacks.
        Outputs:
            None.
        Side Effects:
            Clears timer bookkeeping, reschedules itself while splash exists, and
            finalizes Data-tab selection/focus once the notebook is ready.
        Exceptions:
            Best-effort guards prevent failures during early-launch widget churn.
        """
        _ = _event

        # Keep only one retry callback active to avoid stacked startup reschedules.
        after_id = getattr(self, "_initial_tab_after_id", None)
        if after_id is not None:
            try:
                self.after_cancel(after_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._initial_tab_after_id = None

        if getattr(self, "_initial_tab_shown", False):
            return

        startup_overlay = getattr(self, "_startup_loading_overlay", None)
        if startup_overlay is not None:
            try:
                if startup_overlay.winfo_exists():
                    try:
                        self._initial_tab_after_id = self.after(
                            150, self._ensure_initial_data_tab_visible
                        )
                    except Exception:
                        self._initial_tab_after_id = None
                    return
            except Exception:
                # Best-effort guard; continue with default flow.
                pass

        nb = getattr(self, "nb", None)
        data_tab = getattr(self, "tab_data", None)
        if (
            nb is None
            or data_tab is None
            or not getattr(nb, "winfo_exists", lambda: False)()
        ):
            try:
                self._initial_tab_after_id = self.after(
                    150, self._ensure_initial_data_tab_visible
                )
            except Exception:
                self._initial_tab_after_id = None
            return

        # Keep fallback behavior deterministic: finalize Data tab, no visible cycling.
        self._finalize_startup_to_data_tab()

    def _handle_font_increase(self, event):
        """Handle font increase.
        Used as an event callback for font increase."""
        self._adjust_ui_zoom(0.1)
        return "break"

    def _handle_font_decrease(self, event):
        """Handle font decrease.
        Used as an event callback for font decrease."""
        self._adjust_ui_zoom(-0.1)
        return "break"

    def _handle_font_reset(self, event):
        """Handle font reset.
        Used as an event callback for font reset."""
        self._set_global_scale(getattr(self, "_initial_ui_scale", 1.0), reflow=False)
        return "break"

    def _build_ui(self):
        """Build UI.
        Purpose: Assemble the main window layout and widget wiring.
        Why: Centralizes UI construction after state initialization.
        Inputs: None.
        Outputs: None.
        Side effects: Creates/grids widgets, stores widget references, and binds events.
        Exceptions: Best-effort guards are used internally; no intentional raises.
        """
        self._update_startup_loading_splash_progress(
            progress=16.0,
            message="Building Data, Columns, and Plot tabs...",
        )

        # Root uses grid: row 0 (Notebook) grows, row 1 (buttons) stays fixed

        self.grid_rowconfigure(0, weight=1)

        self.grid_rowconfigure(1, weight=0)

        self.grid_columnconfigure(0, weight=1)

        base_font = tkfont.nametofont("TkDefaultFont")

        # --- Bordered shell around the tab strip for a strong, black outline ---

        tabshell = tk.Frame(
            self,
            bd=2,
            relief="solid",
            highlightthickness=1,
            highlightbackground="black",
            highlightcolor="black",
        )

        tabshell.grid(row=0, column=0, sticky="nsew", padx=8, pady=8)

        # Notebook lives inside the bordered shell

        self._main_notebook_style = "Main.TNotebook"
        self._main_notebook_tab_style = "Main.TNotebook.Tab"
        self.nb = ttk.Notebook(tabshell, style=self._main_notebook_style)

        self.nb.pack(fill="both", expand=True)

        style = ttk.Style(self)
        self._apply_main_notebook_style(style=style)

        btn_font_family = getattr(self, "_ui_font_family", base_font.actual("family"))

        btn_font_size = getattr(
            self, "_tab_font_size", max(base_font.actual("size") - 2, 8)
        )

        cycle_pad = (self._scale_length(12), self._scale_length(8))
        style.configure(
            "Cycle.TButton",
            font=(btn_font_family, btn_font_size),  # same size as tab text
            padding=cycle_pad,
        )

        # Make the hint text match the tab/button font size

        style.configure(
            "CycleHint.TLabel",
            font=(
                btn_font_family,
                btn_font_size,
            ),  # same point size as tabs & Cycle buttons
        )

        # Tabs

        self.tab_data = ttk.Frame(self.nb)

        self.tab_columns = ttk.Frame(self.nb)

        self.tab_plot = ttk.Frame(self.nb)
        self._plot_settings_tab = self.tab_plot

        self.tab_cycle = ttk.Frame(self.nb)

        self.tab_contamination = ttk.Frame(self.nb)

        self.tab_solubility = ttk.Frame(self.nb)
        self.tab_solubility_new = ttk.Frame(self.nb)
        self.tab_final_report = ttk.Frame(self.nb)

        self.nb.add(self.tab_data, text="Data")

        self.nb.add(self.tab_columns, text="Columns")

        self.nb.add(self.tab_plot, text="Plot Settings")

        self.nb.add(self.tab_cycle, text="Cycle Analysis")
        self._cycle_tab_added = True

        # Build the tabs we do have now

        self._build_tab_data()

        self._build_tab_columns()

        self._build_tab_plot()
        self._update_startup_loading_splash_progress(
            progress=34.0,
            message="Building deferred Cycle Analysis layout...",
        )

        # Cycle Analysis tab builds in deferred stages to reduce startup blocking.

        self._start_cycle_tab_build(defer=True)
        self._update_startup_loading_splash_progress(
            progress=44.0,
            message="Building secondary analysis tabs...",
        )

        self._build_tab_contamination()

        self._apply_contamination_tab_visibility(initial=True)

        self._build_tab_solubility()
        self._build_tab_solubility_new()
        self.nb.add(self.tab_final_report, text="Final Report")
        self._build_tab_final_report()
        self._update_startup_loading_splash_progress(
            progress=58.0,
            message="Finalizing base startup layout...",
        )

        self._apply_solubility_tab_visibility(initial=True)
        self._apply_tab_order_from_settings(initial=True)

        self._plot_tab_stage_two_built = False

        self._mark_columns_dirty(
            reason="initial build"
        )  # start with explicit Apply requirement

        # Bottom action bar (stays visible)

        btns = ttk.Frame(self)

        btns.grid(
            row=1,
            column=0,
            sticky="ew",
            padx=self._scale_length(8),
            pady=self._scale_length(8),
        )

        # Iterate over the configured range to apply the per-item logic.
        for col in range(5):
            weight = 1 if col in (0, 3) else 0
            btns.grid_columnconfigure(col, weight=weight)

        self._plot_select_fig1_var = tk.BooleanVar()
        self._bind_setting_var(
            self._plot_select_fig1_var,
            ("plot_generation_selection", "fig1"),
            default=False,
            to_setting=bool,
            from_setting=bool,
        )

        self._plot_select_fig2_var = tk.BooleanVar()
        self._bind_setting_var(
            self._plot_select_fig2_var,
            ("plot_generation_selection", "fig2"),
            default=False,
            to_setting=bool,
            from_setting=bool,
        )

        self._plot_select_combined_var = tk.BooleanVar()
        self._bind_setting_var(
            self._plot_select_combined_var,
            ("plot_generation_selection", "fig_combined"),
            default=True,
            to_setting=bool,
            from_setting=bool,
        )

        plot_select = ttk.Frame(btns)
        plot_select.grid(row=0, column=0, sticky="w")

        _ui_checkbutton(
            plot_select,
            text="Pressure & Temperature vs Time",
            variable=self._plot_select_fig1_var,
        ).grid(row=0, column=0, sticky="w")

        _ui_checkbutton(
            plot_select,
            text="Pressure & First Derivative vs Time",
            variable=self._plot_select_fig2_var,
        ).grid(row=0, column=1, sticky="w", padx=(self._scale_length(8), 0))

        _ui_checkbutton(
            plot_select,
            text="Combined Triple-Axis Plot",
            variable=self._plot_select_combined_var,
        ).grid(row=0, column=2, sticky="w", padx=(self._scale_length(8), 0))

        generate_btn = _ui_button(
            plot_select,
            text="Generate Plot",
            command=self._generate_selected_plots,
        )
        generate_btn.grid(
            row=0, column=3, sticky="ew", padx=(self._scale_length(12), 0)
        )
        self._plot_select_generate_btn = generate_btn

        apply_frame = ttk.Frame(btns)
        apply_frame.grid(row=0, column=1, sticky="w", padx=(self._scale_length(8), 0))
        apply_frame.grid_columnconfigure(0, weight=1)
        apply_button = _ui_button(
            apply_frame,
            text="Apply Column Selection",
            command=lambda: self._apply_columns(auto_refresh_axes=True),
        )
        apply_button.grid(row=0, column=0, sticky="ew")
        self._register_apply_button(apply_button)
        self._create_apply_indicator(
            apply_frame, row=0, column=1, padx=(6, 0), sticky="w"
        )

        _ui_button(btns, text="Save Settings", command=self.save_settings).grid(
            row=0, column=2, sticky="ew", padx=(self._scale_length(8), 0)
        )

        # spacer in column 3 consumes extra width

        ttk.Label(btns, text="").grid(row=0, column=3, sticky="ew")

        _ui_button(
            btns,
            text="Exit",
            command=self.save_and_close,
        ).grid(row=0, column=4, sticky="ew", padx=(0, 0))
        self._startup_ui_built = True
        self._update_startup_loading_splash_progress(
            progress=62.0,
            message="Main interface ready. Finalizing deferred startup tasks...",
        )

    def _log_plot_tab_debug(self, message: str):
        """Emit plot tab debug output.

        Purpose:
            Send plot tab lifecycle messages to the debug logger.
        Why:
            Helps trace plot tab refresh behavior without ad-hoc prints.
        Args:
            message: Debug message describing the plot tab event.
        Returns:
            None.
        Side Effects:
            Writes to the debug logger when plotting.render is enabled.
        Exceptions:
            Best-effort guards suppress logging failures.
        """
        self._dbg("plotting.render", "%s", message)

    def _finalize_matplotlib_canvas_layout(
        self,
        *,
        canvas,
        fig,
        tk_widget=None,
        keep_export_size: bool = False,
        trigger_resize_event: bool = True,
        force_draw: bool = False,
    ) -> None:
        """Perform finalize matplotlib canvas layout.
        Used to keep the workflow logic localized and testable."""
        if canvas is None or fig is None:
            return

        def _measure(widget_obj):
            """Perform measure.
            Used to keep the workflow logic localized and testable."""
            width = height = 0
            try:
                width = int(widget_obj.winfo_width())
                height = int(widget_obj.winfo_height())
            except Exception:
                width = height = 0
            if width <= 1 or height <= 1:
                try:
                    width = int(widget_obj.winfo_reqwidth())
                    height = int(widget_obj.winfo_reqheight())
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            return max(width, 1), max(height, 1)

        widget = tk_widget
        if widget is None:
            try:
                widget = canvas.get_tk_widget()
            except Exception:
                widget = None
            if widget is not None:
                try:
                    widget.update_idletasks()
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass

        if not keep_export_size and widget is not None:
            widget_w, widget_h = _measure(widget)
            try:
                dpi = float(fig.get_dpi())
                if not math.isfinite(dpi) or dpi <= 0.0:
                    dpi = 100.0
            except Exception:
                dpi = 100.0
            target_w = max(widget_w / dpi, 1.0)
            target_h = max(widget_h / dpi, 1.0)
            try:
                cur_w, cur_h = fig.get_size_inches()
            except Exception:
                cur_w, cur_h = (0.0, 0.0)
            if abs(cur_w - target_w) > 1e-2 or abs(cur_h - target_h) > 1e-2:
                try:
                    fig.set_size_inches(target_w, target_h, forward=False)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        needs_draw = True
        try:
            renderer = canvas.get_renderer()
            if renderer is not None:
                needs_draw = False
        except Exception:
            needs_draw = True
        if force_draw or needs_draw:
            try:
                canvas.draw()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        try:
            layout_mgr = getattr(fig, "_gl260_layout_manager", None)
            if layout_mgr is not None:
                layout_mgr.solve()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if trigger_resize_event:
            try:
                canvas.resize_event()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if force_draw:
            try:
                canvas.draw()
                return
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            canvas.draw_idle()
        except Exception:
            try:
                canvas.draw()
            except Exception:
                pass

    def _refresh_canvas_display(self, frame, canvas, *, trigger_resize=True):
        """Refresh canvas display.
        Used to sync canvas display with current settings."""

        try:
            self.nb.select(frame)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        # Iterate over (frame, self.nb) to apply the per-item logic.
        for widget_obj in (frame, self.nb):
            try:
                widget_obj.update_idletasks()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        widget = None
        try:
            widget = canvas.get_tk_widget()
        except Exception:
            widget = None
        if widget is not None:
            try:
                widget.update_idletasks()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        fig = getattr(canvas, "figure", None)
        if fig is None:
            if trigger_resize:
                try:
                    canvas.resize_event()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            try:
                canvas.draw_idle()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        self._finalize_matplotlib_canvas_layout(
            canvas=canvas,
            fig=fig,
            tk_widget=widget,
            keep_export_size=False,
            trigger_resize_event=trigger_resize,
            force_draw=False,
        )

    def _install_plot_loading_overlay(
        self, frame, widget, *, message: str = "Loading plot..."
    ) -> None:
        """Install a loading overlay over a plot canvas.

        Purpose:
            Display a blocking overlay so the initial render is hidden.
        Why:
            The first draw can occur before geometry settles; hiding it prevents
            users from seeing an unstable layout.
        Inputs:
            frame: Plot tab frame hosting the plot.
            widget: Tk widget returned by the FigureCanvasTkAgg.
            message: Overlay text to display for the loading state.
        Outputs:
            None.
        Side Effects:
            Creates and places overlay widgets, stores overlay references on the frame.
        Exceptions:
            Overlay creation errors are caught to avoid UI interruption.
        """
        if frame is None or widget is None:
            return
        overlay = getattr(frame, "_plot_loading_overlay", None)
        if overlay is not None:
            try:
                if overlay.winfo_exists():
                    overlay.lift()
                    self._update_plot_loading_overlay_progress(
                        frame, progress=5.0, message=message, reset=True
                    )
                    return
            except Exception:
                overlay = None
        try:
            base_bg = frame.cget("background")
        except Exception:
            base_bg = None
        if not base_bg:
            try:
                base_bg = self.cget("background")
            except Exception:
                base_bg = None
        try:
            overlay = tk.Frame(frame, background=base_bg)
        except Exception:
            overlay = tk.Frame(frame)
        try:
            overlay.place(
                in_=widget, relx=0.0, rely=0.0, relwidth=1.0, relheight=1.0
            )
        except Exception:
            try:
                overlay.place(relx=0.0, rely=0.0, relwidth=1.0, relheight=1.0)
            except Exception:
                return
        label = None
        progress_var = None
        progress_bar = None
        percent_label = None
        try:
            content = ttk.Frame(overlay)
            content.place(relx=0.5, rely=0.5, anchor="center")
            label = ttk.Label(content, text=str(message or "Loading plot..."))
            label.pack(side="top", pady=(0, 8))
            progress_var = tk.DoubleVar(master=overlay, value=0.0)
            progress_bar = ttk.Progressbar(
                content,
                mode="determinate",
                length=260,
                maximum=100.0,
                variable=progress_var,
            )
            progress_bar.pack(side="top")
            percent_label = ttk.Label(content, text="0%")
            percent_label.pack(side="top", pady=(6, 0))
        except Exception:
            label = None
            progress_var = None
            progress_bar = None
            percent_label = None
        try:
            overlay.lift()
        except Exception:
            # Best-effort guard; ignore failures.
            pass
        frame._plot_loading_overlay = overlay
        frame._plot_loading_label = label
        frame._plot_loading_progress_var = progress_var
        frame._plot_loading_bar = progress_bar
        frame._plot_loading_progress_label = percent_label
        frame._plot_loading_progress_value = 0.0
        self._update_plot_loading_overlay_progress(
            frame, progress=5.0, message=message, reset=True
        )

    def _clear_plot_loading_overlay(self, frame) -> None:
        """Clear a plot loading overlay if present.

        Purpose:
            Remove the blocking overlay once the stable render is ready.
        Why:
            Users should only see the final, correctly scaled plot.
        Inputs:
            frame: Plot tab frame hosting the plot.
        Outputs:
            None.
        Side Effects:
            Destroys overlay widgets and clears stored references.
        Exceptions:
            Overlay removal errors are guarded to keep the UI responsive.
        """
        if frame is None:
            return
        overlay = getattr(frame, "_plot_loading_overlay", None)
        if overlay is None:
            return
        try:
            overlay.place_forget()
        except Exception:
            # Best-effort guard; ignore failures.
            pass
        try:
            overlay.destroy()
        except Exception:
            # Best-effort guard; ignore failures.
            pass
        frame._plot_loading_overlay = None
        frame._plot_loading_label = None
        frame._plot_loading_progress_var = None
        frame._plot_loading_bar = None
        frame._plot_loading_progress_label = None
        frame._plot_loading_progress_value = 0.0

    def _update_plot_loading_overlay_progress(
        self,
        frame,
        *,
        progress: Optional[float] = None,
        message: Optional[str] = None,
        reset: bool = False,
    ) -> None:
        """Update one plot splash overlay with deterministic progress milestones.

        Purpose:
            Keep loading-overlay message and progress state synchronized with
            async plot-render milestones.
        Why:
            Core/combined render orchestration can fire callbacks out of order;
            monotonic progress avoids visible regressions while still providing
            meaningful stage feedback.
        Inputs:
            frame: Plot tab frame owning the active loading overlay widgets.
            progress: Optional new progress value in the 0..100 range.
            message: Optional overlay status text.
            reset: When True, resets tracked progress before applying updates.
        Outputs:
            None.
        Side Effects:
            Mutates overlay text/progress widgets and frame progress cache.
        Exceptions:
            Best-effort behavior; missing widgets are ignored.
        """
        if frame is None:
            return
        overlay = getattr(frame, "_plot_loading_overlay", None)
        if overlay is None:
            return
        try:
            if not overlay.winfo_exists():
                return
        except Exception:
            return
        if reset:
            try:
                frame._plot_loading_progress_value = 0.0
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        current_value = getattr(frame, "_plot_loading_progress_value", 0.0)
        try:
            current_value = float(current_value)
        except Exception:
            current_value = 0.0
        if not math.isfinite(current_value):
            current_value = 0.0
        target_value = current_value
        if progress is not None:
            try:
                candidate = float(progress)
            except Exception:
                candidate = current_value
            if not math.isfinite(candidate):
                candidate = current_value
            candidate = max(0.0, min(100.0, candidate))
            # Keep progress monotonic unless the caller explicitly requests reset.
            target_value = candidate if reset else max(current_value, candidate)
        label = getattr(frame, "_plot_loading_label", None)
        if label is not None and message is not None:
            try:
                label.configure(text=str(message))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        progress_var = getattr(frame, "_plot_loading_progress_var", None)
        if progress_var is not None:
            try:
                progress_var.set(float(target_value))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        progress_bar = getattr(frame, "_plot_loading_bar", None)
        if progress_bar is not None:
            try:
                progress_bar.configure(value=float(target_value), maximum=100.0)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        percent_label = getattr(frame, "_plot_loading_progress_label", None)
        if percent_label is not None:
            try:
                percent_label.configure(text=f"{int(round(target_value))}%")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            frame._plot_loading_progress_value = float(target_value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            overlay.lift()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _schedule_plot_auto_refresh(self, frame, canvas) -> None:
        """Schedule the one-time plot auto refresh after initial render.

        Purpose:
            Trigger a programmatic refresh using the same path as the Refresh button.
        Why:
            The refresh path applies stable geometry, ensuring the first visible
            render matches the manual Refresh output. Combined plots additionally
            require a second forced refresh pass before the overlay is cleared.
        Inputs:
            frame: Plot tab frame hosting the plot.
            canvas: FigureCanvasTkAgg displaying the figure.
        Outputs:
            None.
        Side Effects:
            Updates auto-refresh state, seeds combined refresh phase tracking,
            schedules an idle callback, and invokes refresh.
        Exceptions:
            Errors are caught to avoid UI interruption.
        """
        if frame is None or canvas is None:
            return
        if not getattr(frame, "_plot_auto_refresh_enabled", True):
            return
        state = getattr(frame, "_plot_auto_refresh_state", None)
        # Only schedule once per tab creation to prevent refresh recursion.
        if state not in (None, "pending"):
            return
        if not getattr(frame, "_plot_initial_render_complete", False):
            return
        plot_key = getattr(frame, "_plot_key", None)
        frame._plot_auto_refresh_state = "scheduled"
        if plot_key == "fig_combined":
            self._log_plot_tab_debug("Combined auto-refresh scheduled.")
            # Combined plots begin with phase 1; phase 2 is preference/decision driven.
            frame._plot_auto_refresh_phase = 1
        else:
            frame._plot_auto_refresh_phase = None
        after_id = getattr(frame, "_plot_auto_refresh_after_id", None)
        # Avoid duplicate idle callbacks if one is already queued.
        if after_id is not None:
            return

        def _run():
            """Trigger the plot auto refresh once layout is idle.

            Purpose:
                Enter the auto-refresh phase and invoke the shared refresh path.
            Why:
                Plot refreshes must use the manual refresh path for stable sizing.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                Updates auto-refresh state and rebuilds the plot.
            Exceptions:
                Errors are caught to avoid breaking the UI loop.
            """
            frame._plot_auto_refresh_after_id = None
            if getattr(frame, "_plot_auto_refresh_state", None) != "scheduled":
                return
            try:
                if not frame.winfo_exists():
                    self._clear_plot_loading_overlay(frame)
                    return
            except Exception:
                return
            try:
                widget = canvas.get_tk_widget()
                if widget is not None and not widget.winfo_exists():
                    self._clear_plot_loading_overlay(frame)
                    return
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            frame._plot_auto_refresh_state = "refreshing"
            frame._plot_auto_refresh_in_progress = True
            # Use the same refresh path as the Refresh button.
            self._force_plot_refresh(frame, canvas, capture_combined_legend=True)

        try:
            frame._plot_auto_refresh_after_id = self.after_idle(_run)
        except Exception:
            _run()

    def _complete_plot_auto_refresh(self, frame) -> None:
        """Complete the plot auto refresh and reveal the plot.

        Purpose:
            Finalize auto refresh state and remove the loading overlay.
        Why:
            Ensures the first visible plot uses the refresh path output. Combined
            plots can run one or two refresh passes depending on adaptive decision
            signals and Plot Render Settings overrides before reveal.
        Inputs:
            frame: Plot tab frame hosting the plot.
        Outputs:
            None.
        Side Effects:
            Updates auto-refresh state, optionally schedules a second refresh
            pass for combined plots, and clears the loading overlay on completion.
        Exceptions:
            Errors are caught to avoid UI interruption.
        """
        if frame is None:
            return
        plot_key = getattr(frame, "_plot_key", None)
        if plot_key in {"fig1", "fig2"} and bool(
            getattr(frame, "_core_overlay_hold", False)
        ):
            self._finalize_core_overlay(frame)
            return
        if getattr(frame, "_plot_auto_refresh_state", None) != "refreshing":
            return
        phase = getattr(frame, "_plot_auto_refresh_phase", None)
        after_id = getattr(frame, "_plot_auto_refresh_after_id", None)
        if plot_key == "fig_combined":
            second_refresh_disabled = self._combined_second_refresh_disabled()
            if phase == 1:
                if second_refresh_disabled:
                    frame._plot_auto_refresh_phase = None
                    self._log_plot_tab_debug(
                        "Combined auto-refresh phase 2 skipped by Plot Render Settings."
                    )
                else:
                    frame._plot_auto_refresh_phase = 2

                    def _run_second_pass():
                        """Trigger the second combined refresh pass before reveal.

                        Purpose:
                            Run the same refresh path a second time for combined plots.
                        Why:
                            Combined layouts need two passes to fully stabilize margins.
                        Inputs:
                            None.
                        Outputs:
                            None.
                        Side Effects:
                            Invokes the shared refresh path and keeps the overlay visible.
                        Exceptions:
                            Errors are caught to avoid breaking the UI loop.
                        """
                        frame._plot_auto_refresh_after_id = None
                        if getattr(frame, "_plot_auto_refresh_state", None) != "refreshing":
                            return
                        if getattr(frame, "_plot_auto_refresh_phase", None) != 2:
                            return
                        try:
                            if not frame.winfo_exists():
                                self._clear_plot_loading_overlay(frame)
                                return
                        except Exception:
                            return
                        _, canvas = self._find_plot_tab_canvas(plot_key)
                        if canvas is None:
                            # Fail closed: avoid leaving the overlay stuck if the canvas
                            # is gone.
                            frame._plot_auto_refresh_state = "done"
                            frame._plot_auto_refresh_after_id = None
                            frame._plot_auto_refresh_in_progress = False
                            frame._plot_auto_refresh_phase = None
                            self._clear_plot_loading_overlay(frame)
                            return
                        # Use the same refresh path as the Refresh button.
                        self._force_plot_refresh(
                            frame,
                            canvas,
                            capture_combined_legend=True,
                        )

                    try:
                        frame._plot_auto_refresh_after_id = self.after_idle(
                            _run_second_pass
                        )
                    except Exception:
                        _run_second_pass()
                    return
            if phase == 2 and after_id is not None:
                # Second pass is queued; keep the overlay until it completes.
                return
        # Mark completion so the auto-refresh only runs once.
        frame._plot_auto_refresh_state = "done"
        frame._plot_auto_refresh_after_id = None
        frame._plot_auto_refresh_in_progress = False
        frame._plot_auto_refresh_phase = None
        if plot_key == "fig_combined":
            self._log_plot_tab_debug(
                "Combined auto-refresh complete; clearing loading overlay."
            )
        self._update_plot_loading_overlay_progress(
            frame,
            progress=100.0,
            message="Plot ready.",
        )
        self._clear_plot_loading_overlay(frame)

    def _finalize_combined_plot_display(
        self,
        frame,
        canvas,
        *,
        placement_state: dict[str, Any] | None = None,
    ) -> None:
        """Finalize the combined plot display with a deferred single-pass draw.

        Purpose:
            Apply final sizing, legend anchors, and tracking before drawing the
            combined plot once, then schedule the auto refresh if needed.
        Why:
            Combined plots depend on stable geometry; deferring avoids an initial
            incorrect render, and the auto refresh aligns with the manual Refresh
            render path before the overlay is removed.
        Inputs:
            frame: Plot tab frame hosting the combined plot.
            canvas: FigureCanvasTkAgg bound to the combined figure.
            placement_state: Optional plot element placement state to restore.
        Outputs:
            None.
        Side Effects:
            Defers render until widget geometry is ready, applies display layout
            settings and plot elements, restores legend anchors, registers drag
            tracking, retargets annotation controllers, triggers a single
            draw_idle, and defers the one-shot combined refresh until the first
            draw_event can invoke the manual Refresh callback. When completing a
            forced refresh, synchronously finalizes layout before deferring
            overlay removal to the post-refresh draw handler.
        Exceptions:
            Errors are caught defensively to keep UI workflows responsive.
        """
        if canvas is None:
            return
        fig = getattr(canvas, "figure", None)
        if fig is None:
            return
        plot_key = getattr(frame, "_plot_key", None)
        plot_id = getattr(frame, "_plot_id", None)
        if placement_state is None and plot_id:
            placement_state = self._capture_plot_element_placement_state(plot_id)
        widget = None
        try:
            widget = canvas.get_tk_widget()
        except Exception:
            widget = None
        if widget is not None:
            try:
                widget.update_idletasks()
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            try:
                width_px = int(widget.winfo_width())
                height_px = int(widget.winfo_height())
            except Exception:
                width_px = 0
                height_px = 0
            if width_px <= 2 or height_px <= 2:
                # Defer combined render until Tk geometry is stable.
                try:
                    self.after(
                        50,
                        lambda: self._finalize_combined_plot_display(
                            frame,
                            canvas,
                            placement_state=placement_state,
                        ),
                    )
                except Exception:
                    self.after_idle(
                        lambda: self._finalize_combined_plot_display(
                            frame,
                            canvas,
                            placement_state=placement_state,
                        )
                    )
                return

        def _render():
            """Perform deferred combined render.

            Purpose:
                Apply final geometry and legend anchoring before the single draw.
            Why:
                Combined plots must render once with final DPI/size and anchors.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                Updates figure size/DPI, applies anchors, registers legend tracking,
                restores placement state, and schedules draw_idle.
            Exceptions:
                Errors are caught to keep the UI responsive.
            """
            try:
                dpi = float(getattr(fig, "dpi", plt.rcParams.get("figure.dpi", 100.0)))
                if not math.isfinite(dpi) or dpi <= 0.0:
                    dpi = 100.0
            except Exception:
                dpi = 100.0
            target_width = None
            target_height = None
            if widget is not None:
                try:
                    widget.update_idletasks()
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass
                try:
                    target_width = max(int(widget.winfo_width()), 1)
                    target_height = max(int(widget.winfo_height()), 1)
                except Exception:
                    target_width = None
                    target_height = None
            if target_width is None or target_height is None:
                try:
                    fig_size = self._compute_target_figsize_inches()
                except Exception:
                    fig_size = (11.0, 8.5)
                target_width = max(int(fig_size[0] * dpi), 1)
                target_height = max(int(fig_size[1] * dpi), 1)
            try:
                fig.set_dpi(dpi)
                fig.set_size_inches(
                    max(target_width / dpi, 1.0),
                    max(target_height / dpi, 1.0),
                    forward=False,
                )
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            if plot_id:
                try:
                    self._update_plot_loading_overlay_progress(
                        frame,
                        progress=82.0,
                        message="Adding Plot Elements...",
                    )
                    self._apply_display_settings_for_plot(fig, plot_id, canvas)
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass
            try:
                self._apply_combined_saved_legend_anchors(fig)
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            try:
                self._register_combined_legend_tracking(
                    fig,
                    force_draw=False,
                    defer_saved_anchor=False,
                )
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            if plot_id and placement_state:
                try:
                    self._restore_plot_element_placement_state(plot_id, placement_state)
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass
            try:
                frame._combined_render_ready = True
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            was_initial_render = not getattr(
                frame, "_plot_initial_render_complete", False
            )
            draw_succeeded = False
            try:
                canvas.draw_idle()
                draw_succeeded = True
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            if draw_succeeded and was_initial_render:
                try:
                    frame._plot_initial_render_complete = True
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass
                auto_state = getattr(frame, "_plot_auto_refresh_state", None)
                if auto_state == "refreshing":
                    # Reset initial render state so auto-refresh scheduling can run.
                    frame._plot_auto_refresh_state = "pending"
                    frame._plot_auto_refresh_in_progress = False
                    frame._plot_auto_refresh_after_id = None
                if plot_key == "fig_combined":
                    # Combined plots refresh after the first draw_event; keep
                    # overlay state pending until that callback runs.
                    frame._plot_auto_refresh_state = "pending"
                    frame._plot_auto_refresh_in_progress = False
                    frame._plot_auto_refresh_after_id = None
                else:
                    self._schedule_plot_auto_refresh(frame, canvas)
            auto_state = getattr(frame, "_plot_auto_refresh_state", None)
            if auto_state == "refreshing" and not was_initial_render:
                # Apply the same finalize/draw logic as manual Refresh before revealing.
                try:
                    self._update_plot_loading_overlay_progress(
                        frame,
                        progress=92.0,
                        message="Final Layout Adjustments...",
                    )
                    self._finalize_matplotlib_canvas_layout(
                        canvas=canvas,
                        fig=fig,
                        tk_widget=widget,
                        keep_export_size=False,
                        trigger_resize_event=True,
                        force_draw=True,
                    )
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass
                if plot_key == "fig_combined" and getattr(
                    frame, "_post_first_draw_refresh_hold_overlay", False
                ):
                    # Defer overlay removal for combined until the post-refresh draw.
                    frame._plot_auto_refresh_state = "pending"
                    frame._plot_auto_refresh_in_progress = False
                    frame._plot_auto_refresh_after_id = None
                    frame._plot_auto_refresh_phase = None
                else:
                    # Auto refresh completed; reveal the stabilized render.
                    self._complete_plot_auto_refresh(frame)

        self._with_loading_cursor(_render, widget=widget)

    def _finalize_plot_refresh(self, canvas, fig) -> None:
        """Refresh value.
        Used by finalize plot workflows to refresh value."""
        if canvas is None or fig is None:
            return
        try:
            layout_mgr = getattr(fig, "_gl260_layout_manager", None)
            if layout_mgr is not None:
                layout_mgr.solve()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            canvas.resize_event()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            canvas.draw()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _install_refreshed_figure_and_finalize(
        self, frame, canvas, new_fig, *, plot_id: Optional[str] = None
    ) -> None:
        """Install a refreshed figure on the canvas and finalize display.

        Purpose:
            Attach a new figure to the existing canvas and complete the
            display finalization for a refreshed plot.
        Why:
            Async render installs must bind the final figure before refresh
            so layout profiles and plot elements apply to the correct figure.
        Inputs:
            frame: Plot tab frame hosting the canvas.
            canvas: FigureCanvasTkAgg instance to update.
            new_fig: Rendered Matplotlib Figure to install.
            plot_id: Optional plot identifier for applying display settings.
        Outputs:
            None.
        Side Effects:
            Attaches the figure to the canvas, applies display settings,
            updates refresh progress stages for plot elements/final layout,
            triggers canvas resize/draw, and finalizes layout.
        Exceptions:
            Errors are caught to avoid interrupting UI workflows.
        """
        if canvas is None or new_fig is None:
            return
        self._log_plot_tab_debug("Installing refreshed figure onto canvas.")
        widget = None
        try:
            widget = canvas.get_tk_widget()
        except Exception:
            widget = None
        try:
            new_fig.set_canvas(canvas)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            canvas.figure = new_fig
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if plot_id:
            try:
                self._update_plot_loading_overlay_progress(
                    frame,
                    progress=82.0,
                    message="Adding Plot Elements...",
                )
                self._apply_display_settings_for_plot(new_fig, plot_id, canvas)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            self._update_plot_loading_overlay_progress(
                frame,
                progress=92.0,
                message="Final Layout Adjustments...",
            )
            self._finalize_matplotlib_canvas_layout(
                canvas=canvas,
                fig=new_fig,
                tk_widget=widget,
                keep_export_size=False,
                trigger_resize_event=True,
                force_draw=True,
            )
            self._log_plot_tab_debug(
                "Refreshed figure: deterministic finalize complete."
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            canvas.draw_idle()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _install_rendered_plot_in_tab(
        self,
        frame,
        canvas,
        plot_key: str,
        fig: Figure,
        *,
        placement_state: dict[str, Any] | None = None,
    ) -> None:
        """Install a rendered figure into an existing plot tab.

        Purpose:
            Swap a newly rendered figure into its target tab/canvas.
        Why:
            Async rendering must reuse tabs to keep UI state and overlays intact.
        Inputs:
            frame: Plot tab frame hosting the canvas.
            canvas: FigureCanvasTkAgg instance to update.
            plot_key: Plot key identifier (e.g., "fig1", "fig_combined").
            fig: Rendered Matplotlib Figure to install.
            placement_state: Optional plot element placement state to restore.
        Outputs:
            None.
        Side Effects:
            Updates figure bindings, refreshes canvas display, retargets plot
            annotations, restores placement state, updates dirty flags, and
            clears loading overlays when auto-refresh is not pending/scheduled.
        Exceptions:
            Errors are caught to avoid interrupting UI workflows.
        """
        if frame is None or canvas is None or fig is None:
            return
        plot_id = self._plot_key_to_plot_id(plot_key)
        if not plot_id:
            plot_id = getattr(frame, "_plot_id", None)
        is_core_key = plot_key in {"fig1", "fig2"}
        if plot_id:
            try:
                self._teardown_layout_editor(plot_id, apply_changes=False)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if is_core_key:
            was_real_core = bool(getattr(frame, "_core_real_figure_installed", False))
            is_real_core = self._is_real_core_figure(fig)
            overlay_exists = bool(getattr(frame, "_plot_loading_overlay", None) is not None)
            try:
                frame._core_real_figure_installed = is_real_core
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if is_real_core and not was_real_core and overlay_exists:
                try:
                    frame._core_overlay_refresh_invoked_count = 0
                    frame._core_overlay_refresh_completed_count = 0
                    frame._core_overlay_layout_sig_baseline = None
                    frame._core_overlay_need_second_refresh = True
                    frame._core_overlay_target_refreshes = 2
                    frame._core_overlay_ready_seen = False
                    frame._core_overlay_second_refresh_scheduled = False
                    frame._core_overlay_hold = True
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                self._log_plot_tab_debug(
                    "Core real figure installed for %s; reset overlay refresh orchestration."
                    % plot_key
                )
        if plot_key == "fig_combined":
            was_real_combined = bool(
                getattr(frame, "_combined_real_figure_installed", False)
            )
            is_real_combined = self._is_real_combined_figure(fig)
            try:
                fig.set_canvas(canvas)
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            try:
                canvas.figure = fig
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                frame._combined_real_figure_installed = is_real_combined
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if is_real_combined and not was_real_combined:
                # Reset one-shot post-first-draw refresh flags when transitioning
                # from placeholder to the first real combined figure.
                prior_finalize_after_id = getattr(
                    frame, "_combined_overlay_finalize_after_id", None
                )
                if prior_finalize_after_id is not None:
                    try:
                        self.after_cancel(prior_finalize_after_id)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                try:
                    default_target_refreshes = (
                        self._combined_overlay_default_target_refreshes()
                    )
                    frame._post_first_draw_refresh_done = False
                    frame._post_first_draw_refresh_invoked = False
                    frame._post_first_draw_refresh_hold_overlay = True
                    frame._post_first_draw_refresh_retry_count = 0
                    frame._combined_overlay_refresh_invoked_count = 0
                    frame._combined_overlay_refresh_completed_count = 0
                    frame._combined_overlay_layout_sig_baseline = None
                    frame._combined_overlay_decision_sig_baseline = None
                    frame._combined_overlay_decision_sig_last = None
                    frame._combined_overlay_data_sig_current = None
                    frame._combined_overlay_need_second_refresh = (
                        default_target_refreshes > 1
                    )
                    frame._combined_overlay_target_refreshes = default_target_refreshes
                    frame._combined_overlay_ready_seen = False
                    frame._combined_overlay_second_refresh_scheduled = False
                    frame._combined_placeholder_draw_logged = False
                    frame._combined_overlay_last_geometry_sig = None
                    frame._combined_overlay_stable_draw_count = 0
                    frame._combined_overlay_finalize_started_at = None
                    frame._combined_overlay_finalize_after_id = None
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                self._log_plot_tab_debug(
                    "Combined real figure installed; reset post-draw refresh orchestration."
                )
            try:
                self._finalize_combined_plot_display(
                    frame, canvas, placement_state=placement_state
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        else:
            try:
                self._install_refreshed_figure_and_finalize(
                    frame,
                    canvas,
                    fig,
                    plot_id=plot_id,
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if plot_id and placement_state:
                try:
                    self._restore_plot_element_placement_state(plot_id, placement_state)
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass
            if is_core_key and bool(getattr(frame, "_core_overlay_hold", False)):
                renderer_ok = False
                try:
                    renderer_ok = canvas.get_renderer() is not None
                except Exception:
                    renderer_ok = False
                if renderer_ok and not bool(
                    getattr(frame, "_core_overlay_ready_seen", False)
                ):
                    try:
                        frame._core_overlay_ready_seen = True
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                    self._log_plot_tab_debug(
                        "Core overlay ready signal observed for %s."
                        % plot_key
                    )
                invoked_count = getattr(frame, "_core_overlay_refresh_invoked_count", 0)
                completed_before = getattr(
                    frame, "_core_overlay_refresh_completed_count", 0
                )
                try:
                    invoked_count = int(invoked_count)
                except Exception:
                    invoked_count = 0
                try:
                    completed_before = int(completed_before)
                except Exception:
                    completed_before = 0
                completed_count = completed_before
                if invoked_count > completed_before:
                    completed_count = self._mark_core_overlay_refresh_completed(
                        frame,
                        fig=fig,
                    )
                    target_refreshes = getattr(frame, "_core_overlay_target_refreshes", 2)
                    self._log_plot_tab_debug(
                        "Core auto-refresh completion recorded for %s: invoked=%s completed=%s target=%s."
                        % (
                            plot_key,
                            invoked_count,
                            completed_count,
                            target_refreshes,
                        )
                    )
                else:
                    self._log_plot_tab_debug(
                        "Core render install skipped completion count for %s: invoked=%s completed=%s."
                        % (
                            plot_key,
                            invoked_count,
                            completed_before,
                        )
                    )
                target_refreshes = getattr(frame, "_core_overlay_target_refreshes", 2)
                try:
                    target_refreshes = int(target_refreshes)
                except Exception:
                    target_refreshes = 2
                if target_refreshes <= 0:
                    target_refreshes = 1
                if invoked_count <= 0 and completed_count <= 0:
                    self._schedule_core_refresh_pass(
                        frame,
                        canvas,
                        pass_index=1,
                    )
                elif (
                    completed_count >= 1
                    and completed_count < target_refreshes
                    and not bool(
                        getattr(frame, "_core_overlay_second_refresh_scheduled", False)
                    )
                ):
                    self._schedule_core_refresh_pass(
                        frame,
                        canvas,
                        pass_index=2,
                    )
                self._finalize_core_overlay(frame)
        if plot_id:
            try:
                self._set_plot_dirty_flags(
                    plot_id,
                    dirty_data=False,
                    dirty_layout=False,
                    dirty_elements=False,
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        auto_state = getattr(frame, "_plot_auto_refresh_state", None)
        auto_enabled = getattr(frame, "_plot_auto_refresh_enabled", True)
        combined_overlay_hold = bool(
            plot_key == "fig_combined"
            and getattr(frame, "_post_first_draw_refresh_hold_overlay", False)
        )
        if is_core_key and bool(getattr(frame, "_core_overlay_hold", False)):
            # Completion-based core orchestration keeps the overlay until done.
            pass
        elif auto_state == "refreshing" and not combined_overlay_hold:
            self._complete_plot_auto_refresh(frame)
        elif combined_overlay_hold and auto_state == "refreshing":
            # Combined overlay release is draw-event gated; keep generic
            # completion from clearing the splash before adaptive passes finish.
            pass
        elif auto_enabled and auto_state in {"pending", "scheduled"}:
            # Keep the overlay active until the forced refresh pipeline completes.
            pass
        else:
            self._clear_plot_loading_overlay(frame)

    def _compute_target_figsize_inches(self):
        """Compute target figsize inches.
        Used to derive target figsize inches for analysis or plotting."""
        width_px = 0
        height_px = 0

        widgets = [
            getattr(self, "tab_plot", None),
            getattr(self, "nb", None),
            self,
        ]

        # Iterate over widgets to apply the per-item logic.
        for widget in widgets:
            if widget is None:
                continue
            try:
                widget.update_idletasks()
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            try:
                w = widget.winfo_width()
                h = widget.winfo_height()
            except Exception:
                continue
            if w and h:
                width_px = max(width_px, int(w))
                height_px = max(height_px, int(h))

        if width_px <= 0 or height_px <= 0:
            width_px, height_px = 1100, 800

        try:
            dpi = float(plt.rcParams.get("figure.dpi", 100.0))
            if not math.isfinite(dpi) or dpi <= 0.0:
                dpi = 100.0
        except Exception:
            dpi = 100.0

        width_in = max(width_px / dpi, 4.0)
        height_in = max(height_px / dpi, 3.0)
        return (width_in, height_in)

    def _is_real_core_figure(self, fig: Optional[Figure]) -> bool:
        """Return whether a figure is a real core render output."""
        if fig is None:
            return False
        return bool(getattr(fig, "_gl260_core_real_figure", False))

    def _mark_core_figure_real(self, fig: Optional[Figure]) -> None:
        """Mark a figure as a real core render output."""
        if fig is None:
            return
        try:
            fig._gl260_core_real_figure = True  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _core_layout_signature(self, fig: Optional[Figure]) -> Any:
        """Build a lightweight layout signature for core plots."""
        if fig is None:
            return None

        def _norm_num(value: Any) -> Any:
            try:
                value_f = float(value)
            except Exception:
                return value
            if not math.isfinite(value_f):
                return None
            return round(value_f, 4)

        def _norm_tuple(value: Any) -> Any:
            if isinstance(value, (list, tuple)):
                return tuple(_norm_num(item) for item in value)
            return _norm_num(value)

        try:
            size = fig.get_size_inches()
            size_sig = tuple(_norm_num(v) for v in size)
        except Exception:
            size_sig = None
        try:
            subplot = fig.subplotpars
            subplot_sig = (
                _norm_num(getattr(subplot, "left", None)),
                _norm_num(getattr(subplot, "right", None)),
                _norm_num(getattr(subplot, "bottom", None)),
                _norm_num(getattr(subplot, "top", None)),
                _norm_num(getattr(subplot, "wspace", None)),
                _norm_num(getattr(subplot, "hspace", None)),
            )
        except Exception:
            subplot_sig = None
        axes_sig: List[Any] = []
        try:
            for idx, ax in enumerate(list(getattr(fig, "axes", []) or [])):
                if getattr(ax, "_gl260_legend_only", False):
                    continue
                role = str(getattr(ax, "_gl260_axis_role", "") or "")
                try:
                    bounds = tuple(_norm_num(v) for v in ax.get_position().bounds)
                except Exception:
                    bounds = None
                try:
                    xlim = tuple(_norm_num(v) for v in ax.get_xlim())
                except Exception:
                    xlim = None
                try:
                    ylim = tuple(_norm_num(v) for v in ax.get_ylim())
                except Exception:
                    ylim = None
                axes_sig.append((idx, role, bounds, xlim, ylim))
        except Exception:
            axes_sig = []
        legend_sig: List[Any] = []
        try:
            legends = _collect_gl260_legends(fig)
        except Exception:
            legends = []
        for idx, legend in enumerate(legends):
            role = str(getattr(legend, "_gl260_legend_role", "") or "")
            try:
                loc_val = legend.get_loc()
            except Exception:
                loc_val = getattr(legend, "_loc", None)
            try:
                bbox = legend.get_bbox_to_anchor()
                bounds = tuple(_norm_num(v) for v in bbox.bounds) if bbox is not None else None
            except Exception:
                bounds = None
            legend_sig.append((idx, role, _norm_tuple(loc_val), bounds))
        return (size_sig, subplot_sig, tuple(axes_sig), tuple(legend_sig))

    def _overlay_layout_decision_signature(self, fig: Optional[Figure]) -> Any:
        """Build a low-noise layout signature for adaptive refresh pass decisions.

        Purpose:
            Capture only geometry that materially affects whether a second
            refresh pass is needed before revealing the plot.
        Why:
            Overlay pass orchestration should react to structural layout changes
            only; data limits and legend bounds are noisy and can trigger
            unnecessary second passes.
        Inputs:
            fig: Matplotlib Figure being evaluated for adaptive refresh.
        Outputs:
            Tuple signature containing figure size, subplot parameters, and
            non-legend axis geometry/visibility; returns None when unavailable.
        Side Effects:
            None.
        Exceptions:
            Internal lookups are guarded; missing values degrade to None.
        """
        if fig is None:
            return None

        def _norm_num(value: Any) -> Any:
            """Normalize one numeric value for signature stability."""
            try:
                value_f = float(value)
            except Exception:
                return value
            if not math.isfinite(value_f):
                return None
            return round(value_f, 4)

        try:
            size = fig.get_size_inches()
            size_sig = tuple(_norm_num(v) for v in size)
        except Exception:
            size_sig = None
        try:
            subplot = fig.subplotpars
            subplot_sig = (
                _norm_num(getattr(subplot, "left", None)),
                _norm_num(getattr(subplot, "right", None)),
                _norm_num(getattr(subplot, "bottom", None)),
                _norm_num(getattr(subplot, "top", None)),
                _norm_num(getattr(subplot, "wspace", None)),
                _norm_num(getattr(subplot, "hspace", None)),
            )
        except Exception:
            subplot_sig = None

        axes_sig: List[Any] = []
        try:
            for idx, ax in enumerate(list(getattr(fig, "axes", []) or [])):
                if getattr(ax, "_gl260_legend_only", False):
                    continue
                role = str(getattr(ax, "_gl260_axis_role", "") or "")
                try:
                    visible = bool(ax.get_visible())
                except Exception:
                    visible = True
                try:
                    bounds = tuple(_norm_num(v) for v in ax.get_position().bounds)
                except Exception:
                    bounds = None
                axes_sig.append((idx, role, visible, bounds))
        except Exception:
            axes_sig = []

        return (size_sig, subplot_sig, tuple(axes_sig))

    def _capture_core_overlay_layout_baseline(
        self,
        frame: Optional[ttk.Frame],
        *,
        canvas: Optional[FigureCanvasTkAgg] = None,
    ) -> Any:
        """Capture the core overlay baseline used to decide if pass 2 is required.

        Purpose:
            Store the baseline layout signature before the first forced refresh.
        Why:
            Core overlay orchestration compares pass-1 output against this
            baseline to avoid unnecessary second passes.
        Inputs:
            frame: Plot tab frame storing core overlay refresh state.
            canvas: Optional canvas to resolve the active figure quickly.
        Outputs:
            The captured signature, or None when no figure is available.
        Side Effects:
            Persists baseline on frame as `_core_overlay_layout_sig_baseline`.
        Exceptions:
            Resolution and frame writes are guarded to keep UI flow resilient.
        """
        if frame is None:
            return None
        fig = getattr(canvas, "figure", None) if canvas is not None else None
        if fig is None:
            plot_key = str(getattr(frame, "_plot_key", "") or "")
            _, resolved_canvas = self._find_plot_tab_canvas(plot_key)
            fig = getattr(resolved_canvas, "figure", None) if resolved_canvas is not None else None
        baseline = self._overlay_layout_decision_signature(fig)
        try:
            frame._core_overlay_layout_sig_baseline = baseline
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._log_plot_tab_debug(
            "Core auto-refresh baseline captured for %s: available=%s."
            % (getattr(frame, "_plot_key", None), bool(baseline is not None))
        )
        return baseline

    def _mark_core_overlay_refresh_completed(
        self,
        frame: Optional[ttk.Frame],
        *,
        fig: Optional[Figure] = None,
    ) -> int:
        """Record one core refresh completion and derive the adaptive pass target.

        Purpose:
            Track completed refresh renders for core overlay release gating.
        Why:
            The first completed pass decides whether a second pass is necessary
            based on low-noise layout signature changes.
        Inputs:
            frame: Plot tab frame storing core overlay orchestration state.
            fig: Optional rendered figure for current-pass signature capture.
        Outputs:
            Integer completion count after increment.
        Side Effects:
            Updates completion counters and target refresh metadata on frame.
        Exceptions:
            Counter and state writes are guarded to avoid UI disruption.
        """
        if frame is None:
            return 0
        completed_count = getattr(frame, "_core_overlay_refresh_completed_count", 0)
        try:
            completed_count = int(completed_count)
        except Exception:
            completed_count = 0
        completed_count += 1
        try:
            frame._core_overlay_refresh_completed_count = completed_count
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if completed_count == 1:
            baseline_sig = getattr(frame, "_core_overlay_layout_sig_baseline", None)
            current_sig = self._overlay_layout_decision_signature(fig)
            need_second_refresh = False
            if baseline_sig is not None and current_sig is not None:
                need_second_refresh = baseline_sig != current_sig
            target_refreshes = 2 if need_second_refresh else 1
            try:
                frame._core_overlay_need_second_refresh = need_second_refresh
                frame._core_overlay_target_refreshes = target_refreshes
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._log_plot_tab_debug(
                "Core adaptive refresh decision for %s: need_second=%s target=%s baseline_available=%s current_available=%s."
                % (
                    getattr(frame, "_plot_key", None),
                    need_second_refresh,
                    target_refreshes,
                    baseline_sig is not None,
                    current_sig is not None,
                )
            )
        target_refreshes = getattr(frame, "_core_overlay_target_refreshes", 2)
        try:
            target_refreshes = int(target_refreshes)
        except Exception:
            target_refreshes = 2
        if target_refreshes <= 0:
            target_refreshes = 1
        milestone_value = 98.0 if completed_count >= target_refreshes else 90.0
        self._update_plot_loading_overlay_progress(
            frame,
            progress=milestone_value,
            message=(
                "Finalizing plot..."
                if completed_count >= target_refreshes
                else "Auto-refresh pass complete."
            ),
        )
        return completed_count

    def _finalize_core_overlay(
        self, frame: Optional[ttk.Frame], *, force_clear: bool = False
    ) -> None:
        """Finalize core loading overlay after completion-based refresh passes."""
        if frame is None:
            return
        hold_overlay = bool(getattr(frame, "_core_overlay_hold", False))
        if not hold_overlay and not force_clear:
            return
        completed_count = getattr(frame, "_core_overlay_refresh_completed_count", 0)
        try:
            completed_count = int(completed_count)
        except Exception:
            completed_count = 0
        target_refreshes = getattr(frame, "_core_overlay_target_refreshes", 2)
        try:
            target_refreshes = int(target_refreshes)
        except Exception:
            target_refreshes = 2
        if target_refreshes <= 0:
            target_refreshes = 1
        ready_seen = bool(getattr(frame, "_core_overlay_ready_seen", False))
        if not force_clear and (completed_count < target_refreshes or not ready_seen):
            self._log_plot_tab_debug(
                "Core overlay hold for %s: completed=%s target=%s ready_seen=%s."
                % (
                    getattr(frame, "_plot_key", None),
                    completed_count,
                    target_refreshes,
                    ready_seen,
                )
            )
            return
        try:
            frame._core_overlay_hold = False
            frame._core_overlay_second_refresh_scheduled = False
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            frame._plot_auto_refresh_state = "done"
            frame._plot_auto_refresh_after_id = None
            frame._plot_auto_refresh_in_progress = False
            frame._plot_auto_refresh_phase = None
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._log_plot_tab_debug(
            "Core auto-refresh overlay cleared for %s: completed=%s target=%s ready_seen=%s force=%s."
            % (
                getattr(frame, "_plot_key", None),
                completed_count,
                target_refreshes,
                ready_seen,
                force_clear,
            )
        )
        self._update_plot_loading_overlay_progress(
            frame,
            progress=100.0,
            message="Plot ready.",
        )
        self._clear_plot_loading_overlay(frame)

    def _schedule_core_refresh_pass(
        self,
        frame: Optional[ttk.Frame],
        canvas: Optional[FigureCanvasTkAgg],
        *,
        pass_index: int,
    ) -> None:
        """Schedule one core refresh pass for completion-based overlay orchestration."""
        if frame is None or canvas is None:
            return
        if not bool(getattr(frame, "_core_overlay_hold", False)):
            return
        after_id = getattr(frame, "_plot_auto_refresh_after_id", None)
        if after_id is not None:
            return
        try:
            if not frame.winfo_exists():
                self._finalize_core_overlay(frame, force_clear=True)
                return
        except Exception:
            self._finalize_core_overlay(frame, force_clear=True)
            return
        try:
            widget = canvas.get_tk_widget()
        except Exception:
            widget = None
        if widget is None:
            self._finalize_core_overlay(frame, force_clear=True)
            return
        try:
            if not widget.winfo_exists():
                self._finalize_core_overlay(frame, force_clear=True)
                return
        except Exception:
            self._finalize_core_overlay(frame, force_clear=True)
            return
        refresh_command = getattr(frame, "_refresh_command", None)
        if not callable(refresh_command):
            self._log_plot_tab_debug(
                "Core auto-refresh pass %s missing refresh command for %s; clearing overlay."
                % (pass_index, getattr(frame, "_plot_key", None))
            )
            self._finalize_core_overlay(frame, force_clear=True)
            return
        if pass_index <= 1 and getattr(frame, "_core_overlay_layout_sig_baseline", None) is None:
            self._capture_core_overlay_layout_baseline(frame, canvas=canvas)
        if pass_index >= 2:
            try:
                frame._core_overlay_second_refresh_scheduled = True
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _invoke_refresh() -> None:
            """Invoke one scheduled core refresh pass."""
            try:
                frame._plot_auto_refresh_after_id = None
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if not bool(getattr(frame, "_core_overlay_hold", False)):
                return
            invoked_count = getattr(frame, "_core_overlay_refresh_invoked_count", 0)
            try:
                invoked_count = int(invoked_count)
            except Exception:
                invoked_count = 0
            invoked_count += 1
            try:
                frame._core_overlay_refresh_invoked_count = invoked_count
                frame._plot_auto_refresh_state = "refreshing"
                frame._plot_auto_refresh_in_progress = True
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            completed_count = getattr(frame, "_core_overlay_refresh_completed_count", 0)
            self._log_plot_tab_debug(
                "Core auto-refresh pass %s invoked for %s: invoked=%s completed=%s."
                % (
                    pass_index,
                    getattr(frame, "_plot_key", None),
                    invoked_count,
                    completed_count,
                )
            )
            self._update_plot_loading_overlay_progress(
                frame,
                progress=84.0 if pass_index <= 1 else 94.0,
                message=(
                    "Running auto-refresh pass 1..."
                    if pass_index <= 1
                    else "Running auto-refresh pass 2..."
                ),
            )
            try:
                refresh_command()
            except Exception:
                # Fail closed: avoid leaving the overlay stuck if refresh fails.
                self._finalize_core_overlay(frame, force_clear=True)

        try:
            frame._plot_auto_refresh_after_id = widget.after_idle(_invoke_refresh)
        except Exception:
            try:
                frame._plot_auto_refresh_after_id = self.after_idle(_invoke_refresh)
            except Exception:
                _invoke_refresh()

    def _is_real_combined_figure(self, fig: Optional[Figure]) -> bool:
        """Return whether a figure is a real combined render output."""
        if fig is None:
            return False
        return bool(getattr(fig, "_gl260_combined_real_figure", False))

    def _mark_combined_figure_real(self, fig: Optional[Figure]) -> None:
        """Mark a figure as a real combined render output."""
        if fig is None:
            return
        try:
            fig._gl260_combined_real_figure = True  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _combined_rendered_geometry_signature(self, fig: Optional[Figure]) -> Any:
        """Build a rendered-geometry signature for combined overlays."""
        if fig is None:
            return None

        def _norm_num(value: Any) -> Any:
            try:
                value_f = float(value)
            except Exception:
                return value
            if not math.isfinite(value_f):
                return None
            return round(value_f, 4)

        def _norm_tuple(value: Any) -> Any:
            if isinstance(value, (list, tuple)):
                return tuple(_norm_num(item) for item in value)
            return _norm_num(value)

        try:
            size = fig.get_size_inches()
            size_sig = tuple(_norm_num(v) for v in size)
        except Exception:
            size_sig = None
        try:
            subplot = fig.subplotpars
            subplot_sig = (
                _norm_num(getattr(subplot, "left", None)),
                _norm_num(getattr(subplot, "right", None)),
                _norm_num(getattr(subplot, "bottom", None)),
                _norm_num(getattr(subplot, "top", None)),
                _norm_num(getattr(subplot, "wspace", None)),
                _norm_num(getattr(subplot, "hspace", None)),
            )
        except Exception:
            subplot_sig = None
        axes_sig: List[Any] = []
        try:
            for idx, ax in enumerate(list(getattr(fig, "axes", []) or [])):
                if getattr(ax, "_gl260_legend_only", False):
                    continue
                role = str(getattr(ax, "_gl260_axis_role", "") or "")
                try:
                    bounds = tuple(_norm_num(v) for v in ax.get_position().bounds)
                except Exception:
                    bounds = None
                try:
                    xlim = tuple(_norm_num(v) for v in ax.get_xlim())
                except Exception:
                    xlim = None
                try:
                    ylim = tuple(_norm_num(v) for v in ax.get_ylim())
                except Exception:
                    ylim = None
                axes_sig.append((idx, role, bounds, xlim, ylim))
        except Exception:
            axes_sig = []
        legend_sig: List[Any] = []
        try:
            legends = _collect_gl260_legends(fig)
        except Exception:
            legends = []
        for idx, legend in enumerate(legends):
            role = str(getattr(legend, "_gl260_legend_role", "") or "")
            try:
                loc_val = legend.get_loc()
            except Exception:
                loc_val = getattr(legend, "_loc", None)
            try:
                bbox = legend.get_bbox_to_anchor()
                bounds = (
                    tuple(_norm_num(v) for v in bbox.bounds) if bbox is not None else None
                )
            except Exception:
                bounds = None
            legend_sig.append((idx, role, _norm_tuple(loc_val), bounds))
        return (size_sig, subplot_sig, tuple(axes_sig), tuple(legend_sig))

    def _resolve_combined_overlay_figure(
        self,
        frame: Optional[ttk.Frame],
        *,
        canvas: Optional[FigureCanvasTkAgg] = None,
        fig: Optional[Figure] = None,
    ) -> Optional[Figure]:
        """Resolve the active combined figure from direct or tab context."""
        if fig is not None:
            return fig
        resolved_fig = getattr(canvas, "figure", None) if canvas is not None else None
        if resolved_fig is not None:
            return resolved_fig
        if frame is not None:
            plot_key = str(getattr(frame, "_plot_key", "") or "")
            if plot_key:
                _, resolved_canvas = self._find_plot_tab_canvas(plot_key)
                resolved_fig = (
                    getattr(resolved_canvas, "figure", None)
                    if resolved_canvas is not None
                    else None
                )
                if resolved_fig is not None:
                    return resolved_fig
        _, resolved_canvas = self._find_plot_tab_canvas("fig_combined")
        if resolved_canvas is None:
            return None
        return getattr(resolved_canvas, "figure", None)

    def _combined_current_layout_sig(self) -> Any:
        """Return the most recent combined layout signature, if available."""
        state = self._combined_plot_state if isinstance(self._combined_plot_state, dict) else {}
        return self._combined_rendered_geometry_signature(state.get("fig"))

    def _combined_overlay_decision_signature(
        self,
        frame: Optional[ttk.Frame],
        *,
        canvas: Optional[FigureCanvasTkAgg] = None,
        fig: Optional[Figure] = None,
    ) -> Dict[str, Any]:
        """Build the combined adaptive-refresh decision signature bundle.

        Purpose:
            Collect the low-noise signals used to decide whether combined pass 2
            is required.
        Why:
            Combined overlay gating should avoid unconditional second refreshes
            while still failing closed when decision signals are incomplete.
        Inputs:
            frame: Plot tab frame that stores combined overlay orchestration state.
            canvas: Optional active canvas used to resolve the rendered figure.
            fig: Optional explicit figure override for signature collection.
        Outputs:
            Mapping with `data_sig`, `layout_sig`, `elements_sig`, and
            `geometry_sig`; values are None when unavailable.
        Side Effects:
            None.
        Exceptions:
            Resolution failures are guarded; missing values degrade to None.
        """
        active_fig = self._resolve_combined_overlay_figure(frame, canvas=canvas, fig=fig)
        state = self._combined_plot_state if isinstance(self._combined_plot_state, dict) else {}

        data_sig = None
        if frame is not None:
            data_sig = getattr(frame, "_combined_overlay_data_sig_current", None)
        if data_sig is None and active_fig is not None:
            data_sig = getattr(active_fig, "_gl260_combined_data_sig", None)

        layout_sig = getattr(active_fig, "_gl260_combined_layout_sig", None)
        state_fig = state.get("fig")
        if layout_sig is None and active_fig is not None and state_fig is active_fig:
            layout_sig = state.get("layout_sig")
        if layout_sig is None:
            layout_sig = self._combined_layout_state

        return {
            "data_sig": data_sig,
            "layout_sig": layout_sig,
            "elements_sig": self._plot_elements_signature("fig_combined_triple_axis"),
            "geometry_sig": self._overlay_layout_decision_signature(active_fig),
        }

    def _capture_combined_overlay_layout_baseline(
        self,
        frame: Optional[ttk.Frame],
        *,
        canvas: Optional[FigureCanvasTkAgg] = None,
        fig: Optional[Figure] = None,
    ) -> Any:
        """Capture the combined overlay baseline used by adaptive pass selection.

        Purpose:
            Store baseline geometry before the first post-draw combined refresh.
        Why:
            Combined overlay logic should request pass 2 only when material
            layout geometry changed after pass 1.
        Inputs:
            frame: Plot tab frame storing combined overlay state.
            canvas: Optional canvas used to resolve the active combined figure.
            fig: Optional explicit figure override for baseline capture.
        Outputs:
            Baseline decision-signature bundle, or None when unavailable.
        Side Effects:
            Persists baseline metadata on the frame for pass-target derivation.
        Exceptions:
            Resolution and state writes are guarded to avoid UI interruption.
        """
        if frame is None:
            return None
        baseline_bundle = self._combined_overlay_decision_signature(
            frame,
            canvas=canvas,
            fig=fig,
        )
        baseline = baseline_bundle.get("geometry_sig")
        try:
            frame._combined_overlay_layout_sig_baseline = baseline
            frame._combined_overlay_decision_sig_baseline = baseline_bundle
            frame._combined_overlay_decision_sig_last = baseline_bundle
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._log_plot_tab_debug(
            "Combined auto-refresh baseline captured: data=%s layout=%s elements=%s geometry=%s."
            % (
                baseline_bundle.get("data_sig") is not None,
                baseline_bundle.get("layout_sig") is not None,
                baseline_bundle.get("elements_sig") is not None,
                baseline_bundle.get("geometry_sig") is not None,
            )
        )
        return baseline_bundle

    def _mark_combined_overlay_refresh_completed(
        self,
        frame: Optional[ttk.Frame],
        *,
        fig: Optional[Figure] = None,
    ) -> int:
        """Record one combined refresh completion and compute adaptive pass count.

        Purpose:
            Maintain completion counters for combined overlay hold/release flow.
        Why:
            Combined plots should run a second pass only when data/layout/element
            changes also produce a material geometry shift; ambiguous signal
            sets fail closed to a second pass.
        Inputs:
            frame: Plot tab frame storing combined overlay orchestration state.
            fig: Optional combined figure for current-pass signature capture.
        Outputs:
            Integer completion count after increment.
        Side Effects:
            Updates pass-target metadata and stores latest decision signatures on
            the frame after pass 1 completes.
        Exceptions:
            Counter and state writes are guarded to avoid UI disruption.
        """
        if frame is None:
            return 0
        completed_count = getattr(frame, "_combined_overlay_refresh_completed_count", 0)
        try:
            completed_count = int(completed_count)
        except Exception:
            completed_count = 0
        completed_count += 1
        try:
            frame._combined_overlay_refresh_completed_count = completed_count
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if completed_count == 1:
            second_refresh_disabled = self._combined_second_refresh_disabled()
            baseline_bundle = getattr(frame, "_combined_overlay_decision_sig_baseline", None)
            if not isinstance(baseline_bundle, dict):
                baseline_bundle = {
                    "data_sig": None,
                    "layout_sig": None,
                    "elements_sig": None,
                    "geometry_sig": getattr(
                        frame, "_combined_overlay_layout_sig_baseline", None
                    ),
                }
            current_bundle = self._combined_overlay_decision_signature(frame, fig=fig)
            try:
                frame._combined_overlay_decision_sig_last = current_bundle
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            def _changed(key: str) -> Optional[bool]:
                """Compare one baseline/current signature field."""
                baseline_value = baseline_bundle.get(key)
                current_value = current_bundle.get(key)
                if baseline_value is None or current_value is None:
                    return None
                return baseline_value != current_value

            data_changed = _changed("data_sig")
            layout_changed = _changed("layout_sig")
            elements_changed = _changed("elements_sig")
            geometry_changed = _changed("geometry_sig")
            ambiguous = any(
                value is None
                for value in (
                    data_changed,
                    layout_changed,
                    elements_changed,
                    geometry_changed,
                )
            )
            # Conservative adaptive policy: when key decision signals are missing,
            # require pass 2 so the overlay never clears on an uncertain state.
            if ambiguous:
                need_second_refresh = True
            elif not any([data_changed, layout_changed, elements_changed]):
                need_second_refresh = False
            else:
                need_second_refresh = bool(geometry_changed)
            if second_refresh_disabled:
                # Explicit preference override keeps adaptive policy testable by
                # forcing a single-pass target regardless of signal state.
                need_second_refresh = False
            target_refreshes = 2 if need_second_refresh else 1
            try:
                frame._combined_overlay_need_second_refresh = need_second_refresh
                frame._combined_overlay_target_refreshes = target_refreshes
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._log_plot_tab_debug(
                "Combined adaptive refresh decision: need_second=%s target=%s data_changed=%s layout_changed=%s elements_changed=%s geometry_changed=%s ambiguous=%s."
                % (
                    need_second_refresh,
                    target_refreshes,
                    data_changed,
                    layout_changed,
                    elements_changed,
                    geometry_changed,
                    ambiguous,
                )
            )
            if second_refresh_disabled:
                self._log_plot_tab_debug(
                    "Combined adaptive refresh override active: forcing target=1 (second pass disabled)."
                )
        target_refreshes = getattr(
            frame,
            "_combined_overlay_target_refreshes",
            self._combined_overlay_default_target_refreshes(),
        )
        try:
            target_refreshes = int(target_refreshes)
        except Exception:
            target_refreshes = self._combined_overlay_default_target_refreshes()
        if target_refreshes <= 0:
            target_refreshes = 1
        milestone_value = 98.0 if completed_count >= target_refreshes else 90.0
        self._update_plot_loading_overlay_progress(
            frame,
            progress=milestone_value,
            message=(
                "Finalizing combined plot..."
                if completed_count >= target_refreshes
                else "Combined auto-refresh pass complete."
            ),
        )
        return completed_count

    def _resolve_combined_initial_figsize_inches(
        self,
        frame: Optional[ttk.Frame] = None,
        canvas: Optional[FigureCanvasTkAgg] = None,
        *,
        timeout_ms: int = 250,
        poll_ms: int = 25,
    ) -> Tuple[float, float]:
        """Resolve initial combined figsize from the real canvas with a short bounded wait."""
        if frame is None or canvas is None:
            frame, canvas = self._find_plot_tab_canvas("fig_combined")
        return self._resolve_initial_canvas_figsize_inches(
            frame,
            canvas,
            timeout_ms=timeout_ms,
            poll_ms=poll_ms,
            tag="combined",
        )

    def _resolve_initial_canvas_figsize_inches(
        self,
        frame: Optional[ttk.Frame],
        canvas: Optional[FigureCanvasTkAgg],
        *,
        timeout_ms: int = 250,
        poll_ms: int = 25,
        tag: str = "plot",
    ) -> Tuple[float, float]:
        """Resolve initial figsize from a real canvas with a short bounded wait."""
        fallback = self._compute_target_figsize_inches()
        if frame is None or canvas is None:
            self._log_plot_tab_debug(
                "%s initial figsize fallback: frame/canvas unavailable."
                % str(tag).capitalize()
            )
            return fallback
        try:
            widget = canvas.get_tk_widget()
        except Exception:
            widget = None
        if widget is None:
            self._log_plot_tab_debug(
                "%s initial figsize fallback: canvas widget unavailable."
                % str(tag).capitalize()
            )
            return fallback
        timeout_s = max(float(timeout_ms), 0.0) / 1000.0
        poll_s = max(float(poll_ms), 1.0) / 1000.0
        deadline = time.monotonic() + timeout_s
        width_px = 0
        height_px = 0
        while True:
            for widget_obj in (self.nb, frame, widget):
                try:
                    widget_obj.update_idletasks()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            try:
                width_px = int(widget.winfo_width())
                height_px = int(widget.winfo_height())
            except Exception:
                width_px = 0
                height_px = 0
            if width_px > 2 and height_px > 2:
                break
            if time.monotonic() >= deadline:
                width_px = 0
                height_px = 0
                break
            time.sleep(poll_s)
        if width_px <= 2 or height_px <= 2:
            self._log_plot_tab_debug(
                "%s initial figsize fallback: timed out waiting for canvas size."
                % str(tag).capitalize()
            )
            return fallback
        try:
            dpi = float(getattr(canvas.figure, "dpi", 100.0))
            if not math.isfinite(dpi) or dpi <= 0.0:
                dpi = 100.0
        except Exception:
            dpi = 100.0
        size = (max(width_px / dpi, 1.0), max(height_px / dpi, 1.0))
        self._log_plot_tab_debug(
            "%s initial figsize resolved from canvas: %sx%s px -> %.3fx%.3f in."
            % (str(tag).capitalize(), width_px, height_px, size[0], size[1])
        )
        return size

    def _resolve_initial_core_figsize_inches(
        self,
        plot_keys: Sequence[str],
        *,
        timeout_ms: int = 250,
        poll_ms: int = 25,
    ) -> Dict[str, Tuple[float, float]]:
        """Resolve initial core figsizes for selected core plot tabs."""
        sizes: Dict[str, Tuple[float, float]] = {}
        for key in [key for key in plot_keys if key in {"fig1", "fig2"}]:
            frame, canvas = self._find_plot_tab_canvas(key)
            if frame is None or canvas is None:
                continue
            sizes[key] = self._resolve_initial_canvas_figsize_inches(
                frame,
                canvas,
                timeout_ms=timeout_ms,
                poll_ms=poll_ms,
                tag=key,
            )
        return sizes

    def _force_plot_refresh(
        self,
        frame,
        canvas,
        *,
        capture_combined_legend: bool = True,
        refresh_reason: Optional[str] = None,
    ):
        """Force a plot refresh and rebuild as needed.

        Purpose:
            Rebuild the requested plot with current settings and re-install it
            on the existing Tk canvas without changing overall layout rules.
        Why:
            Refresh needs to reuse cached data where possible while preserving
            user-driven legend placement for combined plots.

        Args:
            frame: Tkinter frame hosting the plot tab.
            canvas: FigureCanvasTkAgg displaying the figure.
            capture_combined_legend: When True, capture combined legend anchors
                before refresh if persistence is enabled and not locked.
            refresh_reason: Optional splash message shown while the refresh
                pipeline runs.

        Returns:
            None.

        Side Effects:
            Auto-applies staged Plot Settings dialog values before refresh so
            manual Refresh always uses the latest dialog inputs.
            Captures combined legend anchors before rebuild when enabled, applies
            or reattaches the loading overlay for refresh visibility, applies
            display/layout finalization for the active canvas (including the
            combined plot on every refresh), defers combined refresh until
            geometry is ready, starts background compute, and schedules UI-thread
            rendering/overlay updates. When provided, `refresh_reason` is used
            as the initial overlay message.

        Exceptions:
            Internal errors are caught and ignored to keep UI responsive.
        """
        plot_key = getattr(frame, "_plot_key", None)
        plot_id = self._plot_key_to_plot_id(plot_key)
        if not plot_id:
            plot_id = getattr(frame, "_plot_id", None)
        try:
            # Refresh should honor any in-flight Plot Settings edits before
            # building a new render snapshot to avoid stale/default margins.
            self._flush_open_plot_settings_dialog(refresh_after_apply=False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        auto_state = getattr(frame, "_plot_auto_refresh_state", None)
        if auto_state == "scheduled":
            # Manual refresh should satisfy the pending auto-refresh and avoid
            # duplicates.
            after_id = getattr(frame, "_plot_auto_refresh_after_id", None)
            if after_id is not None:
                try:
                    self.after_cancel(after_id)
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass
            frame._plot_auto_refresh_after_id = None
            frame._plot_auto_refresh_state = "refreshing"
            frame._plot_auto_refresh_in_progress = True
        overlay_message = (
            str(refresh_reason).strip()
            if isinstance(refresh_reason, str) and str(refresh_reason).strip()
            else (
                "Refreshing combined plot..."
                if plot_key == "fig_combined"
                else "Refreshing plot..."
            )
        )
        refresh_widget = None
        try:
            refresh_widget = canvas.get_tk_widget()
        except Exception:
            refresh_widget = None
        if refresh_widget is not None:
            try:
                if not refresh_widget.winfo_exists():
                    refresh_widget = None
            except Exception:
                refresh_widget = None
        if refresh_widget is not None:
            # Reattach the overlay before refresh so stale content never flashes.
            self._install_plot_loading_overlay(
                frame,
                refresh_widget,
                message=overlay_message,
            )
        self._update_plot_loading_overlay_progress(
            frame,
            progress=12.0,
            message=overlay_message,
            reset=True,
        )
        combined_widget = None
        combined_size = None
        if plot_key == "fig_combined":
            try:
                frame._combined_render_ready = False
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            try:
                self.nb.select(frame)
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            # Ensure geometry is settled before rebuilding the combined figure.
            try:
                frame.update_idletasks()
                self.nb.update_idletasks()
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            try:
                combined_widget = canvas.get_tk_widget()
            except Exception:
                combined_widget = None
            if combined_widget is not None:
                try:
                    combined_widget.update_idletasks()
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass
                try:
                    width_px = int(combined_widget.winfo_width())
                    height_px = int(combined_widget.winfo_height())
                except Exception:
                    width_px = 0
                    height_px = 0
                if width_px <= 2 or height_px <= 2:
                    # Defer combined refresh until widget geometry is ready.
                    try:
                        self.after(
                            50,
                            lambda: self._force_plot_refresh(
                                frame,
                                canvas,
                                capture_combined_legend=capture_combined_legend,
                                refresh_reason=refresh_reason,
                            ),
                        )
                    except Exception:
                        self.after_idle(
                            lambda: self._force_plot_refresh(
                                frame,
                                canvas,
                                capture_combined_legend=capture_combined_legend,
                                refresh_reason=refresh_reason,
                            )
                        )
                    return
                combined_size = (max(width_px, 1), max(height_px, 1))
        if (
            plot_key == "fig_combined"
            and capture_combined_legend
            and self._combined_cycle_legend_capture_enabled()
        ):
            # Capture current legend anchors before rebuilding the combined figure.
            try:
                self._capture_combined_legend_anchor_from_fig(
                    getattr(canvas, "figure", None),
                    source="refresh",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            self._refresh_canvas_display(frame, canvas, trigger_resize=True)
        except Exception:
            # Best-effort guard; ignore failures.
            pass
        placement_state = self._capture_plot_element_placement_state(plot_id)
        fig_size = None
        if plot_key in {"fig1", "fig2"}:
            fig_size = self._resolve_initial_canvas_figsize_inches(
                frame,
                canvas,
                timeout_ms=250,
                poll_ms=25,
                tag=f"{plot_key} refresh",
            )
        if plot_key == "fig_combined":
            try:
                if combined_size is None:
                    widget = canvas.get_tk_widget()
                    widget.update_idletasks()
                    width_px = max(int(widget.winfo_width()), 1)
                    height_px = max(int(widget.winfo_height()), 1)
                    combined_size = (width_px, height_px)
                dpi = float(getattr(canvas.figure, "dpi", 100.0))
                if not math.isfinite(dpi) or dpi <= 0:
                    dpi = 100.0
                fig_size = (
                    max((combined_size[0] if combined_size else 1) / dpi, 1.0),
                    max((combined_size[1] if combined_size else 1) / dpi, 1.0),
                )
            except Exception:
                fig_size = self._compute_target_figsize_inches()

        try:
            if plot_key in {"fig1", "fig2", "fig_peaks"}:
                snapshot = self._capture_plot_render_snapshot(
                    fig_size=fig_size if plot_key in {"fig1", "fig2"} else None,
                    plot_id=plot_id or "",
                    target="display",
                )
                self._start_core_render_async(
                    snapshot,
                    [plot_key],
                    warn_on_failure=False,
                    placement_states={plot_key: placement_state},
                )
                return
            if plot_key == "fig_combined":
                snapshot = self._capture_plot_render_snapshot(
                    fig_size=fig_size,
                    plot_id=plot_id or "fig_combined_triple_axis",
                    target="display",
                )
                self._start_combined_render_async(
                    snapshot,
                    warn_on_failure=False,
                    frame=frame,
                    canvas=canvas,
                    placement_state=placement_state,
                )
                return
        except Exception:
            # Best-effort fallback: keep the existing figure visible.
            fig = getattr(canvas, "figure", None)
            if fig is None:
                return
            try:
                if plot_key == "fig_combined":
                    self._finalize_combined_plot_display(
                        frame,
                        canvas,
                        placement_state=placement_state,
                    )
                else:
                    self._finalize_plot_refresh(canvas, fig)
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            if plot_key != "fig_combined":
                try:
                    if plot_key in {"fig1", "fig2"} and bool(
                        getattr(frame, "_core_overlay_hold", False)
                    ):
                        self._finalize_core_overlay(frame, force_clear=True)
                    elif (
                        getattr(frame, "_plot_auto_refresh_state", None) == "refreshing"
                    ):
                        self._complete_plot_auto_refresh(frame)
                except Exception:
                    # Best-effort guard; ignore failures.
                    pass
            return

    def _plot_key_to_plot_id(
        self, plot_key: Optional[str], title: Optional[str] = None
    ) -> Optional[str]:
        """Perform plot key to plot ID.
        Used to keep the workflow logic localized and testable."""
        mapping = {
            "fig1": "fig_pressure_temp",
            "fig2": "fig_pressure_derivative",
            "fig_combined": "fig_combined_triple_axis",
            "fig_peaks": "fig_cycle_analysis",
        }
        plot_id = mapping.get(plot_key or "")
        if plot_id:
            return plot_id
        if title:
            slug = re.sub(r"[^a-z0-9]+", "_", title.strip().lower()).strip("_")
            if slug:
                return f"plot_tab_{slug}"
        return None

    def _resolve_plot_element_axes(self, fig: Figure) -> Dict[str, Axes]:
        """Resolve plot element axes.
        Used to compute plot element axes before rendering or export."""
        axes_map: Dict[str, Axes] = {}
        # Iterate over fig.axes to apply the per-item logic.
        for ax in fig.axes:
            if getattr(ax, "_gl260_legend_only", False):
                continue
            role = getattr(ax, "_gl260_axis_role", None)
            if isinstance(role, str):
                role_key = role.strip().lower()
                if role_key in {"primary", "right", "third"}:
                    axes_map.setdefault(role_key, ax)
        if "primary" not in axes_map:
            # Iterate over fig.axes to apply the per-item logic.
            for ax in fig.axes:
                if getattr(ax, "_gl260_legend_only", False):
                    continue
                axes_map["primary"] = ax
                break
        primary = axes_map.get("primary")
        if primary is not None:
            axes_map.setdefault("right", primary)
            axes_map.setdefault("third", primary)
        return axes_map

    def _plot_element_axis_labels(self, fig: Figure) -> Dict[str, str]:
        """Perform plot element axis labels.
        Used to keep the workflow logic localized and testable."""
        axes_map = self._resolve_plot_element_axes(fig)
        fallback = {"primary": "Axis 1", "right": "Axis 2", "third": "Axis 3"}
        labels: Dict[str, str] = {}
        # Iterate over ("primary", "right", "third") to apply the per-item logic.
        for role in ("primary", "right", "third"):
            ax = axes_map.get(role)
            label = ""
            if ax is not None:
                try:
                    label = str(ax.get_ylabel() or "").strip()
                except Exception:
                    label = ""
                if not label:
                    try:
                        label = str(ax.get_title() or "").strip()
                    except Exception:
                        label = ""
            if not label:
                label = fallback[role]
            labels[role] = label
        counts: Dict[str, int] = {}
        # Iterate over values from labels to apply the per-item logic.
        for label in labels.values():
            counts[label] = counts.get(label, 0) + 1
        if any(count > 1 for count in counts.values()):
            suffix = {"primary": "Axis 1", "right": "Axis 2", "third": "Axis 3"}
            # Iterate over items from labels to apply the per-item logic.
            for role, label in labels.items():
                if counts[label] > 1:
                    labels[role] = f"{label} ({suffix[role]})"
        return labels

    def _clear_plot_element_artists(self, fig: Figure) -> None:
        """Clear plot element artists.
        Used to reset plot element artists state safely."""
        if hasattr(self, "_annotation_renderer"):
            try:
                self._annotation_renderer.clear(fig)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        raw_artists = list(getattr(fig, "_gl260_plot_element_artists", []) or [])
        artists: List[Any] = []
        # Iterate over raw_artists to apply the per-item logic.
        for artist in raw_artists:
            if isinstance(artist, (list, tuple)):
                artists.extend([child for child in artist if child is not None])
            elif artist is not None:
                artists.append(artist)
        # Iterate over artists to apply the per-item logic.
        for artist in artists:
            try:
                artist.remove()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        fig._gl260_plot_element_artists = []
        # Iterate over fig.axes to apply the per-item logic.
        for ax in fig.axes:
            candidates = []
            try:
                candidates.extend(ax.patches)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                candidates.extend(ax.lines)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                candidates.extend(ax.texts)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                candidates.extend(ax.artists)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            # Iterate over list(candidates) to apply the per-item logic.
            for artist in list(candidates):
                if getattr(artist, "_gl260_plot_element_editor_only", False):
                    try:
                        artist.remove()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

    def _plot_element_style_value(
        self, style: Mapping[str, Any], key: str, default: float
    ) -> float:
        """Perform plot element style value.
        Used to keep the workflow logic localized and testable."""
        try:
            value = float(style.get(key, default))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return default
        if not math.isfinite(value):
            return default
        return value

    def _build_plot_element_artist(
        self, ax: Axes, element: Mapping[str, Any]
    ) -> Optional[Any]:
        """Build plot element artist.
        Used to assemble plot element artist during UI or plot setup."""
        if not element or not isinstance(element, Mapping):
            return None
        if not element.get("visible", True):
            return None
        element_type = str(element.get("type") or "").strip().lower()
        coords = str(element.get("coords") or "data").strip().lower()
        data = element.get("data") if isinstance(element.get("data"), dict) else {}
        style = element.get("style") if isinstance(element.get("style"), dict) else {}
        alpha = max(0.0, min(1.0, self._plot_element_style_value(style, "alpha", 0.9)))
        linewidth = max(0.5, self._plot_element_style_value(style, "linewidth", 1.5))
        fontsize = max(6.0, self._plot_element_style_value(style, "fontsize", 10.0))
        color = style.get("color") or "#000000"
        transform = ax.transAxes if coords == "axes" else ax.transData

        if element_type == "text":
            text_value = data.get("text", "Text")
            x = data.get("x")
            y = data.get("y")
            if x is None or y is None:
                return None
            artist = ax.text(
                x,
                y,
                text_value,
                transform=transform,
                fontsize=fontsize,
                color=color,
                alpha=alpha,
                va="bottom",
                ha="left",
            )
        elif element_type == "arrow":
            x0 = data.get("x0")
            y0 = data.get("y0")
            x1 = data.get("x1")
            y1 = data.get("y1")
            if None in (x0, y0, x1, y1):
                return None
            text_value = data.get("text", "")
            coord_key = "axes fraction" if coords == "axes" else "data"
            artist = ax.annotate(
                text_value,
                xy=(x1, y1),
                xytext=(x0, y0),
                xycoords=coord_key,
                textcoords=coord_key,
                arrowprops={
                    "arrowstyle": "->",
                    "linewidth": linewidth,
                    "color": color,
                    "alpha": alpha,
                },
            )
        elif element_type == "point":
            x = data.get("x")
            y = data.get("y")
            if x is None or y is None:
                return None
            marker_size = max(6.0, linewidth * 3.5)
            (artist,) = ax.plot(
                [x],
                [y],
                linestyle="None",
                marker="o",
                markersize=marker_size,
                color=color,
                alpha=alpha,
                transform=transform,
            )
        elif element_type == "xspan":
            from matplotlib import patches as mpatches

            x0 = data.get("x0")
            x1 = data.get("x1")
            if x0 is None or x1 is None:
                return None
            left = min(x0, x1)
            width = abs(x1 - x0)
            if coords == "axes":
                span_transform = ax.transAxes
            else:
                span_transform = ax.get_xaxis_transform()
            rect = mpatches.Rectangle(
                (left, 0.0),
                width,
                1.0,
                transform=span_transform,
                facecolor=color,
                edgecolor=color,
                linewidth=linewidth,
                alpha=alpha,
            )
            ax.add_patch(rect)
            artist = rect
        elif element_type == "xspan_text":
            from matplotlib import patches as mpatches
            from matplotlib import transforms

            x0 = data.get("x0")
            x1 = data.get("x1")
            if x0 is None or x1 is None:
                return None
            left = min(x0, x1)
            width = abs(x1 - x0)
            if coords == "axes":
                span_transform = ax.transAxes
                text_transform = ax.transAxes
            else:
                span_transform = ax.get_xaxis_transform()
                text_transform = transforms.blended_transform_factory(
                    ax.transData, ax.transAxes
                )
            rect = mpatches.Rectangle(
                (left, 0.0),
                width,
                1.0,
                transform=span_transform,
                facecolor=color,
                edgecolor=color,
                linewidth=linewidth,
                alpha=alpha,
            )
            ax.add_patch(rect)
            text_value = data.get("text", "Note")
            try:
                text_y = float(data.get("text_y", 0.92))
            except Exception:
                text_y = 0.92
            text_align = str(data.get("text_align") or "center").strip().lower()
            if text_align not in {"left", "center", "right"}:
                text_align = "center"
            x_mid = (x0 + x1) / 2.0
            wrapped_text = text_value
            span_px = None
            try:
                if coords == "axes":
                    span_transform_width = ax.transAxes
                    y_ref = 0.5
                else:
                    span_transform_width = ax.transData
                    y_limits = ax.get_ylim()
                    y_ref = (y_limits[0] + y_limits[1]) / 2.0
                x0_disp = span_transform_width.transform((x0, y_ref))[0]
                x1_disp = span_transform_width.transform((x1, y_ref))[0]
                span_px = abs(x1_disp - x0_disp)
            except Exception:
                span_px = None
            if span_px is not None:
                fig = ax.figure
                dpi = fig.dpi if fig is not None else 72.0
                fontsize_px = max(1.0, fontsize * dpi / 72.0)
                pad_px = max(6.0, fontsize_px * 0.8)
                usable_px = max(1.0, span_px - pad_px)
                avg_char_px = max(4.0, fontsize_px * 0.6)
                max_chars = max(1, int(usable_px / avg_char_px))
                if max_chars >= 1:
                    wrapped_lines = []
                    # Iterate over str(text_value).splitlines() to apply the per-item logic.
                    for line in str(text_value).splitlines():
                        if not line:
                            wrapped_lines.append("")
                            continue
                        wrapped_lines.extend(
                            textwrap.fill(line, width=max_chars).splitlines()
                        )
                    wrapped_text = "\n".join(wrapped_lines)
            text_artist = ax.text(
                x_mid,
                text_y,
                wrapped_text,
                transform=text_transform,
                fontsize=fontsize,
                color=color,
                alpha=alpha,
                ha=text_align,
                va="center",
                bbox=dict(
                    facecolor="white",
                    edgecolor="none",
                    alpha=0.85,
                    boxstyle="round,pad=0.2",
                ),
            )
            text_artist.set_wrap(True)
            artists = [rect, text_artist]
        elif element_type == "freehand":
            points = data.get("points")
            if not points:
                return None
            try:
                xs, ys = zip(*points)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            line = Line2D(xs, ys, color=color, alpha=alpha, linewidth=linewidth)
            if coords == "axes":
                line.set_transform(ax.transAxes)
            ax.add_line(line)
            artist = line
        else:
            return None

        if element_type == "xspan_text":
            # Iterate over artists to apply the per-item logic.
            for child in artists:
                try:
                    child._gl260_plot_element = element
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            return artists
        try:
            artist._gl260_plot_element = element
        except Exception:
            # Best-effort guard; ignore failures.
            pass
        return artist

    def _apply_plot_elements(self, fig: Figure, plot_id: str) -> None:
        """Apply plot elements.
        Used to apply plot elements changes to live state."""
        if fig is None or not plot_id:
            return
        elements_map = settings.get("plot_elements", {})
        elements = elements_map.get(plot_id) if isinstance(elements_map, dict) else []
        self._clear_plot_element_artists(fig)
        axes_map = self._resolve_plot_element_axes(fig)
        effective_elements = elements or []
        self._annotation_renderer.render(fig, axes_map, effective_elements)
        scatter_series_settings = settings.get("scatter_series", {})
        self._annotation_renderer.apply_trace_behavior_filters(
            fig,
            effective_elements,
            scatter_series_settings
            if isinstance(scatter_series_settings, Mapping)
            else {},
        )

    def _apply_display_settings_for_plot(
        self,
        fig: Figure,
        plot_id: str,
        canvas: FigureCanvasTkAgg,
    ) -> None:
        """Apply display settings for a plot figure.

        Purpose:
            Centralize the display settings stack for plot figures.
        Why:
            Async render installs and initial tab creation must apply layout
            profiles, plot elements, and annotation bindings before refresh.
        Inputs:
            fig: Matplotlib Figure to update for display.
            plot_id: Plot identifier used for settings lookup.
            canvas: FigureCanvasTkAgg associated with the display.
        Outputs:
            None.
        Side Effects:
            Applies layout profiles, re-renders plot elements, and creates or
            retargets annotation controllers for the figure/canvas pair.
        Exceptions:
            Errors are caught to avoid interrupting UI workflows.
        """
        if fig is None or not plot_id or canvas is None:
            return
        try:
            _apply_layout_profile_to_figure(fig, plot_id, "display")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._apply_plot_elements(fig, plot_id)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        controller = self._plot_annotation_controllers.get(plot_id)
        if controller is None:
            try:
                axes_map = self._resolve_plot_element_axes(fig)
            except Exception:
                axes_map = {}
            try:
                axis_labels = self._plot_element_axis_labels(fig)
            except Exception:
                axis_labels = {}
            try:
                controller = PlotAnnotationsController(
                    plot_id,
                    fig,
                    canvas,
                    self._annotation_store,
                    self._annotation_renderer,
                    axes_map,
                    axis_labels,
                    on_elements_changed=self._mark_plot_elements_dirty,
                )
                self._plot_annotation_controllers[plot_id] = controller
            except Exception:
                controller = None
        # Create or retarget controllers so annotation bindings follow the final fig/canvas pair.
        if controller is not None:
            try:
                self._retarget_plot_annotation_controller(plot_id, fig, canvas)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _retarget_plot_annotation_controller(
        self, plot_id: str, fig: Figure, canvas: FigureCanvasTkAgg
    ) -> None:
        """Perform retarget plot annotation controller.
        Used to keep the workflow logic localized and testable."""
        if not plot_id or fig is None or canvas is None:
            return
        controller = self._plot_annotation_controllers.get(plot_id)
        if controller is None:
            return
        self._log_plot_tab_debug(
            f"Retargeting plot annotation controller for {plot_id}."
        )
        axes_map = {}
        axis_labels = {}
        try:
            axes_map = self._resolve_plot_element_axes(fig)
        except Exception:
            axes_map = {}
        try:
            axis_labels = self._plot_element_axis_labels(fig)
        except Exception:
            axis_labels = {}
        try:
            controller.rebind(fig, canvas, axes_map, axis_labels)
        except Exception:
            try:
                controller.set_target(fig, canvas)
            except Exception:
                pass
            try:
                controller.update_axis_map(fig, axes_map, axis_labels)
            except Exception:
                pass
            try:
                controller.render()
            except Exception:
                pass
        self._log_plot_tab_debug(
            f"Plot annotation controller retarget complete for {plot_id}."
        )
        window = self._plot_element_windows.get(plot_id)
        panel = self._plot_annotation_panels.get(plot_id)
        if window is not None:
            try:
                if not window.winfo_exists():
                    window = None
            except Exception:
                window = None
        if window is not None:
            if panel is not None:
                try:
                    panel.refresh()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            else:
                try:
                    window.destroy()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                self._plot_element_windows.pop(plot_id, None)
                self._plot_element_editors.pop(plot_id, None)

    def _capture_plot_element_placement_state(
        self, plot_id: Optional[str]
    ) -> Optional[Dict[str, Any]]:
        """Perform capture plot element placement state.
        Used to keep the workflow logic localized and testable."""
        if not plot_id:
            return None
        controller = self._plot_annotation_controllers.get(plot_id)
        if controller is None:
            return None
        element_type = getattr(controller, "_placing_type", None)
        if not element_type:
            return None
        return {
            "type": element_type,
            "style_overrides": dict(
                getattr(controller, "_placing_style_overrides", {}) or {}
            ),
            "geometry_seed": dict(
                getattr(controller, "_placing_geometry_seed", {}) or {}
            ),
            "axis_target": getattr(controller, "_placing_axis_target", None),
            "coord_space": getattr(controller, "_placing_coord_space", None),
            "keep_placing": bool(getattr(controller, "_placing_keep_placing", False)),
        }

    def _restore_plot_element_placement_state(
        self, plot_id: Optional[str], placement_state: Optional[Dict[str, Any]]
    ) -> None:
        """Perform restore plot element placement state.
        Used to keep the workflow logic localized and testable."""
        if not plot_id or not placement_state:
            return
        controller = self._plot_annotation_controllers.get(plot_id)
        if controller is None:
            return
        element_type = placement_state.get("type")
        if not element_type:
            return
        style_overrides = dict(placement_state.get("style_overrides") or {})
        if placement_state.get("keep_placing"):
            style_overrides["_keep_placing"] = True
        try:
            controller.begin_place_element(
                element_type,
                style_overrides,
                geometry_seed=placement_state.get("geometry_seed"),
                axis_target=placement_state.get("axis_target"),
                coord_space=placement_state.get("coord_space"),
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        panel = self._plot_annotation_panels.get(plot_id)
        if panel is not None:
            try:
                panel.set_add_placement_active(True)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _ensure_plot_dirty_flags(
        self, plot_id: Optional[str]
    ) -> Optional[Dict[str, bool]]:
        """Perform ensure plot dirty flags.
        Used to keep the workflow logic localized and testable."""
        if not plot_id:
            return None
        flags = self._plot_dirty_flags.get(plot_id)
        if not isinstance(flags, dict):
            flags = {
                "dirty_data": True,
                "dirty_layout": True,
                "dirty_elements": True,
            }
            self._plot_dirty_flags[plot_id] = flags
        else:
            flags.setdefault("dirty_data", True)
            flags.setdefault("dirty_layout", True)
            flags.setdefault("dirty_elements", True)
        return flags

    def _set_plot_dirty_flags(
        self,
        plot_id: Optional[str],
        *,
        dirty_data: Optional[bool] = None,
        dirty_layout: Optional[bool] = None,
        dirty_elements: Optional[bool] = None,
    ) -> None:
        """Set plot dirty flags.
        Used to persist plot dirty flags into the current state."""
        flags = self._ensure_plot_dirty_flags(plot_id)
        if flags is None:
            return
        if dirty_data is not None:
            flags["dirty_data"] = bool(dirty_data)
        if dirty_layout is not None:
            flags["dirty_layout"] = bool(dirty_layout)
        if dirty_elements is not None:
            flags["dirty_elements"] = bool(dirty_elements)

    def _mark_plot_data_dirty(self, plot_id: Optional[str] = None) -> None:
        """Perform mark plot data dirty.
        Used to keep the workflow logic localized and testable."""
        if plot_id:
            self._set_plot_dirty_flags(plot_id, dirty_data=True)
            return
        seen = set(self._plot_dirty_flags.keys())
        # Iterate over keys from list(self._plot_annotation_controllers to apply the per-item logic.
        for key in list(self._plot_annotation_controllers.keys()):
            seen.add(key)
        # Iterate over seen to apply the per-item logic.
        for key in seen:
            self._set_plot_dirty_flags(key, dirty_data=True)

    def _mark_plot_layout_dirty(self, plot_id: Optional[str] = None) -> None:
        """Perform mark plot layout dirty.
        Used to keep the workflow logic localized and testable."""
        if not plot_id:
            return
        self._set_plot_dirty_flags(plot_id, dirty_layout=True)

    def _mark_plot_elements_dirty(self, plot_id: Optional[str] = None) -> None:
        """Perform mark plot elements dirty.
        Used to keep the workflow logic localized and testable."""
        if not plot_id:
            return
        self._set_plot_dirty_flags(plot_id, dirty_elements=True)

    def _refresh_plot_for_plot_id(
        self,
        plot_id: Optional[str],
        *,
        reason: Optional[str] = None,
        rearm_overlay: bool = False,
        capture_combined_legend: bool = True,
    ) -> None:
        """Run one unified refresh pipeline for a plot tab.

        Purpose:
            Route plot-tab refresh requests through one overlay-aware path.
        Why:
            Plot Settings/Data Trace/Layout apply actions and manual Refresh
            must share the same stabilization pipeline to avoid post-splash
            layout snaps.
        Inputs:
            plot_id: Plot identifier for the target tab.
            reason: Optional splash message shown at refresh start.
            rearm_overlay: When True, reset overlay orchestration state before
                invoking refresh.
            capture_combined_legend: When True, capture combined legend anchors
                before combined refresh rebuild.
        Outputs:
            None.
        Side Effects:
            Optionally resets overlay orchestration state and invokes
            `_force_plot_refresh` for the target tab/canvas.
        Exceptions:
            Best-effort guards suppress refresh failures to keep UI responsive.
        """
        if not plot_id:
            return
        if rearm_overlay:
            try:
                self._prepare_plot_refresh_overlay_for_settings(plot_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        # Iterate over indexed elements from getattr(self, "_plot_tabs", []) or [] to apply the per-item logic.
        for idx, tab in enumerate(getattr(self, "_plot_tabs", []) or []):
            if getattr(tab, "_plot_id", None) != plot_id:
                continue
            if idx < len(getattr(self, "_canvases", []) or []):
                canvas = self._canvases[idx]
                try:
                    self._force_plot_refresh(
                        tab,
                        canvas,
                        capture_combined_legend=capture_combined_legend,
                        refresh_reason=reason,
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            break

    def _prepare_plot_refresh_overlay_for_settings(
        self, plot_id: Optional[str]
    ) -> None:
        """Re-arm overlay orchestration before a settings-triggered plot refresh.

        Purpose:
            Ensure settings-driven refreshes keep plot overlays visible until final
            layout stabilization passes complete.
        Why:
            Plot Settings apply can run after prior refresh state has already settled;
            without resetting per-frame counters and hold flags, overlays can clear
            too early and expose late layout margin snaps.
        Args:
            plot_id: Plot identifier targeted by the settings dialog apply action.
        Returns:
            None.
        Side Effects:
            Cancels stale scheduled callbacks, resets per-frame auto-refresh counters
            and signatures, and re-enables core/combined overlay hold flags so the
            refresh pipeline completes behind the loading overlay.
        Exceptions:
            Best-effort guards ignore callback-cancel and attribute-write failures to
            avoid interrupting the UI workflow.
        """
        if not plot_id:
            return
        plot_tabs = list(getattr(self, "_plot_tabs", []) or [])
        canvases = list(getattr(self, "_canvases", []) or [])

        def _cancel_after(callback_id: Any, tk_widget: Optional[Any]) -> None:
            """Cancel one scheduled Tk callback id using widget/root fallbacks.

            Purpose:
                Clear stale scheduled callback handles before re-arming refresh state.
            Why:
                Old `after` callbacks can race with settings-triggered refresh passes
                and prematurely clear overlay guards.
            Args:
                callback_id: Tk callback handle returned by `after`/`after_idle`.
                tk_widget: Optional widget used to cancel widget-scoped callbacks.
            Returns:
                None.
            Side Effects:
                Cancels queued callbacks when they still exist.
            Exceptions:
                Uses best-effort guards and ignores invalid/expired callback ids.
            """
            if callback_id is None:
                return
            if tk_widget is not None:
                try:
                    tk_widget.after_cancel(callback_id)
                    return
                except Exception:
                    # Best-effort guard; fallback to root-level cancellation.
                    pass
            try:
                self.after_cancel(callback_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Iterate over indexed tab frames so canvas references stay aligned.
        for idx, frame in enumerate(plot_tabs):
            if getattr(frame, "_plot_id", None) != plot_id:
                continue
            canvas = canvases[idx] if idx < len(canvases) else None
            tk_widget = None
            if canvas is not None:
                try:
                    tk_widget = canvas.get_tk_widget()
                except Exception:
                    tk_widget = None

            scheduled_after_id = getattr(frame, "_plot_auto_refresh_after_id", None)
            _cancel_after(scheduled_after_id, tk_widget)
            try:
                frame._plot_auto_refresh_after_id = None
                frame._plot_auto_refresh_in_progress = False
                frame._plot_auto_refresh_phase = None
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            if plot_id in {"fig_pressure_temp", "fig_pressure_derivative"}:
                try:
                    frame._core_overlay_refresh_invoked_count = 0
                    frame._core_overlay_refresh_completed_count = 0
                    frame._core_overlay_layout_sig_baseline = None
                    frame._core_overlay_need_second_refresh = True
                    frame._core_overlay_target_refreshes = 2
                    frame._core_overlay_ready_seen = False
                    frame._core_overlay_second_refresh_scheduled = False
                    frame._core_overlay_hold = True
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            elif plot_id == "fig_combined_triple_axis":
                prior_finalize_after_id = getattr(
                    frame, "_combined_overlay_finalize_after_id", None
                )
                _cancel_after(prior_finalize_after_id, tk_widget)
                default_target_refreshes = (
                    self._combined_overlay_default_target_refreshes()
                )
                try:
                    frame._post_first_draw_refresh_done = False
                    frame._post_first_draw_refresh_invoked = False
                    frame._post_first_draw_refresh_hold_overlay = True
                    frame._post_first_draw_refresh_retry_count = 0
                    frame._combined_overlay_refresh_invoked_count = 0
                    frame._combined_overlay_refresh_completed_count = 0
                    frame._combined_overlay_layout_sig_baseline = None
                    frame._combined_overlay_decision_sig_baseline = None
                    frame._combined_overlay_decision_sig_last = None
                    frame._combined_overlay_data_sig_current = None
                    frame._combined_overlay_need_second_refresh = (
                        default_target_refreshes > 1
                    )
                    frame._combined_overlay_target_refreshes = default_target_refreshes
                    frame._combined_overlay_ready_seen = False
                    frame._combined_overlay_second_refresh_scheduled = False
                    frame._combined_placeholder_draw_logged = False
                    frame._combined_overlay_last_geometry_sig = None
                    frame._combined_overlay_stable_draw_count = 0
                    frame._combined_overlay_finalize_started_at = None
                    frame._combined_overlay_finalize_after_id = None
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            break

    def _open_plot_settings_for_active_tab(self) -> None:
        """Open plot settings for active tab.
        Used by UI actions to open plot settings for active tab."""
        plot_id = None
        try:
            current = self.nb.select()
            if current:
                tab = self.nametowidget(current)
                plot_id = getattr(tab, "_plot_id", None)
        except Exception:
            plot_id = None
        self._open_plot_settings_dialog(plot_id or "fig_combined_triple_axis")

    def _sync_plot_layout_profile(
        self,
        plot_id: str,
        *,
        display_margins: Optional[Mapping[str, float]] = None,
        export_margins: Optional[Mapping[str, float]] = None,
        legend_anchor_y_display: Optional[float] = None,
        legend_anchor_y_export: Optional[float] = None,
    ) -> None:
        """Perform sync plot layout profile.
        Used to keep the workflow logic localized and testable."""
        profile = _get_layout_profile(plot_id)
        # Iterate to apply the per-item logic.
        for mode, margins, anchor_y in (
            ("display", display_margins, legend_anchor_y_display),
            ("export", export_margins, legend_anchor_y_export),
        ):
            section = profile.setdefault(mode, {})
            if margins is not None:
                section["margins"] = _normalize_layout_margins(
                    margins, _default_layout_margins(plot_id, mode)
                )
            if anchor_y is not None:
                try:
                    anchor_value = float(anchor_y)
                except Exception:
                    anchor_value = None
                if anchor_value is not None and math.isfinite(anchor_value):
                    section["legend_anchor_y"] = max(-0.1, min(1.1, anchor_value))
        settings["layout_profiles"] = _normalize_layout_profiles(
            settings.get("layout_profiles")
        )

    def _clear_plot_elements_for_plot_id(
        self,
        plot_id: str,
        fig: Optional[Figure] = None,
        *,
        save: bool = True,
    ) -> None:
        """Clear plot elements for plot ID.
        Used to reset plot elements for plot ID state safely."""
        elements = self._plot_elements.get(plot_id, [])
        if isinstance(elements, list):
            self._plot_elements[plot_id] = []
        try:
            self._annotation_store.set_elements(plot_id, [])
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if fig is not None:
            try:
                self._clear_plot_element_artists(fig)
                if fig.canvas:
                    fig.canvas.draw_idle()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        controller = self._plot_annotation_controllers.get(plot_id)
        if controller is not None:
            controller.set_selected_id(None)
            controller.render()
        try:
            self.settings["plot_elements"][plot_id] = []
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if save:
            _save_settings_to_disk()
        try:
            self._mark_plot_elements_dirty(plot_id)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _open_plot_elements_editor(
        self, fig: Figure, canvas: FigureCanvasTkAgg, plot_id: str
    ) -> None:
        """Open the Plot Elements editor for one rendered plot.

        Purpose:
            Launch the annotation/elements editor bound to a specific plot tab.
        Why:
            Users need a dedicated surface for per-plot visual elements without
            crowding the main workflow tabs.
        Args:
            fig: Active Matplotlib figure for the selected plot tab.
            canvas: Tk canvas hosting `fig`.
            plot_id: Internal plot identifier used for controller/state lookup.
        Returns:
            None.
        Side Effects:
            Creates or focuses a modal editor window, wires callbacks that can
            mutate figure annotations, and stores window references per plot.
        Exceptions:
            Best-effort guards prevent UI interruption if controller/window lookups fail.
        """
        if not plot_id:
            return
        controller = self._plot_annotation_controllers.get(plot_id)
        if controller is None:
            return
        existing = self._plot_element_windows.get(plot_id)
        if existing is not None and existing.winfo_exists():
            try:
                existing.deiconify()
                existing.lift()
                existing.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        axes_map = self._resolve_plot_element_axes(fig)
        axis_labels = self._plot_element_axis_labels(fig)
        try:
            controller.set_target(fig, canvas)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            controller.update_axis_map(fig, axes_map, axis_labels)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        ui_state = self._annotation_store.ui_state_for(plot_id)
        editor = tk.Toplevel(self)
        editor.title("Plot Elements")
        editor.transient(self)
        editor.resizable(True, True)
        editor.minsize(int(self._scale_length(960)), int(self._scale_length(620)))
        self._plot_element_windows[plot_id] = editor

        self._apply_plot_elements_editor_geometry(editor, ui_state)

        main = ttk.Frame(editor, padding=10)
        main.grid(row=0, column=0, sticky="nsew")
        editor.grid_rowconfigure(0, weight=1)
        editor.grid_columnconfigure(0, weight=1)
        main.grid_rowconfigure(0, weight=1)
        main.grid_columnconfigure(0, weight=1)

        panel = AnnotationsPanel(main, controller, plot_id)
        panel.frame.grid(row=0, column=0, sticky="nsew")
        controller.set_panel(panel)
        self._plot_annotation_panels[plot_id] = panel
        close_state = {"closing": False, "refresh_scheduled": False}

        buttons = ttk.Frame(main)
        buttons.grid(row=1, column=0, sticky="ew", pady=(6, 0))

        def _refresh_panel() -> None:
            """Refresh panel.
            Used to sync panel with current settings."""
            controller.render()
            panel.refresh()

        def _apply_selected() -> None:
            """Apply selected.
            Used to apply selected changes to live state."""
            panel.apply_selected()

        def _duplicate_selected() -> None:
            """Perform duplicate selected.
            Used to keep the workflow logic localized and testable."""
            panel.duplicate_selected()

        def _delete_selected() -> None:
            """Perform delete selected.
            Used to keep the workflow logic localized and testable."""
            panel.delete_selected()

        def _clear_all() -> None:
            """Clear all.
            Used to reset all state safely."""
            if not messagebox.askyesno(
                "Clear All", "Remove all plot elements for this plot?"
            ):
                return
            try:
                controller.cancel_place_element()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._clear_plot_elements_for_plot_id(plot_id, fig=fig)
            panel.refresh()

        def _on_destroy(_event: Any = None) -> None:
            """Handle destroy.
            Used as an event callback for destroy."""
            if _event is not None and getattr(_event, "widget", None) is not editor:
                return
            self._plot_element_windows.pop(plot_id, None)
            self._plot_element_editors.pop(plot_id, None)
            self._plot_annotation_panels.pop(plot_id, None)
            try:
                controller.set_panel(None)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _close_editor() -> None:
            """Close Plot Elements editor and schedule one post-close refresh.

            Purpose:
                Persist editor UI state, release editor/controller bindings, and
                close the Plot Elements window.
            Why:
                Closing the editor should immediately re-run the shared plot
                refresh pipeline so users see the same splash/progress behavior
                as the plot tab Refresh action.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                Cancels active placement mode, persists geometry/sash state,
                destroys the editor, and schedules one idle refresh for the
                owning plot tab.
            Exceptions:
                Errors are guarded to avoid interrupting the close workflow.
            """
            if close_state["closing"]:
                return
            close_state["closing"] = True
            try:
                controller.cancel_place_element()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                sash_pos = panel.get_sash_pos()
                self._annotation_store.set_ui_state(
                    plot_id,
                    editor_geometry=editor.geometry(),
                    editor_sash=sash_pos,
                )
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            _on_destroy()
            try:
                editor.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if not close_state["refresh_scheduled"]:
                close_state["refresh_scheduled"] = True

                def _refresh_after_close() -> None:
                    """Trigger one refresh after Plot Elements editor close.

                    Purpose:
                        Run the existing plot-tab refresh pipeline after close.
                    Why:
                        Reuses the shared splash/progress refresh behavior
                        instead of introducing a separate refresh path.
                    Inputs:
                        None.
                    Outputs:
                        None.
                    Side Effects:
                        Invokes `_refresh_plot_for_plot_id` for the owning plot.
                    Exceptions:
                        Errors are guarded to keep close flow resilient.
                    """
                    try:
                        self._refresh_plot_for_plot_id(
                            plot_id,
                            reason="Refreshing Plot Elements...",
                            rearm_overlay=True,
                            capture_combined_legend=False,
                        )
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

                try:
                    self.after_idle(_refresh_after_close)
                except Exception:
                    _refresh_after_close()

        _ui_button(buttons, text="Refresh", command=_refresh_panel).pack(
            side="left", padx=(0, 6)
        )
        _ui_button(buttons, text="Apply to Selected", command=_apply_selected).pack(
            side="left", padx=(0, 6)
        )
        _ui_button(buttons, text="Duplicate", command=_duplicate_selected).pack(
            side="left", padx=(0, 6)
        )
        _ui_button(buttons, text="Delete Selected", command=_delete_selected).pack(
            side="left", padx=(0, 6)
        )
        _ui_button(buttons, text="Clear All", command=_clear_all).pack(
            side="left", padx=(0, 6)
        )
        _ui_button(buttons, text="Close", command=_close_editor).pack(
            side="right", padx=(6, 0)
        )

        editor.protocol("WM_DELETE_WINDOW", _close_editor)
        editor.bind("<Destroy>", _on_destroy, add="+")
        panel.refresh()
        return

        elements_map = settings.get("plot_elements", {})
        elements = elements_map.get(plot_id) if isinstance(elements_map, dict) else []
        state = {
            "elements": copy.deepcopy(elements) if isinstance(elements, list) else [],
            "artists": [],
            "selected_index": None,
            "highlight_artist": None,
            "dragging": False,
            "drag_mode": None,
            "drag_start": None,
            "drag_snapshot": None,
            "draft_tool": None,
            "draft_index": None,
            "cid_press": None,
            "cid_motion": None,
            "cid_release": None,
        }

        def _clear_highlight() -> None:
            """Clear highlight.
            Used to reset highlight state safely."""
            highlight = state.get("highlight_artist")
            if highlight is None:
                return
            try:
                highlight.remove()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            state["highlight_artist"] = None

        def _draw_selection_highlight() -> None:
            """Perform draw selection highlight.
            Used to keep the workflow logic localized and testable."""
            idx = state.get("selected_index")
            if idx is None:
                return
            try:
                element = state["elements"][idx]
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return
            element_type = str(element.get("type") or "").strip().lower()
            data = element.get("data") if isinstance(element.get("data"), dict) else {}
            coords_kind = str(element.get("coords") or "data").strip().lower()
            axes_target = str(element.get("axes_target") or "primary").strip().lower()
            axes_map_local = self._resolve_plot_element_axes(fig)
            ax = axes_map_local.get(axes_target) or axes_map_local.get("primary")
            if ax is None:
                return
            if coords_kind == "axes":
                pad_x = 0.02
                pad_y = 0.02
            else:
                try:
                    x0_lim, x1_lim = ax.get_xlim()
                    y0_lim, y1_lim = ax.get_ylim()
                    pad_x = 0.02 * abs(x1_lim - x0_lim)
                    pad_y = 0.02 * abs(y1_lim - y0_lim)
                except Exception:
                    pad_x = 0.02
                    pad_y = 0.02
            if element_type in {"text", "point"}:
                x = data.get("x")
                y = data.get("y")
                if x is None or y is None:
                    return
                xmin, xmax = x - pad_x, x + pad_x
                ymin, ymax = y - pad_y, y + pad_y
            elif element_type == "arrow":
                x0 = data.get("x0")
                y0 = data.get("y0")
                x1 = data.get("x1")
                y1 = data.get("y1")
                if None in (x0, y0, x1, y1):
                    return
                xmin, xmax = min(x0, x1) - pad_x, max(x0, x1) + pad_x
                ymin, ymax = min(y0, y1) - pad_y, max(y0, y1) + pad_y
            elif element_type in {"xspan", "xspan_text"}:
                x0 = data.get("x0")
                x1 = data.get("x1")
                if x0 is None or x1 is None:
                    return
                xmin, xmax = min(x0, x1) - pad_x, max(x0, x1) + pad_x
                if coords_kind == "axes":
                    ymin, ymax = -pad_y, 1.0 + pad_y
                else:
                    try:
                        y0_lim, y1_lim = ax.get_ylim()
                        ymin, ymax = y0_lim - pad_y, y1_lim + pad_y
                    except Exception:
                        ymin, ymax = -pad_y, 1.0 + pad_y
            elif element_type == "freehand":
                points = data.get("points") or []
                if not points:
                    return
                try:
                    xs, ys = zip(*points)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    return
                xmin, xmax = min(xs) - pad_x, max(xs) + pad_x
                ymin, ymax = min(ys) - pad_y, max(ys) + pad_y
            else:
                return
            if None in (xmin, xmax, ymin, ymax):
                return
            from matplotlib import patches as mpatches

            highlight = mpatches.Rectangle(
                (xmin, ymin),
                max(0.0, xmax - xmin),
                max(0.0, ymax - ymin),
                fill=False,
                linestyle="--",
                linewidth=1.0,
                edgecolor="#666",
                alpha=0.8,
                transform=ax.transAxes if coords_kind == "axes" else ax.transData,
                zorder=6,
            )
            try:
                highlight._gl260_plot_element_editor_only = True
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            ax.add_patch(highlight)
            state["highlight_artist"] = highlight

        def _render_all():
            """Render all.
            Used to draw all for preview or export workflows."""
            _clear_highlight()
            self._clear_plot_element_artists(fig)
            state["artists"] = []
            axes_map_local = self._resolve_plot_element_axes(fig)
            # Iterate over indexed elements from state["elements"] to apply the per-item logic.
            for idx, element in enumerate(state["elements"]):
                axes_target = (
                    str(element.get("axes_target") or "primary").strip().lower()
                )
                ax = axes_map_local.get(axes_target) or axes_map_local.get("primary")
                if ax is None:
                    continue
                artist = self._build_plot_element_artist(ax, element)
                if artist is None:
                    continue
                if isinstance(artist, (list, tuple)):
                    # Iterate over artist to apply the per-item logic.
                    for child in artist:
                        if child is None:
                            continue
                        try:
                            child._gl260_plot_element_index = idx
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass
                        state["artists"].append(child)
                else:
                    try:
                        artist._gl260_plot_element_index = idx
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                    state["artists"].append(artist)
            fig._gl260_plot_element_artists = list(state["artists"])
            _draw_selection_highlight()
            try:
                canvas.draw_idle()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _element_label(element: Mapping[str, Any], idx: int) -> str:
            """Perform element label.
            Used to keep the workflow logic localized and testable."""
            el_type = str(element.get("type") or "element").strip()
            axes_target = str(element.get("axes_target") or "primary").strip().lower()
            axis_label = _axis_display_for(axes_target)
            return f"{idx + 1}. {el_type} ({axis_label})"

        editor = tk.Toplevel(self)
        editor.title("Plot Elements")
        editor.transient(self)
        editor.resizable(False, False)
        self._plot_element_windows[plot_id] = editor

        _pending_render = None

        def _schedule_render() -> None:
            """Schedule render.
            Used to queue render without blocking the UI."""
            nonlocal _pending_render
            if _pending_render is not None:
                try:
                    editor.after_cancel(_pending_render)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

            # Closure captures _schedule_render local context to keep helper logic scoped and invoked directly within _schedule_render.
            def _run():
                """Run value.
                Used to execute value and coordinate results."""
                nonlocal _pending_render
                _pending_render = None
                _render_all()

            _pending_render = editor.after(30, _run)

        axis_options = controller.get_axis_choices()
        coords_options = [
            ("Data (x/y)", "data"),
            ("Axes fraction (0–1)", "axes"),
        ]
        coords_display_options = list(coords_options)

        axis_label_by_role = {}
        axis_role_by_label = {}
        # Iterate over axis_options to apply the per-item logic.
        for label, role in axis_options:
            role_value = str(role or "").strip().lower()
            if not role_value:
                continue
            label_value = str(label or "").strip() or role_value
            if role_value not in axis_label_by_role:
                axis_label_by_role[role_value] = label_value
            if label_value and label_value not in axis_role_by_label:
                axis_role_by_label[label_value] = role_value  # keep first role if labels repeat

        coords_display_by_value = {value: label for label, value in coords_options}
        coords_value_by_display = {label: value for label, value in coords_options}

        def _coords_display_for(value: str) -> str:
            """Perform coords display for.
            Used to keep the workflow logic localized and testable."""
            value_key = str(value or "").strip().lower()
            return coords_display_by_value.get(
                value_key, coords_display_by_value.get("data", "Data (x/y)")
            )

        def _coords_value_for(display: str) -> str:
            """Perform coords value for.
            Used to keep the workflow logic localized and testable."""
            return coords_value_by_display.get(str(display or "").strip(), "data")

        def _axis_display_for(role: str) -> str:
            """Perform axis display for.
            Used to keep the workflow logic localized and testable."""
            role_key = str(role or "").strip().lower()
            if not role_key:
                role_key = "primary"
            return axis_label_by_role.get(role_key, role_key)

        def _axis_role_for(display: str) -> str:
            """Perform axis role for.
            Used to keep the workflow logic localized and testable."""
            return axis_role_by_label.get(str(display or "").strip(), "primary")

        tool_var = tk.StringVar(value="select")
        coords_var = tk.StringVar(value="data")
        coords_display_var = tk.StringVar(value=_coords_display_for(coords_var.get()))
        axes_target_var = tk.StringVar(value="primary")
        axes_display_var = tk.StringVar(
            value=_axis_display_for(axes_target_var.get())
        )
        color_var = tk.StringVar(value="#000000")
        alpha_var = tk.StringVar(value="0.9")
        alpha_scale_var = tk.DoubleVar(value=0.9)
        linewidth_var = tk.StringVar(value="1.5")
        fontsize_var = tk.StringVar(value="10")
        text_var = tk.StringVar(value="Note")
        instruction_var = tk.StringVar(value="")
        _suspend_prop_traces = False

        instruction_text = {
            "select": "Select/Move: drag elements to reposition.",
            "text": "Text: click to place.",
            "arrow": "Arrow: click and drag to draw.",
            "point": "Point: click to place.",
            "xspan": "X-span: click and drag to draw.",
            "xspan_text": "X-span + Text: click and drag to draw.",
            "freehand": "Freehand: click and drag to sketch.",
            "delete": "Delete: click an element to remove.",
        }

        def _update_instruction() -> None:
            """Update instruction.
            Used to keep instruction in sync with current state."""
            instruction_var.set(instruction_text.get(tool_var.get(), ""))

        def _style_overrides_from_ui() -> Dict[str, Any]:
            """Perform style overrides from UI.
            Used to keep the workflow logic localized and testable."""
            try:
                alpha_value = float(alpha_var.get())
            except Exception:
                alpha_value = 0.9
            alpha_value = max(0.0, min(1.0, alpha_value))
            try:
                linewidth_value = float(linewidth_var.get())
            except Exception:
                linewidth_value = 1.5
            linewidth_value = max(0.5, linewidth_value)
            try:
                fontsize_value = float(fontsize_var.get())
            except Exception:
                fontsize_value = 10.0
            fontsize_value = max(6.0, fontsize_value)
            return {
                "alpha": alpha_value,
                "linewidth": linewidth_value,
                "fontsize": fontsize_value,
                "color": _normalize_mpl_color(color_var.get()),
            }

        def _on_tool_change(*_args) -> None:
            """Handle tool change.
            Used as an event callback for tool change."""
            _update_instruction()
            tool = tool_var.get()
            axis_target = axes_target_var.get() or "primary"
            coord_space = coords_var.get() or "data"
            style_overrides = _style_overrides_from_ui()
            if tool == "select":
                controller.set_mode("select")
                controller.cancel_place_element()
            elif tool == "delete":
                controller.set_mode("erase")
                controller.cancel_place_element()
            else:
                tool_map = {
                    "text": "text",
                    "arrow": "arrow",
                    "point": "point",
                    "xspan": "xspan",
                    "xspan_text": "xspan_label",
                    "freehand": "ink",
                }
                mapped = tool_map.get(tool)
                if mapped is None:
                    controller.set_mode("select")
                    controller.cancel_place_element()
                else:
                    controller.set_mode(mapped)
                    controller.begin_place_element(
                        mapped,
                        style_overrides,
                        axis_target=axis_target,
                        coord_space=coord_space,
                    )
            _render_all()

        main = ttk.Frame(editor, padding=10)
        main.grid(row=0, column=0, sticky="nsew")
        main.grid_columnconfigure(0, weight=1)
        main.grid_columnconfigure(1, weight=1)

        instruction_label = ttk.Label(
            main, textvariable=instruction_var, wraplength=360, justify="left"
        )
        instruction_label.grid(row=0, column=0, columnspan=2, sticky="w", pady=(0, 8))

        tools_frame = ttk.LabelFrame(main, text="Tools")
        tools_frame.grid(row=1, column=0, sticky="ew", padx=(0, 6))
        # Iterate to apply the per-item logic.
        for idx, (label, value) in enumerate(
            [
                ("Select/Move", "select"),
                ("Text", "text"),
                ("Arrow", "arrow"),
                ("Point", "point"),
                ("X-span", "xspan"),
                ("X-span + Text", "xspan_text"),
                ("Freehand", "freehand"),
                ("Delete", "delete"),
            ]
        ):
            _ui_radiobutton(
                tools_frame,
                text=label,
                value=value,
                variable=tool_var,
            ).grid(row=idx, column=0, sticky="w", padx=6, pady=2)

        props_frame = ttk.LabelFrame(main, text="Properties")
        props_frame.grid(row=1, column=1, sticky="ew")
        props_frame.grid_columnconfigure(1, weight=1)

        ttk.Label(props_frame, text="Axis target").grid(
            row=0, column=0, sticky="w", pady=2, padx=6
        )
        axes_options = [
            _axis_display_for("primary"),
            _axis_display_for("right"),
            _axis_display_for("third"),
        ]
        axes_combo = _ui_combobox(
            props_frame,
            textvariable=axes_display_var,
            values=axes_options,
            state="readonly",
            width=24,
        )
        axes_combo.grid(row=0, column=1, sticky="ew", pady=2, padx=6)

        ttk.Label(props_frame, text="Attach to").grid(
            row=1, column=0, sticky="w", pady=2, padx=6
        )
        coords_combo = _ui_combobox(
            props_frame,
            textvariable=coords_display_var,
            values=[label for label, _value in coords_display_options],
            state="readonly",
            width=28,
        )
        coords_combo.grid(row=1, column=1, sticky="ew", pady=2, padx=6)

        def _sync_axes_target_from_display(_event=None) -> None:
            """Perform sync axes target from display.
            Used to keep the workflow logic localized and testable."""
            axes_target_var.set(_axis_role_for(axes_display_var.get()))

        def _sync_coords_from_display(_event=None) -> None:
            """Perform sync coords from display.
            Used to keep the workflow logic localized and testable."""
            coords_var.set(_coords_value_for(coords_display_var.get()))

        ttk.Label(props_frame, text="Color").grid(
            row=2, column=0, sticky="w", pady=2, padx=6
        )
        color_frame = ttk.Frame(props_frame)
        color_frame.grid(row=2, column=1, sticky="ew", pady=2, padx=6)
        color_swatch = tk.Label(color_frame, width=2, relief="groove")
        color_swatch.grid(row=0, column=0, padx=(0, 4))

        def _update_color_swatch() -> None:
            """Update color swatch.
            Used to keep color swatch in sync with current state."""
            color = _normalize_mpl_color(color_var.get())
            try:
                color_swatch.configure(background=color)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _choose_color() -> None:
            """Perform choose color.
            Used to keep the workflow logic localized and testable."""
            nonlocal _suspend_prop_traces
            initial = _normalize_mpl_color(color_var.get())
            result = colorchooser.askcolor(color=initial, parent=editor)
            if not result or not result[1]:
                return
            chosen = _normalize_mpl_color(result[1])
            _suspend_prop_traces = True
            try:
                color_var.set(chosen)
                _update_color_swatch()
            finally:
                _suspend_prop_traces = False
            if state.get("selected_index") is not None:
                _apply_properties(schedule_render=True, refresh=False)

        _ui_button(color_frame, text="Color...", command=_choose_color).grid(
            row=0, column=1, padx=(0, 4)
        )
        _ui_entry(color_frame, textvariable=color_var, width=10).grid(
            row=0, column=2, sticky="ew"
        )
        color_frame.grid_columnconfigure(2, weight=1)
        _update_color_swatch()

        ttk.Label(props_frame, text="Alpha").grid(
            row=3, column=0, sticky="w", pady=2, padx=6
        )
        _ui_entry(props_frame, textvariable=alpha_var, width=8).grid(
            row=3, column=1, sticky="w", pady=2, padx=6
        )

        def _on_alpha_scale_change(value) -> None:
            """Handle alpha scale change.
            Used as an event callback for alpha scale change."""
            nonlocal _suspend_prop_traces
            if _suspend_prop_traces:
                return
            try:
                alpha_value = float(value)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return
            alpha_value = max(0.0, min(1.0, alpha_value))
            _suspend_prop_traces = True
            try:
                alpha_var.set(f"{alpha_value:.2f}")
            finally:
                _suspend_prop_traces = False
            if state.get("selected_index") is not None:
                _apply_properties(schedule_render=True, refresh=False)

        _ui_scale(
            props_frame,
            from_=0.0,
            to=1.0,
            variable=alpha_scale_var,
            command=_on_alpha_scale_change,
        ).grid(row=4, column=1, sticky="ew", pady=2, padx=6)

        ttk.Label(props_frame, text="Line width").grid(
            row=5, column=0, sticky="w", pady=2, padx=6
        )
        _ui_entry(props_frame, textvariable=linewidth_var, width=8).grid(
            row=5, column=1, sticky="w", pady=2, padx=6
        )
        ttk.Label(props_frame, text="Font size").grid(
            row=6, column=0, sticky="w", pady=2, padx=6
        )
        _ui_entry(props_frame, textvariable=fontsize_var, width=8).grid(
            row=6, column=1, sticky="w", pady=2, padx=6
        )
        ttk.Label(props_frame, text="Text").grid(
            row=7, column=0, sticky="w", pady=2, padx=6
        )
        _ui_entry(props_frame, textvariable=text_var).grid(
            row=7, column=1, sticky="ew", pady=2, padx=6
        )

        ttk.Label(props_frame, text="Anchor presets").grid(
            row=8, column=0, sticky="w", pady=(6, 2), padx=6
        )
        anchor_frame = ttk.Frame(props_frame)
        anchor_frame.grid(row=9, column=0, columnspan=2, sticky="ew", padx=6)

        def _apply_anchor_to_element(
            element: Dict[str, Any], x: float, y: float
        ) -> None:
            """Apply anchor to element.
            Used to apply anchor to element changes to live state."""
            element["coords"] = "axes"
            data = element.get("data") if isinstance(element.get("data"), dict) else {}
            element_type = str(element.get("type") or "").strip().lower()
            if element_type in {"text", "point"}:
                data["x"] = x
                data["y"] = y
                if element_type == "text":
                    data["text"] = text_var.get()
            elif element_type == "arrow":
                data["x0"] = x
                data["y0"] = y
                data["x1"] = x
                data["y1"] = y
                data["text"] = text_var.get()
            elif element_type == "xspan":
                data["x0"] = x
                data["x1"] = x
            elif element_type == "xspan_text":
                data["x0"] = x
                data["x1"] = x
                data["text"] = text_var.get()
                data["text_y"] = y
                data["text_align"] = data.get("text_align") or "center"
            elif element_type == "freehand":
                data["points"] = [(x, y)]
            element["data"] = data

        def _apply_anchor_preset(x: float, y: float) -> None:
            """Apply anchor preset.
            Used to apply anchor preset changes to live state."""
            coords_var.set("axes")
            coords_display_var.set(_coords_display_for("axes"))
            idx = state.get("selected_index")
            if idx is not None:
                try:
                    element = state["elements"][idx]
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    return
                _apply_anchor_to_element(element, x, y)
                state["elements"][idx] = element
                _render_all()
                _select_index(idx)
                return
            tool = tool_var.get()
            if tool in {"select", "delete"}:
                return
            element = _new_element_base(tool)
            _apply_anchor_to_element(element, x, y)
            _add_element(element)

        anchor_buttons = [
            ("Top-Left", (0.02, 0.98)),
            ("Top-Right", (0.98, 0.98)),
            ("Bottom-Left", (0.02, 0.02)),
            ("Bottom-Right", (0.98, 0.02)),
            ("Center", (0.5, 0.5)),
        ]
        # Iterate over indexed elements from anchor_buttons to apply the per-item logic.
        for idx, (label, coords) in enumerate(anchor_buttons):
            row = idx // 3
            col = idx % 3
            _ui_button(
                anchor_frame,
                text=label,
                command=lambda xy=coords: _apply_anchor_preset(xy[0], xy[1]),
                width=10,
            ).grid(row=row, column=col, padx=2, pady=2, sticky="ew")
        # Iterate over the configured range to apply the per-item logic.
        for col in range(3):
            anchor_frame.grid_columnconfigure(col, weight=1)

        list_frame = ttk.LabelFrame(main, text="Elements")
        list_frame.grid(row=2, column=0, columnspan=2, sticky="ew", pady=(8, 0))
        listbox = tk.Listbox(list_frame, height=6, exportselection=False)
        listbox.grid(row=0, column=0, sticky="ew", padx=6, pady=6)
        list_frame.grid_columnconfigure(0, weight=1)

        def _get_selected_index() -> Optional[int]:
            """Return selected index.
            Used to retrieve selected index for downstream logic."""
            selection = listbox.curselection()
            if selection:
                return selection[0]
            return state.get("selected_index")

        def _refresh_listbox():
            """Refresh listbox.
            Used to sync listbox with current settings."""
            listbox.delete(0, "end")
            # Iterate over indexed elements from state["elements"] to apply the per-item logic.
            for idx, element in enumerate(state["elements"]):
                listbox.insert("end", _element_label(element, idx))

        def _select_index(idx: Optional[int]) -> None:
            """Perform select index.
            Used to keep the workflow logic localized and testable."""
            state["selected_index"] = idx
            listbox.selection_clear(0, "end")
            if idx is None:
                if tool_var.get() == "select":
                    _render_all()
                return
            try:
                listbox.selection_set(idx)
                listbox.activate(idx)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            element = state["elements"][idx]
            axes_target = str(element.get("axes_target") or "primary").strip().lower()
            coords_value = str(element.get("coords") or "data").strip().lower()
            style = (
                element.get("style") if isinstance(element.get("style"), dict) else {}
            )
            data = element.get("data") if isinstance(element.get("data"), dict) else {}
            nonlocal _suspend_prop_traces
            _suspend_prop_traces = True
            try:
                axes_target_var.set(axes_target)
                axes_display_var.set(_axis_display_for(axes_target))
                coords_var.set(coords_value)
                coords_display_var.set(_coords_display_for(coords_value))
                try:
                    alpha_value = float(style.get("alpha", 0.9))
                except Exception:
                    alpha_value = 0.9
                alpha_value = max(0.0, min(1.0, alpha_value))
                alpha_var.set(str(alpha_value))
                alpha_scale_var.set(alpha_value)
                linewidth_var.set(str(style.get("linewidth", 1.5)))
                fontsize_var.set(str(style.get("fontsize", 10.0)))
                color_var.set(_normalize_mpl_color(style.get("color", "#000000")))
                text_var.set(str(data.get("text", text_var.get())))
                _update_color_swatch()
            finally:
                _suspend_prop_traces = False
            if tool_var.get() == "select":
                _render_all()

        def _remove_selected_element() -> None:
            """Perform remove selected element.
            Used to keep the workflow logic localized and testable."""
            idx = _get_selected_index()
            if idx is None:
                return
            del state["elements"][idx]
            _refresh_listbox()
            _render_all()

        def _remove_all_elements() -> None:
            """Perform remove all elements.
            Used to keep the workflow logic localized and testable."""
            if not messagebox.askyesno(
                "Remove All", "Remove all plot elements for this plot?"
            ):
                return
            state["elements"].clear()
            _refresh_listbox()
            _render_all()

        remove_frame = ttk.Frame(list_frame)
        remove_frame.grid(row=1, column=0, sticky="e", padx=6, pady=(0, 6))
        _ui_button(
            remove_frame, text="Remove Selected", command=_remove_selected_element
        ).grid(row=0, column=0, padx=(0, 6))
        _ui_button(remove_frame, text="Remove All", command=_remove_all_elements).grid(
            row=0, column=1
        )

        def _apply_properties(*, schedule_render: bool = False, refresh: bool = True):
            """Apply properties.
            Used to apply properties changes to live state."""
            nonlocal _suspend_prop_traces
            idx = state["selected_index"]
            if idx is None:
                return
            _sync_axes_target_from_display()
            _sync_coords_from_display()
            try:
                element = state["elements"][idx]
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return
            style = (
                element.get("style") if isinstance(element.get("style"), dict) else {}
            )
            try:
                alpha_val = float(alpha_var.get())
            except Exception:
                alpha_val = 0.9
            try:
                linewidth_val = float(linewidth_var.get())
            except Exception:
                linewidth_val = 1.5
            try:
                fontsize_val = float(fontsize_var.get())
            except Exception:
                fontsize_val = 10.0
            style["alpha"] = max(0.0, min(1.0, alpha_val))
            style["linewidth"] = max(0.5, linewidth_val)
            style["fontsize"] = max(6.0, fontsize_val)
            normalized_color = _normalize_mpl_color(color_var.get())
            style["color"] = normalized_color
            element["style"] = style
            if alpha_scale_var.get() != style["alpha"]:
                alpha_scale_var.set(style["alpha"])
            if normalized_color != color_var.get():
                _suspend_prop_traces = True
                try:
                    color_var.set(normalized_color)
                    _update_color_swatch()
                finally:
                    _suspend_prop_traces = False
            element["axes_target"] = axes_target_var.get() or "primary"
            element["coords"] = coords_var.get() or "data"
            if element.get("type") in {"text", "arrow", "xspan_text"}:
                data = (
                    element.get("data") if isinstance(element.get("data"), dict) else {}
                )
                data["text"] = text_var.get()
                element["data"] = data
            if schedule_render:
                _schedule_render()
            else:
                _render_all()
            if refresh:
                _select_index(idx)

        def _on_property_change(*_args) -> None:
            """Handle property change.
            Used as an event callback for property change."""
            if _suspend_prop_traces:
                return
            try:
                alpha_value = float(alpha_var.get())
            except Exception:
                alpha_value = None
            if alpha_value is not None:
                alpha_value = max(0.0, min(1.0, alpha_value))
                if alpha_scale_var.get() != alpha_value:
                    alpha_scale_var.set(alpha_value)
            if state.get("selected_index") is None:
                return
            _apply_properties(schedule_render=True, refresh=False)

        def _on_color_change(*_args) -> None:
            """Handle color change.
            Used as an event callback for color change."""
            if _suspend_prop_traces:
                return
            _update_color_swatch()
            if state.get("selected_index") is None:
                return
            _apply_properties(schedule_render=True, refresh=False)

        def _on_axes_display_change(*_args) -> None:
            """Handle axes display change.
            Used as an event callback for axes display change."""
            if _suspend_prop_traces:
                return
            _sync_axes_target_from_display()
            _on_property_change()

        def _on_coords_display_change(*_args) -> None:
            """Handle coords display change.
            Used as an event callback for coords display change."""
            if _suspend_prop_traces:
                return
            _sync_coords_from_display()
            _on_property_change()

        tool_var.trace_add("write", _on_tool_change)
        axes_display_var.trace_add("write", _on_axes_display_change)
        coords_display_var.trace_add("write", _on_coords_display_change)
        alpha_var.trace_add("write", _on_property_change)
        linewidth_var.trace_add("write", _on_property_change)
        fontsize_var.trace_add("write", _on_property_change)
        text_var.trace_add("write", _on_property_change)
        color_var.trace_add("write", _on_color_change)

        _ui_button(
            props_frame, text="Apply to Selected", command=_apply_properties
        ).grid(row=10, column=0, columnspan=2, pady=(6, 4))

        def _on_list_select(_event=None):
            """Handle list select.
            Used as an event callback for list select."""
            selection = listbox.curselection()
            if not selection:
                return
            _select_index(selection[0])

        listbox.bind("<<ListboxSelect>>", _on_list_select)

        def _safe_float(text_value: Any, default: float) -> float:
            """Perform safe float.
            Used to keep the workflow logic localized and testable."""
            try:
                return float(text_value)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return default

        def _new_element_base(element_type: str) -> Dict[str, Any]:
            """Perform new element base.
            Used to keep the workflow logic localized and testable."""
            _sync_axes_target_from_display()
            _sync_coords_from_display()
            alpha_value = _safe_float(alpha_var.get(), 0.9)
            alpha_value = max(0.0, min(1.0, alpha_value))
            linewidth_value = max(0.5, _safe_float(linewidth_var.get(), 1.5))
            fontsize_value = max(6.0, _safe_float(fontsize_var.get(), 10.0))
            color_value = _normalize_mpl_color(color_var.get())
            return {
                "id": uuid.uuid4().hex,
                "type": element_type,
                "axes_target": axes_target_var.get() or "primary",
                "coords": coords_var.get() or "data",
                "data": {},
                "style": {
                    "alpha": alpha_value,
                    "linewidth": linewidth_value,
                    "fontsize": fontsize_value,
                    "color": color_value,
                },
                "visible": True,
            }

        def _add_element(element: Dict[str, Any]) -> None:
            """Perform add element.
            Used to keep the workflow logic localized and testable."""
            state["elements"].append(element)
            _render_all()
            _refresh_listbox()
            _select_index(len(state["elements"]) - 1)

        def _remove_element(idx: int) -> None:
            """Perform remove element.
            Used to keep the workflow logic localized and testable."""
            if idx < 0 or idx >= len(state["elements"]):
                return
            del state["elements"][idx]
            _render_all()
            _refresh_listbox()
            _select_index(None)

        def _artists_for_element_index(idx: int) -> List[Any]:
            """Perform artists for element index.
            Used to keep the workflow logic localized and testable."""
            return [
                artist
                # Iterate to apply the per-item logic.
                for artist in state["artists"]
                if getattr(artist, "_gl260_plot_element_index", None) == idx
            ]

        def _find_element_at_event(event) -> Optional[int]:
            """Perform find element at event.
            Used to keep the workflow logic localized and testable."""
            # Iterate over reversed elements from state["artists"] to apply the per-item logic.
            for artist in reversed(state["artists"]):
                try:
                    contains, _ = artist.contains(event)
                except Exception:
                    continue
                if contains:
                    return getattr(artist, "_gl260_plot_element_index", None)
            return None

        def _coords_from_event(
            event: Any, ax: Optional[Axes], coords_kind: str
        ) -> Optional[Tuple[float, float]]:
            """Perform coords from event.
            Used to keep the workflow logic localized and testable."""
            if event is None or ax is None:
                return None
            coords_kind = str(coords_kind or "data").strip().lower()
            if coords_kind == "axes":
                if event.x is None or event.y is None:
                    return None
                try:
                    x_val, y_val = ax.transAxes.inverted().transform((event.x, event.y))
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    return None
                return (x_val, y_val)
            if event.inaxes != ax:
                return None
            if event.xdata is None or event.ydata is None:
                return None
            return (event.xdata, event.ydata)

        def _sync_artist_from_element(element: Mapping[str, Any], artist: Any) -> None:
            """Perform sync artist from element.
            Used to keep the workflow logic localized and testable."""
            element_type = str(element.get("type") or "").strip().lower()
            data = element.get("data") if isinstance(element.get("data"), dict) else {}
            style = (
                element.get("style") if isinstance(element.get("style"), dict) else {}
            )
            try:
                alpha = float(style.get("alpha", 0.9))
            except Exception:
                alpha = 0.9
            alpha = max(0.0, min(1.0, alpha))
            try:
                linewidth = float(style.get("linewidth", 1.5))
            except Exception:
                linewidth = 1.5
            linewidth = max(0.5, linewidth)
            try:
                fontsize = float(style.get("fontsize", 10.0))
            except Exception:
                fontsize = 10.0
            fontsize = max(6.0, fontsize)
            color = style.get("color", "#000000")
            if element_type == "text":
                artist.set_position((data.get("x"), data.get("y")))
                artist.set_text(data.get("text", "Text"))
                artist.set_alpha(alpha)
                artist.set_color(color)
                artist.set_fontsize(fontsize)
            elif element_type == "point":
                artist.set_data([data.get("x")], [data.get("y")])
                artist.set_alpha(alpha)
                artist.set_color(color)
                artist.set_markersize(max(6.0, linewidth * 3.5))
            elif element_type == "arrow":
                artist.xy = (data.get("x1"), data.get("y1"))
                artist.set_position((data.get("x0"), data.get("y0")))
                try:
                    artist.set_text(data.get("text", ""))
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                arrow_patch = getattr(artist, "arrow_patch", None)
                if arrow_patch is not None:
                    try:
                        arrow_patch.set_linewidth(linewidth)
                        arrow_patch.set_alpha(alpha)
                        arrow_patch.set_edgecolor(color)
                        arrow_patch.set_facecolor(color)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
            elif element_type == "xspan":
                x0 = data.get("x0")
                x1 = data.get("x1")
                if x0 is None or x1 is None:
                    return
                left = min(x0, x1)
                width = abs(x1 - x0)
                try:
                    artist.set_x(left)
                    artist.set_width(width)
                    artist.set_alpha(alpha)
                    artist.set_edgecolor(color)
                    artist.set_facecolor(color)
                    artist.set_linewidth(linewidth)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            elif element_type == "xspan_text":
                x0 = data.get("x0")
                x1 = data.get("x1")
                if x0 is None or x1 is None:
                    return
                left = min(x0, x1)
                width = abs(x1 - x0)
                text_value = data.get("text", "Note")
                try:
                    text_y = float(data.get("text_y", 0.92))
                except Exception:
                    text_y = 0.92
                text_align = str(data.get("text_align") or "center").strip().lower()
                if text_align not in {"left", "center", "right"}:
                    text_align = "center"
                if hasattr(artist, "set_x") and hasattr(artist, "set_width"):
                    try:
                        artist.set_x(left)
                        artist.set_width(width)
                        artist.set_alpha(alpha)
                        artist.set_edgecolor(color)
                        artist.set_facecolor(color)
                        artist.set_linewidth(linewidth)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                elif hasattr(artist, "set_text") and hasattr(artist, "set_position"):
                    try:
                        artist.set_position(((x0 + x1) / 2.0, text_y))
                        artist.set_text(text_value)
                        artist.set_alpha(alpha)
                        artist.set_color(color)
                        artist.set_fontsize(fontsize)
                        artist.set_ha(text_align)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
            elif element_type == "freehand":
                points = data.get("points") or []
                if points:
                    xs, ys = zip(*points)
                    artist.set_data(xs, ys)
                artist.set_alpha(alpha)
                artist.set_color(color)
                artist.set_linewidth(linewidth)

        def _create_draft_element(
            tool: str, x: float, y: float, axes_target: str, coords_kind: str
        ) -> Optional[Dict[str, Any]]:
            """Create draft element.
            Used to instantiate draft element during setup."""
            if tool not in {
                "text",
                "point",
                "arrow",
                "xspan",
                "xspan_text",
                "freehand",
            }:
                return None
            element = _new_element_base(tool)
            element["axes_target"] = axes_target
            element["coords"] = coords_kind
            element["_draft"] = True
            if tool == "text":
                element["data"] = {"x": x, "y": y, "text": text_var.get()}
            elif tool == "point":
                element["data"] = {"x": x, "y": y}
            elif tool == "arrow":
                element["data"] = {
                    "x0": x,
                    "y0": y,
                    "x1": x,
                    "y1": y,
                    "text": text_var.get(),
                }
            elif tool == "xspan":
                element["data"] = {"x0": x, "x1": x}
            elif tool == "xspan_text":
                element["data"] = {
                    "x0": x,
                    "x1": x,
                    "text": text_var.get(),
                    "text_y": 0.92,
                    "text_align": "center",
                }
            elif tool == "freehand":
                element["data"] = {"points": [(x, y)]}
            return element

        def _on_press(event):
            """Handle press.
            Used as an event callback for press."""
            if event is None or event.x is None or event.y is None:
                return
            tool = tool_var.get()
            if tool in {"select", "delete"}:
                idx = _find_element_at_event(event)
                if idx is None:
                    return
                if tool == "delete":
                    _remove_element(idx)
                    return
                _select_index(idx)
                element = state["elements"][idx]
                axes_target = str(element.get("axes_target") or "primary").lower()
                coords_kind = str(element.get("coords") or "data").lower()
                ax = axes_map.get(axes_target) or axes_map.get("primary")
                start = _coords_from_event(event, ax, coords_kind)
                if start is None:
                    return
                state["dragging"] = True
                state["drag_mode"] = "move"
                state["drag_start"] = start
                state["drag_snapshot"] = copy.deepcopy(element.get("data") or {})
                return

            _sync_axes_target_from_display()
            _sync_coords_from_display()
            axes_target = axes_target_var.get() or "primary"
            coords_kind = coords_var.get() or "data"
            ax = axes_map.get(axes_target) or axes_map.get("primary")
            coords_point = _coords_from_event(event, ax, coords_kind)
            if coords_point is None:
                return
            x, y = coords_point
            draft = _create_draft_element(tool, x, y, axes_target, coords_kind)
            if draft is None:
                return
            state["dragging"] = True
            state["drag_mode"] = "draft"
            state["drag_start"] = (x, y)
            state["drag_snapshot"] = copy.deepcopy(draft.get("data") or {})
            state["draft_tool"] = tool
            state["draft_index"] = len(state["elements"])
            _add_element(draft)

        def _update_element_position(
            element: Dict[str, Any], coords: Tuple[float, float]
        ) -> None:
            """Update element position.
            Used to keep element position in sync with current state."""
            element_type = str(element.get("type") or "").strip().lower()
            data = element.get("data") if isinstance(element.get("data"), dict) else {}
            x_val, y_val = coords
            if element_type in {"text", "point"}:
                data["x"] = x_val
                data["y"] = y_val
            elif element_type == "arrow":
                data["x1"] = x_val
                data["y1"] = y_val
            elif element_type == "xspan":
                data["x1"] = x_val
            elif element_type == "xspan_text":
                data["x1"] = x_val
            elif element_type == "freehand":
                points = data.get("points") or []
                points.append((x_val, y_val))
                data["points"] = points
            element["data"] = data

        def _on_motion(event):
            """Handle motion.
            Used as an event callback for motion."""
            if not state.get("dragging"):
                return
            mode = state.get("drag_mode")
            if mode == "move":
                idx = state.get("selected_index")
                if idx is None:
                    return
                element = state["elements"][idx]
                axes_target = str(element.get("axes_target") or "primary").lower()
                coords_kind = str(element.get("coords") or "data").lower()
                ax = axes_map.get(axes_target) or axes_map.get("primary")
                current = _coords_from_event(event, ax, coords_kind)
                if current is None:
                    return
                start = state.get("drag_start")
                snapshot = state.get("drag_snapshot") or {}
                if start is None:
                    return
                dx = current[0] - start[0]
                dy = current[1] - start[1]
                element_type = str(element.get("type") or "").strip().lower()
                data = (
                    element.get("data") if isinstance(element.get("data"), dict) else {}
                )
                if element_type in {"text", "point"}:
                    data["x"] = snapshot.get("x", data.get("x", 0.0)) + dx
                    data["y"] = snapshot.get("y", data.get("y", 0.0)) + dy
                elif element_type == "arrow":
                    data["x0"] = snapshot.get("x0", data.get("x0", 0.0)) + dx
                    data["y0"] = snapshot.get("y0", data.get("y0", 0.0)) + dy
                    data["x1"] = snapshot.get("x1", data.get("x1", 0.0)) + dx
                    data["y1"] = snapshot.get("y1", data.get("y1", 0.0)) + dy
                elif element_type == "xspan":
                    data["x0"] = snapshot.get("x0", data.get("x0", 0.0)) + dx
                    data["x1"] = snapshot.get("x1", data.get("x1", 0.0)) + dx
                elif element_type == "xspan_text":
                    data["x0"] = snapshot.get("x0", data.get("x0", 0.0)) + dx
                    data["x1"] = snapshot.get("x1", data.get("x1", 0.0)) + dx
                elif element_type == "freehand":
                    points = snapshot.get("points", data.get("points", []))
                    if points:
                        data["points"] = [(px + dx, py + dy) for px, py in points]
                element["data"] = data
                # Iterate over _artists_for_element_index(idx) to apply the per-item logic.
                for artist in _artists_for_element_index(idx):
                    _sync_artist_from_element(element, artist)
                _clear_highlight()
                _draw_selection_highlight()
                try:
                    canvas.draw_idle()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                _schedule_render()
                return
            if mode != "draft":
                return
            idx = state.get("draft_index")
            if idx is None or idx >= len(state["elements"]):
                return
            element = state["elements"][idx]
            axes_target = str(element.get("axes_target") or "primary").lower()
            coords_kind = str(element.get("coords") or "data").lower()
            ax = axes_map.get(axes_target) or axes_map.get("primary")
            current = _coords_from_event(event, ax, coords_kind)
            if current is None:
                return
            _update_element_position(element, (current[0], current[1]))
            state["elements"][idx] = element
            _schedule_render()

        def _on_release(event):
            """Handle release.
            Used as an event callback for release."""
            if not state.get("dragging"):
                return
            mode = state.get("drag_mode")
            if mode == "move":
                state["dragging"] = False
                state["drag_mode"] = None
                state["drag_start"] = None
                state["drag_snapshot"] = None
                _render_all()
                return
            if mode != "draft":
                state["dragging"] = False
                state["drag_mode"] = None
                state["drag_start"] = None
                state["drag_snapshot"] = None
                return
            idx = state.get("draft_index")
            state["dragging"] = False
            state["drag_mode"] = None
            state["drag_start"] = None
            state["drag_snapshot"] = None
            state["draft_index"] = None
            state["draft_tool"] = None
            if idx is None or idx >= len(state["elements"]):
                return
            element = state["elements"][idx]
            axes_target = str(element.get("axes_target") or "primary").lower()
            coords_kind = str(element.get("coords") or "data").lower()
            ax = axes_map.get(axes_target) or axes_map.get("primary")
            current = _coords_from_event(event, ax, coords_kind)
            if current is not None:
                _update_element_position(element, (current[0], current[1]))
            element.pop("_draft", None)
            state["elements"][idx] = element
            _render_all()
            _refresh_listbox()
            _select_index(idx)

        def _save_elements():
            """Save elements.
            Used when persisting elements to storage."""
            settings["plot_elements"] = settings.get("plot_elements", {})
            if not isinstance(settings["plot_elements"], dict):
                settings["plot_elements"] = {}
            cleaned = [
                element
                # Iterate to apply the per-item logic.
                for element in state["elements"]
                if isinstance(element, dict) and not element.get("_draft")
            ]
            settings["plot_elements"][plot_id] = copy.deepcopy(cleaned)
            self._plot_elements = settings["plot_elements"]
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _close_editor():
            """Close editor.
            Used by UI actions to close editor safely."""
            try:
                controller.cancel_place_element()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                if state.get("cid_press") is not None:
                    canvas.mpl_disconnect(state["cid_press"])
                if state.get("cid_motion") is not None:
                    canvas.mpl_disconnect(state["cid_motion"])
                if state.get("cid_release") is not None:
                    canvas.mpl_disconnect(state["cid_release"])
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                _clear_highlight()
                state["elements"] = [
                    element
                    # Iterate to apply the per-item logic.
                    for element in state["elements"]
                    if isinstance(element, dict) and not element.get("_draft")
                ]
                _render_all()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                editor.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._plot_element_windows.pop(plot_id, None)
            self._plot_element_editors.pop(plot_id, None)

        buttons = ttk.Frame(main)
        buttons.grid(row=3, column=0, columnspan=2, sticky="e", pady=(8, 0))
        _ui_button(buttons, text="Save", command=_save_elements).grid(
            row=0, column=0, padx=(0, 6)
        )
        _ui_button(buttons, text="Close", command=_close_editor).grid(row=0, column=1)

        editor.protocol("WM_DELETE_WINDOW", _close_editor)
        editor.bind("<Delete>", lambda _event: _remove_selected_element())
        editor.bind("<BackSpace>", lambda _event: _remove_selected_element())

        state["cid_press"] = canvas.mpl_connect("button_press_event", _on_press)
        state["cid_motion"] = canvas.mpl_connect("motion_notify_event", _on_motion)
        state["cid_release"] = canvas.mpl_connect("button_release_event", _on_release)
        self._plot_element_editors[plot_id] = state

        _on_tool_change()
        _refresh_listbox()

    def _apply_layout_editor_changes(
        self,
        plot_id: str,
        fig: Figure,
        canvas: Optional[FigureCanvasTkAgg],
        pending: Dict[str, Any],
        target_mode: str,
    ) -> None:
        """Commit staged layout editor values and refresh target display tab.

        Purpose:
            Persist staged layout edits into the selected layout profile mode(s).
        Why:
            Layout editor Apply/Close should use the same splash-backed refresh
            pipeline as manual Refresh so users do not see late layout snaps.
        Inputs:
            plot_id: Plot identifier whose layout profile is being edited.
            fig: Active figure reference from the editor state.
            canvas: Active canvas reference from the editor state.
            pending: Staged layout changes captured by editor handles.
            target_mode: Profile target mode (`display`, `export`, or `both`).
        Outputs:
            None.
        Side Effects:
            Updates layout profile sections, persists settings, marks layout
            dirty, and triggers a unified display refresh when display mode is
            affected.
        Exceptions:
            Best-effort guards suppress non-critical UI and persistence failures.
        """
        if fig is None or not plot_id:
            return
        mode_value = (target_mode or "display").strip().lower()
        if mode_value not in {"display", "export", "both"}:
            mode_value = "display"
        modes = ["display", "export"] if mode_value == "both" else [mode_value]
        profile = _get_layout_profile(plot_id)
        # Iterate over modes to apply the per-item logic.
        for mode in modes:
            section = profile.get(mode)
            if not isinstance(section, dict):
                section = {}
                profile[mode] = section
            axis_labelpads = section.get("axis_labelpads")
            if not isinstance(axis_labelpads, dict):
                axis_labelpads = {}
                section["axis_labelpads"] = axis_labelpads
            pending_pads = pending.get("axis_labelpads", {})
            if isinstance(pending_pads, dict):
                # Iterate over items from pending_pads to apply the per-item logic.
                for key, value in pending_pads.items():
                    try:
                        pad_value = float(value)
                    except Exception:
                        continue
                    if math.isfinite(pad_value):
                        axis_labelpads[str(key)] = pad_value
            if pending.get("xlabel_pad_pts") is not None:
                try:
                    pad_value = float(pending["xlabel_pad_pts"])
                except Exception:
                    pad_value = None
                if pad_value is not None and math.isfinite(pad_value):
                    section["xlabel_pad_pts"] = pad_value
            if pending.get("detached_spine_offset") is not None:
                try:
                    offset_value = float(pending["detached_spine_offset"])
                except Exception:
                    offset_value = None
                if offset_value is not None and math.isfinite(offset_value):
                    section["detached_spine_offset"] = offset_value
            if pending.get("detached_labelpad") is not None:
                try:
                    pad_value = float(pending["detached_labelpad"])
                except Exception:
                    pad_value = None
                if pad_value is not None and math.isfinite(pad_value):
                    section["detached_labelpad"] = pad_value
            if pending.get("title_xy") is not None:
                section["title_xy"] = tuple(pending["title_xy"])
            if pending.get("suptitle_xy") is not None:
                section["suptitle_xy"] = tuple(pending["suptitle_xy"])
            if pending.get("legend_anchor") is not None:
                section["legend_anchor"] = tuple(pending["legend_anchor"])
            if pending.get("legend_loc") is not None:
                section["legend_loc"] = pending["legend_loc"]
            if pending.get("cycle_legend_anchor") is not None:
                section["cycle_legend_anchor"] = tuple(pending["cycle_legend_anchor"])
            if pending.get("cycle_legend_loc") is not None:
                section["cycle_legend_loc"] = pending["cycle_legend_loc"]
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._mark_plot_layout_dirty(plot_id)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if mode_value in {"display", "both"}:
            # Route display-impacting layout edits through the unified refresh
            # path so final layout stabilization remains behind the overlay.
            self._refresh_plot_for_plot_id(
                plot_id,
                reason="Applying Layout Changes...",
                rearm_overlay=True,
                capture_combined_legend=False,
            )

    def _teardown_layout_editor(
        self,
        plot_id: str,
        *,
        apply_changes: bool = False,
        target_override: Optional[str] = None,
    ) -> None:
        """Tear down the layout editor and optionally apply staged changes.
        Used when closing the editor to commit or discard pending edits."""
        state = self._layout_editor_states.get(plot_id)
        if state is None:
            window = self._layout_editor_windows.pop(plot_id, None)
            if window is not None:
                try:
                    window.destroy()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            return
        fig = state.get("fig")
        canvas = state.get("canvas")
        pending = state.get("pending") or {}
        # Closing with apply changes commits staged edits into the selected
        # layout profile; otherwise the pending state is discarded.
        if apply_changes and fig is not None:
            target_mode = target_override or "display"
            target_var = state.get("apply_target_var")
            if target_override is None and target_var is not None:
                try:
                    target_mode = target_var.get()
                except Exception:
                    target_mode = "display"
            try:
                self._apply_layout_editor_changes(
                    plot_id,
                    fig,
                    canvas,
                    pending,
                    str(target_mode),
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        # Cleanup: disconnect callbacks and remove overlay artists to avoid leaks
        # or stale handlers if the editor is reopened later.
        # Iterate over state.get("cids", []) or [] to apply the per-item logic.
        for cid in state.get("cids", []) or []:
            try:
                if canvas is not None:
                    canvas.mpl_disconnect(cid)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        # Iterate over state.get("overlay_artists", []) or [] to apply the per-item logic.
        for artist in state.get("overlay_artists", []) or []:
            if artist is None:
                continue
            try:
                artist.remove()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            if canvas is not None:
                canvas.draw_idle()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._layout_editor_states.pop(plot_id, None)
        window = self._layout_editor_windows.pop(plot_id, None)
        if window is not None:
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _open_layout_editor(
        self, canvas: FigureCanvasTkAgg, plot_id: Optional[str]
    ) -> None:
        """Open the layout editor for a specific plot.

        Purpose:
            Launch the layout editor for a given plot and stage layout edits.
        Why:
            The editor allows non-destructive layout tuning before applying
            changes to preview/export profiles.

        Args:
            canvas: FigureCanvasTkAgg hosting the target plot.
            plot_id: Identifier for the plot layout profile to edit.

        Returns:
            None.

        Side Effects:
            Creates a Toplevel window, registers editor state, and wires event
            handlers for interactive layout edits.

        Exceptions:
            Errors are caught to avoid interrupting the UI.
        """
        if not plot_id or canvas is None:
            return
        existing = self._layout_editor_windows.get(plot_id)
        if existing is not None and existing.winfo_exists():
            try:
                existing.deiconify()
                existing.lift()
                existing.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        fig = getattr(canvas, "figure", None)
        if fig is None:
            return

        from matplotlib import patches as mpatches
        from matplotlib.lines import Line2D
        from matplotlib.transforms import Bbox

        # Layout profiles are per-plot settings; editor stages changes and only
        # commits to profiles when Apply/Close is invoked.
        profile = _get_layout_profile(plot_id)
        section = _layout_profile_section(profile, "display")
        mirror_detached_labelpad = bool(profile.get("mirror_detached_labelpad", False))

        editor = tk.Toplevel(self)
        editor.title("Layout Editor")
        editor.transient(self)
        editor.resizable(False, False)
        editor.minsize(420, 220)
        self._layout_editor_windows[plot_id] = editor

        root = ttk.Frame(editor, padding=10)
        root.pack(fill="both", expand=True)
        instruction = ttk.Label(
            root,
            text=(
                "Drag the handles on the plot to stage layout changes. "
                "Changes apply only on Apply or Close."
            ),
            wraplength=380,
            justify="left",
        )
        instruction.pack(anchor="w", pady=(0, 8))

        # Apply target routes staged edits to preview, export, or both profiles.
        target_row = ttk.Frame(root)
        target_row.pack(anchor="w", pady=(0, 8))
        ttk.Label(target_row, text="Apply target:").pack(side="left")
        apply_target_var = tk.StringVar(value="display")
        ttk.Radiobutton(
            target_row,
            text="Preview",
            value="display",
            variable=apply_target_var,
        ).pack(side="left", padx=(8, 0))
        ttk.Radiobutton(
            target_row,
            text="Export",
            value="export",
            variable=apply_target_var,
        ).pack(side="left", padx=(8, 0))
        ttk.Radiobutton(
            target_row,
            text="Both",
            value="both",
            variable=apply_target_var,
        ).pack(side="left", padx=(8, 0))

        elements_label_var = tk.StringVar(value="")
        elements_label = ttk.Label(
            root, textvariable=elements_label_var, wraplength=380, justify="left"
        )
        elements_label.pack(anchor="w", pady=(0, 8))

        actions = ttk.Frame(root)
        actions.pack(anchor="e")

        def _apply_now() -> None:
            """Apply now.
            Used to apply now changes to live state."""
            state = self._layout_editor_states.get(plot_id)
            if state is None:
                return
            pending = state.get("pending") or {}
            # Apply target determines which profile(s) receive the staged edits.
            self._apply_layout_editor_changes(
                plot_id,
                fig,
                canvas,
                pending,
                apply_target_var.get(),
            )

        ttk.Button(actions, text="Apply", command=_apply_now).pack(
            side="right", padx=(6, 0)
        )
        ttk.Button(
            actions,
            text="Close",
            command=lambda: self._teardown_layout_editor(plot_id, apply_changes=True),
        ).pack(side="right")

        overlay_artists: List[Any] = []
        elements: List[Dict[str, Any]] = []
        # Pending holds staged edits until Apply/Close commits them to settings.
        pending: Dict[str, Any] = {
            "axis_labelpads": {},
            "xlabel_pad_pts": None,
            "detached_spine_offset": None,
            "detached_labelpad": None,
            "title_xy": None,
            "suptitle_xy": None,
            "legend_anchor": None,
            "legend_loc": None,
            "cycle_legend_anchor": None,
            "cycle_legend_loc": None,
        }

        def _register_artist(artist) -> None:
            """Perform register artist.
            Used to keep the workflow logic localized and testable."""
            if artist is None:
                return
            overlay_artists.append(artist)
            try:
                fig.add_artist(artist)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                artist._gl260_layout_editor_only = True
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _figure_metrics() -> Tuple[float, float, float]:
            """Perform figure metrics.
            Used to keep the workflow logic localized and testable."""
            fig_w_in, fig_h_in = fig.get_size_inches()
            fig_w_px = max(fig_w_in * fig.dpi, 1.0)
            fig_h_px = max(fig_h_in * fig.dpi, 1.0)
            return fig_w_px, fig_h_px, float(fig.dpi)

        def _to_fig_from_display(xy: Tuple[float, float]) -> Tuple[float, float]:
            """Perform to fig from display.
            Used to keep the workflow logic localized and testable."""
            try:
                return tuple(fig.transFigure.inverted().transform(xy))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return (0.5, 0.5)

        def _text_pos_fig(text_artist) -> Tuple[float, float]:
            """Perform text pos fig.
            Used to keep the workflow logic localized and testable."""
            if text_artist is None:
                return (0.5, 0.5)
            try:
                pos = text_artist.get_position()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return (0.5, 0.5)
            try:
                ax = getattr(text_artist, "axes", None)
                if ax is not None and text_artist.get_transform() == ax.transAxes:
                    display_xy = ax.transAxes.transform(pos)
                    return _to_fig_from_display(display_xy)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                if text_artist.get_transform() == fig.transFigure:
                    return tuple(pos)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                display_xy = text_artist.get_transform().transform(pos)
                return _to_fig_from_display(display_xy)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return (0.5, 0.5)

        def _legend_loc_value(legend) -> str:
            """Perform legend loc value.
            Used to keep the workflow logic localized and testable."""
            loc_map = {
                0: "best",
                1: "upper right",
                2: "upper left",
                3: "lower left",
                4: "lower right",
                5: "right",
                6: "center left",
                7: "center right",
                8: "lower center",
                9: "upper center",
                10: "center",
            }
            try:
                loc_value = legend.get_loc()
            except Exception:
                loc_value = getattr(legend, "_loc", "upper right")
            if isinstance(loc_value, str):
                loc_text = loc_value.strip().lower()
            elif isinstance(loc_value, int):
                loc_text = loc_map.get(loc_value, "upper right")
            else:
                loc_text = "upper right"
            if loc_text == "best":
                loc_text = "upper right"
            return loc_text

        def _anchor_from_bbox(bbox: Bbox, loc_text: str) -> Tuple[float, float]:
            """Perform anchor from bbox.
            Used to keep the workflow logic localized and testable."""
            if bbox is None:
                return (0.5, 0.5)
            x0, y0, x1, y1 = bbox.x0, bbox.y0, bbox.x1, bbox.y1
            cx = x0 + ((x1 - x0) / 2.0)
            cy = y0 + ((y1 - y0) / 2.0)
            loc_text = (loc_text or "upper right").lower()
            if loc_text in {"upper left", "ul"}:
                return (x0, y1)
            if loc_text in {"upper center", "uc"}:
                return (cx, y1)
            if loc_text in {"upper right", "ur"}:
                return (x1, y1)
            if loc_text in {"lower left", "ll"}:
                return (x0, y0)
            if loc_text in {"lower center", "lc"}:
                return (cx, y0)
            if loc_text in {"lower right", "lr"}:
                return (x1, y0)
            if loc_text in {"center left", "cl", "left"}:
                return (x0, cy)
            if loc_text in {"center right", "cr", "right"}:
                return (x1, cy)
            return (cx, cy)

        def _clamp_anchor(value: float) -> float:
            """Clamp anchor.
            Used to keep anchor within safe bounds."""
            return max(-0.1, min(1.1, float(value)))

        def _make_handle(
            fig_xy: Tuple[float, float],
            *,
            size_px: float = 10.0,
            facecolor: str = "#ffd966",
            edgecolor: str = "#997300",
        ):
            """Handle value.
            Used by make workflows to handle value."""
            fig_w_px, fig_h_px, _dpi = _figure_metrics()
            size_fx = size_px / fig_w_px
            size_fy = size_px / fig_h_px
            x0 = fig_xy[0] - (size_fx / 2.0)
            y0 = fig_xy[1] - (size_fy / 2.0)
            rect = mpatches.Rectangle(
                (x0, y0),
                size_fx,
                size_fy,
                transform=fig.transFigure,
                facecolor=facecolor,
                edgecolor=edgecolor,
                linewidth=1.2,
                zorder=30,
            )
            _register_artist(rect)
            return rect, size_px

        def _handle_hitbox(
            display_xy: Tuple[float, float], size_px: float
        ) -> Tuple[float, float, float, float]:
            """Handle hitbox.
            Used as an event callback for hitbox."""
            half = size_px / 2.0
            return (
                display_xy[0] - half,
                display_xy[1] - half,
                display_xy[0] + half,
                display_xy[1] + half,
            )

        def _label_center_display(text_artist) -> Optional[Tuple[float, float]]:
            """Center display.
            Used by label workflows to center display."""
            if text_artist is None:
                return None
            try:
                renderer = fig.canvas.get_renderer()
            except Exception:
                renderer = None
            if renderer is None:
                try:
                    fig.canvas.draw()
                    renderer = fig.canvas.get_renderer()
                except Exception:
                    renderer = None
            if renderer is None:
                return None
            try:
                bbox = text_artist.get_window_extent(renderer=renderer)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            return (bbox.x0 + bbox.width / 2.0, bbox.y0 + bbox.height / 2.0)

        axes = []
        # Iterate over fig.get_axes() to apply the per-item logic.
        for ax in fig.get_axes():
            if ax is None:
                continue
            try:
                if not ax.get_visible():
                    continue
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if getattr(ax, "_gl260_legend_only", False):
                continue
            axes.append(ax)

        axis_roles: List[Tuple[Axes, str]] = []
        right_count = 0
        # Iterate over axes to apply the per-item logic.
        for ax in axes:
            role = getattr(ax, "_gl260_axis_role", None)
            role_key = None
            if isinstance(role, str):
                role_key = role.strip().lower()
            if role_key not in {"primary", "right", "third"}:
                try:
                    label_pos = ax.yaxis.get_label_position()
                except Exception:
                    label_pos = "left"
                if label_pos == "right":
                    role_key = "right" if right_count == 0 else "third"
                    right_count += 1
                else:
                    role_key = "primary"
            axis_roles.append((ax, role_key))

        primary_axis = None
        detached_axis = None
        detached_offset = None
        # Iterate over axis_roles to apply the per-item logic.
        for ax, role in axis_roles:
            if primary_axis is None and role == "primary":
                primary_axis = ax
            if role == "third" and detached_axis is None:
                detached_axis = ax
        if primary_axis is None and axes:
            primary_axis = axes[0]
        if detached_axis is not None:
            try:
                spine_pos = detached_axis.spines["right"].get_position()
            except Exception:
                spine_pos = None
            if isinstance(spine_pos, tuple) and len(spine_pos) >= 2:
                if spine_pos[0] == "axes":
                    try:
                        detached_offset = float(spine_pos[1])
                    except Exception:
                        detached_offset = None

        title_artist = getattr(fig, "_gl260_title_text", None)
        if title_artist is not None:
            try:
                if not str(title_artist.get_text() or "").strip():
                    title_artist = None
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if title_artist is not None:
            fig_xy = _text_pos_fig(title_artist)
            handle, handle_px = _make_handle(fig_xy, facecolor="#d9ead3")
            display_xy = fig.transFigure.transform(fig_xy)
            elements.append(
                {
                    "kind": "title",
                    "label": "Title",
                    "handle": handle,
                    "handle_px": handle_px,
                    "base_handle_display": display_xy,
                    "current_handle_display": display_xy,
                    "base_pos_fig": fig_xy,
                    "current_pos_fig": fig_xy,
                    "hit_box": _handle_hitbox(display_xy, handle_px),
                }
            )

        suptitle_artist = getattr(fig, "_gl260_suptitle_text", None)
        if suptitle_artist is None:
            suptitle_artist = getattr(fig, "_suptitle", None)
        if suptitle_artist is not None:
            try:
                if not str(suptitle_artist.get_text() or "").strip():
                    suptitle_artist = None
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if suptitle_artist is not None:
            fig_xy = _text_pos_fig(suptitle_artist)
            handle, handle_px = _make_handle(fig_xy, facecolor="#cfe2f3")
            display_xy = fig.transFigure.transform(fig_xy)
            elements.append(
                {
                    "kind": "suptitle",
                    "label": "Suptitle (Job Information)",
                    "handle": handle,
                    "handle_px": handle_px,
                    "base_handle_display": display_xy,
                    "current_handle_display": display_xy,
                    "base_pos_fig": fig_xy,
                    "current_pos_fig": fig_xy,
                    "hit_box": _handle_hitbox(display_xy, handle_px),
                }
            )

        supxlabel_artist = getattr(fig, "_gl260_xlabel_text", None)
        if supxlabel_artist is not None:
            try:
                if not str(supxlabel_artist.get_text() or "").strip():
                    supxlabel_artist = None
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if supxlabel_artist is not None:
            display_xy = _label_center_display(supxlabel_artist)
            if display_xy is not None:
                fig_xy = _to_fig_from_display(display_xy)
                handle, handle_px = _make_handle(fig_xy, facecolor="#fff2cc")
                base_pad = section.get("xlabel_pad_pts")
                if base_pad is None and isinstance(section.get("axis_labelpads"), dict):
                    base_pad = section["axis_labelpads"].get("x")
                try:
                    base_pad = float(base_pad)
                except Exception:
                    base_pad = 0.0
                elements.append(
                    {
                        "kind": "supxlabel",
                        "label": "X label",
                        "handle": handle,
                        "handle_px": handle_px,
                        "base_handle_display": display_xy,
                        "current_handle_display": display_xy,
                        "base_labelpad": base_pad,
                        "current_labelpad": base_pad,
                        "hit_box": _handle_hitbox(display_xy, handle_px),
                    }
                )
        elif primary_axis is not None:
            xlabel_artist = primary_axis.xaxis.get_label()
            try:
                xlabel_text = str(xlabel_artist.get_text() or "").strip()
            except Exception:
                xlabel_text = ""
            if xlabel_text:
                display_xy = _label_center_display(xlabel_artist)
                if display_xy is not None:
                    fig_xy = _to_fig_from_display(display_xy)
                    handle, handle_px = _make_handle(fig_xy, facecolor="#fff2cc")
                    try:
                        base_pad = float(primary_axis.xaxis.labelpad)
                    except Exception:
                        base_pad = 0.0
                    elements.append(
                        {
                            "kind": "xlabel",
                            "label": "X label",
                            "handle": handle,
                            "handle_px": handle_px,
                            "base_handle_display": display_xy,
                            "current_handle_display": display_xy,
                            "base_labelpad": base_pad,
                            "current_labelpad": base_pad,
                            "axis_role": "x",
                            "hit_box": _handle_hitbox(display_xy, handle_px),
                        }
                    )

        # Iterate over axis_roles to apply the per-item logic.
        for ax, role in axis_roles:
            label_artist = ax.yaxis.get_label()
            try:
                label_text = str(label_artist.get_text() or "").strip()
            except Exception:
                label_text = ""
            if not label_text:
                continue
            display_xy = _label_center_display(label_artist)
            if display_xy is None:
                continue
            fig_xy = _to_fig_from_display(display_xy)
            locked = False
            pad_key = role
            if ax is detached_axis:
                pad_key = "detached_labelpad"
                locked = mirror_detached_labelpad
            handle, handle_px = _make_handle(
                fig_xy,
                facecolor="#e2efda" if not locked else "#dddddd",
                edgecolor="#6aa84f" if not locked else "#888888",
            )
            try:
                base_pad = float(ax.yaxis.labelpad)
            except Exception:
                base_pad = 0.0
            try:
                label_side = ax.yaxis.get_label_position()
            except Exception:
                label_side = "right" if role in {"right", "third"} else "left"
            elements.append(
                {
                    "kind": "ylabel",
                    "label": label_text,
                    "handle": handle,
                    "handle_px": handle_px,
                    "base_handle_display": display_xy,
                    "current_handle_display": display_xy,
                    "base_labelpad": base_pad,
                    "current_labelpad": base_pad,
                    "axis_role": pad_key,
                    "label_side": label_side,
                    "locked": locked,
                    "hit_box": _handle_hitbox(display_xy, handle_px),
                }
            )

        try:
            fig.canvas.draw()
            renderer = fig.canvas.get_renderer()
        except Exception:
            renderer = None

        fig_legends = [lg for lg in getattr(fig, "legends", []) if lg is not None]
        axis_legends: List[Any] = []
        axis_legend_axes: Dict[Any, Axes] = {}
        # Iterate over axes to apply the per-item logic.
        for ax in axes:
            try:
                legend = ax.get_legend()
            except Exception:
                legend = None
            if legend is None:
                continue
            axis_legends.append(legend)
            axis_legend_axes[legend] = ax

        main_legend = fig_legends[0] if fig_legends else None
        if main_legend is None:
            # Iterate over axis_legends to apply the per-item logic.
            for legend in axis_legends:
                if getattr(legend, "_cycle_overlay_legend", False):
                    continue
                main_legend = legend
                break

        cycle_legend = None
        # Iterate over fig_legends to apply the per-item logic.
        for legend in fig_legends:
            if getattr(legend, "_cycle_overlay_legend", False):
                cycle_legend = legend
                break
        if cycle_legend is None:
            # Iterate over axis_legends to apply the per-item logic.
            for legend in axis_legends:
                if getattr(legend, "_cycle_overlay_legend", False):
                    cycle_legend = legend
                    break

        def _add_legend_element(
            legend_obj,
            *,
            label: str,
            anchor_space: str,
            anchor_axis: Optional[Axes] = None,
            pending_key: str = "legend_anchor",
            loc_key: str = "legend_loc",
        ) -> None:
            """Perform add legend element.
            Used to keep the workflow logic localized and testable."""
            if legend_obj is None or renderer is None:
                return
            try:
                bbox_disp = legend_obj.get_window_extent(renderer=renderer)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return
            bbox_fig = bbox_disp.transformed(fig.transFigure.inverted())
            loc_text = _legend_loc_value(legend_obj)
            if anchor_space == "axes" and anchor_axis is not None:
                try:
                    x0, y0 = anchor_axis.transAxes.inverted().transform(
                        (bbox_disp.x0, bbox_disp.y0)
                    )
                    x1, y1 = anchor_axis.transAxes.inverted().transform(
                        (bbox_disp.x1, bbox_disp.y1)
                    )
                    bbox_axes = Bbox.from_extents(
                        min(x0, x1), min(y0, y1), max(x0, x1), max(y0, y1)
                    )
                except Exception:
                    bbox_axes = None
                anchor_value = (
                    _anchor_from_bbox(bbox_axes, loc_text)
                    if bbox_axes
                    else (
                        0.5,
                        0.5,
                    )
                )
            else:
                anchor_value = _anchor_from_bbox(bbox_fig, loc_text)

            fig_w_px, fig_h_px, _dpi = _figure_metrics()
            shadow_dx = 2.0 / fig_w_px
            shadow_dy = -2.0 / fig_h_px
            shadow = mpatches.Rectangle(
                (bbox_fig.x0 + shadow_dx, bbox_fig.y0 + shadow_dy),
                bbox_fig.width,
                bbox_fig.height,
                transform=fig.transFigure,
                facecolor="#000000",
                alpha=0.18,
                linewidth=0.0,
                zorder=2,
            )
            rect = mpatches.Rectangle(
                (bbox_fig.x0, bbox_fig.y0),
                bbox_fig.width,
                bbox_fig.height,
                transform=fig.transFigure,
                fill=False,
                edgecolor="#3d85c6",
                linewidth=1.4,
                zorder=3,
            )
            _register_artist(shadow)
            _register_artist(rect)
            disp0 = fig.transFigure.transform((bbox_fig.x0, bbox_fig.y0))
            disp1 = fig.transFigure.transform((bbox_fig.x1, bbox_fig.y1))
            hit_box = (disp0[0], disp0[1], disp1[0], disp1[1])
            elements.append(
                {
                    "kind": "legend",
                    "label": label,
                    "handle": rect,
                    "shadow": shadow,
                    "base_bbox_fig": bbox_fig,
                    "current_bbox_fig": bbox_fig,
                    "anchor_space": anchor_space,
                    "anchor_axis": anchor_axis,
                    "base_anchor": anchor_value,
                    "current_anchor": anchor_value,
                    "loc_value": loc_text,
                    "pending_key": pending_key,
                    "loc_key": loc_key,
                    "hit_box": hit_box,
                }
            )

        _add_legend_element(
            main_legend,
            label="Legend",
            anchor_space="figure",
            anchor_axis=None,
            pending_key="legend_anchor",
            loc_key="legend_loc",
        )
        if cycle_legend is not None:
            # Respect lock/drag settings to avoid accidental cycle legend changes.
            if (
                bool(settings.get("combined_cycle_legend_enable_drag", True))
                and not bool(settings.get("combined_cycle_legend_lock_position", False))
            ):
                _make_legend_draggable(cycle_legend)

            cycle_anchor_space = "axes"
            cycle_anchor_axis = axis_legend_axes.get(cycle_legend)
            if cycle_legend in fig_legends:
                cycle_anchor_space = "figure"
                cycle_anchor_axis = None
            _add_legend_element(
                cycle_legend,
                label="Cycle Legend",
                anchor_space=cycle_anchor_space,
                anchor_axis=cycle_anchor_axis,
                pending_key="cycle_legend_anchor",
                loc_key="cycle_legend_loc",
            )

        if detached_axis is not None:
            try:
                axis_pos = detached_axis.get_position()
            except Exception:
                axis_pos = None
            if axis_pos is not None:
                if detached_offset is None:
                    detached_offset = 1.12
                x_fig = axis_pos.x0 + (axis_pos.width * float(detached_offset))
                spine_line = Line2D(
                    [x_fig, x_fig],
                    [axis_pos.y0, axis_pos.y1],
                    transform=fig.transFigure,
                    color="#cc0000",
                    linewidth=1.4,
                    zorder=27,
                )
                _register_artist(spine_line)
                line_x_disp = fig.transFigure.transform((x_fig, axis_pos.y0))[0]
                hit_box = (
                    line_x_disp - 6.0,
                    fig.transFigure.transform((0.0, axis_pos.y0))[1],
                    line_x_disp + 6.0,
                    fig.transFigure.transform((0.0, axis_pos.y1))[1],
                )
                elements.append(
                    {
                        "kind": "detached_spine",
                        "label": "Detached spine",
                        "handle": spine_line,
                        "axis": detached_axis,
                        "axis_pos": axis_pos,
                        "base_offset": detached_offset,
                        "current_offset": detached_offset,
                        "hit_box": hit_box,
                    }
                )

        element_names = ", ".join(
            [element["label"] for element in elements if element.get("label")]
        )
        if element_names:
            elements_label_var.set(f"Handles: {element_names}")
        else:
            elements_label_var.set("No draggable elements found on this plot.")

        def _hit_test(event) -> Optional[Dict[str, Any]]:
            """Perform hit test.
            Used to keep the workflow logic localized and testable."""
            if event is None or event.x is None or event.y is None:
                return None
            # Iterate over reversed elements from elements to apply the per-item logic.
            for element in reversed(elements):
                if element.get("locked"):
                    continue
                hit_box = element.get("hit_box")
                if hit_box is None:
                    continue
                x0, y0, x1, y1 = hit_box
                if x0 <= event.x <= x1 and y0 <= event.y <= y1:
                    return element
            return None

        def _move_handle(
            element: Dict[str, Any], display_xy: Tuple[float, float]
        ) -> None:
            """Handle value.
            Used by move workflows to handle value."""
            fig_xy = _to_fig_from_display(display_xy)
            handle = element.get("handle")
            handle_px = element.get("handle_px", 10.0)
            fig_w_px, fig_h_px, _dpi = _figure_metrics()
            size_fx = handle_px / fig_w_px
            size_fy = handle_px / fig_h_px
            try:
                handle.set_xy((fig_xy[0] - size_fx / 2.0, fig_xy[1] - size_fy / 2.0))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            element["current_handle_display"] = display_xy
            element["hit_box"] = _handle_hitbox(display_xy, handle_px)

        def _move_legend_rect(element: Dict[str, Any], bbox_fig: Bbox) -> None:
            """Perform move legend rect.
            Used to keep the workflow logic localized and testable."""
            rect = element.get("handle")
            shadow = element.get("shadow")
            if rect is None:
                return
            try:
                rect.set_x(bbox_fig.x0)
                rect.set_y(bbox_fig.y0)
                rect.set_width(bbox_fig.width)
                rect.set_height(bbox_fig.height)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if shadow is not None:
                fig_w_px, fig_h_px, _dpi = _figure_metrics()
                shadow_dx = 2.0 / fig_w_px
                shadow_dy = -2.0 / fig_h_px
                try:
                    shadow.set_x(bbox_fig.x0 + shadow_dx)
                    shadow.set_y(bbox_fig.y0 + shadow_dy)
                    shadow.set_width(bbox_fig.width)
                    shadow.set_height(bbox_fig.height)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            element["current_bbox_fig"] = bbox_fig
            disp0 = fig.transFigure.transform((bbox_fig.x0, bbox_fig.y0))
            disp1 = fig.transFigure.transform((bbox_fig.x1, bbox_fig.y1))
            element["hit_box"] = (disp0[0], disp0[1], disp1[0], disp1[1])

        drag_state: Dict[str, Any] = {"active": None, "start": None}

        def _on_press(event):
            """Handle press.
            Used as an event callback for press."""
            try:
                if event.button not in (1, None):
                    return
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            target = _hit_test(event)
            if target is None:
                return
            drag_state["active"] = target
            drag_state["start"] = (event.x, event.y)
            if target["kind"] in {"xlabel", "ylabel", "supxlabel"}:
                target["drag_base_labelpad"] = target.get("current_labelpad", 0.0)
                target["drag_base_display"] = target.get(
                    "current_handle_display", (event.x, event.y)
                )
            elif target["kind"] in {"title", "suptitle"}:
                target["drag_base_display"] = target.get(
                    "current_handle_display", (event.x, event.y)
                )
            elif target["kind"] == "legend":
                target["drag_base_bbox_fig"] = target.get("current_bbox_fig")
                target["drag_base_anchor"] = target.get("current_anchor")
                anchor_space = target.get("anchor_space")
                anchor_axis = target.get("anchor_axis")
                if anchor_space == "axes" and anchor_axis is not None:
                    target["drag_base_anchor_display"] = (
                        anchor_axis.transAxes.transform(target.get("current_anchor"))
                    )
                else:
                    target["drag_base_anchor_display"] = fig.transFigure.transform(
                        target.get("current_anchor")
                    )
            elif target["kind"] == "detached_spine":
                target["drag_base_offset"] = target.get("current_offset")
                target["drag_base_axis_pos"] = target.get("axis_pos")

        def _on_motion(event):
            """Handle motion.
            Used as an event callback for motion."""
            target = drag_state.get("active")
            start = drag_state.get("start")
            if target is None or start is None:
                return
            if event.x is None or event.y is None:
                return
            dx = event.x - start[0]
            dy = event.y - start[1]
            fig_w_px, fig_h_px, dpi = _figure_metrics()
            if target["kind"] in {"xlabel", "supxlabel"}:
                base_pad = target.get("drag_base_labelpad", 0.0)
                base_display = target.get("drag_base_display")
                if base_display is None:
                    base_display = (event.x, event.y)
                delta_points = (-dy) * 72.0 / dpi
                new_pad = base_pad + delta_points
                target["current_labelpad"] = new_pad
                new_display = (base_display[0], base_display[1] + dy)
                _move_handle(target, new_display)
                if target["kind"] == "supxlabel":
                    pending["xlabel_pad_pts"] = new_pad
                else:
                    pending["axis_labelpads"]["x"] = new_pad
            elif target["kind"] == "ylabel":
                base_pad = target.get("drag_base_labelpad", 0.0)
                base_display = target.get("drag_base_display")
                if base_display is None:
                    base_display = (event.x, event.y)
                side = target.get("label_side", "left")
                sign = 1.0 if side == "right" else -1.0
                delta_points = (dx * sign) * 72.0 / dpi
                new_pad = base_pad + delta_points
                target["current_labelpad"] = new_pad
                new_display = (base_display[0] + dx, base_display[1])
                _move_handle(target, new_display)
                pad_key = target.get("axis_role")
                if pad_key == "detached_labelpad":
                    pending["detached_labelpad"] = new_pad
                else:
                    pending["axis_labelpads"][pad_key] = new_pad
            elif target["kind"] in {"title", "suptitle"}:
                base_display = target.get("drag_base_display")
                if base_display is None:
                    base_display = (event.x, event.y)
                new_display = (base_display[0] + dx, base_display[1] + dy)
                _move_handle(target, new_display)
                fig_xy = _to_fig_from_display(new_display)
                fig_xy = (_clamp_anchor(fig_xy[0]), _clamp_anchor(fig_xy[1]))
                target["current_pos_fig"] = fig_xy
                if target["kind"] == "title":
                    pending["title_xy"] = fig_xy
                else:
                    pending["suptitle_xy"] = fig_xy
            elif target["kind"] == "legend":
                base_bbox = target.get("drag_base_bbox_fig")
                if base_bbox is None:
                    return
                dx_fig = dx / fig_w_px
                dy_fig = dy / fig_h_px
                new_bbox = Bbox.from_extents(
                    base_bbox.x0 + dx_fig,
                    base_bbox.y0 + dy_fig,
                    base_bbox.x1 + dx_fig,
                    base_bbox.y1 + dy_fig,
                )
                _move_legend_rect(target, new_bbox)
                anchor_space = target.get("anchor_space")
                base_anchor_disp = target.get("drag_base_anchor_display")
                if base_anchor_disp is None:
                    base_anchor_disp = (event.x, event.y)
                new_anchor_disp = (base_anchor_disp[0] + dx, base_anchor_disp[1] + dy)
                if anchor_space == "axes":
                    anchor_axis = target.get("anchor_axis")
                    if anchor_axis is None:
                        return
                    new_anchor = anchor_axis.transAxes.inverted().transform(
                        new_anchor_disp
                    )
                else:
                    new_anchor = _to_fig_from_display(new_anchor_disp)
                new_anchor = (
                    _clamp_anchor(new_anchor[0]),
                    _clamp_anchor(new_anchor[1]),
                )
                target["current_anchor"] = new_anchor
                pending[target.get("pending_key", "legend_anchor")] = new_anchor
                pending[target.get("loc_key", "legend_loc")] = target.get("loc_value")
            elif target["kind"] == "detached_spine":
                axis_pos = target.get("drag_base_axis_pos")
                if axis_pos is None:
                    return
                base_offset = target.get("drag_base_offset", 1.12)
                base_x = axis_pos.x0 + (axis_pos.width * float(base_offset))
                base_x_disp = fig.transFigure.transform((base_x, axis_pos.y0))[0]
                new_x_disp = base_x_disp + dx
                new_x_fig = _to_fig_from_display((new_x_disp, 0.0))[0]
                try:
                    new_offset = (new_x_fig - axis_pos.x0) / axis_pos.width
                except Exception:
                    new_offset = base_offset
                new_offset = max(1.0, min(2.0, float(new_offset)))
                target["current_offset"] = new_offset
                x_fig = axis_pos.x0 + (axis_pos.width * new_offset)
                line = target.get("handle")
                if line is not None:
                    try:
                        line.set_xdata([x_fig, x_fig])
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                line_x_disp = fig.transFigure.transform((x_fig, axis_pos.y0))[0]
                target["hit_box"] = (
                    line_x_disp - 6.0,
                    fig.transFigure.transform((0.0, axis_pos.y0))[1],
                    line_x_disp + 6.0,
                    fig.transFigure.transform((0.0, axis_pos.y1))[1],
                )
                pending["detached_spine_offset"] = new_offset
            try:
                canvas.draw_idle()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _commit_target(target: Dict[str, Any]) -> None:
            """Perform commit target.
            Used to keep the workflow logic localized and testable."""
            kind = target.get("kind")
            if kind in {"xlabel", "ylabel", "supxlabel"}:
                target["base_labelpad"] = target.get("current_labelpad", 0.0)
                target["base_handle_display"] = target.get("current_handle_display")
            elif kind in {"title", "suptitle"}:
                target["base_pos_fig"] = target.get("current_pos_fig")
                target["base_handle_display"] = target.get("current_handle_display")
            elif kind == "legend":
                target["base_bbox_fig"] = target.get("current_bbox_fig")
                target["base_anchor"] = target.get("current_anchor")
                anchor_space = target.get("anchor_space")
                anchor_axis = target.get("anchor_axis")
                if anchor_space == "axes" and anchor_axis is not None:
                    target["base_anchor_display"] = anchor_axis.transAxes.transform(
                        target.get("current_anchor")
                    )
                else:
                    target["base_anchor_display"] = fig.transFigure.transform(
                        target.get("current_anchor")
                    )
            elif kind == "detached_spine":
                target["base_offset"] = target.get("current_offset")

        def _on_release(_event):
            """Handle release.
            Used as an event callback for release."""
            target = drag_state.get("active")
            if target is not None:
                _commit_target(target)
            drag_state["active"] = None
            drag_state["start"] = None

        cids = [
            canvas.mpl_connect("button_press_event", _on_press),
            canvas.mpl_connect("motion_notify_event", _on_motion),
            canvas.mpl_connect("button_release_event", _on_release),
        ]

        self._layout_editor_states[plot_id] = {
            "fig": fig,
            "canvas": canvas,
            "pending": pending,
            "overlay_artists": overlay_artists,
            "elements": elements,
            "apply_target_var": apply_target_var,
            "cids": cids,
        }
        try:
            canvas.draw_idle()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        def _close_editor() -> None:
            """Close editor.
            Used by UI actions to close editor safely."""
            self._teardown_layout_editor(plot_id, apply_changes=True)

        editor.protocol("WM_DELETE_WINDOW", _close_editor)

    def _clear_plot_tabs(self):
        """Clear all plot tabs and associated UI state.

        Purpose:
            Remove generated plot tabs and release associated controllers/canvases.
        Why:
            Plot regeneration and dataset changes require a clean plot tab slate
            without leaving stale canvases or losing persisted legend anchors.

        Args:
            None.

        Returns:
            None.

        Side Effects:
            Captures combined legend anchors when persistence is enabled,
            tears down plot UI helpers, and removes tabs/canvases from the notebook.

        Exceptions:
            Errors are caught to avoid breaking the UI teardown flow.
        """

        # remove any previously added plot tabs
        for controller in list(self._plot_annotation_controllers.values()):
            try:
                controller.disconnect()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._plot_annotation_controllers = {}
        self._plot_annotation_panels = {}
        # Iterate over values from list(self._plot_element_windows to apply the per-item logic.
        for window in list(self._plot_element_windows.values()):
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._plot_element_windows = {}
        # Iterate over keys from list(self._layout_editor_windows to apply the per-item logic.
        for plot_id in list(self._layout_editor_windows.keys()):
            self._teardown_layout_editor(plot_id, apply_changes=False)
        self._layout_editor_windows = {}
        self._layout_editor_states = {}
        self._plot_dirty_flags = {}
        try:
            self._close_plot_settings_dialog()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        # Capture combined legend anchors before tabs are destroyed.
        try:
            tabs = list(getattr(self, "_plot_tabs", []) or [])
            canvases = list(getattr(self, "_canvases", []) or [])
            # Iterate over indexed elements from tabs to apply the per-item logic.
            for idx, tab in enumerate(tabs):
                if getattr(tab, "_plot_key", None) != "fig_combined" and getattr(
                    tab, "_plot_id", None
                ) != "fig_combined_triple_axis":
                    continue
                if not self._combined_cycle_legend_capture_enabled():
                    # Skip capture when persistence is disabled or locked.
                    continue
                canvas = canvases[idx] if idx < len(canvases) else None
                try:
                    self._capture_combined_legend_anchor_from_fig(
                        getattr(canvas, "figure", None),
                        source="refresh",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        # Iterate over getattr(self, "_plot_tabs", []) to apply the per-item logic.
        for tab in getattr(self, "_plot_tabs", []):

            try:

                self.nb.forget(tab)

                tab.destroy()

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        self._plot_tabs = []

        self._canvases = []

        plot_settings_tab = getattr(self, "_plot_settings_tab", None) or getattr(
            self, "tab_plot", None
        )
        if plot_settings_tab is not None:
            try:
                # Explicitly return focus to Plot Settings after tab teardown.
                self.nb.select(plot_settings_tab)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        self._log_plot_tab_debug("Plot tabs cleared; flushing Tk events.")

        try:
            self.nb.update_idletasks()
            self.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _add_plot_tab(
        self, title, fig, *, plot_key: str | None = None, auto_refresh: bool = True
    ):
        """Add a plot tab and embed the provided figure.

        Purpose:
            Create a plot tab with toolbar controls and a Matplotlib canvas.
        Why:
            The UI renders plots into tabs so users can switch between figures
            without losing per-plot controls or annotations, while keeping save
            controls and format toggles grouped together.
        Inputs:
            title: Tab title string.
            fig: Matplotlib Figure to embed.
            plot_key: Optional plot key used to tag plot metadata and routing.
            auto_refresh: When True, schedule the auto-refresh pipeline that
                stabilizes the first render before removing overlays.
        Outputs:
            The created tab frame.
        Side Effects:
            Creates Tk widgets, binds canvas resize handlers, registers plot
            controllers, selects the new tab immediately, schedules display
            refresh logic (when enabled), and initializes plot loading/auto-
            refresh state for the generated tab.
        Exceptions:
            Widget and canvas errors are caught to avoid UI interruption.
        """

        frame = ttk.Frame(self.nb)
        frame._plot_key = plot_key
        frame._plot_auto_refresh_state = "pending"
        frame._plot_auto_refresh_phase = None
        frame._plot_auto_refresh_enabled = bool(auto_refresh)
        frame._plot_auto_refresh_after_id = None
        frame._plot_auto_refresh_in_progress = False
        frame._plot_initial_render_complete = False
        frame._plot_render_task_id = None
        frame._plot_loading_overlay = None
        frame._plot_loading_label = None
        frame._plot_loading_progress_var = None
        frame._plot_loading_bar = None
        frame._plot_loading_progress_label = None
        frame._plot_loading_progress_value = 0.0
        frame._refresh_command = None
        frame._post_first_draw_refresh_done = False
        frame._post_first_draw_refresh_invoked = False
        frame._post_first_draw_refresh_hold_overlay = False
        frame._post_first_draw_refresh_retry_count = 0
        if plot_key in {"fig1", "fig2"}:
            is_real_core = self._is_real_core_figure(fig)
            frame._core_real_figure_installed = bool(is_real_core)
            frame._core_overlay_refresh_invoked_count = 0
            frame._core_overlay_refresh_completed_count = 0
            frame._core_overlay_layout_sig_baseline = None
            frame._core_overlay_need_second_refresh = True
            frame._core_overlay_target_refreshes = 2
            frame._core_overlay_ready_seen = False
            frame._core_overlay_second_refresh_scheduled = False
            frame._core_overlay_hold = not bool(is_real_core)
        if plot_key == "fig_combined":
            is_real_combined = self._is_real_combined_figure(fig)
            default_target_refreshes = self._combined_overlay_default_target_refreshes()
            frame._combined_render_ready = False
            frame._post_first_draw_refresh_hold_overlay = True
            frame._combined_real_figure_installed = bool(is_real_combined)
            frame._combined_overlay_refresh_invoked_count = 0
            frame._combined_overlay_refresh_completed_count = 0
            frame._combined_overlay_layout_sig_baseline = None
            frame._combined_overlay_decision_sig_baseline = None
            frame._combined_overlay_decision_sig_last = None
            frame._combined_overlay_data_sig_current = None
            frame._combined_overlay_need_second_refresh = default_target_refreshes > 1
            frame._combined_overlay_target_refreshes = default_target_refreshes
            frame._combined_overlay_ready_seen = False
            frame._combined_overlay_second_refresh_scheduled = False
            frame._combined_placeholder_draw_logged = False
            frame._combined_overlay_last_geometry_sig = None
            frame._combined_overlay_stable_draw_count = 0
            frame._combined_overlay_finalize_started_at = None
            frame._combined_overlay_finalize_after_id = None

        self._log_plot_tab_debug(f"Creating tab frame for '{title}'")

        try:
            self.nb.add(frame, text=title)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:
            self.nb.update_idletasks()

        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if not hasattr(self, "_plot_tabs"):
            self._plot_tabs = []

            self._canvases = []

        # --- Toolbar shell for action controls and export format toggles.
        topbar_shell = ttk.Frame(frame)
        topbar_shell.pack(side="top", fill="x")
        topbar = ttk.Frame(topbar_shell)
        topbar.pack(side="top", fill="x")

        plot_id = self._plot_key_to_plot_id(plot_key, title)
        frame._plot_id = plot_id

        canvas = FigureCanvasTkAgg(fig, master=frame)
        try:
            # Bind the tab frame so draw-event handlers can route refresh state.
            canvas._plot_frame = frame  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        # Closure captures _add_plot_tab state for callback wiring, kept nested to
        # scope the handler, and invoked by bindings set in _add_plot_tab.
        def _refresh_panel_internal() -> None:
            """Refresh panel via internal orchestration callback.

            Purpose:
                Execute one refresh pass for auto-refresh orchestration.
            Why:
                Post-draw and adaptive refresh passes rely on the legacy direct
                refresh callback and must not re-arm overlay counters.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                Invokes `_force_plot_refresh` on the current frame/canvas pair.
            Exceptions:
                Errors are handled by the downstream refresh pipeline.
            """
            self._force_plot_refresh(frame, canvas)

        def _refresh_panel_user() -> None:
            """Refresh the plot panel using the user-facing unified pipeline.

            Purpose:
                Rebuild the current plot tab using the same Refresh logic.
            Why:
                Manual Refresh should re-arm overlay orchestration and avoid
                pre-refresh combined legend recapture drift.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                Triggers a plot rebuild and display refresh on the existing canvas.
            Exceptions:
                Errors are handled by the downstream refresh pipeline.
            """
            refresh_message = (
                "Refreshing combined plot..."
                if plot_key == "fig_combined"
                else "Refreshing plot..."
            )
            if plot_id:
                self._refresh_plot_for_plot_id(
                    plot_id,
                    reason=refresh_message,
                    rearm_overlay=True,
                    capture_combined_legend=False,
                )
                return
            self._force_plot_refresh(
                frame,
                canvas,
                capture_combined_legend=False,
                refresh_reason=refresh_message,
            )

        # Assign the refresh command before any draw/draw_idle can run.
        frame._refresh_command = _refresh_panel_internal

        toolbar = NavigationToolbar2Tk(canvas, topbar)  # mount toolbar in the topbar

        toolbar.update()

        toolbar.pack(side="left", fill="x")

        widget = canvas.get_tk_widget()
        widget.pack(fill="both", expand=True)

        try:
            self.nb.update_idletasks()
            self.update_idletasks()
            widget.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        overlay_message = (
            "Loading combined plot..."
            if plot_key == "fig_combined"
            else "Loading plot..."
        )
        # Hide the initial render behind a loading overlay until auto-refresh completes.
        self._install_plot_loading_overlay(frame, widget, message=overlay_message)
        # Select immediately so the loading overlay is visible without delay.
        try:
            self.nb.select(frame)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        # Flush pending UI work so the new tab and overlay paint right away.
        for widget_obj in (self.nb, frame, widget):
            try:
                widget_obj.update_idletasks()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        fig_size = None
        try:
            width_px = max(int(widget.winfo_width()), 1)
            height_px = max(int(widget.winfo_height()), 1)
            if width_px > 1 and height_px > 1:
                dpi = float(getattr(fig, "dpi", 100.0))
                if not math.isfinite(dpi) or dpi <= 0.0:
                    dpi = 100.0
                fig_size = (
                    max(width_px / dpi, 1.0),
                    max(height_px / dpi, 1.0),
                )
        except Exception:
            fig_size = None
        if fig_size is None:
            try:
                fig_size = self._compute_target_figsize_inches()
            except Exception:
                fig_size = None
        if fig_size is not None:
            try:
                fig.set_size_inches(fig_size, forward=False)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if plot_id and plot_key != "fig_combined":
            try:
                self._apply_display_settings_for_plot(fig, plot_id, canvas)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        format_order = ("png", "pdf", "svg")
        format_specs = {
            "png": ("PNG files", "*.png"),
            "pdf": ("PDF files", "*.pdf"),
            "svg": ("SVG files", "*.svg"),
        }

        # Closure captures _add_plot_tab local context to keep helper logic scoped and invoked directly within _add_plot_tab.
        def _get_plot_export_formats_defaulted():
            """Return plot export formats defaulted.
            Used to retrieve plot export formats defaulted for downstream logic."""
            raw = settings.get("plot_export_formats")
            if not isinstance(raw, dict):
                raw = {}
            normalized = {fmt: bool(raw.get(fmt, False)) for fmt in format_order}
            if not any(normalized.values()):
                normalized["svg"] = True
            return normalized

        format_defaults = _get_plot_export_formats_defaulted()
        format_vars = {
            fmt: tk.BooleanVar(
                master=frame, value=bool(format_defaults.get(fmt, False))
            )
            # Iterate to apply the per-item logic.
            for fmt in format_order
        }

        # Closure captures _add_plot_tab local context to keep helper logic scoped and invoked directly within _add_plot_tab.
        def _persist_plot_export_formats():
            """Export formats.
            Used by persist plot workflows to export formats."""
            settings["plot_export_formats"] = {
                fmt: bool(format_vars[fmt].get()) for fmt in format_order
            }
            if hasattr(self, "_schedule_save_settings"):
                try:
                    self._schedule_save_settings()
                    return
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Closure captures _add_plot_tab local context to keep helper logic scoped and invoked directly within _add_plot_tab.
        def _selected_formats():
            """Perform selected formats.
            Used to keep the workflow logic localized and testable."""
            return [fmt for fmt in format_order if format_vars[fmt].get()]

        save_button = None

        # Closure captures _add_plot_tab state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _add_plot_tab.
        def _update_save_button_state():
            """Update save button state.
            Used to keep save button state in sync with current state."""
            if save_button is None:
                return
            self._set_widget_enabled(save_button, bool(_selected_formats()))

        # Closure captures _add_plot_tab state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _add_plot_tab.
        def _on_format_toggle():
            """Handle format toggle.
            Used as an event callback for format toggle."""
            _persist_plot_export_formats()
            _update_save_button_state()

        # Closure captures _add_plot_tab local context to keep helper logic scoped and invoked directly within _add_plot_tab.
        def _save_selected_formats():
            """Save selected formats.
            Used when persisting selected formats to storage."""

            _persist_plot_export_formats()

            selected_formats = _selected_formats()

            if not selected_formats:
                try:
                    messagebox.showinfo(
                        "No File Type Selected",
                        "Select at least one file type before saving.",
                    )

                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

                return

            initial_ext = selected_formats[0]

            filetypes = [format_specs[fmt] for fmt in selected_formats]
            filetypes.append(("All files", "*.*"))

            path = filedialog.asksaveasfilename(
                title="Save Plot",
                defaultextension=f".{initial_ext}",
                filetypes=filetypes,
                initialfile=(
                    (title.replace(":", " - ") + f".{initial_ext}")
                    if title
                    else f"plot.{initial_ext}"
                ),
            )

            if not path:
                return

            base, _ = os.path.splitext(path)

            if not base:
                base = path

            prev_size = fig.get_size_inches()
            base_width, base_height = tuple(prev_size)

            prev_dpi = fig.dpi

            target_w, target_h = self._compute_output_dimensions(
                "plot_export", base_width, base_height
            )

            export_fig = fig
            close_export_fig = False
            resized_current_fig = False

            try:
                if plot_key == "fig_combined":
                    try:
                        preview_fig = getattr(self, "_combined_plot_preview_fig", None)
                        target_fig = preview_fig if preview_fig is not None else fig
                        if target_fig is not None and target_fig.canvas is not None:
                            try:
                                target_fig.canvas.draw()
                            except Exception:
                                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                                pass
                        self._capture_combined_legend_anchor_from_fig(
                            target_fig,
                            source="sync",
                        )
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                    export_fig = self.render_plot(
                        "fig_combined",
                        target="export",
                        mode="export",
                        plot_id=plot_id,
                        fig_size=(11.0, 8.5),
                    )
                    if export_fig is None:
                        msg = "Combined plot could not be rebuilt for export."
                        try:
                            messagebox.showerror("Save Error", msg)
                        except Exception:
                            print(f"Save Error: {msg}")
                        return
                    close_export_fig = True
                    if not self._assert_combined_export_size(export_fig):
                        return
                else:
                    export_fig = self.render_plot(
                        plot_key or "",
                        target="export",
                        mode="export",
                        plot_id=plot_id,
                        fig_size=(target_w, target_h),
                    )
                    if export_fig is None:
                        msg = "Plot could not be rebuilt for export."
                        try:
                            messagebox.showerror("Save Error", msg)
                        except Exception:
                            print(f"Save Error: {msg}")
                        return
                    close_export_fig = True
                    if plot_id:
                        try:
                            _apply_layout_profile_to_figure(
                                export_fig, plot_id, "export"
                            )
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass

                if plot_id and plot_key != "fig_combined":
                    try:
                        self._apply_plot_elements(export_fig, plot_id)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                try:
                    self._apply_gl260_legend_sizing(
                        export_fig, plot_id=plot_id, plot_key=plot_key
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

                errors = []
                export_dpi = self._get_export_dpi()

                if plot_key == "fig_combined":
                    try:
                        from matplotlib.backends.backend_agg import FigureCanvasAgg
                    except Exception:
                        FigureCanvasAgg = None
                    export_canvas = None
                    try:
                        export_canvas = export_fig.canvas
                    except Exception:
                        export_canvas = None
                    if FigureCanvasAgg is not None:
                        if export_canvas is None or not isinstance(
                            export_canvas, FigureCanvasAgg
                        ):
                            try:
                                export_canvas = FigureCanvasAgg(export_fig)
                            except Exception:
                                export_canvas = getattr(export_fig, "canvas", None)
                    if export_canvas is None:
                        export_canvas = getattr(export_fig, "canvas", None)
                    try:
                        self._finalize_matplotlib_canvas_layout(
                            canvas=export_canvas,
                            fig=export_fig,
                            tk_widget=None,
                            keep_export_size=True,
                            trigger_resize_event=False,
                            force_draw=True,
                        )
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

                # Iterate over selected_formats to apply the per-item logic.
                for fmt in selected_formats:
                    out_path = f"{base}.{fmt}"

                    try:
                        save_kwargs = {"format": fmt}

                        if fmt.lower() in {"png", "pdf"}:
                            save_kwargs["dpi"] = export_dpi

                        export_fig.savefig(out_path, **save_kwargs)

                    except Exception as exc:
                        errors.append((fmt, exc))

                if errors:
                    try:
                        messagebox.showerror(
                            "Save Error",
                            "The following files could not be saved:\n"
                            + "\n".join(f"{fmt.upper()}: {exc}" for fmt, exc in errors),
                        )

                    except Exception:
                        # Iterate over errors to apply the per-item logic.
                        for _, exc in errors:
                            print(f"Save Error: {exc}")

            finally:
                if resized_current_fig:
                    try:
                        fig.set_size_inches(prev_size, forward=False)

                        fig.set_dpi(prev_dpi)

                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                    if plot_id and plot_key != "fig_combined":
                        try:
                            _apply_layout_profile_to_figure(fig, plot_id, "display")
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass

                if close_export_fig and export_fig is not fig:
                    try:
                        plt.close(export_fig)

                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

                try:
                    canvas.draw_idle()

                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        # Closure captures _add_plot_tab state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _add_plot_tab.
        def _close_this_plot():
            """Close the current plot tab and return to Plot Settings.

            Purpose:
                Tear down the selected plot tab and route focus back to the
                Plot Settings tab to keep the workflow centered on plotting.
            Why:
                Users expect to continue adjusting plot settings after closing
                a generated figure, not to land on Final Report.

            Args:
                None.

            Returns:
                None.

            Side Effects:
                Captures combined legend anchors when persistence is enabled,
                destroys the tab/canvas, and selects the Plot Settings tab.

            Exceptions:
                Errors are caught to avoid interrupting UI teardown.
            """

            self._log_plot_tab_debug(f"Close requested for '{title}'")

            if plot_key == "fig_combined":
                # Capture combined legend anchors before the figure is closed.
                if self._combined_cycle_legend_capture_enabled():
                    try:
                        self._capture_combined_legend_anchor_from_fig(
                            fig,
                            source="refresh",
                        )
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            if plot_id:
                controller = self._plot_annotation_controllers.pop(plot_id, None)
                if controller is not None:
                    try:
                        controller.disconnect()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                self._plot_annotation_panels.pop(plot_id, None)
                window = self._plot_element_windows.pop(plot_id, None)
                if window is not None:
                    try:
                        window.destroy()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                self._plot_element_editors.pop(plot_id, None)
                try:
                    self._teardown_layout_editor(plot_id, apply_changes=False)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                self._plot_dirty_flags.pop(plot_id, None)
                if getattr(self, "_plot_settings_target_id", None) == plot_id:
                    try:
                        self._close_plot_settings_dialog()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            try:
                self.nb.forget(frame)

            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            try:
                frame.destroy()

            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            try:
                idx = self._plot_tabs.index(frame)

                del self._plot_tabs[idx]

                if idx < len(self._canvases):
                    del self._canvases[idx]

            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            try:
                import matplotlib.pyplot as plt

                plt.close(fig)

            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            plot_settings_tab = getattr(self, "_plot_settings_tab", None) or getattr(
                self, "tab_plot", None
            )
            if plot_settings_tab is not None:
                try:
                    # Explicitly route focus to Plot Settings after tab close.
                    self.nb.select(plot_settings_tab)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        btn_close = _ui_button(topbar, text="Close Plot", command=_close_this_plot)

        btn_close.pack(side="right", padx=6, pady=4)

        btn_refresh = _ui_button(
            topbar,
            text="Refresh",
            command=_refresh_panel_user,
        )

        btn_refresh.pack(side="right", padx=6, pady=4)

        if plot_id:
            if plot_key == "fig_combined":
                btn_elements = _ui_button(
                    topbar,
                    text="Plot Elements...",
                    command=lambda: self._open_plot_elements_editor(
                        canvas.figure, canvas, plot_id
                    ),
                )
                btn_elements.pack(side="right", padx=6, pady=4)
                btn_settings = _ui_button(
                    topbar,
                    text="Plot Settings...",
                    command=lambda: self._open_plot_settings_dialog(plot_id),
                )
                btn_settings.pack(side="right", padx=6, pady=4)
                btn_trace_settings = _ui_button(
                    topbar,
                    text="Data Trace Settings...",
                    command=self._open_data_trace_settings_dialog,
                )
                btn_trace_settings.pack(side="right", padx=6, pady=4)
            else:
                btn_elements = _ui_button(
                    topbar,
                    text="Add Plot Elements...",
                    command=lambda: self._open_plot_elements_editor(
                        canvas.figure, canvas, plot_id
                    ),
                )
                btn_elements.pack(side="right", padx=6, pady=4)
                btn_settings = _ui_button(
                    topbar,
                    text="Plot Settings...",
                    command=lambda: self._open_plot_settings_dialog(plot_id),
                )
                btn_settings.pack(side="right", padx=6, pady=4)
                btn_trace_settings = _ui_button(
                    topbar,
                    text="Data Trace Settings...",
                    command=self._open_data_trace_settings_dialog,
                )
                btn_trace_settings.pack(side="right", padx=6, pady=4)

        save_controls = ttk.Frame(topbar)

        save_controls.pack(side="left", padx=6, pady=4)

        save_button = _ui_button(
            save_controls, text="Save As", command=_save_selected_formats
        )

        save_button.pack(side="left", padx=(0, 8))

        if plot_key == "fig_combined":
            preview_button = _ui_button(
                save_controls,
                text="Plot Preview",
                command=lambda: self._open_plot_preview(plot_key, plot_id, title),
            )
            preview_button.pack(side="left", padx=(0, 8))

        combined_export_row = plot_key == "fig_combined"
        checkbox_frame = ttk.Frame(save_controls)
        checkbox_frame.pack(side="left", padx=(0, 2) if combined_export_row else (0, 6))

        # Iterate over format_order to apply the per-item logic.
        for fmt in format_order:
            if combined_export_row:
                check_widget = ttk.Checkbutton(
                    checkbox_frame,
                    text=fmt.upper(),
                    variable=format_vars[fmt],
                    command=_on_format_toggle,
                )
            else:
                check_widget = _ui_checkbutton(
                    checkbox_frame,
                    text=fmt.upper(),
                    variable=format_vars[fmt],
                    command=_on_format_toggle,
                )
            check_widget.pack(side="left", padx=(0, 1) if combined_export_row else (0, 6))

        _update_save_button_state()

        # --- Canvas below the topbar

        widget = canvas.get_tk_widget()

        refresh_state = {"scheduled": False}

        # Closure captures _add_plot_tab local context to keep helper logic scoped and invoked directly within _add_plot_tab.
        def _schedule_canvas_sync(_event=None):
            """Schedule a canvas sync on idle.

            Purpose:
                Queue a lightweight refresh of the canvas display on idle.
            Why:
                Canvas geometry can change during layout; syncing on idle keeps
                the UI responsive while avoiding redundant refresh work.
            Inputs:
                _event: Optional Tk event payload (unused).
            Outputs:
                None.
            Side Effects:
                Schedules a deferred refresh of the canvas display.
            Exceptions:
                Errors are caught to avoid interrupting the UI loop.
            """

            if refresh_state["scheduled"]:
                return
            if plot_key == "fig_combined" and not getattr(
                frame, "_combined_render_ready", False
            ):
                # Combined plots defer the first draw; skip premature sync.
                return

            refresh_state["scheduled"] = True

            # Closure captures _schedule_canvas_sync local context to keep helper logic scoped and invoked directly within _schedule_canvas_sync.
            def _do_refresh():
                """Refresh value.
                Used by do workflows to refresh value."""

                refresh_state["scheduled"] = False

                self._refresh_canvas_display(frame, canvas, trigger_resize=False)

            try:
                self.after_idle(_do_refresh)

            except Exception:
                _do_refresh()

        try:
            widget.bind("<Configure>", _schedule_canvas_sync, add="+")

        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        _schedule_canvas_sync()

        if plot_key != "fig_combined":
            canvas.draw()

        # Closure captures _add_plot_tab local context to keep helper logic scoped and invoked directly within _add_plot_tab.
        def _finalize_tab_display():
            """Perform finalize tab display.
            Used to keep the workflow logic localized and testable."""

            try:
                if plot_key == "fig_combined":
                    self._finalize_combined_plot_display(frame, canvas)
                else:
                    self._refresh_canvas_display(frame, canvas, trigger_resize=True)
                    try:
                        frame._plot_initial_render_complete = True
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                    if getattr(frame, "_plot_auto_refresh_enabled", True):
                        self._schedule_plot_auto_refresh(frame, canvas)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        _finalize_tab_display()

        self._plot_tabs.append(frame)

        self._canvases.append(canvas)

        if plot_id:
            try:
                self._set_plot_dirty_flags(
                    plot_id,
                    dirty_data=False,
                    dirty_layout=False,
                    dirty_elements=False,
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        return frame

    def _set_combined_plot_preview_loading_state(
        self,
        *,
        progress: Optional[float] = None,
        message: Optional[str] = None,
        reset: bool = False,
        show: bool = True,
    ) -> None:
        """Update combined Plot Preview loading overlay message/progress.

        Purpose:
            Keep preview splash progress synchronized with async preview stages.
        Why:
            Preview rendering runs across worker/UI phases and needs deterministic
            user feedback.
        Inputs:
            progress: Optional progress value in the 0..100 range.
            message: Optional stage message to display.
            reset: When True, reset tracked progress before applying updates.
            show: When True, ensure overlay remains visible.
        Outputs:
            None.
        Side Effects:
            Mutates preview overlay widgets and cached progress value.
        Exceptions:
            Best-effort behavior; missing widgets are ignored.
        """
        overlay = getattr(self, "_combined_plot_preview_overlay", None)
        if overlay is None:
            return
        try:
            if not overlay.winfo_exists():
                return
        except Exception:
            return
        if reset:
            self._combined_plot_preview_progress_value = 0.0
        current_value = getattr(self, "_combined_plot_preview_progress_value", 0.0)
        try:
            current_value = float(current_value)
        except Exception:
            current_value = 0.0
        if not math.isfinite(current_value):
            current_value = 0.0
        target_value = current_value
        if progress is not None:
            try:
                candidate = float(progress)
            except Exception:
                candidate = current_value
            if not math.isfinite(candidate):
                candidate = current_value
            candidate = max(0.0, min(100.0, candidate))
            target_value = candidate if reset else max(current_value, candidate)
        label = getattr(self, "_combined_plot_preview_overlay_label", None)
        if label is not None and message is not None:
            try:
                label.configure(text=str(message))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        progress_var = getattr(self, "_combined_plot_preview_overlay_progress_var", None)
        if progress_var is not None:
            try:
                progress_var.set(float(target_value))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        progress_label = getattr(self, "_combined_plot_preview_overlay_progress_label", None)
        if progress_label is not None:
            try:
                progress_label.configure(text=f"{int(round(target_value))}%")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._combined_plot_preview_progress_value = float(target_value)
        if show:
            try:
                overlay.place(relx=0.0, rely=0.0, relwidth=1.0, relheight=1.0)
                overlay.lift()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        window = getattr(self, "_combined_plot_preview_window", None)
        if window is not None:
            try:
                window.update_idletasks()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _hide_combined_plot_preview_loading(self, *, defer: bool = True) -> None:
        """Hide the combined Plot Preview loading overlay.

        Purpose:
            Remove splash overlay after preview install/failure handling.
        Why:
            Ensures overlay cleanup is centralized across success and error paths.
        Inputs:
            defer: When True, hide via after_idle to allow pending UI updates first.
        Outputs:
            None.
        Side Effects:
            Hides the preview overlay frame.
        Exceptions:
            Best-effort behavior; widget errors are ignored.
        """

        def _do_hide() -> None:
            """Hide preview overlay widgets.

            Purpose:
                Centralize overlay hide logic.
            Why:
                Prevent duplicate cleanup code across callbacks.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                Calls `place_forget()` on preview overlay.
            Exceptions:
                Best-effort behavior; errors are ignored.
            """
            overlay = getattr(self, "_combined_plot_preview_overlay", None)
            if overlay is None:
                return
            try:
                overlay.place_forget()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if defer:
            try:
                self.after_idle(_do_hide)
            except Exception:
                _do_hide()
        else:
            _do_hide()

    def _close_combined_plot_preview_window(self, _event: Any = None) -> None:
        """Close combined Plot Preview window and invalidate in-flight preview tasks.

        Purpose:
            Tear down preview resources safely.
        Why:
            Preview callbacks can complete after close; token invalidation avoids
            stale UI mutation.
        Inputs:
            _event: Optional Tk event payload.
        Outputs:
            None.
        Side Effects:
            Closes preview figure/window widgets, clears preview state, restores
            combined legend tracking when combined tab exists.
        Exceptions:
            Best-effort cleanup; exceptions are suppressed.
        """
        window = getattr(self, "_combined_plot_preview_window", None)
        if window is None:
            return
        if _event is not None and getattr(_event, "widget", None) is not window:
            return
        if getattr(self, "_combined_plot_preview_closing", False):
            return
        self._combined_plot_preview_closing = True
        try:
            self._combined_plot_preview_request_token += 1
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            after_id = getattr(self, "_combined_plot_preview_resize_after_id", None)
            if after_id is not None:
                window.after_cancel(after_id)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._combined_plot_preview_resize_after_id = None
        preview_fig = getattr(self, "_combined_plot_preview_fig", None)
        if preview_fig is not None:
            try:
                self._capture_combined_legend_anchor_from_fig(
                    preview_fig,
                    source="sync",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                plt.close(preview_fig)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            if _event is None and window.winfo_exists():
                window.destroy()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._combined_plot_preview_window = None
        self._combined_plot_preview_host = None
        self._combined_plot_preview_content = None
        self._combined_plot_preview_overlay = None
        self._combined_plot_preview_overlay_label = None
        self._combined_plot_preview_overlay_progress_var = None
        self._combined_plot_preview_overlay_progress_label = None
        self._combined_plot_preview_canvas = None
        self._combined_plot_preview_toolbar = None
        self._combined_plot_preview_fig = None
        self._combined_plot_preview_progress_value = 0.0
        self._combined_plot_preview_task_id = None
        try:
            tabs = list(getattr(self, "_plot_tabs", []) or [])
            has_combined_tab = any(
                getattr(tab, "_plot_key", None) == "fig_combined"
                or getattr(tab, "_plot_id", None) == "fig_combined_triple_axis"
                for tab in tabs
            )
        except Exception:
            has_combined_tab = False
        if has_combined_tab:
            try:
                self._apply_saved_cycle_legend_state_to_display_combined()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._combined_plot_preview_closing = False

    def _open_plot_preview(
        self, plot_key: str | None, plot_id: str | None, title: str
    ) -> None:
        """Open combined Plot Preview with async compute and splash overlay.

        Purpose:
            Show the preview window immediately, then build preview in stages.
        Why:
            Data preparation is expensive; running it in a worker keeps Tk
            responsive while the splash/progress stays active on the UI thread.
        Inputs:
            plot_key: Plot key requested for preview; only combined is supported.
            plot_id: Plot identifier for combined preview settings.
            title: Title text from the invoking button (unused).
        Outputs:
            None.
        Side Effects:
            Opens/reuses preview window, runs async preview prep, installs preview
            figure widgets, and updates loading overlay progress stages.
        Exceptions:
            Failures are caught and reported via dialog while preventing stuck UI.
        """
        if plot_key != "fig_combined":
            return
        try:
            # Ensure preview uses the latest staged Plot Settings values.
            self._flush_open_plot_settings_dialog(refresh_after_apply=False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        preview_plot_id = plot_id or "fig_combined_triple_axis"
        try:
            _display_frame, display_canvas = self._find_plot_tab_canvas("fig_combined")
            display_fig = getattr(display_canvas, "figure", None)
            if display_fig is not None:
                # Sync latest display legend placement before rebuilding preview.
                self._capture_combined_legend_anchor_from_fig(
                    display_fig,
                    source="sync",
                )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        window = getattr(self, "_combined_plot_preview_window", None)
        if window is None or not bool(getattr(window, "winfo_exists", lambda: False)()):
            window = tk.Toplevel(self)
            window.title("Plot Preview (Export 11x8.5)")
            window.transient(self)
            host = ttk.Frame(window)
            host.pack(fill="both", expand=True)
            content = ttk.Frame(host)
            content.pack(fill="both", expand=True)
            try:
                base_bg = window.cget("background")
            except Exception:
                base_bg = None
            overlay = tk.Frame(host, background=base_bg)
            center = ttk.Frame(overlay)
            center.place(relx=0.5, rely=0.5, anchor="center")
            label = ttk.Label(center, text="Opening Preview...")
            label.pack(side="top", pady=(0, 8))
            progress_var = tk.DoubleVar(master=overlay, value=0.0)
            ttk.Progressbar(
                center,
                mode="determinate",
                length=260,
                maximum=100.0,
                variable=progress_var,
            ).pack(side="top")
            progress_label = ttk.Label(center, text="0%")
            progress_label.pack(side="top", pady=(6, 0))
            overlay.place(relx=0.0, rely=0.0, relwidth=1.0, relheight=1.0)
            overlay.place_forget()

            self._combined_plot_preview_window = window
            self._combined_plot_preview_host = host
            self._combined_plot_preview_content = content
            self._combined_plot_preview_overlay = overlay
            self._combined_plot_preview_overlay_label = label
            self._combined_plot_preview_overlay_progress_var = progress_var
            self._combined_plot_preview_overlay_progress_label = progress_label
            self._combined_plot_preview_progress_value = 0.0
            self._combined_plot_preview_canvas = None
            self._combined_plot_preview_toolbar = None
            self._combined_plot_preview_resize_after_id = None
            window.protocol("WM_DELETE_WINDOW", self._close_combined_plot_preview_window)
            window.bind("<Destroy>", self._close_combined_plot_preview_window, add="+")
        else:
            try:
                window.deiconify()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            window.lift()
            window.focus_force()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        self._combined_plot_preview_request_token += 1
        request_token = int(getattr(self, "_combined_plot_preview_request_token", 0))
        self._set_combined_plot_preview_loading_state(
            progress=5.0,
            message="Opening Preview...",
            reset=True,
            show=True,
        )
        self._set_combined_plot_preview_loading_state(
            progress=20.0,
            message="Preparing Preview Data...",
        )

        try:
            snapshot = self._capture_combined_render_snapshot(
                fig_size=(11.0, 8.5),
                plot_id=preview_plot_id,
                target="preview",
            )
        except Exception as exc:
            self._set_combined_plot_preview_loading_state(
                progress=100.0,
                message="Preview failed.",
            )
            self._hide_combined_plot_preview_loading()
            try:
                messagebox.showerror(
                    "Plot Preview",
                    f"Combined plot preview could not prepare inputs.\n{exc}",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        def _is_stale_request() -> bool:
            """Return whether the async preview callback is stale.

            Purpose:
                Guard async callbacks against close/reopen and repeated clicks.
            Why:
                Stale callbacks can otherwise install old figures into new windows.
            Inputs:
                None.
            Outputs:
                True when callback must be ignored; otherwise False.
            Side Effects:
                None.
            Exceptions:
                Window-state lookup failures fail closed to stale.
            """
            if request_token != getattr(self, "_combined_plot_preview_request_token", 0):
                return True
            active_window = getattr(self, "_combined_plot_preview_window", None)
            if active_window is None:
                return True
            try:
                return not active_window.winfo_exists()
            except Exception:
                return True

        def _handle_preview_failure(message: str, exc: Optional[BaseException] = None) -> None:
            """Handle preview async failures and clear loading state.

            Purpose:
                Surface errors while keeping preview overlay state consistent.
            Why:
                Worker or build failures must not leave a stuck splash.
            Inputs:
                message: Error lead message.
                exc: Optional exception details.
            Outputs:
                None.
            Side Effects:
                Updates loading overlay and displays an error dialog.
            Exceptions:
                Best-effort behavior; dialog failures are ignored.
            """
            if _is_stale_request():
                return
            self._set_combined_plot_preview_loading_state(
                progress=100.0,
                message="Preview failed.",
            )
            self._hide_combined_plot_preview_loading()
            detail = f"{message}\n{exc}" if exc is not None else message
            try:
                messagebox.showerror("Plot Preview", detail)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _worker() -> RenderPacket:
            """Compute preview packet on worker thread.

            Purpose:
                Prepare combined preview data off the UI thread.
            Why:
                Keeps the app responsive while heavy prep runs.
            Inputs:
                None.
            Outputs:
                RenderPacket for UI-thread preview build/install.
            Side Effects:
                May update render cache metadata.
            Exceptions:
                Worker exceptions are routed to error callback.
            """
            return self._compute_combined_plot_data(snapshot)

        def _on_ok(packet: RenderPacket) -> None:
            """Handle worker success and build preview on UI thread.

            Purpose:
                Build and install preview figure from prepared render packet.
            Why:
                Matplotlib/Tk widget installation must remain on UI thread.
            Inputs:
                packet: Worker-prepared render packet.
            Outputs:
                None.
            Side Effects:
                Replaces preview figure widgets and updates overlay stages.
            Exceptions:
                Build/install failures route through preview failure handler.
            """
            if _is_stale_request():
                return
            self._set_combined_plot_preview_loading_state(
                progress=55.0,
                message="Building Preview Figure...",
            )

            def _build_and_install() -> None:
                """Build/install preview figure after overlay paint.

                Purpose:
                    Defer heavy UI-thread preview build by one idle cycle.
                Why:
                    Allows splash stage updates to render before blocking work.
                Inputs:
                    None.
                Outputs:
                    None.
                Side Effects:
                    Builds preview figure and finalizes preview layout.
                Exceptions:
                    Failures route through preview failure handler.
                """
                if _is_stale_request():
                    return
                perf_run = packet.perf if isinstance(packet.perf, dict) else None
                try:
                    fig = self._build_combined_triple_axis_from_state(
                        args=packet.args,
                        fig_size=(11.0, 8.5),
                        mode="export",
                        reuse=False,
                        render_ctx=packet.render_ctx,
                        perf_run=perf_run,
                    )
                except Exception as exc:
                    _handle_preview_failure(
                        "Combined plot could not be rebuilt for preview.", exc
                    )
                    return
                if fig is None:
                    _handle_preview_failure(
                        "Combined plot could not be rebuilt for preview."
                    )
                    return
                if _is_stale_request():
                    try:
                        plt.close(fig)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                    return
                if not self._assert_combined_export_size(fig):
                    try:
                        plt.close(fig)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                    self._hide_combined_plot_preview_loading()
                    return

                current_window = getattr(self, "_combined_plot_preview_window", None)
                current_content = getattr(self, "_combined_plot_preview_content", None)
                if current_window is None or current_content is None:
                    try:
                        plt.close(fig)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                    return

                after_id = getattr(self, "_combined_plot_preview_resize_after_id", None)
                if after_id is not None:
                    try:
                        current_window.after_cancel(after_id)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                self._combined_plot_preview_resize_after_id = None

                old_toolbar = getattr(self, "_combined_plot_preview_toolbar", None)
                if old_toolbar is not None:
                    try:
                        old_toolbar.destroy()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                old_canvas = getattr(self, "_combined_plot_preview_canvas", None)
                if old_canvas is not None:
                    try:
                        old_widget = old_canvas.get_tk_widget()
                    except Exception:
                        old_widget = None
                    if old_widget is not None:
                        try:
                            old_widget.destroy()
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass
                old_fig = getattr(self, "_combined_plot_preview_fig", None)
                if old_fig is not None and old_fig is not fig:
                    try:
                        plt.close(old_fig)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

                self._set_combined_plot_preview_loading_state(
                    progress=82.0,
                    message="Adding Plot Elements...",
                )
                try:
                    self._apply_gl260_legend_sizing(
                        fig,
                        plot_id=preview_plot_id,
                        plot_key="fig_combined",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

                canvas = FigureCanvasTkAgg(fig, master=current_content)
                toolbar = NavigationToolbar2Tk(canvas, current_content)
                toolbar.update()
                toolbar.pack(side="top", fill="x")
                widget = canvas.get_tk_widget()
                widget.pack(fill="both", expand=True)
                self._combined_plot_preview_canvas = canvas
                self._combined_plot_preview_toolbar = toolbar
                self._combined_plot_preview_fig = fig

                def _schedule_preview_finalize(_event: Any = None) -> None:
                    """Schedule debounced preview finalize pass.

                    Purpose:
                        Re-run preview layout finalize after window resizes.
                    Why:
                        Prevents redundant finalize calls during resize bursts.
                    Inputs:
                        _event: Optional Tk configure event payload.
                    Outputs:
                        None.
                    Side Effects:
                        Schedules one deferred preview finalize pass.
                    Exceptions:
                        Best-effort behavior; failures are ignored.
                    """
                    active_after_id = getattr(
                        self, "_combined_plot_preview_resize_after_id", None
                    )
                    if active_after_id is not None:
                        try:
                            current_window.after_cancel(active_after_id)
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass

                    def _apply_finalize() -> None:
                        """Apply one preview finalize pass.

                        Purpose:
                            Finalize preview layout after geometry settles.
                        Why:
                            Keeps preview reveal consistent after resizes.
                        Inputs:
                            None.
                        Outputs:
                            None.
                        Side Effects:
                            Runs deterministic canvas finalize + draw.
                        Exceptions:
                            Best-effort behavior; failures are ignored.
                        """
                        self._combined_plot_preview_resize_after_id = None
                        if _is_stale_request():
                            return
                        self._set_combined_plot_preview_loading_state(
                            progress=92.0,
                            message="Final Layout Adjustments...",
                        )
                        try:
                            self._finalize_matplotlib_canvas_layout(
                                canvas=canvas,
                                fig=fig,
                                tk_widget=widget,
                                keep_export_size=True,
                                trigger_resize_event=False,
                                force_draw=True,
                            )
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass

                    try:
                        self._combined_plot_preview_resize_after_id = current_window.after(
                            120, _apply_finalize
                        )
                    except Exception:
                        _apply_finalize()

                try:
                    widget.bind("<Configure>", _schedule_preview_finalize, add="+")
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                try:
                    current_window.update_idletasks()
                    widget.update_idletasks()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                self._set_combined_plot_preview_loading_state(
                    progress=92.0,
                    message="Final Layout Adjustments...",
                )
                try:
                    self._finalize_matplotlib_canvas_layout(
                        canvas=canvas,
                        fig=fig,
                        tk_widget=widget,
                        keep_export_size=True,
                        trigger_resize_event=False,
                        force_draw=True,
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                self._set_combined_plot_preview_loading_state(
                    progress=100.0,
                    message="Preview Ready.",
                )
                self._hide_combined_plot_preview_loading()

            try:
                self.after_idle(_build_and_install)
            except Exception:
                _build_and_install()

        def _on_err(exc: BaseException) -> None:
            """Handle preview worker failure.

            Purpose:
                Surface async preview preparation errors.
            Why:
                Ensures failure states clear splash and inform users.
            Inputs:
                exc: Worker exception payload.
            Outputs:
                None.
            Side Effects:
                Updates splash state and displays an error dialog.
            Exceptions:
                Best-effort behavior; dialog failures are ignored.
            """
            _handle_preview_failure(
                "Combined plot preview failed during data preparation.",
                exc,
            )

        runner = getattr(self, "_task_runner", None)
        if runner is not None and hasattr(runner, "submit"):
            self._combined_plot_preview_task_id = runner.submit(
                "combined_plot_preview_render",
                _worker,
                _on_ok,
                _on_err,
            )
            return

        def _thread_worker() -> None:
            """Run preview compute fallback on daemon thread.

            Purpose:
                Preserve async preview behavior without TkTaskRunner.
            Why:
                Fallback avoids UI blocking if task runner is unavailable.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                Executes worker in background thread and marshals callbacks to UI.
            Exceptions:
                Worker errors are routed to `_on_err`.
            """
            try:
                packet = _worker()
            except Exception as exc:
                self.after(0, lambda exc=exc: _on_err(exc))
                return
            self.after(0, lambda packet=packet: _on_ok(packet))

        threading.Thread(target=_thread_worker, daemon=True).start()

    def _place_annotations_panel(
        self, frame: ttk.Frame, topbar: ttk.Frame, panel: AnnotationsPanel
    ) -> None:
        """Perform place annotations panel.
        Used to keep the workflow logic localized and testable."""
        def _reposition(_event: Any = None) -> None:
            """Perform reposition.
            Used to keep the workflow logic localized and testable."""
            try:
                frame.update_idletasks()
                topbar.update_idletasks()
                panel.frame.update_idletasks()
                frame_width = frame.winfo_width()
                panel_width = min(520, max(280, frame_width - 16))
                x = max(6, frame_width - panel_width - 6)
                y = topbar.winfo_height() + 6
                panel.frame.place(x=x, y=y, width=panel_width)
                panel.frame.lift()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        try:
            frame.bind("<Configure>", _reposition, add="+")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        _reposition()

    def _render_figures_in_tabs(
        self, figs: dict, *, clear_existing: bool = True, auto_refresh: bool = True
    ):
        """Render figures in tabs.

        Purpose:
            Embed rendered Matplotlib figures into notebook tabs.
        Why:
            Plot previews and exports share a consistent tab-embedding workflow.
        Inputs:
            figs: Mapping of plot keys to Matplotlib figures.
            clear_existing: When True, remove existing plot tabs before adding.
            auto_refresh: When True, schedule the one-time auto-refresh for each tab.
        Outputs:
            None.
        Side Effects:
            Creates/destroys tabs, embeds canvases, and may schedule refreshes.
        Exceptions:
            Errors are caught to avoid interrupting the UI.
        """

        # figs may contain 'fig1', 'fig2', 'fig_peaks'

        perf_run = self._perf_diag_active_run if isinstance(self._perf_diag_active_run, dict) else None
        perf_start = time.perf_counter() if perf_run is not None else None

        if clear_existing:
            self._clear_plot_tabs()

        if not isinstance(figs, dict):

            self._log_plot_tab_debug(
                "render_figures_in_tabs called with non-dict payload."
            )

            return
        # Closure captures _render_figures_in_tabs local context to keep helper logic scoped and invoked directly within _render_figures_in_tabs.
        def _replace_plot(title: str, fig, *, plot_key: str) -> None:
            """Perform replace plot.
            Used to keep the workflow logic localized and testable."""
            if not clear_existing:
                self._remove_plot_tab_by_title(title)
            self._add_plot_tab(
                title, fig, plot_key=plot_key, auto_refresh=auto_refresh
            )

        if figs.get("fig1"):
            _replace_plot(
                "Figure 1: Pressure + Temperature", figs["fig1"], plot_key="fig1"
            )

        if figs.get("fig2"):
            _replace_plot(
                "Figure 2: Pressure + Derivative", figs["fig2"], plot_key="fig2"
            )

        if figs.get("fig_combined"):
            _replace_plot(
                "Figure 1+2: Combined Triple-Axis",
                figs["fig_combined"],
                plot_key="fig_combined",
            )

        if figs.get("fig_peaks"):
            _replace_plot(
                "Figure 3: Cycle Analysis", figs["fig_peaks"], plot_key="fig_peaks"
            )

        if perf_run is not None and perf_start is not None:
            elapsed_ms = (time.perf_counter() - perf_start) * 1000.0
            stages = perf_run.setdefault("stages", {})
            stages["embed"] = {"ms": elapsed_ms}

    def _find_plot_tab_canvas(
        self, plot_key: str
    ) -> Tuple[Optional[ttk.Frame], Optional[FigureCanvasTkAgg]]:
        """Find the plot tab and canvas for a plot key.

        Purpose:
            Locate the active tab/canvas pair tied to a plot key.
        Why:
            Async plot rendering needs a stable target without rebuilding tabs.
        Inputs:
            plot_key: Plot key identifier (e.g., "fig1", "fig_combined").
        Outputs:
            Tuple of (tab frame, canvas) or (None, None) if not found.
        Side Effects:
            None.
        Exceptions:
            Errors are caught to avoid interrupting plot updates.
        """
        try:
            tabs = list(getattr(self, "_plot_tabs", []) or [])
            canvases = list(getattr(self, "_canvases", []) or [])
        except Exception:
            return None, None
        # Iterate over indexed tab/canvas pairs to apply the per-item lookup logic.
        for idx, tab in enumerate(tabs):
            try:
                if getattr(tab, "_plot_key", None) != plot_key:
                    continue
                canvas = canvases[idx] if idx < len(canvases) else None
                return tab, canvas
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                continue
        return None, None

    def _remove_plot_tab_by_title(self, title: str):
        """Remove a plot tab by its notebook title.

        Purpose:
            Remove a specific plot tab and its associated resources.
        Why:
            Targeted plot refreshes need to replace individual tabs without
            clearing the entire plot area.

        Args:
            title: Notebook tab title to remove.

        Returns:
            None.

        Side Effects:
            Captures combined legend anchors when persistence is enabled, destroys canvases, and tears down
            plot controllers tied to the removed tab.

        Exceptions:
            Errors are caught to avoid interrupting tab removal.
        """

        if not hasattr(self, "_plot_tabs"):

            self._plot_tabs, self._canvases = [], []

            return

        # Iterate over indexed elements from list(self._plot_tabs to apply the per-item logic.
        for i, tab in enumerate(list(self._plot_tabs)):

            try:

                if self.nb.tab(tab, "text") == title:
                    plot_id = getattr(tab, "_plot_id", None)
                    plot_key = getattr(tab, "_plot_key", None)
                    if plot_key == "fig_combined" or plot_id == "fig_combined_triple_axis":
                        # Capture combined legend anchors before removing the tab.
                        if self._combined_cycle_legend_capture_enabled():
                            try:
                                canvas = (
                                    self._canvases[i] if i < len(self._canvases) else None
                                )
                                self._capture_combined_legend_anchor_from_fig(
                                    getattr(canvas, "figure", None),
                                    source="refresh",
                                )
                            except Exception:
                                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                                pass
                    if plot_id and plot_id in self._plot_annotation_controllers:
                        try:
                            self._plot_annotation_controllers[plot_id].disconnect()
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass
                        self._plot_annotation_controllers.pop(plot_id, None)
                        self._plot_annotation_panels.pop(plot_id, None)
                        self._plot_dirty_flags.pop(plot_id, None)
                        if getattr(self, "_plot_settings_target_id", None) == plot_id:
                            try:
                                self._close_plot_settings_dialog()
                            except Exception:
                                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                                pass
                        window = self._plot_element_windows.pop(plot_id, None)
                        if window is not None:
                            try:
                                window.destroy()
                            except Exception:
                                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                                pass
                        self._teardown_layout_editor(plot_id, apply_changes=False)

                    self.nb.forget(tab)

                    try:
                        # also drop paired canvas if it exists at same index

                        self._canvases[i].get_tk_widget().destroy()

                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

                    tab.destroy()

                    del self._plot_tabs[i]

                    if i < len(self._canvases):
                        del self._canvases[i]

                    break

            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _update_cycle_fig_tab(self, fig):
        """Update cycle fig tab.
        Used to keep cycle fig tab in sync with current state."""

        self._remove_plot_tab_by_title("Figure 3: Cycle Analysis")

        if fig is None:

            return

        self._add_plot_tab("Figure 3: Cycle Analysis", fig)

    def _open_cycle_analysis_from_button(self):
        """Open cycle analysis from button.
        Used by UI actions to open cycle analysis from button."""

        try:

            self._suspend_cycle_autorun = True

            self._suspend_cycle_fig3_refresh = True

            self._apply_columns(auto_refresh_axes=False)

            self.open_cycle_analysis_tab()

        finally:

            self._suspend_cycle_autorun = False

            self._suspend_cycle_fig3_refresh = False

    def _build_static_cycle_overview_figure(
        self, xv, yv, mask, peaks, troughs, cycles, total_drop
    ):
        """Build a static cycle overview figure for summary/display workflows.

        Purpose:
            Render a non-interactive cycle figure with cycle markers and summary
            legend content.
        Why:
            The application needs a deterministic cycle snapshot for preview,
            tab display, and export workflows.
        Inputs:
            xv/yv: Full x/y numeric arrays.
            mask: Boolean selection mask for visible data range.
            peaks/troughs: Marker index collections.
            cycles: Structured cycle rows produced by cycle detection.
            total_drop: Aggregate pressure drop across valid cycles.
        Outputs:
            Matplotlib Figure object configured for cycle overview output.
        Side Effects:
            Creates and populates a Matplotlib figure with axes/artists.
        Exceptions:
            Best-effort guards preserve rendering continuity on optional failures.
        """

        import matplotlib.pyplot as plt

        from matplotlib.ticker import MultipleLocator, AutoMinorLocator, AutoLocator

        from matplotlib.lines import Line2D

        import matplotlib.patches as mpatches

        import numpy as np

        fig, ax = plt.subplots(figsize=(11, 8.5))
        try:
            ax._gl260_axis_role = "primary"
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        fig.subplots_adjust(left=0.076, right=0.97, bottom=0.079, top=0.914)

        xplot = np.asarray(xv, float)[mask]

        yplot = np.asarray(yv, float)[mask]

        style = get_cycle_trace_style()

        _plot_series(
            ax,
            xplot,
            yplot,
            label="Pressure (PSI)",
            color=style["line_color"],
            zorder=2,
            series_key="y1",
            line_style=style["resolved_linestyle"],
            linewidth=style["line_width"],
        )

        ax.set_xlabel(
            str(
                globals().get("selected_columns", {}).get("x", "Elapsed Time (days)")
            ).replace("_", " "),
            fontsize=label_fontsize,
        )

        ax.set_ylabel("Pressure (PSI)", fontsize=label_fontsize)

        min_cycle_drop_val = self._safe_get_var(self.min_cycle_drop, float)

        title_text = (
            f"Pressure vs Time with Detected Cycles ( ΔP {min_cycle_drop_val:.2f} PSI)"
        )

        # Only show markers that participate in cycles (plus manual additions)

        peaks_in, troughs_in = self._markers_for_display(
            mask, cycles, include_manual=True, cycle_only=True
        )

        cycle_marker_zorder = _compute_top_overlay_zorder(
            ax, min_z=CYCLE_MARKER_MIN_ZORDER, pad=CYCLE_MARKER_ZORDER_PAD
        )
        peak_label_added = False
        # Iterate over peaks_in to apply the per-item logic.
        for idx in peaks_in:
            label = "Peak" if not peak_label_added else ""
            ax.scatter(
                xv[idx],
                yv[idx],
                marker=style["peak_marker"],
                s=style["marker_size"],
                c=style["peak_color"],
                zorder=cycle_marker_zorder,
                label=label,
            )
            peak_label_added = peak_label_added or bool(label)

            ax.annotate(
                f"{yv[idx]:.1f}",
                (xv[idx], yv[idx]),
                textcoords="offset points",
                xytext=(0, 10),
                ha="center",
                fontsize=label_fontsize,
                color=style["peak_color"],
            )

        trough_label_added = False
        # Iterate over troughs_in to apply the per-item logic.
        for idx in troughs_in:
            label = "Trough" if not trough_label_added else ""
            ax.scatter(
                xv[idx],
                yv[idx],
                marker=style["trough_marker"],
                s=style["marker_size"],
                c=style["trough_color"],
                zorder=cycle_marker_zorder,
                label=label,
            )
            trough_label_added = trough_label_added or bool(label)

            ax.annotate(
                f"{yv[idx]:.1f}",
                (xv[idx], yv[idx]),
                textcoords="offset points",
                xytext=(0, -15),
                ha="center",
                fontsize=label_fontsize,
                color=style["trough_color"],
            )

        # Limits + ticks consistent with Plot Settings

        ax.set_xlim(self.min_time.get(), self.max_time.get())

        ax.set_ylim(self.min_y.get(), self.max_y.get())

        if self.auto_time_ticks.get():

            ax.xaxis.set_major_locator(AutoLocator())

            ax.xaxis.set_minor_locator(AutoMinorLocator())

        else:

            ax.xaxis.set_major_locator(MultipleLocator(self.xmaj_tick.get()))

            ax.xaxis.set_minor_locator(MultipleLocator(self.xmin_tick.get()))

        if self.auto_y_ticks.get():

            ax.yaxis.set_major_locator(AutoLocator())

            ax.yaxis.set_minor_locator(AutoMinorLocator())

        else:

            ax.yaxis.set_major_locator(MultipleLocator(self.ymaj_tick.get()))

            ax.yaxis.set_minor_locator(MultipleLocator(self.ymin_tick.get()))

        ax.minorticks_on()

        ax.tick_params(axis="both", which="major", labelsize=tick_labelsize)
        font_family = (settings.get("font_family") or "").strip()
        _enforce_axis_text_style(
            ax,
            font_family=font_family,
            tick_fontsize=tick_labelsize,
            label_fontsize=label_fontsize,
        )

        # Legend extras

        h, l = ax.get_legend_handles_labels()

        h.append(Line2D([], [], color="none"))

        l.append(f"Cycles: {len(cycles)}")

        h.append(mpatches.Patch(color="none"))

        l.append(f"Total  ΔP: {total_drop:.2f} PSI")

        h.append(mpatches.Patch(color="none"))

        l.append(f"Min  ΔP threshold: {min_cycle_drop_val:.2f} PSI")

        legend = ax.legend(h, l, loc="lower right")

        _make_legend_draggable(legend)

        _center_titles_to_axes_union(
            fig,
            [ax],
            title_text,
            self.suptitle_text.get(),
            subplottitle_fontsize,
            suptitle_fontsize,
            font_family,
            float(plt.rcParams.get("axes.titlepad", 6.0)),
            0.0,
            suptitle_y=suptitle_yposition,
        )

        return fig

    def _gather_scatter_settings(self) -> dict:
        """Perform gather scatter settings.
        Used to keep the workflow logic localized and testable."""

        # Closure captures _gather_scatter_settings local context to keep helper logic scoped and invoked directly within _gather_scatter_settings.
        def _float_from(var, default):
            """Perform float from.
            Used to keep the workflow logic localized and testable."""
            try:
                return float(var.get())
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return default

        marker_value = self.scatter_marker.get() or DEFAULT_SCATTER_SETTINGS["marker"]
        if marker_value not in SCATTER_MARKER_CHOICES and len(marker_value) > 1:
            marker_value = DEFAULT_SCATTER_SETTINGS["marker"]

        size_value = max(
            1.0, _float_from(self.scatter_size, DEFAULT_SCATTER_SETTINGS["size"])
        )
        alpha_value = _float_from(self.scatter_alpha, DEFAULT_SCATTER_SETTINGS["alpha"])
        alpha_value = max(0.0, min(alpha_value, 1.0))
        linewidth_value = max(
            0.0,
            _float_from(self.scatter_linewidth, DEFAULT_SCATTER_SETTINGS["linewidth"]),
        )

        return {
            "enabled": bool(self.scatter_enabled.get()),
            "marker": marker_value,
            "size": size_value,
            "color": (self.scatter_color.get() or "").strip(),
            "alpha": alpha_value,
            "edgecolor": (self.scatter_edgecolor.get() or "").strip(),
            "linewidth": linewidth_value,
            "linestyle": "",
        }

    def _sanitize_single_series_config(self, data: Optional[dict]) -> dict:
        """Sanitize a single series config dictionary.

        Purpose:
            Normalize a per-series style payload before it is used or persisted.
        Why:
            Prevents invalid values from leaking into plotting defaults or settings.
        Args:
            data: Per-series settings dict (may be None or malformed).
        Returns:
            A sanitized dict containing only valid series override keys.
        Side Effects:
            None.
        Exceptions:
            None. Invalid inputs return an empty dict.
        """
        result: dict = {}
        if not isinstance(data, dict):
            return result

        if "size" in data:
            try:
                size_val = float(data["size"])
            except (TypeError, ValueError):
                size_val = None
            if size_val is not None and math.isfinite(size_val) and size_val > 0.0:
                result["size"] = size_val

        if "color" in data:
            color_val = data["color"]
            if isinstance(color_val, str):
                color_str = color_val.strip()
                if color_str:
                    result["color"] = color_str

        if "linestyle" in data:
            canonical = _canonicalize_linestyle_name(data.get("linestyle"))
            if canonical:
                result["linestyle"] = canonical

        if "zorder" in data:
            zorder_val = _coerce_float(data.get("zorder"))
            if zorder_val is not None and math.isfinite(zorder_val):
                result["zorder"] = zorder_val
        if "start_x" in data:
            start_x_val = _coerce_float(data.get("start_x"))
            if start_x_val is not None and math.isfinite(start_x_val):
                result["start_x"] = start_x_val

        # Iterate over ("marker", "edgecolor", "alpha", "linewidth") to apply the per-item logic.
        for key in ("marker", "edgecolor", "alpha", "linewidth"):
            if key in data and data[key] not in (None, ""):
                result[key] = data[key]

        return result

    def _sanitize_series_settings_dict(self, data: Optional[dict]) -> dict:
        """Sanitize the full series settings dictionary.

        Purpose:
            Validate and normalize persisted series settings across all keys.
        Why:
            Ensures per-series overrides remain safe and consistent across loads.
        Args:
            data: Mapping of series keys to per-series config dictionaries.
        Returns:
            A sanitized mapping of series keys to validated override dicts.
        Side Effects:
            None.
        Exceptions:
            None. Invalid inputs return an empty dict.
        """
        result: dict = {}
        if isinstance(data, dict):
            ordered_keys: List[str] = []
            seen_keys: set[str] = set()
            # Preserve the canonical ordering for known series keys first.
            for key in SCATTER_SERIES_KEYS:
                if key in data:
                    ordered_keys.append(key)
                    seen_keys.add(key)
            # Include any additional series keys stored in settings.
            for key in data:
                if key not in seen_keys:
                    ordered_keys.append(key)
                    seen_keys.add(key)
            # Iterate over ordered_keys to apply the per-item logic.
            for key in ordered_keys:
                sanitized = self._sanitize_single_series_config(data.get(key))
                if sanitized:
                    result[key] = sanitized
        return result

    def _gather_series_scatter_settings(self) -> dict:
        """Gather the active per-series scatter settings.

        Purpose:
            Build the current series override map used by plot rendering.
        Why:
            Consolidates UI inputs and persisted settings into one source of truth.
        Inputs:
            None.
        Outputs:
            Mapping of series keys to override dictionaries.
        Side Effects:
            None.
        Exceptions:
            Errors are guarded and result in partial or empty output.
        """
        configs: dict = {}
        stored = (
            self._stored_scatter_series
            if isinstance(getattr(self, "_stored_scatter_series", None), dict)
            else {}
        )
        if getattr(self, "scatter_series_vars", None):
            # Iterate over SCATTER_SERIES_KEYS to apply the per-item logic.
            for key in SCATTER_SERIES_KEYS:
                vars_map = self.scatter_series_vars.get(key)
                if not vars_map:
                    continue
                config: dict = {}
                size_raw = (vars_map.get("size").get() or "").strip()
                if size_raw:
                    try:
                        size_val = float(size_raw)
                    except ValueError:
                        size_val = None
                    if (
                        size_val is not None
                        and math.isfinite(size_val)
                        and size_val > 0.0
                    ):
                        config["size"] = size_val
                linewidth_var = vars_map.get("linewidth")
                if linewidth_var is not None:
                    linewidth_raw = (linewidth_var.get() or "").strip()
                    if linewidth_raw:
                        try:
                            linewidth_val = float(linewidth_raw)
                        except ValueError:
                            linewidth_val = None
                        if (
                            linewidth_val is not None
                            and math.isfinite(linewidth_val)
                            and linewidth_val > 0.0
                        ):
                            config["linewidth"] = linewidth_val
                color_raw = (vars_map.get("color").get() or "").strip()
                if color_raw:
                    config["color"] = color_raw
                linestyle_var = vars_map.get("linestyle")
                if linestyle_var is not None:
                    linestyle_value = _canonicalize_linestyle_name(
                        (linestyle_var.get() or "").strip()
                    )
                    if linestyle_value:
                        config["linestyle"] = linestyle_value
                stored_config = stored.get(key)
                if isinstance(stored_config, dict):
                    # Preserve per-series overrides that are not surfaced in the Columns UI.
                    for extra_key in ("marker", "edgecolor", "alpha", "zorder", "start_x"):
                        if extra_key not in config and extra_key in stored_config:
                            config[extra_key] = stored_config[extra_key]
                if config:
                    configs[key] = config
            # Preserve any stored series configs that are not part of the UI key set.
            for key, value in stored.items():
                if key in configs or key in SCATTER_SERIES_KEYS:
                    continue
                if value:
                    configs[key] = dict(value)
        if not configs and getattr(self, "_stored_scatter_series", None):
            # Fall back to stored values if the UI has not been initialized yet.
            configs = {
                key: dict(value)
                # Iterate to apply the per-item logic.
                for key, value in self._stored_scatter_series.items()
                if value
            }
        return configs

    def _sync_scatter_series_vars(
        self, series_configs: Mapping[str, Mapping[str, Any]]
    ) -> None:
        """Sync scatter series Tk variables with stored settings.

        Purpose:
            Keep Columns-tab per-series controls aligned with persisted settings.
        Why:
            The Data Trace Settings dialog updates settings outside the Columns
            tab; syncing avoids stale UI values overriding newer choices.
        Inputs:
            series_configs: Mapping of series key to sanitized style overrides.
        Outputs:
            None.
        Side Effects:
            Updates Tkinter StringVar instances for size, linewidth, color, and
            line style fields when they exist.
        Exceptions:
            Errors are guarded to avoid interrupting the UI workflow.
        """
        vars_map = getattr(self, "scatter_series_vars", None)
        if not isinstance(vars_map, dict):
            return
        configs = series_configs if isinstance(series_configs, dict) else {}
        # Iterate over vars_map to apply the per-item logic.
        for key, field_vars in vars_map.items():
            if not isinstance(field_vars, dict):
                continue
            config = configs.get(key, {})
            size_var = field_vars.get("size")
            if size_var is not None:
                size_val = config.get("size")
                if (
                    isinstance(size_val, (int, float))
                    and math.isfinite(size_val)
                    and size_val > 0.0
                ):
                    size_var.set(f"{float(size_val):g}")
                else:
                    size_var.set("")
            linewidth_var = field_vars.get("linewidth")
            if linewidth_var is not None:
                linewidth_val = config.get("linewidth")
                if (
                    isinstance(linewidth_val, (int, float))
                    and math.isfinite(linewidth_val)
                    and linewidth_val > 0.0
                ):
                    linewidth_var.set(f"{float(linewidth_val):g}")
                else:
                    linewidth_var.set("")
            color_var = field_vars.get("color")
            if color_var is not None:
                color_val = config.get("color")
                color_var.set(color_val if isinstance(color_val, str) else "")
            linestyle_var = field_vars.get("linestyle")
            if linestyle_var is not None:
                linestyle_value = _canonicalize_linestyle_name(config.get("linestyle"))
                if linestyle_value and linestyle_value in LINE_STYLE_CHOICES:
                    linestyle_var.set(linestyle_value)
                else:
                    linestyle_var.set("Default")

    def _update_scatter_globals(self) -> None:
        """Update scatter globals.
        Used to keep scatter globals in sync with current state."""
        globals()["scatter_config"] = self._gather_scatter_settings()
        globals()["scatter_series_configs"] = self._gather_series_scatter_settings()

    def _persist_scatter_settings(self) -> None:
        """Perform persist scatter settings.
        Used to keep the workflow logic localized and testable."""
        scatter = self._gather_scatter_settings()
        settings["scatter_enabled"] = scatter["enabled"]
        settings["scatter_marker"] = scatter["marker"]
        settings["scatter_size"] = scatter["size"]
        settings["scatter_color"] = scatter["color"]
        settings["scatter_alpha"] = scatter["alpha"]
        settings["scatter_edgecolor"] = scatter["edgecolor"]
        settings["scatter_linewidth"] = scatter["linewidth"]
        series_configs = self._gather_series_scatter_settings()
        settings["scatter_series"] = {
            key: dict(value) for key, value in series_configs.items()
        }
        self._stored_scatter_series = {
            key: dict(value) for key, value in series_configs.items()
        }
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _bind_color_preview(
        self, var: tk.StringVar, preview_label: tk.Label, *, default_text: str = "Auto"
    ) -> None:
        """Perform bind color preview.
        Used to keep the workflow logic localized and testable."""
        default_bg = preview_label.cget("background")
        existing_text = preview_label.cget("text")
        default_label_text = existing_text if existing_text else default_text

        def _update_preview(*_):
            """Update preview.
            Used to keep preview in sync with current state."""
            color_value = (var.get() or "").strip()
            if color_value:
                try:
                    preview_label.configure(background=color_value, text="")
                except tk.TclError:
                    preview_label.configure(
                        background=default_bg, text=default_label_text
                    )
            else:
                preview_label.configure(background=default_bg, text=default_label_text)

        var.trace_add("write", _update_preview)
        _update_preview()

    def _open_scatter_preferences(self):
        """Open scatter preferences.
        Used by UI actions to open scatter preferences."""
        if (
            self._scatter_pref_window is not None
            and self._scatter_pref_window.winfo_exists()
        ):
            try:
                self._scatter_pref_window.deiconify()
                self._scatter_pref_window.lift()
                self._scatter_pref_window.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        win = tk.Toplevel(self)
        win.title("Scatter Plot Settings")
        win.transient(self)
        win.resizable(False, False)
        self._scatter_pref_window = win

        vars_dict = {
            "enabled": tk.BooleanVar(value=self.scatter_enabled.get()),
            "marker": tk.StringVar(value=self.scatter_marker.get()),
            "size": tk.DoubleVar(value=self.scatter_size.get()),
            "color": tk.StringVar(value=self.scatter_color.get()),
            "alpha": tk.DoubleVar(value=self.scatter_alpha.get()),
            "edgecolor": tk.StringVar(value=self.scatter_edgecolor.get()),
            "linewidth": tk.DoubleVar(value=self.scatter_linewidth.get()),
        }
        self._scatter_pref_vars = vars_dict

        # Closure captures _open_scatter_preferences local context to keep helper logic scoped and invoked directly within _open_scatter_preferences.
        def _choose_color_for(var: tk.StringVar, title: str) -> None:
            """Perform choose color for.
            Used to keep the workflow logic localized and testable."""
            initial = (var.get() or "").strip()
            initial_color = initial if initial else None
            try:
                _, hex_value = colorchooser.askcolor(
                    color=initial_color,
                    parent=win,
                    title=title,
                )
            except Exception:
                hex_value = None
            if hex_value:
                var.set(str(hex_value).upper())

        # Closure captures _open_scatter_preferences local context to keep helper logic scoped and invoked directly within _open_scatter_preferences.
        def _clear_color(var: tk.StringVar) -> None:
            """Clear color.
            Used to reset color state safely."""
            var.set("")

        container = ttk.Frame(win, padding=12)
        container.grid(row=0, column=0, sticky="nsew")
        container.grid_columnconfigure(1, weight=1)

        enabled_check = ttk.Checkbutton(
            container,
            text="Render Figures 1/2/3 as scatter plots",
            variable=vars_dict["enabled"],
        )
        enabled_check.grid(row=0, column=0, columnspan=2, sticky="w", pady=(0, 8))
        self._attach_tooltip(
            enabled_check,
            "Toggle scatter rendering for Figures 1-3. Disable to keep line plots.",
        )

        ttk.Label(container, text="Marker style").grid(
            row=1, column=0, sticky="w", pady=4
        )
        marker_combo = ttk.Combobox(
            container,
            textvariable=vars_dict["marker"],
            values=SCATTER_MARKER_CHOICES,
            state="readonly",
            width=8,
        )
        marker_combo.grid(row=1, column=1, sticky="ew", pady=4)
        self._attach_tooltip(
            marker_combo,
            "Choose the Matplotlib marker symbol applied to each scatter point.",
        )

        ttk.Label(container, text="Marker size (pts²)").grid(
            row=2, column=0, sticky="w", pady=4
        )
        size_entry = ttk.Entry(container, textvariable=vars_dict["size"], width=10)
        size_entry.grid(row=2, column=1, sticky="ew", pady=4)
        self._attach_tooltip(
            size_entry,
            (
                "Sets the marker area in pt² for scatter plots and adjusts the marker size used "
                "when the series is rendered as a line plot."
            ),
        )

        ttk.Label(container, text="Face color (optional)").grid(
            row=3, column=0, sticky="w", pady=4
        )
        color_frame = ttk.Frame(container)
        color_frame.grid(row=3, column=1, sticky="ew", pady=4)
        color_frame.columnconfigure(1, weight=1)
        color_preview = tk.Label(
            color_frame,
            width=6,
            relief="groove",
            borderwidth=1,
            text="Auto",
        )
        color_preview.grid(row=0, column=0, sticky="w")
        color_entry = ttk.Entry(
            color_frame, textvariable=vars_dict["color"], state="readonly"
        )
        color_entry.grid(row=0, column=1, sticky="ew", padx=(6, 4))
        color_button = ttk.Button(
            color_frame,
            text="Choose...",
            command=partial(
                _choose_color_for,
                vars_dict["color"],
                "Select Scatter Face Color",
            ),
        )
        color_button.grid(row=0, column=2, padx=(0, 4))
        color_clear_btn = ttk.Button(
            color_frame,
            text="Clear",
            command=partial(_clear_color, vars_dict["color"]),
        )
        color_clear_btn.grid(row=0, column=3)
        self._bind_color_preview(vars_dict["color"], color_preview)
        self._attach_tooltip(
            color_preview,
            "Preview of the face color applied to scatter points and line plots (Auto keeps the series default).",
        )
        self._attach_tooltip(
            color_entry,
            "Displays the selected color for scatter and line plots; leave blank to reuse the series color.",
        )
        self._attach_tooltip(
            color_button,
            "Open a palette and mixer to choose a color for both scatter and line plots without typing RGB codes.",
        )
        self._attach_tooltip(
            color_clear_btn,
            "Clear the face color selection so the series reverts to the default line color.",
        )

        ttk.Label(container, text="Alpha (0-1)").grid(
            row=4, column=0, sticky="w", pady=4
        )
        alpha_entry = ttk.Entry(container, textvariable=vars_dict["alpha"], width=10)
        alpha_entry.grid(row=4, column=1, sticky="ew", pady=4)
        self._attach_tooltip(
            alpha_entry,
            "Set transparency (0-1) for both scatter points and line plots.",
        )

        ttk.Label(container, text="Edge color (optional)").grid(
            row=5, column=0, sticky="w", pady=4
        )
        edge_frame = ttk.Frame(container)
        edge_frame.grid(row=5, column=1, sticky="ew", pady=4)
        edge_frame.columnconfigure(1, weight=1)
        edge_preview = tk.Label(
            edge_frame,
            width=6,
            relief="groove",
            borderwidth=1,
            text="Auto",
        )
        edge_preview.grid(row=0, column=0, sticky="w")
        edge_entry = ttk.Entry(
            edge_frame, textvariable=vars_dict["edgecolor"], state="readonly"
        )
        edge_entry.grid(row=0, column=1, sticky="ew", padx=(6, 4))
        edge_button = ttk.Button(
            edge_frame,
            text="Choose...",
            command=partial(
                _choose_color_for,
                vars_dict["edgecolor"],
                "Select Scatter Edge Color",
            ),
        )
        edge_button.grid(row=0, column=2, padx=(0, 4))
        edge_clear_btn = ttk.Button(
            edge_frame,
            text="Clear",
            command=partial(_clear_color, vars_dict["edgecolor"]),
        )
        edge_clear_btn.grid(row=0, column=3)
        self._bind_color_preview(vars_dict["edgecolor"], edge_preview)
        self._attach_tooltip(
            edge_preview,
            "Preview of the scatter marker edge color (Auto keeps series color).",
        )
        self._attach_tooltip(
            edge_entry,
            "Displays the selected marker edge color; leave blank to keep the original series color.",
        )
        self._attach_tooltip(
            edge_button,
            "Open the color chooser to set a marker edge color from a palette or mix your own.",
        )
        self._attach_tooltip(
            edge_clear_btn,
            "Clear the edge color selection to inherit the series color.",
        )

        ttk.Label(container, text="Edge linewidth").grid(
            row=6, column=0, sticky="w", pady=4
        )
        lw_entry = ttk.Entry(container, textvariable=vars_dict["linewidth"], width=10)
        lw_entry.grid(row=6, column=1, sticky="ew", pady=4)
        self._attach_tooltip(
            lw_entry,
            "Controls scatter edge thickness and line width (use 0 to omit marker outlines).",
        )

        hint = ttk.Label(
            container,
            text=(
                "Leave color fields blank to keep the original series colors.\n"
                "Scatter settings do not affect the interactive Cycle Analysis plot."
            ),
            wraplength=340,
            justify="left",
        )
        hint.grid(row=7, column=0, columnspan=2, sticky="w", pady=(8, 12))

        button_frame = ttk.Frame(container)
        button_frame.grid(row=8, column=0, columnspan=2, sticky="ew")
        button_frame.columnconfigure(0, weight=1)
        button_frame.columnconfigure(1, weight=0)
        button_frame.columnconfigure(2, weight=0)

        status_label = ttk.Label(container, text="", foreground="forest green")
        status_label.grid(row=9, column=0, columnspan=2, sticky="w")

        widgets_to_toggle = [
            (marker_combo, "readonly"),
            (size_entry, "normal"),
            (color_entry, "readonly"),
            (color_button, "normal"),
            (color_clear_btn, "normal"),
            (alpha_entry, "normal"),
            (edge_entry, "readonly"),
            (edge_button, "normal"),
            (edge_clear_btn, "normal"),
            (lw_entry, "normal"),
        ]

        # Closure captures _open_scatter_preferences local context to keep helper logic scoped and invoked directly within _open_scatter_preferences.
        def _sync_state(*_):
            """Perform sync state.
            Used to keep the workflow logic localized and testable."""
            enable = vars_dict["enabled"].get()
            # Iterate over widgets_to_toggle to apply the per-item logic.
            for widget, enable_state in widgets_to_toggle:
                try:
                    widget.configure(state=enable_state if enable else "disabled")
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        _sync_state()
        vars_dict["enabled"].trace_add("write", _sync_state)

        # Closure captures _open_scatter_preferences state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_scatter_preferences.
        def _apply():
            """Apply value.
            Used to apply value changes to live state."""
            self._apply_scatter_preferences(vars_dict, status_label)
            _sync_state()

        # Closure captures _open_scatter_preferences state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_scatter_preferences.
        def _close():
            """Close value.
            Used by UI actions to close value safely."""
            try:
                win.destroy()
            finally:
                self._scatter_pref_window = None
                self._scatter_pref_vars = None

        ttk.Button(button_frame, text="Apply", command=_apply).grid(
            row=0, column=1, padx=(0, 8)
        )
        ttk.Button(button_frame, text="Close", command=_close).grid(row=0, column=2)

        win.protocol("WM_DELETE_WINDOW", _close)

    def _open_data_columns_settings_dialog(self):
        """Open data columns settings dialog.
        Used by UI actions to open data columns settings dialog."""
        if (
            self._data_columns_pref_window is not None
            and self._data_columns_pref_window.winfo_exists()
        ):
            try:
                self._data_columns_pref_window.deiconify()
                self._data_columns_pref_window.lift()
                self._data_columns_pref_window.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        win = tk.Toplevel(self)
        win.title("Data & Columns Settings")
        win.transient(self)
        win.resizable(False, False)
        self._data_columns_pref_window = win

        unit_var = tk.StringVar(value=self._elapsed_unit_label())

        container = ttk.Frame(win, padding=12)
        container.grid(row=0, column=0, sticky="nsew")
        container.grid_columnconfigure(1, weight=1)

        ttk.Label(container, text="Elapsed time unit for stitched sheets").grid(
            row=0, column=0, sticky="w", pady=(0, 6)
        )
        unit_combo = ttk.Combobox(
            container,
            textvariable=unit_var,
            values=list(ELAPSED_TIME_UNITS),
            state="readonly",
            width=16,
        )
        unit_combo.grid(row=0, column=1, sticky="ew", padx=(6, 0), pady=(0, 6))
        self._attach_tooltip(
            unit_combo,
            "Controls the elapsed-time axis for stitched multi-sheet data.",
        )

        # Closure captures _open_data_columns_settings_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_data_columns_settings_dialog.
        def _apply_updates(close_after: bool = False) -> None:
            """Apply updates.
            Used to apply updates changes to live state."""
            new_unit = _normalize_elapsed_time_unit(unit_var.get())
            settings["elapsed_time_unit"] = new_unit
            self._elapsed_time_unit = new_unit
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            try:
                self._refresh_columns_ui()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            dt_col = (self.columns or {}).get("dt")
            if (
                self.multi_sheet_enabled
                and self.file_path
                and self.selected_sheets
                and dt_col
                and dt_col != "None"
            ):
                if self._columns_applied:
                    try:
                        self._apply_columns(auto_refresh_axes=True)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                else:
                    try:
                        self._build_stitched_dataframe(self.selected_sheets, dt_col)
                        self._refresh_columns_ui()
                        self._mark_columns_dirty(
                            reason="elapsed time unit changed",
                            allow_during_apply=True,
                        )
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            if close_after:
                _cancel()

        button_frame = ttk.Frame(win, padding=(12, 0, 12, 12))
        button_frame.grid(row=1, column=0, sticky="e")

        ttk.Button(
            button_frame, text="Apply", command=lambda: _apply_updates(False)
        ).grid(row=0, column=0, padx=(0, 6))
        ttk.Button(button_frame, text="OK", command=lambda: _apply_updates(True)).grid(
            row=0, column=1, padx=(0, 6)
        )

        # Closure captures _open_data_columns_settings_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_data_columns_settings_dialog.
        def _cancel():
            """Perform cancel.
            Used to keep the workflow logic localized and testable."""
            try:
                win.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._data_columns_pref_window = None

        ttk.Button(button_frame, text="Cancel", command=_cancel).grid(row=0, column=2)

        # Closure captures _open_data_columns_settings_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_data_columns_settings_dialog.
        def _on_close():
            """Handle close.
            Used as an event callback for close."""
            self._data_columns_pref_window = None
            _cancel()

        win.protocol("WM_DELETE_WINDOW", _on_close)

    def _data_trace_series_label(self, series_key: str) -> str:
        """Return a display label for a data-trace series key.

        Purpose:
            Provide consistent, user-friendly labels in the Data Trace Settings dialog.
        Why:
            Series keys are internal identifiers that are not ideal UI labels.
        Args:
            series_key: Internal series identifier (e.g., "y1", "z2").
        Returns:
            A display-ready label string for the given series key.
        Side Effects:
            None.
        Exceptions:
            Falls back to the raw key when mapping fails.
        """
        label_map = {
            "y1": "Reactor Pressure",
            "y3": "Manifold Pressure",
            "y2": "Derivative (dP/dt)",
            "z": "Internal Temperature",
            "z2": "External Temperature",
        }
        label = label_map.get(series_key)
        if label:
            return label
        series_labels = getattr(self, "_series_label_map", None)
        if isinstance(series_labels, dict) and series_key in series_labels:
            return series_labels.get(series_key, series_key.upper())
        return series_key.upper()

    def _collect_data_trace_series_keys(self) -> List[str]:
        """Collect the series keys shown in the Data Trace Settings dialog.

        Purpose:
            Build a stable list of series rows for the settings dialog.
        Why:
            Ensures key core traces always appear while honoring stored extras.
        Inputs:
            None.
        Outputs:
            Ordered list of series keys to display.
        Side Effects:
            None.
        Exceptions:
            Returns the base key ordering on error.
        """
        base_order = ["y1", "y3", "z", "z2", "y2"]
        keys: List[str] = []
        # Keep the canonical ordering for known keys.
        for key in base_order:
            if key not in keys:
                keys.append(key)
        stored = getattr(self, "_stored_scatter_series", None)
        if isinstance(stored, dict):
            extras = [key for key in stored.keys() if key not in keys]
            # Keep extra keys sorted for deterministic ordering.
            keys.extend(sorted(extras))
        return keys

    def _parse_optional_float_entry(
        self, raw_value: str, *, positive: bool = False
    ) -> Optional[float]:
        """Parse an optional float entry from a dialog field.

        Purpose:
            Convert optional text input into a validated float.
        Why:
            Dialog fields use blank entries to mean "inherit defaults".
        Args:
            raw_value: User-entered text from a Tk entry.
            positive: When True, require the value to be > 0.
        Returns:
            Parsed float if valid; otherwise None.
        Side Effects:
            None.
        Exceptions:
            None. Invalid values return None.
        """
        if raw_value is None:
            return None
        text = str(raw_value).strip()
        if not text:
            return None
        try:
            value = float(text)
        except (TypeError, ValueError):
            return None
        if not math.isfinite(value):
            return None
        if positive and value <= 0.0:
            return None
        return value

    def _resolve_zorder_priority_value(self, label: str) -> Optional[float]:
        """Resolve a priority label into a numeric zorder.

        Purpose:
            Map user-facing priority choices to safe zorder values.
        Why:
            Keeps zorder selection predictable while allowing numeric overrides.
        Args:
            label: Priority label selected in the UI.
        Returns:
            Numeric zorder for valid labels; otherwise None.
        Side Effects:
            None.
        Exceptions:
            None. Invalid labels return None.
        """
        if not isinstance(label, str):
            return None
        choice = label.strip()
        if not choice or choice == "Inherit":
            return None
        return DATA_TRACE_ZORDER_PRIORITY.get(choice)

    def _open_data_trace_settings_dialog(self) -> None:
        """Open the Data Trace Settings dialog.

        Purpose:
            Provide a centralized editor for per-series trace styling overrides.
        Why:
            Users need consistent, profile-persisted styling controls across plots,
            and the dialog must stay compact enough to fit typical app window sizes.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Creates a modal dialog, updates settings on apply, and may refresh plots.
            The trace-row editor region is rendered in a scrollable shell so narrow
            windows remain usable without clipping controls.
        Exceptions:
            Best-effort guards keep the UI resilient to dialog failures.
        """
        existing = getattr(self, "_data_trace_settings_window", None)
        if existing is not None and existing.winfo_exists():
            try:
                existing.deiconify()
                existing.lift()
                existing.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        win = tk.Toplevel(self)
        win.title("Data Trace Settings")
        win.transient(self)
        win.resizable(True, True)
        self._data_trace_settings_window = win

        try:
            self.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        parent_width = int(getattr(self, "winfo_width", lambda: 0)() or 0)
        parent_height = int(getattr(self, "winfo_height", lambda: 0)() or 0)
        if parent_width <= 0:
            parent_width = int(self.winfo_screenwidth() * 0.9)
        if parent_height <= 0:
            parent_height = int(self.winfo_screenheight() * 0.9)
        min_dialog_width = self._scale_length(620)
        min_dialog_height = self._scale_length(360)
        preferred_dialog_width = self._scale_length(1120)
        preferred_dialog_height = self._scale_length(560)
        max_dialog_width = max(min_dialog_width, int(parent_width * 0.95))
        max_dialog_height = max(min_dialog_height, int(parent_height * 0.92))
        dialog_width = max(min_dialog_width, min(preferred_dialog_width, max_dialog_width))
        dialog_height = max(
            min_dialog_height, min(preferred_dialog_height, max_dialog_height)
        )
        try:
            root_x = int(self.winfo_rootx())
            root_y = int(self.winfo_rooty())
            parent_width_px = int(self.winfo_width() or dialog_width)
            parent_height_px = int(self.winfo_height() or dialog_height)
            pos_x = root_x + max((parent_width_px - dialog_width) // 2, 0)
            pos_y = root_y + max((parent_height_px - dialog_height) // 2, 0)
            win.geometry(f"{dialog_width}x{dialog_height}+{pos_x}+{pos_y}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            win.geometry(f"{dialog_width}x{dialog_height}")
        try:
            win.minsize(min_dialog_width, min_dialog_height)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        compact_font_size = max(
            8, int(getattr(self, "_tab_font_size", getattr(self, "_default_font_size", 10)))
        )
        compact_pad_x = self._scale_length(4)
        compact_pad_y = self._scale_length(3)
        compact_control_gap = self._scale_length(3)
        compact_button_height = self._scale_length(26)
        compact_instruction_wrap = max(self._scale_length(360), dialog_width - self._scale_length(84))

        def _dialog_width(ttk_chars: int, ctk_pixels: int) -> int:
            """Resolve per-dialog control widths for ttk/CTk compatibility.

            Purpose:
                Keep Data Trace controls compact without changing global wrappers.
            Why:
                ttk width uses character units while CTk width uses pixels.
            Inputs:
                ttk_chars: Width to use on ttk fallback paths.
                ctk_pixels: Width to use when CTk widgets are active.
            Outputs:
                Integer width value for the active toolkit.
            Side Effects:
                None.
            Exceptions:
                None.
            """
            return int(ctk_pixels) if ctk is not None else int(ttk_chars)

        def _compact_dialog_button(parent: tk.Widget, *, text: str, command) -> tk.Widget:
            """Build a compact button for the Data Trace dialog only.

            Purpose:
                Keep row/action buttons tightly fitted to their text labels.
            Why:
                CTk buttons default to wide fixed widths that over-expand this dialog.
            Inputs:
                parent: Parent container for the button.
                text: Button caption.
                command: Callback invoked on button press.
            Outputs:
                Constructed button widget.
            Side Effects:
                Instantiates a Tk/CTk button with dialog-specific sizing.
            Exceptions:
                Font measurement falls back safely if toolkit metrics are unavailable.
            """
            if ctk is None:
                return _ui_button(parent, text=text, command=command)
            try:
                base_font = tkfont.nametofont("TkDefaultFont")
                family = str(base_font.actual("family"))
                measured_size = int(base_font.actual("size"))
                if measured_size < 0:
                    measured_size = abs(measured_size)
            except Exception:
                family = "Verdana"
                measured_size = 10
            button_size = max(8, min(compact_font_size, measured_size))
            measure_font = tkfont.Font(family=family, size=button_size)
            try:
                text_width = int(measure_font.measure(str(text)))
            except Exception:
                text_width = int(self._scale_length(42))
            button_width = max(self._scale_length(56), text_width + self._scale_length(18))
            return _ui_button(
                parent,
                text=text,
                command=command,
                width=button_width,
                height=compact_button_height,
                font=(family, button_size),
            )

        try:
            win.grab_set()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        win.grid_rowconfigure(0, weight=1)
        win.grid_columnconfigure(0, weight=1)

        container = ttk.Frame(win, padding=12)
        container.grid(row=0, column=0, sticky="nsew")
        container.grid_columnconfigure(0, weight=1)
        container.grid_rowconfigure(2, weight=1)

        ttk.Label(
            container,
            text="Blank fields inherit the default plot styling.",
        ).grid(row=0, column=0, sticky="w", pady=(0, compact_pad_y))
        detail_note_label = ttk.Label(
            container,
            text=(
                "Cycle peak/trough markers are overlays and always render on top. "
                "Priority and Z-Order Override in this dialog affect trace layers only."
            ),
            wraplength=compact_instruction_wrap,
            justify="left",
        )
        detail_note_label.grid(row=1, column=0, sticky="w", pady=(0, compact_pad_y))

        def _sync_dialog_wraplength(_event: Any = None) -> None:
            """Keep instruction text wrapping aligned to current dialog width."""
            try:
                current_width = int(win.winfo_width() or dialog_width)
            except Exception:
                current_width = dialog_width
            detail_note_label.configure(
                wraplength=max(self._scale_length(320), current_width - self._scale_length(84))
            )

        win.bind("<Configure>", _sync_dialog_wraplength, add="+")

        grid_shell = ttk.Frame(container)
        grid_shell.grid(row=2, column=0, sticky="nsew", pady=(0, compact_pad_y))
        grid_shell.grid_rowconfigure(0, weight=1)
        grid_shell.grid_columnconfigure(0, weight=1)

        # Keep dense row content reachable without forcing oversized dialog widths.
        grid_canvas = tk.Canvas(grid_shell, borderwidth=0, highlightthickness=0)
        grid_canvas.grid(row=0, column=0, sticky="nsew")
        grid_vscroll = _ui_scrollbar(
            grid_shell, orient="vertical", command=grid_canvas.yview
        )
        grid_vscroll.grid(row=0, column=1, sticky="ns")
        grid_hscroll = _ui_scrollbar(
            grid_shell, orient="horizontal", command=grid_canvas.xview
        )
        grid_hscroll.grid(row=1, column=0, sticky="ew")
        grid_canvas.configure(
            yscrollcommand=grid_vscroll.set,
            xscrollcommand=grid_hscroll.set,
        )

        grid = ttk.Frame(grid_canvas)
        grid_canvas.create_window((0, 0), window=grid, anchor="nw")

        def _refresh_grid_scrollregion(_event: Any = None) -> None:
            """Refresh the Data Trace grid canvas scrollregion."""
            grid_canvas.configure(scrollregion=grid_canvas.bbox("all"))

        grid.bind("<Configure>", _refresh_grid_scrollregion)

        grid.grid_columnconfigure(0, weight=0)
        grid.grid_columnconfigure(1, weight=0)
        grid.grid_columnconfigure(2, weight=0)
        grid.grid_columnconfigure(3, weight=0)
        grid.grid_columnconfigure(4, weight=0)
        grid.grid_columnconfigure(5, weight=0)
        grid.grid_columnconfigure(6, weight=0)
        grid.grid_columnconfigure(7, weight=0)
        grid.grid_columnconfigure(8, weight=0)
        grid.grid_columnconfigure(9, weight=1)

        headers = [
            ("Trace", 0),
            ("Color", 1),
            ("Marker", 2),
            ("Marker Size (pt^2)", 3),
            ("Line Style", 4),
            ("Line Width (pt)", 5),
            ("Priority", 6),
            ("Z-Order Override", 7),
            ("Start X", 8),
            ("Effective Z", 9),
        ]
        header_widgets: Dict[str, ttk.Label] = {}
        # Iterate over headers to apply the per-item logic.
        for label, column in headers:
            header_widget = ttk.Label(grid, text=label)
            header_widget.grid(
                row=0,
                column=column,
                sticky="w",
                padx=compact_pad_x,
                pady=(0, compact_pad_y),
            )
            header_widgets[label] = header_widget

        priority_tooltip_text = (
            "Maps trace layering to Background=1, Normal=2, Foreground=3, Hero=5. "
            "Cycle peak/trough overlays are not controlled by this setting."
        )
        zorder_override_tooltip_text = (
            "Optional numeric z-order override for traces only. "
            "When provided, it supersedes Priority for that trace row."
        )
        if "Priority" in header_widgets:
            self._attach_tooltip(header_widgets["Priority"], priority_tooltip_text)
        if "Z-Order Override" in header_widgets:
            self._attach_tooltip(
                header_widgets["Z-Order Override"], zorder_override_tooltip_text
            )

        stored = (
            self._stored_scatter_series
            if isinstance(getattr(self, "_stored_scatter_series", None), dict)
            else {}
        )
        series_vars: Dict[str, Dict[str, tk.Variable]] = {}

        # Closure captures dialog state and computes resolved trace zorder shown
        # in the read-only Effective Z column as users edit priority/override.
        def _update_effective_z_display(vars_map: Dict[str, tk.Variable]) -> None:
            """Refresh the Effective Z display for one data trace row.

            Purpose:
                Show the resolved zorder used for trace rendering in this row.
            Why:
                Priority and numeric override interplay can be unclear without a
                live resolved value shown next to the inputs.
            Inputs:
                vars_map: Tk variable mapping for one trace row.
            Outputs:
                None.
            Side Effects:
                Updates the row's read-only Effective Z text variable.
            Exceptions:
                Invalid inputs resolve to an inherit placeholder safely.
            """
            effective_var = vars_map.get("effective_z")
            if not isinstance(effective_var, tk.StringVar):
                return
            zorder_var = vars_map.get("zorder")
            zorder_override = (
                self._parse_optional_float_entry(zorder_var.get())
                if isinstance(zorder_var, tk.StringVar)
                else None
            )
            if zorder_override is not None:
                effective_var.set(f"{float(zorder_override):g} (Override)")
                return
            priority_var = vars_map.get("priority")
            priority_label = (
                (priority_var.get() or "").strip()
                if isinstance(priority_var, tk.StringVar)
                else ""
            )
            priority_value = self._resolve_zorder_priority_value(priority_label)
            if priority_value is not None:
                effective_var.set(f"{float(priority_value):g} ({priority_label})")
                return
            effective_var.set("Inherit")

        def _wire_effective_z_updates(vars_map: Dict[str, tk.Variable]) -> None:
            """Bind live Effective Z refresh handlers for one trace row.

            Purpose:
                Keep Effective Z synchronized with Priority and Override fields.
            Why:
                Users should see immediate resolved layering feedback while editing.
            Inputs:
                vars_map: Tk variable mapping for one trace row.
            Outputs:
                None.
            Side Effects:
                Registers Tk variable trace callbacks.
            Exceptions:
                None.
            """
            priority_var = vars_map.get("priority")
            if isinstance(priority_var, tk.StringVar):
                priority_var.trace_add(
                    "write",
                    lambda *_args, _vars=vars_map: _update_effective_z_display(_vars),
                )
            zorder_var = vars_map.get("zorder")
            if isinstance(zorder_var, tk.StringVar):
                zorder_var.trace_add(
                    "write",
                    lambda *_args, _vars=vars_map: _update_effective_z_display(_vars),
                )

        # Closure captures dialog state for callback wiring, kept nested to scope
        # the handler, and invoked by bindings set in _open_data_trace_settings_dialog.
        def _pick_color(target_var: tk.StringVar, display_label: str) -> None:
            """Select a custom color for a data trace.

            Purpose:
                Open a color picker and assign the result to the target variable.
            Why:
                Provides a consistent color selection workflow for series rows.
            Inputs:
                target_var: Tkinter variable receiving the selected color.
                display_label: Display label used in the picker title.
            Outputs:
                None.
            Side Effects:
                Updates the provided variable with a hex color string.
            Exceptions:
                Errors are caught to avoid interrupting the UI workflow.
            """
            initial = (target_var.get() or "").strip() or None
            try:
                _, hex_value = colorchooser.askcolor(
                    color=initial,
                    parent=win,
                    title=f"Select Trace Color ({display_label})",
                )
            except Exception:
                hex_value = None
            if hex_value:
                target_var.set(str(hex_value).upper())

        for row_offset, series_key in enumerate(
            self._collect_data_trace_series_keys(), start=1
        ):
            config = stored.get(series_key, {})
            display_label = self._data_trace_series_label(series_key)

            color_val = config.get("color")
            color_var = tk.StringVar(
                value=color_val if isinstance(color_val, str) else ""
            )

            marker_value = config.get("marker")
            marker_choices = ["Default"] + list(SCATTER_MARKER_CHOICES)
            if marker_value and marker_value not in marker_choices:
                marker_choices.append(str(marker_value))
            marker_var = tk.StringVar(
                value=str(marker_value) if marker_value else "Default"
            )

            size_val = config.get("size")
            size_var = tk.StringVar(
                value=(
                    f"{float(size_val):g}"
                    if isinstance(size_val, (int, float))
                    and math.isfinite(size_val)
                    and size_val > 0.0
                    else ""
                )
            )

            linestyle_value = _canonicalize_linestyle_name(config.get("linestyle"))
            linestyle_display = (
                linestyle_value
                if linestyle_value and linestyle_value in LINE_STYLE_CHOICES
                else "Default"
            )
            linestyle_var = tk.StringVar(value=linestyle_display)

            linewidth_val = config.get("linewidth")
            linewidth_var = tk.StringVar(
                value=(
                    f"{float(linewidth_val):g}"
                    if isinstance(linewidth_val, (int, float))
                    and math.isfinite(linewidth_val)
                    and linewidth_val > 0.0
                    else ""
                )
            )
            start_x_val = config.get("start_x")
            start_x_var = tk.StringVar(
                value=(
                    f"{float(start_x_val):g}"
                    if isinstance(start_x_val, (int, float))
                    and math.isfinite(start_x_val)
                    else ""
                )
            )

            priority_label = "Inherit"
            zorder_override_value = ""
            zorder_val = config.get("zorder")
            if isinstance(zorder_val, (int, float)) and math.isfinite(zorder_val):
                matched = False
                for label, mapped_value in DATA_TRACE_ZORDER_PRIORITY.items():
                    if math.isclose(float(zorder_val), float(mapped_value)):
                        priority_label = label
                        matched = True
                        break
                if not matched:
                    zorder_override_value = f"{float(zorder_val):g}"
            priority_var = tk.StringVar(value=priority_label)
            zorder_var = tk.StringVar(value=zorder_override_value)
            effective_z_var = tk.StringVar(value="")

            series_vars[series_key] = {
                "color": color_var,
                "marker": marker_var,
                "size": size_var,
                "linestyle": linestyle_var,
                "linewidth": linewidth_var,
                "priority": priority_var,
                "zorder": zorder_var,
                "start_x": start_x_var,
                "effective_z": effective_z_var,
            }

            ttk.Label(grid, text=display_label).grid(
                row=row_offset,
                column=0,
                sticky="w",
                padx=compact_pad_x,
                pady=compact_pad_y,
            )

            color_frame = ttk.Frame(grid)
            color_frame.grid(
                row=row_offset,
                column=1,
                sticky="w",
                padx=compact_pad_x,
                pady=compact_pad_y,
            )
            color_preview = tk.Label(
                color_frame,
                width=4,
                relief="groove",
                borderwidth=1,
                text="Auto",
            )
            color_preview.grid(row=0, column=0, sticky="w", padx=(0, compact_control_gap))
            self._bind_color_preview(color_var, color_preview)
            _compact_dialog_button(
                color_frame,
                text="Pick",
                command=lambda v=color_var, label=display_label: _pick_color(v, label),
            ).grid(row=0, column=1, padx=(0, compact_control_gap))
            _compact_dialog_button(
                color_frame,
                text="Clear",
                command=lambda v=color_var: v.set(""),
            ).grid(row=0, column=2)

            marker_frame = ttk.Frame(grid)
            marker_frame.grid(
                row=row_offset,
                column=2,
                sticky="w",
                padx=compact_pad_x,
                pady=compact_pad_y,
            )
            marker_combo = _ui_combobox(
                marker_frame,
                textvariable=marker_var,
                values=marker_choices,
                state="readonly",
                width=_dialog_width(8, self._scale_length(98)),
            )
            marker_combo.grid(row=0, column=0, sticky="w")
            _compact_dialog_button(
                marker_frame,
                text="Clear",
                command=lambda v=marker_var: v.set("Default"),
            ).grid(row=0, column=1, padx=(compact_control_gap, 0))

            size_frame = ttk.Frame(grid)
            size_frame.grid(
                row=row_offset,
                column=3,
                sticky="w",
                padx=compact_pad_x,
                pady=compact_pad_y,
            )
            _ui_entry(
                size_frame,
                textvariable=size_var,
                width=_dialog_width(8, self._scale_length(86)),
            ).grid(
                row=0, column=0, sticky="w"
            )
            _compact_dialog_button(
                size_frame,
                text="Clear",
                command=lambda v=size_var: v.set(""),
            ).grid(row=0, column=1, padx=(compact_control_gap, 0))

            linestyle_frame = ttk.Frame(grid)
            linestyle_frame.grid(
                row=row_offset,
                column=4,
                sticky="w",
                padx=compact_pad_x,
                pady=compact_pad_y,
            )
            linestyle_combo = _ui_combobox(
                linestyle_frame,
                textvariable=linestyle_var,
                values=LINE_STYLE_CHOICES,
                state="readonly",
                width=_dialog_width(14, self._scale_length(122)),
            )
            linestyle_combo.grid(row=0, column=0, sticky="w")
            _compact_dialog_button(
                linestyle_frame,
                text="Clear",
                command=lambda v=linestyle_var: v.set("Default"),
            ).grid(row=0, column=1, padx=(compact_control_gap, 0))

            linewidth_frame = ttk.Frame(grid)
            linewidth_frame.grid(
                row=row_offset,
                column=5,
                sticky="w",
                padx=compact_pad_x,
                pady=compact_pad_y,
            )
            _ui_entry(
                linewidth_frame,
                textvariable=linewidth_var,
                width=_dialog_width(8, self._scale_length(86)),
            ).grid(
                row=0, column=0, sticky="w"
            )
            _compact_dialog_button(
                linewidth_frame,
                text="Clear",
                command=lambda v=linewidth_var: v.set(""),
            ).grid(row=0, column=1, padx=(compact_control_gap, 0))

            priority_combo = _ui_combobox(
                grid,
                textvariable=priority_var,
                values=DATA_TRACE_ZORDER_CHOICES,
                state="readonly",
                width=_dialog_width(12, self._scale_length(118)),
            )
            priority_combo.grid(
                row=row_offset,
                column=6,
                sticky="w",
                padx=compact_pad_x,
                pady=compact_pad_y,
            )
            self._attach_tooltip(priority_combo, priority_tooltip_text)

            zorder_frame = ttk.Frame(grid)
            zorder_frame.grid(
                row=row_offset,
                column=7,
                sticky="w",
                padx=compact_pad_x,
                pady=compact_pad_y,
            )
            zorder_entry = _ui_entry(
                zorder_frame,
                textvariable=zorder_var,
                width=_dialog_width(10, self._scale_length(96)),
            )
            zorder_entry.grid(row=0, column=0, sticky="w")
            self._attach_tooltip(zorder_entry, zorder_override_tooltip_text)
            _compact_dialog_button(
                zorder_frame,
                text="Clear",
                command=lambda v=zorder_var, p=priority_var: (
                    v.set(""),
                    p.set("Inherit"),
                ),
            ).grid(row=0, column=1, padx=(compact_control_gap, 0))

            _ui_entry(
                grid,
                textvariable=effective_z_var,
                width=_dialog_width(14, self._scale_length(120)),
                state="readonly",
            ).grid(
                row=row_offset,
                column=9,
                sticky="w",
                padx=compact_pad_x,
                pady=compact_pad_y,
            )
            start_x_frame = ttk.Frame(grid)
            start_x_frame.grid(
                row=row_offset,
                column=8,
                sticky="w",
                padx=compact_pad_x,
                pady=compact_pad_y,
            )
            _ui_entry(
                start_x_frame,
                textvariable=start_x_var,
                width=_dialog_width(10, self._scale_length(96)),
            ).grid(
                row=0, column=0, sticky="w"
            )
            _compact_dialog_button(
                start_x_frame,
                text="Clear",
                command=lambda v=start_x_var: v.set(""),
            ).grid(row=0, column=1, padx=(compact_control_gap, 0))
            _wire_effective_z_updates(series_vars[series_key])
            _update_effective_z_display(series_vars[series_key])

        ttk.Separator(container).grid(
            row=3, column=0, sticky="ew", pady=(compact_pad_y, compact_pad_y)
        )

        button_frame = ttk.Frame(container)
        button_frame.grid(row=4, column=0, sticky="e")

        # Closure captures _open_data_trace_settings_dialog state for callback wiring.
        def _apply_updates(close_after: bool = False) -> None:
            """Apply data trace settings to live state.

            Purpose:
                Persist dialog edits and refresh plots with updated trace styles.
            Why:
                Data trace overrides must apply consistently across plot modes.
            Inputs:
                close_after: When True, close the dialog after applying.
            Outputs:
                None.
            Side Effects:
                Updates settings, syncs Columns UI, saves to disk, and refreshes plots.
            Exceptions:
                Errors are caught to avoid interrupting the UI workflow.
            """
            updated: Dict[str, Dict[str, Any]] = {}
            # Iterate over series_vars to apply the per-item logic.
            for series_key, vars_map in series_vars.items():
                if not isinstance(vars_map, dict):
                    continue
                config: Dict[str, Any] = {}
                color_var = vars_map.get("color")
                color_value = (color_var.get() or "").strip() if color_var else ""
                if color_value:
                    config["color"] = color_value
                marker_var = vars_map.get("marker")
                marker_value = (marker_var.get() or "").strip() if marker_var else ""
                if marker_value and marker_value != "Default":
                    if marker_value in SCATTER_MARKER_CHOICES or len(marker_value) > 1:
                        config["marker"] = marker_value
                size_var = vars_map.get("size")
                size_value = (
                    self._parse_optional_float_entry(size_var.get(), positive=True)
                    if size_var
                    else None
                )
                if size_value is not None:
                    config["size"] = size_value
                linestyle_var = vars_map.get("linestyle")
                linestyle_value = _canonicalize_linestyle_name(
                    (linestyle_var.get() or "").strip() if linestyle_var else ""
                )
                if linestyle_value:
                    config["linestyle"] = linestyle_value
                linewidth_var = vars_map.get("linewidth")
                linewidth_value = (
                    self._parse_optional_float_entry(linewidth_var.get(), positive=True)
                    if linewidth_var
                    else None
                )
                if linewidth_value is not None:
                    config["linewidth"] = linewidth_value

                start_x_var = vars_map.get("start_x")
                start_x_value = (
                    self._parse_optional_float_entry(start_x_var.get(), positive=False)
                    if start_x_var
                    else None
                )
                if start_x_value is not None:
                    config["start_x"] = start_x_value

                zorder_var = vars_map.get("zorder")
                zorder_override = (
                    self._parse_optional_float_entry(zorder_var.get())
                    if zorder_var
                    else None
                )
                if zorder_override is not None:
                    config["zorder"] = zorder_override
                else:
                    priority_var = vars_map.get("priority")
                    priority_value = (
                        self._resolve_zorder_priority_value(priority_var.get())
                        if priority_var
                        else None
                    )
                    if priority_value is not None:
                        config["zorder"] = priority_value
                if config:
                    updated[series_key] = config

            sanitized = self._sanitize_series_settings_dict(updated)
            settings["scatter_series"] = {
                key: dict(value) for key, value in sanitized.items()
            }
            self._stored_scatter_series = {
                key: dict(value) for key, value in sanitized.items()
            }
            self._sync_scatter_series_vars(self._stored_scatter_series)
            self._update_scatter_globals()
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            # Refresh any visible plots so style updates are applied immediately.
            for plot_id in (
                "fig_pressure_temp",
                "fig_pressure_derivative",
                "fig_combined_triple_axis",
                "fig_cycle_analysis",
            ):
                self._refresh_plot_for_plot_id(
                    plot_id,
                    reason="Applying Data Trace Settings...",
                    rearm_overlay=True,
                    capture_combined_legend=False,
                )

            if close_after:
                _cancel()

        _compact_dialog_button(
            button_frame, text="Apply", command=lambda: _apply_updates(False)
        ).grid(row=0, column=0, padx=(0, compact_control_gap))
        _compact_dialog_button(
            button_frame, text="OK", command=lambda: _apply_updates(True)
        ).grid(
            row=0,
            column=1,
            padx=(0, compact_control_gap),
        )

        # Closure captures _open_data_trace_settings_dialog state for callback wiring.
        def _cancel() -> None:
            """Cancel and close the data trace settings dialog.

            Purpose:
                Close the dialog without applying further changes.
            Why:
                Users need a safe exit path that leaves settings untouched.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                Destroys the dialog window and clears the window reference.
            Exceptions:
                Errors are caught to avoid interrupting the UI workflow.
            """
            try:
                win.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._data_trace_settings_window = None

        _compact_dialog_button(button_frame, text="Cancel", command=_cancel).grid(
            row=0, column=2
        )

        # Closure captures _open_data_trace_settings_dialog state for callback wiring.
        def _on_close() -> None:
            """Handle dialog close requests.

            Purpose:
                Route window-manager close events through the cancel path.
            Why:
                Ensures references are cleared and the dialog shuts down safely.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                Clears dialog state and destroys the window.
            Exceptions:
                Errors are caught to avoid interrupting the UI workflow.
            """
            self._data_trace_settings_window = None
            _cancel()

        win.protocol("WM_DELETE_WINDOW", _on_close)

    def _apply_scatter_preferences(self, vars_dict, status_label):
        """Apply scatter preferences.
        Used to apply scatter preferences changes to live state."""

        # Closure captures _apply_scatter_preferences local context to keep helper logic scoped and invoked directly within _apply_scatter_preferences.
        def _float_from(var, default):
            """Perform float from.
            Used to keep the workflow logic localized and testable."""
            try:
                return float(var.get())
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return default

        marker_value = vars_dict["marker"].get() or DEFAULT_SCATTER_SETTINGS["marker"]
        if marker_value not in SCATTER_MARKER_CHOICES and len(marker_value) > 1:
            marker_value = DEFAULT_SCATTER_SETTINGS["marker"]

        size_value = max(
            1.0, _float_from(vars_dict["size"], DEFAULT_SCATTER_SETTINGS["size"])
        )
        alpha_value = _float_from(vars_dict["alpha"], DEFAULT_SCATTER_SETTINGS["alpha"])
        alpha_value = max(0.0, min(alpha_value, 1.0))
        linewidth_value = max(
            0.0,
            _float_from(vars_dict["linewidth"], DEFAULT_SCATTER_SETTINGS["linewidth"]),
        )

        self.scatter_enabled.set(bool(vars_dict["enabled"].get()))
        self.scatter_marker.set(marker_value)
        self.scatter_size.set(size_value)
        self.scatter_color.set((vars_dict["color"].get() or "").strip())
        self.scatter_alpha.set(alpha_value)
        self.scatter_edgecolor.set((vars_dict["edgecolor"].get() or "").strip())
        self.scatter_linewidth.set(linewidth_value)

        self._update_scatter_globals()
        self._persist_scatter_settings()

        if status_label is not None and status_label.winfo_exists():
            status_label.configure(text="Scatter settings applied.")
            status_label.after(4000, lambda: status_label.configure(text=""))

    def _on_series_size_change(self, series_key: str) -> None:
        """Handle series size change.
        Used as an event callback for series size change."""
        vars_map = getattr(self, "scatter_series_vars", {}).get(series_key)
        if not vars_map:
            return
        size_var = vars_map.get("size")
        if size_var is None:
            return
        raw_value = (size_var.get() or "").strip()
        if raw_value:
            try:
                size_val = float(raw_value)
            except ValueError:
                size_val = None
            else:
                if not (math.isfinite(size_val) and size_val > 0.0):
                    size_val = None
            if size_val is None:
                size_var.set("")
            else:
                size_var.set(f"{size_val:g}")
        self._update_scatter_globals()
        self._persist_scatter_settings()

    def _on_series_linewidth_change(self, series_key: str) -> None:
        """Handle series linewidth change.
        Used as an event callback for series linewidth change."""
        vars_map = getattr(self, "scatter_series_vars", {}).get(series_key)
        if not vars_map:
            return
        linewidth_var = vars_map.get("linewidth")
        if linewidth_var is None:
            return
        raw_value = (linewidth_var.get() or "").strip()
        trace_active = bool(getattr(self, "_series_linewidth_trace_active", False))
        if not raw_value:
            if not trace_active:
                linewidth_var.set("")
            self._update_scatter_globals()
            self._persist_scatter_settings()
            return
        try:
            linewidth_val = float(raw_value)
        except ValueError:
            if not trace_active:
                linewidth_var.set("")
                self._update_scatter_globals()
                self._persist_scatter_settings()
            return
        if not (math.isfinite(linewidth_val) and linewidth_val > 0.0):
            if not trace_active:
                linewidth_var.set("")
                self._update_scatter_globals()
                self._persist_scatter_settings()
            return
        formatted_value = f"{linewidth_val:g}"
        if not trace_active and formatted_value != raw_value:
            linewidth_var.set(formatted_value)
        self._update_scatter_globals()
        self._persist_scatter_settings()

    def _on_series_linestyle_change(self, series_key: str) -> None:
        """Handle series linestyle change.
        Used as an event callback for series linestyle change."""
        vars_map = getattr(self, "scatter_series_vars", {}).get(series_key)
        if not vars_map:
            return
        linestyle_var = vars_map.get("linestyle")
        if linestyle_var is None:
            return
        value = (linestyle_var.get() or "").strip()
        if value and value not in LINE_STYLE_CHOICES:
            value = "Default"
            linestyle_var.set(value)
        self._update_scatter_globals()
        self._persist_scatter_settings()

    def _choose_series_color(self, series_key: str) -> None:
        """Perform choose series color.
        Used to keep the workflow logic localized and testable."""
        vars_map = getattr(self, "scatter_series_vars", {}).get(series_key)
        if not vars_map:
            return
        color_var = vars_map.get("color")
        if color_var is None:
            return
        display_name = self._series_label_map.get(series_key, series_key.upper())
        initial = (color_var.get() or "").strip() or None
        try:
            _, hex_value = colorchooser.askcolor(
                color=initial,
                parent=self,
                title=f"Select Scatter Color ({display_name})",
            )
        except Exception:
            hex_value = None
        if hex_value:
            color_var.set(str(hex_value).upper())
        self._update_scatter_globals()
        self._persist_scatter_settings()

    def _clear_series_color(self, series_key: str) -> None:
        """Clear series color.
        Used to reset series color state safely."""
        vars_map = getattr(self, "scatter_series_vars", {}).get(series_key)
        if not vars_map:
            return
        color_var = vars_map.get("color")
        if color_var is None:
            return
        color_var.set("")
        self._update_scatter_globals()
        self._persist_scatter_settings()

    def _persist_cycle_trace_settings(self, config: dict) -> None:
        """Perform persist cycle trace settings.
        Used to keep the workflow logic localized and testable."""
        cycle_trace_settings.update(
            {key: config.get(key, cycle_trace_settings.get(key)) for key in config}
        )
        settings["cycle_trace"] = {
            key: cycle_trace_settings[key] for key in DEFAULT_CYCLE_TRACE_SETTINGS
        }
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _collect_cycle_trace_settings(self, vars_map: dict):
        """Collect cycle trace settings.
        Used to gather cycle trace settings into a structured payload."""
        defaults = DEFAULT_CYCLE_TRACE_SETTINGS
        sanitized = {}
        warnings = []

        style_input = vars_map["line_style"].get() if "line_style" in vars_map else ""
        canonical_style = _canonicalize_linestyle_name(style_input)
        if not canonical_style:
            canonical_style = defaults["line_style"]
        sanitized["line_style"] = canonical_style

        color_fields = (
            ("line_color", defaults["line_color"]),
            ("peak_color", defaults["peak_color"]),
            ("trough_color", defaults["trough_color"]),
        )
        # Iterate over color_fields to apply the per-item logic.
        for field_name, default in color_fields:
            raw = (
                vars_map.get(field_name).get() if field_name in vars_map else ""
            ).strip()
            normalized = _normalize_color(raw, default)
            sanitized[field_name] = normalized
            if raw and normalized == default and raw.lower() != default.lower():
                warnings.append(f"{field.replace('_', ' ').title()} reset to default.")

        try:
            line_width = float(vars_map["line_width"].get())
        except Exception as exc:
            raise ValueError("Line width must be a positive number.") from exc
        if not (math.isfinite(line_width) and line_width > 0.0):
            raise ValueError("Line width must be a positive number.")
        sanitized["line_width"] = line_width

        try:
            marker_size = float(vars_map["marker_size"].get())
        except Exception as exc:
            raise ValueError("Marker size must be a positive number.") from exc
        if not (math.isfinite(marker_size) and marker_size > 0.0):
            raise ValueError("Marker size must be a positive number.")
        sanitized["marker_size"] = marker_size

        # Closure captures _collect_cycle_trace_settings local context to keep helper logic scoped and invoked directly within _collect_cycle_trace_settings.
        def _sanitize_marker(field_name: str, default_marker: str) -> str:
            """Sanitize marker.
            Used to strip or normalize marker before use."""
            raw_value = vars_map.get(field_name).get() if field_name in vars_map else ""
            candidate = (raw_value or "").strip()
            if not candidate:
                return default_marker
            if candidate not in SCATTER_MARKER_CHOICES and len(candidate) > 1:
                warnings.append(
                    f"{field_name.replace('_', ' ').title()} reset to default."
                )
                return default_marker
            return candidate

        sanitized["peak_marker"] = _sanitize_marker(
            "peak_marker", defaults["peak_marker"]
        )
        sanitized["trough_marker"] = _sanitize_marker(
            "trough_marker", defaults["trough_marker"]
        )

        return sanitized, warnings

    def _apply_cycle_trace_settings_from_dialog(self, vars_map, status_label):
        """Apply cycle trace settings from dialog.
        Used to apply cycle trace settings from dialog changes to live state."""
        prior_marker_size = cycle_trace_settings.get("marker_size")
        try:
            sanitized, warnings = self._collect_cycle_trace_settings(vars_map)
        except ValueError as exc:
            messagebox.showerror(
                "Cycle Analysis Plot Settings",
                str(exc),
                parent=self._cycle_trace_window,
            )
            return

        self.cycle_line_color.set(sanitized["line_color"])
        self.cycle_line_style.set(sanitized["line_style"])
        self.cycle_line_width.set(sanitized["line_width"])
        self.cycle_peak_color.set(sanitized["peak_color"])
        self.cycle_trough_color.set(sanitized["trough_color"])
        self.cycle_peak_marker.set(sanitized["peak_marker"])
        self.cycle_trough_marker.set(sanitized["trough_marker"])
        self.cycle_marker_size.set(sanitized["marker_size"])

        vars_map["line_color"].set(self.cycle_line_color.get())
        vars_map["line_style"].set(self.cycle_line_style.get())
        vars_map["line_width"].set(f"{sanitized['line_width']:.3f}")
        vars_map["peak_color"].set(self.cycle_peak_color.get())
        vars_map["trough_color"].set(self.cycle_trough_color.get())
        vars_map["peak_marker"].set(self.cycle_peak_marker.get())
        vars_map["trough_marker"].set(self.cycle_trough_marker.get())
        vars_map["marker_size"].set(f"{sanitized['marker_size']:.3f}")

        self._persist_cycle_trace_settings(sanitized)
        marker_size_changed = (
            prior_marker_size != cycle_trace_settings.get("marker_size")
        )
        if marker_size_changed:
            try:
                self._render_cache.cycles.clear()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._combined_plot_state = None
            self._combined_layout_state = None
            self._combined_layout_dirty = True
        try:
            self._schedule_combined_preview_refresh()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if status_label is not None and status_label.winfo_exists():
            message = "Cycle plot settings applied."
            if warnings:
                message += " " + " ".join(warnings)
            status_label.configure(text=message)
            status_label.after(5000, lambda: status_label.configure(text=""))

        if getattr(self, "_cycle_ui_built", False):
            try:
                self._recompute_cycle_analysis(auto_detect=False, preserve_view=True)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _choose_cycle_trace_color(self, var: tk.StringVar, title: str) -> None:
        """Perform choose cycle trace color.
        Used to keep the workflow logic localized and testable."""
        initial = (var.get() or "").strip() or None
        try:
            _, hex_value = colorchooser.askcolor(
                color=initial, parent=self, title=title
            )
        except Exception:
            hex_value = None
        if hex_value:
            var.set(str(hex_value).upper())

    def _clear_cycle_trace_color(self, var: tk.StringVar) -> None:
        """Clear cycle trace color.
        Used to reset cycle trace color state safely."""
        var.set("")

    def _open_saved_output_preferences(self):
        """Open saved output preferences.
        Used by UI actions to open saved output preferences."""
        if (
            self._output_pref_window is not None
            and self._output_pref_window.winfo_exists()
        ):
            try:
                self._output_pref_window.deiconify()
                self._output_pref_window.lift()
                self._output_pref_window.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        window = tk.Toplevel(self)
        window.title("Saved Output Options")
        window.transient(self)
        window.minsize(720, 420)
        window.protocol("WM_DELETE_WINDOW", self._close_saved_output_preferences)
        self._output_pref_window = window

        container = ttk.Frame(window, padding=12)
        container.grid(row=0, column=0, sticky="nsew")
        window.grid_rowconfigure(0, weight=1)
        window.grid_columnconfigure(0, weight=1)
        container.grid_columnconfigure(1, weight=1)
        container.grid_rowconfigure(2, weight=1)

        ttk.Label(container, text="Saved outputs").grid(
            row=0, column=0, sticky="w", pady=(0, 4)
        )

        listbox = tk.Listbox(container, exportselection=False, height=8)
        listbox.grid(row=1, column=0, sticky="nsew", padx=(0, 12))
        container.grid_rowconfigure(1, weight=1)
        # Iterate over self._output_profile_keys to apply the per-item logic.
        for key in self._output_profile_keys:
            label = DEFAULT_OUTPUT_PROFILE_SETTINGS.get(key, {}).get("label", key)
            listbox.insert("end", label)
        listbox.bind("<<ListboxSelect>>", self._on_output_profile_select)
        self._output_profile_listbox = listbox

        detail_frame = ttk.Frame(container)
        detail_frame.grid(row=0, column=1, rowspan=3, sticky="nsew")
        detail_frame.grid_columnconfigure(0, weight=1)
        detail_frame.grid_rowconfigure(2, weight=1)

        title_label = ttk.Label(
            detail_frame,
            textvariable=self._output_profile_title_var,
            font=("TkDefaultFont", 11, "bold"),
        )
        title_label.grid(row=0, column=0, sticky="w")

        dpi_frame = ttk.LabelFrame(
            detail_frame, text="Global Export DPI (applies to every save)"
        )
        dpi_frame.grid(row=1, column=0, sticky="ew", pady=(8, 8))
        dpi_frame.columnconfigure(1, weight=1)
        self._export_dpi_entry_var = tk.StringVar(value=str(self._get_export_dpi()))
        ttk.Label(dpi_frame, text="DPI").grid(row=0, column=0, sticky="w")
        dpi_entry = ttk.Entry(
            dpi_frame, width=10, textvariable=self._export_dpi_entry_var
        )
        dpi_entry.grid(row=0, column=1, sticky="w", padx=(8, 8))
        ttk.Button(
            dpi_frame, text="Apply DPI", command=self._apply_export_dpi_from_form
        ).grid(row=0, column=2, padx=(8, 0))
        ttk.Label(
            dpi_frame,
            text="Higher DPI increases detail (PNG/PDF).",
            foreground="#555555",
        ).grid(row=1, column=0, columnspan=3, sticky="w", pady=(6, 0))

        profile_frame = ttk.LabelFrame(detail_frame, text="Output Size Profile")
        profile_frame.grid(row=2, column=0, sticky="nsew")
        profile_frame.grid_columnconfigure(1, weight=1)

        self._output_profile_form_vars = {
            "mode": tk.StringVar(value="auto"),
            "units": tk.StringVar(value="in"),
            "width": tk.StringVar(value=""),
            "height": tk.StringVar(value=""),
            "aspect_width": tk.StringVar(value=""),
            "aspect_height": tk.StringVar(value=""),
            "limit_dimension": tk.StringVar(value="width"),
            "limit_value": tk.StringVar(value=""),
        }

        mode_frame = ttk.Frame(profile_frame)
        mode_frame.grid(row=0, column=0, columnspan=2, sticky="w", pady=(0, 8))
        ttk.Label(mode_frame, text="Mode:").pack(side="left", padx=(0, 12))
        mode_options = [
            ("Automatic (content sized)", "auto"),
            ("Fixed width + height", "fixed"),
            ("Aspect ratio + max", "aspect"),
        ]
        # Iterate over mode_options to apply the per-item logic.
        for label, value in mode_options:
            ttk.Radiobutton(
                mode_frame,
                text=label,
                value=value,
                variable=self._output_profile_form_vars["mode"],
            ).pack(side="left", padx=(0, 8))

        ttk.Label(profile_frame, text="Units (in or px)").grid(
            row=1, column=0, sticky="w", pady=4
        )
        units_combo = ttk.Combobox(
            profile_frame,
            textvariable=self._output_profile_form_vars["units"],
            values=OUTPUT_PROFILE_UNITS,
            width=6,
            state="readonly",
        )
        units_combo.grid(row=1, column=1, sticky="w", pady=4)

        ttk.Label(profile_frame, text="Width").grid(row=2, column=0, sticky="w", pady=4)
        width_entry = ttk.Entry(
            profile_frame, textvariable=self._output_profile_form_vars["width"]
        )
        width_entry.grid(row=2, column=1, sticky="ew", pady=4)

        ttk.Label(profile_frame, text="Height").grid(
            row=3, column=0, sticky="w", pady=4
        )
        height_entry = ttk.Entry(
            profile_frame, textvariable=self._output_profile_form_vars["height"]
        )
        height_entry.grid(row=3, column=1, sticky="ew", pady=4)

        ttk.Label(profile_frame, text="Aspect ratio (width : height)").grid(
            row=4, column=0, columnspan=2, sticky="w"
        )
        aspect_row = ttk.Frame(profile_frame)
        aspect_row.grid(row=5, column=0, columnspan=2, sticky="ew", pady=4)
        ttk.Label(aspect_row, text="W").pack(side="left")
        aspect_w_entry = ttk.Entry(
            aspect_row,
            width=8,
            textvariable=self._output_profile_form_vars["aspect_width"],
        )
        aspect_w_entry.pack(side="left", padx=(4, 12))
        ttk.Label(aspect_row, text="H").pack(side="left")
        aspect_h_entry = ttk.Entry(
            aspect_row,
            width=8,
            textvariable=self._output_profile_form_vars["aspect_height"],
        )
        aspect_h_entry.pack(side="left", padx=(4, 0))

        ttk.Label(
            profile_frame, text="Aspect mode max dimension (width or height)"
        ).grid(row=6, column=0, columnspan=2, sticky="w", pady=(8, 0))
        limit_row = ttk.Frame(profile_frame)
        limit_row.grid(row=7, column=0, columnspan=2, sticky="ew", pady=4)
        limit_combo = ttk.Combobox(
            limit_row,
            textvariable=self._output_profile_form_vars["limit_dimension"],
            values=OUTPUT_PROFILE_LIMIT_DIMENSIONS,
            width=8,
            state="readonly",
        )
        limit_combo.pack(side="left", padx=(0, 8))
        limit_entry = ttk.Entry(
            limit_row,
            width=12,
            textvariable=self._output_profile_form_vars["limit_value"],
        )
        limit_entry.pack(side="left")

        ttk.Label(
            profile_frame,
            text=(
                "Fixed mode enforces width + height directly. Aspect mode scales "
                "to your ratio while clamping to a max width or height."
            ),
            wraplength=420,
            foreground="#555555",
        ).grid(row=8, column=0, columnspan=2, sticky="w", pady=(8, 4))

        button_row = ttk.Frame(profile_frame)
        button_row.grid(row=9, column=0, columnspan=2, sticky="e", pady=(8, 0))
        ttk.Button(
            button_row, text="Apply Changes", command=self._apply_output_profile_changes
        ).pack(side="left", padx=(0, 8))
        ttk.Button(
            button_row,
            text="Restore Defaults",
            command=self._reset_output_profile_to_defaults,
        ).pack(side="left")

        self._output_profile_entries = {
            "width": width_entry,
            "height": height_entry,
            "aspect_width": aspect_w_entry,
            "aspect_height": aspect_h_entry,
            "limit_value": limit_entry,
            "limit_dimension": limit_combo,
            "units": units_combo,
        }

        selected_key = self._output_profile_selected
        if not selected_key or selected_key not in self._output_profile_keys:
            selected_key = (
                self._output_profile_keys[0] if self._output_profile_keys else None
            )
        if selected_key:
            idx = self._output_profile_keys.index(selected_key)
            listbox.selection_set(idx)
            listbox.see(idx)
            self._output_profile_selected = selected_key
            self._load_output_profile_into_form(selected_key)
        else:
            self._output_profile_title_var.set("Select an output target.")

    def _close_saved_output_preferences(self):
        """Close saved output preferences.
        Used by UI actions to close saved output preferences safely."""
        window = getattr(self, "_output_pref_window", None)
        if window is not None:
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._output_pref_window = None
        self._output_profile_form_vars = {}
        self._output_profile_entries = {}
        self._output_profile_listbox = None
        self._export_dpi_entry_var = None
        self._output_profile_title_var.set("")

    def _profile_storage_dir(self) -> Optional[Path]:
        """Perform profile storage dir.
        Used to keep the workflow logic localized and testable."""
        base_dir = Path(__file__).resolve().parent
        profiles_dir = base_dir / "profiles"
        try:
            profiles_dir.mkdir(parents=True, exist_ok=True)
        except Exception as exc:
            messagebox.showerror(
                "Profiles",
                f"Could not create the profiles folder:\n{exc}",
            )
            return None
        return profiles_dir

    def _sanitize_profile_name(self, name: str) -> str:
        """Sanitize profile name.
        Used to strip or normalize profile name before use."""
        if not isinstance(name, str):
            return ""
        cleaned = name.strip()
        cleaned = re.sub(r"[<>:\"/\\\\|?*]", "_", cleaned)
        cleaned = re.sub(r"\s+", " ", cleaned)
        cleaned = cleaned.strip(" .")
        return cleaned

    def _profile_path(self, name: str) -> Optional[Path]:
        """Perform profile path.
        Used to keep the workflow logic localized and testable."""
        profiles_dir = self._profile_storage_dir()
        if profiles_dir is None:
            return None
        safe_name = self._sanitize_profile_name(name)
        if not safe_name:
            return None
        return profiles_dir / f"{safe_name}.json"

    def _profile_timestamp(self) -> str:
        """Perform profile timestamp.
        Used to keep the workflow logic localized and testable."""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _read_profile_document(self, path: Path) -> Optional[Dict[str, Any]]:
        """Perform read profile document.
        Used to keep the workflow logic localized and testable."""
        try:
            with path.open("r", encoding="utf-8") as handle:
                payload = json.load(handle)
        except Exception as exc:
            messagebox.showerror("Profiles", f"Could not read profile:\n{exc}")
            return None
        if not isinstance(payload, dict):
            messagebox.showerror("Profiles", "Profile data is invalid.")
            return None
        return payload

    def _write_profile_document(
        self, path: Path, payload: Dict[str, Any], *, show_errors: bool = True
    ) -> bool:
        """Perform write profile document.
        Used to keep the workflow logic localized and testable."""
        try:
            with path.open("w", encoding="utf-8") as handle:
                json.dump(payload, handle, indent=2, sort_keys=True)
                handle.write("\n")
        except Exception as exc:
            if show_errors:
                messagebox.showerror("Profiles", f"Could not save profile:\n{exc}")
            return False
        return True

    def _list_profile_names(self) -> List[str]:
        """Perform list profile names.
        Used to keep the workflow logic localized and testable."""
        profiles_dir = self._profile_storage_dir()
        if profiles_dir is None or not profiles_dir.exists():
            return []
        names: List[str] = []
        # Iterate over profiles_dir.glob("*.json") to apply the per-item logic.
        for profile_path in profiles_dir.glob("*.json"):
            stem = profile_path.stem
            if stem in {"index", "_autosave_last_workspace"}:
                continue
            if stem.startswith("_"):
                continue
            names.append(stem)
        names.sort(key=lambda value: value.lower())
        return names

    def _refresh_profile_listbox(self, *, select_name: Optional[str] = None) -> None:
        """Refresh profile listbox.
        Used to sync profile listbox with current settings."""
        listbox = getattr(self, "_profile_manager_listbox", None)
        if listbox is None:
            return
        names = self._list_profile_names()
        listbox.delete(0, tk.END)
        # Iterate over names to apply the per-item logic.
        for name in names:
            listbox.insert(tk.END, name)
        if select_name and select_name in names:
            idx = names.index(select_name)
            listbox.selection_set(idx)
            listbox.see(idx)

    def _selected_profile_name(self) -> Optional[str]:
        """Perform selected profile name.
        Used to keep the workflow logic localized and testable."""
        listbox = getattr(self, "_profile_manager_listbox", None)
        if listbox is None:
            return None
        selection = listbox.curselection()
        if not selection:
            return None
        return listbox.get(selection[0])

    def _open_profile_manager(self) -> None:
        """Open the Profiles Manager dialog.

        Purpose:
            Present the profile list and profile actions in a modal dialog.
        Why:
            Centralizes profile creation, load, and maintenance workflows.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Creates Tk widgets, measures profile-name content width to size the
            initial window geometry, binds callbacks, and captures dialog references.
        Exceptions:
            Best-effort guards keep UI focus and window creation resilient.
        """
        existing = getattr(self, "_profile_manager_window", None)
        if existing is not None and existing.winfo_exists():
            try:
                existing.deiconify()
                existing.lift()
                existing.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        window = tk.Toplevel(self)
        window.title("Process Profiles")
        window.transient(self)
        window.resizable(True, True)
        self._profile_manager_window = window

        profile_names = self._list_profile_names()
        max_profile_name_chars = max(
            [len(str(name)) for name in profile_names] + [len("Profile Name")]
        )
        try:
            measure_font = tkfont.nametofont("TkDefaultFont")
        except Exception:
            measure_font = tkfont.Font(
                family=getattr(self, "_ui_font_family", "Verdana"), size=10
            )
        try:
            longest_profile_name_px = max(
                [int(measure_font.measure(str(name))) for name in profile_names]
                + [int(measure_font.measure("Profile Name"))]
            )
        except Exception:
            longest_profile_name_px = max_profile_name_chars * self._scale_length(8)

        # Closure captures _open_profile_manager state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_profile_manager.
        def _close_window() -> None:
            """Close window.
            Used by UI actions to close window safely."""
            try:
                window.grab_release()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._profile_manager_window = None
            self._profile_manager_listbox = None

        window.protocol("WM_DELETE_WINDOW", _close_window)
        ctk_module = ctk
        if ctk_module is not None:
            container: Any = ctk_module.CTkFrame(window, corner_radius=10)
            container.grid(row=0, column=0, sticky="nsew", padx=12, pady=12)
        else:
            container = ttk.Frame(window, padding=12)
            container.grid(row=0, column=0, sticky="nsew")
        window.grid_rowconfigure(0, weight=1)
        window.grid_columnconfigure(0, weight=1)
        container.grid_rowconfigure(1, weight=1)
        container.grid_columnconfigure(0, weight=1)

        if ctk_module is not None:
            ctk_module.CTkLabel(
                container,
                text="Profiles",
                anchor="w",
                font=(getattr(self, "_ui_font_family", "Verdana"), 14, "bold"),
            ).grid(row=0, column=0, sticky="w")
        else:
            ttk.Label(container, text="Profiles").grid(row=0, column=0, sticky="w")

        list_shell: Any
        if ctk_module is not None:
            list_shell = ctk_module.CTkFrame(container, corner_radius=8)
            list_shell.grid(row=1, column=0, sticky="nsew", pady=(6, 0))
        else:
            list_shell = ttk.Frame(container)
            list_shell.grid(row=1, column=0, sticky="nsew", pady=(6, 0))
        list_shell.grid_rowconfigure(0, weight=1)
        list_shell.grid_columnconfigure(0, weight=1)

        listbox = tk.Listbox(
            list_shell,
            exportselection=False,
            height=10,
            width=max(36, min(96, max_profile_name_chars + 2)),
        )
        listbox.grid(row=0, column=0, sticky="nsew", padx=4, pady=4)

        if ctk_module is not None:
            appearance_mode = ""
            try:
                appearance_mode = str(ctk_module.get_appearance_mode() or "").lower()
            except Exception:
                appearance_mode = ""
            is_dark_mode = (
                appearance_mode == "dark"
                or _normalize_ui_display_mode(settings.get("ui_display_mode"))
                == DISPLAY_MODE_DARK
            )
            if is_dark_mode:
                colors = {
                    "background": "#1F252D",
                    "foreground": "#F1F3F5",
                    "selectbackground": "#2F80ED",
                    "selectforeground": "#FFFFFF",
                    "border": "#4A5568",
                }
            else:
                colors = {
                    "background": "#F6F8FA",
                    "foreground": "#111827",
                    "selectbackground": "#1F6FD1",
                    "selectforeground": "#FFFFFF",
                    "border": "#C7CDD3",
                }
            try:
                listbox.configure(
                    bg=colors["background"],
                    fg=colors["foreground"],
                    selectbackground=colors["selectbackground"],
                    selectforeground=colors["selectforeground"],
                    highlightthickness=1,
                    highlightbackground=colors["border"],
                    highlightcolor=colors["border"],
                    borderwidth=1,
                    relief="flat",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        scroll = _ui_scrollbar(list_shell, orient="vertical", command=listbox.yview)
        scroll.grid(row=0, column=1, sticky="ns", pady=4)
        listbox.configure(yscrollcommand=scroll.set)
        self._profile_manager_listbox = listbox

        button_frame = (
            ctk_module.CTkFrame(container, fg_color="transparent")
            if ctk_module is not None
            else ttk.Frame(container)
        )
        button_frame.grid(row=1, column=2, sticky="n", padx=(12, 0))
        _ui_button(
            button_frame,
            text="New Profile",
            command=self._profile_new_blank,
        ).pack(fill="x", pady=2)
        _ui_button(
            button_frame,
            text="Save Current As...",
            command=self._profile_save_current_as,
        ).pack(fill="x", pady=2)
        _ui_button(
            button_frame,
            text="Load",
            command=self._profile_load_selected,
        ).pack(fill="x", pady=2)
        _ui_button(
            button_frame,
            text="Overwrite",
            command=self._profile_overwrite_selected,
        ).pack(fill="x", pady=2)
        _ui_button(
            button_frame,
            text="Rename",
            command=self._profile_rename_selected,
        ).pack(fill="x", pady=2)
        _ui_button(
            button_frame,
            text="Delete",
            command=self._profile_delete_selected,
        ).pack(fill="x", pady=2)
        if ctk_module is not None:
            ctk_module.CTkFrame(
                button_frame, height=1, corner_radius=0, fg_color=("#C7CDD3", "#4A5568")
            ).pack(fill="x", pady=(6, 6))
        else:
            ttk.Separator(button_frame, orient="horizontal").pack(fill="x", pady=(6, 6))
        _ui_button(
            button_frame,
            text="Export",
            command=self._profile_export_selected,
        ).pack(fill="x", pady=2)
        _ui_button(
            button_frame,
            text="Import",
            command=self._profile_import_profile,
        ).pack(fill="x", pady=2)

        _ui_checkbutton(
            container,
            text="Include dataset file path",
            variable=self._profile_include_path_var,
        ).grid(row=2, column=0, columnspan=3, sticky="w", pady=(8, 0))
        _ui_checkbutton(
            container,
            text="Keep plot settings for New Profile",
            variable=self._profile_keep_plot_settings_var,
        ).grid(row=3, column=0, columnspan=3, sticky="w", pady=(4, 0))

        try:
            self.update_idletasks()
            window.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        min_list_px = self._scale_length(420)
        max_list_px = self._scale_length(980)
        measured_list_px = longest_profile_name_px + self._scale_length(56)
        # Clamp measured name width so long profiles improve visibility while
        # preserving screen-safe geometry on smaller displays.
        list_target_px = max(min_list_px, min(measured_list_px, max_list_px))
        button_col_reqwidth = self._scale_length(180)
        try:
            button_col_reqwidth = max(
                button_col_reqwidth, int(button_frame.winfo_reqwidth())
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        min_dialog_width = self._scale_length(760)
        min_dialog_height = self._scale_length(360)
        preferred_dialog_width = (
            list_target_px + button_col_reqwidth + self._scale_length(72)
        )
        preferred_dialog_height = self._scale_length(420)
        parent_width = int(getattr(self, "winfo_width", lambda: 0)() or 0)
        parent_height = int(getattr(self, "winfo_height", lambda: 0)() or 0)
        if parent_width <= 0:
            parent_width = int(window.winfo_screenwidth() * 0.9)
        if parent_height <= 0:
            parent_height = int(window.winfo_screenheight() * 0.9)
        max_dialog_width = max(min_dialog_width, int(parent_width * 0.95))
        max_dialog_height = max(min_dialog_height, int(parent_height * 0.92))
        dialog_width = max(
            min_dialog_width, min(preferred_dialog_width, max_dialog_width)
        )
        dialog_height = max(
            min_dialog_height, min(preferred_dialog_height, max_dialog_height)
        )
        try:
            root_x = int(self.winfo_rootx())
            root_y = int(self.winfo_rooty())
            parent_width_px = int(self.winfo_width() or dialog_width)
            parent_height_px = int(self.winfo_height() or dialog_height)
            pos_x = root_x + max((parent_width_px - dialog_width) // 2, 0)
            pos_y = root_y + max((parent_height_px - dialog_height) // 2, 0)
            window.geometry(f"{dialog_width}x{dialog_height}+{pos_x}+{pos_y}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            window.geometry(f"{dialog_width}x{dialog_height}")
        try:
            window.minsize(min_dialog_width, min_dialog_height)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        self._refresh_profile_listbox()
        try:
            # Ensure geometry/list population is stable before enabling modal grab.
            window.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            window.grab_set()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            window.lift()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            window.focus_force()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _profile_new_blank(self) -> None:
        """Create a new blank profile from startup-default workspace state.

        Purpose:
            Start a fresh analysis session and persist it as a profile snapshot.
        Why:
            Prevents stale state from leaking when switching to a new dataset,
            while allowing users to optionally keep tuned plot/layout settings.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Clears the workspace, optionally preserves/restores plot and layout
            settings, prompts the user, applies settings, and writes a profile
            document to disk.
        Exceptions:
            Best-effort guards prevent UI interruptions from blocking the workflow.
        """
        parent = getattr(self, "_profile_manager_window", None) or self
        if not messagebox.askyesno(
            "New Profile",
            "Creating a new profile clears the current workspace. Continue?",
            parent=parent,
        ):
            return
        keep_plot_settings = True
        keep_plot_settings_var = getattr(self, "_profile_keep_plot_settings_var", None)
        if keep_plot_settings_var is not None:
            try:
                keep_plot_settings = bool(keep_plot_settings_var.get())
            except Exception:
                keep_plot_settings = True
        preserved_plot_settings: Optional[Dict[str, Any]] = None
        preserved_layout_profiles: Optional[Dict[str, Any]] = None
        if keep_plot_settings:
            preserved_plot_settings = self._collect_profile_plot_settings()
            preserved_layout_profiles = copy.deepcopy(settings.get("layout_profiles", {}))
        self._autosave_last_workspace()
        self._reset_workspace_to_startup_defaults()
        # Restore preserved plot state only after baseline reset completes so
        # plot elements and annotation state still reset as intended.
        if keep_plot_settings:
            if isinstance(preserved_plot_settings, dict):
                self._apply_profile_plot_settings(preserved_plot_settings)
            if isinstance(preserved_layout_profiles, dict):
                self._apply_profile_layout_profiles(preserved_layout_profiles)
        config = self._prompt_new_profile_configuration(parent)
        if not config:
            return
        profile_name = config.get("profile_name")
        if not profile_name:
            return
        path = self._profile_path(profile_name)
        if path is None:
            return
        created_at = config.get("created_at")
        doc = self._build_profile_document(
            include_dataset_path=False,
            created_at=created_at,
        )
        payload = doc.get("payload")
        if isinstance(payload, dict):
            # Flag new profiles as dataset-optional to avoid relink prompts.
            payload["dataset_required"] = False
        if self._write_profile_document(path, doc):
            self._refresh_profile_listbox(select_name=profile_name)

    def _prompt_new_profile_configuration(
        self, parent: tk.Misc
    ) -> dict[str, Any] | None:
        """Prompt for new profile configuration values.

        Purpose:
            Collect job-specific parameters before saving a blank profile.
        Why:
            New profiles should capture gas model and starting material inputs
            alongside the new suptitle metadata.
        Args:
            parent: Parent window used to scope the modal dialog.
        Returns:
            A configuration dict on success, or None if canceled.
        Side Effects:
            Creates a modal dialog, validates inputs, and applies values to state.
        Exceptions:
            Best-effort guards keep dialog flow resilient to UI errors.
        """
        window = tk.Toplevel(parent)
        window.title("New Profile Configuration")
        window.transient(parent)
        window.resizable(False, False)
        window.grab_set()

        result: dict[str, Any] = {"config": None}

        def _format_float(value: Any) -> str:
            """Format a numeric value for entry defaults.

            Purpose:
                Normalize numeric defaults for dialog entry widgets.
            Why:
                Keeps initial field values readable and consistent.
            Args:
                value: Value to format as a string.
            Returns:
                String representation or an empty string on failure.
            Side Effects:
                None.
            Exceptions:
                Returns an empty string when conversion fails.
            """
            try:
                return f"{float(value)}"
            except Exception:
                return ""

        def _parse_float(value: str, label: str) -> Optional[float]:
            """Parse a float input with user-facing validation.

            Purpose:
                Validate numeric fields before applying them to the workspace.
            Why:
                Ensures dialog inputs are numeric before running apply routines.
            Args:
                value: Raw string from the entry widget.
                label: Human-readable label for error messaging.
            Returns:
                Parsed float, or None when validation fails.
            Side Effects:
                Shows a message box on invalid input.
            Exceptions:
                None; invalid values return None.
            """
            try:
                parsed = float(value)
            except Exception:
                messagebox.showerror(
                    "Invalid Input",
                    f"Please enter a valid {label}.",
                    parent=window,
                )
                return None
            if not math.isfinite(parsed):
                messagebox.showerror(
                    "Invalid Input",
                    f"{label} must be a finite number.",
                    parent=window,
                )
                return None
            return parsed

        profile_name_var = tk.StringVar(value="")
        suptitle_var = tk.StringVar(value=str(self.suptitle_text.get() or ""))

        gas_preset_var = tk.StringVar(value=str(self.v_gas.get() or ""))
        volume_var = tk.StringVar(value=_format_float(self.v_volume.get()))
        vdw_a_var = tk.StringVar(value=_format_float(self.v_a.get()))
        vdw_b_var = tk.StringVar(value=_format_float(self.v_b.get()))
        gas_molar_mass_var = tk.StringVar(
            value=_format_float(self.v_gas_molar_mass.get())
        )

        product_preset_var = tk.StringVar(value=str(self.v_product_preset.get() or ""))
        product_molar_mass_var = tk.StringVar(
            value=_format_float(self.v_product_molar_mass.get())
        )
        starting_mass_var = tk.StringVar(
            value=_format_float(self.v_starting_mass.get())
        )
        stoich_var = tk.StringVar(value=_format_float(self.v_starting_stoich.get()))

        ctk_module = ctk
        if ctk_module is not None:
            container: Any = ctk_module.CTkFrame(window, corner_radius=10)
            container.grid(row=0, column=0, sticky="nsew", padx=12, pady=12)
        else:
            container = ttk.Frame(window, padding=12)
            container.grid(row=0, column=0, sticky="nsew")
        window.grid_rowconfigure(0, weight=1)
        window.grid_columnconfigure(0, weight=1)

        def _make_section(parent_widget: Any, title: str) -> Tuple[Any, Any]:
            """Create one profile-configuration section with CTk/ttk compatibility.

            Purpose:
                Build titled section containers for the profile configuration form.
            Why:
                The dialog should mirror CTk styling where available while keeping
                a robust ttk fallback path.
            Args:
                parent_widget: Container widget that owns the section.
                title: Section title text.
            Returns:
                Tuple of `(section_widget, content_frame)` used for layout and child
                control placement.
            Side Effects:
                Creates widgets and applies basic column-weight configuration.
            Exceptions:
                None; callers receive fallback widgets when CTk is unavailable.
            """
            if ctk_module is not None:
                section_widget = ctk_module.CTkFrame(parent_widget, corner_radius=8)
                section_widget.grid_columnconfigure(0, weight=1)
                ctk_module.CTkLabel(
                    section_widget,
                    text=title,
                    anchor="w",
                    font=(getattr(self, "_ui_font_family", "Verdana"), 13, "bold"),
                ).grid(row=0, column=0, sticky="ew", padx=10, pady=(8, 4))
                content_frame: Any = ctk_module.CTkFrame(
                    section_widget, fg_color="transparent"
                )
                content_frame.grid(row=1, column=0, sticky="ew", padx=8, pady=(0, 8))
                content_frame.grid_columnconfigure(1, weight=1)
                return section_widget, content_frame
            section_widget = ttk.Labelframe(parent_widget, text=title)
            section_widget.grid_columnconfigure(1, weight=1)
            return section_widget, section_widget

        def _label(parent_widget: Any, text: str) -> Any:
            """Create one section label with CTk/ttk compatibility.

            Purpose:
                Standardize label construction for the profile configuration form.
            Why:
                The dialog uses mixed toolkit support and should keep one label
                call-site contract during CTk migration.
            Args:
                parent_widget: Widget that owns the label.
                text: Label text content.
            Returns:
                Constructed label widget instance.
            Side Effects:
                Creates one label widget in the dialog layout tree.
            Exceptions:
                None; ttk fallback is used when CTk is unavailable.
            """
            if ctk_module is not None:
                return ctk_module.CTkLabel(parent_widget, text=text, anchor="w")
            return ttk.Label(parent_widget, text=text)

        info_frame, info_body = _make_section(container, "Profile Info")
        info_frame.grid(row=0, column=0, sticky="ew", pady=(0, 8))

        _label(info_body, "Profile name").grid(
            row=0, column=0, sticky="w", padx=6, pady=4
        )
        name_entry = _ui_entry(info_body, textvariable=profile_name_var)
        name_entry.grid(row=0, column=1, sticky="ew", padx=6, pady=4)
        _label(info_body, "Suptitle (Job Information)").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(info_body, textvariable=suptitle_var).grid(
            row=1, column=1, sticky="ew", padx=6, pady=4
        )

        vdw_frame, vdw_body = _make_section(container, "Gas Model (Van der Waals)")
        vdw_frame.grid(row=1, column=0, sticky="ew", pady=(0, 8))

        _label(vdw_body, "Preset").grid(row=0, column=0, sticky="w", padx=6, pady=4)
        gas_combo = _ui_combobox(
            vdw_body,
            textvariable=gas_preset_var,
            state="readonly",
            values=list(GAS_PRESETS.keys()),
        )
        gas_combo.grid(row=0, column=1, sticky="ew", padx=6, pady=4)

        _label(vdw_body, "Vessel Volume (L)").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(vdw_body, textvariable=volume_var).grid(
            row=1, column=1, sticky="ew", padx=6, pady=4
        )
        _label(vdw_body, "VDW a (L^2*atm/mol^2)").grid(
            row=2, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(vdw_body, textvariable=vdw_a_var).grid(
            row=2, column=1, sticky="ew", padx=6, pady=4
        )
        _label(vdw_body, "VDW b (L/mol)").grid(
            row=3, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(vdw_body, textvariable=vdw_b_var).grid(
            row=3, column=1, sticky="ew", padx=6, pady=4
        )
        _label(vdw_body, "Gaseous Reagent Molar Mass (g/mol)").grid(
            row=4, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(vdw_body, textvariable=gas_molar_mass_var).grid(
            row=4, column=1, sticky="ew", padx=6, pady=4
        )

        reagent_frame, reagent_body = _make_section(container, "Starting Material")
        reagent_frame.grid(row=2, column=0, sticky="ew", pady=(0, 8))

        _label(reagent_body, "Preset").grid(row=0, column=0, sticky="w", padx=6, pady=4)
        product_combo = _ui_combobox(
            reagent_body,
            textvariable=product_preset_var,
            state="readonly",
            values=list(PRODUCT_PRESETS.keys()),
        )
        product_combo.grid(row=0, column=1, sticky="ew", padx=6, pady=4)

        _label(reagent_body, "Starting Material Molar Mass (g/mol)").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(reagent_body, textvariable=product_molar_mass_var).grid(
            row=1, column=1, sticky="ew", padx=6, pady=4
        )
        _label(reagent_body, "Starting Material Mass (g)").grid(
            row=2, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(reagent_body, textvariable=starting_mass_var).grid(
            row=2, column=1, sticky="ew", padx=6, pady=4
        )
        _label(reagent_body, "Stoichiometry (mol gas per mol starting)").grid(
            row=3, column=0, sticky="w", padx=6, pady=4
        )
        _ui_entry(reagent_body, textvariable=stoich_var).grid(
            row=3, column=1, sticky="ew", padx=6, pady=4
        )

        buttons = (
            ctk_module.CTkFrame(container, fg_color="transparent")
            if ctk_module is not None
            else ttk.Frame(container)
        )
        buttons.grid(row=3, column=0, sticky="e", pady=(4, 0))

        def _close_window() -> None:
            """Close the configuration dialog safely.

            Purpose:
                Release modal grabs and destroy the dialog window.
            Why:
                Ensures the UI unblocks cleanly after dialog completion.
            Args:
                None.
            Returns:
                None.
            Side Effects:
                Releases grabs and destroys the dialog window.
            Exceptions:
                Best-effort guards suppress Tk errors during cleanup.
            """
            try:
                window.grab_release()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _cancel() -> None:
            """Cancel the dialog and return no configuration.

            Purpose:
                Exit the dialog without applying any changes.
            Why:
                Allows users to abandon profile creation safely.
            Args:
                None.
            Returns:
                None.
            Side Effects:
                Clears the result payload and closes the dialog.
            Exceptions:
                None.
            """
            result["config"] = None
            _close_window()

        def _sync_gas_preset(*_) -> None:
            """Sync VDW fields when the gas preset selection changes.

            Purpose:
                Auto-populate VDW inputs based on the selected gas preset.
            Why:
                Reduces manual entry and keeps preset defaults consistent.
            Args:
                *_: Tk callback args (unused).
            Returns:
                None.
            Side Effects:
                Updates VDW field variables.
            Exceptions:
                Best-effort guards avoid interrupting the dialog flow.
            """
            choice = gas_preset_var.get()
            preset = GAS_PRESETS.get(choice)
            if preset:
                vdw_a_var.set(_format_float(preset.get("a")))
                vdw_b_var.set(_format_float(preset.get("b")))
            override = self._gas_preset_overrides.get(choice) or {}
            molar = override.get("molar_mass")
            if molar is None and preset is not None:
                molar = preset.get("molar_mass")
            try:
                molar_val = float(molar)
            except (TypeError, ValueError):
                molar_val = None
            if molar_val is not None and math.isfinite(molar_val) and molar_val > 0.0:
                gas_molar_mass_var.set(_format_float(molar_val))

        def _sync_product_preset(*_) -> None:
            """Sync starting material fields when the preset changes.

            Purpose:
                Auto-populate starting material molar mass from presets.
            Why:
                Keeps preset values consistent while allowing overrides.
            Args:
                *_: Tk callback args (unused).
            Returns:
                None.
            Side Effects:
                Updates the molar mass field variable.
            Exceptions:
                Best-effort guards avoid interrupting the dialog flow.
            """
            preset_key = product_preset_var.get()
            preset = PRODUCT_PRESETS.get(preset_key)
            if preset:
                product_molar_mass_var.set(_format_float(preset.get("molar_mass")))

        def _confirm() -> None:
            """Validate inputs and apply the configuration to the workspace.

            Purpose:
                Ensure dialog inputs are valid before saving a new profile.
            Why:
                Prevents invalid or incomplete profiles from being persisted.
            Args:
                None.
            Returns:
                None.
            Side Effects:
                Applies validated configuration to live state and closes the dialog.
            Exceptions:
                None.
            """
            raw_name = (profile_name_var.get() or "").strip()
            safe_name = self._sanitize_profile_name(raw_name)
            if not safe_name:
                messagebox.showerror(
                    "New Profile",
                    "Profile name cannot be empty.",
                    parent=window,
                )
                return
            profile_path = self._profile_path(safe_name)
            if profile_path is None:
                return
            created_at = None
            if profile_path.exists():
                if not messagebox.askyesno(
                    "Overwrite Profile?",
                    f"A profile named '{safe_name}' already exists. Overwrite it?",
                    parent=window,
                ):
                    return
                existing = self._read_profile_document(profile_path)
                if isinstance(existing, dict):
                    created_at = existing.get("created_at")

            vessel_volume = _parse_float(volume_var.get(), "vessel volume (L)")
            if vessel_volume is None:
                return
            vdw_a = _parse_float(vdw_a_var.get(), "VDW a")
            if vdw_a is None:
                return
            vdw_b = _parse_float(vdw_b_var.get(), "VDW b")
            if vdw_b is None:
                return
            gas_molar_mass = _parse_float(
                gas_molar_mass_var.get(), "gaseous reagent molar mass (g/mol)"
            )
            if gas_molar_mass is None:
                return
            product_molar_mass = _parse_float(
                product_molar_mass_var.get(),
                "starting material molar mass (g/mol)",
            )
            if product_molar_mass is None:
                return
            starting_mass = _parse_float(
                starting_mass_var.get(), "starting material mass (g)"
            )
            if starting_mass is None:
                return
            stoich_ratio = _parse_float(
                stoich_var.get(),
                "stoichiometry (mol gas per mol starting)",
            )
            if stoich_ratio is None:
                return

            gas_preset = gas_preset_var.get()
            if gas_preset not in GAS_PRESETS:
                gas_preset = next(iter(GAS_PRESETS))
            product_preset = product_preset_var.get()
            if product_preset not in PRODUCT_PRESETS:
                product_preset = next(iter(PRODUCT_PRESETS))

            config = {
                "profile_name": safe_name,
                "created_at": created_at,
                "suptitle_text": (suptitle_var.get() or "").strip(),
                "gas_preset": gas_preset,
                "vessel_volume": vessel_volume,
                "vdw_a": vdw_a,
                "vdw_b": vdw_b,
                "gas_molar_mass": gas_molar_mass,
                "product_preset": product_preset,
                "product_molar_mass": product_molar_mass,
                "starting_mass": starting_mass,
                "stoich_ratio": stoich_ratio,
            }
            if not self._apply_new_profile_configuration(config):
                return
            result["config"] = config
            _close_window()

        gas_preset_var.trace_add("write", _sync_gas_preset)
        product_preset_var.trace_add("write", _sync_product_preset)
        _sync_gas_preset()
        _sync_product_preset()

        _ui_button(buttons, text="Cancel", command=_cancel).pack(side="right")
        _ui_button(buttons, text="Create Profile", command=_confirm).pack(
            side="right", padx=(0, 8)
        )

        window.bind("<Escape>", lambda _event: _cancel())
        window.bind("<Return>", lambda _event: _confirm())
        window.protocol("WM_DELETE_WINDOW", _cancel)
        try:
            name_entry.focus_set()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        window.wait_window()
        return result.get("config")

    def _apply_new_profile_configuration(self, config: dict[str, Any]) -> bool:
        """Apply new profile configuration values to the live workspace.

        Purpose:
            Persist dialog inputs into Tk variables and settings using existing
            validation workflows.
        Why:
            Ensures New Profile values are validated consistently with the rest
            of the application.
        Args:
            config: Dictionary of validated configuration values.
        Returns:
            True if the configuration was applied successfully, otherwise False.
        Side Effects:
            Updates Tk variables, settings, and triggers apply routines.
        Exceptions:
            Best-effort guards prevent validation errors from crashing the UI.
        """
        def _float_matches(expected: float, actual: Any) -> bool:
            """Compare floats with a small tolerance.

            Purpose:
                Validate that applied settings match dialog inputs.
            Why:
                Guards against invalid inputs that failed validation.
            Args:
                expected: Expected float value.
                actual: Actual value read from settings.
            Returns:
                True when values are within tolerance.
            Side Effects:
                None.
            Exceptions:
                Returns False when values cannot be coerced safely.
            """
            try:
                actual_val = float(actual)
            except Exception:
                return False
            if not math.isfinite(actual_val):
                return False
            return abs(float(expected) - actual_val) <= 1e-6

        suptitle_value = str(config.get("suptitle_text") or "")
        self.suptitle_text.set(suptitle_value)
        settings["suptitle_text"] = suptitle_value

        gas_preset = config.get("gas_preset") or self.v_gas.get()
        if gas_preset not in GAS_PRESETS:
            gas_preset = next(iter(GAS_PRESETS))
        self.v_gas.set(gas_preset)
        self.v_volume.set(float(config.get("vessel_volume", 0.0)))
        self.v_a.set(float(config.get("vdw_a", 0.0)))
        self.v_b.set(float(config.get("vdw_b", 0.0)))
        self.v_gas_molar_mass.set(float(config.get("gas_molar_mass", 0.0)))
        self.v_starting_mass.set(float(config.get("starting_mass", 0.0)))
        self._apply_vdw()

        product_preset = config.get("product_preset") or self.v_product_preset.get()
        if product_preset not in PRODUCT_PRESETS:
            product_preset = next(iter(PRODUCT_PRESETS))
        self.v_product_preset.set(product_preset)
        self.v_product_molar_mass.set(float(config.get("product_molar_mass", 0.0)))
        self.v_starting_mass.set(float(config.get("starting_mass", 0.0)))
        self.v_starting_stoich.set(float(config.get("stoich_ratio", 0.0)))
        self._apply_product_settings()

        if settings.get("vdw_gas") != gas_preset:
            messagebox.showerror(
                "New Profile",
                "Gas preset could not be applied. Check your inputs and try again.",
                parent=self,
            )
            return False
        if not _float_matches(config["vessel_volume"], settings.get("vessel_volume")):
            messagebox.showerror(
                "New Profile",
                "Vessel volume could not be applied. Check your inputs and try again.",
                parent=self,
            )
            return False
        if not _float_matches(config["vdw_a"], settings.get("vdw_a")):
            messagebox.showerror(
                "New Profile",
                "VDW a could not be applied. Check your inputs and try again.",
                parent=self,
            )
            return False
        if not _float_matches(config["vdw_b"], settings.get("vdw_b")):
            messagebox.showerror(
                "New Profile",
                "VDW b could not be applied. Check your inputs and try again.",
                parent=self,
            )
            return False
        if not _float_matches(
            config["gas_molar_mass"], settings.get("vdw_gas_molar_mass")
        ):
            messagebox.showerror(
                "New Profile",
                "Gas molar mass could not be applied. Check your inputs and try again.",
                parent=self,
            )
            return False
        if settings.get("starting_material_preset") != product_preset:
            messagebox.showerror(
                "New Profile",
                (
                    "Starting material preset could not be applied. "
                    "Check your inputs and try again."
                ),
                parent=self,
            )
            return False
        if not _float_matches(
            config["product_molar_mass"],
            settings.get("starting_material_mw_g_mol"),
        ):
            messagebox.showerror(
                "New Profile",
                "Starting material molar mass could not be applied.",
                parent=self,
            )
            return False
        if not _float_matches(
            config["starting_mass"], settings.get("starting_material_mass_g")
        ):
            messagebox.showerror(
                "New Profile",
                "Starting material mass could not be applied.",
                parent=self,
            )
            return False
        if not _float_matches(
            config["stoich_ratio"],
            settings.get("stoich_mol_gas_per_mol_starting"),
        ):
            messagebox.showerror(
                "New Profile",
                "Stoichiometry could not be applied. Check your inputs and try again.",
                parent=self,
            )
            return False

        try:
            self._update_auto_title_preview()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return True

    def _build_profile_document(
        self,
        *,
        include_dataset_path: bool,
        created_at: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Build profile document.
        Used to assemble profile document during UI or plot setup."""
        try:
            self._save_settings_dict(self._collect_plot_args())
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        payload = self._serialize_workspace_state(include_dataset_path)
        timestamp = self._profile_timestamp()
        return {
            "profile_version": 1,
            "created_at": created_at or timestamp,
            "updated_at": timestamp,
            "description": "",
            "payload": payload,
        }

    def _profile_save_current_as(self) -> None:
        """Save current as.
        Used by profile workflows to save current as."""
        parent = getattr(self, "_profile_manager_window", None) or self
        name = simpledialog.askstring("Save Profile", "Profile name:", parent=parent)
        if not name:
            return
        safe_name = self._sanitize_profile_name(name)
        if not safe_name:
            messagebox.showerror("Save Profile", "Profile name cannot be empty.")
            return
        path = self._profile_path(safe_name)
        if path is None:
            return
        created_at = None
        if path.exists():
            if not messagebox.askyesno(
                "Overwrite Profile?",
                f"A profile named '{safe_name}' already exists. Overwrite it?",
            ):
                return
            existing = self._read_profile_document(path)
            if isinstance(existing, dict):
                created_at = existing.get("created_at")
        doc = self._build_profile_document(
            include_dataset_path=bool(self._profile_include_path_var.get()),
            created_at=created_at,
        )
        if self._write_profile_document(path, doc):
            self._refresh_profile_listbox(select_name=safe_name)

    def _profile_overwrite_selected(self) -> None:
        """Perform profile overwrite selected.
        Used to keep the workflow logic localized and testable."""
        name = self._selected_profile_name()
        if not name:
            messagebox.showinfo("Profiles", "Select a profile to overwrite.")
            return
        if not messagebox.askyesno(
            "Overwrite Profile?",
            f"Overwrite '{name}' with the current workspace?",
        ):
            return
        path = self._profile_path(name)
        if path is None:
            return
        created_at = None
        if path.exists():
            existing = self._read_profile_document(path)
            if isinstance(existing, dict):
                created_at = existing.get("created_at")
        doc = self._build_profile_document(
            include_dataset_path=bool(self._profile_include_path_var.get()),
            created_at=created_at,
        )
        if self._write_profile_document(path, doc):
            self._refresh_profile_listbox(select_name=name)

    def _profile_rename_selected(self) -> None:
        """Perform profile rename selected.
        Used to keep the workflow logic localized and testable."""
        name = self._selected_profile_name()
        if not name:
            messagebox.showinfo("Profiles", "Select a profile to rename.")
            return
        parent = getattr(self, "_profile_manager_window", None) or self
        new_name = simpledialog.askstring(
            "Rename Profile", "New profile name:", initialvalue=name, parent=parent
        )
        if not new_name:
            return
        safe_name = self._sanitize_profile_name(new_name)
        if not safe_name:
            messagebox.showerror("Rename Profile", "Profile name cannot be empty.")
            return
        if safe_name == name:
            return
        old_path = self._profile_path(name)
        new_path = self._profile_path(safe_name)
        if old_path is None or new_path is None:
            return
        if new_path.exists():
            messagebox.showerror(
                "Rename Profile", f"A profile named '{safe_name}' already exists."
            )
            return
        try:
            old_path.rename(new_path)
        except Exception as exc:
            messagebox.showerror("Rename Profile", f"Rename failed:\n{exc}")
            return
        self._refresh_profile_listbox(select_name=safe_name)

    def _profile_delete_selected(self) -> None:
        """Perform profile delete selected.
        Used to keep the workflow logic localized and testable."""
        name = self._selected_profile_name()
        if not name:
            messagebox.showinfo("Profiles", "Select a profile to delete.")
            return
        if not messagebox.askyesno(
            "Delete Profile?", f"Delete '{name}' permanently?"
        ):
            return
        path = self._profile_path(name)
        if path is None:
            return
        try:
            path.unlink()
        except Exception as exc:
            messagebox.showerror("Profiles", f"Could not delete profile:\n{exc}")
            return
        self._refresh_profile_listbox()

    def _profile_export_selected(self) -> None:
        """Export selected.
        Used by profile workflows to export selected."""
        name = self._selected_profile_name()
        if not name:
            messagebox.showinfo("Profiles", "Select a profile to export.")
            return
        source_path = self._profile_path(name)
        if source_path is None or not source_path.exists():
            messagebox.showerror("Profiles", "Selected profile could not be found.")
            return
        target_path = filedialog.asksaveasfilename(
            title="Export Profile",
            defaultextension=".json",
            filetypes=[("Profile JSON", "*.json"), ("All files", "*.*")],
            initialfile=f"{name}.json",
        )
        if not target_path:
            return
        try:
            shutil.copyfile(source_path, target_path)
        except Exception as exc:
            messagebox.showerror("Profiles", f"Export failed:\n{exc}")
            return
        messagebox.showinfo("Profiles", f"Profile exported to:\n{target_path}")

    def _profile_import_profile(self) -> None:
        """Import profile.
        Used by profile workflows to import profile."""
        source_path = filedialog.askopenfilename(
            title="Import Profile",
            filetypes=[("Profile JSON", "*.json"), ("All files", "*.*")],
        )
        if not source_path:
            return
        try:
            with open(source_path, "r", encoding="utf-8") as handle:
                data = json.load(handle)
        except Exception as exc:
            messagebox.showerror("Profiles", f"Could not read profile:\n{exc}")
            return
        if not isinstance(data, dict):
            messagebox.showerror("Profiles", "Profile data is invalid.")
            return
        if "payload" not in data:
            data = {
                "profile_version": 1,
                "created_at": self._profile_timestamp(),
                "updated_at": self._profile_timestamp(),
                "description": "",
                "payload": data,
            }
        name_guess = self._sanitize_profile_name(Path(source_path).stem)
        if not name_guess:
            name_guess = "Imported Profile"
        parent = getattr(self, "_profile_manager_window", None) or self
        name = simpledialog.askstring(
            "Import Profile",
            "Profile name:",
            initialvalue=name_guess,
            parent=parent,
        )
        if not name:
            return
        safe_name = self._sanitize_profile_name(name)
        if not safe_name:
            messagebox.showerror("Import Profile", "Profile name cannot be empty.")
            return
        path = self._profile_path(safe_name)
        if path is None:
            return
        if path.exists():
            if not messagebox.askyesno(
                "Overwrite Profile?",
                f"A profile named '{safe_name}' already exists. Overwrite it?",
            ):
                return
        data.setdefault("profile_version", 1)
        data.setdefault("created_at", self._profile_timestamp())
        data["updated_at"] = self._profile_timestamp()
        if self._write_profile_document(path, data):
            self._refresh_profile_listbox(select_name=safe_name)

    def _profile_load_selected(self) -> None:
        """Load selected.
        Used by profile workflows to load selected."""
        name = self._selected_profile_name()
        if not name:
            messagebox.showinfo("Profiles", "Select a profile to load.")
            return
        path = self._profile_path(name)
        if path is None or not path.exists():
            messagebox.showerror("Profiles", "Selected profile could not be found.")
            return
        profile_doc = self._read_profile_document(path)
        if not profile_doc:
            return
        if not messagebox.askyesno(
            "Load Profile",
            "Loading a profile replaces the current workspace. Continue?",
        ):
            return
        self._autosave_last_workspace()
        self._restore_workspace_from_profile(profile_doc)

    def _collect_profile_plot_settings(self) -> Dict[str, Any]:
        """Collect profile plot settings.
        Used to gather profile plot settings into a structured payload."""
        keys = {
            "plot_generation_selection",
            "axis_auto_range",
            "axis_pad_pct",
            "min_time",
            "max_time",
            "min_y",
            "max_y",
            "twin_y_min",
            "twin_y_max",
            "deriv_y_min",
            "deriv_y_max",
            "auto_time_ticks",
            "auto_y_ticks",
            "auto_temp_ticks",
            "auto_deriv_ticks",
            "x_major_tick",
            "x_minor_tick",
            "y_major_tick",
            "y_minor_tick",
            "temp_major_tick",
            "temp_minor_tick",
            "deriv_major_tick",
            "deriv_minor_tick",
            "title_text",
            "suptitle_text",
            "enable_temp_axis",
            "enable_deriv_axis",
            "min_cycle_drop",
            "peak_prominence",
            "peak_distance",
            "peak_width",
            "show_cycle_markers_on_core_plots",
            "show_cycle_legend_on_core_plots",
            "include_moles_in_core_plot_legend",
            "scatter_enabled",
            "scatter_marker",
            "scatter_size",
            "scatter_color",
            "scatter_alpha",
            "scatter_edgecolor",
            "scatter_linewidth",
            "scatter_series",
            "cycle_trace",
            "core_legend_fontsize",
            "core_cycle_legend_fontsize",
            "core_plot_render_profiles",
            "combined_y_left_key",
            "combined_y_right_key",
            "combined_y_third_key",
            "combined_center_plot_legend",
        }
        snapshot: Dict[str, Any] = {}
        # Iterate over keys to apply the per-item logic.
        for key in keys:
            if key in settings:
                snapshot[key] = copy.deepcopy(settings.get(key))
        # Iterate over items from settings to apply the per-item logic.
        for key, value in settings.items():
            if key.startswith("combined_"):
                snapshot[key] = copy.deepcopy(value)
        return snapshot

    def _capture_startup_profile_plot_settings(self) -> dict[str, Any]:
        """Capture startup plot settings for new profile resets.

        Purpose:
            Snapshot plot/cycle settings in their startup-default state.
        Why:
            New Profile must reset to a clean baseline that mirrors a fresh launch.
        Args:
            None.
        Returns:
            A plot settings payload compatible with profile save/load routines.
        Side Effects:
            None.
        Exceptions:
            Best-effort guards fall back to safe defaults on lookup failures.
        """
        payload: dict[str, Any] = {}

        payload["plot_generation_selection"] = {
            "fig1": bool(
                self._default_value_from_var(
                    getattr(self, "_plot_select_fig1_var", None), False
                )
            ),
            "fig2": bool(
                self._default_value_from_var(
                    getattr(self, "_plot_select_fig2_var", None), False
                )
            ),
            "fig_combined": bool(
                self._default_value_from_var(
                    getattr(self, "_plot_select_combined_var", None), True
                )
            ),
        }

        payload["axis_auto_range"] = {
            "time": bool(self._default_value_from_var(self.axis_auto_time, True)),
            "pressure": bool(
                self._default_value_from_var(self.axis_auto_pressure, True)
            ),
            "temperature": bool(
                self._default_value_from_var(self.axis_auto_temp, True)
            ),
            "derivative": bool(
                self._default_value_from_var(self.axis_auto_deriv, True)
            ),
        }

        key_map = (
            ("axis_pad_pct", "axis_pad_pct"),
            ("min_time", "min_time"),
            ("max_time", "max_time"),
            ("min_y", "min_y"),
            ("max_y", "max_y"),
            ("twin_y_min", "twin_y_min"),
            ("twin_y_max", "twin_y_max"),
            ("deriv_y_min", "deriv_y_min"),
            ("deriv_y_max", "deriv_y_max"),
            ("auto_time_ticks", "auto_time_ticks"),
            ("auto_y_ticks", "auto_y_ticks"),
            ("auto_temp_ticks", "auto_temp_ticks"),
            ("auto_deriv_ticks", "auto_deriv_ticks"),
            ("x_major_tick", "xmaj_tick"),
            ("x_minor_tick", "xmin_tick"),
            ("y_major_tick", "ymaj_tick"),
            ("y_minor_tick", "ymin_tick"),
            ("temp_major_tick", "temp_maj_tick"),
            ("temp_minor_tick", "temp_min_tick"),
            ("deriv_major_tick", "deriv_maj_tick"),
            ("deriv_minor_tick", "deriv_min_tick"),
            ("title_text", "title_text"),
            ("suptitle_text", "suptitle_text"),
            ("enable_temp_axis", "enable_temp_axis"),
            ("enable_deriv_axis", "enable_deriv_axis"),
            ("min_cycle_drop", "min_cycle_drop"),
            ("peak_prominence", "pk_prominence"),
            ("peak_distance", "pk_distance"),
            ("peak_width", "pk_width"),
            ("show_cycle_markers_on_core_plots", "show_cycle_markers_on_core"),
            ("show_cycle_legend_on_core_plots", "show_cycle_legend_on_core"),
            ("include_moles_in_core_plot_legend", "include_moles_core_legend"),
            ("scatter_enabled", "scatter_enabled"),
            ("scatter_marker", "scatter_marker"),
            ("scatter_size", "scatter_size"),
            ("scatter_color", "scatter_color"),
            ("scatter_alpha", "scatter_alpha"),
            ("scatter_edgecolor", "scatter_edgecolor"),
            ("scatter_linewidth", "scatter_linewidth"),
            ("core_legend_fontsize", "core_legend_fontsize"),
            ("core_cycle_legend_fontsize", "core_cycle_legend_fontsize"),
            ("combined_y_left_key", "combined_y_left_key"),
            ("combined_y_right_key", "combined_y_right_key"),
            ("combined_y_third_key", "combined_y_third_key"),
            ("combined_center_plot_legend", "center_combined_plot_legend"),
        )
        # Iterate over the key map to ensure every profile-scoped setting is included.
        for key, attr in key_map:
            payload[key] = self._default_value_from_var(getattr(self, attr, None))

        stored_series = getattr(self, "_stored_scatter_series", None)
        payload["scatter_series"] = (
            copy.deepcopy(stored_series) if isinstance(stored_series, dict) else {}
        )

        payload["cycle_trace"] = (
            copy.deepcopy(cycle_trace_settings)
            if isinstance(cycle_trace_settings, dict)
            else {}
        )
        payload["core_plot_render_profiles"] = copy.deepcopy(
            _get_core_plot_render_profiles()
        )

        combined_defaults = {
            key: copy.deepcopy(value)
            # Iterate to apply the per-item logic.
            for key, value in settings.items()
            if key.startswith("combined_")
        }
        # Ensure optional combined-legend persistence keys are explicitly cleared.
        for key in (
            "combined_legend_anchor",
            "combined_legend_loc",
            "combined_cycle_legend_anchor",
            "combined_cycle_legend_loc",
            "combined_cycle_legend_anchor_space",
            "combined_cycle_legend_anchor_mode",
            "combined_cycle_legend_ref_dx_px",
            "combined_cycle_legend_ref_dy_px",
            "combined_cycle_legend_markerscale",
        ):
            combined_defaults.setdefault(key, copy.deepcopy(settings.get(key)))
        payload.update(combined_defaults)

        return payload

    def _default_profile_plot_settings_payload(self) -> dict[str, Any]:
        """Return the startup-default plot settings payload for a new profile.

        Purpose:
            Provide a deterministic baseline plot settings payload for resets.
        Why:
            New Profile must discard the current session state and restore
            startup defaults.
        Args:
            None.
        Returns:
            A deep-copied plot settings payload for profile application.
        Side Effects:
            None.
        Exceptions:
            Falls back to a fresh snapshot if the startup payload is unavailable.
        """
        startup_payload = getattr(self, "_startup_profile_plot_settings", None)
        if isinstance(startup_payload, dict):
            return copy.deepcopy(startup_payload)
        return copy.deepcopy(self._capture_startup_profile_plot_settings())

    def _serialize_workspace_state(self, include_dataset_path: bool) -> Dict[str, Any]:
        """Perform serialize workspace state.
        Used to keep the workflow logic localized and testable."""
        payload: Dict[str, Any] = {
            "multi_sheet_enabled": bool(self.multi_sheet_enabled),
            "selected_sheet": self.selected_sheet.get(),
            "selected_sheets": list(self.selected_sheets),
            "column_assignments": (
                dict(self.columns) if isinstance(self.columns, dict) else {}
            ),
            "per_sheet_mapping": self._get_per_sheet_column_map(),
            "plot_elements": copy.deepcopy(settings.get("plot_elements", {})),
            "plot_settings": self._collect_profile_plot_settings(),
            "layout_profiles": copy.deepcopy(settings.get("layout_profiles", {})),
            "final_report_settings": self._collect_final_report_state_from_ui(),
        }
        if include_dataset_path and self.file_path:
            payload["dataset_path"] = self.file_path
        return payload

    def _deserialize_workspace_state(
        self, payload: dict[str, Any]
    ) -> dict[str, Any]:
        """Deserialize a profile payload into normalized workspace state.

        Purpose:
            Normalize profile payloads into a predictable workspace state dict.
        Why:
            Ensures profile load paths can reliably reset the UI and data model.
        Args:
            payload: Profile payload dictionary to parse.
        Returns:
            A normalized state dict used by profile restore logic.
        Side Effects:
            None.
        Exceptions:
            Returns an empty dict for invalid payloads instead of raising.
        """
        if not isinstance(payload, dict):
            return {}
        dataset_required = payload.get("dataset_required")
        if dataset_required is None:
            dataset_required = True
        state: dict[str, Any] = {
            "dataset_path": payload.get("dataset_path"),
            "dataset_required": bool(dataset_required),
            "multi_sheet_enabled": bool(payload.get("multi_sheet_enabled", False)),
            "selected_sheet": str(payload.get("selected_sheet") or ""),
            "selected_sheets": [
                str(name) for name in (payload.get("selected_sheets") or []) if name
            ],
            "column_assignments": dict(payload.get("column_assignments") or {}),
            "per_sheet_mapping": dict(payload.get("per_sheet_mapping") or {}),
            "plot_elements": dict(payload.get("plot_elements") or {}),
            "plot_settings": dict(payload.get("plot_settings") or {}),
            "layout_profiles": dict(payload.get("layout_profiles") or {}),
            "final_report_settings": dict(payload.get("final_report_settings") or {}),
        }
        return state

    def _apply_profile_plot_settings(self, plot_settings: Dict[str, Any]) -> None:
        """Apply profile plot settings.
        Used to apply profile plot settings changes to live state."""
        if not isinstance(plot_settings, dict):
            return

        # Iterate over items from plot_settings to apply the per-item logic.
        for key, value in plot_settings.items():
            settings[key] = copy.deepcopy(value)
        settings["core_plot_render_profiles"] = _normalize_core_plot_render_profiles(
            plot_settings.get("core_plot_render_profiles"),
            seed_source=settings,
        )
        _legacy_core_profile = settings["core_plot_render_profiles"].get(
            CORE_RENDER_PROFILE_PLOT_IDS[0]
        )
        _write_legacy_core_legend_settings_from_profile(_legacy_core_profile)

        # Closure captures _apply_profile_plot_settings local context to keep helper logic scoped and invoked directly within _apply_profile_plot_settings.
        def _set_var(var: Optional[tk.Variable], value: Any) -> None:
            """Set var.
            Used to persist var into the current state."""
            if var is None:
                return
            try:
                var.set(value)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Iterate to apply the per-item logic.
        for key, attr in (
            ("min_time", "min_time"),
            ("max_time", "max_time"),
            ("min_y", "min_y"),
            ("max_y", "max_y"),
            ("twin_y_min", "twin_y_min"),
            ("twin_y_max", "twin_y_max"),
            ("deriv_y_min", "deriv_y_min"),
            ("deriv_y_max", "deriv_y_max"),
            ("auto_time_ticks", "auto_time_ticks"),
            ("auto_y_ticks", "auto_y_ticks"),
            ("auto_temp_ticks", "auto_temp_ticks"),
            ("auto_deriv_ticks", "auto_deriv_ticks"),
            ("x_major_tick", "xmaj_tick"),
            ("x_minor_tick", "xmin_tick"),
            ("y_major_tick", "ymaj_tick"),
            ("y_minor_tick", "ymin_tick"),
            ("temp_major_tick", "temp_maj_tick"),
            ("temp_minor_tick", "temp_min_tick"),
            ("deriv_major_tick", "deriv_maj_tick"),
            ("deriv_minor_tick", "deriv_min_tick"),
            ("title_text", "title_text"),
            ("suptitle_text", "suptitle_text"),
            ("enable_temp_axis", "enable_temp_axis"),
            ("enable_deriv_axis", "enable_deriv_axis"),
            ("min_cycle_drop", "min_cycle_drop"),
            ("peak_prominence", "pk_prominence"),
            ("peak_distance", "pk_distance"),
            ("peak_width", "pk_width"),
            ("core_legend_fontsize", "core_legend_fontsize"),
            ("core_cycle_legend_fontsize", "core_cycle_legend_fontsize"),
        ):
            if key in plot_settings:
                _set_var(getattr(self, attr, None), plot_settings.get(key))
        _set_var(
            getattr(self, "core_legend_fontsize", None),
            settings.get("core_legend_fontsize", label_fontsize),
        )
        _set_var(
            getattr(self, "core_cycle_legend_fontsize", None),
            settings.get(
                "core_cycle_legend_fontsize",
                settings.get("core_legend_fontsize", label_fontsize),
            ),
        )

        auto_range = plot_settings.get("axis_auto_range")
        if isinstance(auto_range, dict):
            _set_var(self.axis_auto_time, bool(auto_range.get("time", True)))
            _set_var(self.axis_auto_pressure, bool(auto_range.get("pressure", True)))
            _set_var(self.axis_auto_temp, bool(auto_range.get("temperature", True)))
            _set_var(self.axis_auto_deriv, bool(auto_range.get("derivative", True)))

        if "axis_pad_pct" in plot_settings:
            _set_var(self.axis_pad_pct, plot_settings.get("axis_pad_pct"))

        plot_selection = plot_settings.get("plot_generation_selection")
        if isinstance(plot_selection, dict):
            _set_var(self._plot_select_fig1_var, bool(plot_selection.get("fig1")))
            _set_var(self._plot_select_fig2_var, bool(plot_selection.get("fig2")))
            _set_var(
                self._plot_select_combined_var,
                bool(plot_selection.get("fig_combined")),
            )

        # Iterate to apply the per-item logic.
        for key, attr in (
            ("scatter_enabled", "scatter_enabled"),
            ("scatter_marker", "scatter_marker"),
            ("scatter_size", "scatter_size"),
            ("scatter_color", "scatter_color"),
            ("scatter_alpha", "scatter_alpha"),
            ("scatter_edgecolor", "scatter_edgecolor"),
            ("scatter_linewidth", "scatter_linewidth"),
        ):
            if key in plot_settings:
                _set_var(getattr(self, attr, None), plot_settings.get(key))

        if "scatter_series" in plot_settings:
            settings["scatter_series"] = copy.deepcopy(
                plot_settings.get("scatter_series") or {}
            )
        try:
            self._persist_scatter_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        cycle_trace = plot_settings.get("cycle_trace")
        if isinstance(cycle_trace, dict):
            try:
                self._persist_cycle_trace_settings(cycle_trace)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            # Iterate to apply the per-item logic.
            for key, attr in (
                ("line_color", "cycle_line_color"),
                ("line_style", "cycle_line_style"),
                ("line_width", "cycle_line_width"),
                ("peak_color", "cycle_peak_color"),
                ("trough_color", "cycle_trough_color"),
                ("peak_marker", "cycle_peak_marker"),
                ("trough_marker", "cycle_trough_marker"),
                ("marker_size", "cycle_marker_size"),
            ):
                if key in cycle_trace:
                    _set_var(getattr(self, attr, None), cycle_trace.get(key))

        # Iterate to apply the per-item logic.
        for key, attr in (
            ("combined_y_left_key", "combined_y_left_key"),
            ("combined_y_right_key", "combined_y_right_key"),
            ("combined_y_third_key", "combined_y_third_key"),
            ("combined_x_axis_label", "combined_x_axis_label"),
            ("combined_primary_axis_label", "combined_primary_axis_label"),
            ("combined_deriv_axis_label", "combined_deriv_axis_label"),
            ("combined_temp_axis_label", "combined_temp_axis_label"),
            ("combined_primary_labelpad", "combined_primary_labelpad"),
            ("combined_temp_labelpad", "combined_temp_labelpad"),
            ("combined_deriv_labelpad", "combined_deriv_labelpad"),
            ("combined_deriv_axis_offset", "combined_deriv_axis_offset"),
            ("combined_xlabel_tick_gap_pts", "combined_xlabel_tick_gap"),
            ("combined_left_pad_pct", "combined_left_padding_pct"),
            ("combined_right_pad_pct", "combined_right_padding_pct"),
            ("combined_title_pad_pts", "combined_title_pad_pts"),
            ("combined_suptitle_pad_pts", "combined_suptitle_pad_pts"),
            ("combined_suptitle_y", "combined_suptitle_y"),
            ("combined_top_margin_pct", "combined_top_margin_pct"),
            ("combined_export_pad_pts", "combined_export_pad_pts"),
            ("combined_suptitle_fontsize", "combined_suptitle_fontsize"),
            ("combined_title_fontsize", "combined_title_fontsize"),
            ("combined_label_fontsize", "combined_label_fontsize"),
            ("combined_tick_fontsize", "combined_tick_fontsize"),
            ("combined_legend_fontsize", "combined_legend_fontsize"),
            ("combined_cycle_legend_fontsize", "combined_cycle_legend_fontsize"),
            ("combined_font_family", "combined_font_family"),
            ("combined_legend_wrap", "combined_legend_wrap"),
            ("combined_legend_rows", "combined_legend_rows"),
            ("combined_legend_gap_pts", "combined_legend_label_gap"),
            ("combined_legend_bottom_margin_pts", "combined_legend_bottom_margin"),
            ("combined_legend_alignment", "combined_legend_alignment"),
            (
                "combined_legend_shadowbox_fill_color",
                "combined_legend_shadowbox_fill_color",
            ),
            ("combined_cycle_legend_loc_choice", "combined_cycle_legend_loc_choice"),
            ("combined_cycle_legend_ref_axis", "combined_cycle_legend_ref_axis"),
            ("combined_cycle_legend_ref_corner", "combined_cycle_legend_ref_corner"),
        ):
            if key in plot_settings:
                _set_var(getattr(self, attr, None), plot_settings.get(key))

        if "combined_center_plot_legend" in plot_settings:
            _set_var(
                getattr(self, "center_combined_plot_legend", None),
                bool(plot_settings.get("combined_center_plot_legend")),
            )

        legend_anchor = plot_settings.get("combined_legend_anchor")
        if isinstance(legend_anchor, (list, tuple)) and len(legend_anchor) == 2:
            self._combined_legend_anchor = (legend_anchor[0], legend_anchor[1])
        cycle_anchor = plot_settings.get("combined_cycle_legend_anchor")
        if isinstance(cycle_anchor, (list, tuple)) and len(cycle_anchor) == 2:
            self._combined_cycle_legend_anchor = (cycle_anchor[0], cycle_anchor[1])
        cycle_anchor_space = plot_settings.get("combined_cycle_legend_anchor_space")
        if isinstance(cycle_anchor_space, str):
            self._combined_cycle_legend_anchor_space = cycle_anchor_space

        try:
            self._sync_combined_axis_display()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._apply_combined_axis_preferences(skip_save=True)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        for _core_plot_id in CORE_RENDER_PROFILE_PLOT_IDS:
            try:
                self._mark_plot_layout_dirty(_core_plot_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _apply_profile_layout_profiles(self, layout_profiles: Dict[str, Any]) -> None:
        """Apply profile layout profiles.
        Used to apply profile layout profiles changes to live state."""
        if not isinstance(layout_profiles, dict):
            return
        settings["layout_profiles"] = _normalize_layout_profiles(layout_profiles)
        # Iterate over keys from settings["layout_profiles"] to apply the per-item logic.
        for plot_id in settings["layout_profiles"].keys():
            try:
                self._mark_plot_layout_dirty(plot_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _apply_profile_plot_elements(self, plot_elements: Dict[str, Any]) -> None:
        """Apply profile plot elements.
        Used to apply profile plot elements changes to live state."""
        if not isinstance(plot_elements, dict):
            return
        normalized = _normalize_plot_elements(plot_elements)
        settings["plot_elements"] = normalized
        self._plot_elements = settings["plot_elements"]
        # Iterate over keys from normalized to apply the per-item logic.
        for plot_id in normalized.keys():
            try:
                self._mark_plot_elements_dirty(plot_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _apply_profile_final_report_state(self, final_state: Dict[str, Any]) -> None:
        """Apply profile final report state.
        Used to apply profile final report state changes to live state."""
        if not isinstance(final_state, dict):
            return
        settings["final_report"] = copy.deepcopy(final_state)
        try:
            self._apply_final_report_state_to_ui(settings["final_report"])
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._refresh_final_report_preview()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _clear_workspace_state(self) -> None:
        """Clear workspace state.
        Used to reset workspace state state safely."""
        self.df = None
        self.sheet_dfs = {}
        self.sheet_names = []
        self.file_path = ""
        self._sheet_names_loaded = False
        self._columns_schema_preview = []
        self._columns_schema_preview_sheet = None
        self._columns_schema_preview_path = None
        self._columns_applied = False
        self._last_applied_columns = None
        self._cycle_mask = None
        self._cycle_pending_range = None
        self._cached_cycle_markers = None
        self._preloaded_cycle_markers = None
        self._markers_seeded_from_cache = False
        self.columns = {}
        settings["columns"] = {}
        settings["per_sheet_column_map"] = {}
        settings["plot_elements"] = {}
        settings["layout_profiles"] = {}
        self._plot_elements = {}
        self._per_sheet_column_map_cache = None
        try:
            self.selected_sheet.set("")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._set_selected_sheets([], persist=False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._set_multi_sheet_enabled(False, persist=False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        entry = getattr(self, "e_file", None)
        if entry is not None:
            try:
                entry.delete(0, tk.END)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            self._clear_plot_tabs()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._clear_numeric_cache()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._render_cache.prepared.clear()
            self._render_cache.cycles.clear()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._auto_title_view_cache.clear()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self.lbl_status.config(text="No file loaded.")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._refresh_columns_ui()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _reset_workspace_to_startup_defaults(self) -> None:
        """Reset the workspace to startup-default state for New Profile.

        Purpose:
            Clear dataset-bound state and restore plot/cycle/report defaults.
        Why:
            New Profile must begin from a clean baseline identical to a fresh launch.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Clears datasets and caches, updates settings, refreshes UI state, and
            resets annotations and report configuration.
        Exceptions:
            Best-effort guards prevent UI reset failures from interrupting the flow.
        """
        self._clear_workspace_state()

        default_plot_settings = self._default_profile_plot_settings_payload()
        self._apply_profile_plot_settings(default_plot_settings)

        settings["final_report"] = copy.deepcopy(FINAL_REPORT_DEFAULT_STATE)
        try:
            self._apply_final_report_state_to_ui(settings["final_report"])
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._refresh_final_report_preview()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        # Clear annotation UI state so new profiles do not inherit stale defaults.
        settings["annotations_ui"] = _normalize_annotations_ui({})
        settings["plot_elements"] = _normalize_plot_elements({})
        self._plot_elements = settings["plot_elements"]
        try:
            self._annotation_store = AnnotationStore(settings)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        # Reset cycle marker undo stacks to match a fresh session.
        self._cycle_marker_undo_stack = []
        self._cycle_marker_redo_stack = []
        self._cycle_marker_undo_lock = False

    def _resolve_profile_dataset_path(self, path: Optional[str]) -> Optional[str]:
        """Resolve profile dataset path.
        Used to compute profile dataset path before rendering or export."""
        candidate = (path or "").strip()
        if candidate and os.path.exists(candidate):
            return candidate
        if candidate:
            messagebox.showwarning(
                "Relink Dataset",
                "The dataset path stored in this profile cannot be found.\n"
                "Select the dataset file to continue.",
            )
        else:
            messagebox.showinfo(
                "Relink Dataset",
                "This profile does not include a dataset path.\n"
                "Select the dataset file to continue.",
            )
        new_path = filedialog.askopenfilename(
            title="Select Dataset File",
            filetypes=[("Excel Files", "*.xlsx *.xls")],
        )
        if not new_path:
            return None
        return new_path

    def _autosave_last_workspace(self) -> None:
        """Perform autosave last workspace.
        Used to keep the workflow logic localized and testable."""
        profiles_dir = self._profile_storage_dir()
        if profiles_dir is None:
            return
        path = profiles_dir / "_autosave_last_workspace.json"
        doc = self._build_profile_document(include_dataset_path=True)
        doc["description"] = "Autosave before loading a profile."
        self._write_profile_document(path, doc, show_errors=False)

    def _apply_column_selection(self, *, auto_refresh_axes: bool = False) -> None:
        """Apply column selection.
        Used to apply column selection changes to live state."""
        self._apply_columns(auto_refresh_axes=auto_refresh_axes)

    def _finalize_profile_restore(self) -> None:
        """Perform finalize profile restore.
        Used to keep the workflow logic localized and testable."""
        pending = getattr(self, "_profile_restore_pending", None)
        if not isinstance(pending, dict):
            self._profile_restore_pending = None
            return
        self._profile_restore_pending = None
        self._apply_profile_layout_profiles(pending.get("layout_profiles") or {})
        self._apply_profile_plot_elements(pending.get("plot_elements") or {})
        self._apply_profile_final_report_state(
            pending.get("final_report_settings") or {}
        )
        try:
            self._refresh_axis_ranges()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self.save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _restore_workspace_from_profile(self, profile_doc: dict[str, Any]) -> None:
        """Restore the workspace from a stored profile document.

        Purpose:
            Load a profile payload and rehydrate workspace state consistently.
        Why:
            Profiles are the persistence boundary for long-lived analysis sessions.
        Args:
            profile_doc: Profile document containing metadata and payload state.
        Returns:
            None.
        Side Effects:
            Clears current workspace, updates settings/UI, and may prompt for data.
        Exceptions:
            Best-effort guards prevent restore failures from crashing the UI.
        """
        payload = profile_doc.get("payload")
        state = self._deserialize_workspace_state(payload or {})
        if not state:
            messagebox.showerror("Load Profile", "Profile payload is invalid.")
            return
        dataset_required = bool(state.get("dataset_required", True))
        if dataset_required:
            dataset_path = self._resolve_profile_dataset_path(state.get("dataset_path"))
            if not dataset_path:
                return
            state["dataset_path"] = dataset_path

        self._clear_workspace_state()
        self._apply_profile_plot_settings(state.get("plot_settings") or {})

        if not dataset_required:
            self._profile_restore_pending = {
                "plot_elements": state.get("plot_elements") or {},
                "layout_profiles": state.get("layout_profiles") or {},
                "final_report_settings": state.get("final_report_settings") or {},
            }
            try:
                self._finalize_profile_restore()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        self.file_path = dataset_path
        settings["last_file_path"] = self.file_path
        entry = getattr(self, "e_file", None)
        if entry is not None:
            try:
                entry.delete(0, tk.END)
                entry.insert(0, self.file_path)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            self._load_sheet_names()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        multi_sheet = bool(state.get("multi_sheet_enabled", False))
        try:
            self._set_multi_sheet_enabled(multi_sheet, persist=False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if multi_sheet:
            try:
                self._set_selected_sheets(
                    state.get("selected_sheets") or [], persist=False
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                self._refresh_multi_sheet_lists()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        else:
            selected_sheet = (state.get("selected_sheet") or "").strip()
            if selected_sheet and selected_sheet in self.sheet_names:
                self.selected_sheet.set(selected_sheet)
            elif self.sheet_names:
                self.selected_sheet.set(self.sheet_names[0])

        columns_map = state.get("column_assignments")
        if isinstance(columns_map, dict):
            self.columns = dict(columns_map)
            settings["columns"] = dict(columns_map)
        else:
            self.columns = dict(settings.get("columns", {}))

        per_sheet_map = state.get("per_sheet_mapping")
        if isinstance(per_sheet_map, dict):
            settings["per_sheet_column_map"] = copy.deepcopy(per_sheet_map)
        else:
            settings["per_sheet_column_map"] = {}
        self._per_sheet_column_map_cache = None

        if multi_sheet:
            try:
                self._refresh_columns_ui()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        else:
            try:
                self._load_dataframe()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        try:
            self._mark_columns_dirty(reason="profile load", allow_during_apply=True)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        self._profile_restore_pending = {
            "plot_elements": state.get("plot_elements") or {},
            "layout_profiles": state.get("layout_profiles") or {},
            "final_report_settings": state.get("final_report_settings") or {},
        }

        self._apply_column_selection(auto_refresh_axes=True)

    def _open_plot_settings_dialog(self, plot_id: Optional[str] = None) -> None:
        """Open the plot settings dialog for the selected plot.

        Purpose:
            Present per-plot layout, spacing, and legend controls in a modal window.
        Why:
            Keeps advanced plot layout tuning scoped to a dedicated dialog without
            overcrowding the main Plot Settings tab.
        Args:
            plot_id: Optional plot identifier; defaults to the combined plot if omitted.
        Returns:
            None.
        Side Effects:
            Builds Tk dialog widgets, binds callbacks, and may update staged values.
        Exceptions:
            Best-effort guards keep dialog creation resilient to UI errors.
        """
        plot_id = plot_id or "fig_combined_triple_axis"
        is_combined = plot_id == "fig_combined_triple_axis"
        is_core = plot_id in {"fig_pressure_temp", "fig_pressure_derivative"}
        cycle_overlay = None
        try:
            cycle_overlay = self._core_cycle_overlay_state()
        except Exception:
            cycle_overlay = None
        cycle_legend_available = bool(self.show_cycle_legend_on_core.get()) and bool(
            cycle_overlay
        )
        existing = getattr(self, "_plot_settings_window", None)
        if existing is not None and existing.winfo_exists():
            if getattr(self, "_plot_settings_target_id", None) == plot_id:
                try:
                    existing.deiconify()
                    existing.lift()
                    existing.focus_force()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                return
            try:
                existing.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._plot_settings_window = None
            self._plot_settings_target_id = None
            self._plot_settings_apply_callback = None
            self._plot_settings_has_pending_changes_callback = None

        window = tk.Toplevel(self)
        plot_label_map = {
            "fig_pressure_temp": "Figure 1: Pressure + Temperature",
            "fig_pressure_derivative": "Figure 2: Pressure + Derivative",
            "fig_combined_triple_axis": "Combined Triple-Axis",
            "fig_cycle_analysis": "Figure 3: Cycle Analysis",
        }
        display_label = plot_label_map.get(plot_id, plot_id)
        window.title(f"Plot Settings - {display_label}")
        window.transient(self)
        window.geometry("576x990")
        window.resizable(True, True)
        self._plot_settings_window = window
        self._plot_settings_target_id = plot_id
        self._plot_settings_apply_callback = None
        self._plot_settings_has_pending_changes_callback = None

        window.grid_rowconfigure(0, weight=1)
        window.grid_columnconfigure(0, weight=1)

        outer = ttk.Frame(window)
        outer.grid(row=0, column=0, sticky="nsew")
        outer.grid_rowconfigure(0, weight=1)
        outer.grid_rowconfigure(1, weight=0)
        outer.grid_rowconfigure(2, weight=0)
        outer.grid_columnconfigure(0, weight=1)

        scroll_shell = ttk.Frame(outer)
        scroll_shell.grid(row=0, column=0, sticky="nsew")
        scroll_shell.grid_rowconfigure(0, weight=1)
        scroll_shell.grid_columnconfigure(0, weight=1)

        canvas = tk.Canvas(scroll_shell, borderwidth=0, highlightthickness=0)
        vscroll = _ui_scrollbar(scroll_shell, orient="vertical", command=canvas.yview)
        canvas.configure(yscrollcommand=vscroll.set)
        canvas.grid(row=0, column=0, sticky="nsew")
        vscroll.grid(row=0, column=1, sticky="ns")

        container = ttk.Frame(canvas, padding=12)
        container_id = canvas.create_window((0, 0), window=container, anchor="nw")
        container.grid_columnconfigure(0, weight=1)
        ttk.Separator(outer, orient="horizontal").grid(row=1, column=0, sticky="ew")
        footer = ttk.Frame(outer, padding=(12, 8, 12, 10))
        footer.grid(row=2, column=0, sticky="ew")
        footer.grid_columnconfigure(0, weight=1)

        # Closure captures _open_plot_settings_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_plot_settings_dialog.
        def _refresh_scroll_region(_event=None):
            """Refresh scroll region.
            Used to sync scroll region with current settings."""
            try:
                canvas.configure(scrollregion=canvas.bbox("all"))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Closure captures _open_plot_settings_dialog local context to keep helper logic scoped and invoked directly within _open_plot_settings_dialog.
        def _expand_width(event):
            """Perform expand width.
            Used to keep the workflow logic localized and testable."""
            try:
                canvas.itemconfigure(container_id, width=event.width)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        container.bind("<Configure>", _refresh_scroll_region)
        canvas.bind("<Configure>", _expand_width)

        # Closure captures _open_plot_settings_dialog local context to keep helper logic scoped and invoked directly within _open_plot_settings_dialog.
        def _bind_mousewheel(widget):
            """Perform bind mousewheel.
            Used to keep the workflow logic localized and testable."""

            # Closure captures _bind_mousewheel state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _bind_mousewheel.
            def _on_mousewheel(event):
                """Handle mousewheel.
                Used as an event callback for mousewheel."""
                delta = event.delta
                if delta == 0:
                    return
                step = -1 if delta > 0 else 1
                if abs(delta) >= 120:
                    step = int(-delta / 120)
                canvas.yview_scroll(step, "units")
                return "break"

            widget.bind("<MouseWheel>", _on_mousewheel, add="+")
            widget.bind(
                "<Button-4>", lambda _event: canvas.yview_scroll(-1, "units"), add="+"
            )
            widget.bind(
                "<Button-5>", lambda _event: canvas.yview_scroll(1, "units"), add="+"
            )
            # Iterate over widget.winfo_children() to apply the per-item logic.
            for child in widget.winfo_children():
                _bind_mousewheel(child)

        self.after_idle(lambda: _bind_mousewheel(container))

        layout_profile = _get_layout_profile(plot_id)
        display_section = _layout_profile_section(layout_profile, "display")
        export_section = _layout_profile_section(layout_profile, "export")
        display_margins = display_section.get(
            "margins", _default_layout_margins(plot_id, "display")
        )
        export_margins = export_section.get(
            "margins", _default_layout_margins(plot_id, "export")
        )
        legend_anchor_display = display_section.get("legend_anchor_y")
        legend_anchor_export = export_section.get("legend_anchor_y")

        stage_vars: Dict[str, tk.Variable] = {}
        core_stage_profile: Dict[str, Any] = {}
        if is_combined:
            stage_vars = {
                "combined_x_axis_label": tk.StringVar(
                    value=self.combined_x_axis_label.get()
                ),
                "combined_primary_axis_label": tk.StringVar(
                    value=self.combined_primary_axis_label.get()
                ),
                "combined_deriv_axis_label": tk.StringVar(
                    value=self.combined_deriv_axis_label.get()
                ),
                "combined_temp_axis_label": tk.StringVar(
                    value=self.combined_temp_axis_label.get()
                ),
                "combined_deriv_axis_offset": tk.DoubleVar(
                    value=self.combined_deriv_axis_offset.get()
                ),
                "combined_primary_labelpad": tk.DoubleVar(
                    value=self.combined_primary_labelpad.get()
                ),
                "combined_deriv_labelpad": tk.DoubleVar(
                    value=self.combined_deriv_labelpad.get()
                ),
                "combined_temp_labelpad": tk.DoubleVar(
                    value=self.combined_temp_labelpad.get()
                ),
                "combined_left_padding_pct": tk.DoubleVar(
                    value=self.combined_left_padding_pct.get()
                ),
                "combined_right_padding_pct": tk.DoubleVar(
                    value=self.combined_right_padding_pct.get()
                ),
                "combined_export_pad_pts": tk.DoubleVar(
                    value=self.combined_export_pad_pts.get()
                ),
                "combined_title_pad_pts": tk.DoubleVar(
                    value=self.combined_title_pad_pts.get()
                ),
                "combined_suptitle_pad_pts": tk.DoubleVar(
                    value=self.combined_suptitle_pad_pts.get()
                ),
                "combined_suptitle_y": tk.DoubleVar(
                    value=self.combined_suptitle_y.get()
                ),
                "combined_top_margin_pct": tk.DoubleVar(
                    value=self.combined_top_margin_pct.get()
                ),
                "combined_font_family": tk.StringVar(
                    value=self.combined_font_family.get()
                ),
                "combined_suptitle_fontsize": tk.DoubleVar(
                    value=self.combined_suptitle_fontsize.get()
                ),
                "combined_title_fontsize": tk.DoubleVar(
                    value=self.combined_title_fontsize.get()
                ),
                "combined_label_fontsize": tk.DoubleVar(
                    value=self.combined_label_fontsize.get()
                ),
                "combined_tick_fontsize": tk.DoubleVar(
                    value=self.combined_tick_fontsize.get()
                ),
                "combined_legend_fontsize": tk.DoubleVar(
                    value=self.combined_legend_fontsize.get()
                ),
                "combined_cycle_legend_fontsize": tk.DoubleVar(
                    value=self.combined_cycle_legend_fontsize.get()
                ),
                "combined_legend_wrap": tk.BooleanVar(
                    value=bool(self.combined_legend_wrap.get())
                ),
                "combined_legend_rows": tk.IntVar(
                    value=self.combined_legend_rows.get()
                ),
                "combined_legend_label_gap": tk.DoubleVar(
                    value=self.combined_legend_label_gap.get()
                ),
                "combined_xlabel_tick_gap": tk.DoubleVar(
                    value=self.combined_xlabel_tick_gap.get()
                ),
                "combined_legend_bottom_margin": tk.DoubleVar(
                    value=self.combined_legend_bottom_margin.get()
                ),
                "combined_legend_alignment": tk.StringVar(
                    value=self.combined_legend_alignment.get()
                ),
                "combined_cycle_legend_loc_choice": tk.StringVar(
                    value=self.combined_cycle_legend_loc_choice.get()
                ),
                "combined_cycle_legend_ref_axis": tk.StringVar(
                    value=self.combined_cycle_legend_ref_axis.get()
                ),
                "combined_cycle_legend_ref_corner": tk.StringVar(
                    value=self.combined_cycle_legend_ref_corner.get()
                ),
            }
        elif is_core:
            core_stage_profile = _get_core_plot_render_profile(plot_id)
            stage_vars = {
                "core_x_axis_label": tk.StringVar(
                    value=core_stage_profile.get("x_axis_label", "")
                ),
                "core_primary_axis_label": tk.StringVar(
                    value=core_stage_profile.get("primary_axis_label", "")
                ),
                "core_deriv_axis_label": tk.StringVar(
                    value=core_stage_profile.get("third_axis_label", "")
                ),
                "core_temp_axis_label": tk.StringVar(
                    value=core_stage_profile.get("right_axis_label", "")
                ),
                "core_deriv_axis_offset": tk.DoubleVar(
                    value=float(core_stage_profile.get("third_axis_offset", 1.12))
                ),
                "core_primary_labelpad": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "primary_labelpad", yaxis_labelpad_amount
                        )
                    )
                ),
                "core_deriv_labelpad": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "third_labelpad", twinyaxis_labelpad_amount
                        )
                    )
                ),
                "core_temp_labelpad": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "right_labelpad", twinyaxis_labelpad_amount
                        )
                    )
                ),
                "core_left_padding_pct": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "left_padding_pct", DEFAULT_COMBINED_LEFT_PAD_PCT
                        )
                    )
                ),
                "core_right_padding_pct": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "right_padding_pct", DEFAULT_COMBINED_RIGHT_PAD_PCT
                        )
                    )
                ),
                "core_export_pad_pts": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "export_pad_pts", DEFAULT_COMBINED_EXPORT_PAD_PTS
                        )
                    )
                ),
                "core_title_pad_pts": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "title_pad_pts", DEFAULT_COMBINED_TITLE_PAD_PTS
                        )
                    )
                ),
                "core_suptitle_pad_pts": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "suptitle_pad_pts", DEFAULT_COMBINED_SUPTITLE_PAD_PTS
                        )
                    )
                ),
                "core_suptitle_y": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "suptitle_y", DEFAULT_COMBINED_SUPTITLE_Y
                        )
                    )
                ),
                "core_top_margin_pct": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "top_margin_pct", DEFAULT_COMBINED_TOP_MARGIN_PCT
                        )
                    )
                ),
                "core_font_family": tk.StringVar(
                    value=str(core_stage_profile.get("font_family", "") or "")
                ),
                "core_suptitle_fontsize": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "suptitle_fontsize", DEFAULT_COMBINED_SUPTITLE_FONTSIZE
                        )
                    )
                ),
                "core_title_fontsize": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "title_fontsize", DEFAULT_COMBINED_TITLE_FONTSIZE
                        )
                    )
                ),
                "core_label_fontsize": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "label_fontsize", DEFAULT_COMBINED_LABEL_FONTSIZE
                        )
                    )
                ),
                "core_tick_fontsize": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "tick_fontsize", DEFAULT_COMBINED_TICK_FONTSIZE
                        )
                    )
                ),
                "core_legend_fontsize": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "legend_fontsize", self.core_legend_fontsize.get()
                        )
                    )
                ),
                "core_cycle_legend_fontsize": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "cycle_legend_fontsize",
                            self.core_cycle_legend_fontsize.get(),
                        )
                    )
                ),
                "core_legend_wrap": tk.BooleanVar(
                    value=bool(core_stage_profile.get("legend_wrap", False))
                ),
                "core_legend_rows": tk.IntVar(
                    value=int(core_stage_profile.get("legend_rows", 2))
                ),
                "core_legend_label_gap": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "legend_label_gap_pts", DEFAULT_COMBINED_LEGEND_GAP_PTS
                        )
                    )
                ),
                "core_xlabel_tick_gap": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "xlabel_tick_gap_pts", DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS
                        )
                    )
                ),
                "core_legend_bottom_margin": tk.DoubleVar(
                    value=float(
                        core_stage_profile.get(
                            "legend_bottom_margin_pts",
                            DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
                        )
                    )
                ),
                "core_legend_alignment": tk.StringVar(
                    value=str(
                        core_stage_profile.get("legend_alignment", "center") or "center"
                    )
                ),
                "core_cycle_legend_loc_choice": tk.StringVar(
                    value=str(
                        core_stage_profile.get("cycle_legend_loc_choice", "upper right")
                        or "upper right"
                    )
                ),
                "core_cycle_legend_ref_axis": tk.StringVar(
                    value=str(
                        core_stage_profile.get("cycle_legend_ref_axis", "main")
                        or "main"
                    )
                ),
                "core_cycle_legend_ref_corner": tk.StringVar(
                    value=str(
                        core_stage_profile.get("cycle_legend_ref_corner", "upper right")
                        or "upper right"
                    )
                ),
            }
        stage_vars["combined_legend_shadowbox_fill_color"] = tk.StringVar(
            value=_normalize_color(
                self.combined_legend_shadowbox_fill_color.get(),
                DEFAULT_LEGEND_SHADOWBOX_FILL_COLOR,
            )
        )

        stage_layout_display_left = tk.DoubleVar(
            value=display_margins.get("left", 0.125)
        )
        stage_layout_display_right = tk.DoubleVar(
            value=display_margins.get("right", 0.9)
        )
        stage_layout_display_top = tk.DoubleVar(value=display_margins.get("top", 0.88))
        stage_layout_display_bottom = tk.DoubleVar(
            value=display_margins.get("bottom", 0.11)
        )
        stage_layout_export_left = tk.DoubleVar(value=export_margins.get("left", 0.125))
        stage_layout_export_right = tk.DoubleVar(value=export_margins.get("right", 0.9))
        stage_layout_export_top = tk.DoubleVar(value=export_margins.get("top", 0.88))
        stage_layout_export_bottom = tk.DoubleVar(
            value=export_margins.get("bottom", DEFAULT_EXPORT_BOTTOM_MARGIN)
        )
        stage_legend_anchor_y_display = tk.StringVar(
            value=(
                ""
                if legend_anchor_display is None
                else f"{float(legend_anchor_display):.4f}"
            )
        )
        stage_legend_anchor_y_export = tk.StringVar(
            value=(
                ""
                if legend_anchor_export is None
                else f"{float(legend_anchor_export):.4f}"
            )
        )
        stage_mirror_detached_labelpad = (
            tk.BooleanVar(
                value=bool(layout_profile.get("mirror_detached_labelpad", False))
            )
            if is_combined
            else tk.BooleanVar(value=False)
        )
        is_core_pressure_temp = plot_id == "fig_pressure_temp"
        is_core_pressure_derivative = plot_id == "fig_pressure_derivative"

        row_idx = 0
        if is_combined or is_core:
            key_prefix = "combined" if is_combined else "core"
            x_axis_key = f"{key_prefix}_x_axis_label"
            primary_axis_key = f"{key_prefix}_primary_axis_label"
            derivative_axis_key = f"{key_prefix}_deriv_axis_label"
            temperature_axis_key = f"{key_prefix}_temp_axis_label"
            deriv_axis_offset_key = f"{key_prefix}_deriv_axis_offset"
            primary_labelpad_key = f"{key_prefix}_primary_labelpad"
            deriv_labelpad_key = f"{key_prefix}_deriv_labelpad"
            temp_labelpad_key = f"{key_prefix}_temp_labelpad"
            left_padding_key = f"{key_prefix}_left_padding_pct"
            right_padding_key = f"{key_prefix}_right_padding_pct"
            export_pad_key = f"{key_prefix}_export_pad_pts"
            title_pad_key = f"{key_prefix}_title_pad_pts"
            suptitle_pad_key = f"{key_prefix}_suptitle_pad_pts"
            suptitle_y_key = f"{key_prefix}_suptitle_y"
            top_margin_key = f"{key_prefix}_top_margin_pct"
            derivative_axis_label_state = (
                "disabled" if (is_core and is_core_pressure_temp) else "normal"
            )
            temperature_axis_label_state = (
                "disabled" if (is_core and is_core_pressure_derivative) else "normal"
            )
            derivative_axis_offset_state = "normal" if is_combined else "disabled"

            label_frame = ttk.Labelframe(container, text="Axis labels")
            label_frame.grid(row=row_idx, column=0, sticky="ew", pady=(0, 8))
            label_frame.grid_columnconfigure(1, weight=1)
            label_entries = [
                ("X-axis label", stage_vars[x_axis_key], "normal"),
                ("Primary Y-axis label", stage_vars[primary_axis_key], "normal"),
                (
                    "Derivative Y-axis label",
                    stage_vars[derivative_axis_key],
                    derivative_axis_label_state,
                ),
                (
                    "Temperature axis label",
                    stage_vars[temperature_axis_key],
                    temperature_axis_label_state,
                ),
            ]
            # Iterate over indexed elements from label_entries to apply the per-item logic.
            for row_index, (label_text, var, entry_state) in enumerate(label_entries):
                ttk.Label(label_frame, text=label_text).grid(
                    row=row_index, column=0, sticky="w", padx=(0, 6), pady=2
                )
                entry = _ui_entry(label_frame, textvariable=var, state=entry_state)
                entry.grid(row=row_index, column=1, sticky="ew", pady=2)

            row_idx += 1
            spacing_frame = ttk.Labelframe(container, text="Spacing & padding")
            spacing_frame.grid(row=row_idx, column=0, sticky="ew")
            spacing_frame.grid_columnconfigure(1, weight=1)

            ttk.Label(spacing_frame, text="Derivative axis offset").grid(
                row=0, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                spacing_frame,
                textvariable=stage_vars[deriv_axis_offset_key],
                width=8,
                state=derivative_axis_offset_state,
            ).grid(row=0, column=1, sticky="w", pady=2)

            ttk.Label(spacing_frame, text="Primary Y label padding").grid(
                row=1, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                spacing_frame,
                textvariable=stage_vars[primary_labelpad_key],
                width=8,
            ).grid(row=1, column=1, sticky="w", pady=2)

            ttk.Label(spacing_frame, text="Derivative label padding").grid(
                row=2, column=0, sticky="w", padx=(0, 6), pady=2
            )
            deriv_label_entry = _ui_entry(
                spacing_frame,
                textvariable=stage_vars[deriv_labelpad_key],
                width=8,
                state=derivative_axis_label_state,
            )
            deriv_label_entry.grid(row=2, column=1, sticky="w", pady=2)

            ttk.Label(spacing_frame, text="Temperature label padding").grid(
                row=3, column=0, sticky="w", padx=(0, 6), pady=2
            )
            temp_label_entry = _ui_entry(
                spacing_frame,
                textvariable=stage_vars[temp_labelpad_key],
                width=8,
                state=temperature_axis_label_state,
            )
            temp_label_entry.grid(row=3, column=1, sticky="w", pady=2)
            _ui_checkbutton(
                spacing_frame,
                text="Mirror attached right Y-axis label spacing to detached axis",
                variable=stage_mirror_detached_labelpad,
                state="normal" if is_combined else "disabled",
            ).grid(row=4, column=0, columnspan=2, sticky="w", pady=(4, 2))
            ttk.Label(spacing_frame, text="Left padding (%)").grid(
                row=5, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                spacing_frame,
                textvariable=stage_vars[left_padding_key],
                width=8,
            ).grid(row=5, column=1, sticky="w", pady=2)
            ttk.Label(spacing_frame, text="Right padding (%)").grid(
                row=6, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                spacing_frame,
                textvariable=stage_vars[right_padding_key],
                width=8,
            ).grid(row=6, column=1, sticky="w", pady=2)
            ttk.Label(spacing_frame, text="Export padding (pt)").grid(
                row=7, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                spacing_frame,
                textvariable=stage_vars[export_pad_key],
                width=8,
            ).grid(row=7, column=1, sticky="w", pady=2)
            ttk.Label(
                spacing_frame,
                text=(
                    "Extra whitespace reserved inside the figure so additional Y axes "
                    "and tick labels stay visible in the combined plot and saved export."
                ),
                wraplength=420,
                foreground="#555555",
            ).grid(row=8, column=0, columnspan=2, sticky="w", pady=(2, 0))
            ttk.Label(spacing_frame, text="Title padding (pt)").grid(
                row=9, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                spacing_frame,
                textvariable=stage_vars[title_pad_key],
                width=8,
            ).grid(row=9, column=1, sticky="w", pady=2)
            ttk.Label(
                spacing_frame,
                text="Suptitle (Job Information) padding (pt)",
            ).grid(row=10, column=0, sticky="w", padx=(0, 6), pady=2)
            _ui_entry(
                spacing_frame,
                textvariable=stage_vars[suptitle_pad_key],
                width=8,
            ).grid(row=10, column=1, sticky="w", pady=2)
            ttk.Label(spacing_frame, text="Suptitle (Job Information) Y (0-1)").grid(
                row=11, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                spacing_frame,
                textvariable=stage_vars[suptitle_y_key],
                width=8,
            ).grid(row=11, column=1, sticky="w", pady=2)
            ttk.Label(spacing_frame, text="Top margin above plot (%)").grid(
                row=12, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                spacing_frame,
                textvariable=stage_vars[top_margin_key],
                width=8,
            ).grid(row=12, column=1, sticky="w", pady=2)
            ttk.Label(
                spacing_frame,
                text=(
                    "Control title/suptitle spacing: title pad adds gap above the axes title; "
                    "suptitle pad nudges the figure title upward; top margin reserves space above the plot."
                ),
                wraplength=420,
                foreground="#555555",
            ).grid(row=13, column=0, columnspan=2, sticky="w", pady=(2, 0))

            if is_combined:
                # Closure captures _open_plot_settings_dialog local context to keep helper logic scoped and invoked directly within _open_plot_settings_dialog.
                def _sync_detached_labelpad(*_):
                    """Perform sync detached labelpad.
                    Used to keep the workflow logic localized and testable."""
                    if stage_mirror_detached_labelpad.get():
                        stage_vars["combined_deriv_labelpad"].set(
                            stage_vars["combined_temp_labelpad"].get()
                        )
                        try:
                            deriv_label_entry.configure(state="disabled")
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass
                    else:
                        try:
                            deriv_label_entry.configure(state="normal")
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass

                stage_mirror_detached_labelpad.trace_add(
                    "write", _sync_detached_labelpad
                )
                stage_vars["combined_temp_labelpad"].trace_add(
                    "write", _sync_detached_labelpad
                )
                _sync_detached_labelpad()

            row_idx += 1

        margins_frame = ttk.Labelframe(container, text="Layout margins")
        margins_frame.grid(row=row_idx, column=0, sticky="ew", pady=(8, 0))
        margins_frame.grid_columnconfigure(1, weight=1)

        # Closure captures _open_plot_settings_dialog local context to keep helper logic scoped and invoked directly within _open_plot_settings_dialog.
        def _build_margin_row(row, title, left_var, right_var, top_var, bottom_var):
            """Build margin row.
            Used to assemble margin row during UI or plot setup."""
            ttk.Label(margins_frame, text=title).grid(
                row=row, column=0, sticky="w", padx=(0, 6), pady=2
            )
            row_frame = ttk.Frame(margins_frame)
            row_frame.grid(row=row, column=1, sticky="w")
            # Iterate to apply the per-item logic.
            for label, var in (
                ("L", left_var),
                ("R", right_var),
                ("T", top_var),
                ("B", bottom_var),
            ):
                ttk.Label(row_frame, text=label).pack(side="left", padx=(0, 2))
                _ui_entry(row_frame, textvariable=var, width=7).pack(
                    side="left", padx=(0, 6)
                )

        _build_margin_row(
            0,
            "Display",
            stage_layout_display_left,
            stage_layout_display_right,
            stage_layout_display_top,
            stage_layout_display_bottom,
        )
        _build_margin_row(
            1,
            "Export",
            stage_layout_export_left,
            stage_layout_export_right,
            stage_layout_export_top,
            stage_layout_export_bottom,
        )
        ttk.Label(
            margins_frame,
            text=(
                "Margins are normalized figure fractions (0-1). "
                f"Default export bottom is {DEFAULT_EXPORT_BOTTOM_MARGIN}."
            ),
            wraplength=420,
            foreground="#555555",
        ).grid(row=2, column=0, columnspan=2, sticky="w", pady=(2, 0))

        row_idx += 1

        if is_combined or is_core:
            key_prefix = "combined" if is_combined else "core"
            font_frame = ttk.Labelframe(container, text="Fonts")
            font_frame.grid(row=row_idx, column=0, sticky="ew", pady=(8, 0))
            font_frame.grid_columnconfigure(1, weight=1)

            ttk.Label(font_frame, text="Font family").grid(
                row=0, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                font_frame,
                textvariable=stage_vars[f"{key_prefix}_font_family"],
                width=18,
            ).grid(row=0, column=1, sticky="w", pady=2)
            ttk.Label(font_frame, text="Suptitle (Job Information) size").grid(
                row=1, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                font_frame,
                textvariable=stage_vars[f"{key_prefix}_suptitle_fontsize"],
                width=8,
            ).grid(row=1, column=1, sticky="w", pady=2)
            ttk.Label(font_frame, text="Title size").grid(
                row=2, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                font_frame,
                textvariable=stage_vars[f"{key_prefix}_title_fontsize"],
                width=8,
            ).grid(row=2, column=1, sticky="w", pady=2)
            ttk.Label(font_frame, text="Axis label size").grid(
                row=3, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                font_frame,
                textvariable=stage_vars[f"{key_prefix}_label_fontsize"],
                width=8,
            ).grid(row=3, column=1, sticky="w", pady=2)
            ttk.Label(font_frame, text="Tick label size").grid(
                row=4, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                font_frame,
                textvariable=stage_vars[f"{key_prefix}_tick_fontsize"],
                width=8,
            ).grid(row=4, column=1, sticky="w", pady=2)
            ttk.Label(font_frame, text="Main legend size").grid(
                row=5, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                font_frame,
                textvariable=stage_vars[f"{key_prefix}_legend_fontsize"],
                width=8,
            ).grid(row=5, column=1, sticky="w", pady=2)
            ttk.Label(font_frame, text="Cycle legend size").grid(
                row=6, column=0, sticky="w", padx=(0, 6), pady=2
            )
            cycle_legend_entry_state = (
                "normal" if cycle_legend_available else "disabled"
            )
            _ui_entry(
                font_frame,
                textvariable=stage_vars[f"{key_prefix}_cycle_legend_fontsize"],
                width=8,
                state=cycle_legend_entry_state,
            ).grid(row=6, column=1, sticky="w", pady=2)
            ttk.Label(
                font_frame,
                text="Leave font family blank to use the default plot font.",
                wraplength=420,
                foreground="#555555",
            ).grid(row=7, column=0, columnspan=2, sticky="w", pady=(2, 0))

            row_idx += 1

        legend_frame = ttk.Labelframe(container, text="Legend layout")
        legend_frame.grid(row=row_idx, column=0, sticky="ew", pady=(8, 0))
        legend_frame.grid_columnconfigure(1, weight=0)

        if is_combined or is_core:
            key_prefix = "combined" if is_combined else "core"
            _ui_checkbutton(
                legend_frame,
                text="Wrap legend into rows",
                variable=stage_vars[f"{key_prefix}_legend_wrap"],
            ).grid(row=0, column=0, columnspan=2, sticky="w", pady=2)

            ttk.Label(legend_frame, text="Legend rows").grid(
                row=1, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                legend_frame,
                width=8,
                textvariable=stage_vars[f"{key_prefix}_legend_rows"],
            ).grid(row=1, column=1, sticky="w", pady=2)
            ttk.Label(
                legend_frame,
                text="Number of rows to divide the legend into when wrapping is enabled.",
                wraplength=420,
                foreground="#555555",
            ).grid(row=2, column=0, columnspan=2, sticky="w", pady=(4, 0))

            ttk.Label(legend_frame, text="Gap above legend (pt)").grid(
                row=3, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                legend_frame,
                width=8,
                textvariable=stage_vars[f"{key_prefix}_legend_label_gap"],
            ).grid(row=3, column=1, sticky="w", pady=2)
            ttk.Label(
                legend_frame,
                text="Distance from the lowest y-label to the top of the legend shadowbox.",
                wraplength=420,
                foreground="#555555",
            ).grid(row=4, column=0, columnspan=2, sticky="w", pady=(2, 0))

            ttk.Label(legend_frame, text="X-label spacing from x-ticks (pts)").grid(
                row=5, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                legend_frame,
                width=8,
                textvariable=stage_vars[f"{key_prefix}_xlabel_tick_gap"],
            ).grid(row=5, column=1, sticky="w", pady=2)
            ttk.Label(
                legend_frame,
                text="Minimum spacing between x tick labels and the x-axis label.",
                wraplength=420,
                foreground="#555555",
            ).grid(row=6, column=0, columnspan=2, sticky="w", pady=(2, 0))

            ttk.Label(legend_frame, text="Bottom margin (pt)").grid(
                row=7, column=0, sticky="w", padx=(0, 6), pady=2
            )
            _ui_entry(
                legend_frame,
                width=8,
                textvariable=stage_vars[f"{key_prefix}_legend_bottom_margin"],
            ).grid(row=7, column=1, sticky="w", pady=2)
            ttk.Label(
                legend_frame,
                text="Space between the bottom of the legend and the figure edge in saved exports.",
                wraplength=420,
                foreground="#555555",
            ).grid(row=8, column=0, columnspan=2, sticky="w", pady=(2, 0))

            if is_combined:
                _ui_button(
                    legend_frame,
                    text="Combined Plot Layout Tuner...",
                    command=self._open_combined_layout_tuner,
                ).grid(row=9, column=0, columnspan=2, sticky="w", pady=(6, 2))

            ttk.Label(legend_frame, text="Legend alignment").grid(
                row=10, column=0, sticky="w", padx=(0, 6), pady=2
            )
            alignment_menu = ttk.OptionMenu(
                legend_frame,
                stage_vars[f"{key_prefix}_legend_alignment"],
                stage_vars[f"{key_prefix}_legend_alignment"].get(),
                "left",
                "center",
                "right",
            )
            alignment_menu.grid(row=10, column=1, sticky="w", pady=2)

            cycle_loc_choices = [
                "upper right",
                "upper left",
                "lower right",
                "lower left",
                "center right",
                "center left",
                "upper center",
                "lower center",
                "center",
            ]
            cycle_loc_var = stage_vars[f"{key_prefix}_cycle_legend_loc_choice"]
            if (cycle_loc_var.get() or "").strip().lower() not in cycle_loc_choices:
                cycle_loc_var.set("upper right")

            ttk.Label(legend_frame, text="Cycle Legend Location").grid(
                row=11, column=0, sticky="w", padx=(0, 6), pady=2
            )
            cycle_loc_menu = ttk.OptionMenu(
                legend_frame,
                cycle_loc_var,
                cycle_loc_var.get(),
                *cycle_loc_choices,
            )
            if not cycle_legend_available:
                cycle_loc_menu.configure(state="disabled")
            cycle_loc_menu.grid(row=11, column=1, sticky="w", pady=2)

            ref_axis_var = stage_vars[f"{key_prefix}_cycle_legend_ref_axis"]
            if (
                ref_axis_var.get() or ""
            ).strip().lower() not in COMBINED_CYCLE_REF_AXIS_CHOICES:
                ref_axis_var.set("main")
            ttk.Label(legend_frame, text="Cycle Legend Reference Axis").grid(
                row=12, column=0, sticky="w", padx=(0, 6), pady=2
            )
            ref_axis_menu = ttk.OptionMenu(
                legend_frame,
                ref_axis_var,
                ref_axis_var.get(),
                *COMBINED_CYCLE_REF_AXIS_CHOICES,
            )
            if (not cycle_legend_available) or is_core:
                ref_axis_menu.configure(state="disabled")
            ref_axis_menu.grid(row=12, column=1, sticky="w", pady=2)

            ref_corner_var = stage_vars[f"{key_prefix}_cycle_legend_ref_corner"]
            if (
                ref_corner_var.get() or ""
            ).strip().lower() not in COMBINED_CYCLE_REF_CORNER_CHOICES:
                ref_corner_var.set("upper right")
            ttk.Label(legend_frame, text="Cycle Legend Reference Corner").grid(
                row=13, column=0, sticky="w", padx=(0, 6), pady=2
            )
            ref_corner_menu = ttk.OptionMenu(
                legend_frame,
                ref_corner_var,
                ref_corner_var.get(),
                *COMBINED_CYCLE_REF_CORNER_CHOICES,
            )
            if (not cycle_legend_available) or is_core:
                ref_corner_menu.configure(state="disabled")
            ref_corner_menu.grid(row=13, column=1, sticky="w", pady=2)

            # Keep legend shadowbox controls in Plot Settings so core and combined
            # rendering share one visual source of truth for frame fill color.
            legend_fill_row = 14
            ttk.Label(legend_frame, text="Legend shadowbox fill").grid(
                row=legend_fill_row, column=0, sticky="w", padx=(0, 6), pady=2
            )
            legend_fill_frame = ttk.Frame(legend_frame)
            legend_fill_frame.grid(row=legend_fill_row, column=1, sticky="w", pady=2)
            legend_fill_preview = tk.Label(
                legend_fill_frame,
                width=6,
                relief="groove",
                borderwidth=1,
                text="Default",
            )
            legend_fill_preview.pack(side="left")
            self._bind_color_preview(
                stage_vars["combined_legend_shadowbox_fill_color"],
                legend_fill_preview,
                default_text="Default",
            )
            _ui_entry(
                legend_fill_frame,
                textvariable=stage_vars["combined_legend_shadowbox_fill_color"],
                width=12,
                state="readonly",
            ).pack(side="left", padx=(6, 4))

            def _choose_legend_fill_color() -> None:
                """Pick legend shadowbox fill color from the platform color chooser."""
                initial = (
                    stage_vars["combined_legend_shadowbox_fill_color"].get() or ""
                ).strip() or None
                try:
                    _, hex_value = colorchooser.askcolor(
                        color=initial,
                        parent=window,
                        title="Legend Shadowbox Fill Color",
                    )
                except Exception:
                    hex_value = None
                if hex_value:
                    stage_vars["combined_legend_shadowbox_fill_color"].set(
                        str(hex_value).upper()
                    )

            _ui_button(
                legend_fill_frame,
                text="Choose...",
                command=_choose_legend_fill_color,
            ).pack(side="left", padx=(0, 4))
            _ui_button(
                legend_fill_frame,
                text="Reset",
                command=lambda: stage_vars["combined_legend_shadowbox_fill_color"].set(
                    DEFAULT_LEGEND_SHADOWBOX_FILL_COLOR
                ),
            ).pack(side="left")
            ttk.Label(
                legend_frame,
                text="Applies to combined and non-combined legend shadowbox backgrounds.",
                wraplength=420,
                foreground="#555555",
            ).grid(
                row=legend_fill_row + 1,
                column=0,
                columnspan=2,
                sticky="w",
                pady=(2, 0),
            )

        # Closure captures _open_plot_settings_dialog local context to keep helper logic scoped and invoked directly within _open_plot_settings_dialog.
        def _parse_anchor_value(var: tk.StringVar) -> Optional[float]:
            """Parse anchor value.
            Used to interpret anchor value inputs safely."""
            raw = (var.get() or "").strip()
            if not raw:
                return None
            try:
                return float(raw)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None

        # Closure captures _open_plot_settings_dialog local context to keep helper logic scoped and invoked directly within _open_plot_settings_dialog.
        def _nudge_anchor(var: tk.StringVar, direction: int) -> None:
            """Perform nudge anchor.
            Used to keep the workflow logic localized and testable."""
            value = _parse_anchor_value(var)
            if value is None:
                value = 0.02
            value = max(-0.1, min(1.1, value + (0.01 * direction)))
            var.set(f"{value:.4f}")

        anchor_row = 16 if (is_combined or is_core) else 0
        ttk.Label(legend_frame, text="Legend anchor Y (display)").grid(
            row=anchor_row, column=0, sticky="w", padx=(0, 6), pady=2
        )
        display_anchor_frame = ttk.Frame(legend_frame)
        display_anchor_frame.grid(row=anchor_row, column=1, sticky="w", pady=2)
        _ui_entry(
            display_anchor_frame,
            textvariable=stage_legend_anchor_y_display,
            width=8,
        ).pack(side="left")
        _ui_button(
            display_anchor_frame,
            text="Up",
            width=4,
            command=lambda: _nudge_anchor(stage_legend_anchor_y_display, 1),
        ).pack(side="left", padx=(4, 2))
        _ui_button(
            display_anchor_frame,
            text="Down",
            width=5,
            command=lambda: _nudge_anchor(stage_legend_anchor_y_display, -1),
        ).pack(side="left")

        ttk.Label(legend_frame, text="Legend anchor Y (export)").grid(
            row=anchor_row + 1, column=0, sticky="w", padx=(0, 6), pady=2
        )
        export_anchor_frame = ttk.Frame(legend_frame)
        export_anchor_frame.grid(row=anchor_row + 1, column=1, sticky="w", pady=2)
        _ui_entry(
            export_anchor_frame,
            textvariable=stage_legend_anchor_y_export,
            width=8,
        ).pack(side="left")
        _ui_button(
            export_anchor_frame,
            text="Up",
            width=4,
            command=lambda: _nudge_anchor(stage_legend_anchor_y_export, 1),
        ).pack(side="left", padx=(4, 2))
        _ui_button(
            export_anchor_frame,
            text="Down",
            width=5,
            command=lambda: _nudge_anchor(stage_legend_anchor_y_export, -1),
        ).pack(side="left")

        ttk.Label(
            legend_frame,
            text="Up moves the legend toward the x-label; down moves it away.",
            wraplength=420,
            foreground="#555555",
        ).grid(row=anchor_row + 2, column=0, columnspan=2, sticky="w", pady=(2, 0))

        row_idx += 1

        button_frame = ttk.Frame(footer)
        button_frame.grid(row=0, column=1, sticky="e")

        default_display_margins = _default_layout_margins(plot_id, "display")
        default_export_margins = _default_layout_margins(plot_id, "export")

        # Closure captures _open_plot_settings_dialog local context to keep helper logic scoped and invoked directly within _open_plot_settings_dialog.
        def _safe_stage_float(var: Optional[tk.Variable], default: float) -> float:
            """Perform safe stage float.
            Used to keep the workflow logic localized and testable."""
            if var is None:
                return default
            try:
                value = float(var.get())
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return default
            if not math.isfinite(value):
                return default
            return value

        # Closure captures _open_plot_settings_dialog local context to keep helper logic scoped and invoked directly within _open_plot_settings_dialog.
        def _normalized_core_stage_profile() -> Dict[str, Any]:
            """Return a normalized core render profile from staged dialog values."""
            defaults = _default_core_plot_render_profile(seed_source=settings)
            raw_profile = {
                "x_axis_label": str(
                    stage_vars.get("core_x_axis_label").get()
                    if stage_vars.get("core_x_axis_label") is not None
                    else ""
                ),
                "primary_axis_label": str(
                    stage_vars.get("core_primary_axis_label").get()
                    if stage_vars.get("core_primary_axis_label") is not None
                    else ""
                ),
                "right_axis_label": str(
                    stage_vars.get("core_temp_axis_label").get()
                    if stage_vars.get("core_temp_axis_label") is not None
                    else ""
                ),
                "third_axis_label": str(
                    stage_vars.get("core_deriv_axis_label").get()
                    if stage_vars.get("core_deriv_axis_label") is not None
                    else ""
                ),
                "primary_labelpad": _safe_stage_float(
                    stage_vars.get("core_primary_labelpad"), yaxis_labelpad_amount
                ),
                "right_labelpad": _safe_stage_float(
                    stage_vars.get("core_temp_labelpad"), twinyaxis_labelpad_amount
                ),
                "third_labelpad": _safe_stage_float(
                    stage_vars.get("core_deriv_labelpad"), twinyaxis_labelpad_amount
                ),
                "third_axis_offset": _safe_stage_float(
                    stage_vars.get("core_deriv_axis_offset"), 1.12
                ),
                "left_padding_pct": _safe_stage_float(
                    stage_vars.get("core_left_padding_pct"),
                    DEFAULT_COMBINED_LEFT_PAD_PCT,
                ),
                "right_padding_pct": _safe_stage_float(
                    stage_vars.get("core_right_padding_pct"),
                    DEFAULT_COMBINED_RIGHT_PAD_PCT,
                ),
                "export_pad_pts": _safe_stage_float(
                    stage_vars.get("core_export_pad_pts"),
                    DEFAULT_COMBINED_EXPORT_PAD_PTS,
                ),
                "title_pad_pts": _safe_stage_float(
                    stage_vars.get("core_title_pad_pts"), DEFAULT_COMBINED_TITLE_PAD_PTS
                ),
                "suptitle_pad_pts": _safe_stage_float(
                    stage_vars.get("core_suptitle_pad_pts"),
                    DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
                ),
                "suptitle_y": _safe_stage_float(
                    stage_vars.get("core_suptitle_y"), DEFAULT_COMBINED_SUPTITLE_Y
                ),
                "top_margin_pct": _safe_stage_float(
                    stage_vars.get("core_top_margin_pct"),
                    DEFAULT_COMBINED_TOP_MARGIN_PCT,
                ),
                "font_family": str(
                    stage_vars.get("core_font_family").get()
                    if stage_vars.get("core_font_family") is not None
                    else ""
                ),
                "suptitle_fontsize": _safe_stage_float(
                    stage_vars.get("core_suptitle_fontsize"),
                    DEFAULT_COMBINED_SUPTITLE_FONTSIZE,
                ),
                "title_fontsize": _safe_stage_float(
                    stage_vars.get("core_title_fontsize"),
                    DEFAULT_COMBINED_TITLE_FONTSIZE,
                ),
                "label_fontsize": _safe_stage_float(
                    stage_vars.get("core_label_fontsize"),
                    DEFAULT_COMBINED_LABEL_FONTSIZE,
                ),
                "tick_fontsize": _safe_stage_float(
                    stage_vars.get("core_tick_fontsize"), DEFAULT_COMBINED_TICK_FONTSIZE
                ),
                "legend_fontsize": _safe_stage_float(
                    stage_vars.get("core_legend_fontsize"),
                    settings.get("core_legend_fontsize", label_fontsize),
                ),
                "cycle_legend_fontsize": _safe_stage_float(
                    stage_vars.get("core_cycle_legend_fontsize"),
                    settings.get(
                        "core_cycle_legend_fontsize",
                        settings.get("core_legend_fontsize", label_fontsize),
                    ),
                ),
                "legend_wrap": bool(stage_vars.get("core_legend_wrap").get())
                if stage_vars.get("core_legend_wrap") is not None
                else False,
                "legend_rows": int(
                    _safe_stage_float(stage_vars.get("core_legend_rows"), 2)
                ),
                "legend_label_gap_pts": _safe_stage_float(
                    stage_vars.get("core_legend_label_gap"),
                    DEFAULT_COMBINED_LEGEND_GAP_PTS,
                ),
                "xlabel_tick_gap_pts": _safe_stage_float(
                    stage_vars.get("core_xlabel_tick_gap"),
                    DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS,
                ),
                "legend_bottom_margin_pts": _safe_stage_float(
                    stage_vars.get("core_legend_bottom_margin"),
                    DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
                ),
                "legend_alignment": str(
                    stage_vars.get("core_legend_alignment").get()
                    if stage_vars.get("core_legend_alignment") is not None
                    else "center"
                ),
                "cycle_legend_loc_choice": str(
                    stage_vars.get("core_cycle_legend_loc_choice").get()
                    if stage_vars.get("core_cycle_legend_loc_choice") is not None
                    else "upper right"
                ),
                "cycle_legend_ref_axis": str(
                    stage_vars.get("core_cycle_legend_ref_axis").get()
                    if stage_vars.get("core_cycle_legend_ref_axis") is not None
                    else "main"
                ),
                "cycle_legend_ref_corner": str(
                    stage_vars.get("core_cycle_legend_ref_corner").get()
                    if stage_vars.get("core_cycle_legend_ref_corner") is not None
                    else "upper right"
                ),
            }
            return _normalize_core_plot_render_profile(raw_profile, defaults=defaults)

        # Closure captures _open_plot_settings_dialog local context to keep helper logic scoped and invoked directly within _open_plot_settings_dialog.
        def _normalized_plot_settings_snapshot() -> Dict[str, Any]:
            """Perform normalized plot settings snapshot.
            Used to keep the workflow logic localized and testable."""
            snapshot: Dict[str, Any] = {}
            # Iterate over items from stage_vars to apply the per-item logic.
            for key, var in stage_vars.items():
                try:
                    value = var.get()
                except Exception:
                    value = None
                if isinstance(value, bool):
                    snapshot[key] = bool(value)
                elif isinstance(value, float):
                    snapshot[key] = round(value, 6) if math.isfinite(value) else value
                else:
                    snapshot[key] = value
            display_margins = {
                "left": _safe_stage_float(
                    stage_layout_display_left,
                    default_display_margins.get("left", 0.125),
                ),
                "right": _safe_stage_float(
                    stage_layout_display_right,
                    default_display_margins.get("right", 0.9),
                ),
                "top": _safe_stage_float(
                    stage_layout_display_top, default_display_margins.get("top", 0.88)
                ),
                "bottom": _safe_stage_float(
                    stage_layout_display_bottom,
                    default_display_margins.get("bottom", 0.11),
                ),
            }
            export_margins = {
                "left": _safe_stage_float(
                    stage_layout_export_left, default_export_margins.get("left", 0.125)
                ),
                "right": _safe_stage_float(
                    stage_layout_export_right, default_export_margins.get("right", 0.9)
                ),
                "top": _safe_stage_float(
                    stage_layout_export_top, default_export_margins.get("top", 0.88)
                ),
                "bottom": _safe_stage_float(
                    stage_layout_export_bottom,
                    default_export_margins.get("bottom", DEFAULT_EXPORT_BOTTOM_MARGIN),
                ),
            }
            snapshot["layout_display_margins"] = _normalize_layout_margins(
                display_margins, default_display_margins
            )
            snapshot["layout_export_margins"] = _normalize_layout_margins(
                export_margins, default_export_margins
            )
            snapshot["legend_anchor_y_display"] = _parse_anchor_value(
                stage_legend_anchor_y_display
            )
            snapshot["legend_anchor_y_export"] = _parse_anchor_value(
                stage_legend_anchor_y_export
            )
            if is_combined:
                snapshot["mirror_detached_labelpad"] = bool(
                    stage_mirror_detached_labelpad.get()
                )
            if is_core:
                snapshot["core_render_profile"] = _normalized_core_stage_profile()
            snapshot["combined_legend_shadowbox_fill_color"] = _normalize_color(
                stage_vars["combined_legend_shadowbox_fill_color"].get(),
                DEFAULT_LEGEND_SHADOWBOX_FILL_COLOR,
            )
            return snapshot

        baseline_snapshot = _normalized_plot_settings_snapshot()

        # Closure captures _open_plot_settings_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_plot_settings_dialog.
        def _apply_stage_values(
            close_after: bool = False,
            *,
            refresh_after_apply: bool = True,
        ) -> bool:
            """Apply staged Plot Settings values into canonical app state.

            Purpose:
                Commit staged dialog inputs for layout, fonts, and legend settings.
            Why:
                Apply/Refresh/Generate must share one commit path so renders always
                use the same normalized values.
            Inputs:
                close_after: When True, close the dialog after applying.
                refresh_after_apply: When True, trigger the dialog-target plot refresh.
            Outputs:
                True when staged changes were committed, else False.
            Side Effects:
                Updates Tk variables/settings, syncs layout profiles, optionally
                refreshes the target plot, and updates the staged baseline snapshot.
            Exceptions:
                Best-effort guards suppress non-critical UI failures.
            """
            nonlocal baseline_snapshot
            staged_snapshot = _normalized_plot_settings_snapshot()
            if staged_snapshot == baseline_snapshot:
                if close_after:
                    self._close_plot_settings_dialog()
                return False
            if stage_vars:
                # Iterate over items from stage_vars to apply the per-item logic.
                for key, var in stage_vars.items():
                    target_var = getattr(self, key, None)
                    if target_var is None:
                        continue
                    try:
                        target_var.set(var.get())
                    except Exception:
                        try:
                            target_var.set(var.get())
                        except Exception:
                            pass
            legend_fill_color_value = _normalize_color(
                self.combined_legend_shadowbox_fill_color.get(),
                DEFAULT_LEGEND_SHADOWBOX_FILL_COLOR,
            )
            self.combined_legend_shadowbox_fill_color.set(legend_fill_color_value)
            settings["combined_legend_shadowbox_fill_color"] = legend_fill_color_value
            if is_combined:
                self._apply_combined_axis_preferences(skip_save=True)
            if is_core:
                staged_core_profile = staged_snapshot.get("core_render_profile")
                applied_core_profile = _set_core_plot_render_profile(
                    plot_id,
                    staged_core_profile if isinstance(staged_core_profile, Mapping) else {},
                )
                self.core_legend_fontsize.set(
                    float(
                        applied_core_profile.get(
                            "legend_fontsize", self.core_legend_fontsize.get()
                        )
                    )
                )
                self.core_cycle_legend_fontsize.set(
                    float(
                        applied_core_profile.get(
                            "cycle_legend_fontsize",
                            self.core_cycle_legend_fontsize.get(),
                        )
                    )
                )
            display_margins = staged_snapshot.get("layout_display_margins")
            if not isinstance(display_margins, Mapping):
                display_margins = default_display_margins
            export_margins = staged_snapshot.get("layout_export_margins")
            if not isinstance(export_margins, Mapping):
                export_margins = default_export_margins
            legend_anchor_display = staged_snapshot.get("legend_anchor_y_display")
            legend_anchor_export = staged_snapshot.get("legend_anchor_y_export")
            if is_combined:
                self._sync_combined_layout_profile(
                    display_margins=display_margins,
                    export_margins=export_margins,
                    legend_anchor_y_display=legend_anchor_display,
                    legend_anchor_y_export=legend_anchor_export,
                    mirror_detached_labelpad=bool(
                        staged_snapshot.get(
                            "mirror_detached_labelpad",
                            stage_mirror_detached_labelpad.get(),
                        )
                    ),
                )
            else:
                self._sync_plot_layout_profile(
                    plot_id,
                    display_margins=display_margins,
                    export_margins=export_margins,
                    legend_anchor_y_display=legend_anchor_display,
                    legend_anchor_y_export=legend_anchor_export,
                )
            try:
                plot_tabs = list(getattr(self, "_plot_tabs", []) or [])
                canvases = list(getattr(self, "_canvases", []) or [])
                # Legend fill color is shared globally, so refresh every open plot.
                for idx, canvas in enumerate(canvases):
                    fig = getattr(canvas, "figure", None)
                    if fig is None:
                        continue
                    canvas_plot_id = None
                    if idx < len(plot_tabs):
                        canvas_plot_id = getattr(plot_tabs[idx], "_plot_id", None)
                    self._apply_gl260_legend_sizing(fig, plot_id=canvas_plot_id)
                    if fig.canvas is not None:
                        if canvas_plot_id == plot_id:
                            # Keep target-plot layout work inside the overlay-controlled
                            # refresh path so post-overlay snaps are not visible.
                            continue
                        fig.canvas.draw_idle()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                self._mark_plot_layout_dirty(plot_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if refresh_after_apply:
                # Route dialog apply through one refresh path so overlay release
                # waits for final layout stabilization.
                self._refresh_plot_for_plot_id(
                    plot_id,
                    reason="Applying Plot Settings...",
                    rearm_overlay=True,
                    capture_combined_legend=False,
                )
            baseline_snapshot = _normalized_plot_settings_snapshot()
            if close_after:
                self._close_plot_settings_dialog()
            return True

        # Closure captures _open_plot_settings_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_plot_settings_dialog.
        def _has_pending_stage_values() -> bool:
            """Return whether staged Plot Settings values differ from baseline.

            Purpose:
                Detect unsaved dialog edits for shared refresh/generate workflows.
            Why:
                External triggers should only force-apply when staged values changed.
            Inputs:
                None.
            Outputs:
                True when staged edits are pending, else False.
            Side Effects:
                None.
            Exceptions:
                Best-effort guards treat snapshot failures as no pending changes.
            """
            try:
                staged_snapshot = _normalized_plot_settings_snapshot()
            except Exception:
                return False
            return staged_snapshot != baseline_snapshot

        self._plot_settings_apply_callback = _apply_stage_values
        self._plot_settings_has_pending_changes_callback = _has_pending_stage_values

        _ui_button(
            button_frame, text="Apply", command=lambda: _apply_stage_values(False)
        ).grid(row=0, column=0, padx=(0, 6))
        _ui_button(
            button_frame, text="Close", command=lambda: _apply_stage_values(True)
        ).grid(row=0, column=1)

        window.protocol("WM_DELETE_WINDOW", lambda: _apply_stage_values(True))

    def _flush_open_plot_settings_dialog(
        self,
        *,
        refresh_after_apply: bool = False,
    ) -> bool:
        """Apply pending Plot Settings dialog edits without closing the dialog.

        Purpose:
            Reuse the Plot Settings apply path from refresh/generate triggers.
        Why:
            Manual Refresh and Generate Plot must honor unsaved dialog edits before
            creating new render snapshots.
        Inputs:
            refresh_after_apply: When True, the dialog apply path also triggers the
                target-plot refresh; False avoids recursive/double refreshes when the
                caller is already performing a refresh/generate action.
        Outputs:
            True when pending staged edits were committed, else False.
        Side Effects:
            May update settings/layout profiles and plot state via the shared dialog
            apply callback when pending edits exist.
        Exceptions:
            Best-effort guards return False on missing callbacks/window errors.
        """
        window = getattr(self, "_plot_settings_window", None)
        if window is None:
            return False
        try:
            if not window.winfo_exists():
                return False
        except Exception:
            return False

        has_pending_callback = getattr(
            self,
            "_plot_settings_has_pending_changes_callback",
            None,
        )
        if callable(has_pending_callback):
            try:
                if not bool(has_pending_callback()):
                    return False
            except Exception:
                # Best-effort guard; ignore failures and attempt apply.
                pass

        apply_callback = getattr(self, "_plot_settings_apply_callback", None)
        if not callable(apply_callback):
            return False
        try:
            applied = apply_callback(
                close_after=False,
                refresh_after_apply=refresh_after_apply,
            )
        except Exception:
            return False
        return bool(applied)

    def _close_plot_settings_dialog(self) -> None:
        """Close the Plot Settings dialog and clear staged callback hooks.

        Purpose:
            Tear down the active Plot Settings window safely.
        Why:
            Shared apply/pending callbacks must be cleared so other actions do not
            call stale closures after the dialog is closed.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Destroys the dialog window when present and resets dialog-tracking
            attributes/callback references.
        Exceptions:
            Best-effort guards suppress window-destroy failures.
        """

        window = getattr(self, "_plot_settings_window", None)
        if window is not None:
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._plot_settings_window = None
        self._plot_settings_target_id = None
        self._plot_settings_apply_callback = None
        self._plot_settings_has_pending_changes_callback = None

    def _open_combined_axis_preferences(self) -> None:
        """Open combined axis preferences.
        Used by UI actions to open combined axis preferences."""
        self._open_plot_settings_dialog("fig_combined_triple_axis")

    def _sync_combined_layout_profile(
        self,
        *,
        display_margins: Optional[Mapping[str, float]] = None,
        export_margins: Optional[Mapping[str, float]] = None,
        legend_anchor_y_display: Optional[float] = None,
        legend_anchor_y_export: Optional[float] = None,
        mirror_detached_labelpad: Optional[bool] = None,
    ) -> None:
        """Perform sync combined layout profile.
        Used to keep the workflow logic localized and testable."""
        profile = _get_layout_profile("fig_combined_triple_axis")
        # Iterate to apply the per-item logic.
        for mode, margins, anchor_y in (
            ("display", display_margins, legend_anchor_y_display),
            ("export", export_margins, legend_anchor_y_export),
        ):
            section = profile.setdefault(mode, {})
            if margins is not None:
                section["margins"] = _normalize_layout_margins(
                    margins, _default_layout_margins("fig_combined_triple_axis", mode)
                )
            axis_labelpads = section.get("axis_labelpads")
            if not isinstance(axis_labelpads, dict):
                axis_labelpads = {}
            axis_labelpads["primary"] = self._safe_get_var(
                self.combined_primary_labelpad, float
            )
            axis_labelpads["right"] = self._safe_get_var(
                self.combined_temp_labelpad, float
            )
            axis_labelpads["third"] = self._safe_get_var(
                self.combined_deriv_labelpad, float
            )
            section["axis_labelpads"] = axis_labelpads
            section["detached_spine_offset"] = self._safe_get_var(
                self.combined_deriv_axis_offset, float
            )
            section["detached_labelpad"] = self._safe_get_var(
                self.combined_deriv_labelpad, float
            )
            if anchor_y is not None:
                try:
                    anchor_value = float(anchor_y)
                except Exception:
                    anchor_value = None
                if anchor_value is not None and math.isfinite(anchor_value):
                    section["legend_anchor_y"] = max(-0.1, min(1.1, anchor_value))
        if mirror_detached_labelpad is not None:
            profile["mirror_detached_labelpad"] = bool(mirror_detached_labelpad)
        settings["layout_profiles"] = _normalize_layout_profiles(
            settings.get("layout_profiles")
        )
        try:
            self._mark_plot_layout_dirty("fig_combined_triple_axis")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _apply_combined_axis_preferences(self, *, skip_save: bool = False) -> None:
        """Apply combined axis preferences.
        Used to apply combined axis preferences changes to live state."""
        # Closure captures _apply_combined_axis_preferences local context to keep helper logic scoped and invoked directly within _apply_combined_axis_preferences.
        def _label_value(var: tk.StringVar) -> str:
            """Perform label value.
            Used to keep the workflow logic localized and testable."""
            return (var.get() or "").strip()

        settings["combined_x_axis_label"] = _label_value(self.combined_x_axis_label)
        settings["combined_primary_axis_label"] = _label_value(
            self.combined_primary_axis_label
        )
        settings["combined_deriv_axis_label"] = _label_value(
            self.combined_deriv_axis_label
        )
        settings["combined_temp_axis_label"] = _label_value(
            self.combined_temp_axis_label
        )

        settings["combined_primary_labelpad"] = self._safe_get_var(
            self.combined_primary_labelpad, float
        )
        settings["combined_deriv_labelpad"] = self._safe_get_var(
            self.combined_deriv_labelpad, float
        )
        settings["combined_temp_labelpad"] = self._safe_get_var(
            self.combined_temp_labelpad, float
        )
        settings["combined_deriv_axis_offset"] = self._safe_get_var(
            self.combined_deriv_axis_offset, float
        )
        settings["combined_xlabel_tick_gap_pts"] = _sanitize_spacing_value(
            self._safe_get_var(self.combined_xlabel_tick_gap, float),
            DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS,
            MIN_COMBINED_XLABEL_TICK_GAP_PTS,
            MAX_COMBINED_XLABEL_TICK_GAP_PTS,
        )
        left_pad_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_left_padding_pct, float),
            DEFAULT_COMBINED_LEFT_PAD_PCT,
            MIN_COMBINED_SIDE_PAD_PCT,
            MAX_COMBINED_SIDE_PAD_PCT,
        )
        right_pad_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_right_padding_pct, float),
            DEFAULT_COMBINED_RIGHT_PAD_PCT,
            MIN_COMBINED_SIDE_PAD_PCT,
            MAX_COMBINED_SIDE_PAD_PCT,
        )
        title_pad_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_title_pad_pts, float),
            DEFAULT_COMBINED_TITLE_PAD_PTS,
            MIN_COMBINED_TITLE_PAD_PTS,
            MAX_COMBINED_TITLE_PAD_PTS,
        )
        suptitle_pad_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_suptitle_pad_pts, float),
            DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
            MIN_COMBINED_SUPTITLE_PAD_PTS,
            MAX_COMBINED_SUPTITLE_PAD_PTS,
        )
        suptitle_y_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_suptitle_y, float),
            DEFAULT_COMBINED_SUPTITLE_Y,
            MIN_COMBINED_SUPTITLE_Y,
            MAX_COMBINED_SUPTITLE_Y,
        )
        top_margin_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_top_margin_pct, float),
            DEFAULT_COMBINED_TOP_MARGIN_PCT,
            MIN_COMBINED_TOP_MARGIN_PCT,
            MAX_COMBINED_TOP_MARGIN_PCT,
        )
        export_pad_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_export_pad_pts, float),
            DEFAULT_COMBINED_EXPORT_PAD_PTS,
            MIN_COMBINED_EXPORT_PAD_PTS,
            MAX_COMBINED_EXPORT_PAD_PTS,
        )
        self.combined_left_padding_pct.set(left_pad_value)
        self.combined_right_padding_pct.set(right_pad_value)
        self.combined_title_pad_pts.set(title_pad_value)
        self.combined_suptitle_pad_pts.set(suptitle_pad_value)
        self.combined_suptitle_y.set(suptitle_y_value)
        self.combined_top_margin_pct.set(top_margin_value)
        self.combined_export_pad_pts.set(export_pad_value)
        suptitle_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_suptitle_fontsize, float),
            DEFAULT_COMBINED_SUPTITLE_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        title_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_title_fontsize, float),
            DEFAULT_COMBINED_TITLE_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        label_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_label_fontsize, float),
            DEFAULT_COMBINED_LABEL_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        tick_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_tick_fontsize, float),
            DEFAULT_COMBINED_TICK_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        legend_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_legend_fontsize, float),
            DEFAULT_COMBINED_LEGEND_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        cycle_legend_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_cycle_legend_fontsize, float),
            legend_font_value,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        family_value = (self.combined_font_family.get() or "").strip()
        self.combined_suptitle_fontsize.set(suptitle_font_value)
        self.combined_title_fontsize.set(title_font_value)
        self.combined_label_fontsize.set(label_font_value)
        self.combined_tick_fontsize.set(tick_font_value)
        self.combined_legend_fontsize.set(legend_font_value)
        self.combined_cycle_legend_fontsize.set(cycle_legend_font_value)
        self.combined_font_family.set(family_value)
        settings["combined_left_pad_pct"] = left_pad_value
        settings["combined_right_pad_pct"] = right_pad_value
        settings["combined_title_pad_pts"] = title_pad_value
        settings["combined_suptitle_pad_pts"] = suptitle_pad_value
        settings["combined_suptitle_y"] = suptitle_y_value
        settings["combined_top_margin_pct"] = top_margin_value
        settings["combined_export_pad_pts"] = export_pad_value
        settings["combined_suptitle_fontsize"] = suptitle_font_value
        settings["combined_title_fontsize"] = title_font_value
        settings["combined_label_fontsize"] = label_font_value
        settings["combined_tick_fontsize"] = tick_font_value
        settings["combined_legend_fontsize"] = legend_font_value
        settings["combined_cycle_legend_fontsize"] = cycle_legend_font_value
        settings["combined_font_family"] = family_value
        settings["combined_legend_wrap"] = bool(self.combined_legend_wrap.get())
        legend_rows_value = self._safe_get_var(self.combined_legend_rows, int)
        legend_rows_value = max(1, legend_rows_value)
        self.combined_legend_rows.set(legend_rows_value)
        settings["combined_legend_rows"] = legend_rows_value
        legend_gap_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_legend_label_gap, float),
            DEFAULT_COMBINED_LEGEND_GAP_PTS,
            MIN_COMBINED_LEGEND_GAP_PTS,
            MAX_COMBINED_LEGEND_GAP_PTS,
        )
        self.combined_legend_label_gap.set(legend_gap_value)
        settings["combined_legend_gap_pts"] = legend_gap_value
        xlabel_tick_gap_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_xlabel_tick_gap, float),
            DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS,
            MIN_COMBINED_XLABEL_TICK_GAP_PTS,
            MAX_COMBINED_XLABEL_TICK_GAP_PTS,
        )
        self.combined_xlabel_tick_gap.set(xlabel_tick_gap_value)
        settings["combined_xlabel_tick_gap_pts"] = xlabel_tick_gap_value
        legend_margin_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_legend_bottom_margin, float),
            DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
            MIN_COMBINED_LEGEND_MARGIN_PTS,
            MAX_COMBINED_LEGEND_MARGIN_PTS,
        )
        self.combined_legend_bottom_margin.set(legend_margin_value)
        settings["combined_legend_bottom_margin_pts"] = legend_margin_value
        settings.pop("combined_legend_panel_height", None)
        legend_alignment_value = (
            self.combined_legend_alignment.get() or ""
        ).strip().lower() or "center"
        if legend_alignment_value not in {"left", "center", "right"}:
            legend_alignment_value = "center"
        self.combined_legend_alignment.set(legend_alignment_value)
        settings["combined_legend_alignment"] = legend_alignment_value
        legend_fill_color_value = _normalize_color(
            self.combined_legend_shadowbox_fill_color.get(),
            DEFAULT_LEGEND_SHADOWBOX_FILL_COLOR,
        )
        self.combined_legend_shadowbox_fill_color.set(legend_fill_color_value)
        settings["combined_legend_shadowbox_fill_color"] = legend_fill_color_value
        cycle_loc_choices = {
            "upper right",
            "upper left",
            "lower right",
            "lower left",
            "center right",
            "center left",
            "upper center",
            "lower center",
            "center",
        }
        cycle_loc_choice_value = (
            (self.combined_cycle_legend_loc_choice.get() or "").strip().lower()
        )
        if cycle_loc_choice_value not in cycle_loc_choices:
            cycle_loc_choice_value = "upper right"
        self.combined_cycle_legend_loc_choice.set(cycle_loc_choice_value)
        settings["combined_cycle_legend_loc_choice"] = cycle_loc_choice_value
        ref_axis_value = _normalize_combined_cycle_ref_axis(
            self.combined_cycle_legend_ref_axis.get()
        )
        self.combined_cycle_legend_ref_axis.set(ref_axis_value)
        settings["combined_cycle_legend_ref_axis"] = ref_axis_value
        ref_corner_value = _normalize_combined_cycle_ref_corner(
            self.combined_cycle_legend_ref_corner.get()
        )
        self.combined_cycle_legend_ref_corner.set(ref_corner_value)
        settings["combined_cycle_legend_ref_corner"] = ref_corner_value

        try:
            self._mark_plot_layout_dirty("fig_combined_triple_axis")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if not skip_save:
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _close_combined_layout_tuner(self) -> None:
        """Close combined layout tuner.
        Used by UI actions to close combined layout tuner safely."""
        window = getattr(self, "_combined_layout_tuner_window", None)
        if window is not None:
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._combined_layout_tuner_window = None

    def _apply_combined_layout_values(self) -> None:
        """Apply combined layout values.
        Used to apply combined layout values changes to live state."""
        legend_gap_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_legend_label_gap, float),
            DEFAULT_COMBINED_LEGEND_GAP_PTS,
            MIN_COMBINED_LEGEND_GAP_PTS,
            MAX_COMBINED_LEGEND_GAP_PTS,
        )
        xlabel_tick_gap_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_xlabel_tick_gap, float),
            DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS,
            MIN_COMBINED_XLABEL_TICK_GAP_PTS,
            MAX_COMBINED_XLABEL_TICK_GAP_PTS,
        )
        legend_margin_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_legend_bottom_margin, float),
            DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
            MIN_COMBINED_LEGEND_MARGIN_PTS,
            MAX_COMBINED_LEGEND_MARGIN_PTS,
        )
        self.combined_legend_label_gap.set(legend_gap_value)
        self.combined_xlabel_tick_gap.set(xlabel_tick_gap_value)
        self.combined_legend_bottom_margin.set(legend_margin_value)
        settings["combined_legend_gap_pts"] = legend_gap_value
        settings["combined_xlabel_tick_gap_pts"] = xlabel_tick_gap_value
        settings["combined_legend_bottom_margin_pts"] = legend_margin_value
        settings.pop("combined_legend_panel_height", None)
        self._combined_layout_dirty = True
        try:
            self._schedule_save_settings()
        except Exception:
            try:
                _save_settings_to_disk()
            except Exception:
                pass
        self._schedule_combined_preview_refresh()

    def _apply_combined_layout_preset(self, preset_name: str) -> None:
        """Apply combined layout preset.
        Used to apply combined layout preset changes to live state."""
        preset_key = (preset_name or "").strip().lower()
        if preset_key == "tight":
            scale = 0.6
        elif preset_key == "airy":
            scale = 1.25
        else:
            scale = 1.0
        self.combined_legend_label_gap.set(DEFAULT_COMBINED_LEGEND_GAP_PTS * scale)
        self.combined_xlabel_tick_gap.set(DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS * scale)
        self.combined_legend_bottom_margin.set(
            DEFAULT_COMBINED_LEGEND_MARGIN_PTS * scale
        )
        self._apply_combined_layout_values()

    def _reset_combined_layout_defaults(self) -> None:
        """Perform reset combined layout defaults.
        Used to keep the workflow logic localized and testable."""
        self.combined_legend_label_gap.set(DEFAULT_COMBINED_LEGEND_GAP_PTS)
        self.combined_xlabel_tick_gap.set(DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS)
        self.combined_legend_bottom_margin.set(DEFAULT_COMBINED_LEGEND_MARGIN_PTS)
        self._apply_combined_layout_values()

    def _schedule_combined_preview_refresh(self) -> None:
        """Schedule combined preview refresh.
        Used to queue combined preview refresh without blocking the UI."""
        after_id = getattr(self, "_combined_preview_after_id", None)
        if after_id is not None:
            try:
                self.after_cancel(after_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            self._combined_preview_after_id = self.after(
                200, self._refresh_combined_preview_now
            )
        except Exception:
            self._combined_preview_after_id = None
            self._refresh_combined_preview_now()

    def _refresh_combined_preview_now(self) -> None:
        """Refresh the combined preview immediately.

        Purpose:
            Force a combined plot refresh for the active preview tab.
        Why:
            Keeps combined plot layout changes visible without manual reloads.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Triggers a plot refresh and logs debug/perf timing when enabled.
        Exceptions:
            Best-effort guards suppress UI refresh failures.
        """
        if getattr(self, "_combined_preview_after_id", None) is not None:
            self._combined_preview_after_id = None

        combined_tab = None
        combined_canvas = None
        if hasattr(self, "_plot_tabs"):
            # Iterate over indexed elements from list(self._plot_tabs to apply the per-item logic.
            for idx, tab in enumerate(list(self._plot_tabs)):
                try:
                    if self.nb.tab(tab, "text") == "Figure 1+2: Combined Triple-Axis":
                        combined_tab = tab
                        if idx < len(self._canvases):
                            combined_canvas = self._canvases[idx]
                        break
                except Exception:
                    continue
        if combined_tab is None or combined_canvas is None:
            return

        try:
            start_fig = getattr(combined_canvas, "figure", None)
        except Exception:
            start_fig = None
        start_fig_id = id(start_fig) if start_fig is not None else None
        self._dbg("plotting.render", "Combined preview refresh start fig_id=%s", start_fig_id)
        try:
            with self._perf_time("plotting.render", "combined_preview_refresh"):
                self._force_plot_refresh(combined_tab, combined_canvas)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            end_fig = getattr(combined_canvas, "figure", None)
        except Exception:
            end_fig = None
        end_fig_id = id(end_fig) if end_fig is not None else None
        self._dbg("plotting.render", "Combined preview refresh end fig_id=%s", end_fig_id)

    def _open_combined_layout_tuner(self) -> None:
        """Open combined layout tuner.
        Used by UI actions to open combined layout tuner."""
        existing = getattr(self, "_combined_layout_tuner_window", None)
        if existing is not None and existing.winfo_exists():
            try:
                existing.deiconify()
                existing.lift()
                existing.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        window = tk.Toplevel(self)
        window.title("Combined Plot Layout Tuner")
        window.transient(self)
        window.resizable(False, False)
        self._combined_layout_tuner_window = window

        container = ttk.Frame(window, padding=12)
        container.grid(row=0, column=0, sticky="nsew")
        container.grid_columnconfigure(1, weight=1)

        stage_legend_gap = tk.DoubleVar(value=self.combined_legend_label_gap.get())
        stage_xlabel_gap = tk.DoubleVar(value=self.combined_xlabel_tick_gap.get())
        stage_legend_margin = tk.DoubleVar(
            value=self.combined_legend_bottom_margin.get()
        )

        ttk.Label(
            container,
            text="Adjust combined plot spacing. Changes apply on Apply or Close.",
            wraplength=440,
        ).grid(row=0, column=0, columnspan=4, sticky="w", pady=(0, 8))

        preset_frame = ttk.Frame(container)
        preset_frame.grid(row=1, column=0, columnspan=4, sticky="w", pady=(0, 8))
        ttk.Label(preset_frame, text="Presets:").pack(side="left", padx=(0, 6))

        # Closure captures _open_combined_layout_tuner state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_combined_layout_tuner.
        def _apply_stage_preset(preset_name: str) -> None:
            """Apply stage preset.
            Used to apply stage preset changes to live state."""
            preset_key = (preset_name or "").strip().lower()
            if preset_key == "tight":
                scale = 0.6
            elif preset_key == "airy":
                scale = 1.25
            else:
                scale = 1.0
            stage_legend_gap.set(DEFAULT_COMBINED_LEGEND_GAP_PTS * scale)
            stage_xlabel_gap.set(DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS * scale)
            stage_legend_margin.set(DEFAULT_COMBINED_LEGEND_MARGIN_PTS * scale)

        # Closure captures _open_combined_layout_tuner local context to keep helper logic scoped and invoked directly within _open_combined_layout_tuner.
        def _reset_stage_defaults() -> None:
            """Perform reset stage defaults.
            Used to keep the workflow logic localized and testable."""
            stage_legend_gap.set(DEFAULT_COMBINED_LEGEND_GAP_PTS)
            stage_xlabel_gap.set(DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS)
            stage_legend_margin.set(DEFAULT_COMBINED_LEGEND_MARGIN_PTS)

        # Closure captures _open_combined_layout_tuner state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_combined_layout_tuner.
        def _commit_stage(close_after: bool = False) -> None:
            """Perform commit stage.
            Used to keep the workflow logic localized and testable."""
            self.combined_legend_label_gap.set(stage_legend_gap.get())
            self.combined_xlabel_tick_gap.set(stage_xlabel_gap.get())
            self.combined_legend_bottom_margin.set(stage_legend_margin.get())
            self._apply_combined_layout_values()
            if close_after:
                self._close_combined_layout_tuner()

        ttk.Button(
            preset_frame,
            text="Tight",
            command=lambda: _apply_stage_preset("tight"),
        ).pack(side="left", padx=(0, 6))
        ttk.Button(
            preset_frame,
            text="Normal",
            command=lambda: _apply_stage_preset("normal"),
        ).pack(side="left", padx=(0, 6))
        ttk.Button(
            preset_frame,
            text="Airy",
            command=lambda: _apply_stage_preset("airy"),
        ).pack(side="left")

        # Closure captures _open_combined_layout_tuner local context to keep helper logic scoped and invoked directly within _open_combined_layout_tuner.
        def _build_spacing_row(
            row: int,
            label: str,
            var: tk.DoubleVar,
            min_value: float,
            max_value: float,
            increment: float,
        ) -> None:
            """Build spacing row.
            Used to assemble spacing row during UI or plot setup."""
            ttk.Label(container, text=label).grid(
                row=row, column=0, sticky="w", padx=(0, 6), pady=2
            )
            scale = ttk.Scale(
                container,
                from_=min_value,
                to=max_value,
                orient="horizontal",
                variable=var,
            )
            scale.grid(row=row, column=1, sticky="ew", pady=2)
            spin = ttk.Spinbox(
                container,
                from_=min_value,
                to=max_value,
                increment=increment,
                textvariable=var,
                width=8,
            )
            spin.grid(row=row, column=2, sticky="w", pady=2)
            ttk.Label(container, text="pt").grid(
                row=row, column=3, sticky="w", padx=(4, 0)
            )

        _build_spacing_row(
            2,
            "Legend to plot gap",
            stage_legend_gap,
            MIN_COMBINED_LEGEND_GAP_PTS,
            MAX_COMBINED_LEGEND_GAP_PTS,
            0.5,
        )
        _build_spacing_row(
            3,
            "X-label to tick gap",
            stage_xlabel_gap,
            MIN_COMBINED_XLABEL_TICK_GAP_PTS,
            MAX_COMBINED_XLABEL_TICK_GAP_PTS,
            0.5,
        )
        _build_spacing_row(
            4,
            "Bottom margin below legend",
            stage_legend_margin,
            MIN_COMBINED_LEGEND_MARGIN_PTS,
            MAX_COMBINED_LEGEND_MARGIN_PTS,
            0.5,
        )

        button_frame = ttk.Frame(container)
        button_frame.grid(row=5, column=0, columnspan=4, sticky="e", pady=(8, 0))
        ttk.Button(
            button_frame,
            text="Reset to Defaults",
            command=_reset_stage_defaults,
        ).pack(side="left", padx=(0, 8))
        ttk.Button(
            button_frame, text="Apply", command=lambda: _commit_stage(False)
        ).pack(side="left", padx=(0, 8))
        ttk.Button(
            button_frame, text="Close", command=lambda: _commit_stage(True)
        ).pack(side="left")

        window.protocol("WM_DELETE_WINDOW", lambda: _commit_stage(True))

    def _combined_axis_label_overrides(self) -> Dict[str, str]:
        """Perform combined axis label overrides.
        Used to keep the workflow logic localized and testable."""
        return {
            "x": (self.combined_x_axis_label.get() or "").strip(),
            "primary": (self.combined_primary_axis_label.get() or "").strip(),
            "derivative": (self.combined_deriv_axis_label.get() or "").strip(),
            "temperature": (self.combined_temp_axis_label.get() or "").strip(),
        }

    def _combined_axis_labelpad_overrides(self) -> Dict[str, float]:
        """Perform combined axis labelpad overrides.
        Used to keep the workflow logic localized and testable."""
        pads: Dict[str, float] = {}
        sources = (
            ("primary", self.combined_primary_labelpad),
            ("temperature", self.combined_temp_labelpad),
            ("derivative", self.combined_deriv_labelpad),
        )
        # Iterate over sources to apply the per-item logic.
        for key, var in sources:
            try:
                value = float(self._safe_get_var(var, float))
            except Exception:
                continue
            if math.isfinite(value):
                pads[key] = value
        return pads

    def _valid_combined_dataset_keys(self) -> List[str]:
        """Perform valid combined dataset keys.
        Used to keep the workflow logic localized and testable."""
        return ["y1", "y3", "y2", "z", "z2"]

    def _normalize_combined_axis_key(self, key: Any) -> Optional[str]:
        """Normalize combined axis key.
        Used to keep combined axis key consistent across workflows and persistence."""
        if key is None:
            return None
        candidate = str(key).strip().lower()
        if not candidate:
            return None
        if candidate in self._valid_combined_dataset_keys():
            return candidate
        # allow parsing values like "y1 (Primary)" by splitting on whitespace or punctuation
        for token in re.split(r"[\\s/|,-]+", candidate):
            if token in self._valid_combined_dataset_keys():
                return token
        return None

    def _sanitize_combined_axis_keys(
        self, left: Any, right: Any, third: Any
    ) -> Tuple[str, str, str]:
        """Sanitize combined axis keys.
        Used to strip or normalize combined axis keys before use."""
        valid: Set[str] = set(self._valid_combined_dataset_keys())
        defaults: Tuple[str, str, str] = ("y1", "z", "y2")
        requested = (
            self._normalize_combined_axis_key(left),
            self._normalize_combined_axis_key(right),
            self._normalize_combined_axis_key(third),
        )
        resolved: List[str] = []
        # Iterate over indexed elements from requested to apply the per-item logic.
        for idx, req in enumerate(requested):
            if req in valid:
                resolved.append(req)
            else:
                resolved.append(defaults[idx])
        return tuple(resolved)  # type: ignore

    def _combined_dataset_label(self, key: str) -> str:
        """Perform combined dataset label.
        Used to keep the workflow logic localized and testable."""
        label_map = getattr(self, "_series_label_map", {}) or {}
        fallback_labels = {
            "y1": "Primary Y (Reactor, PSI)",
            "y3": "Primary Y (Manifold, PSI)",
            "y2": "Secondary Y (Derivative)",
            "z": "Temperature Trace (Internal)",
            "z2": "Temperature Trace 2 (External)",
        }
        return label_map.get(key, fallback_labels.get(key, key.upper()))

    def _combined_axis_options(self) -> List[str]:
        """Perform combined axis options.
        Used to keep the workflow logic localized and testable."""
        # Always expose all potential combined datasets to keep selections distinct.
        return list(self._valid_combined_dataset_keys())

    def _refresh_combined_axis_choices(self) -> None:
        """Refresh combined axis choices.
        Used to sync combined axis choices with current settings."""
        keys = self._combined_axis_options()
        if not keys:
            return
        display_map: Dict[str, str] = {}
        # Iterate over keys to apply the per-item logic.
        for key in keys:
            label_text = self._combined_dataset_label(key)
            suffix = key.upper()
            display_map[key] = f"{label_text} ({suffix})" if label_text else suffix
        values = tuple(display_map.values())
        self._combined_axis_display_map = {
            display: key for key, display in display_map.items()
        }
        # Iterate to apply the per-item logic.
        for combo in (
            getattr(self, "_combined_left_combo", None),
            getattr(self, "_combined_right_combo", None),
            getattr(self, "_combined_third_combo", None),
        ):
            if combo is not None:
                combo["values"] = values

        left_key, right_key, third_key = self._sanitize_combined_axis_keys(
            self.combined_y_left_key.get(),
            self.combined_y_right_key.get(),
            self.combined_y_third_key.get(),
        )
        self.combined_y_left_key.set(left_key)
        self.combined_y_right_key.set(right_key)
        self.combined_y_third_key.set(third_key)
        self._combined_left_display_var.set(display_map.get(left_key, left_key))
        self._combined_right_display_var.set(display_map.get(right_key, right_key))
        self._combined_third_display_var.set(display_map.get(third_key, third_key))
        self._combined_axis_last_values = {
            "left": left_key,
            "right": right_key,
            "third": third_key,
        }

    def _sync_combined_axis_display(self) -> None:
        """Perform sync combined axis display.
        Used to keep the workflow logic localized and testable."""
        # Ensure the visible textvariables mirror the stored key variables.
        display_map = {
            v: k for k, v in getattr(self, "_combined_axis_display_map", {}).items()
        }
        self._combined_left_display_var.set(
            display_map.get(
                self.combined_y_left_key.get(), self.combined_y_left_key.get()
            )
        )
        self._combined_right_display_var.set(
            display_map.get(
                self.combined_y_right_key.get(), self.combined_y_right_key.get()
            )
        )
        self._combined_third_display_var.set(
            display_map.get(
                self.combined_y_third_key.get(), self.combined_y_third_key.get()
            )
        )

    def _persist_combined_axis_keys(self) -> None:
        """Perform persist combined axis keys.
        Used to keep the workflow logic localized and testable."""
        settings["combined_y_left_key"] = self.combined_y_left_key.get()
        settings["combined_y_right_key"] = self.combined_y_right_key.get()
        settings["combined_y_third_key"] = self.combined_y_third_key.get()
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _on_combined_axis_change(self, axis: str, value: str) -> None:
        """Handle combined axis change.
        Used as an event callback for combined axis change."""
        display_map = getattr(self, "_combined_axis_display_map", {}) or {}
        new_key = display_map.get(value) or self._normalize_combined_axis_key(value)
        if new_key is None:
            self._sync_combined_axis_display()
            return

        current = {
            "left": self.combined_y_left_key.get(),
            "right": self.combined_y_right_key.get(),
            "third": self.combined_y_third_key.get(),
        }
        current[axis] = new_key

        left_key, right_key, third_key = self._sanitize_combined_axis_keys(
            current["left"], current["right"], current["third"]
        )
        self.combined_y_left_key.set(left_key)
        self.combined_y_right_key.set(right_key)
        self.combined_y_third_key.set(third_key)
        self._combined_axis_last_values = {
            "left": left_key,
            "right": right_key,
            "third": third_key,
        }
        self._sync_combined_axis_display()
        self._persist_combined_axis_keys()

    def _combined_second_refresh_disabled(self) -> bool:
        """Return whether the combined second refresh pass is disabled by preference.

        Purpose:
            Centralize access to the user toggle for combined adaptive refresh pass 2.
        Why:
            Multiple combined refresh paths need one consistent on/off decision.
        Inputs:
            None.
        Outputs:
            Boolean flag indicating whether pass 2 must be disabled.
        Side Effects:
            None.
        Exceptions:
            None.
        """
        return bool(settings.get("combined_disable_second_refresh", False))

    def _combined_overlay_default_target_refreshes(self) -> int:
        """Return the default combined refresh pass target from current preferences.

        Purpose:
            Derive the baseline combined refresh pass count (1 or 2).
        Why:
            Reset paths and fallback reads should share one preference-aware target.
        Inputs:
            None.
        Outputs:
            Integer pass count (1 when disabled, otherwise 2).
        Side Effects:
            None.
        Exceptions:
            None.
        """
        return 1 if self._combined_second_refresh_disabled() else 2

    def _close_plot_render_settings_dialog(self) -> None:
        """Close the Plot Render Settings dialog.

        Purpose:
            Destroy the render settings window and clear tracked references.
        Why:
            Preferences dialogs must clean up state for reliable reopen behavior.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Destroys the dialog window when present.
        Exceptions:
            Destruction errors are guarded to avoid UI interruption.
        """
        window = getattr(self, "_plot_render_settings_window", None)
        if window is not None:
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._plot_render_settings_window = None

    def _open_plot_render_settings_dialog(self) -> None:
        """Open the Plot Render Settings preference dialog.

        Purpose:
            Expose render behavior toggles for combined triple-axis previews.
        Why:
            The second adaptive refresh pass needs a user-controlled disable switch
            for validation and hardening of the combined render pipeline.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Creates/updates a preferences dialog, persists settings, and can
            trigger a combined plot refresh for immediate feedback.
        Exceptions:
            Dialog and persistence errors are guarded to keep UI responsive.
        """
        existing = getattr(self, "_plot_render_settings_window", None)
        if existing is not None and existing.winfo_exists():
            try:
                existing.deiconify()
                existing.lift()
                existing.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        self._combined_disable_second_refresh_var.set(
            self._combined_second_refresh_disabled()
        )
        window = tk.Toplevel(self)
        window.title("Plot Render Settings")
        window.transient(self)
        window.resizable(False, False)
        window.protocol("WM_DELETE_WINDOW", self._close_plot_render_settings_dialog)
        self._plot_render_settings_window = window

        container = ttk.Frame(window, padding=12)
        container.grid(row=0, column=0, sticky="nsew")
        container.grid_columnconfigure(0, weight=1)

        ttk.Label(
            container,
            text=(
                "Configure combined triple-axis render pass behavior for debugging "
                "and adaptive refresh hardening."
            ),
            wraplength=520,
            justify="left",
        ).grid(row=0, column=0, sticky="w", pady=(0, 8))

        ttk.Checkbutton(
            container,
            text="Disable second refresh for combined triple-axis plot",
            variable=self._combined_disable_second_refresh_var,
        ).grid(row=1, column=0, sticky="w", pady=(0, 10))

        button_frame = ttk.Frame(container)
        button_frame.grid(row=2, column=0, sticky="e")

        def _apply_settings(close_after: bool = False) -> None:
            """Apply Plot Render Settings preferences to live state.

            Purpose:
                Persist combined second-pass toggle and refresh combined preview.
            Why:
                Users need immediate verification of adaptive refresh behavior.
            Inputs:
                close_after: When True, close the dialog after apply.
            Outputs:
                None.
            Side Effects:
                Updates settings, saves to disk, and refreshes combined plot tab.
            Exceptions:
                Persistence and refresh errors are guarded to avoid UI interruption.
            """
            disabled = bool(self._combined_disable_second_refresh_var.get())
            settings["combined_disable_second_refresh"] = disabled
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._log_plot_tab_debug(
                "Plot Render Settings applied: combined_disable_second_refresh=%s."
                % disabled
            )
            self._refresh_plot_for_plot_id("fig_combined_triple_axis")
            if close_after:
                self._close_plot_render_settings_dialog()

        ttk.Button(
            button_frame, text="Apply", command=lambda: _apply_settings(False)
        ).grid(row=0, column=0, padx=(0, 6))
        ttk.Button(
            button_frame, text="OK", command=lambda: _apply_settings(True)
        ).grid(row=0, column=1, padx=(0, 6))
        ttk.Button(
            button_frame, text="Cancel", command=self._close_plot_render_settings_dialog
        ).grid(row=0, column=2)

    def _close_axis_range_preferences(self) -> None:
        """Close axis range preferences.
        Used by UI actions to close axis range preferences safely."""
        window = getattr(self, "_axis_range_pref_window", None)
        if window is not None:
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._axis_range_pref_window = None

    def _open_axis_range_preferences(self) -> None:
        """Open axis range preferences.
        Used by UI actions to open axis range preferences."""
        if (
            self._axis_range_pref_window is not None
            and self._axis_range_pref_window.winfo_exists()
        ):
            try:
                self._axis_range_pref_window.deiconify()
                self._axis_range_pref_window.lift()
                self._axis_range_pref_window.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        window = tk.Toplevel(self)
        window.title("Axis Auto-Range Settings")
        window.transient(self)
        window.resizable(False, False)
        window.protocol("WM_DELETE_WINDOW", self._close_axis_range_preferences)
        self._axis_range_pref_window = window

        container = ttk.Frame(window, padding=12)
        container.grid(row=0, column=0, sticky="nsew")
        container.grid_columnconfigure(0, weight=1)

        ttk.Label(
            container,
            text=(
                "Choose which axes the automatic range tools update. "
                "Unchecked axes keep the manual min/max you enter."
            ),
            wraplength=480,
            foreground="#444444",
        ).grid(row=0, column=0, sticky="w", pady=(0, 8))

        rows = [
            (
                "Time (X-axis)",
                self.axis_auto_time,
                "Allow automatic limits for the X/time axis.",
            ),
            (
                "Pressure Y axes",
                self.axis_auto_pressure,
                "Auto-range the primary pressure axes (y1/y3).",
            ),
            (
                "Temperature axis",
                self.axis_auto_temp,
                "Auto-range temperature traces when present.",
            ),
            (
                "Derivative axis",
                self.axis_auto_deriv,
                "Auto-range the first-derivative axis.",
            ),
        ]

        # Iterate over indexed elements from rows, start=1 to apply the per-item logic.
        for idx, (label, var, tip) in enumerate(rows, start=1):
            cb = ttk.Checkbutton(container, text=label, variable=var)
            cb.grid(row=idx, column=0, sticky="w", pady=2)
            try:
                self._attach_tooltip(cb, tip)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        btns = ttk.Frame(container)
        btns.grid(row=len(rows) + 1, column=0, sticky="e", pady=(10, 0))
        ttk.Button(
            btns, text="Refresh Axis Ranges", command=self._refresh_axis_ranges
        ).grid(row=0, column=0, padx=(0, 8))
        ttk.Button(btns, text="Close", command=self._close_axis_range_preferences).grid(
            row=0, column=1
        )

    def _open_font_family_dialog(self) -> None:
        """Open font family dialog.
        Used by UI actions to open font family dialog."""
        existing = getattr(self, "_font_family_window", None)
        if existing is not None and existing.winfo_exists():
            try:
                existing.deiconify()
                existing.lift()
                existing.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        window = tk.Toplevel(self)
        window.title("Font Family")
        window.transient(self)
        window.resizable(False, False)
        window.grab_set()
        self._font_family_window = window

        ttk.Label(
            window,
            text="Select a font family to use for plots and tables:",
        ).grid(row=0, column=0, columnspan=2, sticky="w", padx=12, pady=(12, 6))

        font_names = sorted(
            {entry.name for entry in font_manager.fontManager.ttflist if entry.name}
        )
        choices = ["(Default)"] + font_names
        current_family = (settings.get("font_family") or "").strip()
        display_value = current_family if current_family else "(Default)"
        selected_var = tk.StringVar(value=display_value)
        combo = ttk.Combobox(
            window,
            textvariable=selected_var,
            values=choices,
            state="readonly",
            width=36,
        )
        combo.grid(row=1, column=0, columnspan=2, sticky="ew", padx=12, pady=(0, 10))

        button_frame = ttk.Frame(window)
        button_frame.grid(row=2, column=0, columnspan=2, sticky="e", padx=12, pady=10)

        # Closure captures _open_font_family_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_font_family_dialog.
        def _apply_selection() -> None:
            """Apply selection.
            Used to apply selection changes to live state."""
            selection = (selected_var.get() or "").strip()
            selected_family = "" if selection == "(Default)" else selection
            settings["font_family"] = selected_family
            _apply_default_plot_fonts(selected_family)
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                self._refresh_font_family_previews()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            _close_window()

        # Closure captures _open_font_family_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_font_family_dialog.
        def _close_window() -> None:
            """Close window.
            Used by UI actions to close window safely."""
            try:
                window.grab_release()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._font_family_window = None

        window.protocol("WM_DELETE_WINDOW", _close_window)

        ttk.Button(button_frame, text="Apply", command=_apply_selection).grid(
            row=0, column=1, padx=(0, 6)
        )
        ttk.Button(button_frame, text="Cancel", command=_close_window).grid(
            row=0, column=2
        )

    def _open_csv_import_dialog(self) -> None:
        """Open CSV import dialog.
        Used by UI actions to open CSV import dialog."""
        existing = getattr(self, "_csv_import_dialog", None)
        window = getattr(existing, "window", None) if existing is not None else None
        if window is not None and window.winfo_exists():
            try:
                window.deiconify()
                window.lift()
                window.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        # Closure captures _open_csv_import_dialog local context to keep helper logic scoped and invoked directly within _open_csv_import_dialog.
        def _clear_dialog() -> None:
            """Clear dialog.
            Used to reset dialog state safely."""
            self._csv_import_dialog = None

        dialog = CsvImportDialog(self, on_close=_clear_dialog)
        self._csv_import_dialog = dialog

    def _refresh_font_family_previews(self) -> None:
        """Refresh font family previews.
        Used to sync font family previews with current settings."""
        # Iterate to apply the per-item logic.
        for frame, canvas in zip(
            getattr(self, "_plot_tabs", []) or [], getattr(self, "_canvases", []) or []
        ):
            try:
                self._force_plot_refresh(frame, canvas)
            except Exception:
                continue

        cycle_ax = getattr(self, "_cycle_ax", None)
        cycle_canvas = getattr(self, "_cycle_canvas", None)
        if cycle_ax is not None:
            try:
                self._apply_cycle_axis_style(cycle_ax)
                legend = cycle_ax.get_legend()
                if legend is not None:
                    self._apply_cycle_legend_style(legend)
                if cycle_canvas is not None:
                    cycle_canvas.draw_idle()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        structured = getattr(self, "_sol_last_structured", None)
        if structured is not None:
            try:
                self._update_solubility_structured_widgets(structured)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        else:
            try:
                self._update_solubility_plots(None)
                self._update_solubility_preview_plots(None)
                self._update_solubility_sweep_plot(None)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            self._render_sol_simulation_plot()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:
            self._refresh_final_report_preview()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        preview_window = getattr(self, "_final_report_preview_window", None)
        if preview_window is not None and preview_window.winfo_exists():
            try:
                self._open_final_report_preview_window()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _on_output_profile_select(self, _event=None):
        """Handle output profile select.
        Used as an event callback for output profile select."""
        listbox = self._output_profile_listbox
        if listbox is None or not listbox.winfo_exists():
            return
        selection = listbox.curselection()
        if not selection:
            return
        idx = int(selection[0])
        if idx < 0 or idx >= len(self._output_profile_keys):
            return
        key = self._output_profile_keys[idx]
        self._output_profile_selected = key
        self._load_output_profile_into_form(key)

    def _load_output_profile_into_form(self, key: Optional[str]) -> None:
        """Load output profile into form.
        Used when restoring output profile into form from storage."""
        if not key or not self._output_profile_form_vars:
            return
        profile = dict(
            self._output_profiles.get(key) or _sanitize_single_output_profile(key, None)
        )
        defaults = DEFAULT_OUTPUT_PROFILE_SETTINGS.get(key, {}).get("defaults", {})
        label = DEFAULT_OUTPUT_PROFILE_SETTINGS.get(key, {}).get("label", key)
        self._output_profile_title_var.set(label)
        vars_map = self._output_profile_form_vars
        vars_map["mode"].set(profile.get("mode", defaults.get("mode", "auto")))
        vars_map["units"].set(profile.get("units", defaults.get("units", "in")))
        vars_map["width"].set(self._format_profile_value(profile.get("width")))
        vars_map["height"].set(self._format_profile_value(profile.get("height")))
        vars_map["aspect_width"].set(
            self._format_profile_value(profile.get("aspect_width"))
        )
        vars_map["aspect_height"].set(
            self._format_profile_value(profile.get("aspect_height"))
        )
        vars_map["limit_dimension"].set(
            profile.get("limit_dimension", defaults.get("limit_dimension", "width"))
        )
        vars_map["limit_value"].set(
            self._format_profile_value(profile.get("limit_value"))
        )

    def _format_profile_value(self, value: Any) -> str:
        """Format profile value.
        Used to prepare profile value for display or export."""
        try:
            numeric = float(value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return ""
        if not math.isfinite(numeric):
            return ""
        if abs(numeric) >= 1000:
            return f"{numeric:.0f}"
        return f"{numeric:.4g}"

    def _apply_output_profile_changes(self):
        """Apply output profile changes.
        Used to apply output profile changes changes to live state."""
        key = self._output_profile_selected
        if not key or not self._output_profile_form_vars:
            return
        vars_map = self._output_profile_form_vars
        profile = dict(
            self._output_profiles.get(key) or _sanitize_single_output_profile(key, None)
        )
        mode = vars_map["mode"].get()
        units = vars_map["units"].get()
        limit_dimension = vars_map["limit_dimension"].get()
        parent = self._output_pref_window or self

        # Closure captures _apply_output_profile_changes local context to keep helper logic scoped and invoked directly within _apply_output_profile_changes.
        def _parse_positive(raw_value: str) -> Optional[float]:
            """Parse positive.
            Used to interpret positive inputs safely."""
            text = (raw_value or "").strip()
            if not text:
                return None
            try:
                candidate = float(text)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            if not (math.isfinite(candidate) and candidate > 0):
                return None
            return candidate

        width_value = _parse_positive(vars_map["width"].get())
        if width_value is None:
            width_value = profile.get("width")
        height_value = _parse_positive(vars_map["height"].get())
        if height_value is None:
            height_value = profile.get("height")
        aspect_w_value = _parse_positive(vars_map["aspect_width"].get())
        if aspect_w_value is None:
            aspect_w_value = profile.get("aspect_width")
        aspect_h_value = _parse_positive(vars_map["aspect_height"].get())
        if aspect_h_value is None:
            aspect_h_value = profile.get("aspect_height")
        limit_value = _parse_positive(vars_map["limit_value"].get())
        if limit_value is None:
            limit_value = profile.get("limit_value")

        if mode == "fixed":
            if width_value is None or height_value is None:
                messagebox.showerror(
                    "Saved Output Options",
                    "Enter positive width and height values for Fixed mode.",
                    parent=parent,
                )
                return
        if mode == "aspect":
            if (
                aspect_w_value is None
                or aspect_h_value is None
                or limit_value is None
                or limit_dimension not in OUTPUT_PROFILE_LIMIT_DIMENSIONS
            ):
                messagebox.showerror(
                    "Saved Output Options",
                    "Aspect mode requires a width ratio, height ratio, "
                    "and a positive max dimension selection.",
                    parent=parent,
                )
                return

        sanitized = _sanitize_single_output_profile(
            key,
            {
                "mode": mode,
                "units": units,
                "width": width_value,
                "height": height_value,
                "aspect_width": aspect_w_value,
                "aspect_height": aspect_h_value,
                "limit_dimension": limit_dimension,
                "limit_value": limit_value,
            },
        )
        self._output_profiles[key] = sanitized
        self._commit_output_profiles()
        self._load_output_profile_into_form(key)

    def _reset_output_profile_to_defaults(self):
        """Perform reset output profile to defaults.
        Used to keep the workflow logic localized and testable."""
        key = self._output_profile_selected
        if not key:
            return
        defaults = _sanitize_single_output_profile(key, None)
        self._output_profiles[key] = defaults
        self._commit_output_profiles()
        self._load_output_profile_into_form(key)

    def _commit_output_profiles(self) -> None:
        """Perform commit output profiles.
        Used to keep the workflow logic localized and testable."""
        try:
            settings["output_size_profiles"] = copy.deepcopy(self._output_profiles)
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _apply_export_dpi_from_form(self) -> None:
        """Apply export DPI from form.
        Used to apply export DPI from form changes to live state."""
        if self._export_dpi_entry_var is None:
            return
        raw_value = (self._export_dpi_entry_var.get() or "").strip()
        parent = self._output_pref_window or self
        try:
            dpi_value = int(float(raw_value))
        except Exception:
            dpi_value = -1
        if dpi_value <= 0:
            messagebox.showerror(
                "Saved Output Options",
                "Enter a positive DPI value.",
                parent=parent,
            )
            return
        self._export_dpi_var.set(dpi_value)
        settings["export_dpi"] = dpi_value
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _assert_combined_export_size(
        self, fig: Figure, *, expected: Tuple[float, float] = (11.0, 8.5)
    ) -> bool:
        """Export size.
        Used by assert combined workflows to export size."""
        try:
            size = fig.get_size_inches()
        except Exception as exc:
            messagebox.showerror(
                "Export Error", f"Could not read export figure size: {exc}"
            )
            return False
        tol = 0.02
        if abs(size[0] - expected[0]) > tol or abs(size[1] - expected[1]) > tol:
            messagebox.showerror(
                "Export Error",
                "Combined plot export size mismatch. Expected 11x8.5 inches.",
            )
            return False
        return True

    def _get_export_dpi(self) -> int:
        """Return export DPI.
        Used to retrieve export DPI for downstream logic."""
        try:
            dpi_value = int(self._export_dpi_var.get())
        except Exception:
            dpi_value = DEFAULT_EXPORT_DPI
        if dpi_value <= 0:
            dpi_value = DEFAULT_EXPORT_DPI
        return dpi_value

    def _compute_output_dimensions(
        self, profile_key: Optional[str], base_width: float, base_height: float
    ) -> Tuple[float, float]:
        """Compute output dimensions.
        Used to derive output dimensions for analysis or plotting."""
        def _sanitize_size(value: Any, fallback: float) -> float:
            """Sanitize size.
            Used to strip or normalize size before use."""
            try:
                candidate = float(value)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return fallback
            if not (math.isfinite(candidate) and candidate > 0):
                return fallback
            return candidate

        width = _sanitize_size(base_width, 6.0)
        height = _sanitize_size(base_height, 4.0)
        if not profile_key:
            return width, height
        profile = (self._output_profiles or {}).get(profile_key)
        if not profile:
            return width, height
        mode = profile.get("mode", "auto")
        units = profile.get("units", "in")
        dpi = max(1, self._get_export_dpi())

        def _to_inches(value: Any) -> float:
            """Perform to inches.
            Used to keep the workflow logic localized and testable."""
            numeric = _sanitize_size(value, 0.0)
            if numeric <= 0:
                return 0.0
            if units == "px":
                return numeric / dpi
            return numeric

        if mode == "fixed":
            w_in = _to_inches(profile.get("width"))
            h_in = _to_inches(profile.get("height"))
            if w_in > 0 and h_in > 0:
                return w_in, h_in
        elif mode == "aspect":
            ratio_w = _sanitize_size(profile.get("aspect_width"), 0.0)
            ratio_h = _sanitize_size(profile.get("aspect_height"), 0.0)
            limit_value = _to_inches(profile.get("limit_value"))
            limit_dimension = profile.get("limit_dimension", "width")
            if ratio_w > 0 and ratio_h > 0 and limit_value > 0:
                if limit_dimension == "height":
                    height = limit_value
                    width = height * (ratio_w / ratio_h)
                else:
                    width = limit_value
                    height = width * (ratio_h / ratio_w)
                if width > 0 and height > 0:
                    return width, height
        return width, height

    def _open_cycle_trace_settings(self):
        """Open cycle trace settings.
        Used by UI actions to open cycle trace settings."""
        if (
            self._cycle_trace_window is not None
            and self._cycle_trace_window.winfo_exists()
        ):
            try:
                self._cycle_trace_window.deiconify()
                self._cycle_trace_window.lift()
                self._cycle_trace_window.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        win = tk.Toplevel(self)
        win.title("Cycle Analysis Plot Settings")
        win.transient(self)
        win.resizable(False, False)
        self._cycle_trace_window = win

        vars_map = {
            "line_color": tk.StringVar(value=self.cycle_line_color.get()),
            "line_style": tk.StringVar(value=self.cycle_line_style.get()),
            "line_width": tk.StringVar(value=f"{self.cycle_line_width.get():.3f}"),
            "peak_color": tk.StringVar(value=self.cycle_peak_color.get()),
            "trough_color": tk.StringVar(value=self.cycle_trough_color.get()),
            "peak_marker": tk.StringVar(value=self.cycle_peak_marker.get()),
            "trough_marker": tk.StringVar(value=self.cycle_trough_marker.get()),
            "marker_size": tk.StringVar(value=f"{self.cycle_marker_size.get():.3f}"),
        }

        container = ttk.Frame(win, padding=12)
        container.grid(row=0, column=0, sticky="nsew")
        container.grid_columnconfigure(1, weight=1)

        ttk.Label(container, text="Trace line color").grid(
            row=0, column=0, sticky="w", padx=(0, 8), pady=4
        )
        color_frame = ttk.Frame(container)
        color_frame.grid(row=0, column=1, sticky="ew", pady=4)
        color_frame.columnconfigure(1, weight=1)
        line_color_preview = tk.Label(
            color_frame, width=6, relief="groove", borderwidth=1, text="Auto"
        )
        line_color_preview.grid(row=0, column=0, sticky="w")
        line_color_entry = ttk.Entry(
            color_frame, textvariable=vars_map["line_color"], state="readonly"
        )
        line_color_entry.grid(row=0, column=1, sticky="ew", padx=(6, 4))
        ttk.Button(
            color_frame,
            text="Choose...",
            command=lambda: self._choose_cycle_trace_color(
                vars_map["line_color"], "Select Trace Line Color"
            ),
        ).grid(row=0, column=2, padx=(0, 4))
        ttk.Button(
            color_frame,
            text="Clear",
            command=lambda: self._clear_cycle_trace_color(vars_map["line_color"]),
        ).grid(row=0, column=3)
        self._bind_color_preview(vars_map["line_color"], line_color_preview)
        self._attach_tooltip(
            line_color_entry,
            "Set the color used for the pressure trace in the interactive cycle plot and Figure 3.",
        )

        ttk.Label(container, text="Trace line style").grid(
            row=1, column=0, sticky="w", padx=(0, 8), pady=4
        )
        line_style_combo = ttk.Combobox(
            container,
            textvariable=vars_map["line_style"],
            values=LINE_STYLE_CHOICES,
            state="readonly",
        )
        line_style_combo.grid(row=1, column=1, sticky="ew", pady=4)
        self._attach_tooltip(
            line_style_combo,
            "Choose how the pressure trace line is rendered. Select Default for a solid line.",
        )

        ttk.Label(container, text="Trace line width (pt)").grid(
            row=2, column=0, sticky="w", padx=(0, 8), pady=4
        )
        line_width_entry = ttk.Entry(container, textvariable=vars_map["line_width"])
        line_width_entry.grid(row=2, column=1, sticky="ew", pady=4)
        self._attach_tooltip(
            line_width_entry, "Set the linewidth used for the pressure trace."
        )

        ttk.Label(container, text="Peak marker color").grid(
            row=3, column=0, sticky="w", padx=(0, 8), pady=4
        )
        peak_frame = ttk.Frame(container)
        peak_frame.grid(row=3, column=1, sticky="ew", pady=4)
        peak_frame.columnconfigure(1, weight=1)
        peak_preview = tk.Label(
            peak_frame, width=6, relief="groove", borderwidth=1, text="Auto"
        )
        peak_preview.grid(row=0, column=0, sticky="w")
        peak_entry = ttk.Entry(
            peak_frame, textvariable=vars_map["peak_color"], state="readonly"
        )
        peak_entry.grid(row=0, column=1, sticky="ew", padx=(6, 4))
        ttk.Button(
            peak_frame,
            text="Choose...",
            command=lambda: self._choose_cycle_trace_color(
                vars_map["peak_color"], "Select Peak Marker Color"
            ),
        ).grid(row=0, column=2, padx=(0, 4))
        ttk.Button(
            peak_frame,
            text="Clear",
            command=lambda: self._clear_cycle_trace_color(vars_map["peak_color"]),
        ).grid(row=0, column=3)
        self._bind_color_preview(
            vars_map["peak_color"], peak_preview, default_text="Auto"
        )

        ttk.Label(container, text="Trough marker color").grid(
            row=4, column=0, sticky="w", padx=(0, 8), pady=4
        )
        trough_frame = ttk.Frame(container)
        trough_frame.grid(row=4, column=1, sticky="ew", pady=4)
        trough_frame.columnconfigure(1, weight=1)
        trough_preview = tk.Label(
            trough_frame, width=6, relief="groove", borderwidth=1, text="Auto"
        )
        trough_preview.grid(row=0, column=0, sticky="w")
        trough_entry = ttk.Entry(
            trough_frame, textvariable=vars_map["trough_color"], state="readonly"
        )
        trough_entry.grid(row=0, column=1, sticky="ew", padx=(6, 4))
        ttk.Button(
            trough_frame,
            text="Choose...",
            command=lambda: self._choose_cycle_trace_color(
                vars_map["trough_color"], "Select Trough Marker Color"
            ),
        ).grid(row=0, column=2, padx=(0, 4))
        ttk.Button(
            trough_frame,
            text="Clear",
            command=lambda: self._clear_cycle_trace_color(vars_map["trough_color"]),
        ).grid(row=0, column=3)
        self._bind_color_preview(
            vars_map["trough_color"], trough_preview, default_text="Auto"
        )

        ttk.Label(container, text="Peak marker shape").grid(
            row=5, column=0, sticky="w", padx=(0, 8), pady=4
        )
        peak_marker_combo = ttk.Combobox(
            container,
            textvariable=vars_map["peak_marker"],
            values=SCATTER_MARKER_CHOICES,
            state="readonly",
        )
        peak_marker_combo.grid(row=5, column=1, sticky="ew", pady=4)
        self._attach_tooltip(
            peak_marker_combo,
            "Controls the marker shape used for peak points across cycle plots.",
        )

        ttk.Label(container, text="Trough marker shape").grid(
            row=6, column=0, sticky="w", padx=(0, 8), pady=4
        )
        trough_marker_combo = ttk.Combobox(
            container,
            textvariable=vars_map["trough_marker"],
            values=SCATTER_MARKER_CHOICES,
            state="readonly",
        )
        trough_marker_combo.grid(row=6, column=1, sticky="ew", pady=4)
        self._attach_tooltip(
            trough_marker_combo,
            "Controls the marker shape used for trough points across cycle plots.",
        )

        ttk.Label(container, text="Peak / Trough Marker Size (pt²)").grid(
            row=7, column=0, sticky="w", padx=(0, 8), pady=4
        )
        marker_spin = ttk.Spinbox(
            container,
            from_=1,
            to=500,
            increment=1,
            textvariable=vars_map["marker_size"],
        )
        marker_spin.grid(row=7, column=1, sticky="ew", pady=4)
        self._attach_tooltip(
            marker_spin,
            "Maps to Matplotlib scatter s (area in points²) for peak/trough markers.",
        )

        hint = ttk.Label(
            container,
            text=(
                "These settings affect the interactive cycle analysis plot and "
                "Figure 3 exports. Leave color fields blank to use defaults."
            ),
            wraplength=360,
            justify="left",
        )
        hint.grid(row=8, column=0, columnspan=2, sticky="w", pady=(8, 12))

        button_frame = ttk.Frame(container)
        button_frame.grid(row=9, column=0, columnspan=2, sticky="ew")
        button_frame.grid_columnconfigure(0, weight=1)
        status_label = ttk.Label(container, text="", foreground="forest green")
        status_label.grid(row=10, column=0, columnspan=2, sticky="w", pady=(4, 0))

        ttk.Button(
            button_frame,
            text="Apply",
            command=lambda: self._apply_cycle_trace_settings_from_dialog(
                vars_map, status_label
            ),
        ).grid(row=0, column=0, sticky="e", padx=(0, 8))

        # Closure captures _open_cycle_trace_settings state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_cycle_trace_settings.
        def _on_close():
            """Handle close.
            Used as an event callback for close."""
            self._cycle_trace_window = None
            win.destroy()

        ttk.Button(button_frame, text="Close", command=_on_close).grid(
            row=0, column=1, sticky="e"
        )

        win.protocol("WM_DELETE_WINDOW", _on_close)

    def _apply_contamination_tab_visibility(self, *, initial: bool = False) -> None:
        """Apply contamination tab visibility.
        Used to apply contamination tab visibility changes to live state."""
        notebook = getattr(self, "nb", None)
        tab = getattr(self, "tab_contamination", None)

        if notebook is None or tab is None:
            return

        show = bool(self._contamination_tab_visible)

        try:
            tabs = list(notebook.tabs())
        except Exception:
            tabs = []

        tab_id = str(tab)
        currently_added = tab_id in tabs

        if show and not currently_added:
            insert_index: Union[int, str] = "end"
            try:
                tabs = list(notebook.tabs())
                cycle_tab = getattr(self, "tab_cycle", None)
                if cycle_tab is not None:
                    cycle_id = str(cycle_tab)
                    if cycle_id in tabs:
                        insert_index = tabs.index(cycle_id) + 1
            except Exception:
                insert_index = "end"

            try:
                notebook.insert(
                    insert_index,
                    tab,
                    text=self._contamination_tab_title,
                )
            except Exception:
                notebook.add(tab, text=self._contamination_tab_title)

        elif not show and currently_added:
            if notebook.select() == tab_id:
                fallback = getattr(self, "tab_plot", None) or getattr(
                    self, "tab_data", None
                )
                if fallback is not None:
                    try:
                        notebook.select(fallback)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            notebook.forget(tab)

        visible_var = getattr(self, "_visible_tabs_var", None)
        if visible_var is not None:
            try:
                visible_var.set(show)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if not initial:
            settings["show_contamination_tab"] = show
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._apply_tab_order_from_settings(initial=initial)

    def _set_contamination_tab_visible(self, value: bool) -> None:
        """Set contamination tab visible.
        Used to persist contamination tab visible into the current state."""
        desired = bool(value)
        if desired == bool(self._contamination_tab_visible):
            return

        self._contamination_tab_visible = desired
        self._apply_contamination_tab_visibility()

    def _apply_solubility_tab_visibility(self, *, initial: bool = False) -> None:
        """Apply solubility tab visibility.
        Used to apply solubility tab visibility changes to live state."""
        notebook = getattr(self, "nb", None)
        legacy_tab = getattr(self, "tab_solubility", None)
        preview_tab = getattr(self, "tab_solubility_new", None)
        if notebook is None or legacy_tab is None:
            return

        show_legacy = bool(self._solubility_tab_visible)
        show_preview = bool(getattr(self, "_solubility_new_tab_visible", True))
        try:
            current_tabs = list(notebook.tabs())
        except Exception:
            current_tabs = []

        selected = None
        try:
            selected = notebook.select()
        except Exception:
            selected = None

        tabs_to_manage: List[Tuple[Optional[ttk.Frame], str, bool]] = [
            (legacy_tab, self._solubility_tab_title, show_legacy),
            (
                preview_tab,
                getattr(self, "_solubility_new_tab_title", "Advanced Solubility (New)"),
                show_preview,
            ),
        ]

        removed_ids: List[str] = []
        # Iterate over tabs_to_manage to apply the per-item logic.
        for tab_obj, _label, should_show in tabs_to_manage:
            if tab_obj is None or should_show:
                continue
            tab_id = str(tab_obj)
            if tab_id not in current_tabs:
                continue
            if selected == tab_id and not removed_ids:
                fallback = getattr(self, "tab_plot", None) or getattr(
                    self, "tab_data", None
                )
                if fallback is not None:
                    try:
                        notebook.select(fallback)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
            notebook.forget(tab_obj)
            removed_ids.append(tab_id)
            try:
                current_tabs.remove(tab_id)
            except ValueError:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        try:
            current_tabs = list(notebook.tabs())
        except Exception:
            current_tabs = []

        insert_index: Union[int, str] = "end"
        try:
            contam_tab = getattr(self, "tab_contamination", None)
            if contam_tab is not None:
                contam_id = str(contam_tab)
                if contam_id in current_tabs:
                    insert_index = current_tabs.index(contam_id) + 1
        except Exception:
            insert_index = "end"

        # Closure captures _apply_solubility_tab_visibility local context to keep helper logic scoped and invoked directly within _apply_solubility_tab_visibility.
        def _current_index(tab_id: str) -> Optional[int]:
            """Return current index.
            Used to surface index for downstream logic."""
            try:
                return current_tabs.index(tab_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None

        # Iterate over tabs_to_manage to apply the per-item logic.
        for tab_obj, label, should_show in tabs_to_manage:
            if tab_obj is None or not should_show:
                continue
            tab_id = str(tab_obj)
            if tab_id in current_tabs:
                idx = _current_index(tab_id)
                if idx is not None:
                    insert_index = idx + 1
                continue
            try:
                notebook.insert(insert_index, tab_obj, text=label)
            except Exception:
                notebook.add(tab_obj, text=label)
            try:
                current_tabs = list(notebook.tabs())
                idx = current_tabs.index(tab_id)
                insert_index = idx + 1
            except Exception:
                insert_index = "end"

        visible_var = getattr(self, "_solubility_visible_var", None)
        if visible_var is not None:
            try:
                visible_var.set(show_legacy)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        new_visible_var = getattr(self, "_solubility_new_visible_var", None)
        if new_visible_var is not None:
            try:
                new_visible_var.set(show_preview)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if not initial:
            settings["show_solubility_tab"] = show_legacy
            settings["show_solubility_new_tab"] = show_preview
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._apply_tab_order_from_settings(initial=initial)

    def _set_solubility_tab_visible(self, value: bool) -> None:
        """Set solubility tab visible.
        Used to persist solubility tab visible into the current state."""
        desired = bool(value)
        if desired == bool(self._solubility_tab_visible):
            return

        self._solubility_tab_visible = desired
        self._apply_solubility_tab_visibility()

    def _set_solubility_new_tab_visible(self, value: bool) -> None:
        """Set solubility new tab visible.
        Used to persist solubility new tab visible into the current state."""
        desired = bool(value)
        if desired == bool(getattr(self, "_solubility_new_tab_visible", True)):
            return

        self._solubility_new_tab_visible = desired
        self._apply_solubility_tab_visibility()

    # --- Tab order helpers ---

    def _tab_frame_for_key(self, key: str) -> Optional[ttk.Frame]:
        """Perform tab frame for key.
        Used to keep the workflow logic localized and testable."""
        return getattr(self, f"tab_{key}", None)

    def _tab_label_for_key(self, key: str) -> str:
        """Perform tab label for key.
        Used to keep the workflow logic localized and testable."""
        if key == "data":
            return "Data"
        if key == "columns":
            return "Columns"
        if key == "plot":
            return "Plot Settings"
        if key == "cycle":
            return "Cycle Analysis"
        if key == "contamination":
            return getattr(self, "_contamination_tab_title", "Contamination")
        if key == "solubility":
            return getattr(self, "_solubility_tab_title", "Legacy Speciation Tab")
        if key == "solubility_new":
            return getattr(
                self,
                "_solubility_new_tab_title",
                "Advanced Speciation & Equilibrium Engine",
            )
        if key == "final_report":
            return "Final Report"
        return key.replace("_", " ").title()

    def _tab_is_visible(self, key: str) -> bool:
        """Check whether it is visible.
        Used by tab workflows to check visible."""
        if key == "contamination":
            return bool(getattr(self, "_contamination_tab_visible", True))
        if key == "solubility":
            return bool(getattr(self, "_solubility_tab_visible", True))
        if key == "solubility_new":
            return bool(getattr(self, "_solubility_new_tab_visible", True))
        return True

    def _resolved_tab_order(self, *, include_hidden: bool = True) -> List[str]:
        """Perform resolved tab order.
        Used to keep the workflow logic localized and testable."""
        stored = settings.get("tab_order")
        normalized: List[str] = []
        seen: Set[str] = set()
        if isinstance(stored, list):
            # Iterate over stored to apply the per-item logic.
            for key in stored:
                if key in DEFAULT_TAB_ORDER_KEYS and key not in seen:
                    normalized.append(key)
                    seen.add(key)
        # Iterate over DEFAULT_TAB_ORDER_KEYS to apply the per-item logic.
        for key in DEFAULT_TAB_ORDER_KEYS:
            if key not in seen:
                normalized.append(key)
                seen.add(key)
        if normalized and normalized != stored:
            settings["tab_order"] = normalized
        if include_hidden:
            return list(normalized)
        return [key for key in normalized if self._tab_is_visible(key)]

    def _apply_tab_order_from_settings(self, *, initial: bool = False) -> None:
        """Apply tab order from settings.
        Used to apply tab order from settings changes to live state."""
        notebook = getattr(self, "nb", None)
        if notebook is None:
            return
        order = self._resolved_tab_order(include_hidden=True)
        visible_keys = [key for key in order if self._tab_is_visible(key)]
        frames: List[Tuple[str, Optional[ttk.Frame]]] = []
        # Iterate over visible_keys to apply the per-item logic.
        for key in visible_keys:
            frame = self._tab_frame_for_key(key)
            if frame is not None:
                frames.append((key, frame))
        if not frames:
            return
        selected = notebook.select()
        # Iterate over frames to apply the per-item logic.
        for _, frame in frames:
            try:
                notebook.forget(frame)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        # Iterate over indexed elements from frames to apply the per-item logic.
        for index, (key, frame) in enumerate(frames):
            label = self._tab_label_for_key(key)
            try:
                notebook.insert(index, frame, text=label)
            except Exception:
                try:
                    notebook.add(frame, text=label)
                except Exception:
                    pass
        try:
            if selected and selected in notebook.tabs():
                notebook.select(selected)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if not initial:
            self._refresh_tab_order_listbox_if_needed()

    def _refresh_tab_order_listbox_if_needed(self) -> None:
        """Refresh tab order listbox if needed.
        Used to sync tab order listbox if needed with current settings."""
        window = getattr(self, "_tab_layout_window", None)
        if window is None or not window.winfo_exists():
            if window is not None:
                self._tab_layout_window = None
            return
        self._refresh_tab_order_listbox()

    def _refresh_tab_order_listbox(self) -> None:
        """Refresh tab order listbox.
        Used to sync tab order listbox with current settings."""
        listbox = getattr(self, "_tab_order_listbox", None)
        if listbox is None or not listbox.winfo_exists():
            return
        current_key: Optional[str] = None
        selection = listbox.curselection()
        if selection and 0 <= selection[0] < len(self._tab_order_listbox_keys):
            current_key = self._tab_order_listbox_keys[selection[0]]
        visible_keys = self._resolved_tab_order(include_hidden=False)
        listbox.delete(0, "end")
        # Iterate over visible_keys to apply the per-item logic.
        for key in visible_keys:
            listbox.insert("end", self._tab_label_for_key(key))
        self._tab_order_listbox_keys = visible_keys
        if current_key in visible_keys:
            new_index = visible_keys.index(current_key)
            listbox.selection_set(new_index)
            listbox.see(new_index)
        self._update_tab_order_button_states()

    def _update_tab_order_button_states(self) -> None:
        """Update tab order button states.
        Used to keep tab order button states in sync with current state."""
        listbox = getattr(self, "_tab_order_listbox", None)
        if listbox is None or not listbox.winfo_exists():
            return
        size = listbox.size()
        selection = listbox.curselection()
        up_state = "disabled"
        down_state = "disabled"
        if selection:
            index = selection[0]
            if index > 0:
                up_state = "normal"
            if index < size - 1:
                down_state = "normal"
        if self._tab_order_up_button is not None:
            self._tab_order_up_button.configure(state=up_state)
        if self._tab_order_down_button is not None:
            self._tab_order_down_button.configure(state=down_state)

    def _persist_tab_order_from_visible_sequence(self, sequence: List[str]) -> None:
        """Perform persist tab order from visible sequence.
        Used to keep the workflow logic localized and testable."""
        order = self._resolved_tab_order(include_hidden=True)
        visible_set = set(sequence)
        new_order: List[str] = []
        inserted = False
        # Iterate over order to apply the per-item logic.
        for key in order:
            if key in visible_set:
                if not inserted:
                    new_order.extend(sequence)
                    inserted = True
                continue
            new_order.append(key)
        if not inserted:
            new_order.extend(sequence)
        settings["tab_order"] = new_order
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._apply_tab_order_from_settings()

    def _move_tab_order_selection(self, direction: int) -> None:
        """Perform move tab order selection.
        Used to keep the workflow logic localized and testable."""
        listbox = getattr(self, "_tab_order_listbox", None)
        if listbox is None or not listbox.winfo_exists():
            return
        selection = listbox.curselection()
        if not selection:
            return
        index = selection[0]
        target = index + direction
        if target < 0 or target >= len(self._tab_order_listbox_keys):
            return
        self._tab_order_listbox_keys[index], self._tab_order_listbox_keys[target] = (
            self._tab_order_listbox_keys[target],
            self._tab_order_listbox_keys[index],
        )
        self._persist_tab_order_from_visible_sequence(self._tab_order_listbox_keys)
        listbox.selection_clear(0, "end")
        listbox.selection_set(target)
        listbox.see(target)

    def _open_tab_layout_preferences(self) -> None:
        """Open tab layout preferences.
        Used by UI actions to open tab layout preferences."""
        if (
            self._tab_layout_window is not None
            and self._tab_layout_window.winfo_exists()
        ):
            try:
                self._tab_layout_window.deiconify()
                self._tab_layout_window.lift()
                self._tab_layout_window.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        window = tk.Toplevel(self)
        window.title("Tab Layout Preferences")
        window.transient(self)
        window.resizable(False, False)
        window.protocol("WM_DELETE_WINDOW", self._close_tab_layout_preferences)
        self._tab_layout_window = window

        container = ttk.Frame(window, padding=12)
        container.pack(fill="both", expand=True)

        visibility_frame = ttk.LabelFrame(container, text="Visible Tabs")
        visibility_frame.pack(fill="x")
        visibility_frame.grid_columnconfigure(0, weight=1)
        tab_controls = [
            (
                "Show Contamination Calculator Tab",
                self._visible_tabs_var,
                lambda: self._set_contamination_tab_visible(
                    self._visible_tabs_var.get()
                ),
            ),
            (
                "Show Legacy Speciation Tab",
                self._solubility_visible_var,
                lambda: self._set_solubility_tab_visible(
                    self._solubility_visible_var.get()
                ),
            ),
            (
                "Show Advanced Speciation & Equilibrium Engine Tab",
                self._solubility_new_visible_var,
                lambda: self._set_solubility_new_tab_visible(
                    self._solubility_new_visible_var.get()
                ),
            ),
        ]
        # Iterate over indexed elements from tab_controls to apply the per-item logic.
        for idx, (label, var, command) in enumerate(tab_controls):
            ttk.Checkbutton(
                visibility_frame,
                text=label,
                variable=var,
                command=command,
            ).grid(row=idx, column=0, sticky="w", pady=2, padx=4)

        order_frame = ttk.LabelFrame(container, text="Tab Order (visible tabs only)")
        order_frame.pack(fill="both", expand=True, pady=(8, 0))
        order_frame.grid_rowconfigure(0, weight=1)
        order_frame.grid_columnconfigure(0, weight=1)
        listbox = tk.Listbox(
            order_frame,
            activestyle="none",
            height=8,
            exportselection=False,
        )
        listbox.grid(row=0, column=0, sticky="nsew", pady=4, padx=(4, 0))
        scrollbar = ttk.Scrollbar(order_frame, orient="vertical", command=listbox.yview)
        scrollbar.grid(row=0, column=1, sticky="ns", pady=4, padx=(0, 4))
        listbox.configure(yscrollcommand=scrollbar.set)
        button_frame = ttk.Frame(order_frame)
        button_frame.grid(row=0, column=2, sticky="n", padx=(0, 4), pady=4)
        up_button = ttk.Button(
            button_frame,
            text="Up",
            command=lambda: self._move_tab_order_selection(-1),
        )
        up_button.pack(fill="x", pady=2)
        down_button = ttk.Button(
            button_frame,
            text="Down",
            command=lambda: self._move_tab_order_selection(1),
        )
        down_button.pack(fill="x", pady=2)
        self._tab_order_listbox = listbox
        self._tab_order_up_button = up_button
        self._tab_order_down_button = down_button
        listbox.bind(
            "<<ListboxSelect>>", lambda _: self._update_tab_order_button_states()
        )

        listbox.focus_set()
        self._refresh_tab_order_listbox()

    def _close_tab_layout_preferences(self) -> None:
        """Close tab layout preferences.
        Used by UI actions to close tab layout preferences safely."""
        window = getattr(self, "_tab_layout_window", None)
        if window is None:
            return
        try:
            window.destroy()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._tab_layout_window = None
        self._tab_order_listbox = None
        self._tab_order_listbox_keys = []
        self._tab_order_up_button = None
        self._tab_order_down_button = None

    def _start_cycle_loading_indicator(
        self, message: str = "Applying column selection"
    ):
        """Perform start cycle loading indicator.
        Used to keep the workflow logic localized and testable."""
        self._stop_cycle_loading_indicator(restore_text=False)

        self._cycle_loading_message = message
        self._cycle_loading_step = 0
        self._cycle_loading_active = True

        label = getattr(self, "_cycle_sel_label", None)
        if label is not None and label.winfo_exists():
            try:
                label.configure(text=message)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        self._set_cycle_summary(message)
        self._schedule_cycle_loading_pulse()

    def _schedule_cycle_loading_pulse(self):
        """Schedule cycle loading pulse.
        Used to queue cycle loading pulse without blocking the UI."""
        if not getattr(self, "_cycle_loading_active", False):
            return

        label = getattr(self, "_cycle_sel_label", None)
        if label is None or not label.winfo_exists():
            self._cycle_loading_active = False
            return

        dots = "." * (self._cycle_loading_step % 4)
        try:
            label.configure(text=f"{self._cycle_loading_message}{dots}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        self._cycle_loading_step += 1
        self._cycle_loading_after = self.after(700, self._schedule_cycle_loading_pulse)

    def _stop_cycle_loading_indicator(self, *, restore_text: bool = True):
        """Perform stop cycle loading indicator.
        Used to keep the workflow logic localized and testable."""
        if self._cycle_loading_after is not None:
            try:
                self.after_cancel(self._cycle_loading_after)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._cycle_loading_after = None

        self._cycle_loading_active = False
        self._cycle_loading_message = ""

        if restore_text:
            self._refresh_cycle_selection_text()

    def _ensure_cycle_tab(self, *, defer_build=True):
        """Perform ensure cycle tab.
        Used to keep the workflow logic localized and testable."""

        if self.tab_cycle is None:
            self.tab_cycle = ttk.Frame(self.nb)

        if str(self.tab_cycle) not in self.nb.tabs():
            self.nb.add(self.tab_cycle, text="Cycle Analysis")

        self._cycle_tab_added = True

        if not getattr(self, "_cycle_ui_built", False):
            self._start_cycle_tab_build(defer=defer_build)

        return self.tab_cycle

    def _set_cycle_summary_text(self, text: str):
        """Set cycle summary text.
        Used to persist cycle summary text into the current state."""

        normalized = text or "No cycle analysis available yet."

        self._set_cycle_summary(normalized)

    # UI Builders

    def _build_tab_plot_legacy_pre_ctk(self):
        """Build the Plot Settings tab UI.

        Purpose:
            Assemble the Plot Settings tab widgets and bindings.
        Why:
            Centralizes plot configuration controls so titles, ranges, and
            cycle-related preferences remain visible and consistent.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Creates Tk widgets, binds callbacks, and stores widget references.
        Exceptions:
            Best-effort guards in callbacks prevent UI failures from bubbling up.
        """

        f = self.tab_plot
        f.grid_rowconfigure(0, weight=1)
        f.grid_columnconfigure(0, weight=1)

        canvas = tk.Canvas(f, borderwidth=0, highlightthickness=0)
        vscroll = ttk.Scrollbar(f, orient="vertical", command=canvas.yview)
        canvas.configure(yscrollcommand=vscroll.set)
        canvas.grid(row=0, column=0, sticky="nsew")
        vscroll.grid(row=0, column=1, sticky="ns")

        content = ttk.Frame(canvas)
        settings_window = canvas.create_window((0, 0), window=content, anchor="nw")

        # Closure captures _build_tab_plot state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_tab_plot.
        def _refresh_scroll_region(_event=None):
            """Refresh scroll region.
            Used to sync scroll region with current settings."""
            try:
                canvas.configure(scrollregion=canvas.bbox("all"))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Closure captures _build_tab_plot local context to keep helper logic scoped and invoked directly within _build_tab_plot.
        def _expand_width(event):
            """Perform expand width.
            Used to keep the workflow logic localized and testable."""
            try:
                canvas.itemconfigure(settings_window, width=event.width)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        content.bind("<Configure>", _refresh_scroll_region)
        canvas.bind("<Configure>", _expand_width)

        # Closure captures _build_tab_plot local context to keep helper logic scoped and invoked directly within _build_tab_plot.
        def _bind_mousewheel(widget):
            """Perform bind mousewheel.
            Used to keep the workflow logic localized and testable."""
            # Closure captures _bind_mousewheel state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _bind_mousewheel.
            def _on_mousewheel(event):
                """Handle mousewheel.
                Used as an event callback for mousewheel."""
                delta = event.delta
                if delta == 0:
                    return
                step = -1 if delta > 0 else 1
                if abs(delta) >= 120:
                    step = int(-delta / 120)
                canvas.yview_scroll(step, "units")
                return "break"

            widget.bind("<MouseWheel>", _on_mousewheel, add="+")
            widget.bind(
                "<Button-4>", lambda _event: canvas.yview_scroll(-1, "units"), add="+"
            )
            widget.bind(
                "<Button-5>", lambda _event: canvas.yview_scroll(1, "units"), add="+"
            )
            # Iterate over widget.winfo_children() to apply the per-item logic.
            for child in widget.winfo_children():
                _bind_mousewheel(child)

        self.after_idle(lambda: _bind_mousewheel(content))

        # Iterate over the configured range to apply the per-item logic.
        for i in range(4):

            content.grid_columnconfigure(i, weight=1)

        pad = {"padx": 8, "pady": 6}

        # Titles

        lf_titles = ttk.Labelframe(content, text="Titles")

        lf_titles.grid(row=0, column=0, columnspan=4, sticky="ew", **pad)

        lf_titles.grid_columnconfigure(1, weight=1)
        lf_titles.grid_columnconfigure(2, weight=0)

        ttk.Label(lf_titles, text="Suptitle (Job Information)").grid(
            row=0, column=0, sticky="w", padx=6, pady=4
        )

        ttk.Entry(lf_titles, textvariable=self.suptitle_text).grid(
            row=0, column=1, sticky="ew", padx=6, pady=4
        )

        ttk.Label(lf_titles, text="Title").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )

        title_entry = ttk.Entry(lf_titles, textvariable=self.title_text)
        title_entry.grid(
            row=1, column=1, sticky="ew", padx=6, pady=4
        )
        self._title_entry = title_entry

        copy_btn = ttk.Button(
            lf_titles,
            text="Copy Auto Title -> Manual Title",
            command=self._copy_auto_title_to_manual,
        )
        copy_btn.grid(row=1, column=2, sticky="e", padx=6, pady=4)
        self._copy_auto_title_btn = copy_btn

        auto_frame = ttk.Frame(lf_titles)
        auto_frame.grid(
            row=2, column=0, columnspan=3, sticky="ew", padx=6, pady=(2, 6)
        )
        auto_frame.grid_columnconfigure(1, weight=1)

        ttk.Checkbutton(
            auto_frame,
            text="Auto-generate Title",
            variable=self.auto_title_enabled_var,
        ).grid(row=0, column=0, sticky="w", pady=(2, 4))

        ttk.Label(auto_frame, text="Data Type").grid(
            row=1, column=0, sticky="w", padx=(0, 6), pady=2
        )
        type_choices = self._get_title_type_choices()
        type_combo = ttk.Combobox(
            auto_frame,
            textvariable=self.title_data_type_var,
            state="readonly",
            values=type_choices,
        )
        type_combo.grid(row=1, column=1, sticky="ew", padx=6, pady=2)
        self._title_type_combo = type_combo
        ttk.Button(
            auto_frame, text="Manage Types...", command=self._open_manage_title_types_dialog
        ).grid(row=1, column=2, sticky="e", padx=(6, 0), pady=2)

        source_labels = {
            AUTO_TITLE_SOURCE_FULL: "Full dataset (Columns tab)",
            AUTO_TITLE_SOURCE_CURRENT: "Current view range",
        }
        source_label_to_value = {v: k for k, v in source_labels.items()}
        source_display_var = tk.StringVar(
            value=source_labels.get(
                self.auto_title_source_var.get(), source_labels[AUTO_TITLE_SOURCE_FULL]
            )
        )
        self._auto_title_source_display_var = source_display_var

        ttk.Label(auto_frame, text="Auto Title uses").grid(
            row=2, column=0, sticky="w", padx=(0, 6), pady=2
        )
        source_combo = ttk.Combobox(
            auto_frame,
            textvariable=source_display_var,
            state="readonly",
            values=list(source_labels.values()),
        )
        source_combo.grid(row=2, column=1, sticky="ew", padx=6, pady=2)
        self._auto_title_source_combo = source_combo

        day_mode_labels = {
            AUTO_TITLE_DAY_DIFF: "Date diff (end-start)",
            AUTO_TITLE_DAY_INCLUSIVE: "Inclusive (end-start+1)",
        }
        day_mode_label_to_value = {v: k for k, v in day_mode_labels.items()}
        day_mode_display_var = tk.StringVar(
            value=day_mode_labels.get(
                self.auto_title_day_mode_var.get(), day_mode_labels[AUTO_TITLE_DAY_DIFF]
            )
        )
        self._auto_title_day_mode_display_var = day_mode_display_var

        ttk.Label(auto_frame, text="Day count mode").grid(
            row=3, column=0, sticky="w", padx=(0, 6), pady=2
        )
        day_mode_combo = ttk.Combobox(
            auto_frame,
            textvariable=day_mode_display_var,
            state="readonly",
            values=list(day_mode_labels.values()),
        )
        day_mode_combo.grid(row=3, column=1, sticky="ew", padx=6, pady=2)
        self._auto_title_day_mode_combo = day_mode_combo

        ttk.Label(auto_frame, text="Template").grid(
            row=4, column=0, sticky="w", padx=(0, 6), pady=2
        )
        template_entry = ttk.Entry(
            auto_frame, textvariable=self.auto_title_template_var
        )
        template_entry.grid(row=4, column=1, sticky="ew", padx=6, pady=2)
        self._auto_title_template_entry = template_entry
        ttk.Button(
            auto_frame, text="Edit...", command=self._open_auto_title_template_editor
        ).grid(row=4, column=2, sticky="e", padx=(6, 0), pady=2)

        ttk.Label(auto_frame, text="Auto Title Preview").grid(
            row=5, column=0, sticky="w", padx=(0, 6), pady=2
        )
        ttk.Label(
            auto_frame,
            textvariable=self._auto_title_preview_var,
            wraplength=540,
        ).grid(row=5, column=1, columnspan=2, sticky="w", padx=6, pady=2)

        # Closure captures _build_tab_plot local context to keep helper logic scoped and invoked directly within _build_tab_plot.
        def _sync_source_from_display(*_):
            """Perform sync source from display.
            Used to keep the workflow logic localized and testable."""
            label = source_display_var.get()
            value = source_label_to_value.get(label, AUTO_TITLE_SOURCE_FULL)
            if value != self.auto_title_source_var.get():
                self.auto_title_source_var.set(value)

        # Closure captures _build_tab_plot local context to keep helper logic scoped and invoked directly within _build_tab_plot.
        def _sync_source_display(*_):
            """Perform sync source display.
            Used to keep the workflow logic localized and testable."""
            value = self.auto_title_source_var.get()
            label = source_labels.get(value, source_labels[AUTO_TITLE_SOURCE_FULL])
            if label != source_display_var.get():
                source_display_var.set(label)

        # Closure captures _build_tab_plot local context to keep helper logic scoped and invoked directly within _build_tab_plot.
        def _sync_day_mode_from_display(*_):
            """Perform sync day mode from display.
            Used to keep the workflow logic localized and testable."""
            label = day_mode_display_var.get()
            value = day_mode_label_to_value.get(label, AUTO_TITLE_DAY_DIFF)
            if value != self.auto_title_day_mode_var.get():
                self.auto_title_day_mode_var.set(value)

        # Closure captures _build_tab_plot local context to keep helper logic scoped and invoked directly within _build_tab_plot.
        def _sync_day_mode_display(*_):
            """Perform sync day mode display.
            Used to keep the workflow logic localized and testable."""
            value = self.auto_title_day_mode_var.get()
            label = day_mode_labels.get(value, day_mode_labels[AUTO_TITLE_DAY_DIFF])
            if label != day_mode_display_var.get():
                day_mode_display_var.set(label)

        source_display_var.trace_add("write", _sync_source_from_display)
        self.auto_title_source_var.trace_add("write", _sync_source_display)
        day_mode_display_var.trace_add("write", _sync_day_mode_from_display)
        self.auto_title_day_mode_var.trace_add("write", _sync_day_mode_display)

        # Iterate to apply the per-item logic.
        for var in (
            self.auto_title_enabled_var,
            self.auto_title_source_var,
            self.auto_title_template_var,
            self.auto_title_day_mode_var,
            self.title_data_type_var,
        ):
            var.trace_add("write", self._update_auto_title_preview)

        self.auto_title_enabled_var.trace_add(
            "write", self._update_auto_title_controls_state
        )
        self._update_auto_title_controls_state()
        self._update_auto_title_preview()

        # Ranges

        lf_ranges = ttk.Labelframe(content, text="Ranges")

        lf_ranges.grid(row=1, column=0, columnspan=4, sticky="ew", **pad)

        # Time

        fr_time = ttk.Frame(lf_ranges)

        fr_time.grid(row=0, column=0, sticky="w", padx=6, pady=4)

        ttk.Label(fr_time, text="Time (min / max)").grid(row=0, column=0, sticky="w")

        ttk.Entry(fr_time, textvariable=self.min_time, width=10).grid(
            row=0, column=1, padx=6
        )

        ttk.Entry(fr_time, textvariable=self.max_time, width=10).grid(
            row=0, column=2, padx=6
        )

        # Pressure Y

        fr_py = ttk.Frame(lf_ranges)

        fr_py.grid(row=0, column=1, sticky="w", padx=6, pady=4)

        ttk.Label(fr_py, text="Pressure Y (min / max)").grid(
            row=0, column=0, sticky="w"
        )

        ttk.Entry(fr_py, textvariable=self.min_y, width=10).grid(
            row=0, column=1, padx=6
        )

        ttk.Entry(fr_py, textvariable=self.max_y, width=10).grid(
            row=0, column=2, padx=6
        )

        # Temp Y

        fr_ty = ttk.Frame(lf_ranges)

        fr_ty.grid(row=1, column=0, sticky="w", padx=6, pady=4)

        ttk.Label(fr_ty, text="Temp Y °C (min / max)").grid(row=0, column=0, sticky="w")

        ttk.Entry(fr_ty, textvariable=self.twin_y_min, width=10).grid(
            row=0, column=1, padx=6
        )

        ttk.Entry(fr_ty, textvariable=self.twin_y_max, width=10).grid(
            row=0, column=2, padx=6
        )

        # Derivative Y

        fr_dy = ttk.Frame(lf_ranges)

        fr_dy.grid(row=1, column=1, sticky="w", padx=6, pady=4)

        ttk.Label(fr_dy, text="Derivative Y (min / max)").grid(
            row=0, column=0, sticky="w"
        )

        ttk.Entry(fr_dy, textvariable=self.deriv_y_min, width=10).grid(
            row=0, column=1, padx=6
        )

        ttk.Entry(fr_dy, textvariable=self.deriv_y_max, width=10).grid(
            row=0, column=2, padx=6
        )

        # Axes (inside _build_tab_plot)

        lf_axes = ttk.Labelframe(content, text="Axes")

        lf_axes.grid(row=2, column=0, columnspan=4, sticky="ew", **pad)

        # Let columns expand so the combobox has room

        # Iterate over the configured range to apply the per-item logic.
        for c in range(4):

            lf_axes.grid_columnconfigure(c, weight=1)

        ttk.Checkbutton(
            lf_axes, text="Enable Temperature Axis", variable=self.enable_temp_axis
        ).grid(row=0, column=0, sticky="w", padx=6, pady=4)

        ttk.Checkbutton(
            lf_axes, text="Enable Derivative Axis", variable=self.enable_deriv_axis
        ).grid(row=0, column=1, sticky="w", padx=6, pady=4)

        fr_axis_offset = ttk.Frame(lf_axes)

        fr_axis_offset.grid(row=1, column=0, columnspan=2, sticky="w", padx=6, pady=4)

        ttk.Label(fr_axis_offset, text="Combined derivative axis offset").grid(
            row=0, column=0, sticky="w"
        )

        ttk.Entry(
            fr_axis_offset, textvariable=self.combined_deriv_axis_offset, width=6
        ).grid(row=0, column=1, padx=6)

        self._attach_tooltip(
            fr_axis_offset,
            "Moves the derivative spine when drawing the combined triple-axis plot. Values >1.0 push it farther right so ticks stay readable.",
        )

        # Controls for refreshing axes and padding

        axis_button_frame = ttk.Frame(lf_axes)
        axis_button_frame.grid(row=0, column=2, sticky="e", padx=6, pady=4)

        btn_refresh = ttk.Button(
            axis_button_frame,
            text="Refresh Axis Ranges",
            command=self._refresh_axis_ranges,
        )
        btn_refresh.grid(row=0, column=0, padx=(0, 6))

        # Shortcut only: opens Axis Auto-Range Settings without refreshing ranges.
        btn_auto_axis_settings = ttk.Button(
            axis_button_frame,
            text="Auto-Axis Settings...",
            command=self._open_axis_range_preferences,
        )
        btn_auto_axis_settings.grid(row=0, column=1)

        lbl_pad = ttk.Label(lf_axes, text="Span Padding (%)")

        lbl_pad.grid(row=0, column=3, sticky="e", padx=6, pady=4)

        ent_pad = ttk.Entry(lf_axes, textvariable=self.axis_pad_pct, width=6)

        ent_pad.grid(row=0, column=4, sticky="w", padx=6, pady=4)

        # Tooltips:

        self._attach_tooltip(
            btn_refresh, "Recalculate and apply axis min/max from current data."
        )
        self._attach_tooltip(
            btn_auto_axis_settings,
            "Open Axis Auto-Range Settings without applying new ranges.",
        )

        self._attach_tooltip(
            lbl_pad,
            "Y-axis padding as a percent of data span.\nDefault 5%. Increase to add more vertical breathing room.",
        )

        self._attach_tooltip(
            ent_pad, "Y-axis padding as a percent of data span.\nDefault 5%."
        )

        if not getattr(self, "_plot_tab_stage_two_built", False):
            self._build_tab_plot_stage_two(content, pad)

    def _build_tab_plot_stage_two_legacy_pre_ctk(self, f, pad):
        """Build the second stage of the Plot Settings tab.

        Purpose:
            Assemble the remaining Plot Settings sections after initial UI load.
        Why:
            Splitting the build keeps startup responsive while still providing
            the full settings surface once the UI is ready.

        Args:
            f: Parent Tkinter frame holding Plot Settings content.
            pad: Padding dictionary applied to section frames.

        Returns:
            None.

        Side Effects:
            Constructs widgets, binds callbacks, and updates layout state.

        Exceptions:
            Errors are handled internally to keep the UI responsive.
        """

        if getattr(self, "_plot_tab_stage_two_built", False):

            return

        self._plot_tab_stage_two_built = True

        # Gas Model (Van der Waals)

        lf_vdw = ttk.Labelframe(f, text="Gas Model (Van der Waals)")

        lf_vdw.grid(row=3, column=0, columnspan=4, sticky="ew", **pad)

        lf_vdw.grid_columnconfigure(1, weight=1)
        lf_vdw.grid_columnconfigure(2, weight=0)

        ttk.Label(lf_vdw, text="Preset").grid(
            row=0, column=0, sticky="w", padx=6, pady=4
        )

        cb_gas = ttk.Combobox(
            lf_vdw,
            textvariable=self.v_gas,
            state="readonly",
            values=list(GAS_PRESETS.keys()),
        )

        cb_gas.grid(row=0, column=1, sticky="ew", padx=6, pady=4)
        self._gas_combo = cb_gas
        self._refresh_gas_preset_choices()

        cb_gas.bind("<<ComboboxSelected>>", self._on_gas_selected)

        ttk.Button(
            lf_vdw, text="Save Preset", command=self._save_custom_gas_preset
        ).grid(row=0, column=2, sticky="e", padx=6, pady=4)

        ttk.Label(lf_vdw, text="Vessel Volume (L)").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )

        self.e_vol = ttk.Entry(lf_vdw, textvariable=self.v_volume)

        self.e_vol.grid(row=1, column=1, sticky="ew", padx=6, pady=4)

        apply_vdw_frame = ttk.Frame(lf_vdw)
        apply_vdw_frame.grid(row=1, column=2, sticky="e", padx=6, pady=4)
        apply_vdw_frame.grid_columnconfigure(0, weight=1)
        ttk.Button(apply_vdw_frame, text="Apply VDW", command=self._apply_vdw).grid(
            row=0, column=0, sticky="e"
        )
        self._create_vdw_indicator(
            apply_vdw_frame, row=0, column=1, padx=(6, 0), sticky="w"
        )

        ttk.Label(lf_vdw, text="VDW a (L^2*atm/mol^2)").grid(
            row=2, column=0, sticky="w", padx=6, pady=4
        )

        self.e_a = ttk.Entry(lf_vdw, textvariable=self.v_a)

        self.e_a.grid(row=2, column=1, sticky="ew", padx=6, pady=4)

        ttk.Label(lf_vdw, text="VDW b (L/mol)").grid(
            row=3, column=0, sticky="w", padx=6, pady=4
        )

        self.e_b = ttk.Entry(lf_vdw, textvariable=self.v_b)

        self.e_b.grid(row=3, column=1, sticky="ew", padx=6, pady=4)

        ttk.Label(lf_vdw, text="Gaseous Reagent Molar Mass (g/mol)").grid(
            row=4, column=0, sticky="w", padx=6, pady=4
        )

        self.e_gas_molar_mass = ttk.Entry(lf_vdw, textvariable=self.v_gas_molar_mass)

        self.e_gas_molar_mass.grid(row=4, column=1, sticky="ew", padx=6, pady=4)

        # Gaseous reagent configuration

        lf_reagent = ttk.Labelframe(f, text="Starting Material Settings")

        lf_reagent.grid(row=4, column=0, columnspan=4, sticky="ew", **pad)

        lf_reagent.grid_columnconfigure(1, weight=1)

        ttk.Label(
            lf_reagent,
            text="Starting material reacting with selected gas",
        ).grid(row=0, column=0, sticky="w", padx=6, pady=4)

        ent_display_name = ttk.Entry(
            lf_reagent, textvariable=self.v_starting_material_display_name
        )
        ent_display_name.grid(row=0, column=1, sticky="ew", padx=6, pady=4)
        ent_display_name.bind("<FocusOut>", self._apply_product_settings)
        ent_display_name.bind("<Return>", self._apply_product_settings)

        ttk.Label(lf_reagent, text="Starting material note (optional)").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )

        ent_display_note = ttk.Entry(
            lf_reagent, textvariable=self.v_starting_material_display_note
        )
        ent_display_note.grid(row=1, column=1, sticky="ew", padx=6, pady=4)
        ent_display_note.bind("<FocusOut>", self._apply_product_settings)
        ent_display_note.bind("<Return>", self._apply_product_settings)

        ttk.Label(lf_reagent, text="Starting Material Molar Mass (g/mol)").grid(
            row=2, column=0, sticky="w", padx=6, pady=4
        )

        ent_molar = ttk.Entry(lf_reagent, textvariable=self.v_product_molar_mass)

        ent_molar.grid(row=2, column=1, sticky="ew", padx=6, pady=4)

        ent_molar.bind("<FocusOut>", self._apply_product_settings)

        ent_molar.bind("<Return>", self._apply_product_settings)

        ttk.Label(lf_reagent, text="Starting Material Mass (g)").grid(
            row=3, column=0, sticky="w", padx=6, pady=4
        )

        ent_start = ttk.Entry(lf_reagent, textvariable=self.v_starting_mass)

        ent_start.grid(row=3, column=1, sticky="ew", padx=6, pady=4)

        ent_start.bind("<FocusOut>", self._apply_product_settings)

        ent_start.bind("<Return>", self._apply_product_settings)

        ttk.Label(
            lf_reagent,
            text="Stoichiometry (mol gas per mol starting)",
        ).grid(row=4, column=0, sticky="w", padx=6, pady=4)

        ent_stoich = ttk.Entry(lf_reagent, textvariable=self.v_starting_stoich)

        ent_stoich.grid(row=4, column=1, sticky="ew", padx=6, pady=4)

        ent_stoich.bind("<FocusOut>", self._apply_product_settings)

        ent_stoich.bind("<Return>", self._apply_product_settings)

        # Peak & Trough Detection

        lf_peak = ttk.Labelframe(f, text="Peak & Trough Detection")

        lf_peak.grid(row=5, column=0, columnspan=4, sticky="ew", **pad)

        # Iterate over the configured range to apply the per-item logic.
        for c in range(4):

            lf_peak.grid_columnconfigure(c, weight=1)

        lbl_prom = ttk.Label(lf_peak, text="Prominence (PSI)")

        lbl_prom.grid(row=0, column=0, sticky="w", padx=6, pady=4)

        ent_prom = ttk.Entry(lf_peak, textvariable=self.pk_prominence, width=10)

        ent_prom.grid(row=0, column=1, sticky="w", padx=6, pady=4)

        lbl_dist = ttk.Label(lf_peak, text="Min Distance (samples)")

        lbl_dist.grid(row=0, column=2, sticky="e", padx=6, pady=4)

        ent_dist = ttk.Entry(lf_peak, textvariable=self.pk_distance, width=10)

        ent_dist.grid(row=0, column=3, sticky="w", padx=6, pady=4)

        lbl_min_dp = ttk.Label(lf_peak, text="Minimum ΔP for Valid Cycle (PSI)")

        lbl_min_dp.grid(row=1, column=0, sticky="w", padx=6, pady=4)

        ent_min_dp = ttk.Entry(lf_peak, textvariable=self.min_cycle_drop, width=10)

        ent_min_dp.grid(row=1, column=1, sticky="w", padx=6, pady=4)

        lbl_width = ttk.Label(lf_peak, text="Min Width (samples)")

        lbl_width.grid(row=1, column=2, sticky="e", padx=6, pady=4)

        ent_width = ttk.Entry(lf_peak, textvariable=self.pk_width, width=10)

        ent_width.grid(row=1, column=3, sticky="w", padx=6, pady=4)

        text_dist = (
            "Min Distance: minimum separation between neighboring peaks (in samples).\n"
            "Higher = peaks must be farther apart; lower = allows closely spaced peaks.\n"
            "If your sample rate is 1 Hz, a distance of 10 equals ~10 seconds.\n"
        )

        self._attach_tooltip(lbl_dist, text_dist)

        self._attach_tooltip(ent_dist, text_dist)

        text_min_dp = (
            "Minimum delta-P for Valid Cycle: only cycles with peak-to-trough drop at or above\n"
            "this PSI threshold are counted for moles/uptake totals.\n"
        )

        self._attach_tooltip(lbl_min_dp, text_min_dp)

        self._attach_tooltip(ent_min_dp, text_min_dp)

        text_width = (
            "Min Width: minimum peak width at half height (FWHM), in samples.\n"
            "Higher = filters out narrow spikes; lower = allows sharp/narrow peaks."
        )

        self._attach_tooltip(lbl_width, text_width)

        self._attach_tooltip(ent_width, text_width)

        # Cycle integration toggles for core plots
        lf_cycle_integration = ttk.Labelframe(f, text="Cycle Integration")
        lf_cycle_integration.grid(row=6, column=0, columnspan=4, sticky="ew", **pad)
        lf_cycle_integration.grid_columnconfigure(0, weight=1)
        lf_cycle_integration.grid_columnconfigure(1, weight=1)

        ttk.Checkbutton(
            lf_cycle_integration,
            text="Show Cycle Peaks/Troughs on Core Plots",
            variable=self.show_cycle_markers_on_core,
        ).grid(row=0, column=0, sticky="w", padx=6, pady=4)

        ttk.Checkbutton(
            lf_cycle_integration,
            text='Show Cycle Legend on Core Plots (Peaks/Troughs/Cycles/ΔP)',
            variable=self.show_cycle_legend_on_core,
        ).grid(row=0, column=1, sticky="w", padx=6, pady=4)

        ttk.Checkbutton(
            lf_cycle_integration,
            text="Include Moles Summary in Core Plot Legend",
            variable=self.include_moles_core_legend,
        ).grid(row=1, column=0, sticky="w", padx=6, pady=4)

        # Combined cycle legend controls
        lf_cycle_legend = ttk.Labelframe(f, text="Cycle Legend (Combined Plot)")
        lf_cycle_legend.grid(row=7, column=0, columnspan=4, sticky="ew", **pad)
        lf_cycle_legend.grid_columnconfigure(0, weight=1)
        lf_cycle_legend.grid_columnconfigure(1, weight=1)

        # Closure captures _build_tab_plot_stage_two local context to keep helper logic scoped and invoked directly within _build_tab_plot_stage_two.
        def _apply_cycle_legend_controls():
            """Apply cycle legend controls.

            Purpose:
                Persist cycle legend control toggles and apply them immediately.
            Why:
                Users expect drag/lock/persist changes to affect the live combined
                plot without manual refresh.

            Args:
                None.

            Returns:
                None.

            Side Effects:
                Updates settings and refreshes legend tracking on active figures.

            Exceptions:
                Errors are caught by the caller to avoid UI interruption.
            """
            self._sync_combined_cycle_legend_controls(refresh_display=True)

        ttk.Checkbutton(
            lf_cycle_legend,
            text="Enable Cycle Legend Dragging",
            variable=self.combined_cycle_legend_enable_drag,
            command=_apply_cycle_legend_controls,
        ).grid(row=0, column=0, sticky="w", padx=6, pady=4)

        ttk.Checkbutton(
            lf_cycle_legend,
            text="Lock Cycle Legend Position",
            variable=self.combined_cycle_legend_lock_position,
            command=_apply_cycle_legend_controls,
        ).grid(row=0, column=1, sticky="w", padx=6, pady=4)

        ttk.Checkbutton(
            lf_cycle_legend,
            text="Persist Cycle Legend Position (Refresh/Rebuild)",
            variable=self.combined_cycle_legend_persist_position,
            command=_apply_cycle_legend_controls,
        ).grid(row=1, column=0, sticky="w", padx=6, pady=4)

        ttk.Checkbutton(
            lf_cycle_legend,
            text="Clamp Cycle Legend Inside Axes on Capture",
            variable=self.combined_cycle_legend_clamp_to_axes,
            command=_apply_cycle_legend_controls,
        ).grid(row=1, column=1, sticky="w", padx=6, pady=4)

        ttk.Button(
            lf_cycle_legend,
            text="Reset Cycle Legend Position",
            command=self._reset_combined_cycle_legend_position,
        ).grid(row=2, column=0, sticky="w", padx=6, pady=4)

        ttk.Checkbutton(
            lf_cycle_legend,
            text="Enable Main Legend Dragging (Combined Plot)",
            variable=self.combined_main_legend_enable_drag,
            command=_apply_cycle_legend_controls,
        ).grid(row=2, column=1, sticky="w", padx=6, pady=4)

        # Combined triple-axis dataset selection
        lf_combined_axis = ttk.Labelframe(f, text="Combined Triple-Axis Settings")
        lf_combined_axis.grid(row=8, column=0, columnspan=4, sticky="ew", **pad)
        lf_combined_axis.grid_columnconfigure(1, weight=1)

        ttk.Label(lf_combined_axis, text="Inner Left Y Axis Dataset").grid(
            row=0, column=0, sticky="w", padx=6, pady=4
        )
        self._combined_left_combo = ttk.Combobox(
            lf_combined_axis,
            state="readonly",
            textvariable=self._combined_left_display_var,
        )
        self._combined_left_combo.grid(row=0, column=1, sticky="ew", padx=6, pady=4)
        self._combined_left_combo.bind(
            "<<ComboboxSelected>>",
            lambda _e: self._on_combined_axis_change(
                "left", self._combined_left_display_var.get()
            ),
        )

        ttk.Label(lf_combined_axis, text="Inner Right Y Axis Dataset").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )
        self._combined_right_combo = ttk.Combobox(
            lf_combined_axis,
            state="readonly",
            textvariable=self._combined_right_display_var,
        )
        self._combined_right_combo.grid(row=1, column=1, sticky="ew", padx=6, pady=4)
        self._combined_right_combo.bind(
            "<<ComboboxSelected>>",
            lambda _e: self._on_combined_axis_change(
                "right", self._combined_right_display_var.get()
            ),
        )

        ttk.Label(lf_combined_axis, text="Outer Right Y Axis Dataset").grid(
            row=2, column=0, sticky="w", padx=6, pady=4
        )
        self._combined_third_combo = ttk.Combobox(
            lf_combined_axis,
            state="readonly",
            textvariable=self._combined_third_display_var,
        )
        self._combined_third_combo.grid(row=2, column=1, sticky="ew", padx=6, pady=4)
        self._combined_third_combo.bind(
            "<<ComboboxSelected>>",
            lambda _e: self._on_combined_axis_change(
                "third", self._combined_third_display_var.get()
            ),
        )

        # Ticks

        lf_ticks = ttk.Labelframe(f, text="Ticks")

        lf_ticks.grid(row=9, column=0, columnspan=4, sticky="ew", **pad)

        # Iterate over the configured range to apply the per-item logic.
        for i in range(8):

            lf_ticks.grid_columnconfigure(i, weight=1)

        # Closure captures _build_tab_plot_stage_two local context to keep helper logic scoped and invoked directly within _build_tab_plot_stage_two.
        def add_tick_row(row, label, auto_var, maj_var, min_var):
            """Perform add tick row.
            Used to keep the workflow logic localized and testable."""

            ttk.Label(lf_ticks, text=label).grid(
                row=row, column=0, sticky="w", padx=6, pady=4
            )

            auto_btn = ttk.Checkbutton(lf_ticks, text="Auto", variable=auto_var)

            auto_btn.grid(row=row, column=1, sticky="w", padx=6, pady=4)

            e_major = ttk.Entry(lf_ticks, textvariable=maj_var, width=10)

            e_minor = ttk.Entry(lf_ticks, textvariable=min_var, width=10)

            ttk.Label(lf_ticks, text="Major").grid(
                row=row, column=2, sticky="e", padx=6, pady=4
            )

            e_major.grid(row=row, column=3, sticky="w", padx=6, pady=4)

            ttk.Label(lf_ticks, text="Minor").grid(
                row=row, column=4, sticky="e", padx=6, pady=4
            )

            e_minor.grid(row=row, column=5, sticky="w", padx=6, pady=4)

            self._wire_auto_to_entries(auto_var, [e_major, e_minor])

            return (e_major, e_minor)

        self._tick_entries_time = add_tick_row(
            0, "Time Ticks", self.auto_time_ticks, self.xmaj_tick, self.xmin_tick
        )

        self._tick_entries_y = add_tick_row(
            1, "Pressure Y Ticks", self.auto_y_ticks, self.ymaj_tick, self.ymin_tick
        )

        self._tick_entries_temp = add_tick_row(
            2,
            "Temp Y Ticks (deg C)",
            self.auto_temp_ticks,
            self.temp_maj_tick,
            self.temp_min_tick,
        )

        self._tick_entries_deriv = add_tick_row(
            3,
            "Derivative Y Ticks",
            self.auto_deriv_ticks,
            self.deriv_maj_tick,
            self.deriv_min_tick,
        )

        self._apply_auto_state(self.auto_time_ticks, self._tick_entries_time)

        self._apply_auto_state(self.auto_y_ticks, self._tick_entries_y)

        self._apply_auto_state(self.auto_temp_ticks, self._tick_entries_temp)

        self._apply_auto_state(self.auto_deriv_ticks, self._tick_entries_deriv)

        self._refresh_combined_axis_choices()

    def _request_plot_settings_scroll_refresh(self) -> None:
        """Request a Plot Settings canvas scrollregion refresh.

        Purpose:
            Recalculate the scrollregion after accordion cards expand or collapse.
        Why:
            Dynamic card visibility changes the content height and the canvas bounds
            must be updated to keep wheel/scrollbar behavior accurate.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Calls the cached scrollregion callback set by `_build_tab_plot`.
        Exceptions:
            Best-effort only; callback failures are ignored to avoid interrupting
            normal UI use.
        """
        callback = getattr(self, "_plot_settings_refresh_scroll_region", None)
        if not callable(callback):
            return
        try:
            callback()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _create_plot_settings_card(
        self,
        parent,
        title: str,
        *,
        section_key: str | None = None,
        expanded: bool = True,
        collapsible: bool = True,
        accent: bool = False,
        reorderable: bool = False,
    ):
        """Create one Plot Settings card with optional collapse behavior.

        Purpose:
            Build a reusable card shell for the redesigned Plot Settings UI.
        Why:
            A shared constructor keeps CTk styling and ttk fallback behavior
            consistent across all cards while preserving existing widget bindings.
        Args:
            parent: Parent widget that owns the card.
            title: Header label shown at the top of the card.
            section_key: Stable key for in-memory expanded/collapsed state tracking.
            expanded: Initial card-body visibility for collapsible cards.
            collapsible: True to add a toggleable body, False for fixed visibility.
            accent: True to apply highlighted styling for the pinned ranges card.
            reorderable: True to render a dedicated drag handle in the card header.
        Returns:
            Tuple[Any, ttk.Frame, Any]: Card container widget, content body frame,
            and optional drag-handle widget (`None` when not reorderable).
        Side Effects:
            Creates child widgets and stores card state in `_plot_settings_card_states`.
        Exceptions:
            Uses best-effort guards for styling/callback updates to keep startup stable.
        """
        ctk_module = ctk
        ctk_border_default = None
        ctk_border_hover = None
        if ctk_module is not None:
            if accent:
                fg_color = ("#F5F9FF", "#1D2633")
                ctk_border_default = ("#B6C9E4", "#425166")
            else:
                fg_color = ("#FFFFFF", "#252526")
                ctk_border_default = ("#C7CDD3", "#51545A")
            ctk_border_hover = ("#1F6FD1", "#8CB4E8")
            container = ctk_module.CTkFrame(
                parent,
                corner_radius=10,
                border_width=1,
                border_color=ctk_border_default,
                fg_color=fg_color,
            )
        else:
            container = tk.Frame(parent, bd=1, relief="solid", highlightthickness=0)

        container.grid_columnconfigure(0, weight=1)
        header = ttk.Frame(container)
        header.grid(row=0, column=0, sticky="ew", padx=8, pady=(8, 4))
        header.grid_columnconfigure(0, weight=1)
        header.grid_columnconfigure(1, weight=0)

        body = ttk.Frame(container)
        body.grid(row=1, column=0, sticky="ew", padx=8, pady=(0, 8))

        def _set_hover_border(enabled: bool) -> None:
            """Apply card-border highlight for hover feedback on CTk cards."""
            if (
                ctk_module is None
                or ctk_border_default is None
                or ctk_border_hover is None
            ):
                return
            target_border = ctk_border_hover if enabled else ctk_border_default
            try:
                container.configure(border_color=target_border)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _bind_hover_border(widget) -> None:
            """Bind enter/leave events so card headers get clear hover affordance."""
            if widget is None:
                return
            widget.bind("<Enter>", lambda _event: _set_hover_border(True), add="+")
            widget.bind("<Leave>", lambda _event: _set_hover_border(False), add="+")

        if not collapsible:
            if ctk_module is not None:
                title_label = ctk_module.CTkLabel(
                    header,
                    text=title,
                    anchor="w",
                    font=(getattr(self, "_ui_font_family", "Verdana"), 14, "bold"),
                    text_color=("black", "#F2F4F6"),
                )
                title_label.grid(row=0, column=0, sticky="w")
                _bind_hover_border(container)
                _bind_hover_border(header)
                _bind_hover_border(title_label)
            else:
                ttk.Label(header, text=title).grid(row=0, column=0, sticky="w")
            return container, body, None

        state_var = tk.BooleanVar(value=bool(expanded))
        if section_key:
            states = getattr(self, "_plot_settings_card_states", None)
            if isinstance(states, dict):
                states[section_key] = state_var

        holder = {"button": None}

        def _refresh_header() -> None:
            """Refresh the card header text to match expanded/collapsed state."""
            arrow = "[-]" if state_var.get() else "[+]"
            caption = f"{arrow} {title}"
            button = holder.get("button")
            if button is None:
                return
            try:
                button.configure(text=caption)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _toggle() -> None:
            """Toggle card visibility and request scrollregion recomputation."""
            state_var.set(not bool(state_var.get()))
            if state_var.get():
                body.grid()
            else:
                body.grid_remove()
            _refresh_header()
            self._request_plot_settings_scroll_refresh()

        if ctk_module is not None:
            button = ctk_module.CTkButton(
                header,
                text="",
                command=_toggle,
                anchor="w",
                fg_color="transparent",
                hover_color=("#EBF2FD", "#3A4758"),
                text_color=("black", "#F2F4F6"),
                text_color_disabled=("black", "#F2F4F6"),
                corner_radius=6,
                height=28,
                font=(getattr(self, "_ui_font_family", "Verdana"), 13, "bold"),
            )
        else:
            button = ttk.Button(header, text="", command=_toggle)
        holder["button"] = button
        button.grid(row=0, column=0, sticky="ew")
        _bind_hover_border(container)
        _bind_hover_border(header)
        _bind_hover_border(button)

        grip = None
        if reorderable:
            if ctk_module is not None:
                grip = ctk_module.CTkLabel(
                    header,
                    text="|||",
                    width=24,
                    anchor="center",
                    text_color=("black", "#F2F4F6"),
                    font=(getattr(self, "_ui_font_family", "Verdana"), 12, "bold"),
                )
            else:
                grip = ttk.Label(header, text="|||")
            try:
                grip.configure(cursor="fleur")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            grip.grid(row=0, column=1, sticky="e", padx=(8, 0))
            _bind_hover_border(grip)

        if not state_var.get():
            body.grid_remove()
        _refresh_header()
        return container, body, grip

    def _add_plot_settings_card(
        self,
        parent,
        section_key: str,
        title: str,
        *,
        expanded: bool = False,
        collapsible: bool = True,
        accent: bool = False,
        reorderable: bool = True,
    ) -> ttk.Frame:
        """Create and place one accordion card in the Plot Settings stack.

        Purpose:
            Centralize row tracking and card-placement behavior for scroll content.
        Why:
            Section order is now intent-driven; a single card-placement helper keeps
            stacking predictable and avoids duplicated row math.
        Args:
            parent: Scroll content frame that owns the accordion cards.
            section_key: Stable identifier for state/body tracking dictionaries.
            title: Card header text.
            expanded: Whether the card starts expanded.
            collapsible: Whether the card body can be toggled.
            accent: Whether to apply highlighted styling.
            reorderable: Whether the card can be drag-reordered in the UI.
        Returns:
            ttk.Frame: Card body frame used by section-specific builders.
        Side Effects:
            Increments `_plot_settings_next_row` and updates card bookkeeping maps.
        Exceptions:
            Uses best-effort guards for optional bookkeeping updates.
        """
        row = int(getattr(self, "_plot_settings_next_row", 0))
        self._plot_settings_next_row = row + 1
        card, body, grip = self._create_plot_settings_card(
            parent,
            title,
            section_key=section_key,
            expanded=expanded,
            collapsible=collapsible,
            accent=accent,
            reorderable=reorderable,
        )
        card.grid(row=row, column=0, columnspan=4, sticky="ew", padx=8, pady=(0, 8))
        try:
            self._plot_settings_card_order.append(section_key)
            self._plot_settings_card_bodies[section_key] = body
            self._plot_settings_card_widgets[section_key] = card
            self._plot_settings_card_reorderable[section_key] = bool(reorderable)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if bool(reorderable) and grip is not None and section_key:
            self._bind_plot_settings_drag_handle(section_key, grip)
        self._request_plot_settings_scroll_refresh()
        return body

    def _default_plot_settings_card_order(self) -> List[str]:
        """Return the canonical default order for reorderable Plot Settings cards.

        Purpose:
            Provide one stable source of truth for stage-two accordion ordering.
        Why:
            Drag-reorder persistence and schema migration both need the same
            canonical key sequence to stay deterministic across app restarts.
        Args:
            None.
        Returns:
            List[str]: Default key order for reorderable (non-ranges) cards.
        Side Effects:
            None.
        Exceptions:
            None.
        """
        return list(PLOT_SETTINGS_CARD_ORDER_DEFAULT)

    def _resolve_plot_settings_card_order(self) -> List[str]:
        """Resolve and normalize stored Plot Settings card order.

        Purpose:
            Load persisted card ordering and map it to valid stage-two keys.
        Why:
            Legacy key migration and duplicate pruning must run before rendering
            drag-reorderable cards so the UI never starts in an invalid order.
        Args:
            None.
        Returns:
            List[str]: Normalized reorderable card order.
        Side Effects:
            Updates and may persist `settings["plot_settings_card_order"]` when
            stored values are missing, invalid, or legacy.
        Exceptions:
            Persistence failures are swallowed to avoid interrupting UI startup.
        """
        stored_order = settings.get("plot_settings_card_order")
        normalized_order = _normalize_plot_settings_card_order(stored_order)
        if stored_order != normalized_order:
            settings["plot_settings_card_order"] = list(normalized_order)
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        return list(normalized_order)

    def _persist_plot_settings_card_order(self, order: List[str]) -> None:
        """Persist the reorderable Plot Settings card order globally.

        Purpose:
            Save drag-reordered accordion card order into global settings.
        Why:
            Users expect card arrangement preferences to survive application
            restarts without relying on profile-level payloads.
        Args:
            order: Requested order of reorderable stage-two card keys.
        Returns:
            None.
        Side Effects:
            Writes normalized order to `settings["plot_settings_card_order"]` and
            persists it to disk.
        Exceptions:
            Disk-write failures are swallowed to avoid interrupting user flows.
        """
        normalized_order = _normalize_plot_settings_card_order(order)
        settings["plot_settings_card_order"] = list(normalized_order)
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _plot_settings_stage_two_card_registry(self) -> List[Dict[str, Any]]:
        """Build the stage-two Plot Settings card registry.

        Purpose:
            Define card metadata (title, builder, defaults) in one place.
        Why:
            Rendering from a registry enables persisted reorder support without
            hardcoding section construction order in the stage-two builder.
        Args:
            None.
        Returns:
            List[Dict[str, Any]]: Ordered card specifications keyed by section id.
        Side Effects:
            None.
        Exceptions:
            None.
        """
        return [
            {
                "key": "titles",
                "title": "Titles",
                "expanded": False,
                "collapsible": True,
                "reorderable": True,
                "builder": self._build_plot_titles_section,
            },
            {
                "key": "ticks",
                "title": "Ticks",
                "expanded": False,
                "collapsible": True,
                "reorderable": True,
                "builder": self._build_plot_ticks_section,
            },
            {
                "key": "cycle_integration_legend",
                "title": "Cycle Integration & Legend Settings",
                "expanded": False,
                "collapsible": True,
                "reorderable": True,
                "builder": self._build_plot_cycle_integration_legend_section,
            },
            {
                "key": "combined_axis",
                "title": "Combined Triple-Axis Settings",
                "expanded": False,
                "collapsible": True,
                "reorderable": True,
                "builder": self._build_plot_combined_axis_section,
            },
            {
                "key": "peak_trough",
                "title": "Peak & Trough Detection",
                "expanded": False,
                "collapsible": True,
                "reorderable": True,
                "builder": self._build_plot_peak_section,
            },
            {
                "key": "gas_model",
                "title": "Gas Model (Van der Waals)",
                "expanded": False,
                "collapsible": True,
                "reorderable": True,
                "builder": self._build_plot_gas_section,
            },
            {
                "key": "starting_material",
                "title": "Starting Material Settings",
                "expanded": False,
                "collapsible": True,
                "reorderable": True,
                "builder": self._build_plot_starting_material_section,
            },
        ]

    def _plot_settings_reorderable_keys(self) -> List[str]:
        """Return reorderable Plot Settings keys in current visual order.

        Purpose:
            Enumerate currently rendered cards that can be drag-reordered.
        Why:
            Drag calculations should ignore fixed cards (like Ranges) while
            preserving the user-visible order of reorderable sections.
        Args:
            None.
        Returns:
            List[str]: Reorderable section keys in current display order.
        Side Effects:
            None.
        Exceptions:
            Missing card maps are handled defensively and return an empty list.
        """
        order = list(getattr(self, "_plot_settings_card_order", []) or [])
        reorderable_map = getattr(self, "_plot_settings_card_reorderable", {}) or {}
        keys: List[str] = []
        # Iterate over current order so drag logic matches on-screen sequence.
        for key in order:
            if not bool(reorderable_map.get(key)):
                continue
            keys.append(key)
        return keys

    def _bind_plot_settings_drag_handle(self, section_key: str, grip_widget: Any) -> None:
        """Bind grip-handle events for Plot Settings card drag reordering.

        Purpose:
            Attach mouse bindings needed to start/move/end drag reorder.
        Why:
            Reorder interaction is intentionally constrained to a dedicated grip
            so header clicks still behave as expand/collapse toggles.
        Args:
            section_key: Card key associated with the grip.
            grip_widget: Widget acting as drag handle in the card header.
        Returns:
            None.
        Side Effects:
            Binds mouse event callbacks to the provided grip widget.
        Exceptions:
            Binding failures are ignored to keep card rendering resilient.
        """
        if not section_key or grip_widget is None:
            return
        try:
            grip_widget.bind(
                "<ButtonPress-1>",
                lambda event, key=section_key: self._on_plot_settings_drag_start(
                    key, event
                ),
                add="+",
            )
            grip_widget.bind("<B1-Motion>", self._on_plot_settings_drag_motion, add="+")
            grip_widget.bind(
                "<ButtonRelease-1>", self._on_plot_settings_drag_release, add="+"
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _on_plot_settings_drag_start(self, section_key: str, event: Any) -> str:
        """Start drag-reordering for one Plot Settings card.

        Purpose:
            Capture drag context when the user presses a card grip handle.
        Why:
            Drag state must track the active section and insertion target before
            motion events can compute live reorder previews.
        Args:
            section_key: Reorderable card key being dragged.
            event: Tk mouse event carrying pointer and source widget data.
        Returns:
            str: `"break"` to stop event propagation into header toggle controls.
        Side Effects:
            Initializes `_plot_settings_drag_state` and attempts to grab pointer
            events on the grip widget.
        Exceptions:
            Invalid keys or missing render state are ignored safely.
        """
        reorderable_keys = self._plot_settings_reorderable_keys()
        if section_key not in reorderable_keys:
            return "break"
        grip_widget = getattr(event, "widget", None)
        self._plot_settings_drag_state = {
            "drag_key": section_key,
            "target_index": reorderable_keys.index(section_key),
            "grip_widget": grip_widget,
        }
        if grip_widget is not None:
            try:
                grip_widget.grab_set()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._on_plot_settings_drag_motion(event)
        return "break"

    def _on_plot_settings_drag_motion(self, event: Any) -> str:
        """Update live insertion preview while dragging a Plot Settings card.

        Purpose:
            Recompute insertion target from pointer position and draw a preview line.
        Why:
            Users need immediate visual feedback for where the card will be placed
            on drop without collapsing or rebuilding card content.
        Args:
            event: Tk mouse-motion event during active drag.
        Returns:
            str: `"break"` to keep drag events scoped to reorder behavior.
        Side Effects:
            Updates `_plot_settings_drag_state["target_index"]` and repositions a
            live insertion marker in the scroll content frame.
        Exceptions:
            Missing drag state or widgets exits safely without raising.
        """
        state = getattr(self, "_plot_settings_drag_state", None)
        if not isinstance(state, dict):
            return "break"
        drag_key = state.get("drag_key")
        reorderable_keys = self._plot_settings_reorderable_keys()
        if drag_key not in reorderable_keys:
            return "break"
        base_keys = [key for key in reorderable_keys if key != drag_key]
        widgets = getattr(self, "_plot_settings_card_widgets", {}) or {}
        target_index = len(base_keys)
        pointer_root_y = getattr(event, "y_root", None)
        if pointer_root_y is not None:
            # Compare pointer against card midpoints to derive insertion slot.
            for idx, key in enumerate(base_keys):
                widget = widgets.get(key)
                if widget is None or not widget.winfo_exists():
                    continue
                midpoint = widget.winfo_rooty() + (widget.winfo_height() / 2.0)
                if pointer_root_y < midpoint:
                    target_index = idx
                    break
        state["target_index"] = target_index

        content = getattr(self, "_plot_settings_content_frame", None)
        if content is None or not content.winfo_exists():
            return "break"
        try:
            content.update_idletasks()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        preview_line = getattr(self, "_plot_settings_drag_preview_line", None)
        if preview_line is None or not preview_line.winfo_exists():
            preview_line = tk.Frame(content, height=2, bg="#1F6FD1")
            self._plot_settings_drag_preview_line = preview_line
        line_y = 0
        if base_keys:
            if target_index < len(base_keys):
                anchor_key = base_keys[target_index]
                anchor_widget = widgets.get(anchor_key)
                if anchor_widget is not None and anchor_widget.winfo_exists():
                    line_y = max(0, int(anchor_widget.winfo_y()) - 2)
            else:
                anchor_key = base_keys[-1]
                anchor_widget = widgets.get(anchor_key)
                if anchor_widget is not None and anchor_widget.winfo_exists():
                    line_y = int(anchor_widget.winfo_y() + anchor_widget.winfo_height() + 2)
        preview_line.place(x=8, y=line_y, relwidth=1.0, width=-16, height=2)
        try:
            preview_line.lift()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return "break"

    def _on_plot_settings_drag_release(self, event: Any) -> str:
        """Commit Plot Settings card reorder when drag handle is released.

        Purpose:
            Finalize reorder and persist the new stage-two card sequence.
        Why:
            Drop-time commit keeps section state intact while applying only row
            re-grid updates and one settings write.
        Args:
            event: Tk button-release event from the drag interaction.
        Returns:
            str: `"break"` to prevent release events from toggling card headers.
        Side Effects:
            Reorders card rows, persists global card order, and clears drag preview.
        Exceptions:
            Missing drag state exits gracefully without raising.
        """
        state = getattr(self, "_plot_settings_drag_state", None)
        if not isinstance(state, dict):
            return "break"
        drag_key = state.get("drag_key")
        target_index = int(state.get("target_index", 0))
        reorderable_keys = self._plot_settings_reorderable_keys()
        if drag_key in reorderable_keys:
            base_keys = [key for key in reorderable_keys if key != drag_key]
            if target_index < 0:
                target_index = 0
            if target_index > len(base_keys):
                target_index = len(base_keys)
            new_order = list(base_keys)
            new_order.insert(target_index, drag_key)
            if new_order != reorderable_keys:
                self._apply_plot_settings_reorder(new_order, persist=True)
        self._end_plot_settings_drag()
        return "break"

    def _end_plot_settings_drag(self) -> None:
        """Clear transient drag-reorder state for Plot Settings cards.

        Purpose:
            Tear down drag preview UI and release any active pointer grab.
        Why:
            Reorder interactions must leave no sticky event state after drop.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Hides the insertion marker, releases grip grab, and resets
            `_plot_settings_drag_state`.
        Exceptions:
            Cleanup guards suppress widget errors during teardown.
        """
        state = getattr(self, "_plot_settings_drag_state", None)
        grip_widget = state.get("grip_widget") if isinstance(state, dict) else None
        if grip_widget is not None:
            try:
                grip_widget.grab_release()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        preview_line = getattr(self, "_plot_settings_drag_preview_line", None)
        if preview_line is not None and preview_line.winfo_exists():
            try:
                preview_line.place_forget()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._plot_settings_drag_state = None

    def _apply_plot_settings_reorder(
        self, reorderable_order: List[str], *, persist: bool
    ) -> None:
        """Apply a reordered stage-two card sequence to the live accordion.

        Purpose:
            Re-grid card containers to match a new reorderable section order.
        Why:
            Keeping card widgets in-place preserves expanded/collapsed state and
            field values while applying drag reorder changes instantly.
        Args:
            reorderable_order: Requested order for reorderable card keys.
            persist: True to save resulting order to global settings.
        Returns:
            None.
        Side Effects:
            Updates `_plot_settings_card_order`, re-grids card widgets, refreshes
            scroll bounds, and optionally persists order to disk.
        Exceptions:
            Missing widgets are skipped safely to keep UI responsive.
        """
        reorderable_keys = self._plot_settings_reorderable_keys()
        seen: Set[str] = set()
        normalized_reorderable: List[str] = []
        # Filter drag results to known keys and preserve first occurrence order.
        for key in reorderable_order:
            if key not in reorderable_keys or key in seen:
                continue
            normalized_reorderable.append(key)
            seen.add(key)
        for key in reorderable_keys:
            if key in seen:
                continue
            normalized_reorderable.append(key)
            seen.add(key)

        current_order = list(getattr(self, "_plot_settings_card_order", []) or [])
        reorderable_map = getattr(self, "_plot_settings_card_reorderable", {}) or {}
        fixed_keys = [key for key in current_order if not bool(reorderable_map.get(key))]
        new_order = fixed_keys + normalized_reorderable
        self._plot_settings_card_order = list(new_order)

        card_widgets = getattr(self, "_plot_settings_card_widgets", {}) or {}
        # Re-grid each card in the new sequence without rebuilding section content.
        for row_idx, key in enumerate(new_order):
            widget = card_widgets.get(key)
            if widget is None or not widget.winfo_exists():
                continue
            try:
                widget.grid_configure(row=row_idx)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if persist:
            self._persist_plot_settings_card_order(normalized_reorderable)
        self._request_plot_settings_scroll_refresh()

    def _build_plot_ranges_controls(self, parent) -> None:
        """Build range controls for quick axis limit editing.

        Purpose:
            Render frequently used min/max controls inside Plot Settings.
        Why:
            Range tuning is the most common task and should be grouped with axis
            controls in the merged Axis & Range section.
        Args:
            parent: Body frame of the pinned ranges card.
        Returns:
            None.
        Side Effects:
            Creates entry widgets bound to existing range Tk variables and wires
            the range-refresh action.
        Exceptions:
            Tooltip wiring is best-effort and does not block UI rendering.
        """
        section = ttk.Frame(parent)
        section.grid(row=0, column=0, sticky="ew")
        section.grid_columnconfigure(0, weight=1)
        section.grid_columnconfigure(1, weight=1)

        def _add_range_pair(
            row_idx: int,
            col_idx: int,
            label: str,
            min_var: tk.Variable,
            max_var: tk.Variable,
        ) -> None:
            """Render one min/max field pair inside the ranges card."""
            frame = ttk.Frame(section)
            frame.grid(row=row_idx, column=col_idx, sticky="ew", padx=4, pady=4)
            ttk.Label(frame, text=label).grid(row=0, column=0, sticky="w")
            ttk.Entry(frame, textvariable=min_var, width=10).grid(
                row=0, column=1, padx=6
            )
            ttk.Entry(frame, textvariable=max_var, width=10).grid(
                row=0, column=2, padx=6
            )

        _add_range_pair(0, 0, "Time (min / max)", self.min_time, self.max_time)
        _add_range_pair(0, 1, "Pressure Y (min / max)", self.min_y, self.max_y)
        _add_range_pair(
            1,
            0,
            "Temp Y deg C (min / max)",
            self.twin_y_min,
            self.twin_y_max,
        )
        _add_range_pair(
            1,
            1,
            "Derivative Y (min / max)",
            self.deriv_y_min,
            self.deriv_y_max,
        )

        actions = ttk.Frame(section)
        actions.grid(row=2, column=0, columnspan=2, sticky="e", padx=4, pady=(6, 2))
        btn_refresh = ttk.Button(
            actions,
            text="Refresh Axis Ranges",
            command=self._refresh_axis_ranges,
        )
        btn_refresh.grid(row=0, column=0, padx=(0, 8))
        self._attach_tooltip(
            btn_refresh, "Recalculate and apply axis min/max from current data."
        )

    def _build_plot_axes_section(self, parent, pad: dict[str, int]) -> None:
        """Build the Axes card content for Plot Settings.

        Purpose:
            Render axis visibility, padding, and auto-range target controls.
        Why:
            Axes settings are adjusted frequently alongside range edits and are
            composed into the merged Axis & Range section.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Creates controls bound to existing axis-related Tk variables and wires
            optional access to the legacy auto-range preferences popup.
        Exceptions:
            Tooltip binding is best-effort and does not block section rendering.
        """
        lf_axes = ttk.Frame(parent)
        lf_axes.grid(row=0, column=0, sticky="ew", **pad)
        for c in range(4):
            lf_axes.grid_columnconfigure(c, weight=1)

        ttk.Checkbutton(
            lf_axes, text="Enable Temperature Axis", variable=self.enable_temp_axis
        ).grid(row=0, column=0, sticky="w", padx=6, pady=4)
        ttk.Checkbutton(
            lf_axes, text="Enable Derivative Axis", variable=self.enable_deriv_axis
        ).grid(row=0, column=1, sticky="w", padx=6, pady=4)

        lbl_pad = ttk.Label(lf_axes, text="Span Padding (%)")
        lbl_pad.grid(row=0, column=2, sticky="e", padx=6, pady=4)
        ent_pad = ttk.Entry(lf_axes, textvariable=self.axis_pad_pct, width=6)
        ent_pad.grid(row=0, column=3, sticky="w", padx=6, pady=4)

        fr_axis_offset = ttk.Frame(lf_axes)
        fr_axis_offset.grid(row=1, column=0, columnspan=2, sticky="w", padx=6, pady=4)
        ttk.Label(fr_axis_offset, text="Combined derivative axis offset").grid(
            row=0, column=0, sticky="w"
        )
        ttk.Entry(
            fr_axis_offset, textvariable=self.combined_deriv_axis_offset, width=6
        ).grid(row=0, column=1, padx=6)

        auto_range_frame = ttk.Labelframe(lf_axes, text="Auto-Range Targets")
        auto_range_frame.grid(
            row=2, column=0, columnspan=4, sticky="ew", padx=6, pady=(6, 4)
        )
        auto_range_frame.grid_columnconfigure(0, weight=1)
        auto_range_frame.grid_columnconfigure(1, weight=1)

        cb_auto_time = ttk.Checkbutton(
            auto_range_frame, text="Time (X-axis)", variable=self.axis_auto_time
        )
        cb_auto_time.grid(row=0, column=0, sticky="w", padx=6, pady=3)
        cb_auto_pressure = ttk.Checkbutton(
            auto_range_frame, text="Pressure Y axes", variable=self.axis_auto_pressure
        )
        cb_auto_pressure.grid(row=0, column=1, sticky="w", padx=6, pady=3)
        cb_auto_temp = ttk.Checkbutton(
            auto_range_frame, text="Temperature axis", variable=self.axis_auto_temp
        )
        cb_auto_temp.grid(row=1, column=0, sticky="w", padx=6, pady=3)
        cb_auto_deriv = ttk.Checkbutton(
            auto_range_frame, text="Derivative axis", variable=self.axis_auto_deriv
        )
        cb_auto_deriv.grid(row=1, column=1, sticky="w", padx=6, pady=3)

        btn_auto_axis_settings = ttk.Button(
            lf_axes,
            text="Open Auto-Axis Dialog...",
            command=self._open_axis_range_preferences,
        )
        btn_auto_axis_settings.grid(row=3, column=0, sticky="w", padx=6, pady=(4, 2))

        self._attach_tooltip(
            fr_axis_offset,
            "Moves the derivative spine for the combined triple-axis plot. "
            "Values >1.0 push it farther right so ticks stay readable.",
        )
        self._attach_tooltip(
            lbl_pad,
            "Y-axis padding as a percent of data span.\nDefault 5%. "
            "Increase to add more vertical breathing room.",
        )
        self._attach_tooltip(
            ent_pad, "Y-axis padding as a percent of data span.\nDefault 5%."
        )
        self._attach_tooltip(
            cb_auto_time, "Allow automatic limits for the X/time axis."
        )
        self._attach_tooltip(
            cb_auto_pressure, "Auto-range the primary pressure axes (y1/y3)."
        )
        self._attach_tooltip(
            cb_auto_temp, "Auto-range temperature traces when present."
        )
        self._attach_tooltip(cb_auto_deriv, "Auto-range the first-derivative axis.")
        self._attach_tooltip(
            btn_auto_axis_settings,
            "Open Axis Auto-Range Settings in a dedicated popup.",
        )

    def _build_plot_axis_range_section(self, parent, pad: dict[str, int]) -> None:
        """Build one merged Axis & Range section for Plot Settings.

        Purpose:
            Render frequently edited range fields and axis behaviors in one card.
        Why:
            Users typically tune ranges and axis options together while plotting;
            merging both surfaces reduces section switching and visual overhead.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Creates all range and axis widgets, preserving existing variable
            bindings and callbacks (including refresh and auto-range controls).
        Exceptions:
            Downstream builders keep best-effort guard behavior.
        """
        parent.grid_columnconfigure(0, weight=1)
        ranges_host = ttk.Frame(parent)
        ranges_host.grid(row=0, column=0, sticky="ew")
        axes_host = ttk.Frame(parent)
        axes_host.grid(row=1, column=0, sticky="ew")
        # Keep existing builders to preserve callback and variable wiring.
        self._build_plot_ranges_controls(ranges_host)
        self._build_plot_axes_section(axes_host, pad)

    def _build_plot_titles_section(self, parent, pad: dict[str, int]) -> None:
        """Build the Titles card content for Plot Settings.

        Purpose:
            Render manual and auto-title configuration controls and preview output.
        Why:
            Title controls are important but edited less frequently than ranges/axes,
            so they live in a collapsed card while keeping all existing behaviors.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Creates title widgets, stores widget references, and wires trace-based
            synchronization between display labels and canonical title variables.
        Exceptions:
            Uses best-effort guard behavior in downstream callbacks already defined.
        """
        lf_titles = ttk.Frame(parent)
        lf_titles.grid(row=0, column=0, sticky="ew", **pad)
        lf_titles.grid_columnconfigure(1, weight=1)
        lf_titles.grid_columnconfigure(2, weight=1)

        ttk.Label(lf_titles, text="Suptitle (Job Information)").grid(
            row=0, column=0, sticky="w", padx=6, pady=4
        )
        ttk.Entry(lf_titles, textvariable=self.suptitle_text, width=72).grid(
            row=0, column=1, columnspan=2, sticky="ew", padx=6, pady=4
        )

        ttk.Label(lf_titles, text="Title").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )
        title_entry = ttk.Entry(lf_titles, textvariable=self.title_text, width=72)
        title_entry.grid(row=1, column=1, columnspan=2, sticky="ew", padx=6, pady=4)
        self._title_entry = title_entry

        copy_btn = ttk.Button(
            lf_titles,
            text="Copy Auto Title -> Manual Title",
            command=self._copy_auto_title_to_manual,
        )
        copy_btn.grid(row=2, column=1, columnspan=2, sticky="w", padx=6, pady=(0, 6))
        self._copy_auto_title_btn = copy_btn

        auto_frame = ttk.Frame(lf_titles)
        auto_frame.grid(row=3, column=0, columnspan=3, sticky="ew", padx=6, pady=(2, 6))
        auto_frame.grid_columnconfigure(1, weight=1)

        ttk.Checkbutton(
            auto_frame,
            text="Auto-generate Title",
            variable=self.auto_title_enabled_var,
        ).grid(row=0, column=0, sticky="w", pady=(2, 4))

        ttk.Label(auto_frame, text="Data Type").grid(
            row=1, column=0, sticky="w", padx=(0, 6), pady=2
        )
        type_choices = self._get_title_type_choices()
        type_combo = ttk.Combobox(
            auto_frame,
            textvariable=self.title_data_type_var,
            state="readonly",
            values=type_choices,
        )
        type_combo.grid(row=1, column=1, sticky="ew", padx=6, pady=2)
        self._title_type_combo = type_combo
        ttk.Button(
            auto_frame,
            text="Manage Types...",
            command=self._open_manage_title_types_dialog,
        ).grid(row=1, column=2, sticky="e", padx=(6, 0), pady=2)

        source_labels = {
            AUTO_TITLE_SOURCE_FULL: "Full dataset (Columns tab)",
            AUTO_TITLE_SOURCE_CURRENT: "Current view range",
        }
        source_label_to_value = {v: k for k, v in source_labels.items()}
        source_display_var = tk.StringVar(
            value=source_labels.get(
                self.auto_title_source_var.get(), source_labels[AUTO_TITLE_SOURCE_FULL]
            )
        )
        self._auto_title_source_display_var = source_display_var

        ttk.Label(auto_frame, text="Auto Title uses").grid(
            row=2, column=0, sticky="w", padx=(0, 6), pady=2
        )
        source_combo = ttk.Combobox(
            auto_frame,
            textvariable=source_display_var,
            state="readonly",
            values=list(source_labels.values()),
        )
        source_combo.grid(row=2, column=1, sticky="ew", padx=6, pady=2)
        self._auto_title_source_combo = source_combo

        day_mode_labels = {
            AUTO_TITLE_DAY_DIFF: "Date diff (end-start)",
            AUTO_TITLE_DAY_INCLUSIVE: "Inclusive (end-start+1)",
        }
        day_mode_label_to_value = {v: k for k, v in day_mode_labels.items()}
        day_mode_display_var = tk.StringVar(
            value=day_mode_labels.get(
                self.auto_title_day_mode_var.get(), day_mode_labels[AUTO_TITLE_DAY_DIFF]
            )
        )
        self._auto_title_day_mode_display_var = day_mode_display_var

        ttk.Label(auto_frame, text="Day count mode").grid(
            row=3, column=0, sticky="w", padx=(0, 6), pady=2
        )
        day_mode_combo = ttk.Combobox(
            auto_frame,
            textvariable=day_mode_display_var,
            state="readonly",
            values=list(day_mode_labels.values()),
        )
        day_mode_combo.grid(row=3, column=1, sticky="ew", padx=6, pady=2)
        self._auto_title_day_mode_combo = day_mode_combo

        ttk.Label(auto_frame, text="Template").grid(
            row=4, column=0, sticky="w", padx=(0, 6), pady=2
        )
        template_entry = ttk.Entry(
            auto_frame, textvariable=self.auto_title_template_var, width=56
        )
        template_entry.grid(row=4, column=1, sticky="ew", padx=6, pady=2)
        self._auto_title_template_entry = template_entry
        ttk.Button(
            auto_frame, text="Edit...", command=self._open_auto_title_template_editor
        ).grid(row=4, column=2, sticky="e", padx=(6, 0), pady=2)

        ttk.Label(auto_frame, text="Auto Title Preview").grid(
            row=5, column=0, sticky="w", padx=(0, 6), pady=2
        )
        ttk.Label(
            auto_frame,
            textvariable=self._auto_title_preview_var,
            wraplength=540,
        ).grid(row=5, column=1, columnspan=2, sticky="w", padx=6, pady=2)

        def _sync_source_from_display(*_) -> None:
            """Mirror display labels back to the stored Auto Title source."""
            label = source_display_var.get()
            value = source_label_to_value.get(label, AUTO_TITLE_SOURCE_FULL)
            if value != self.auto_title_source_var.get():
                self.auto_title_source_var.set(value)

        def _sync_source_display(*_) -> None:
            """Mirror stored Auto Title source to the display combobox."""
            value = self.auto_title_source_var.get()
            label = source_labels.get(value, source_labels[AUTO_TITLE_SOURCE_FULL])
            if label != source_display_var.get():
                source_display_var.set(label)

        def _sync_day_mode_from_display(*_) -> None:
            """Mirror display labels back to stored day-count mode."""
            label = day_mode_display_var.get()
            value = day_mode_label_to_value.get(label, AUTO_TITLE_DAY_DIFF)
            if value != self.auto_title_day_mode_var.get():
                self.auto_title_day_mode_var.set(value)

        def _sync_day_mode_display(*_) -> None:
            """Mirror stored day-count mode to the display combobox."""
            value = self.auto_title_day_mode_var.get()
            label = day_mode_labels.get(value, day_mode_labels[AUTO_TITLE_DAY_DIFF])
            if label != day_mode_display_var.get():
                day_mode_display_var.set(label)

        source_display_var.trace_add("write", _sync_source_from_display)
        self.auto_title_source_var.trace_add("write", _sync_source_display)
        day_mode_display_var.trace_add("write", _sync_day_mode_from_display)
        self.auto_title_day_mode_var.trace_add("write", _sync_day_mode_display)

        for var in (
            self.auto_title_enabled_var,
            self.auto_title_source_var,
            self.auto_title_template_var,
            self.auto_title_day_mode_var,
            self.title_data_type_var,
        ):
            var.trace_add("write", self._update_auto_title_preview)
        self.auto_title_enabled_var.trace_add(
            "write", self._update_auto_title_controls_state
        )
        self._update_auto_title_controls_state()
        self._update_auto_title_preview()

    def _build_plot_ticks_section(self, parent, pad: dict[str, int]) -> None:
        """Build the Ticks card content for Plot Settings.

        Purpose:
            Render auto/manual major/minor tick controls for all supported axes.
        Why:
            Tick controls are less frequently changed during normal iteration, so
            they remain in a collapsed card while preserving exact legacy behavior.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Creates tick widgets and installs trace-driven enable/disable wiring for
            auto/manual switching.
        Exceptions:
            Relies on existing `_wire_auto_to_entries` guard behavior.
        """
        lf_ticks = ttk.Frame(parent)
        lf_ticks.grid(row=0, column=0, sticky="ew", **pad)
        for i in range(8):
            lf_ticks.grid_columnconfigure(i, weight=1)

        def add_tick_row(row, label, auto_var, maj_var, min_var):
            """Render one tick row and connect auto/manual state logic."""
            ttk.Label(lf_ticks, text=label).grid(
                row=row, column=0, sticky="w", padx=6, pady=4
            )
            auto_btn = ttk.Checkbutton(lf_ticks, text="Auto", variable=auto_var)
            auto_btn.grid(row=row, column=1, sticky="w", padx=6, pady=4)
            e_major = ttk.Entry(lf_ticks, textvariable=maj_var, width=10)
            e_minor = ttk.Entry(lf_ticks, textvariable=min_var, width=10)
            ttk.Label(lf_ticks, text="Major").grid(
                row=row, column=2, sticky="e", padx=6, pady=4
            )
            e_major.grid(row=row, column=3, sticky="w", padx=6, pady=4)
            ttk.Label(lf_ticks, text="Minor").grid(
                row=row, column=4, sticky="e", padx=6, pady=4
            )
            e_minor.grid(row=row, column=5, sticky="w", padx=6, pady=4)
            self._wire_auto_to_entries(auto_var, [e_major, e_minor])
            return (e_major, e_minor)

        self._tick_entries_time = add_tick_row(
            0, "Time Ticks", self.auto_time_ticks, self.xmaj_tick, self.xmin_tick
        )
        self._tick_entries_y = add_tick_row(
            1, "Pressure Y Ticks", self.auto_y_ticks, self.ymaj_tick, self.ymin_tick
        )
        self._tick_entries_temp = add_tick_row(
            2,
            "Temp Y Ticks (deg C)",
            self.auto_temp_ticks,
            self.temp_maj_tick,
            self.temp_min_tick,
        )
        self._tick_entries_deriv = add_tick_row(
            3,
            "Derivative Y Ticks",
            self.auto_deriv_ticks,
            self.deriv_maj_tick,
            self.deriv_min_tick,
        )
        self._apply_auto_state(self.auto_time_ticks, self._tick_entries_time)
        self._apply_auto_state(self.auto_y_ticks, self._tick_entries_y)
        self._apply_auto_state(self.auto_temp_ticks, self._tick_entries_temp)
        self._apply_auto_state(self.auto_deriv_ticks, self._tick_entries_deriv)

    def _build_plot_cycle_integration_section(
        self, parent, pad: dict[str, int]
    ) -> None:
        """Build the Cycle Integration card content for Plot Settings.

        Purpose:
            Render core-plot cycle marker and legend integration toggles.
        Why:
            These controls are usually set once per profile and should stay available
            without occupying persistent space in the main working area.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Creates checkbuttons bound to persisted cycle integration variables.
        Exceptions:
            No custom exceptions; uses standard Tk widget construction.
        """
        lf_cycle_integration = ttk.Frame(parent)
        lf_cycle_integration.grid(row=0, column=0, sticky="ew", **pad)
        lf_cycle_integration.grid_columnconfigure(0, weight=1)
        lf_cycle_integration.grid_columnconfigure(1, weight=1)

        ttk.Checkbutton(
            lf_cycle_integration,
            text="Show Cycle Peaks/Troughs on Core Plots",
            variable=self.show_cycle_markers_on_core,
        ).grid(row=0, column=0, sticky="w", padx=6, pady=4)
        ttk.Checkbutton(
            lf_cycle_integration,
            text="Show Cycle Legend on Core Plots (Peaks/Troughs/Cycles/dP)",
            variable=self.show_cycle_legend_on_core,
        ).grid(row=0, column=1, sticky="w", padx=6, pady=4)
        ttk.Checkbutton(
            lf_cycle_integration,
            text="Include Moles Summary in Core Plot Legend",
            variable=self.include_moles_core_legend,
        ).grid(row=1, column=0, sticky="w", padx=6, pady=4)

    def _build_plot_cycle_legend_section(self, parent, pad: dict[str, int]) -> None:
        """Build the combined-cycle legend controls card.

        Purpose:
            Render drag/lock/persist controls for the combined plot cycle legend.
        Why:
            Legend placement preferences are important for polished outputs but are
            adjusted infrequently, making them a good fit for a collapsible card.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Wires controls that call `_sync_combined_cycle_legend_controls` and reset
            legend anchor state when requested.
        Exceptions:
            No custom exceptions; downstream handlers provide best-effort guards.
        """
        lf_cycle_legend = ttk.Frame(parent)
        lf_cycle_legend.grid(row=0, column=0, sticky="ew", **pad)
        lf_cycle_legend.grid_columnconfigure(0, weight=1)
        lf_cycle_legend.grid_columnconfigure(1, weight=1)

        def _apply_cycle_legend_controls():
            """Apply cycle legend control changes to the active combined figure."""
            self._sync_combined_cycle_legend_controls(refresh_display=True)

        ttk.Checkbutton(
            lf_cycle_legend,
            text="Enable Cycle Legend Dragging",
            variable=self.combined_cycle_legend_enable_drag,
            command=_apply_cycle_legend_controls,
        ).grid(row=0, column=0, sticky="w", padx=6, pady=4)
        ttk.Checkbutton(
            lf_cycle_legend,
            text="Lock Cycle Legend Position",
            variable=self.combined_cycle_legend_lock_position,
            command=_apply_cycle_legend_controls,
        ).grid(row=0, column=1, sticky="w", padx=6, pady=4)
        ttk.Checkbutton(
            lf_cycle_legend,
            text="Persist Cycle Legend Position (Refresh/Rebuild)",
            variable=self.combined_cycle_legend_persist_position,
            command=_apply_cycle_legend_controls,
        ).grid(row=1, column=0, sticky="w", padx=6, pady=4)
        ttk.Checkbutton(
            lf_cycle_legend,
            text="Clamp Cycle Legend Inside Axes on Capture",
            variable=self.combined_cycle_legend_clamp_to_axes,
            command=_apply_cycle_legend_controls,
        ).grid(row=1, column=1, sticky="w", padx=6, pady=4)
        ttk.Button(
            lf_cycle_legend,
            text="Reset Cycle Legend Position",
            command=self._reset_combined_cycle_legend_position,
        ).grid(row=2, column=0, sticky="w", padx=6, pady=4)
        ttk.Checkbutton(
            lf_cycle_legend,
            text="Enable Main Legend Dragging (Combined Plot)",
            variable=self.combined_main_legend_enable_drag,
            command=_apply_cycle_legend_controls,
        ).grid(row=2, column=1, sticky="w", padx=6, pady=4)

    def _build_plot_cycle_integration_legend_section(
        self, parent, pad: dict[str, int]
    ) -> None:
        """Build one merged card for cycle integration and legend settings.

        Purpose:
            Consolidate cycle marker toggles and combined-legend controls into one
            workflow-centered accordion section.
        Why:
            Grouping related cycle controls reduces section count while preserving
            all existing settings, callbacks, and tool-specific behavior.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary used by nested section builders.
        Returns:
            None.
        Side Effects:
            Creates nested frames and populates them through existing cycle
            integration/legend builder methods.
        Exceptions:
            Downstream builder methods keep best-effort guard behavior.
        """
        parent.grid_columnconfigure(0, weight=1)
        integration_host = ttk.Frame(parent)
        integration_host.grid(row=0, column=0, sticky="ew")
        legend_host = ttk.Frame(parent)
        legend_host.grid(row=1, column=0, sticky="ew")
        # Reuse existing builders to preserve callback wiring and variable ownership.
        self._build_plot_cycle_integration_section(integration_host, pad)
        self._build_plot_cycle_legend_section(legend_host, pad)

    def _build_plot_combined_axis_section(self, parent, pad: dict[str, int]) -> None:
        """Build the Combined Triple-Axis dataset selection card.

        Purpose:
            Render dataset selector comboboxes for inner-left, inner-right, and
            outer-right y-axes in the combined plot.
        Why:
            Dataset mapping changes infrequently but must remain available and
            synchronized with display labels and stored axis keys.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Creates combobox widgets and binds selection handlers that update
            combined-axis state through `_on_combined_axis_change`.
        Exceptions:
            Uses existing callback guards in downstream axis-change handlers.
        """
        lf_combined_axis = ttk.Frame(parent)
        lf_combined_axis.grid(row=0, column=0, sticky="ew", **pad)
        lf_combined_axis.grid_columnconfigure(1, weight=1)

        ttk.Label(lf_combined_axis, text="Inner Left Y Axis Dataset").grid(
            row=0, column=0, sticky="w", padx=6, pady=4
        )
        self._combined_left_combo = ttk.Combobox(
            lf_combined_axis,
            state="readonly",
            textvariable=self._combined_left_display_var,
        )
        self._combined_left_combo.grid(row=0, column=1, sticky="ew", padx=6, pady=4)
        self._combined_left_combo.bind(
            "<<ComboboxSelected>>",
            lambda _e: self._on_combined_axis_change(
                "left", self._combined_left_display_var.get()
            ),
        )

        ttk.Label(lf_combined_axis, text="Inner Right Y Axis Dataset").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )
        self._combined_right_combo = ttk.Combobox(
            lf_combined_axis,
            state="readonly",
            textvariable=self._combined_right_display_var,
        )
        self._combined_right_combo.grid(row=1, column=1, sticky="ew", padx=6, pady=4)
        self._combined_right_combo.bind(
            "<<ComboboxSelected>>",
            lambda _e: self._on_combined_axis_change(
                "right", self._combined_right_display_var.get()
            ),
        )

        ttk.Label(lf_combined_axis, text="Outer Right Y Axis Dataset").grid(
            row=2, column=0, sticky="w", padx=6, pady=4
        )
        self._combined_third_combo = ttk.Combobox(
            lf_combined_axis,
            state="readonly",
            textvariable=self._combined_third_display_var,
        )
        self._combined_third_combo.grid(row=2, column=1, sticky="ew", padx=6, pady=4)
        self._combined_third_combo.bind(
            "<<ComboboxSelected>>",
            lambda _e: self._on_combined_axis_change(
                "third", self._combined_third_display_var.get()
            ),
        )

    def _build_plot_peak_section(self, parent, pad: dict[str, int]) -> None:
        """Build the Peak & Trough Detection card content.

        Purpose:
            Render threshold controls for automatic cycle peak/trough detection.
        Why:
            Detection thresholds are important tuning parameters but are adjusted
            less often than ranges; placing them in a card reduces visual clutter.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Creates threshold widgets bound to existing Tk variables and attaches
            explanatory tooltips for cycle detection behavior.
        Exceptions:
            Tooltip attachment uses existing best-effort guard logic.
        """
        lf_peak = ttk.Frame(parent)
        lf_peak.grid(row=0, column=0, sticky="ew", **pad)
        for c in range(4):
            lf_peak.grid_columnconfigure(c, weight=1)

        lbl_prom = ttk.Label(lf_peak, text="Prominence (PSI)")
        lbl_prom.grid(row=0, column=0, sticky="w", padx=6, pady=4)
        ent_prom = ttk.Entry(lf_peak, textvariable=self.pk_prominence, width=10)
        ent_prom.grid(row=0, column=1, sticky="w", padx=6, pady=4)

        lbl_dist = ttk.Label(lf_peak, text="Min Distance (samples)")
        lbl_dist.grid(row=0, column=2, sticky="e", padx=6, pady=4)
        ent_dist = ttk.Entry(lf_peak, textvariable=self.pk_distance, width=10)
        ent_dist.grid(row=0, column=3, sticky="w", padx=6, pady=4)

        lbl_min_dp = ttk.Label(lf_peak, text="Minimum dP for Valid Cycle (PSI)")
        lbl_min_dp.grid(row=1, column=0, sticky="w", padx=6, pady=4)
        ent_min_dp = ttk.Entry(lf_peak, textvariable=self.min_cycle_drop, width=10)
        ent_min_dp.grid(row=1, column=1, sticky="w", padx=6, pady=4)

        lbl_width = ttk.Label(lf_peak, text="Min Width (samples)")
        lbl_width.grid(row=1, column=2, sticky="e", padx=6, pady=4)
        ent_width = ttk.Entry(lf_peak, textvariable=self.pk_width, width=10)
        ent_width.grid(row=1, column=3, sticky="w", padx=6, pady=4)

        text_dist = (
            "Min Distance: minimum separation between neighboring peaks (in samples).\n"
            "Higher = peaks must be farther apart; "
            "lower = allows closely spaced peaks.\n"
            "If your sample rate is 1 Hz, a distance of 10 equals about 10 seconds.\n"
        )
        self._attach_tooltip(lbl_dist, text_dist)
        self._attach_tooltip(ent_dist, text_dist)

        text_min_dp = (
            "Minimum delta-P for Valid Cycle: only cycles with peak-to-trough "
            "drop at or above\n"
            "this PSI threshold are counted for moles/uptake totals.\n"
        )
        self._attach_tooltip(lbl_min_dp, text_min_dp)
        self._attach_tooltip(ent_min_dp, text_min_dp)

        text_width = (
            "Min Width: minimum peak width at half height (FWHM), in samples.\n"
            "Higher = filters out narrow spikes; lower = allows sharp/narrow peaks."
        )
        self._attach_tooltip(lbl_width, text_width)
        self._attach_tooltip(ent_width, text_width)

    def _build_plot_gas_section(self, parent, pad: dict[str, int]) -> None:
        """Build the Gas Model (Van der Waals) card content.

        Purpose:
            Render gas preset selection and editable Van der Waals parameters.
        Why:
            These values are typically configured once per profile, so they are
            kept complete but collapsed by default to reduce day-to-day clutter.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Creates gas model widgets, stores entry references, and wires preset
            selection/save/apply callbacks.
        Exceptions:
            Validation and persistence behavior is handled in existing callbacks.
        """
        lf_vdw = ttk.Frame(parent)
        lf_vdw.grid(row=0, column=0, sticky="ew", **pad)
        lf_vdw.grid_columnconfigure(1, weight=1)
        lf_vdw.grid_columnconfigure(2, weight=0)

        ttk.Label(lf_vdw, text="Preset").grid(
            row=0, column=0, sticky="w", padx=6, pady=4
        )
        cb_gas = ttk.Combobox(
            lf_vdw,
            textvariable=self.v_gas,
            state="readonly",
            values=list(GAS_PRESETS.keys()),
        )
        cb_gas.grid(row=0, column=1, sticky="ew", padx=6, pady=4)
        self._gas_combo = cb_gas
        self._refresh_gas_preset_choices()
        cb_gas.bind("<<ComboboxSelected>>", self._on_gas_selected)
        ttk.Button(
            lf_vdw, text="Save Preset", command=self._save_custom_gas_preset
        ).grid(row=0, column=2, sticky="e", padx=6, pady=4)

        ttk.Label(lf_vdw, text="Vessel Volume (L)").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )
        self.e_vol = ttk.Entry(lf_vdw, textvariable=self.v_volume)
        self.e_vol.grid(row=1, column=1, sticky="ew", padx=6, pady=4)

        apply_vdw_frame = ttk.Frame(lf_vdw)
        apply_vdw_frame.grid(row=1, column=2, sticky="e", padx=6, pady=4)
        apply_vdw_frame.grid_columnconfigure(0, weight=1)
        ttk.Button(apply_vdw_frame, text="Apply VDW", command=self._apply_vdw).grid(
            row=0, column=0, sticky="e"
        )
        self._create_vdw_indicator(
            apply_vdw_frame, row=0, column=1, padx=(6, 0), sticky="w"
        )

        ttk.Label(lf_vdw, text="VDW a (L^2*atm/mol^2)").grid(
            row=2, column=0, sticky="w", padx=6, pady=4
        )
        self.e_a = ttk.Entry(lf_vdw, textvariable=self.v_a)
        self.e_a.grid(row=2, column=1, sticky="ew", padx=6, pady=4)

        ttk.Label(lf_vdw, text="VDW b (L/mol)").grid(
            row=3, column=0, sticky="w", padx=6, pady=4
        )
        self.e_b = ttk.Entry(lf_vdw, textvariable=self.v_b)
        self.e_b.grid(row=3, column=1, sticky="ew", padx=6, pady=4)

        ttk.Label(lf_vdw, text="Gaseous Reagent Molar Mass (g/mol)").grid(
            row=4, column=0, sticky="w", padx=6, pady=4
        )
        self.e_gas_molar_mass = ttk.Entry(lf_vdw, textvariable=self.v_gas_molar_mass)
        self.e_gas_molar_mass.grid(row=4, column=1, sticky="ew", padx=6, pady=4)

    def _build_plot_starting_material_section(
        self, parent, pad: dict[str, int]
    ) -> None:
        """Build the Starting Material Settings card content.

        Purpose:
            Render starting-material naming, mass, and stoichiometry controls.
        Why:
            These profile-level settings are required but infrequently changed, so
            the section stays fully available while defaulting to collapsed state.
        Args:
            parent: Card body frame produced by `_add_plot_settings_card`.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Creates entry widgets and binds focus/Enter events to
            `_apply_product_settings` for existing validation and persistence.
        Exceptions:
            Input validation and messagebox handling remain in existing callbacks.
        """
        lf_reagent = ttk.Frame(parent)
        lf_reagent.grid(row=0, column=0, sticky="ew", **pad)
        lf_reagent.grid_columnconfigure(1, weight=1)

        ttk.Label(
            lf_reagent,
            text="Starting material reacting with selected gas",
        ).grid(row=0, column=0, sticky="w", padx=6, pady=4)
        ent_display_name = ttk.Entry(
            lf_reagent, textvariable=self.v_starting_material_display_name, width=56
        )
        ent_display_name.grid(row=0, column=1, sticky="ew", padx=6, pady=4)
        ent_display_name.bind("<FocusOut>", self._apply_product_settings)
        ent_display_name.bind("<Return>", self._apply_product_settings)

        ttk.Label(lf_reagent, text="Starting material note (optional)").grid(
            row=1, column=0, sticky="w", padx=6, pady=4
        )
        ent_display_note = ttk.Entry(
            lf_reagent, textvariable=self.v_starting_material_display_note, width=56
        )
        ent_display_note.grid(row=1, column=1, sticky="ew", padx=6, pady=4)
        ent_display_note.bind("<FocusOut>", self._apply_product_settings)
        ent_display_note.bind("<Return>", self._apply_product_settings)

        ttk.Label(lf_reagent, text="Starting Material Molar Mass (g/mol)").grid(
            row=2, column=0, sticky="w", padx=6, pady=4
        )
        ent_molar = ttk.Entry(lf_reagent, textvariable=self.v_product_molar_mass)
        ent_molar.grid(row=2, column=1, sticky="ew", padx=6, pady=4)
        ent_molar.bind("<FocusOut>", self._apply_product_settings)
        ent_molar.bind("<Return>", self._apply_product_settings)

        ttk.Label(lf_reagent, text="Starting Material Mass (g)").grid(
            row=3, column=0, sticky="w", padx=6, pady=4
        )
        ent_start = ttk.Entry(lf_reagent, textvariable=self.v_starting_mass)
        ent_start.grid(row=3, column=1, sticky="ew", padx=6, pady=4)
        ent_start.bind("<FocusOut>", self._apply_product_settings)
        ent_start.bind("<Return>", self._apply_product_settings)

        ttk.Label(
            lf_reagent,
            text="Stoichiometry (mol gas per mol starting)",
        ).grid(row=4, column=0, sticky="w", padx=6, pady=4)
        ent_stoich = ttk.Entry(lf_reagent, textvariable=self.v_starting_stoich)
        ent_stoich.grid(row=4, column=1, sticky="ew", padx=6, pady=4)
        ent_stoich.bind("<FocusOut>", self._apply_product_settings)
        ent_stoich.bind("<Return>", self._apply_product_settings)

    def _build_tab_plot(self):
        """Build the redesigned Plot Settings tab shell.

        Purpose:
            Assemble a fully scrollable Plot Settings card stack with Axis & Range first.
        Why:
            A unified scroll surface keeps every section reachable with the wheel
            while preserving axis/range-first workflow order and existing controls.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Rebuilds Plot Settings widgets, initializes card-state bookkeeping, and
            schedules stage-two section construction on the Tk idle queue.
        Exceptions:
            UI cleanup and wheel-binding steps use best-effort guards to avoid
            interrupting startup if a widget teardown/bind fails.
        """
        f = self.tab_plot
        for child in f.winfo_children():
            try:
                child.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        f.grid_rowconfigure(0, weight=1)
        f.grid_columnconfigure(0, weight=1)

        self._plot_settings_card_states = {}
        self._plot_settings_card_bodies = {}
        self._plot_settings_card_widgets = {}
        self._plot_settings_card_reorderable = {}
        self._plot_settings_card_order = []
        self._plot_settings_next_row = 0
        self._plot_settings_refresh_scroll_region = None
        self._plot_settings_drag_state = None
        self._plot_settings_drag_preview_line = None
        self._plot_settings_content_frame = None

        scroll_shell = ttk.Frame(f)
        scroll_shell.grid(row=0, column=0, sticky="nsew", padx=8, pady=(8, 8))
        scroll_shell.grid_rowconfigure(0, weight=1)
        scroll_shell.grid_columnconfigure(0, weight=1)

        canvas = tk.Canvas(scroll_shell, borderwidth=0, highlightthickness=0)
        vscroll = _ui_scrollbar(scroll_shell, orient="vertical", command=canvas.yview)
        canvas.configure(yscrollcommand=vscroll.set)
        canvas.grid(row=0, column=0, sticky="nsew")
        vscroll.grid(row=0, column=1, sticky="ns")

        content = ttk.Frame(canvas)
        settings_window = canvas.create_window((0, 0), window=content, anchor="nw")
        self._plot_settings_content_frame = content

        def _refresh_scroll_region(_event=None) -> None:
            """Sync canvas scrollregion to current accordion content bounds."""
            try:
                canvas.configure(scrollregion=canvas.bbox("all"))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _expand_width(event) -> None:
            """Keep scroll content width matched to visible canvas width."""
            try:
                canvas.itemconfigure(settings_window, width=event.width)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        content.bind("<Configure>", _refresh_scroll_region)
        canvas.bind("<Configure>", _expand_width)
        self._plot_settings_refresh_scroll_region = _refresh_scroll_region

        def _bind_mousewheel(widget) -> None:
            """Bind wheel-scrolling recursively for Plot Settings widgets."""

            def _on_mousewheel(event):
                delta = event.delta
                if delta == 0:
                    return
                step = -1 if delta > 0 else 1
                if abs(delta) >= 120:
                    step = int(-delta / 120)
                canvas.yview_scroll(step, "units")
                return "break"

            widget.bind("<MouseWheel>", _on_mousewheel, add="+")
            widget.bind(
                "<Button-4>", lambda _event: canvas.yview_scroll(-1, "units"), add="+"
            )
            widget.bind(
                "<Button-5>", lambda _event: canvas.yview_scroll(1, "units"), add="+"
            )
            # Recursively binding descendants keeps wheel scrolling responsive even
            # when focus sits on nested entries or combobox controls.
            for child in widget.winfo_children():
                _bind_mousewheel(child)

        self.after_idle(lambda: _bind_mousewheel(canvas))
        for i in range(4):
            content.grid_columnconfigure(i, weight=1)

        pad = {"padx": 8, "pady": 6}
        self._plot_tab_stage_two_built = False
        axis_range_body = self._add_plot_settings_card(
            content,
            "axis_range",
            "Axis & Range",
            expanded=True,
            collapsible=False,
            accent=True,
            reorderable=False,
        )
        self._build_plot_axis_range_section(axis_range_body, pad)
        self.after_idle(lambda: self._build_tab_plot_stage_two(content, pad))

    def _build_tab_plot_stage_two(self, f, pad):
        """Build deferred accordion cards for Plot Settings.

        Purpose:
            Render Plot Settings accordion sections after Axis & Range is built.
        Why:
            Deferred build keeps initial tab paint responsive while still exposing
            the complete configuration surface.
        Args:
            f: Scroll-content frame that hosts accordion cards.
            pad: Shared padding dictionary for section internals.
        Returns:
            None.
        Side Effects:
            Creates accordion cards, instantiates all section widgets, and refreshes
            combined-axis selector choices once controls exist.
        Exceptions:
            If the target frame no longer exists, the build exits silently.
        """
        if getattr(self, "_plot_tab_stage_two_built", False):
            return
        if f is None or not f.winfo_exists():
            return
        self._plot_tab_stage_two_built = True

        registry = self._plot_settings_stage_two_card_registry()
        registry_map = {entry["key"]: entry for entry in registry}
        stage_two_order = self._resolve_plot_settings_card_order()

        # Iterate over the normalized persisted order so drag persistence controls
        # the visual sequence without rebuilding card internals.
        for key in stage_two_order:
            entry = registry_map.get(key)
            if entry is None:
                continue
            body = self._add_plot_settings_card(
                f,
                key,
                str(entry.get("title", key)),
                expanded=bool(entry.get("expanded", False)),
                collapsible=bool(entry.get("collapsible", True)),
                reorderable=bool(entry.get("reorderable", True)),
            )
            builder = entry.get("builder")
            if callable(builder):
                builder(body, pad)

        self._refresh_combined_axis_choices()
        self._request_plot_settings_scroll_refresh()
        self._startup_plot_stage_two_ready = True
        self._update_startup_loading_splash_progress(
            progress=74.0,
            message="Plot Settings controls ready.",
        )

    def _start_cycle_tab_build(self, *, defer=True):
        """Build value.
        Used by start cycle tab workflows to build value."""
        self._cycle_ui_built = False
        self._cycle_build_ctx = {}
        self._cycle_button_fonts = []
        self._cycle_build_gen = None  # legacy attribute, kept for compatibility
        self._stop_cycle_loading_indicator(restore_text=False)

        if defer:
            frame = ttk.Frame(self.tab_cycle)
            frame.grid(row=0, column=0, sticky="nsew")

            label = ttk.Label(
                frame,
                text="Preparing Cycle Analysis UI…",
                justify="center",
                anchor="center",
                wraplength=420,
            )
            label.pack(expand=True, fill="both", pady=24, padx=24)

            self._cycle_loading_frame = frame
            self._cycle_loading_label = label
        else:
            self._cycle_loading_frame = None
            self._cycle_loading_label = None

        if defer:
            self.after_idle(self._build_tab_cycle_stage_one)
        else:
            self._build_tab_cycle_stage_one(defer=False)
            self.update_idletasks()

    def _build_tab_cycle(self):
        """Build tab cycle.
        Used to assemble tab cycle during UI or plot setup."""
        self._start_cycle_tab_build()

    def _build_tab_cycle_stage_one(self, *, defer=True):
        """Build stage-one structure for the Cycle Analysis tab.

        Purpose:
            Create the primary split layout and shared helpers used by later
            Cycle Analysis build stages.
        Why:
            Staged construction keeps initial rendering responsive while still
            preparing scrollable controls and plotting surfaces.
        Args:
            defer: When True, keeps stage orchestration compatible with deferred
                build scheduling; retained for existing call paths.
        Returns:
            None.
        Side Effects:
            Initializes cycle build context, creates pane/canvas widgets, and
            defines button-construction helpers consumed by stage two/three.
        Exceptions:
            Missing tab references short-circuit safely without raising.
        """
        if not getattr(self, "tab_cycle", None):
            return

        ctx = self._cycle_build_ctx
        ctx.clear()

        base_font = tkfont.nametofont("TkDefaultFont")
        btn_family = getattr(self, "_ui_font_family", base_font.actual("family"))
        effective_size = getattr(self, "_effective_font_size", base_font.actual("size"))
        btn_size = max(effective_size - 1, 8)
        ctx["btn_family"] = btn_family
        ctx["btn_size"] = btn_size

        scale_len = self._scale_length
        WRAP_PX = scale_len(160)
        FIXED_BTN_WIDTH = scale_len(220)

        # Closure captures _build_tab_cycle_stage_one local context to keep helper logic scoped and invoked directly within _build_tab_cycle_stage_one.
        def _make_cycle_button(
            parent,
            *,
            text,
            command,
            grid_kwargs,
            tooltip=None,
            wrap_px=WRAP_PX,
            bold=True,
            allow_wrap=True,
        ):
            """Perform make cycle button.
            Used to keep the workflow logic localized and testable."""
            font_kwargs = {"family": btn_family, "size": btn_size}
            if bold:
                font_kwargs["weight"] = "bold"

            font_obj = tkfont.Font(**font_kwargs)
            chunks = [
                chunk
                # Iterate to apply the per-item logic.
                for chunk in text.replace("/", " ").replace("-", " ").split()
                if chunk
            ]
            if not chunks:
                chunks = [text]

            # Closure captures _build_tab_cycle_stage_one local context to keep helper logic scoped and invoked directly within _build_tab_cycle_stage_one.
            def longest_chunk_width():
                """Perform longest chunk width.
                Used to keep the workflow logic localized and testable."""
                return max(font_obj.measure(chunk) for chunk in chunks)

            # Closure captures _build_tab_cycle_stage_one local context to keep helper logic scoped and invoked directly within _build_tab_cycle_stage_one.
            def wrap_text_if_needed(label_text, limit_px):
                """Wrap text if needed.
                Used to format text if needed to fit display constraints."""
                words = label_text.split()
                if len(words) <= 1:
                    return label_text

                lines = []
                current = words[0]
                # Iterate over words[1 to apply the per-item logic.
                for word in words[1:]:
                    candidate = f"{current} {word}"
                    if font_obj.measure(candidate) <= limit_px:
                        current = candidate
                    else:
                        lines.append(current)
                        current = word
                lines.append(current)
                return "\n".join(lines)

            effective_wrap = max(wrap_px, longest_chunk_width())
            display_text = text
            if allow_wrap and font_obj.measure(text) > effective_wrap:
                display_text = wrap_text_if_needed(text, effective_wrap)

            holder = ttk.Frame(parent, width=FIXED_BTN_WIDTH)
            holder.grid(**grid_kwargs)
            try:
                holder.grid_propagate(False)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            btn = _ui_button(
                holder,
                text=display_text,
                command=command,
            )
            btn.pack(fill="both", expand=True)
            if tooltip:
                self._attach_tooltip(btn, tooltip)
            return btn

        ctx["make_button"] = _make_cycle_button

        f = self.tab_cycle
        f.grid_rowconfigure(0, weight=1)
        f.grid_columnconfigure(0, weight=1)

        pw = ttk.PanedWindow(f, orient="horizontal")
        pw.grid(
            row=0,
            column=0,
            sticky="nsew",
            padx=scale_len(8),
            pady=scale_len(8),
        )
        ctx["paned"] = pw

        left_outer = ttk.Frame(pw)
        left_outer.grid_rowconfigure(0, weight=1)
        left_outer.grid_columnconfigure(0, weight=1)
        # Tkinter has no native scrollable frame; wrap Cycle controls in a canvas
        # so enlarged UI text does not clip buttons/outputs in the left panel.
        left_canvas = tk.Canvas(left_outer, borderwidth=0, highlightthickness=0)
        left_scrollbar = _ui_scrollbar(
            left_outer, orient="vertical", command=left_canvas.yview
        )
        left_canvas.configure(yscrollcommand=left_scrollbar.set)
        left_canvas.grid(row=0, column=0, sticky="nsew")
        left_scrollbar.grid(row=0, column=1, sticky="ns")
        left = ttk.Frame(left_canvas)
        left_window_id = left_canvas.create_window((0, 0), window=left, anchor="nw")
        right = ttk.Frame(pw)
        ctx["left_frame"] = left
        ctx["left_outer_frame"] = left_outer
        ctx["left_canvas"] = left_canvas
        ctx["right_frame"] = right

        pw.add(left_outer, weight=1)
        pw.add(right, weight=2)

        split_frac = float(settings.get("cycle_split_frac", 0.35))

        # Closure captures _build_tab_cycle_stage_one state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_tab_cycle_stage_one.
        def _apply_initial_split():
            """Apply initial split.
            Used to apply initial split changes to live state."""
            if pw is None or not pw.winfo_exists():
                return
            tot = pw.winfo_width()
            if tot <= 1:
                self.after(0, _apply_initial_split)
                return
            try:
                pw.sashpos(0, int(tot * split_frac))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        self.after(0, _apply_initial_split)

        # Closure captures _build_tab_cycle_stage_one local context to keep helper logic scoped and invoked directly within _build_tab_cycle_stage_one.
        def _persist_split(_e=None):
            """Split value.
            Used by persist workflows to split value."""
            try:
                tot = pw.winfo_width()
                if tot > 1:
                    frac = max(0.05, min(0.95, pw.sashpos(0) / tot))
                    settings["cycle_split_frac"] = frac
                    _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        pw.bind("<ButtonRelease-1>", _persist_split)

        left.grid_columnconfigure(0, weight=1)
        right.grid_rowconfigure(1, weight=1)
        right.grid_columnconfigure(0, weight=1)

        def _refresh_left_scroll_region(_event=None) -> None:
            """Refresh left-panel canvas scrollregion after child layout changes."""
            try:
                left_canvas.configure(scrollregion=left_canvas.bbox("all"))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _sync_left_inner_width(event) -> None:
            """Keep inner left-panel content width in sync with canvas width."""
            try:
                left_canvas.itemconfigure(left_window_id, width=event.width)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        def _bind_left_mousewheel(widget) -> None:
            """Bind wheel scrolling across left-panel controls except text widgets."""

            def _is_native_scroll_target(target) -> bool:
                return isinstance(target, (tk.Text, tk.Listbox, ttk.Treeview))

            def _scroll_units(step: int, event=None):
                target = getattr(event, "widget", None)
                if _is_native_scroll_target(target):
                    return None
                left_canvas.yview_scroll(step, "units")
                return "break"

            def _on_mousewheel(event):
                if _is_native_scroll_target(getattr(event, "widget", None)):
                    return None
                delta = getattr(event, "delta", 0)
                if delta == 0:
                    return "break"
                step = -1 if delta > 0 else 1
                if abs(delta) >= 120:
                    step = int(-delta / 120)
                return _scroll_units(step, event)

            widget.bind("<MouseWheel>", _on_mousewheel, add="+")
            widget.bind(
                "<Button-4>", lambda event: _scroll_units(-1, event), add="+"
            )
            widget.bind(
                "<Button-5>", lambda event: _scroll_units(1, event), add="+"
            )
            # Iterate over widget.winfo_children() to apply the per-item logic.
            for child in widget.winfo_children():
                _bind_left_mousewheel(child)

        left.bind("<Configure>", _refresh_left_scroll_region)
        left_canvas.bind("<Configure>", _sync_left_inner_width)
        ctx["bind_left_mousewheel"] = _bind_left_mousewheel

        sel_label = ttk.Label(left, text="Selection: (awaiting column apply)")
        sel_label.grid(row=0, column=0, sticky="w", pady=(0, scale_len(6)))
        self._cycle_sel_label = sel_label
        ctx["selection_label"] = sel_label

        self._refresh_cycle_selection_text()

        if self._cycle_loading_label:
            self._cycle_loading_label.config(text="Configuring cycle controls…")

        if defer:
            self.after_idle(self._build_tab_cycle_stage_two)
        else:
            self._build_tab_cycle_stage_two(defer=False)

    def _build_tab_cycle_stage_two(self, *, defer=True):
        """Build stage-two controls for Cycle Analysis workflows.

        Purpose:
            Populate the left/right Cycle Analysis panes with core actions,
            marker workflows, and controls that depend on stage-one context.
        Why:
            Separating this stage keeps complex control wiring isolated while
            preserving deferred-build responsiveness.
        Args:
            defer: Maintained for staged-build API compatibility.
        Returns:
            None.
        Side Effects:
            Creates interactive controls, binds callbacks, and updates cycle
            UI state references in the shared build context.
        Exceptions:
            Returns early when stage-one context is unavailable.
        """
        ctx = self._cycle_build_ctx
        left = ctx.get("left_frame")
        right = ctx.get("right_frame")
        make_button = ctx.get("make_button")
        scale_len = self._scale_length
        scale_pad = self._scale_padding

        if left is None or right is None or make_button is None:
            return

        manual_frame = ttk.Labelframe(left, text="Manual Workflow")
        manual_frame.grid(row=1, column=0, sticky="ew", pady=(0, scale_len(10)))
        # Iterate over the configured range to apply the per-item logic.
        for col in range(2):
            manual_frame.grid_columnconfigure(col, weight=1)

        make_button(
            manual_frame,
            text="Update / Generate Figure 3",
            command=self._update_fig3_from_current_markers,
            grid_kwargs={
                "row": 0,
                "column": 0,
                "columnspan": 2,
                "sticky": "nsew",
                "padx": scale_pad((0, 0)),
                "pady": scale_pad((0, 6)),
            },
            tooltip=(
                "Close and regenerate the 'Figure 3: Cycle Analysis' tab using the markers currently "
                'shown in this interactive plot. This ignores the Minimum I"P threshold.'
            ),
            allow_wrap=False,
        )

        make_button(
            manual_frame,
            text="Undo Marker Edit",
            command=self._undo_cycle_marker_edit,
            grid_kwargs={
                "row": 1,
                "column": 0,
                "sticky": "nsew",
                "padx": scale_pad((0, 6)),
                "pady": scale_pad((0, 6)),
            },
            tooltip="Undo the most recent marker edit.",
        )

        make_button(
            manual_frame,
            text="Redo Marker Edit",
            command=self._redo_cycle_marker_edit,
            grid_kwargs={
                "row": 1,
                "column": 1,
                "sticky": "nsew",
                "padx": scale_pad((6, 0)),
                "pady": scale_pad((0, 6)),
            },
            tooltip="Redo the last undone marker edit.",
        )

        make_button(
            manual_frame,
            text="Clear All Markers",
            command=self._clear_all_markers,
            grid_kwargs={
                "row": 2,
                "column": 0,
                "sticky": "nsew",
                "padx": scale_pad((0, 6)),
                "pady": scale_pad((0, 6)),
            },
            tooltip=(
                "Remove ALL markers (auto + manual) and start with a blank slate.\n"
                "Use SHIFT + Left-click = Peak, SHIFT + Right-click = Trough.\n"
                "Right-click (no SHIFT) removes nearest marker."
            ),
        )

        make_button(
            manual_frame,
            text="Save Summary Image (PNG)",
            command=self._save_cycle_summary_png,
            grid_kwargs={
                "row": 2,
                "column": 1,
                "sticky": "nsew",
                "padx": scale_pad((6, 0)),
                "pady": scale_pad((0, 6)),
            },
            tooltip="Save the Cycle Analysis Summary text as a PNG image for sharing or records.",
        )

        make_button(
            manual_frame,
            text="Export Markers (JSON/CSV)",
            command=self._export_cycle_markers,
            grid_kwargs={
                "row": 3,
                "column": 0,
                "sticky": "nsew",
                "padx": scale_pad((0, 6)),
                "pady": scale_pad((0, 6)),
            },
            tooltip="Export the current selection and marker sets to JSON or CSV.",
        )

        make_button(
            manual_frame,
            text="Import Markers",
            command=self._import_cycle_markers,
            grid_kwargs={
                "row": 3,
                "column": 1,
                "sticky": "nsew",
                "padx": scale_pad((6, 0)),
                "pady": scale_pad((0, 6)),
            },
            tooltip="Import a saved marker set (selection range + thresholds included).",
        )

        make_button(
            manual_frame,
            text="Export Cycle Results (CSV)",
            command=self._export_cycle_results_csv,
            grid_kwargs={
                "row": 4,
                "column": 0,
                "sticky": "nsew",
                "padx": scale_pad((0, 6)),
                "pady": scale_pad((0, 0)),
            },
            tooltip="Export per-cycle metrics and gas uptake results to CSV.",
        )

        make_button(
            manual_frame,
            text="Copy Summary to Clipboard",
            command=self._copy_cycle_summary_to_clipboard,
            grid_kwargs={
                "row": 4,
                "column": 1,
                "sticky": "nsew",
                "padx": scale_pad((6, 0)),
                "pady": scale_pad((0, 0)),
            },
            tooltip="Copy the Cycle Analysis Summary text to the clipboard.",
        )

        advanced_container = ttk.Frame(left)
        advanced_container.grid(row=2, column=0, sticky="ew", pady=(0, scale_len(8)))
        advanced_container.grid_columnconfigure(0, weight=1)
        advanced_visible = tk.BooleanVar(value=False)

        # Closure captures _build_tab_cycle_stage_two state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_tab_cycle_stage_two.
        def _toggle_advanced():
            """Toggle advanced.
            Used to flip advanced and refresh dependent views."""
            showing = bool(advanced_visible.get())
            if showing:
                advanced_body.grid_remove()
                advanced_visible.set(False)
                advanced_toggle.configure(text="Show Advanced / Recompute")
            else:
                advanced_body.grid()
                advanced_visible.set(True)
                advanced_toggle.configure(text="Hide Advanced / Recompute")

        advanced_toggle = _ui_button(
            advanced_container,
            text="Show Advanced / Recompute",
            command=_toggle_advanced,
        )
        advanced_toggle.grid(row=0, column=0, sticky="ew")

        advanced_body = ttk.Frame(advanced_container)
        advanced_body.grid(row=1, column=0, sticky="ew", pady=(scale_len(6), 0))
        # Iterate over the configured range to apply the per-item logic.
        for col in range(2):
            advanced_body.grid_columnconfigure(col, weight=1)
        advanced_body.grid_remove()

        make_button(
            advanced_body,
            text="Send to Advanced Speciation & Equilibrium Engine",
            command=self._send_cycles_to_speciation_engine,
            grid_kwargs={
                "row": 0,
                "column": 0,
                "columnspan": 2,
                "sticky": "nsew",
                "padx": scale_pad((0, 0)),
                "pady": scale_pad((0, 6)),
            },
            tooltip=(
                "Send the finalized Cycle Analysis payload to the Advanced Speciation & Equilibrium Engine "
                "workflow, including Reaction Tracker entries and analysis inputs."
            ),
        )

        make_button(
            advanced_body,
            text="Analyze Selection",
            command=self._use_cycle_selection,
            grid_kwargs={
                "row": 1,
                "column": 0,
                "sticky": "nsew",
                "padx": scale_pad((0, 6)),
                "pady": scale_pad((0, 6)),
            },
            tooltip=(
                "Analyze only the last range you dragged on the chart.\n"
                "Tip: drag horizontally to set the gray selection band, then click this."
            ),
        )

        make_button(
            advanced_body,
            text="Analyze Full Range",
            command=self._use_cycle_all,
            grid_kwargs={
                "row": 1,
                "column": 1,
                "sticky": "nsew",
                "padx": scale_pad((6, 0)),
                "pady": scale_pad((0, 6)),
            },
            tooltip="Clear any selection and analyze the entire dataset (all valid rows).",
        )

        make_button(
            advanced_body,
            text="Re-detect Peaks/Troughs",
            command=self._redetect_cycle_peaks,
            grid_kwargs={
                "row": 2,
                "column": 0,
                "sticky": "nsew",
                "padx": scale_pad((0, 6)),
                "pady": scale_pad((0, 0)),
            },
            tooltip=(
                "Re-run automatic peak/trough detection using the current settings "
                "(Prominence, Distance, Width). Manual adds/removals are preserved."
            ),
            allow_wrap=False,
        )

        make_button(
            advanced_body,
            text="Reset Manual Marks",
            command=self._reset_manual_edits,
            grid_kwargs={
                "row": 2,
                "column": 1,
                "sticky": "nsew",
                "padx": scale_pad((6, 0)),
                "pady": scale_pad((0, 0)),
            },
            tooltip=(
                "Remove all manually added/removed peaks & troughs and revert to the current "
                "auto-detected set."
            ),
        )

        self._auto_detect_chk = _ui_checkbutton(
            left,
            text="Enable automatic peak/trough detection",
            variable=self.auto_detect_cycles,
            command=self._on_toggle_auto_detection,
        )
        self._auto_detect_chk.grid(
            row=3,
            column=0,
            sticky="w",
            padx=self._scale_length(2),
            pady=(0, self._scale_length(8)),
        )

        self._attach_tooltip(
            self._auto_detect_chk,
            (
                "When enabled, rerunning analysis will re-detect peaks and troughs "
                "using the configured parameters. Disable this to preserve manual markers."
            ),
        )

        # Temperature selection
        temp_frame = ttk.Frame(left)
        temp_frame.grid(row=4, column=0, sticky="ew", pady=(0, scale_len(8)))
        temp_frame.grid_columnconfigure(1, weight=1)

        ttk.Label(temp_frame, text="Cycle temperature column").grid(
            row=0,
            column=0,
            sticky="w",
            padx=scale_len(6),
            pady=scale_len(6),
        )

        self._cycle_temp_combo = _ui_combobox(
            temp_frame,
            textvariable=self.cycle_temp_column,
            state="readonly",
            values=self._cycle_temp_choices(),
        )
        self._cycle_temp_combo.grid(
            row=0,
            column=1,
            sticky="ew",
            padx=scale_len(6),
            pady=scale_len(6),
        )
        self._cycle_temp_combo.bind(
            "<<ComboboxSelected>>", self._on_cycle_temp_selected
        )

        self._attach_tooltip(
            self._cycle_temp_combo,
            (
                "Select the column used to compute per-cycle temperatures.\n"
                "Choose the default to assume 25 C for every cycle."
            ),
        )

        self._refresh_cycle_temp_choices()
        self._refresh_combined_axis_choices()

        hint = (
            "Selection: Hold Ctrl and drag on the plot to choose an x-range.\n"
            "Marker editing:\n"
            "* SHIFT + Left-click  = Peak\n"
            "* SHIFT + Right-click = Trough\n"
            "* Right-click (no SHIFT) = remove nearest Peak/Trough\n"
            "Tip: Peaks/troughs snap to local extrema near your click."
        )

        ttk.Label(
            left,
            text=hint,
            style="CycleHint.TLabel",
            wraplength=340,
            justify="left",
        ).grid(row=5, column=0, sticky="w", pady=(0, scale_len(8)))

        if self._cycle_loading_label:
            self._cycle_loading_label.config(text="Preparing summary display…")

        if defer:
            self.after_idle(self._build_tab_cycle_stage_three)
        else:
            self._build_tab_cycle_stage_three(defer=False)

    def _build_tab_cycle_stage_three(self, *, defer=True):
        """Build stage-three summary/format controls for Cycle Analysis.

        Purpose:
            Add final-cycle formatting toggles and summary options once stage-two
            controls are present.
        Why:
            This stage groups lower-frequency options separately from primary
            detection actions to keep the workflow readable.
        Args:
            defer: Maintained for staged-build API compatibility.
        Returns:
            None.
        Side Effects:
            Creates additional checkboxes/frames and stores widget references
            used by downstream cycle formatting logic.
        Exceptions:
            Returns safely when prerequisite stage context is missing.
        """
        ctx = self._cycle_build_ctx
        left = ctx.get("left_frame")
        right = ctx.get("right_frame")
        if left is None or right is None:
            return

        self.cb_include_moles_legend = _ui_checkbutton(
            left,
            text="Include moles summary in Figure 3 legend",
            variable=self.include_moles_legend,
        )
        self.cb_include_moles_legend.grid(
            row=6, column=0, sticky="w", padx=2, pady=(0, 6)
        )

        lf_summary_fmt = ttk.Labelframe(left, text="Summary Formatting")
        lf_summary_fmt.grid(
            row=7,
            column=0,
            sticky="ew",
            padx=self._scale_length(4),
            pady=(0, self._scale_length(8)),
        )
        lf_summary_fmt.grid_columnconfigure(0, weight=1)

        _ui_checkbutton(
            lf_summary_fmt,
            text="Compact summary",
            variable=self.summary_compact,
        ).grid(row=0, column=0, sticky="w", padx=6, pady=(4, 2))

        _ui_checkbutton(
            lf_summary_fmt,
            text="Include diagnostics",
            variable=self.summary_include_diagnostics,
        ).grid(row=1, column=0, sticky="w", padx=6, pady=2)

        _ui_checkbutton(
            lf_summary_fmt,
            text="Include per-cycle gas mass",
            variable=self.summary_include_per_cycle_gas_mass,
        ).grid(row=2, column=0, sticky="w", padx=6, pady=2)

        self._summary_include_conversion_chk = _ui_checkbutton(
            lf_summary_fmt,
            text="Include conversion estimate",
            variable=self.summary_include_conversion_estimate,
        )
        self._summary_include_conversion_chk.grid(
            row=3, column=0, sticky="w", padx=6, pady=2
        )

        ttk.Label(
            lf_summary_fmt,
            textvariable=self._cycle_summary_conversion_status,
            wraplength=320,
            justify="left",
        ).grid(row=4, column=0, sticky="w", padx=6, pady=(2, 6))

        self._update_cycle_summary_conversion_status()

        lf_sum = ttk.Labelframe(left, text="Cycle Analysis Summary (this tab)")
        lf_sum.grid(
            row=8,
            column=0,
            sticky="nsew",
            padx=self._scale_length(4),
            pady=(0, self._scale_length(8)),
        )

        left.grid_rowconfigure(6, weight=0)
        left.grid_rowconfigure(7, weight=0)
        left.grid_rowconfigure(8, weight=1)

        summary_font = tkfont.nametofont("TkTextFont")
        self._cycle_summary_box = scrolledtext.ScrolledText(
            lf_sum,
            height=12,
            wrap="word",
            state="disabled",
            font=summary_font,
        )
        self._cycle_summary_box.pack(
            fill="both",
            expand=True,
            padx=self._scale_length(6),
            pady=self._scale_length(6),
        )
        left_mousewheel_binder = ctx.get("bind_left_mousewheel")
        if callable(left_mousewheel_binder):
            self.after_idle(lambda: left_mousewheel_binder(left))
        self._set_cycle_summary(getattr(self, "_pending_cycle_summary", ""))

        right.grid_rowconfigure(1, weight=1)
        right.grid_columnconfigure(0, weight=1)

        if self._cycle_loading_label:
            self._cycle_loading_label.config(text="Initializing plot canvas…")

        if defer:
            self.after_idle(self._build_tab_cycle_stage_four)
        else:
            self._build_tab_cycle_stage_four()

    def _build_tab_cycle_stage_four(self):
        """Finalize Cycle Analysis UI construction and interactive plot wiring.

        Purpose:
            Create the Cycle Analysis Matplotlib canvas, toolbar, and interaction
            hooks after staged control construction completes.
        Why:
            The cycle tab is built in deferred stages to keep startup responsive;
            this final stage marks cycle readiness for startup splash gating.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Instantiates cycle figure/canvas widgets, binds interaction callbacks,
            restores cached marker edits, and updates startup readiness flags.
        Exceptions:
            Returns early when stage context is missing; widget errors are guarded.
        """
        ctx = self._cycle_build_ctx
        right = ctx.get("right_frame")
        if right is None:
            return

        self._stop_cycle_loading_indicator(restore_text=False)

        import matplotlib.pyplot as plt

        self._cycle_fig, self._cycle_ax = plt.subplots(figsize=(11, 8.5))
        self._cycle_fig.subplots_adjust(left=0.08, right=0.98, top=0.92, bottom=0.12)

        self._cycle_canvas = FigureCanvasTkAgg(self._cycle_fig, master=right)
        self._cycle_canvas.draw()
        self._cycle_canvas.get_tk_widget().grid(row=1, column=0, sticky="nsew")

        self._cycle_toolbar = NavigationToolbar2Tk(
            self._cycle_canvas, right, pack_toolbar=False
        )
        self._cycle_toolbar.update()
        self._cycle_toolbar.grid(row=0, column=0, sticky="ew")
        self._apply_toolbar_scaling(self._cycle_toolbar)

        self._cycle_span = SpanSelector(
            self._cycle_ax,
            onselect=self._on_span_select,
            direction="horizontal",
            useblit=True,
            props=dict(alpha=0.2),
            interactive=True,
        )

        try:
            self._cycle_span.set_active(False)
        except Exception:
            self._cycle_span.active = False

        self._cycle_cid = self._cycle_canvas.mpl_connect(
            "button_press_event", self._on_cycle_click
        )
        self._cycle_release_cid = self._cycle_canvas.mpl_connect(
            "button_release_event", self._on_cycle_mouse_release
        )
        self._cycle_kp_cid = self._cycle_canvas.mpl_connect(
            "key_press_event", self._on_cycle_key_press
        )
        self._cycle_kr_cid = self._cycle_canvas.mpl_connect(
            "key_release_event", self._on_cycle_key_release
        )

        # Internal state
        self._cycle_pending_range = None
        self._cycle_pending_limits = (None, None)
        self._cycle_mask = None

        preloaded_markers = getattr(self, "_preloaded_cycle_markers", None) or {}
        self._auto_peaks = set(preloaded_markers.get("peaks", []))
        self._auto_troughs = set(preloaded_markers.get("troughs", []))
        self._preloaded_cycle_markers = None

        self._add_peaks = set()
        self._add_troughs = set()
        self._rm_peaks = set()
        self._rm_troughs = set()

        try:
            self._add_peaks.update(
                int(i) for i in self._preload_cycle_markers.get("add_peaks", [])
            )
            self._add_troughs.update(
                int(i) for i in self._preload_cycle_markers.get("add_troughs", [])
            )
            self._rm_peaks.update(
                int(i) for i in self._preload_cycle_markers.get("rm_peaks", [])
            )
            self._rm_troughs.update(
                int(i) for i in self._preload_cycle_markers.get("rm_troughs", [])
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        self._line_artist = None
        self._peak_artist = None
        self._trough_artist = None
        self._sel_span_artist = None

        # Remove loading frame
        if self._cycle_loading_frame is not None:
            try:
                self._cycle_loading_frame.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._cycle_loading_frame = None
        self._cycle_loading_label = None

        self._cycle_ui_built = True
        self._startup_cycle_ready = True
        self._update_startup_loading_splash_progress(
            progress=84.0,
            message="Cycle Analysis tab ready.",
        )

        if getattr(self, "_pending_cycle_tab_focus", False):
            self.after_idle(self._focus_cycle_tab_when_ready)

        # Determine post-build action
        pending_job = self._pending_cycle_recompute
        self._pending_cycle_recompute = None

        if pending_job:
            self.after_idle(
                lambda job=pending_job: self._recompute_cycle_analysis(
                    auto_detect=job.get("auto_detect", True),
                    ignore_min_drop=job.get("ignore_min_drop", False),
                    preserve_view=job.get("preserve_view", False),
                )
            )
            return

        if not getattr(self, "_columns_applied", False):
            self._show_cycle_apply_prompt()
            return

        if getattr(self, "_suspend_cycle_autorun", False):
            self._show_cycle_ready_message()
        else:
            self.after_idle(lambda: self._recompute_cycle_analysis(auto_detect=True))

    def _export_text_summary_png(
        self,
        text: str,
        path: str,
        metadata: Optional[List[str]] = None,
        *,
        profile_key: Optional[str] = None,
    ) -> None:
        """Export text summary PNG.
        Used to serialize text summary PNG for external workflows."""

        if metadata:
            meta_block = "\n".join(metadata)
            text = f"{text.rstrip()}\n\n---\n{meta_block}"

        lines = text.splitlines() or [""]
        max_chars = max(len(line) for line in lines) or 1

        fig_width = max(6.0, min(16.0, 0.12 * max_chars))
        fig_height = max(2.5, min(20.0, 0.38 * len(lines) + 0.5))

        fig_width, fig_height = self._compute_output_dimensions(
            profile_key, fig_width, fig_height
        )

        fig = Figure(figsize=(fig_width, fig_height), dpi=150)
        canvas = FigureCanvasAgg(fig)
        ax = fig.add_subplot(111)

        ax.axis("off")
        ax.set_facecolor("white")
        fig.patch.set_facecolor("white")
        ax.set_position([0, 0, 1, 1])

        text_artist = ax.text(
            0.0,
            1.0,
            text,
            ha="left",
            va="top",
            fontsize=12,
            family="monospace",
            linespacing=1.35,
            transform=ax.transAxes,
        )

        export_dpi = self._get_export_dpi()

        try:
            canvas.draw()
            renderer = canvas.get_renderer()
            bbox = text_artist.get_window_extent(renderer=renderer)

            if bbox.width <= 0 or bbox.height <= 0:
                fig.savefig(
                    path,
                    dpi=export_dpi,
                    bbox_inches="tight",
                    pad_inches=0.0,
                    facecolor="white",
                )
                return

            pad_x = max(3.0, 0.02 * bbox.width)
            pad_y = max(3.0, 0.02 * bbox.height)
            x0 = bbox.x0 - pad_x
            y0 = bbox.y0 - pad_y
            x1 = bbox.x1 + pad_x
            y1 = bbox.y1 + pad_y

            if x1 <= x0 or y1 <= y0:
                fig.savefig(
                    path,
                    dpi=export_dpi,
                    bbox_inches="tight",
                    pad_inches=0.0,
                    facecolor="white",
                )
                return

            cropped_bbox = Bbox.from_extents(x0, y0, x1, y1)
            bbox_inches = cropped_bbox.transformed(fig.dpi_scale_trans.inverted())

            fig.savefig(
                path,
                dpi=export_dpi,
                bbox_inches=bbox_inches,
                pad_inches=0.0,
                facecolor="white",
            )

        finally:
            fig.clf()

    def _save_cycle_summary_png(self):
        """Save cycle summary PNG.
        Used when persisting cycle summary PNG to storage."""

        widget = getattr(self, "_cycle_summary_box", None)

        if widget is None or not widget.winfo_exists():

            try:

                messagebox.showwarning(
                    "Cycle Analysis", "The Cycle Analysis Summary is not available yet."
                )

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            return

        try:

            text = widget.get("1.0", "end").strip()

        except Exception:

            text = ""

        if not text:

            try:

                messagebox.showinfo(
                    "Cycle Analysis",
                    "The Cycle Analysis Summary is currently empty. Generate an analysis before saving.",
                )

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            return

        path = filedialog.asksaveasfilename(
            title="Save Cycle Analysis Summary as PNG",
            defaultextension=".png",
            filetypes=[("PNG Image", "*.png")],
            initialfile="cycle_analysis_summary.png",
        )

        if not path:

            return

        try:
            self._export_text_summary_png(text, path, profile_key="cycle_summary_png")

        except Exception as exc:

            try:

                messagebox.showerror(
                    "Cycle Analysis", f"Failed to save Cycle Analysis Summary: {exc}"
                )

            except Exception:

                pass

            return

    def _redetect_cycle_peaks(self) -> None:
        """Perform redetect cycle peaks.
        Used to keep the workflow logic localized and testable."""
        if not self._cycle_ready():
            return
        self._push_cycle_marker_undo()
        self._recompute_cycle_analysis(auto_detect=True, preserve_view=True)

    def _cycle_marker_selection_payload(self) -> Dict[str, Any]:
        """Perform cycle marker selection payload.
        Used to keep the workflow logic localized and testable."""
        payload = {"mode": "none", "range": None, "index_range": None}
        pending_range = getattr(self, "_cycle_pending_range", None)
        if pending_range:
            try:
                payload["mode"] = "pending"
                payload["range"] = [float(pending_range[0]), float(pending_range[1])]
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return payload
        mask = getattr(self, "_cycle_mask", None)
        if mask is None:
            return payload
        try:
            mask_arr = np.asarray(mask, dtype=bool)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return payload
        if not mask_arr.size or not mask_arr.any():
            return payload
        x, y1, _ = self._get_xy()
        base_mask = None
        if x is not None and y1 is not None:
            base_mask_raw = (~pd.isna(x)) & (~pd.isna(y1))
            base_mask = (
                base_mask_raw.values
                if hasattr(base_mask_raw, "values")
                else np.asarray(base_mask_raw, dtype=bool)
            )
        if (
            base_mask is not None
            and base_mask.size == mask_arr.size
            and np.array_equal(mask_arr, base_mask)
        ):
            payload["mode"] = "all"
            return payload
        idx = np.where(mask_arr)[0]
        if idx.size:
            payload["index_range"] = [int(idx.min()), int(idx.max())]
            if x is not None:
                try:
                    xv = np.asarray(x, dtype=float)
                except Exception:
                    xv = None
                if xv is not None and idx.max() < xv.size:
                    segment = xv[idx]
                    finite_segment = segment[np.isfinite(segment)]
                    if finite_segment.size:
                        payload["mode"] = "range"
                        payload["range"] = [
                            float(finite_segment.min()),
                            float(finite_segment.max()),
                        ]
                        return payload
        payload["mode"] = "custom"
        return payload

    def _cycle_marker_export_payload(self) -> Dict[str, Any]:
        """Export payload.
        Used by cycle marker workflows to export payload."""
        thresholds = {}
        # Iterate to apply the per-item logic.
        for key, var, cast in (
            ("min_cycle_drop", getattr(self, "min_cycle_drop", None), float),
            ("pk_prominence", getattr(self, "pk_prominence", None), float),
            ("pk_distance", getattr(self, "pk_distance", None), int),
            ("pk_width", getattr(self, "pk_width", None), int),
        ):
            if var is None:
                continue
            try:
                thresholds[key] = cast(var.get())
            except Exception:
                continue
        cycle_temp = None
        cycle_temp_var = getattr(self, "cycle_temp_column", None)
        if cycle_temp_var is not None:
            try:
                cycle_temp = cycle_temp_var.get()
            except Exception:
                cycle_temp = None
        auto_detect_var = getattr(self, "auto_detect_cycles", None)
        auto_detect_enabled = (
            bool(auto_detect_var.get()) if auto_detect_var is not None else False
        )
        payload = {
            "schema_version": 1,
            "created": datetime.now().isoformat(timespec="seconds"),
            "selection": self._cycle_marker_selection_payload(),
            "auto_peaks": sorted(getattr(self, "_auto_peaks", set())),
            "auto_troughs": sorted(getattr(self, "_auto_troughs", set())),
            "add_peaks": sorted(getattr(self, "_add_peaks", set())),
            "add_troughs": sorted(getattr(self, "_add_troughs", set())),
            "rm_peaks": sorted(getattr(self, "_rm_peaks", set())),
            "rm_troughs": sorted(getattr(self, "_rm_troughs", set())),
            "thresholds": thresholds,
            "auto_detect_enabled": auto_detect_enabled,
            "cycle_temp_column": cycle_temp,
        }
        return payload

    def _apply_cycle_selection_payload(self, selection: Dict[str, Any]) -> None:
        """Apply cycle selection payload.
        Used to apply cycle selection payload changes to live state."""
        if not selection:
            self._cycle_mask = None
            self._cycle_pending_range = None
            self._shade_selection(None)
            self._refresh_cycle_selection_text()
            return
        mode = selection.get("mode") or "none"
        rng = selection.get("range")
        if mode == "pending" and rng:
            try:
                xmin = float(rng[0])
                xmax = float(rng[1])
            except Exception:
                xmin = xmax = None
            if xmin is not None and xmax is not None:
                self._cycle_pending_range = (min(xmin, xmax), max(xmin, xmax))
                self._cycle_mask = None
                self._shade_selection(self._cycle_pending_range)
                self._refresh_cycle_selection_text()
                return
        if mode == "none":
            self._cycle_mask = None
            self._cycle_pending_range = None
            self._shade_selection(None)
            self._refresh_cycle_selection_text()
            return
        x, y1, _ = self._get_xy()
        if x is None or y1 is None:
            return
        base = (~pd.isna(x)) & (~pd.isna(y1))
        base_mask = (
            base.values if hasattr(base, "values") else np.asarray(base, dtype=bool)
        )
        if mode == "all":
            self._cycle_mask = base_mask
            self._cycle_pending_range = None
            self._shade_selection(None)
            self._refresh_cycle_selection_text()
            return
        range_applied = False
        if rng:
            try:
                xmin = float(rng[0])
                xmax = float(rng[1])
            except Exception:
                xmin = xmax = None
            if xmin is not None and xmax is not None:
                try:
                    xv = np.asarray(x, dtype=float)
                except Exception:
                    xv = None
                if xv is not None:
                    sel = (xv >= min(xmin, xmax)) & (xv <= max(xmin, xmax))
                    mask = base_mask & sel
                    self._cycle_mask = mask
                    self._cycle_pending_range = None
                    self._shade_selection((min(xmin, xmax), max(xmin, xmax)))
                    range_applied = True
        if not range_applied:
            idx_range = selection.get("index_range")
            if idx_range:
                try:
                    idx_min = int(idx_range[0])
                    idx_max = int(idx_range[1])
                except Exception:
                    idx_min = idx_max = None
                if idx_min is not None and idx_max is not None:
                    idx_min = max(0, min(idx_min, base_mask.size - 1))
                    idx_max = max(0, min(idx_max, base_mask.size - 1))
                    selection_mask = np.zeros_like(base_mask, dtype=bool)
                    selection_mask[idx_min : idx_max + 1] = True
                    self._cycle_mask = base_mask & selection_mask
                    self._cycle_pending_range = None
                    self._shade_selection(None)
                    range_applied = True
        if not range_applied:
            self._cycle_mask = None
            self._cycle_pending_range = None
            self._shade_selection(None)
        self._refresh_cycle_selection_text()

    def _copy_cycle_summary_to_clipboard(self) -> None:
        """Perform copy cycle summary to clipboard.
        Used to keep the workflow logic localized and testable."""
        text = self._final_report_get_cycle_summary_text()
        if not text or not text.strip():
            try:
                messagebox.showwarning(
                    "Cycle Analysis", "The Cycle Analysis Summary is empty."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        try:
            self.clipboard_clear()
            self.clipboard_append(text.strip())
            messagebox.showinfo("Cycle Analysis", "Summary copied to clipboard.")
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Cycle Analysis", f"Failed to copy summary: {exc}"
                )
            except Exception:
                pass

    def _export_cycle_markers(self) -> None:
        """Export cycle markers.
        Used to serialize cycle markers for external workflows."""
        if not self._cycle_ready():
            return
        payload = self._cycle_marker_export_payload()
        path = filedialog.asksaveasfilename(
            title="Export Cycle Markers",
            defaultextension=".json",
            filetypes=[("JSON File", "*.json"), ("CSV File", "*.csv")],
            initialfile="cycle_markers.json",
        )
        if not path:
            return
        ext = os.path.splitext(path)[1].lower()
        try:
            if ext == ".csv":
                with open(path, "w", newline="", encoding="utf-8") as f:
                    writer = csv.writer(f)
                    writer.writerow(["field", "value"])
                    # Iterate over items from payload to apply the per-item logic.
                    for key, value in payload.items():
                        if isinstance(value, (dict, list)):
                            encoded = json.dumps(value, ensure_ascii=True)
                        else:
                            encoded = "" if value is None else str(value)
                        writer.writerow([key, encoded])
            else:
                with open(path, "w", encoding="utf-8") as f:
                    json.dump(payload, f, indent=2, sort_keys=True, ensure_ascii=True)
            messagebox.showinfo("Cycle Analysis", f"Markers exported to {path}")
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Cycle Analysis", f"Failed to export markers: {exc}"
                )
            except Exception:
                pass

    def _import_cycle_markers(self) -> None:
        """Import cycle markers.
        Used to ingest cycle markers into the application."""
        if not self._cycle_ready():
            return
        path = filedialog.askopenfilename(
            title="Import Cycle Markers",
            filetypes=[("JSON File", "*.json"), ("CSV File", "*.csv")],
        )
        if not path:
            return
        ext = os.path.splitext(path)[1].lower()
        payload: Dict[str, Any] = {}
        try:
            if ext == ".csv":
                with open(path, "r", encoding="utf-8") as f:
                    reader = csv.reader(f)
                    headers = next(reader, [])
                    if len(headers) >= 2 and headers[0].lower() != "field":
                        f.seek(0)
                        reader = csv.reader(f)
                    # Iterate over reader to apply the per-item logic.
                    for row in reader:
                        if not row or len(row) < 2:
                            continue
                        key = str(row[0]).strip()
                        value = row[1]
                        if not key:
                            continue
                        try:
                            payload[key] = json.loads(value)
                        except Exception:
                            payload[key] = value
            else:
                with open(path, "r", encoding="utf-8") as f:
                    payload = json.load(f)
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Cycle Analysis", f"Failed to import markers: {exc}"
                )
            except Exception:
                pass
            return
        if not isinstance(payload, dict):
            try:
                messagebox.showerror(
                    "Cycle Analysis", "Marker file is not a valid export payload."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        self._push_cycle_marker_undo()
        thresholds = payload.get("thresholds", {}) or {}
        if "min_cycle_drop" in thresholds:
            try:
                self.min_cycle_drop.set(float(thresholds["min_cycle_drop"]))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if "pk_prominence" in thresholds:
            try:
                self.pk_prominence.set(float(thresholds["pk_prominence"]))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if "pk_distance" in thresholds:
            try:
                self.pk_distance.set(int(thresholds["pk_distance"]))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        if "pk_width" in thresholds:
            try:
                self.pk_width.set(int(thresholds["pk_width"]))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        auto_detect_var = getattr(self, "auto_detect_cycles", None)
        auto_detect_setting = payload.get("auto_detect_enabled")
        if auto_detect_setting is not None:
            try:
                if auto_detect_var is not None:
                    auto_detect_var.set(bool(auto_detect_setting))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        elif auto_detect_var is not None:
            try:
                auto_detect_setting = bool(auto_detect_var.get())
            except Exception:
                auto_detect_setting = None
        temp_column = payload.get("cycle_temp_column")
        if temp_column:
            try:
                self.cycle_temp_column.set(temp_column)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._apply_cycle_selection_payload(payload.get("selection") or {})
        self._auto_peaks = set(payload.get("auto_peaks", []))
        self._auto_troughs = set(payload.get("auto_troughs", []))
        self._add_peaks = set(payload.get("add_peaks", []))
        self._add_troughs = set(payload.get("add_troughs", []))
        self._rm_peaks = set(payload.get("rm_peaks", []))
        self._rm_troughs = set(payload.get("rm_troughs", []))
        try:
            if temp_column:
                self._on_cycle_temp_selected()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._recompute_cycle_analysis(
                auto_detect=bool(auto_detect_setting), preserve_view=True
            )
            messagebox.showinfo("Cycle Analysis", "Markers imported successfully.")
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Cycle Analysis", f"Failed to apply markers: {exc}"
                )
            except Exception:
                pass

    def _export_cycle_results_csv(self) -> None:
        """Export cycle results CSV.
        Used to serialize cycle results CSV for external workflows."""
        if not self._cycle_ready():
            return
        payload = getattr(self, "_cycle_last_transfer_payload", None)
        cycles = list(payload.get("cycles", [])) if payload else []
        per_cycle = list(payload.get("per_cycle", [])) if payload else []
        if not cycles and not per_cycle:
            try:
                messagebox.showwarning(
                    "Cycle Analysis",
                    "Run Cycle Analysis before exporting cycle results.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        path = filedialog.asksaveasfilename(
            title="Export Cycle Results (CSV)",
            defaultextension=".csv",
            filetypes=[("CSV File", "*.csv")],
            initialfile="cycle_results.csv",
        )
        if not path:
            return
        columns = [
            "cycle_index",
            "peak_idx",
            "trough_idx",
            "peak_pressure",
            "trough_pressure",
            "delta_pressure",
            "mean_temp_C",
            "used_default_temp",
            "moles_ideal",
            "moles_vdw",
        ]
        max_len = max(len(cycles), len(per_cycle))
        try:
            with open(path, "w", newline="", encoding="utf-8") as f:
                writer = csv.DictWriter(f, fieldnames=columns)
                writer.writeheader()
                # Iterate over the configured range to apply the per-item logic.
                for idx in range(max_len):
                    cycle = cycles[idx] if idx < len(cycles) else {}
                    stats = per_cycle[idx] if idx < len(per_cycle) else {}
                    delta = stats.get("deltaP", cycle.get("delta_P"))
                    writer.writerow(
                        {
                            "cycle_index": idx + 1,
                            "peak_idx": cycle.get("peak_idx", ""),
                            "trough_idx": cycle.get("trough_idx", ""),
                            "peak_pressure": cycle.get("peak", ""),
                            "trough_pressure": cycle.get("trough", ""),
                            "delta_pressure": delta if delta is not None else "",
                            "mean_temp_C": stats.get("T_mean_C", ""),
                            "used_default_temp": stats.get("used_default", ""),
                            "moles_ideal": stats.get("n_ideal", ""),
                            "moles_vdw": stats.get("n_vdw", ""),
                        }
                    )
            messagebox.showinfo("Cycle Analysis", f"Cycle results exported to {path}")
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Cycle Analysis", f"Failed to export cycle results: {exc}"
                )
            except Exception:
                pass

    def _reset_manual_edits(self):
        """Perform reset manual edits.
        Used to keep the workflow logic localized and testable."""

        if not self._cycle_ready():

            return

        changed = bool(
            self._add_peaks or self._add_troughs or self._rm_peaks or self._rm_troughs
        )

        if changed:
            self._push_cycle_marker_undo()

        self._add_peaks.clear()

        self._add_troughs.clear()

        self._rm_peaks.clear()

        self._rm_troughs.clear()

        if changed:
            self._bump_manual_marker_revision()

        self._recompute_cycle_analysis(auto_detect=False, preserve_view=True)

    def _clear_all_markers(self):
        """Clear all markers.
        Used to reset all markers state safely."""

        if not self._cycle_ready():

            return

        changed = bool(
            self._auto_peaks
            or self._auto_troughs
            or self._add_peaks
            or self._add_troughs
            or self._rm_peaks
            or self._rm_troughs
        )

        if changed:
            self._push_cycle_marker_undo()

        # auto-detected sets

        self._auto_peaks.clear()

        self._auto_troughs.clear()

        # manual edits

        self._add_peaks.clear()

        self._add_troughs.clear()

        self._rm_peaks.clear()

        self._rm_troughs.clear()

        if changed:
            self._bump_manual_marker_revision()

        # Re-draw WITHOUT re-detecting, so the plot stays empty until you add markers

        self._recompute_cycle_analysis(auto_detect=False, preserve_view=True)

        # Friendly hint in the summary box

        self._set_cycle_summary(
            "All peaks and troughs cleared.\n"
            "Add markers manually with:\n"
            "  * SHIFT + Left-click  = Peak\n"
            "  * SHIFT + Right-click = Trough\n"
            "  * Right-click (no SHIFT) = remove nearest"
        )

    def _use_cycle_all(self):
        """Perform use cycle all.
        Used to keep the workflow logic localized and testable."""

        if not self._cycle_ready():

            return

        x, y1, _ = self._get_xy()

        if x is None or y1 is None:

            self._set_cycle_summary("(Load data and select X & y1 first.)")

            return

        base = (~pd.isna(x)) & (~pd.isna(y1))

        self._cycle_mask = (
            base.values if hasattr(base, "values") else np.asarray(base, dtype=bool)
        )
        self._cycle_pending_range = None

        self._refresh_cycle_selection_text()

        self._shade_selection(None)

        self._recompute_cycle_analysis(auto_detect=True)

    def _use_cycle_selection(self):
        """Perform use cycle selection.
        Used to keep the workflow logic localized and testable."""

        if not self._cycle_pending_range:

            return

        if not self._cycle_ready():

            return

        xmin, xmax = self._cycle_pending_range

        x, y1, _ = self._get_xy()

        if x is None or y1 is None:

            self._set_cycle_summary("(Load data and select X & y1 first.)")

            return

        base = (~pd.isna(x)) & (~pd.isna(y1))

        sel = (x >= xmin) & (x <= xmax)

        mask = base & sel

        self._cycle_mask = (
            mask.values if hasattr(mask, "values") else np.asarray(mask, dtype=bool)
        )
        self._cycle_pending_range = None

        self._refresh_cycle_selection_text()

        self._shade_selection((xmin, xmax))

        self._recompute_cycle_analysis(auto_detect=True)

    def _on_span_select(self, xmin, xmax):
        """Handle span select.
        Used as an event callback for span select."""

        if xmin is None or xmax is None:

            self._cycle_pending_range = None

            return

        if xmax < xmin:

            xmin, xmax = xmax, xmin

        self._cycle_pending_range = (xmin, xmax)

        # draw a translucent span just for visual feedback

        self._shade_selection(self._cycle_pending_range)

    def _on_cycle_key_press(self, event):
        """Handle cycle key press.
        Used as an event callback for cycle key press."""

        # Enable span selection only while Ctrl is held

        key = (
            str(getattr(event, "key", "")).lower()
            if getattr(event, "key", None)
            else ""
        )

        if key in ("control", "ctrl"):

            try:

                self._cycle_span.set_active(True)

            except Exception:

                self._cycle_span.active = True

    def _on_cycle_key_release(self, event):
        """Handle cycle key release.
        Used as an event callback for cycle key release."""

        key = (
            str(getattr(event, "key", "")).lower()
            if getattr(event, "key", None)
            else ""
        )

        if key in ("control", "ctrl"):

            try:

                self._cycle_span.set_active(False)

            except Exception:

                self._cycle_span.active = False

    def _shade_selection(self, rng):
        """Perform shade selection.
        Used to keep the workflow logic localized and testable."""

        if self._sel_span_artist:

            try:

                self._sel_span_artist.remove()

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            self._sel_span_artist = None

        if rng and self._cycle_ax:

            self._sel_span_artist = self._cycle_ax.axvspan(
                rng[0], rng[1], color="gray", alpha=0.15, zorder=0
            )

        self._cycle_canvas.draw_idle()

    def _set_cycle_selection_text(self, text: str) -> None:
        """Set cycle selection text.
        Used to persist cycle selection text into the current state."""
        label = getattr(self, "_cycle_sel_label", None)
        if label is None or not label.winfo_exists():
            return
        try:
            label.config(text=text)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _refresh_cycle_selection_text(self) -> None:
        """Refresh cycle selection text.
        Used to sync cycle selection text with current settings."""
        label = getattr(self, "_cycle_sel_label", None)
        if label is None or not label.winfo_exists():
            return

        if not getattr(self, "_columns_applied", False):
            self._set_cycle_selection_text("Selection: (awaiting column apply)")
            return

        pending_range = getattr(self, "_cycle_pending_range", None)
        mask = getattr(self, "_cycle_mask", None)

        if mask is not None:
            mask_arr = np.asarray(mask, dtype=bool)
            if mask_arr.size and mask_arr.any():
                base_mask = None
                x, y1, _ = self._get_xy()
                if x is not None and y1 is not None:
                    base_mask_raw = (~pd.isna(x)) & (~pd.isna(y1))
                    base_mask = (
                        base_mask_raw.values
                        if hasattr(base_mask_raw, "values")
                        else np.asarray(base_mask_raw, dtype=bool)
                    )
                if (
                    base_mask is not None
                    and base_mask.size == mask_arr.size
                    and np.array_equal(mask_arr, base_mask)
                ):
                    self._set_cycle_selection_text("Selection: (using ALL data)")
                    return

                if x is not None:
                    xv = np.asarray(x, dtype=float)
                    idx = np.where(mask_arr)[0]
                    if idx.size and idx.max() < xv.size:
                        segment = xv[idx]
                        finite_segment = segment[np.isfinite(segment)]
                        if finite_segment.size:
                            self._set_cycle_selection_text(
                                f"Selection: [{finite_segment.min():.4f}, {finite_segment.max():.4f}]"
                            )
                            return

                self._set_cycle_selection_text("Selection: (custom range applied)")
                return

            self._set_cycle_selection_text("Selection: (choose an analysis range)")
            return

        if pending_range is not None:
            try:
                xmin = float(pending_range[0])
                xmax = float(pending_range[1])
            except Exception:
                self._set_cycle_selection_text("Selection: (choose an analysis range)")
                return
            self._set_cycle_selection_text(
                f"Selection: pending [{xmin:.4f}, {xmax:.4f}]"
            )
            return

        self._set_cycle_selection_text("Selection: (choose an analysis range)")

    def _on_cycle_click(self, event):
        """Handle cycle click.
        Used as an event callback for cycle click."""

        if event.inaxes != getattr(self, "_cycle_ax", None) or event.xdata is None:

            return

        if not self._cycle_ready():

            return

        btn = getattr(event, "button", None)

        # Robust SHIFT detection

        shift = False

        mods = getattr(event, "modifiers", None)

        if mods and any("shift" in str(m).lower() for m in mods):

            shift = True

        else:

            k = getattr(event, "key", None)

            if isinstance(k, str) and "shift" in k.lower():

                shift = True

            else:

                ge = getattr(event, "guiEvent", None)

                try:

                    if ge is not None and (int(getattr(ge, "state", 0)) & 0x0001):

                        shift = True  # Tk ShiftMask

                except Exception:

                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        # Data must be ready

        x, y1, _ = self._get_xy()

        if x is None or y1 is None:

            return

        mask = self._current_mask()

        if getattr(mask, "sum", lambda: 0)() < 3:

            return

        # No SHIFT: allow right-click to remove nearest; ignore other clicks

        if not shift:

            if btn == 3:

                idx = self._nearest_index_by_x(event.xdata)

                if idx is not None:

                    self._toggle_remove_nearest(idx, x_value=float(event.xdata))

                    self._recompute_cycle_analysis(
                        auto_detect=False, preserve_view=True
                    )

            return

        # SHIFT held: only left/right buttons matter

        if btn not in (1, 3):

            return

        # SHIFT + Left-click  -> Peak (snap to local maximum)

        # SHIFT + Right-click -> Trough (snap to local minimum)

        prefer_peak = btn == 1

        idx = self._find_manual_marker_index(event.xdata, prefer_peak=prefer_peak)

        if idx is None:

            return

        if prefer_peak:

            self._ensure_manual_peak(idx)

        else:

            self._ensure_manual_trough(idx)

        self._recompute_cycle_analysis(
            auto_detect=False, ignore_min_drop=True, preserve_view=True
        )

    def _on_cycle_mouse_release(self, event):
        """Handle cycle mouse release.
        Used as an event callback for cycle mouse release."""

        leg = getattr(self, "_cycle_legend_obj", None)

        if leg is None:

            return

        try:

            # Legend center in display coords

            renderer = self._cycle_fig.canvas.get_renderer()

            bbox = leg.get_window_extent(renderer=renderer)

            cx = 0.5 * (bbox.x0 + bbox.x1)

            cy = 0.5 * (bbox.y0 + bbox.y1)

            # Convert to Axes fraction coords (0..1)

            ax_xy = self._cycle_ax.transAxes.inverted().transform((cx, cy))

            self._cycle_legend_anchor = (float(ax_xy[0]), float(ax_xy[1]))

            # Persist immediately

            settings["cycle_legend_anchor"] = [
                self._cycle_legend_anchor[0],
                self._cycle_legend_anchor[1],
            ]

            _save_settings_to_disk()

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _cycle_marker_snapshot(self) -> Dict[str, set]:
        """Perform cycle marker snapshot.
        Used to keep the workflow logic localized and testable."""
        return {
            "auto_peaks": set(getattr(self, "_auto_peaks", set())),
            "auto_troughs": set(getattr(self, "_auto_troughs", set())),
            "add_peaks": set(getattr(self, "_add_peaks", set())),
            "add_troughs": set(getattr(self, "_add_troughs", set())),
            "rm_peaks": set(getattr(self, "_rm_peaks", set())),
            "rm_troughs": set(getattr(self, "_rm_troughs", set())),
        }

    @staticmethod
    def _cycle_marker_snapshots_equal(
        left: Dict[str, set], right: Dict[str, set]
    ) -> bool:
        """Perform cycle marker snapshots equal.
        Used to keep the workflow logic localized and testable."""
        keys = (
            "auto_peaks",
            "auto_troughs",
            "add_peaks",
            "add_troughs",
            "rm_peaks",
            "rm_troughs",
        )
        # Iterate over keys to apply the per-item logic.
        for key in keys:
            if set(left.get(key, set())) != set(right.get(key, set())):
                return False
        return True

    def _push_cycle_marker_undo(self) -> None:
        """Perform push cycle marker undo.
        Used to keep the workflow logic localized and testable."""
        if getattr(self, "_cycle_marker_undo_lock", False):
            return
        snapshot = self._cycle_marker_snapshot()
        stack = getattr(self, "_cycle_marker_undo_stack", [])
        if stack and self._cycle_marker_snapshots_equal(stack[-1], snapshot):
            return
        stack.append(snapshot)
        if len(stack) > 50:
            stack.pop(0)
        self._cycle_marker_undo_stack = stack
        self._cycle_marker_redo_stack = []

    def _apply_cycle_marker_snapshot(self, snapshot: Dict[str, set]) -> None:
        """Apply cycle marker snapshot.
        Used to apply cycle marker snapshot changes to live state."""
        self._auto_peaks = set(snapshot.get("auto_peaks", set()))
        self._auto_troughs = set(snapshot.get("auto_troughs", set()))
        self._add_peaks = set(snapshot.get("add_peaks", set()))
        self._add_troughs = set(snapshot.get("add_troughs", set()))
        self._rm_peaks = set(snapshot.get("rm_peaks", set()))
        self._rm_troughs = set(snapshot.get("rm_troughs", set()))

    def _undo_cycle_marker_edit(self) -> None:
        """Perform undo cycle marker edit.
        Used to keep the workflow logic localized and testable."""
        if not self._cycle_ready():
            return
        stack = getattr(self, "_cycle_marker_undo_stack", [])
        if not stack:
            try:
                messagebox.showinfo("Cycle Analysis", "No marker edits to undo.")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        current = self._cycle_marker_snapshot()
        snapshot = stack.pop()
        self._cycle_marker_redo_stack.append(current)
        self._cycle_marker_undo_lock = True
        try:
            self._apply_cycle_marker_snapshot(snapshot)
        finally:
            self._cycle_marker_undo_lock = False
        self._bump_manual_marker_revision()
        self._recompute_cycle_analysis(auto_detect=False, preserve_view=True)

    def _redo_cycle_marker_edit(self) -> None:
        """Perform redo cycle marker edit.
        Used to keep the workflow logic localized and testable."""
        if not self._cycle_ready():
            return
        redo_stack = getattr(self, "_cycle_marker_redo_stack", [])
        if not redo_stack:
            try:
                messagebox.showinfo("Cycle Analysis", "No marker edits to redo.")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        current = self._cycle_marker_snapshot()
        snapshot = redo_stack.pop()
        self._cycle_marker_undo_stack.append(current)
        self._cycle_marker_undo_lock = True
        try:
            self._apply_cycle_marker_snapshot(snapshot)
        finally:
            self._cycle_marker_undo_lock = False
        self._bump_manual_marker_revision()
        self._recompute_cycle_analysis(auto_detect=False, preserve_view=True)

    def _bump_manual_marker_revision(self) -> None:
        """Perform bump manual marker revision.
        Used to keep the workflow logic localized and testable."""
        try:
            self._cycle_manual_revision += 1
        except Exception:
            current = int(getattr(self, "_cycle_manual_revision", 0))
            self._cycle_manual_revision = current + 1

    def _ensure_manual_peak(self, idx):
        """Perform ensure manual peak.
        Used to keep the workflow logic localized and testable."""

        idx = int(idx)

        self._push_cycle_marker_undo()

        if idx in self._add_peaks:

            self._add_peaks.remove(idx)
            self._bump_manual_marker_revision()

            return

        changed = False

        if idx in self._add_troughs:
            self._add_troughs.remove(idx)
            changed = True

        if idx in self._rm_troughs:
            self._rm_troughs.remove(idx)
            changed = True

        if idx in self._rm_peaks:
            self._rm_peaks.remove(idx)
            changed = True

        if idx not in self._add_peaks:
            self._add_peaks.add(idx)
            changed = True

        if changed:
            self._bump_manual_marker_revision()

    def _ensure_manual_trough(self, idx):
        """Perform ensure manual trough.
        Used to keep the workflow logic localized and testable."""

        idx = int(idx)

        self._push_cycle_marker_undo()

        if idx in self._add_troughs:

            self._add_troughs.remove(idx)
            self._bump_manual_marker_revision()

            return

        changed = False

        if idx in self._add_peaks:
            self._add_peaks.remove(idx)
            changed = True

        if idx in self._rm_peaks:
            self._rm_peaks.remove(idx)
            changed = True

        if idx in self._rm_troughs:
            self._rm_troughs.remove(idx)
            changed = True

        if idx not in self._add_troughs:
            self._add_troughs.add(idx)
            changed = True

        if changed:
            self._bump_manual_marker_revision()

    def _toggle_remove_nearest(self, idx, *, x_value=None):
        """Toggle remove nearest.
        Used to flip remove nearest and refresh dependent views."""

        x_series, _, _ = self._get_xy()

        xv = None

        if x_value is not None and x_series is not None:

            try:

                xv = np.asarray(x_series, dtype=float)

            except Exception:

                xv = None

        px = self._nearest_in_set(
            idx,
            self._effective_peaks(),
            x_value=x_value,
            xv=xv,
        )

        tx = self._nearest_in_set(
            idx,
            self._effective_troughs(),
            x_value=x_value,
            xv=xv,
        )

        if px is None and tx is None:

            return

        # Closure captures _toggle_remove_nearest local context to keep helper logic scoped and invoked directly within _toggle_remove_nearest.
        def _distance(candidate):
            """Perform distance.
            Used to keep the workflow logic localized and testable."""

            if candidate is None:

                return float("inf")

            if x_value is not None and xv is not None:

                if 0 <= candidate < xv.size:

                    val = float(xv[candidate])

                    if np.isfinite(val):

                        return abs(val - x_value)

            return abs(candidate - idx)

        dp = _distance(px)

        dt = _distance(tx)

        if dp <= dt:

            # remove peak

            self._push_cycle_marker_undo()

            if px in self._add_peaks:

                self._add_peaks.remove(px)
                self._bump_manual_marker_revision()

            elif px in self._auto_peaks:

                self._rm_peaks.add(px)
                self._bump_manual_marker_revision()

        else:

            # remove trough

            self._push_cycle_marker_undo()

            if tx in self._add_troughs:

                self._add_troughs.remove(tx)
                self._bump_manual_marker_revision()

            elif tx in self._auto_troughs:

                self._rm_troughs.add(tx)
                self._bump_manual_marker_revision()

    def _nearest_in_set(self, idx, s, *, x_value=None, xv=None):
        """Set value.
        Used by nearest in workflows to set value."""

        if not s:

            return None

        arr = np.array(sorted(s), dtype=int)

        if arr.size == 0:

            return None

        if x_value is not None and xv is not None:

            distances = np.full(arr.shape, np.inf, dtype=float)

            xv_len = getattr(xv, "size", len(xv))

            valid = (arr >= 0) & (arr < xv_len)

            if np.any(valid):

                try:

                    xvals = np.asarray(xv[arr[valid]], dtype=float)

                except Exception:

                    xvals = np.full(arr[valid].shape, np.nan, dtype=float)

                distances[valid] = np.abs(xvals - x_value)

            if not np.isfinite(distances).any():

                distances = np.abs(arr - idx)

            else:

                distances = np.nan_to_num(distances, nan=np.inf)

        else:

            distances = np.abs(arr - idx)

        j = int(np.argmin(distances))

        return int(arr[j])

    def _effective_peaks(self):
        """Perform effective peaks.
        Used to keep the workflow logic localized and testable."""

        return (self._auto_peaks | self._add_peaks) - self._rm_peaks

    def _effective_troughs(self):
        """Perform effective troughs.
        Used to keep the workflow logic localized and testable."""

        return (self._auto_troughs | self._add_troughs) - self._rm_troughs

    def _current_mask(self):
        """Return current mask.
        Used to surface mask for downstream logic."""

        x, y1, _ = self._get_xy()

        if x is None or y1 is None:

            return np.zeros(0, dtype=bool)

        base = (~pd.isna(x)) & (~pd.isna(y1))

        base = base.values if hasattr(base, "values") else np.asarray(base, dtype=bool)

        if self._cycle_mask is None:

            return base

        return base & self._cycle_mask

    def _get_xy(self):
        """Return xy.
        Used to retrieve xy for downstream logic."""

        x = globals().get("x")

        y1 = globals().get("y1")

        temp = self._get_cycle_temp_series()

        # Leave temp as None when no cycle temperature column is selected so

        # downstream calculations use the configured default of 25 C.

        try:

            return x, y1, temp

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None, None, None

    def _find_manual_marker_index(self, xdata, prefer_peak):
        """Perform find manual marker index.
        Used to keep the workflow logic localized and testable."""

        x, y1, _ = self._get_xy()

        if x is None or y1 is None:

            return None

        xv = np.asarray(x, dtype=float)

        yv = np.asarray(y1, dtype=float)

        mask = self._current_mask()

        if getattr(mask, "sum", lambda: 0)() < 3:

            return None

        visible_idx = np.where(mask)[0]

        if visible_idx.size == 0:

            return None

        visible_x = xv[visible_idx]

        diffs = np.abs(visible_x - xdata)

        closest = int(np.argmin(diffs))

        anchor_idx = int(visible_idx[closest])

        window_radius = max(6, int(len(visible_idx) * 0.01))

        window_radius = min(window_radius, 80)

        lo = max(0, closest - window_radius)

        hi = min(visible_idx.size - 1, closest + window_radius)

        window_indices = visible_idx[lo : hi + 1]

        window_y = yv[window_indices]

        window_x = xv[window_indices]

        finite_mask = np.isfinite(window_y) & np.isfinite(window_x)

        if not finite_mask.any():

            return anchor_idx

        window_indices = window_indices[finite_mask]

        window_y = window_y[finite_mask]

        window_x = window_x[finite_mask]

        if window_indices.size == 0:

            return anchor_idx

        try:

            anchor_pos = int(np.where(window_indices == anchor_idx)[0][0])

        except Exception:

            anchor_pos = 0

        try:

            closest_dx = float(np.nanmin(np.abs(window_x - xdata)))

        except Exception:

            closest_dx = 0.0

        dx_limit = None

        ax = getattr(self, "_cycle_ax", None)

        if ax is not None:

            try:

                x0, x1 = ax.get_xlim()

                dx_range = abs(float(x1) - float(x0))

                if np.isfinite(dx_range) and dx_range > 0:

                    dx_limit = 0.02 * dx_range

            except Exception:

                dx_limit = None

        if dx_limit is None or not np.isfinite(dx_limit) or dx_limit <= 0:

            diffs = np.diff(np.sort(window_x))

            if diffs.size:

                dx_limit = 3.0 * float(np.nanmedian(np.abs(diffs)))

        if dx_limit is None or not np.isfinite(dx_limit) or dx_limit <= 0:

            dx_limit = max(closest_dx * 3.0, 1e-9)

        dx_limit = max(dx_limit, closest_dx * 3.0, 1e-9)

        # Closure captures _find_manual_marker_index local context to keep helper logic scoped and invoked directly within _find_manual_marker_index.
        def _is_local(pos: int) -> bool:
            """Check whether it is local.
            Used to gate conditional behavior in the workflow."""

            val = window_y[pos]

            if not np.isfinite(val):

                return False

            neighbors = []

            if pos > 0:

                neighbors.append(window_y[pos - 1])

            if pos < window_y.size - 1:

                neighbors.append(window_y[pos + 1])

            if not neighbors:

                return True

            if prefer_peak:

                return all(val >= nb for nb in neighbors)

            return all(val <= nb for nb in neighbors)

        try:

            anchor_distance = abs(float(window_x[anchor_pos] - xdata))

        except Exception:

            anchor_distance = float("inf")

        if not np.isfinite(anchor_distance):

            anchor_distance = float("inf")

        best_idx = None

        best_metric = (float("inf"), float("inf"))

        if anchor_distance <= dx_limit:

            best_idx = int(window_indices[anchor_pos])

            best_metric = (anchor_distance, 0.0)

            if _is_local(anchor_pos):

                return int(best_idx)

        n = window_indices.size

        # Iterate over the configured range to apply the per-item logic.
        for offset in range(1, n):

            candidates = []

            left_pos = anchor_pos - offset

            right_pos = anchor_pos + offset

            if left_pos >= 0:

                candidates.append(left_pos)

            if right_pos < n:

                candidates.append(right_pos)

            # Iterate over candidates to apply the per-item logic.
            for pos in candidates:

                if not _is_local(pos):

                    continue

                x_dist = abs(window_x[pos] - xdata)

                if x_dist > dx_limit:

                    continue

                idx_val = int(window_indices[pos])

                metric = (x_dist, abs(idx_val - anchor_idx))

                if metric < best_metric:

                    best_metric = metric

                    best_idx = idx_val

            if best_idx is not None and best_metric[0] <= anchor_distance:

                break

        if best_idx is not None:

            return int(best_idx)

        return anchor_idx

    def _nearest_index_by_x(self, xdata):
        """Perform nearest index by x.
        Used to keep the workflow logic localized and testable."""

        x, _, _ = self._get_xy()

        if x is None:

            return None

        xv = np.asarray(x, dtype=float)

        mask = self._current_mask()

        idx_all = np.where(mask)[0]

        if idx_all.size == 0:

            return None

        distances = np.abs(xv[idx_all] - xdata)

        if not np.isfinite(distances).any():

            return None

        j = int(idx_all[np.nanargmin(distances)])

        return j

    def _recompute_cycle_analysis(
        self, auto_detect=True, ignore_min_drop=False, *, preserve_view=False
    ):
        """Recompute cycle analysis for the current selection.

        Purpose:
            Trigger cycle analysis recomputation and refresh the UI summary.
        Why:
            Keeps cycle plots and summaries in sync with user inputs/markers.
        Args:
            auto_detect: When True, allow automatic peak/trough detection.
            ignore_min_drop: When True, ignore minimum drop thresholds.
            preserve_view: When True, keep current axis limits.
        Returns:
            None.
        Side Effects:
            Updates cycle analysis plots, schedules worker jobs, and logs debug.
        Exceptions:
            Best-effort guards suppress UI refresh failures.
        """

        if not self._cycle_ready():
            self._dbg(
                "cycle.interaction",
                "Cycle analysis recompute skipped: cycle not ready",
            )

            return

        auto_detect = bool(auto_detect and self.auto_detect_cycles.get())
        manual_only = not auto_detect
        self._dbg(
            "cycle.interaction",
            "Cycle analysis recompute start auto_detect=%s manual_only=%s preserve_view=%s",
            auto_detect,
            manual_only,
            preserve_view,
        )

        if (
            getattr(self, "_cycle_canvas", None) is None
            or getattr(self, "_cycle_ax", None) is None
        ):
            self._pending_cycle_recompute = {
                "auto_detect": auto_detect,
                "ignore_min_drop": ignore_min_drop,
                "preserve_view": preserve_view,
            }
            return

        ax = getattr(self, "_cycle_ax", None)

        old_xlim = None

        old_ylim = None

        if preserve_view and ax is not None:

            try:

                old_xlim = tuple(ax.get_xlim())

                old_ylim = tuple(ax.get_ylim())

            except Exception:

                old_xlim = None

                old_ylim = None

        def _apply_axis_limits(target_ax):
            """Apply axis limits.
            Used to apply axis limits changes to live state."""

            if target_ax is None:

                return

            try:

                if preserve_view and old_xlim is not None and old_ylim is not None:

                    target_ax.set_xlim(old_xlim)

                    target_ax.set_ylim(old_ylim)

                else:

                    target_ax.set_xlim(
                        float(self.min_time.get()), float(self.max_time.get())
                    )

                    target_ax.set_ylim(float(self.min_y.get()), float(self.max_y.get()))

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        with self._data_lock:
            # Snapshot shared data for thread safety/no-GIL readiness.
            x, y1, z = self._get_xy()
            mask = np.asarray(self._current_mask(), dtype=bool)

        if x is None or y1 is None:

            self._cycle_ax.clear()

            _apply_axis_limits(self._cycle_ax)

            self._cycle_ax.text(
                0.5,
                0.5,
                "Load data and select X & y1 first.",
                ha="center",
                va="center",
                transform=self._cycle_ax.transAxes,
                fontsize=self._cycle_plot_font_sizes()["axis"],
            )

            self._cycle_canvas.draw_idle()

            self._update_cycle_fig_tab(None)

            self._set_cycle_summary("(Load data and select X & y1 first.)")

            return

        xv = np.asarray(x, dtype=float)

        yv = np.asarray(y1, dtype=float)

        if mask.sum() < 3:

            self._cycle_ax.clear()

            _apply_axis_limits(self._cycle_ax)

            self._cycle_ax.text(
                0.5,
                0.5,
                "Selection too small for analysis.",
                ha="center",
                va="center",
                transform=self._cycle_ax.transAxes,
                fontsize=self._cycle_plot_font_sizes()["axis"],
            )

            self._cycle_canvas.draw_idle()

            self._set_cycle_summary("Selection too small for analysis.")

            return

        z_arr = np.asarray(z, dtype=float) if z is not None else None

        peak_finder = _get_peak_finder()

        if auto_detect and getattr(self, "_markers_seeded_from_cache", False):
            if self._auto_peaks or self._auto_troughs:
                auto_detect = False
            self._markers_seeded_from_cache = False

        if auto_detect and peak_finder is None:

            short_msg = "Cycle analysis requires SciPy."

            self._cycle_ax.clear()

            _apply_axis_limits(self._cycle_ax)

            self._cycle_ax.text(
                0.5,
                0.5,
                short_msg,
                ha="center",
                va="center",
                transform=self._cycle_ax.transAxes,
                fontsize=self._cycle_plot_font_sizes()["axis"],
            )

            self._cycle_canvas.draw_idle()

            full_msg = _scipy_missing_message("automatic cycle detection")

            self._set_cycle_summary(full_msg)

            _warn_missing_scipy("cycle analysis", parent=self, kind="error")

            return

        # Immediate feedback while heavy work happens in a worker thread

        self._cycle_ax.clear()

        _apply_axis_limits(self._cycle_ax)

        self._cycle_ax.text(
            0.5,
            0.5,
            "Analyzing cycle data...",
            ha="center",
            va="center",
            transform=self._cycle_ax.transAxes,
            fontsize=self._cycle_plot_font_sizes()["axis"],
        )

        self._cycle_canvas.draw_idle()

        self._set_cycle_summary("Analyzing cycle data...")

        pending_limits = (old_xlim, old_ylim)

        snapshot = dict(
            auto_peaks=set(getattr(self, "_auto_peaks", set())),
            auto_troughs=set(getattr(self, "_auto_troughs", set())),
            add_peaks=set(getattr(self, "_add_peaks", set())),
            add_troughs=set(getattr(self, "_add_troughs", set())),
            rm_peaks=set(getattr(self, "_rm_peaks", set())),
            rm_troughs=set(getattr(self, "_rm_troughs", set())),
        )

        prom = float(self.pk_prominence.get())

        dist = max(1, int(self.pk_distance.get()))

        wid = max(1, int(self.pk_width.get()))

        min_cycle_drop = float(self.min_cycle_drop.get())

        with self._cycle_job_lock:

            self._cycle_job_counter += 1

            job_id = self._cycle_job_counter

            self._cycle_active_job = job_id

        # Snapshot arrays for background compute.
        mask_copy = mask.copy()
        xv_copy = xv.copy()
        yv_copy = yv.copy()
        z_copy = z_arr.copy() if z_arr is not None else None

        def worker():
            """Perform worker.
            Used to keep the workflow logic localized and testable."""
            return self._compute_cycle_analysis_worker(
                xv_copy,
                yv_copy,
                mask_copy,
                z_copy,
                prom,
                dist,
                wid,
                min_cycle_drop,
                auto_detect,
                ignore_min_drop,
                peak_finder,
                snapshot,
                manual_only=manual_only,
            )

        def _on_ok(result):
            """Handle ok.
            Used as an event callback for ok."""
            self._apply_cycle_analysis_result(
                job_id,
                result,
                xv_copy,
                yv_copy,
                mask_copy,
                z_copy,
                ignore_min_drop,
                preserve_view,
                pending_limits,
            )

        def _on_err(exc):
            """Handle err.
            Used as an event callback for err."""
            self._apply_cycle_analysis_result(
                job_id,
                {"error": exc},
                xv_copy,
                yv_copy,
                mask_copy,
                z_copy,
                ignore_min_drop,
                preserve_view,
                pending_limits,
            )

        self._task_runner.submit("cycle_analysis", worker, _on_ok, _on_err)
        self._dbg(
            "cycle.interaction",
            "Cycle analysis job submitted job_id=%s auto_detect=%s",
            job_id,
            auto_detect,
        )

    def _compute_cycle_segmentation(
        self,
        xv,
        yv,
        mask,
        prom,
        dist,
        wid,
        min_cycle_drop,
        auto_detect,
        ignore_min_drop,
        peak_finder,
        snapshot,
        *,
        manual_only: bool = False,
    ) -> Dict[str, Any]:
        """Compute cycle segmentation.
        Used to reuse cycle segmentation without recomputing metrics."""
        mask_arr = np.asarray(mask, dtype=bool)
        y_arr = np.asarray(yv, dtype=float)

        data_len = int(y_arr.shape[0])
        mask_len = min(mask_arr.size, data_len)
        if mask_arr.size != mask_len:
            mask_arr = mask_arr[:mask_len]

        def _sanitize_indices(values):
            """Sanitize indices.
            Used to strip or normalize indices before use."""
            safe = set()
            # Iterate over values or [] to apply the per-item logic.
            for idx in values or []:
                try:
                    i = int(idx)
                except Exception:
                    continue
                if 0 <= i < mask_len:
                    safe.add(i)
            return safe

        idx_all = np.where(mask_arr)[0]

        auto_peaks = _sanitize_indices(snapshot.get("auto_peaks", set()))
        auto_troughs = _sanitize_indices(snapshot.get("auto_troughs", set()))

        auto_detection_used = bool(
            auto_detect and peak_finder is not None and not manual_only
        )

        if auto_detect and not manual_only:
            if peak_finder is None:
                raise ModuleNotFoundError(
                    _scipy_missing_message("automatic cycle detection")
                )
            y_masked = y_arr[mask_arr]
            p_rel, _ = peak_finder(
                y_masked,
                prominence=prominence_safe(prom),
                distance=max(1, dist),
                width=max(1, wid),
            )
            t_rel, _ = peak_finder(
                -y_masked,
                prominence=prominence_safe(prom),
                distance=max(1, dist),
                width=max(1, wid),
            )
            auto_peaks = _sanitize_indices(idx_all[p_rel].tolist())
            auto_troughs = _sanitize_indices(idx_all[t_rel].tolist())

        add_peaks = _sanitize_indices(snapshot.get("add_peaks", set()))
        add_troughs = _sanitize_indices(snapshot.get("add_troughs", set()))
        rm_peaks = _sanitize_indices(snapshot.get("rm_peaks", set()))
        rm_troughs = _sanitize_indices(snapshot.get("rm_troughs", set()))

        if manual_only:
            effective_peaks = set(add_peaks)
            effective_troughs = set(add_troughs)
        else:
            effective_peaks = (auto_peaks | add_peaks) - rm_peaks
            effective_troughs = (auto_troughs | add_troughs) - rm_troughs

        peaks = sorted(
            [i for i in effective_peaks if 0 <= i < mask_len and mask_arr[i]]
        )
        troughs = sorted(
            [i for i in effective_troughs if 0 <= i < mask_len and mask_arr[i]]
        )

        threshold = -float("inf") if ignore_min_drop else float(min_cycle_drop)
        cycles, total_drop = self._form_cycles(y_arr, peaks, troughs, threshold)

        cycle_peaks = {int(c.get("peak_idx", -1)) for c in cycles}
        cycle_troughs = {int(c.get("trough_idx", -1)) for c in cycles}
        cycle_peaks = {i for i in cycle_peaks if 0 <= i < mask_len and mask_arr[int(i)]}
        cycle_troughs = {
            i for i in cycle_troughs if 0 <= i < mask_len and mask_arr[int(i)]
        }

        display_peaks = set()
        # Iterate over effective_peaks to apply the per-item logic.
        for idx in effective_peaks:
            try:
                i = int(idx)
            except Exception:
                continue
            if 0 <= i < mask_len and mask_arr[i]:
                display_peaks.add(i)

        display_troughs = set()
        # Iterate over effective_troughs to apply the per-item logic.
        for idx in effective_troughs:
            try:
                i = int(idx)
            except Exception:
                continue
            if 0 <= i < mask_len and mask_arr[i]:
                display_troughs.add(i)

        plot_peaks = np.array(sorted(cycle_peaks | display_peaks), dtype=int)
        plot_troughs = np.array(sorted(cycle_troughs | display_troughs), dtype=int)
        if plot_peaks.size:
            plot_peaks = plot_peaks[(plot_peaks >= 0) & (plot_peaks < mask_len)]
        if plot_troughs.size:
            plot_troughs = plot_troughs[(plot_troughs >= 0) & (plot_troughs < mask_len)]

        has_manual_edits = bool(add_peaks or add_troughs or rm_peaks or rm_troughs)
        if manual_only:
            selection_mode = "Manual-only"
        elif auto_detection_used and has_manual_edits:
            selection_mode = "Mixed"
        elif auto_detection_used:
            selection_mode = "Auto"
        else:
            selection_mode = "Manual-only"

        return {
            "auto_peaks": auto_peaks,
            "auto_troughs": auto_troughs,
            "plot_peaks": plot_peaks,
            "plot_troughs": plot_troughs,
            "cycles": cycles,
            "total_drop": total_drop,
            "auto_detection_used": auto_detection_used,
            "selection_mode": selection_mode,
            "mask_len": mask_len,
            "selection_size": int(mask_arr.sum()),
        }

    def _compute_cycle_metrics_from_segmentation(
        self,
        segmentation: Dict[str, Any],
        xv,
        yv,
        z_arr,
        prom,
        dist,
        wid,
        min_cycle_drop,
        ignore_min_drop,
        *,
        data_ctx: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """Compute cycle metrics from segmentation results."""
        cycles = segmentation.get("cycles") or []
        total_drop = segmentation.get("total_drop", 0.0)
        selection_mode = segmentation.get("selection_mode", "Manual-only")

        z_all = np.asarray(z_arr, dtype=float) if z_arr is not None else None

        context = data_ctx or {}
        V_L = context.get(
            "volume", settings.get("vessel_volume", globals().get("volume", 1.0))
        )
        a_c = context.get(
            "a_const", settings.get("vdw_a", globals().get("a_const", 1.39))
        )
        b_c = context.get(
            "b_const", settings.get("vdw_b", globals().get("b_const", 0.0391))
        )

        (
            per_cycle,
            total_moles_ideal,
            total_moles_vdw,
            scipy_available,
            vdw_used,
        ) = _compute_cycle_statistics(
            cycles,
            z_all,
            V_L,
            a_c,
            b_c,
            allow_threads=True,
            force_vdw=False,
        )

        gas_molar_mass = context.get(
            "gas_molar_mass",
            settings.get(
                "vdw_gas_molar_mass",
                globals().get("gas_molar_mass", DEFAULT_GAS_MOLAR_MASS),
            ),
        )
        try:
            gas_molar_mass = float(gas_molar_mass)
            if not math.isfinite(gas_molar_mass) or gas_molar_mass <= 0:
                raise ValueError
        except Exception:
            gas_molar_mass = DEFAULT_GAS_MOLAR_MASS

        try:
            x_all = np.asarray(xv, dtype=float)
        except Exception:
            x_all = None

        def _safe_value(arr, idx):
            """Perform safe value.
            Used to keep the workflow logic localized and testable."""
            if arr is None:
                return None
            try:
                j = int(idx)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            if j < 0:
                return None
            try:
                value = float(arr[j])
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            if not math.isfinite(value):
                return None
            return value

        cumulative_moles = 0.0
        cycle_transfer_rows: List[Dict[str, Any]] = []
        selected_columns_meta = context.get("selected_columns") or globals().get(
            "selected_columns", {}
        )
        x_label = str(selected_columns_meta.get("x", "Elapsed Time (days)")).replace(
            "_", " "
        )
        # Iterate over indexed elements from zip(cycles, per_cycle), 1 to apply the per-item logic.
        for idx, (cycle_row, stats_row) in enumerate(zip(cycles, per_cycle), 1):
            peak_idx = cycle_row.get("peak_idx")
            trough_idx = cycle_row.get("trough_idx")
            start_time = _safe_value(x_all, peak_idx)
            end_time = _safe_value(x_all, trough_idx)
            duration = (
                None
                if start_time is None or end_time is None
                else float(end_time - start_time)
            )
            peak_pressure = float(cycle_row.get("peak", float("nan")))
            trough_pressure = float(cycle_row.get("trough", float("nan")))
            delta_psi = float(stats_row.get("deltaP", float("nan")))
            delta_atm = delta_psi / 14.696 if math.isfinite(delta_psi) else None
            mean_temp_c = float(stats_row.get("T_mean_C", float("nan")))
            used_default_temp = bool(stats_row.get("used_default"))
            moles_vdw = float(stats_row.get("n_vdw", float("nan")))
            use_vdw = math.isfinite(moles_vdw)
            if use_vdw and moles_vdw < 0:
                use_vdw = False
            moles_ideal = float(stats_row.get("n_ideal", float("nan")))
            selected_moles = moles_vdw if use_vdw else moles_ideal
            if not math.isfinite(selected_moles):
                selected_moles_val = None
            else:
                selected_moles_val = selected_moles
                cumulative_moles += selected_moles_val
            selected_mass = (
                None
                if selected_moles_val is None
                else selected_moles_val * gas_molar_mass
            )
            cumulative_co2_mass = cumulative_moles * gas_molar_mass
            cycle_transfer_rows.append(
                {
                    "cycle_id": idx,
                    "peak_index": int(peak_idx) if peak_idx is not None else None,
                    "trough_index": int(trough_idx) if trough_idx is not None else None,
                    "start_x": start_time,
                    "end_x": end_time,
                    "x_label": x_label,
                    "duration_x": duration,
                    "peak_pressure_psi": peak_pressure,
                    "trough_pressure_psi": trough_pressure,
                    "delta_pressure_psi": delta_psi,
                    "delta_pressure_atm": delta_atm,
                    "mean_temperature_c": mean_temp_c,
                    "used_default_temperature": used_default_temp,
                    "moles_ideal": moles_ideal if math.isfinite(moles_ideal) else None,
                    "moles_vdw": moles_vdw if math.isfinite(moles_vdw) else None,
                    "moles_basis": "vdw" if use_vdw else "ideal",
                    "selected_moles": selected_moles_val,
                    "selected_mass_g": selected_mass,
                    "cumulative_moles": cumulative_moles,
                    "cumulative_co2_moles": cumulative_moles,
                    "cumulative_co2_mass_g": cumulative_co2_mass,
                }
            )

        cycle_context = {
            "volume_l": V_L,
            "vdw_a": a_c,
            "vdw_b": b_c,
            "pressure_units": "PSI",
            "temperature_units": "C",
            "x_label": x_label,
            "min_cycle_drop_psi": float(min_cycle_drop),
            "ignore_min_drop": bool(ignore_min_drop),
            "auto_detection_used": bool(segmentation.get("auto_detection_used")),
            "manual_only": bool(segmentation.get("selection_mode") == "Manual-only"),
            "selection_mode": selection_mode,
            "peak_prominence": float(prom),
            "peak_distance": int(dist),
            "peak_width": int(wid),
            "cycle_temp_column": context.get(
                "cycle_temp_column",
                settings.get("cycle_temp_column", CYCLE_TEMP_DEFAULT_LABEL),
            ),
            "vdw_used": vdw_used,
            "gas_molar_mass": gas_molar_mass,
            "selection_size": int(segmentation.get("selection_size") or 0),
        }

        summary_context = {
            "selection_mode": selection_mode,
            "min_cycle_drop_psi": float(min_cycle_drop),
            "ignore_min_drop": bool(ignore_min_drop),
            "peak_prominence": float(prom),
            "peak_distance": int(dist),
            "peak_width": int(wid),
            "temp_column_label": cycle_context["cycle_temp_column"],
            "per_cycle": per_cycle,
            "volume_l": V_L,
            "a_const": a_c,
            "b_const": b_c,
            "gas_molar_mass": gas_molar_mass,
            "scipy_available": scipy_available,
            "vdw_used": vdw_used,
        }

        resolved_inputs = resolve_cycle_summary_inputs(
            settings, globals_fallback=globals(), context=summary_context
        )
        options = resolve_cycle_summary_options(settings)
        summary = build_cycle_analysis_summary(
            cycles,
            per_cycle,
            total_drop,
            total_moles_ideal,
            total_moles_vdw,
            vdw_used=vdw_used,
            scipy_available=scipy_available,
            resolved_inputs=resolved_inputs,
            options=options,
        )

        return {
            "per_cycle": per_cycle,
            "total_moles_ideal": total_moles_ideal,
            "total_moles_vdw": total_moles_vdw,
            "gas_molar_mass": gas_molar_mass,
            "vdw_used": vdw_used,
            "scipy_available": scipy_available,
            "cycle_transfer": cycle_transfer_rows,
            "cycle_context": cycle_context,
            "summary": summary,
        }

    def _compute_cycle_analysis_worker(
        self,
        xv,
        yv,
        mask,
        z_arr,
        prom,
        dist,
        wid,
        min_cycle_drop,
        auto_detect,
        ignore_min_drop,
        peak_finder,
        snapshot,
        *,
        manual_only: bool = False,
        data_ctx: Optional[Dict[str, Any]] = None,
    ):
        """Compute cycle analysis in a worker context.

        Purpose:
            Perform cycle segmentation and metrics computation off the UI thread.
        Why:
            Keeps heavy analysis work from blocking UI responsiveness.
        Args:
            xv: X-axis values array.
            yv: Y-axis values array.
            mask: Boolean mask for selected range.
            z_arr: Optional temperature array.
            prom: Peak prominence.
            dist: Peak distance.
            wid: Peak width.
            min_cycle_drop: Minimum drop threshold.
            auto_detect: Enable automatic peak detection.
            ignore_min_drop: Ignore minimum drop threshold.
            peak_finder: Peak detection callable.
            snapshot: Snapshot dict of cycle state.
            manual_only: When True, only manual markers are used.
            data_ctx: Optional prepared data context.
        Returns:
            Dict of cycle analysis results and summaries.
        Side Effects:
            Records performance timing when enabled.
        Exceptions:
            Exceptions propagate to the worker error handler.
        """
        self._dbg(
            "cycle.analysis",
            "Cycle analysis compute start auto_detect=%s manual_only=%s",
            auto_detect,
            manual_only,
        )
        with self._perf_time("cycle.analysis", "cycle_analysis_compute"):
            segmentation = self._compute_cycle_segmentation(
                xv,
                yv,
                mask,
                prom,
                dist,
                wid,
                min_cycle_drop,
                auto_detect,
                ignore_min_drop,
                peak_finder,
                snapshot,
                manual_only=manual_only,
            )
            metrics = self._compute_cycle_metrics_from_segmentation(
                segmentation,
                xv,
                yv,
                z_arr,
                prom,
                dist,
                wid,
                min_cycle_drop,
                ignore_min_drop,
                data_ctx=data_ctx,
            )

        result = dict(
            auto_peaks=segmentation.get("auto_peaks", set()),
            auto_troughs=segmentation.get("auto_troughs", set()),
            plot_peaks=segmentation.get("plot_peaks"),
            plot_troughs=segmentation.get("plot_troughs"),
            cycles=segmentation.get("cycles") or [],
            per_cycle=metrics.get("per_cycle") or [],
            total_drop=segmentation.get("total_drop", 0.0),
            summary=metrics.get("summary") or "",
            auto_detection_used=bool(segmentation.get("auto_detection_used")),
            total_moles_ideal=metrics.get("total_moles_ideal"),
            total_moles_vdw=metrics.get("total_moles_vdw"),
            gas_molar_mass=metrics.get("gas_molar_mass"),
            vdw_used=metrics.get("vdw_used"),
            scipy_available=metrics.get("scipy_available"),
            cycle_transfer=metrics.get("cycle_transfer") or [],
            cycle_context=metrics.get("cycle_context") or {},
        )
        self._dbg(
            "cycle.analysis",
            "Cycle analysis compute done cycles=%s",
            len(result.get("cycles") or []),
        )
        return result

    def _apply_cycle_analysis_result(
        self,
        job_id,
        result,
        xv,
        yv,
        mask,
        z_arr,
        ignore_min_drop,
        preserve_view,
        pending_limits,
    ):
        """Apply cycle analysis results to the UI state.

        Purpose:
            Update plots and summaries after cycle analysis completes.
        Why:
            Keeps the Cycle Analysis tab synchronized with background results.
        Args:
            job_id: Cycle analysis job identifier.
            result: Result payload or error dict from the worker.
            xv: X-axis values array.
            yv: Y-axis values array.
            mask: Boolean mask for selected range.
            z_arr: Optional temperature array.
            ignore_min_drop: Ignore minimum drop threshold.
            preserve_view: When True, keep current axis limits.
            pending_limits: Optional cached axis limits to restore.
        Returns:
            None.
        Side Effects:
            Updates plot artists, summary text, and debug logs.
        Exceptions:
            Best-effort guards suppress UI update failures.
        """

        if job_id != self._cycle_active_job:

            self._dbg(
                "cycle.interaction",
                "Cycle analysis result ignored (stale) job_id=%s active=%s",
                job_id,
                self._cycle_active_job,
            )
            return  # stale result from an older job

        xlim_pending, ylim_pending = (None, None)

        if isinstance(pending_limits, tuple) and len(pending_limits) == 2:

            xlim_pending, ylim_pending = pending_limits

        def _set_limits():
            """Set limits.
            Used to persist limits into the current state."""

            try:

                if preserve_view and xlim_pending and ylim_pending:

                    self._cycle_ax.set_xlim(xlim_pending)

                    self._cycle_ax.set_ylim(ylim_pending)

                else:

                    self._cycle_ax.set_xlim(
                        float(self.min_time.get()), float(self.max_time.get())
                    )

                    self._cycle_ax.set_ylim(
                        float(self.min_y.get()), float(self.max_y.get())
                    )

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if not isinstance(result, dict) or "error" in result:

            err = result.get("error") if isinstance(result, dict) else None
            if err is not None:
                self._dbg_exc("cycle.analysis", "Cycle analysis failed", err)
            else:
                self._dbg(
                    "cycle.analysis",
                    "Cycle analysis failed with unknown error.",
                )

            msg = "Cycle analysis failed."

            if err is not None:

                msg = f"Cycle analysis failed: {err}"

                print(msg, file=sys.stderr)

            self._cycle_ax.clear()

            _set_limits()

            self._cycle_ax.text(
                0.5,
                0.5,
                msg,
                ha="center",
                va="center",
                transform=self._cycle_ax.transAxes,
                fontsize=self._cycle_plot_font_sizes()["axis"],
            )

            self._cycle_canvas.draw_idle()

            self._set_cycle_summary(msg)

            self._pending_fig3_update = None

            self._suspend_cycle_fig3_refresh = False

            if not getattr(self, "_suspend_cycle_fig3_refresh", False):

                self._update_cycle_fig_tab(None)

            return

        import matplotlib.patches as mpatches

        from matplotlib.lines import Line2D

        mask_arr = np.asarray(mask, dtype=bool)

        self._auto_peaks = set(result.get("auto_peaks", set()))

        self._auto_troughs = set(result.get("auto_troughs", set()))

        auto_detect_used = bool(result.get("auto_detection_used"))
        self._cycle_last_auto_detect = auto_detect_used
        self._cycle_last_ignore_min_drop = bool(ignore_min_drop)

        summary = result.get("summary", "")

        self._set_cycle_summary(summary)
        total_moles_ideal = result.get("total_moles_ideal")
        total_moles_vdw = result.get("total_moles_vdw")
        cycle_transfer = result.get("cycle_transfer") or []
        cycle_context = result.get("cycle_context") or {}
        cycles = result.get("cycles") or []
        per_cycle = result.get("per_cycle") or []
        scipy_available = result.get("scipy_available")
        payload = None
        if (
            total_moles_ideal is not None
            or total_moles_vdw is not None
            or cycle_transfer
        ):
            payload = {
                "timestamp": datetime.now().isoformat(timespec="seconds"),
                "summary": summary,
                "cycles": cycles,
                "per_cycle": per_cycle,
                "total_moles_ideal": (
                    float(total_moles_ideal) if total_moles_ideal is not None else None
                ),
                "total_moles_vdw": (
                    float(total_moles_vdw) if total_moles_vdw is not None else None
                ),
                "gas_molar_mass": result.get("gas_molar_mass"),
                "vdw_used": result.get("vdw_used"),
                "scipy_available": scipy_available,
                "cycle_transfer": cycle_transfer,
                "cycle_context": cycle_context,
                "total_drop_psi": result.get("total_drop"),
            }
        self._cycle_last_transfer_payload = payload

        self._cycle_ax.clear()

        _set_limits()

        style = get_cycle_trace_style()

        self._cycle_ax.set_xlabel(
            str(
                globals().get("selected_columns", {}).get("x", "Elapsed Time (days)")
            ).replace("_", " ")
        )

        self._cycle_ax.set_ylabel("Pressure (PSI)")

        self._apply_cycle_axis_style()
        sizes = self._cycle_plot_font_sizes()
        font_family = (settings.get("font_family") or "").strip()
        _center_titles_to_axes_union(
            self._cycle_ax.figure,
            [self._cycle_ax],
            "Interactive Cycle Analysis",
            None,
            sizes["title"],
            None,
            font_family,
            float(plt.rcParams.get("axes.titlepad", 6.0)),
            0.0,
        )
        try:
            self._cycle_ax.figure.subplots_adjust(top=0.88)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        xplot, yplot = self._apply_plot_selection_nan_mask(xv, yv, mask_arr)

        self._ca_x = np.asarray(xplot, dtype=float)

        self._ca_y = np.asarray(yplot, dtype=float)

        if z_arr is not None:
            zplot = np.asarray(z_arr, dtype=float)
            if mask_arr is not None and zplot.shape[0] == mask_arr.size:
                zplot = zplot.copy()
                zplot[~mask_arr] = np.nan
            self._ca_z = np.asarray(zplot, dtype=float)
        else:
            self._ca_z = None

        (self._line_artist,) = self._cycle_ax.plot(
            xplot,
            yplot,
            linestyle=style["resolved_linestyle"],
            color=style["line_color"],
            linewidth=style["line_width"],
            marker=",",
            markersize=0.8,
            label="Pressure (PSI)",
        )

        plot_peaks = np.asarray(result.get("plot_peaks", []), dtype=int)

        plot_troughs = np.asarray(result.get("plot_troughs", []), dtype=int)

        self._peak_artist = None

        self._trough_artist = None

        cycle_marker_zorder = _compute_top_overlay_zorder(
            self._cycle_ax, min_z=CYCLE_MARKER_MIN_ZORDER, pad=CYCLE_MARKER_ZORDER_PAD
        )
        if plot_peaks.size:
            self._peak_artist = self._cycle_ax.scatter(
                xv[plot_peaks],
                yv[plot_peaks],
                marker=style["peak_marker"],
                s=style["marker_size"],
                c=style["peak_color"],
                zorder=cycle_marker_zorder,
                label="Peak",
            )

        if plot_troughs.size:
            self._trough_artist = self._cycle_ax.scatter(
                xv[plot_troughs],
                yv[plot_troughs],
                marker=style["trough_marker"],
                s=style["marker_size"],
                c=style["trough_color"],
                zorder=cycle_marker_zorder,
                label="Trough",
            )

        cycles = result.get("cycles", [])

        total_drop = float(result.get("total_drop", 0.0))

        handles, labels = self._cycle_ax.get_legend_handles_labels()

        handles.append(Line2D([], [], color="none"))

        labels.append(f"Cycles: {len(cycles)}")

        handles.append(mpatches.Patch(color="none"))

        labels.append(f"Total ΔP: {total_drop:.2f} PSI")

        show_threshold_line = (not ignore_min_drop) and auto_detect_used

        if show_threshold_line:
            handles.append(mpatches.Patch(color="none"))
            labels.append(
                f"Min ΔP threshold: {float(self.min_cycle_drop.get()):.2f} PSI"
            )

        anchor = getattr(self, "_cycle_legend_anchor", None)

        if isinstance(anchor, (tuple, list)) and len(anchor) == 2:

            leg = self._cycle_ax.legend(
                handles,
                labels,
                loc="center",
                bbox_to_anchor=anchor,
                bbox_transform=self._cycle_ax.transAxes,
                **_legend_shadowbox_kwargs(),
            )

        else:

            leg = self._cycle_ax.legend(
                handles,
                labels,
                loc="lower right",
                bbox_to_anchor=(0.98, 0.02),
                bbox_transform=self._cycle_ax.transAxes,
                **_legend_shadowbox_kwargs(),
            )
        self._apply_cycle_legend_style(leg)

        _make_legend_draggable(leg)

        self._cycle_legend_obj = leg

        if self._cycle_pending_range:
            self._shade_selection(self._cycle_pending_range)

        else:
            self._shade_selection(None)

        self._cycle_canvas.draw_idle()

        try:
            effective_peaks = self._effective_peaks()
            effective_troughs = self._effective_troughs()
        except Exception:
            effective_peaks = set()
            effective_troughs = set()

        self._cache_cycle_markers(effective_peaks, effective_troughs, mask)

        try:
            self._refresh_final_report_cycle_snapshot(ignore_min_drop=ignore_min_drop)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        pending = getattr(self, "_pending_fig3_update", None)

        if pending:
            fig = None

            err_msg = None

            try:
                fig = self._build_cycle_figure_from_current_markers(
                    ignore_min_drop=pending.get("ignore_min_drop", True),
                    include_moles_legend=pending.get("include_moles", False),
                )

            except Exception as exc:

                err_msg = f"Figure 3 regeneration failed: {exc}"

                print(err_msg, file=sys.stderr)

            if fig is not None:

                self._update_cycle_fig_tab(fig)

            else:

                if err_msg is None:

                    err_msg = "Figure 3 could not be generated. Adjust your markers and try again."

                try:

                    messagebox.showwarning("Cycle Analysis", err_msg)

                except Exception:

                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

                self._update_cycle_fig_tab(None)

            self._pending_fig3_update = None

            self._suspend_cycle_fig3_refresh = False

            return

        if not getattr(self, "_suspend_cycle_fig3_refresh", False):

            self._update_cycle_fig_tab(None)

    def _recompute_manual_only(self):
        """Recompute cycle outputs using manual marker state only.

        Purpose:
            Refresh cycle summary metrics and the interactive cycle plot after
            manual marker edits.
        Why:
            Manual correction workflows require immediate recalculation without
            auto-detection overriding user-selected peak/trough points.
        Inputs:
            None. Uses current UI state, marker sets, and selected data mask.
        Outputs:
            None.
        Side Effects:
            Rebuilds cycle artists, updates summary text, and refreshes cycle tabs.
        Exceptions:
            Guarded checks return early when required data is unavailable.
        """

        import matplotlib.patches as mpatches

        from matplotlib.lines import Line2D

        if not self._cycle_ready():

            return

        self._cycle_last_auto_detect = False

        x, y1, z = self._get_xy()

        if x is None or y1 is None:

            self._set_cycle_summary("(Load data and select X & y1 first.)")

            return

        xv = np.asarray(x, dtype=float)

        yv = np.asarray(y1, dtype=float)

        mask_arr = np.asarray(self._current_mask(), dtype=bool)

        if mask_arr.size == 0 or mask_arr.sum() < 3:

            self._set_cycle_summary("Selection too small for analysis.")

            return

        # Manual-only markers within current mask

        mask_len = mask_arr.size

        # Closure captures _recompute_manual_only local context to keep helper logic scoped and invoked directly within _recompute_manual_only.
        def _manual_valid(indices):
            """Perform manual valid.
            Used to keep the workflow logic localized and testable."""
            safe = set()
            # Iterate over indices or [] to apply the per-item logic.
            for idx in indices or []:
                try:
                    i = int(idx)
                except Exception:
                    continue
                if 0 <= i < mask_len and mask_arr[i]:
                    safe.add(i)
            return sorted(safe)

        peaks = _manual_valid(self._add_peaks)

        troughs = _manual_valid(self._add_troughs)

        if not peaks or not troughs:

            self._set_cycle_summary(
                "Add at least one manual peak and one manual trough."
            )

            return

        # Form cycles and compute totals

        min_drop = float(self.min_cycle_drop.get())

        cycles, total_drop = self._form_cycles(yv, peaks, troughs, min_drop)

        plot_peaks, plot_troughs = self._markers_for_display(
            mask_arr, cycles, include_manual=True, cycle_only=True
        )

        data_len = int(xv.shape[0])
        plot_peaks = np.asarray([i for i in plot_peaks if 0 <= i < data_len], dtype=int)
        plot_troughs = np.asarray(
            [i for i in plot_troughs if 0 <= i < data_len], dtype=int
        )

        # Compute moles using per-cycle mean temperature (°C) between each peak/trough

        z_all = np.asarray(z, dtype=float) if z is not None else None

        V_L = settings.get("vessel_volume", globals().get("volume", 1.0))

        a_c = settings.get("vdw_a", globals().get("a_const", 1.39))

        b_c = settings.get("vdw_b", globals().get("b_const", 0.0391))

        (
            per_cycle,
            total_moles_ideal,
            total_moles_vdw,
            scipy_available,
            vdw_used,
        ) = _compute_cycle_statistics(
            cycles,
            z_all,
            V_L,
            a_c,
            b_c,
            allow_threads=True,
            force_vdw=True,
        )

        gas_molar_mass = settings.get(
            "vdw_gas_molar_mass",
            globals().get("gas_molar_mass", DEFAULT_GAS_MOLAR_MASS),
        )
        try:
            gas_molar_mass = float(gas_molar_mass)
            if not math.isfinite(gas_molar_mass) or gas_molar_mass <= 0:
                raise ValueError
        except Exception:
            gas_molar_mass = DEFAULT_GAS_MOLAR_MASS

        cycle_context = {
            "volume_l": V_L,
            "vdw_a": a_c,
            "vdw_b": b_c,
            "pressure_units": "PSI",
            "temperature_units": "C",
            "x_label": str(
                globals().get("selected_columns", {}).get("x", "Elapsed Time (days)")
            ).replace("_", " "),
            "min_cycle_drop_psi": float(min_drop),
            "ignore_min_drop": False,
            "auto_detection_used": False,
            "manual_only": True,
            "selection_mode": "Manual-only",
            "peak_prominence": float(self.pk_prominence.get()),
            "peak_distance": int(self.pk_distance.get()),
            "peak_width": int(self.pk_width.get()),
            "cycle_temp_column": settings.get(
                "cycle_temp_column", CYCLE_TEMP_DEFAULT_LABEL
            ),
            "vdw_used": vdw_used,
            "gas_molar_mass": gas_molar_mass,
            "selection_size": int(mask_arr.sum()),
        }

        summary_context = {
            "selection_mode": "Manual-only",
            "min_cycle_drop_psi": float(min_drop),
            "ignore_min_drop": False,
            "peak_prominence": float(self.pk_prominence.get()),
            "peak_distance": int(self.pk_distance.get()),
            "peak_width": int(self.pk_width.get()),
            "temp_column_label": cycle_context["cycle_temp_column"],
            "per_cycle": per_cycle,
            "volume_l": V_L,
            "a_const": a_c,
            "b_const": b_c,
            "gas_molar_mass": gas_molar_mass,
            "scipy_available": scipy_available,
            "vdw_used": vdw_used,
        }

        resolved_inputs = resolve_cycle_summary_inputs(
            settings, globals_fallback=globals(), context=summary_context
        )
        options = resolve_cycle_summary_options(settings)
        summary = build_cycle_analysis_summary(
            cycles,
            per_cycle,
            total_drop,
            total_moles_ideal,
            total_moles_vdw,
            vdw_used=vdw_used,
            scipy_available=scipy_available,
            resolved_inputs=resolved_inputs,
            options=options,
        )

        self._set_cycle_summary(summary)
        self._cycle_last_transfer_payload = {
            "timestamp": datetime.now().isoformat(timespec="seconds"),
            "summary": summary,
            "cycles": cycles,
            "per_cycle": per_cycle,
            "total_moles_ideal": float(total_moles_ideal),
            "total_moles_vdw": float(total_moles_vdw),
            "gas_molar_mass": gas_molar_mass,
            "vdw_used": vdw_used,
            "scipy_available": scipy_available,
            "cycle_transfer": [],
            "cycle_context": cycle_context,
            "total_drop_psi": total_drop,
        }
        # Push the summary through the shared callback

        cb = globals().get("update_cycle_summary_callback")

        if callable(cb):
            cb(summary)

        # Redraw plot (manual markers only)

        self._cycle_ax.clear()

        self._cycle_ax.set_xlim(self.min_time.get(), self.max_time.get())

        self._cycle_ax.set_ylim(self.min_y.get(), self.max_y.get())

        self._cycle_ax.set_xlabel(
            str(
                globals().get("selected_columns", {}).get("x", "Elapsed Time (days)")
            ).replace("_", " ")
        )

        self._cycle_ax.set_ylabel("Pressure (PSI)")

        self._apply_cycle_axis_style()
        sizes = self._cycle_plot_font_sizes()
        font_family = (settings.get("font_family") or "").strip()
        _center_titles_to_axes_union(
            self._cycle_ax.figure,
            [self._cycle_ax],
            "Interactive Cycle Analysis (Manual Only)",
            None,
            sizes["title"],
            None,
            font_family,
            float(plt.rcParams.get("axes.titlepad", 6.0)),
            0.0,
        )
        try:
            self._cycle_ax.figure.subplots_adjust(top=0.88)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        style = get_cycle_trace_style()

        xplot, yplot = self._apply_plot_selection_nan_mask(xv, yv, mask_arr)

        (self._line_artist,) = self._cycle_ax.plot(
            xplot,
            yplot,
            linestyle=style["resolved_linestyle"],
            linewidth=style["line_width"],
            marker=",",
            markersize=0.8,
            color=style["line_color"],
            label="Pressure (PSI)",
        )

        px = xv[plot_peaks]

        py = yv[plot_peaks]

        tx = xv[plot_troughs]

        ty = yv[plot_troughs]

        cycle_marker_zorder = _compute_top_overlay_zorder(
            self._cycle_ax, min_z=CYCLE_MARKER_MIN_ZORDER, pad=CYCLE_MARKER_ZORDER_PAD
        )
        if len(px):
            self._peak_artist = self._cycle_ax.scatter(
                px,
                py,
                marker=style["peak_marker"],
                s=style["marker_size"],
                c=style["peak_color"],
                zorder=cycle_marker_zorder,
                label="Peak",
            )

        if len(tx):
            self._trough_artist = self._cycle_ax.scatter(
                tx,
                ty,
                marker=style["trough_marker"],
                s=style["marker_size"],
                c=style["trough_color"],
                zorder=cycle_marker_zorder,
                label="Trough",
            )

        handles, labels = self._cycle_ax.get_legend_handles_labels()

        handles.append(Line2D([], [], color="none"))

        labels.append(f"Cycles: {len(cycles)}")

        handles.append(mpatches.Patch(color="none"))

        labels.append(f"Total ΔP: {total_drop:.2f} PSI")

        anchor = getattr(self, "_cycle_legend_anchor", None)

        if isinstance(anchor, (tuple, list)) and len(anchor) == 2:

            leg = self._cycle_ax.legend(
                handles,
                labels,
                loc="center",
                bbox_to_anchor=anchor,
                bbox_transform=self._cycle_ax.transAxes,
                **_legend_shadowbox_kwargs(),
            )

        else:

            leg = self._cycle_ax.legend(
                handles,
                labels,
                loc="lower right",
                bbox_to_anchor=(0.98, 0.02),
                bbox_transform=self._cycle_ax.transAxes,
                **_legend_shadowbox_kwargs(),
            )
        self._apply_cycle_legend_style(leg)

        _make_legend_draggable(leg)

        self._cycle_legend_obj = leg

        # Repaint selection band if any

        if self._cycle_pending_range:

            self._shade_selection(self._cycle_pending_range)

        else:

            self._shade_selection(None)

        self._cycle_canvas.draw_idle()

        # Any existing Figure 3 is now stale until the user explicitly regenerates it

        if not getattr(self, "_suspend_cycle_fig3_refresh", False):

            self._update_cycle_fig_tab(None)

        self._cache_cycle_markers(peaks, troughs, mask_arr)

    def _build_cycle_figure_from_current_markers(
        self, *, ignore_min_drop: bool = True, include_moles_legend: bool = False
    ):
        """Build a static cycle figure from the current effective marker state.

        Purpose:
            Create an export/display-ready cycle figure from the active marker set.
        Why:
            Users need a deterministic cycle figure that reflects current manual
            and auto marker decisions without rerunning full plot generation.
        Inputs:
            ignore_min_drop: When True, include cycles regardless of minimum drop.
            include_moles_legend: When True, append moles summary lines to legend.
        Outputs:
            Matplotlib Figure instance, or None when prerequisites are missing.
        Side Effects:
            Constructs a new figure and populates axes, markers, and legend entries.
        Exceptions:
            Returns None when required data/mask context is not available.
        """

        import matplotlib.pyplot as plt

        from matplotlib.ticker import MultipleLocator, AutoMinorLocator, AutoLocator

        from matplotlib.lines import Line2D

        import matplotlib.patches as mpatches

        import numpy as np

        x, y1, z = self._get_xy()

        if x is None or y1 is None:
            return None

        xv = np.asarray(x, dtype=float)

        yv = np.asarray(y1, dtype=float)

        mask_arr = np.asarray(self._current_mask(), dtype=bool)

        if mask_arr.size == 0 or mask_arr.sum() < 3:
            return None

        # Effective markers, restricted to current mask

        mask_len = mask_arr.size

        def _select_valid(indices):
            """Perform select valid.
            Used to keep the workflow logic localized and testable."""
            safe = set()
            # Iterate over indices or [] to apply the per-item logic.
            for idx in indices or []:
                try:
                    i = int(idx)
                except Exception:
                    continue
                if 0 <= i < mask_len and mask_arr[i]:
                    safe.add(i)
            return sorted(safe)

        peaks = _select_valid(self._effective_peaks())

        troughs = _select_valid(self._effective_troughs())

        # Form cycles with/without threshold

        min_drop = (
            -float("inf") if ignore_min_drop else float(self.min_cycle_drop.get())
        )

        cycles, total_drop = self._form_cycles(yv, peaks, troughs, min_drop)

        auto_detect_used = bool(getattr(self, "_cycle_last_auto_detect", False))

        plot_peaks, plot_troughs = self._markers_for_display(
            mask_arr, cycles, include_manual=True, cycle_only=False
        )

        data_len = int(xv.shape[0])
        plot_peaks = np.asarray([i for i in plot_peaks if 0 <= i < data_len], dtype=int)
        plot_troughs = np.asarray(
            [i for i in plot_troughs if 0 <= i < data_len], dtype=int
        )

        # X/Y data for plotting

        xplot, yplot = self._apply_plot_selection_nan_mask(xv, yv, mask_arr)

        fig, ax = plt.subplots(figsize=(11, 8.5))

        fig.subplots_adjust(left=0.076, right=0.97, bottom=0.079, top=0.914)

        style = get_cycle_trace_style()

        _plot_series(
            ax,
            xplot,
            yplot,
            label="Pressure (PSI)",
            color=style["line_color"],
            zorder=2,
            series_key="y1",
            line_style=style["resolved_linestyle"],
            linewidth=style["line_width"],
        )

        # Scatter peaks/troughs (from full arrays but only masked indices are included)

        px = xv[plot_peaks]

        py = yv[plot_peaks]

        tx = xv[plot_troughs]

        ty = yv[plot_troughs]

        cycle_marker_zorder = _compute_top_overlay_zorder(
            ax, min_z=CYCLE_MARKER_MIN_ZORDER, pad=CYCLE_MARKER_ZORDER_PAD
        )
        if len(px):

            ax.scatter(
                px,
                py,
                marker=style["peak_marker"],
                s=style["marker_size"],
                c=style["peak_color"],
                zorder=cycle_marker_zorder,
                label="Peak",
            )

        if len(tx):
            ax.scatter(
                tx,
                ty,
                marker=style["trough_marker"],
                s=style["marker_size"],
                c=style["trough_color"],
                zorder=cycle_marker_zorder,
                label="Trough",
            )

        # Axis labels, ranges, ticks mirror Plot Settings for consistency

        ax.set_xlabel(
            str(
                globals().get("selected_columns", {}).get("x", "Elapsed Time (days)")
            ).replace("_", " "),
            fontsize=label_fontsize,
        )

        ax.set_ylabel("Pressure (PSI)", fontsize=label_fontsize)
        title_text = "Pressure vs Time with Detected Cycles"

        ax.set_xlim(self.min_time.get(), self.max_time.get())

        ax.set_ylim(self.min_y.get(), self.max_y.get())

        # Ticks mimic Plot Settings

        if self.auto_time_ticks.get():

            ax.xaxis.set_major_locator(AutoLocator())

            ax.xaxis.set_minor_locator(AutoMinorLocator())

        else:

            ax.xaxis.set_major_locator(MultipleLocator(self.xmaj_tick.get()))

            ax.xaxis.set_minor_locator(MultipleLocator(self.xmin_tick.get()))

        if self.auto_y_ticks.get():

            ax.yaxis.set_major_locator(AutoLocator())

            ax.yaxis.set_minor_locator(AutoMinorLocator())

        else:

            ax.yaxis.set_major_locator(MultipleLocator(self.ymaj_tick.get()))

            ax.yaxis.set_minor_locator(MultipleLocator(self.ymin_tick.get()))

        ax.minorticks_on()

        ax.tick_params(axis="both", which="major", labelsize=tick_labelsize)
        font_family = (settings.get("font_family") or "").strip()
        _enforce_axis_text_style(
            ax,
            font_family=font_family,
            tick_fontsize=tick_labelsize,
            label_fontsize=label_fontsize,
        )

        # Legend 1 (existing summary)

        handles, labels = ax.get_legend_handles_labels()

        handles.append(Line2D([], [], color="none"))

        labels.append(f"Cycles: {len(cycles)}")

        handles.append(mpatches.Patch(color="none"))

        labels.append(f"Total ΔP: {total_drop:.2f} PSI")

        show_threshold_line = (not ignore_min_drop) and auto_detect_used

        if show_threshold_line:
            handles.append(mpatches.Patch(color="none"))
            labels.append(
                f"Min ΔP threshold: {float(self.min_cycle_drop.get()):.2f} PSI"
            )

        cycle_family = (settings.get("font_family") or "").strip()
        cycle_size = 10
        legend_prop = {"size": cycle_size}
        if cycle_family:
            legend_prop["family"] = cycle_family

        leg1 = ax.legend(
            handles,
            labels,
            loc="lower right",
            bbox_to_anchor=(0.98, 0.02),
            bbox_transform=ax.transAxes,
            prop=legend_prop,
            **_legend_shadowbox_kwargs(),
        )
        # Iterate over leg1.get_texts() to apply the per-item logic.
        for text in leg1.get_texts():
            try:
                if cycle_family:
                    text.set_fontfamily(cycle_family)
                text.set_fontsize(cycle_size)
            except Exception:
                continue

        _make_legend_draggable(leg1)

        # Legend 2 (new: moles summary) —  only if requested

        if include_moles_legend:

            # Use per-cycle mean temperature (deg C) from peak to trough, with 25 deg C fallback

            z_all = np.asarray(z, dtype=float) if z is not None else None

            V_L = globals().get("volume", 1.0)

            a_const = globals().get("a_const", 1.39)

            b_const = globals().get("b_const", 0.0391)

            (
                per_cycle_rows,
                total_moles_ideal,
                total_moles_vdw,
                _scipy_available,
                vdw_used,
            ) = _compute_cycle_statistics(
                cycles,
                z_all,
                V_L,
                a_const,
                b_const,
                allow_threads=True,
                force_vdw=True,
            )

            per_cycle_lines = []

            # Iterate over indexed elements from per_cycle_rows, 1 to apply the per-item logic.
            for i, row in enumerate(per_cycle_rows, 1):

                suffix = " (default T)" if row["used_default"] else ""

                vdw_value = row["n_vdw"]
                if math.isfinite(vdw_value):
                    vdw_text = f"VDW={vdw_value:.6f} mol"
                else:
                    vdw_text = "VDW=N/A"

                per_cycle_lines.append(
                    f"Cycle {i}: ΔP={row['deltaP']:.2f} PSI, "
                    f"Mean T={row['T_mean_C']:.2f} °C{suffix}, "
                    f"Ideal={row['n_ideal']:.6f} mol, {vdw_text}"
                )

            # Build "text-only" legend rows via proxy artists

            h2, l2 = [], []

            # Title row (blank handle)

            h2.append(Line2D([], [], color="none"))

            l2.append("Cycle moles (per-cycle mean T)")

            # Cap per-cycle lines to avoid overlong legends

            CAP = 20

            # Iterate over per_cycle_lines[ to apply the per-item logic.
            for s in per_cycle_lines[:CAP]:

                h2.append(mpatches.Patch(color="none"))

                l2.append(s)

            if len(per_cycle_lines) > CAP:

                h2.append(mpatches.Patch(color="none"))

                l2.append(f"(+{len(per_cycle_lines) - CAP} more cycles)")

            h2.append(mpatches.Patch(color="none"))
            if math.isfinite(total_moles_ideal):
                l2.append(f"Total moles (Ideal): {total_moles_ideal:.6f} mol")
            else:
                l2.append("Total moles (Ideal): N/A")

            h2.append(mpatches.Patch(color="none"))
            if vdw_used and math.isfinite(total_moles_vdw):
                l2.append(f"Total moles (VDW): {total_moles_vdw:.6f} mol")
            elif vdw_used:
                l2.append("Total moles (VDW): N/A")
            else:
                l2.append("Total moles (VDW): N/A (SciPy not installed)")

            product_name = globals().get("product_name", DEFAULT_PRODUCT_NAME)

            product_molar_mass = globals().get(
                "product_molar_mass", DEFAULT_PRODUCT_MOLAR_MASS
            )

            product_formula = globals().get("product_formula", DEFAULT_PRODUCT_FORMULA)

            starting_mass = globals().get("starting_mass_g", 0.0)

            gas_molar_mass = globals().get("gas_molar_mass", DEFAULT_GAS_MOLAR_MASS)

            reagent_metrics = compute_reagent_metrics(
                total_moles_ideal,
                total_moles_vdw,
                vdw_available=vdw_used,
                starting_mass_g=starting_mass,
                starting_molar_mass=product_molar_mass,
                product_name=product_name,
                product_formula=product_formula,
                product_output_molar_mass=gas_molar_mass,
            )

            pct_ideal = reagent_metrics.get("completion_percent_ideal", math.nan)
            pct_vdw = reagent_metrics.get("completion_percent_vdw", math.nan)
            vdw_available = reagent_metrics.get("vdw_available", False)

            h2.append(mpatches.Patch(color="none"))
            if math.isfinite(pct_ideal):
                l2.append(f"Reaction completion (Ideal): {pct_ideal:.2f}%")
            else:
                l2.append("Reaction completion (Ideal): N/A")

            h2.append(mpatches.Patch(color="none"))
            if vdw_available and math.isfinite(pct_vdw):
                l2.append(f"Reaction completion (VDW): {pct_vdw:.2f}%")
            elif vdw_available:
                l2.append("Reaction completion (VDW): N/A")
            else:
                l2.append("Reaction completion (VDW): N/A (SciPy not installed)")

            leg2 = ax.legend(
                h2,
                l2,
                loc="upper left",
                bbox_to_anchor=(0.02, 0.98),
                bbox_transform=ax.transAxes,
                prop=(
                    {"size": 8, "family": cycle_family} if cycle_family else {"size": 8}
                ),
                title=None,
                **_legend_shadowbox_kwargs(),
            )
            # Iterate over leg2.get_texts() to apply the per-item logic.
            for text in leg2.get_texts():
                try:
                    if cycle_family:
                        text.set_fontfamily(cycle_family)
                    text.set_fontsize(8)
                except Exception:
                    continue

            # Keep both legends

            ax.add_artist(leg1)

            _make_legend_draggable(leg1)

            _make_legend_draggable(leg2)

        # Suptitle

        _center_titles_to_axes_union(
            fig,
            [ax],
            title_text,
            self.suptitle_text.get(),
            subplottitle_fontsize,
            suptitle_fontsize,
            font_family,
            float(plt.rcParams.get("axes.titlepad", 6.0)),
            0.0,
            suptitle_y=suptitle_yposition,
        )

        return fig

    def _update_fig3_from_current_markers(self):
        """Update fig3 from current markers.
        Used to keep fig3 from current markers in sync with current state."""

        if not getattr(self, "_cycle_tab_added", False):

            self._ensure_cycle_tab(defer_build=False)

        if not self._cycle_ready():

            self._pending_fig3_update = None

            return

        self._pending_fig3_update = {
            "ignore_min_drop": True,
            "include_moles": bool(self.include_moles_legend.get()),
        }

        self._suspend_cycle_fig3_refresh = True

        try:

            self._recompute_cycle_analysis(
                auto_detect=False, ignore_min_drop=True, preserve_view=True
            )

        except Exception as exc:

            self._pending_fig3_update = None

            self._suspend_cycle_fig3_refresh = False

            msg = f"Cycle analysis refresh failed: {exc}"

            print(msg, file=sys.stderr)

            try:

                messagebox.showerror("Cycle Analysis", msg)

            except Exception:

                pass

    def _form_cycles(self, y_all, peaks_idx, troughs_idx, min_drop):
        """Perform form cycles.
        Used to keep the workflow logic localized and testable."""

        cycles = []

        total = 0.0

        ti = 0

        troughs_idx = list(troughs_idx)

        # Iterate over peaks_idx to apply the per-item logic.
        for pk in peaks_idx:

            # find first trough with index > pk

            # Repeat while ti < len(troughs_idx) and troughs_idx[ti] <= pk to advance the looped workflow.
            while ti < len(troughs_idx) and troughs_idx[ti] <= pk:

                ti += 1

            if ti >= len(troughs_idx):

                break

            tr = troughs_idx[ti]

            dP = float(y_all[pk] - y_all[tr])

            if dP >= min_drop:

                cycles.append(
                    {
                        "peak_idx": int(pk),
                        "trough_idx": int(tr),
                        "peak": float(y_all[pk]),
                        "trough": float(y_all[tr]),
                        "delta_P": dP,
                    }
                )

                total += dP

        return cycles, total

    def _markers_for_display(
        self,
        mask,
        cycles,
        *,
        include_manual: bool = True,
        cycle_only: bool = False,
    ):
        """Perform markers for display.
        Used to keep the workflow logic localized and testable."""

        mask_arr = np.asarray(mask, dtype=bool)

        mask_len = mask_arr.size

        def _valid(source):
            """Perform valid.
            Used to keep the workflow logic localized and testable."""

            result = set()

            # Iterate over source to apply the per-item logic.
            for idx in source:

                try:

                    i = int(idx)

                except Exception:

                    continue

                if 0 <= i < mask_len and mask_arr[i]:

                    result.add(i)

            return result

        cycle_peaks = _valid(c.get("peak_idx", -1) for c in cycles)

        cycle_troughs = _valid(c.get("trough_idx", -1) for c in cycles)

        effective_peaks = _valid(self._effective_peaks())

        effective_troughs = _valid(self._effective_troughs())

        manual_peaks = _valid(getattr(self, "_add_peaks", set()))

        manual_troughs = _valid(getattr(self, "_add_troughs", set()))

        if cycle_only:

            peak_idx = set(cycle_peaks)

            trough_idx = set(cycle_troughs)

        else:

            peak_idx = cycle_peaks | effective_peaks

            trough_idx = cycle_troughs | effective_troughs

        if include_manual:

            peak_idx |= manual_peaks

            trough_idx |= manual_troughs

        else:

            peak_idx -= manual_peaks

            trough_idx -= manual_troughs

        return sorted(peak_idx), sorted(trough_idx)

    def _refresh_final_report_cycle_snapshot(self, *, ignore_min_drop: bool = True) -> None:
        """Refresh final report cycle snapshot.
        Used to sync final report cycle snapshot with current settings."""
        if not self._cycle_ready():
            self._final_report_cycle_snapshot = None
            return

        try:
            with self._data_lock:
                x, y1, _ = self._get_xy()
                mask = np.asarray(self._current_mask(), dtype=bool)
        except Exception:
            self._final_report_cycle_snapshot = None
            return

        if x is None or y1 is None:
            self._final_report_cycle_snapshot = None
            return

        try:
            xv = np.asarray(x, dtype=float)
            yv = np.asarray(y1, dtype=float)
        except Exception:
            self._final_report_cycle_snapshot = None
            return

        data_len = int(yv.shape[0])
        mask_arr = np.asarray(mask, dtype=bool)
        mask_len = min(mask_arr.size, data_len)
        if mask_arr.size != mask_len:
            mask_arr = mask_arr[:mask_len]

        if mask_len == 0 or mask_arr.sum() < 3:
            self._final_report_cycle_snapshot = None
            return

        # Closure captures _refresh_final_report_cycle_snapshot local context to keep helper logic scoped and invoked directly within _refresh_final_report_cycle_snapshot.
        def _sanitize_indices(values):
            """Sanitize indices.
            Used to strip or normalize indices before use."""
            safe = set()
            # Iterate over values or [] to apply the per-item logic.
            for idx in values or []:
                try:
                    i = int(idx)
                except Exception:
                    continue
                if 0 <= i < mask_len:
                    safe.add(i)
            return safe

        auto_peaks = _sanitize_indices(getattr(self, "_auto_peaks", set()))
        auto_troughs = _sanitize_indices(getattr(self, "_auto_troughs", set()))
        add_peaks = _sanitize_indices(getattr(self, "_add_peaks", set()))
        add_troughs = _sanitize_indices(getattr(self, "_add_troughs", set()))
        rm_peaks = _sanitize_indices(getattr(self, "_rm_peaks", set()))
        rm_troughs = _sanitize_indices(getattr(self, "_rm_troughs", set()))

        effective_peaks = (auto_peaks | add_peaks) - rm_peaks
        effective_troughs = (auto_troughs | add_troughs) - rm_troughs

        peaks = sorted(
            [i for i in effective_peaks if 0 <= i < mask_len and mask_arr[i]]
        )
        troughs = sorted(
            [i for i in effective_troughs if 0 <= i < mask_len and mask_arr[i]]
        )

        try:
            min_cycle_drop = float(self.min_cycle_drop.get())
        except Exception:
            min_cycle_drop = 0.0

        threshold = -float("inf") if ignore_min_drop else float(min_cycle_drop)

        cycles, total_drop = self._form_cycles(yv, peaks, troughs, threshold)

        cycle_peaks = {int(c.get("peak_idx", -1)) for c in cycles}
        cycle_troughs = {int(c.get("trough_idx", -1)) for c in cycles}

        cycle_peaks = {i for i in cycle_peaks if 0 <= i < mask_len and mask_arr[int(i)]}
        cycle_troughs = {
            i for i in cycle_troughs if 0 <= i < mask_len and mask_arr[int(i)]
        }

        display_peaks = set()
        # Iterate over effective_peaks to apply the per-item logic.
        for idx in effective_peaks:
            try:
                i = int(idx)
            except Exception:
                continue
            if 0 <= i < mask_len and mask_arr[i]:
                display_peaks.add(i)

        display_troughs = set()
        # Iterate over effective_troughs to apply the per-item logic.
        for idx in effective_troughs:
            try:
                i = int(idx)
            except Exception:
                continue
            if 0 <= i < mask_len and mask_arr[i]:
                display_troughs.add(i)

        plot_peaks = np.array(sorted(cycle_peaks | display_peaks), dtype=int)
        plot_troughs = np.array(sorted(cycle_troughs | display_troughs), dtype=int)

        if plot_peaks.size:
            plot_peaks = plot_peaks[(plot_peaks >= 0) & (plot_peaks < mask_len)]

        if plot_troughs.size:
            plot_troughs = plot_troughs[(plot_troughs >= 0) & (plot_troughs < mask_len)]

        mask_indices = np.where(mask_arr)[0]
        mask_bounds = (
            (int(mask_indices[0]), int(mask_indices[-1]))
            if mask_indices.size
            else None
        )

        snapshot = {
            "x": np.asarray(xv, dtype=float),
            "y": np.asarray(yv, dtype=float),
            "mask": mask_arr.copy(),
            "mask_indices": np.asarray(mask_indices, dtype=int),
            "mask_bounds": mask_bounds,
            "cycles": cycles,
            "total_drop": float(total_drop) if math.isfinite(total_drop) else 0.0,
            "peaks": np.asarray(plot_peaks, dtype=int),
            "troughs": np.asarray(plot_troughs, dtype=int),
            "plot_peaks": np.asarray(plot_peaks, dtype=int),
            "plot_troughs": np.asarray(plot_troughs, dtype=int),
            "auto_peaks": sorted(auto_peaks),
            "auto_troughs": sorted(auto_troughs),
            "add_peaks": sorted(add_peaks),
            "add_troughs": sorted(add_troughs),
            "rm_peaks": sorted(rm_peaks),
            "rm_troughs": sorted(rm_troughs),
            "effective_peaks": sorted(effective_peaks),
            "effective_troughs": sorted(effective_troughs),
            "ignore_min_drop": bool(ignore_min_drop),
            "min_cycle_drop": float(min_cycle_drop),
            "auto_detection_used": bool(getattr(self, "_cycle_last_auto_detect", False)),
        }

        self._final_report_cycle_snapshot = snapshot

    def _core_cycle_overlay_state(self) -> Optional[Dict[str, Any]]:
        """Perform core cycle overlay state.
        Used to keep the workflow logic localized and testable."""
        snapshot = getattr(self, "_final_report_cycle_snapshot", None)
        if not snapshot:
            return None
        x_series = globals().get("x")
        y_series = globals().get("y1")
        if x_series is None or y_series is None:
            return None
        try:
            xv = np.asarray(x_series, dtype=float)
            yv = np.asarray(y_series, dtype=float)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        if xv.size == 0 or yv.size == 0:
            return None
        mask_arr = snapshot.get("mask")
        if mask_arr is not None:
            try:
                mask_arr = np.asarray(mask_arr, dtype=bool)
            except Exception:
                mask_arr = None
        data_len = xv.size
        cycles = snapshot.get("cycles") or []
        total_drop = snapshot.get("total_drop", 0.0)
        try:
            total_drop = float(total_drop)
        except Exception:
            total_drop = 0.0

        # Closure captures _core_cycle_overlay_state local context to keep helper logic scoped and invoked directly within _core_cycle_overlay_state.
        def _valid_points(indices: Any) -> Tuple[List[int], List[Tuple[float, float]]]:
            """Perform valid points.
            Used to keep the workflow logic localized and testable."""
            idx_list: List[int] = []
            pts: List[Tuple[float, float]] = []
            if indices is None:
                iterable: Iterable[Any] = ()
            else:
                try:
                    iterable = np.asarray(indices).ravel().tolist()
                except Exception:
                    if isinstance(indices, (list, tuple, set)):
                        iterable = indices
                    else:
                        iterable = (indices,)
            # Iterate over iterable to apply the per-item logic.
            for idx in iterable:
                try:
                    i = int(idx)
                except Exception:
                    continue
                if i < 0 or i >= data_len:
                    continue
                if mask_arr is not None and mask_arr.size == data_len:
                    if not bool(mask_arr[i]):
                        continue
                x_val = float(xv[i]) if math.isfinite(float(xv[i])) else None
                y_val = float(yv[i]) if math.isfinite(float(yv[i])) else None
                if x_val is None or y_val is None:
                    continue
                idx_list.append(i)
                pts.append((x_val, y_val))
            return idx_list, pts

        peaks_idx, peak_points = _valid_points(snapshot.get("peaks"))
        troughs_idx, trough_points = _valid_points(snapshot.get("troughs"))

        if (peaks_idx or troughs_idx) and not cycles:
            if not getattr(self, "_cycle_snapshot_warned", False):
                self._cycle_snapshot_warned = True
                ignore_flag = snapshot.get("ignore_min_drop")
                min_drop = snapshot.get("min_cycle_drop")
                print(
                    "WARN: Cycle snapshot has markers but no cycles "
                    f"(peaks={len(peaks_idx)}, troughs={len(troughs_idx)}, "
                    f"ignore_min_drop={ignore_flag}, min_cycle_drop={min_drop}).",
                    file=sys.stderr,
                )

        payload = getattr(self, "_cycle_last_transfer_payload", None)

        return {
            "peaks_idx": peaks_idx,
            "troughs_idx": troughs_idx,
            "peak_points": peak_points,
            "trough_points": trough_points,
            "cycles": list(cycles),
            "total_drop": total_drop if math.isfinite(total_drop) else 0.0,
            "payload": payload,
            "moles_lines": self._cycle_moles_legend_lines(payload),
        }

    def _cycle_moles_legend_lines(
        self,
        payload: Optional[Dict[str, Any]],
        *,
        data_ctx: Optional[Dict[str, Any]] = None,
    ) -> List[str]:
        """Perform cycle moles legend lines.
        Used to keep the workflow logic localized and testable."""
        if not payload:
            return []

        lines: List[str] = []
        cycle_rows = payload.get("cycle_transfer") or []
        if cycle_rows:
            lines.append("Cycle moles (per-cycle mean T)")
        CAP = 20
        # Iterate over indexed elements from cycle_rows[ to apply the per-item logic.
        for idx, row in enumerate(cycle_rows[:CAP], 1):
            delta_psi = _safe_float(row.get("delta_pressure_psi"), float("nan"))
            mean_temp = _safe_float(row.get("mean_temperature_c"), float("nan"))
            used_default = bool(row.get("used_default_temperature"))
            ideal_moles = _safe_float(row.get("moles_ideal"), float("nan"))
            vdw_moles = _safe_float(row.get("moles_vdw"), float("nan"))
            if math.isfinite(vdw_moles):
                vdw_text = f"VDW={vdw_moles:.6f} mol"
            else:
                vdw_text = "VDW=N/A"
            ideal_text = (
                f"Ideal={ideal_moles:.6f} mol"
                if math.isfinite(ideal_moles)
                else "Ideal=N/A"
            )
            suffix = " (default T)" if used_default else ""
            delta_text = f"{delta_psi:.2f}" if math.isfinite(delta_psi) else "N/A"
            temp_text = f"{mean_temp:.2f}" if math.isfinite(mean_temp) else "N/A"
            lines.append(
                f'Cycle {idx}: ΔP={delta_text} PSI, Mean T={temp_text} AøC{suffix}, {ideal_text}, {vdw_text}'
            )
        if len(cycle_rows) > CAP:
            lines.append(f"(+{len(cycle_rows) - CAP} more cycles)")

        total_moles_ideal = _safe_float(payload.get("total_moles_ideal"), float("nan"))
        total_moles_vdw = _safe_float(payload.get("total_moles_vdw"), float("nan"))
        vdw_available = bool(payload.get("vdw_used"))
        lines.append(
            "Total moles (Ideal): "
            + (
                f"{total_moles_ideal:.6f} mol"
                if math.isfinite(total_moles_ideal)
                else "N/A"
            )
        )
        if vdw_available:
            lines.append(
                "Total moles (VDW): "
                + (
                    f"{total_moles_vdw:.6f} mol"
                    if math.isfinite(total_moles_vdw)
                    else "N/A"
                )
            )
        else:
            lines.append("Total moles (VDW): N/A (SciPy not installed)")

        metrics = payload.get("reagent_summary")
        context = data_ctx or {}
        if not metrics:
            try:
                product_name = context.get(
                    "product_name", globals().get("product_name", DEFAULT_PRODUCT_NAME)
                )
                product_formula = context.get(
                    "product_formula",
                    globals().get("product_formula", DEFAULT_PRODUCT_FORMULA),
                )
                product_molar_mass = context.get(
                    "product_molar_mass",
                    globals().get("product_molar_mass", DEFAULT_PRODUCT_MOLAR_MASS),
                )
                starting_mass = context.get(
                    "starting_mass_g", globals().get("starting_mass_g", 0.0)
                )
                gas_molar_mass = payload.get("gas_molar_mass", DEFAULT_GAS_MOLAR_MASS)
                metrics = compute_reagent_metrics(
                    total_moles_ideal,
                    total_moles_vdw,
                    vdw_available=vdw_available,
                    starting_mass_g=starting_mass,
                    starting_molar_mass=product_molar_mass,
                    product_name=product_name,
                    product_formula=product_formula,
                    product_output_molar_mass=gas_molar_mass,
                )
            except Exception:
                metrics = None

        if metrics:
            pct_ideal = metrics.get("completion_percent_ideal", math.nan)
            pct_vdw = metrics.get("completion_percent_vdw", math.nan)
            vdw_flag = metrics.get("vdw_available", vdw_available)
            lines.append(
                "Reaction completion (Ideal): "
                + (f"{pct_ideal:.2f}%" if math.isfinite(pct_ideal) else "N/A")
            )
            if vdw_flag:
                lines.append(
                    "Reaction completion (VDW): "
                    + (f"{pct_vdw:.2f}%" if math.isfinite(pct_vdw) else "N/A")
                )
            else:
                lines.append("Reaction completion (VDW): N/A (SciPy not installed)")

        return lines

    def _prime_core_cycle_overlay_globals(self) -> None:
        """Perform prime core cycle overlay globals.
        Used to keep the workflow logic localized and testable."""
        globals()["core_cycle_overlay"] = self._core_cycle_overlay_state()

    def _collect_combined_legends(self, fig: Optional[Figure]) -> List[Any]:
        """Collect combined legends.
        Used to gather combined legends into a structured payload."""
        if fig is None:
            return []
        legends: List[Any] = []
        seen = set()
        try:
            from matplotlib.legend import Legend
        except Exception:
            Legend = None

        # Closure captures _collect_combined_legends local context to keep helper logic scoped and invoked directly within _collect_combined_legends.
        def _is_legend(obj: Any) -> bool:
            """Check whether it is legend.
            Used to gate conditional behavior in the workflow."""
            if obj is None:
                return False
            if Legend is not None:
                return isinstance(obj, Legend)
            return obj.__class__.__name__ == "Legend"

        # Closure captures _collect_combined_legends local context to keep helper logic scoped and invoked directly within _collect_combined_legends.
        def _add_legend(obj: Any) -> None:
            """Perform add legend.
            Used to keep the workflow logic localized and testable."""
            if not _is_legend(obj):
                return
            obj_id = id(obj)
            if obj_id in seen:
                return
            seen.add(obj_id)
            legends.append(obj)

        try:
            # Iterate over getattr(fig, "legends", []) or [] to apply the per-item logic.
            for lg in getattr(fig, "legends", []) or []:
                _add_legend(lg)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            # Iterate over getattr(fig, "axes", []) or [] to apply the per-item logic.
            for ax in getattr(fig, "axes", []) or []:
                try:
                    _add_legend(ax.get_legend())
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                try:
                    # Iterate over ax.get_children() to apply the per-item logic.
                    for child in ax.get_children():
                        _add_legend(child)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            # Iterate over fig.get_children() to apply the per-item logic.
            for child in fig.get_children():
                _add_legend(child)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return legends

    def _combined_cycle_reference_axis(self, fig: Optional[Figure]) -> Optional[Axes]:
        """Perform combined cycle reference axis.
        Used to keep the workflow logic localized and testable."""
        if fig is None:
            return None
        ref_axis_key = _normalize_combined_cycle_ref_axis(
            settings.get("combined_cycle_legend_ref_axis")
        )
        return _resolve_combined_cycle_ref_axis(fig, ref_axis_key=ref_axis_key)

    def _legend_texts(self, legend: Any) -> List[str]:
        """Perform legend texts.
        Used to keep the workflow logic localized and testable."""
        try:
            texts = legend.get_texts()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return []
        values: List[str] = []
        # Iterate over texts or [] to apply the per-item logic.
        for text in texts or []:
            try:
                label = text.get_text()
            except Exception:
                continue
            if label:
                values.append(str(label))
        return values

    def _is_combined_cycle_legend(self, legend: Any) -> bool:
        """Determine whether a legend is the combined cycle legend.

        Purpose:
            Provide a single, consistent cycle-legend identification gate.
        Why:
            Combined plots host main and cycle legends; strict separation prevents
            cross-talk across drag and persistence workflows.

        Args:
            legend: Legend-like object to inspect.

        Returns:
            True when the legend is tagged as the combined cycle legend or matches
            cycle overlay markers; False otherwise.

        Side Effects:
            None.

        Exceptions:
            Errors are handled defensively and yield False.
        """
        if legend is None:
            return False
        role = getattr(legend, "_gl260_legend_role", None)
        if isinstance(role, str):
            role_value = role.strip().lower()
            if role_value in {"main", "combined_main"}:
                return False
            if role_value in {"cycle", "combined_cycle"}:
                return True
        if getattr(legend, "_combined_main_legend", False):
            return False
        if getattr(legend, "_combined_cycle_legend", False):
            return True
        if getattr(legend, "_cycle_overlay_legend", False):
            return True
        labels = [text.strip().lower() for text in self._legend_texts(legend) if text]
        if not labels:
            return False
        has_cycles = any("cycles:" in label for label in labels)
        if not has_cycles:
            return False
        has_peak_trough = any(
            label.startswith("peak") or label.startswith("trough") for label in labels
        )
        has_total = any("total" in label and "psi" in label for label in labels)
        return has_peak_trough or has_total

    def _get_combined_cycle_legend(self, fig: Optional[Figure]) -> Optional[Any]:
        """Return the active combined cycle legend for a figure.

        Purpose:
            Resolve the current cycle legend instance tied to a combined plot.
        Why:
            Combined plots rebuild legends across refresh/regenerate, so a fresh
            lookup is needed before applying persisted offsets.

        Args:
            fig: Matplotlib Figure to scan for combined cycle legends.

        Returns:
            The cycle legend artist when available; otherwise None.

        Side Effects:
            None.

        Exceptions:
            Errors are handled defensively and result in None.
        """
        if fig is None:
            return None
        legends = self._collect_combined_legends(fig)
        if not legends:
            return None
        cycle_legends = [
            lg for lg in legends if self._is_combined_cycle_legend(lg) is True
        ]
        if not cycle_legends:
            return None
        # Prefer explicitly tagged cycle legends to avoid misclassification.
        for legend in cycle_legends:
            if getattr(legend, "_combined_cycle_legend", False):
                return legend
        return cycle_legends[0]

    def _debug_dump_cycle_legend(self, fig: Figure, tag: str) -> None:
        """Dump combined cycle legend identity/geometry for debug tracing.

        Purpose:
            Emit detailed legend metadata for combined cycle legend debugging.
        Why:
            Supports diagnosing legend placement and persistence issues.
        Args:
            fig: Figure containing the combined plot.
            tag: Debug tag to identify the call site or phase.
        Returns:
            None.
        Side Effects:
            Writes to the debug logger when plotting.legends is enabled.
        Exceptions:
            Best-effort guards suppress diagnostic failures.
        """
        if fig is None:
            return
        if not self._is_debug_category_enabled("plotting.legends"):
            return
        try:
            fig_id = id(fig)
        except Exception:
            fig_id = None
        try:
            canvas = getattr(fig, "canvas", None)
        except Exception:
            canvas = None
        canvas_id = id(canvas) if canvas is not None else None
        try:
            legends = self._collect_combined_legends(fig)
        except Exception:
            legends = []
        try:
            fig_legend_ids = {
                id(lg) for lg in getattr(fig, "legends", []) if lg is not None
            }
        except Exception:
            fig_legend_ids = set()
        self._dbg(
            "plotting.legends",
            "Legends found tag=%s count=%s",
            tag,
            len(legends),
        )
        # Iterate over legends to apply the per-item logic.
        for lg in legends:
            parent = "unknown"
            if id(lg) in fig_legend_ids:
                parent = "fig"
            else:
                ax = getattr(lg, "axes", None)
                if ax is not None:
                    parent = f"axes:{id(ax)}"
            try:
                labels = self._legend_texts(lg)
            except Exception:
                labels = []
            self._dbg(
                "plotting.legends",
                "Legend candidate tag=%s legend_id=%s parent=%s labels=%s",
                tag,
                id(lg),
                parent,
                labels,
            )
        legend = None
        try:
            legend = self._get_combined_cycle_legend(fig)
        except Exception:
            legend = None
        if legend is None:
            self._dbg(
                "plotting.legends",
                "Cycle legend dump tag=%s fig_id=%s canvas_id=%s legend_id=None parent=None loc=None",
                tag,
                fig_id,
                canvas_id,
            )
            self._dbg(
                "plotting.legends",
                "Cycle legend labels tag=%s labels=%s",
                tag,
                [],
            )
            self._dbg(
                "plotting.legends",
                "Cycle legend geom tag=%s bbox_to_anchor=None bbox_px=None axpos=None renderer=None",
                tag,
            )
            return
        parent = "unknown"
        if id(legend) in fig_legend_ids:
            parent = "fig"
        else:
            ax = getattr(legend, "axes", None)
            if ax is not None:
                parent = f"axes:{id(ax)}"
        try:
            legend_loc = legend.get_loc()
        except Exception:
            legend_loc = getattr(legend, "_loc", None)
        try:
            labels = self._legend_texts(legend)
        except Exception:
            labels = []
        self._dbg(
            "plotting.legends",
            "Cycle legend dump tag=%s fig_id=%s canvas_id=%s legend_id=%s parent=%s loc=%s",
            tag,
            fig_id,
            canvas_id,
            id(legend),
            parent,
            legend_loc,
        )
        self._dbg(
            "plotting.legends",
            "Cycle legend labels tag=%s labels=%s",
            tag,
            labels,
        )
        try:
            bbox_to_anchor = legend.get_bbox_to_anchor()
        except Exception:
            bbox_to_anchor = None
        renderer = None
        if canvas is not None:
            try:
                renderer = canvas.get_renderer()
            except Exception:
                renderer = getattr(canvas, "renderer", None)
        bbox_px = None
        renderer_label = "None"
        if renderer is not None:
            renderer_label = "ok"
            try:
                ext = legend.get_window_extent(renderer=renderer)
                bbox_px = (ext.x0, ext.y0, ext.x1, ext.y1)
            except Exception:
                bbox_px = None
        ax = getattr(legend, "axes", None)
        if ax is None:
            try:
                axes_map = self._resolve_plot_element_axes(fig)
                ax = axes_map.get("primary") or next(iter(axes_map.values()), None)
            except Exception:
                ax = None
        if ax is None:
            try:
                ax = fig.axes[0] if fig.axes else None
            except Exception:
                ax = None
        axpos = None
        if ax is not None:
            try:
                pos = ax.get_position()
                axpos = (pos.x0, pos.y0, pos.width, pos.height)
            except Exception:
                axpos = None
        self._dbg(
            "plotting.legends",
            "Cycle legend geom tag=%s bbox_to_anchor=%s bbox_px=%s axpos=%s renderer=%s",
            tag,
            bbox_to_anchor,
            bbox_px,
            axpos,
            renderer_label,
        )

    def _combined_cycle_legend_capture_enabled(
        self, *, require_drag: bool = False
    ) -> bool:
        """Return whether combined cycle legend capture is enabled.

        Purpose:
            Centralize gating for cycle legend capture in the combined plot.
        Why:
            Capture must honor persist/lock settings so user intent is respected
            across drag, refresh, and regeneration flows.

        Args:
            require_drag: When True, require cycle legend dragging to be enabled.

        Returns:
            True when capture should proceed; False otherwise.

        Side Effects:
            None.

        Exceptions:
            Errors are handled internally to avoid interrupting UI workflows.
        """
        try:
            if not bool(settings.get("combined_cycle_legend_persist_position", True)):
                return False
            if bool(settings.get("combined_cycle_legend_lock_position", False)):
                return False
            if require_drag and not bool(
                settings.get("combined_cycle_legend_enable_drag", True)
            ):
                return False
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return False
        return True

    def _refresh_combined_legend_tracking(self) -> None:
        """Refresh combined legend tracking for active display figures.

        Purpose:
            Rebind combined legend drag tracking after settings changes.
        Why:
            Drag/lock/persist toggles should take effect immediately without
            a full plot regeneration.

        Args:
            None.

        Returns:
            None.

        Side Effects:
            Re-registers legend drag callbacks on displayed combined plots.

        Exceptions:
            Errors are caught to keep the UI responsive.
        """
        tabs = list(getattr(self, "_plot_tabs", []) or [])
        canvases = list(getattr(self, "_canvases", []) or [])
        # Iterate over indexed elements from tabs to apply the per-item logic.
        for idx, tab in enumerate(tabs):
            if getattr(tab, "_plot_key", None) != "fig_combined" and getattr(
                tab, "_plot_id", None
            ) != "fig_combined_triple_axis":
                continue
            canvas = canvases[idx] if idx < len(canvases) else None
            fig = getattr(canvas, "figure", None)
            if fig is None:
                continue
            try:
                self._register_combined_legend_tracking(fig)
            except Exception:
                # Best-effort guard; ignore failures.
                pass

    def _apply_saved_cycle_legend_state_to_display_combined(self) -> None:
        """Apply persisted cycle legend state to the live combined display figure.

        Purpose:
            Deterministically sync persisted cycle legend placement onto the
            currently visible combined display plot.
        Why:
            Export Preview interactions can update persisted legend placement,
            and the display figure must reflect those changes immediately when
            the preview closes.

        Args:
            None.

        Returns:
            None.

        Side Effects:
            Applies saved cycle legend anchor/offset state to the live combined
            display figure, re-registers combined legend tracking callbacks,
            and schedules a canvas redraw.

        Exceptions:
            Errors are caught to avoid interrupting UI workflows.
        """
        combined_frame, combined_canvas = self._find_plot_tab_canvas("fig_combined")
        fig = getattr(combined_canvas, "figure", None)
        if fig is None:
            return
        try:
            self._apply_combined_saved_legend_anchors(fig)
        except Exception:
            # Best-effort guard; ignore failures.
            pass
        try:
            self._register_combined_legend_tracking(
                fig,
                force_draw=False,
                defer_saved_anchor=False,
            )
        except Exception:
            # Best-effort guard; ignore failures.
            pass
        try:
            if isinstance(combined_canvas, FigureCanvasTkAgg):
                combined_canvas.draw_idle()
            elif getattr(fig, "canvas", None) is not None:
                fig.canvas.draw_idle()
        except Exception:
            # Best-effort guard; ignore failures.
            pass

    def _capture_cycle_legend_loc_tuple_axes(
        self,
        fig: Figure | None,
        legend: Any,
        *,
        source: str,
    ) -> bool:
        """Capture the cycle legend lower-left position in reference-axis space.

        Purpose:
            Persist a canonical cycle legend position that is invariant across
            display, preview, and export figure sizes.
        Why:
            Mixed anchor semantics caused drift between display and preview/export.
            Canonicalizing to lower-left axes coordinates removes the translation
            mismatch and enables deterministic bidirectional sync.
        Inputs:
            fig: Matplotlib Figure containing the cycle legend.
            legend: Cycle legend artist to capture.
            source: Capture trigger source (for debug visibility).
        Outputs:
            True when a canonical tuple was captured and persisted; False otherwise.
        Side Effects:
            Updates in-memory cycle legend anchor state and writes
            combined_cycle_legend_* settings keys in loc_tuple mode.
        Exceptions:
            Errors are caught defensively and return False.
        """
        if fig is None or legend is None:
            return False
        ref_axis = self._combined_cycle_reference_axis(fig)
        if ref_axis is None:
            return False
        renderer = None
        canvas = getattr(fig, "canvas", None)
        if canvas is not None:
            try:
                renderer = canvas.get_renderer()
            except Exception:
                renderer = None
            if renderer is None:
                try:
                    canvas.draw()
                    renderer = canvas.get_renderer()
                except Exception:
                    renderer = None
        if renderer is None:
            return False
        try:
            bbox_disp = legend.get_window_extent(renderer=renderer)
        except Exception:
            bbox_disp = None
        if bbox_disp is None:
            return False
        try:
            bbox_axes = bbox_disp.transformed(ref_axis.transAxes.inverted())
        except Exception:
            bbox_axes = None
        if bbox_axes is None:
            return False
        try:
            raw_x_ll = float(bbox_axes.x0)
            raw_y_ll = float(bbox_axes.y0)
            width_axes = float(max(0.0, bbox_axes.width))
            height_axes = float(max(0.0, bbox_axes.height))
        except Exception:
            return False
        if not (
            math.isfinite(raw_x_ll)
            and math.isfinite(raw_y_ll)
            and math.isfinite(width_axes)
            and math.isfinite(height_axes)
        ):
            return False
        clamp_enabled = bool(settings.get("combined_cycle_legend_clamp_to_axes", True))
        x_ll = raw_x_ll
        y_ll = raw_y_ll
        if clamp_enabled:
            max_x = max(0.0, 1.0 - width_axes)
            max_y = max(0.0, 1.0 - height_axes)
            x_ll = max(0.0, min(max_x, raw_x_ll))
            y_ll = max(0.0, min(max_y, raw_y_ll))
        else:
            x_ll = max(-0.1, min(1.1, raw_x_ll))
            y_ll = max(-0.1, min(1.1, raw_y_ll))
        loc_tuple = (float(x_ll), float(y_ll))
        self._combined_cycle_legend_anchor = loc_tuple
        settings["combined_cycle_legend_anchor"] = [loc_tuple[0], loc_tuple[1]]
        self._combined_cycle_legend_loc = loc_tuple
        settings["combined_cycle_legend_loc"] = [loc_tuple[0], loc_tuple[1]]
        self._combined_cycle_legend_anchor_space = "axes"
        settings["combined_cycle_legend_anchor_space"] = "axes"
        settings["combined_cycle_legend_anchor_mode"] = "loc_tuple"
        settings.pop("combined_cycle_legend_ref_dx_px", None)
        settings.pop("combined_cycle_legend_ref_dy_px", None)
        settings["combined_cycle_legend_persist_position"] = True
        clamp_dx = loc_tuple[0] - raw_x_ll
        clamp_dy = loc_tuple[1] - raw_y_ll
        ref_axis_role = getattr(ref_axis, "_gl260_axis_role", None)
        fig_size = None
        fig_dpi = None
        try:
            size = fig.get_size_inches()
            fig_size = (float(size[0]), float(size[1]))
        except Exception:
            fig_size = None
        try:
            fig_dpi = float(fig.dpi)
        except Exception:
            fig_dpi = None
        self._dbg(
            "plotting.legends",
            "Cycle legend canonical capture source=%s mode=%s ref_axis=%s "
            "anchor_space=%s loc_tuple=%s clamp_delta=(%s,%s) fig_size=%s dpi=%s",
            source,
            "loc_tuple",
            ref_axis_role,
            "axes",
            loc_tuple,
            clamp_dx,
            clamp_dy,
            fig_size,
            fig_dpi,
        )
        return True

    def _apply_cycle_legend_loc_tuple_axes(
        self,
        fig: Figure | None,
        legend: Any,
        *,
        allow_draw: bool = True,
        clamp: bool | None = None,
    ) -> bool:
        """Apply persisted cycle legend tuple in reference-axis coordinates.

        Purpose:
            Reapply canonical cycle legend placement consistently across renders.
        Why:
            A single apply path for loc_tuple mode prevents coordinate-space drift
            between display, preview, and export workflows.
        Inputs:
            fig: Matplotlib Figure containing the cycle legend.
            legend: Cycle legend artist to position.
            allow_draw: When True, permits draw calls to obtain a renderer.
            clamp: Optional clamp override; when None uses settings toggle.
        Outputs:
            True when placement is applied; False otherwise.
        Side Effects:
            Mutates legend bbox transform/location and normalizes in-memory
            cycle legend state/keys to axes-space loc_tuple semantics.
        Exceptions:
            Errors are caught defensively and return False.
        """
        if fig is None or legend is None:
            return False
        normalized_loc = _normalize_legend_loc_value(
            settings.get("combined_cycle_legend_loc")
        )
        if not (
            isinstance(normalized_loc, tuple)
            and len(normalized_loc) == 2
            and all(math.isfinite(float(v)) for v in normalized_loc)
        ):
            return False
        ref_axis = self._combined_cycle_reference_axis(fig)
        if ref_axis is None:
            return False
        if clamp is None:
            clamp_enabled = bool(settings.get("combined_cycle_legend_clamp_to_axes", True))
        else:
            clamp_enabled = bool(clamp)
        x_ll = float(normalized_loc[0])
        y_ll = float(normalized_loc[1])
        try:
            legend.set_bbox_to_anchor((0.0, 0.0, 1.0, 1.0), transform=ref_axis.transAxes)
            legend.set_loc((x_ll, y_ll))
        except Exception:
            return False
        renderer = None
        canvas = getattr(fig, "canvas", None)
        if canvas is not None:
            try:
                renderer = canvas.get_renderer()
            except Exception:
                renderer = None
            if renderer is None and allow_draw:
                try:
                    canvas.draw()
                    renderer = canvas.get_renderer()
                except Exception:
                    renderer = None
        clamp_dx = 0.0
        clamp_dy = 0.0
        if clamp_enabled and renderer is not None:
            try:
                bbox_disp = legend.get_window_extent(renderer=renderer)
                bbox_axes = bbox_disp.transformed(ref_axis.transAxes.inverted())
                width_axes = float(max(0.0, bbox_axes.width))
                height_axes = float(max(0.0, bbox_axes.height))
                max_x = max(0.0, 1.0 - width_axes)
                max_y = max(0.0, 1.0 - height_axes)
                clamped_x = max(0.0, min(max_x, x_ll))
                clamped_y = max(0.0, min(max_y, y_ll))
                clamp_dx = clamped_x - x_ll
                clamp_dy = clamped_y - y_ll
                if abs(clamp_dx) > 1e-12 or abs(clamp_dy) > 1e-12:
                    legend.set_loc((clamped_x, clamped_y))
                    x_ll, y_ll = clamped_x, clamped_y
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting workflows.
                pass
        loc_tuple = (float(x_ll), float(y_ll))
        self._combined_cycle_legend_anchor = loc_tuple
        settings["combined_cycle_legend_anchor"] = [loc_tuple[0], loc_tuple[1]]
        self._combined_cycle_legend_loc = loc_tuple
        settings["combined_cycle_legend_loc"] = [loc_tuple[0], loc_tuple[1]]
        self._combined_cycle_legend_anchor_space = "axes"
        settings["combined_cycle_legend_anchor_space"] = "axes"
        settings["combined_cycle_legend_anchor_mode"] = "loc_tuple"
        settings.pop("combined_cycle_legend_ref_dx_px", None)
        settings.pop("combined_cycle_legend_ref_dy_px", None)
        ref_axis_role = getattr(ref_axis, "_gl260_axis_role", None)
        fig_size = None
        fig_dpi = None
        try:
            size = fig.get_size_inches()
            fig_size = (float(size[0]), float(size[1]))
        except Exception:
            fig_size = None
        try:
            fig_dpi = float(fig.dpi)
        except Exception:
            fig_dpi = None
        self._dbg(
            "plotting.legends",
            "Cycle legend canonical apply mode=%s ref_axis=%s anchor_space=%s "
            "loc_tuple=%s clamp_delta=(%s,%s) fig_size=%s dpi=%s",
            "loc_tuple",
            ref_axis_role,
            "axes",
            loc_tuple,
            clamp_dx,
            clamp_dy,
            fig_size,
            fig_dpi,
        )
        return True

    def _apply_combined_saved_legend_anchors(
        self, fig: Figure | None
    ) -> None:
        """Apply saved combined legend anchors before display draw.

        Purpose:
            Apply persisted cycle legend anchors prior to the first visible draw.
        Why:
            Combined legend anchors must be applied before rendering to avoid
            a transient incorrect legend placement.
        Inputs:
            fig: Matplotlib Figure containing the combined plot legends.
        Outputs:
            None.
        Side Effects:
            Updates the combined cycle legend position, clears pending anchor
            application state, and marks anchors as applied.
        Exceptions:
            Errors are caught defensively to keep UI workflows responsive.
        """
        if fig is None:
            return
        cycle_legend = self._get_combined_cycle_legend(fig)
        if cycle_legend is None:
            return
        applied = False
        try:
            applied = self._apply_cycle_legend_loc_tuple_axes(
                fig,
                cycle_legend,
                allow_draw=False,
                clamp=True,
            )
        except Exception:
            applied = False
        if not applied:
            offsets = _combined_cycle_axis_offset_values()
            if offsets is not None:
                ref_axis = self._combined_cycle_reference_axis(fig)
                if ref_axis is not None:
                    loc_value = _resolve_combined_cycle_legend_loc()
                    original_canvas = getattr(fig, "canvas", None)
                    try:
                        FigureCanvasAgg(fig).draw()
                    except Exception:
                        # Best-effort guard; ignore failures.
                        pass
                    try:
                        applied = _apply_cycle_legend_axis_offset(
                            fig,
                            cycle_legend,
                            ref_axis,
                            settings.get("combined_cycle_legend_ref_corner"),
                            offsets[0],
                            offsets[1],
                            loc_value,
                            allow_draw=False,
                        )
                    finally:
                        if (
                            original_canvas is not None
                            and getattr(original_canvas, "figure", None) is fig
                        ):
                            try:
                                fig.set_canvas(original_canvas)
                            except Exception:
                                # Best-effort guard; ignore failures.
                                pass
                    if applied:
                        try:
                            migrated = self._capture_cycle_legend_loc_tuple_axes(
                                fig,
                                cycle_legend,
                                source="sync",
                            )
                            if migrated:
                                _save_settings_to_disk()
                        except Exception:
                            # Best-effort guard; ignore failures.
                            pass
        if applied:
            try:
                fig._cycle_legend_anchor_applied = True  # type: ignore[attr-defined]
            except Exception:
                # Best-effort guard; ignore failures.
                pass
            self._combined_cycle_legend_pending_apply = False
            self._combined_cycle_legend_pending_fig_id = None
            self._combined_cycle_legend_pending_offsets = None

    def _sync_combined_cycle_legend_controls(
        self, *, refresh_display: bool = True
    ) -> None:
        """Sync combined cycle legend controls to settings and runtime.

        Purpose:
            Persist cycle legend control toggles and apply them immediately.
        Why:
            Users expect drag/lock/persist changes to affect the live combined
            plot without manual refresh.

        Args:
            refresh_display: When True, re-register legend tracking on live plots.

        Returns:
            None.

        Side Effects:
            Updates settings keys, schedules a settings save, and optionally
            refreshes legend tracking.

        Exceptions:
            Errors are caught to avoid interrupting the UI.
        """
        try:
            settings["combined_cycle_legend_enable_drag"] = bool(
                self.combined_cycle_legend_enable_drag.get()
            )
            settings["combined_cycle_legend_lock_position"] = bool(
                self.combined_cycle_legend_lock_position.get()
            )
            settings["combined_cycle_legend_persist_position"] = bool(
                self.combined_cycle_legend_persist_position.get()
            )
            settings["combined_cycle_legend_clamp_to_axes"] = bool(
                self.combined_cycle_legend_clamp_to_axes.get()
            )
            settings["combined_main_legend_enable_drag"] = bool(
                self.combined_main_legend_enable_drag.get()
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        try:
            self._schedule_save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if refresh_display:
            self._refresh_combined_legend_tracking()

    def _reset_combined_cycle_legend_position(self) -> None:
        """Reset combined cycle legend placement to defaults.

        Purpose:
            Clear persisted cycle legend offsets/anchors for the combined plot.
        Why:
            Provides a user-facing reset so the legend can return to default
            placement after manual drags.

        Args:
            None.

        Returns:
            None.

        Side Effects:
            Clears cycle legend placement settings, resets in-memory anchors,
            and refreshes the combined plot if it is displayed.

        Exceptions:
            Errors are caught to avoid interrupting the UI.
        """
        settings.pop("combined_cycle_legend_anchor", None)
        settings.pop("combined_cycle_legend_loc", None)
        settings.pop("combined_cycle_legend_anchor_space", None)
        settings.pop("combined_cycle_legend_ref_dx_px", None)
        settings.pop("combined_cycle_legend_ref_dy_px", None)
        settings["combined_cycle_legend_anchor_mode"] = "legacy_anchor"
        self._combined_cycle_legend_anchor = None
        self._combined_cycle_legend_loc = None
        self._combined_cycle_legend_anchor_space = None
        try:
            self._schedule_save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        tabs = list(getattr(self, "_plot_tabs", []) or [])
        canvases = list(getattr(self, "_canvases", []) or [])
        # Iterate over indexed elements from tabs to apply the per-item logic.
        for idx, tab in enumerate(tabs):
            if getattr(tab, "_plot_key", None) != "fig_combined" and getattr(
                tab, "_plot_id", None
            ) != "fig_combined_triple_axis":
                continue
            canvas = canvases[idx] if idx < len(canvases) else None
            try:
                # Skip pre-refresh capture so the reset is not overwritten.
                self._force_plot_refresh(tab, canvas, capture_combined_legend=False)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            break

    # CRITICAL: This function MUST exist exactly once.
    # Do NOT duplicate or redefine below — this WILL break legend persistence.
    def _capture_combined_legend_anchor_from_fig(
        self, fig: Figure | None, *, source: str = "auto"
    ) -> None:
        """Capture combined cycle legend anchors from a figure.

        Purpose:
            Capture cycle legend placement so refresh/regenerate preserves the
            user-selected position.
        Why:
            Combined legends are rebuilt on each refresh, so explicit capture
            is required to persist cycle legend offsets without affecting the
            main legend.

        Args:
            fig: Matplotlib Figure containing combined legends to inspect.
            source: "auto" for passive capture, "drag" for mouse-up capture,
                "sync" for explicit display/preview synchronization, or
                "refresh" for pre-rebuild capture.

        Returns:
            None.

        Side Effects:
            Updates self._combined_cycle_* anchor fields, writes settings keys,
            and persists settings to disk when capture is permitted.

        Exceptions:
            Errors are caught internally to avoid interrupting UI rendering.
        """
        if fig is None:
            return
        explicit_capture_source = source in {"drag", "sync"}
        if not explicit_capture_source:
            try:
                if settings.get("combined_cycle_legend_anchor_mode") == "loc_tuple":
                    existing_loc = _normalize_legend_loc_value(
                        settings.get("combined_cycle_legend_loc")
                    )
                    if (
                        isinstance(existing_loc, tuple)
                        and len(existing_loc) == 2
                        and all(math.isfinite(float(v)) for v in existing_loc)
                    ):
                        return
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        cycle_capture_enabled = self._combined_cycle_legend_capture_enabled()
        cycle_drag_capture_enabled = self._combined_cycle_legend_capture_enabled(
            require_drag=True
        )
        clamp_cycle_axes = bool(
            settings.get("combined_cycle_legend_clamp_to_axes", True)
        )
        legends = self._collect_combined_legends(fig)
        if not legends:
            return
        updated = False
        cycle_legends: list[Any] = []
        # Iterate over legends to apply the per-item filtering logic.
        for lg in legends:
            if getattr(lg, "_combined_main_legend", False):
                # Main legends never participate in cycle anchor capture.
                continue
            if getattr(lg, "_combined_cycle_legend", False) is True:
                cycle_legends.append(lg)
        if not cycle_legends:
            return
        fig_legend_ids = set()
        try:
            fig_legend_ids = {
                id(lg) for lg in getattr(fig, "legends", []) if lg is not None
            }
        except Exception:
            fig_legend_ids = set()
        ref_axis_key = _normalize_combined_cycle_ref_axis(
            settings.get("combined_cycle_legend_ref_axis")
        )
        ref_corner_key = _normalize_combined_cycle_ref_corner(
            settings.get("combined_cycle_legend_ref_corner")
        )
        settings["combined_cycle_legend_ref_axis"] = ref_axis_key
        settings["combined_cycle_legend_ref_corner"] = ref_corner_key
        cycle_ref_axis = self._combined_cycle_reference_axis(fig)
        stored_offsets = _combined_cycle_axis_offset_values()
        if source == "auto" and stored_offsets is not None:
            # Reapply persisted offsets and skip auto-capture to avoid overwrites.
            loc_value = _resolve_combined_cycle_legend_loc()
            # Iterate over cycle legends to apply the per-item logic.
            for lg in cycle_legends:
                try:
                    _apply_cycle_legend_axis_offset(
                        fig,
                        lg,
                        cycle_ref_axis,
                        ref_corner_key,
                        stored_offsets[0],
                        stored_offsets[1],
                        loc_value,
                        allow_draw=False,
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
            return
        renderer = None
        try:
            canvas = fig.canvas
            if canvas is not None:
                try:
                    renderer = canvas.get_renderer()
                except Exception:
                    renderer = None
                if renderer is None:
                    try:
                        canvas.draw_idle()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting
                        # the workflow.
                        pass
                    try:
                        canvas.draw()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting
                        # the workflow.
                        pass
                    try:
                        renderer = canvas.get_renderer()
                    except Exception:
                        renderer = None
        except Exception:
            renderer = None

        # Closure captures _capture_combined_legend_anchor_from_fig context to keep
        # helper logic scoped and invoked directly within the capture routine.
        def _clamp_axes_anchor(anchor: Any) -> tuple[float, float] | None:
            """Clamp axes anchor.
            Used to keep axes anchor within safe bounds."""
            try:
                x_val = float(anchor[0])
                y_val = float(anchor[1])
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting
                # the workflow.
                return None
            if not (math.isfinite(x_val) and math.isfinite(y_val)):
                return None
            if clamp_cycle_axes:
                # Clamp within axes bounds when the user enables clamp capture.
                x_val = max(0.0, min(1.0, x_val))
                y_val = max(0.0, min(1.0, y_val))
            else:
                x_val = max(-0.1, min(1.1, x_val))
                y_val = max(-0.1, min(1.1, y_val))
            return (x_val, y_val)

        # Closure captures _capture_combined_legend_anchor_from_fig context to keep
        # helper logic scoped and invoked directly within the capture routine.
        def _legend_anchor_axes_fraction(
            lg,
        ) -> tuple[tuple[float, float] | None, str | None]:
            """Perform legend anchor axes fraction.
            Used to keep the workflow logic localized and testable."""
            is_fig_legend = id(lg) in fig_legend_ids
            is_combined_cycle = self._is_combined_cycle_legend(lg)

            # Closure captures _legend_anchor_axes_fraction context to keep helper logic
            # scoped and invoked directly within _legend_anchor_axes_fraction.
            def _legend_loc_text(legend_obj) -> str:
                """Perform legend loc text.
                Used to keep the workflow logic localized and testable."""
                loc_map = {
                    0: "best",
                    1: "upper right",
                    2: "upper left",
                    3: "lower left",
                    4: "lower right",
                    5: "right",
                    6: "center left",
                    7: "center right",
                    8: "lower center",
                    9: "upper center",
                    10: "center",
                }
                try:
                    loc_value = legend_obj.get_loc()
                except Exception:
                    loc_value = getattr(legend_obj, "_loc", "upper right")
                if isinstance(loc_value, str):
                    loc_text = loc_value.strip().lower()
                elif isinstance(loc_value, int):
                    loc_text = loc_map.get(loc_value, "upper right")
                else:
                    loc_text = "upper right"
                if loc_text == "best":
                    loc_text = "upper right"
                return loc_text

            # Closure captures _legend_anchor_axes_fraction context to keep helper logic
            # scoped and invoked directly within _legend_anchor_axes_fraction.
            def _anchor_from_bbox(bbox: Bbox, loc_text: str) -> tuple[float, float]:
                """Perform anchor from bbox.
                Used to keep the workflow logic localized and testable."""
                x0, y0, x1, y1 = bbox.x0, bbox.y0, bbox.x1, bbox.y1
                cx = x0 + ((x1 - x0) / 2.0)
                cy = y0 + ((y1 - y0) / 2.0)
                loc_text = (loc_text or "upper right").lower()
                if loc_text in {"upper left", "ul"}:
                    return (x0, y1)
                if loc_text in {"upper center", "uc"}:
                    return (cx, y1)
                if loc_text in {"upper right", "ur"}:
                    return (x1, y1)
                if loc_text in {"lower left", "ll"}:
                    return (x0, y0)
                if loc_text in {"lower center", "lc"}:
                    return (cx, y0)
                if loc_text in {"lower right", "lr"}:
                    return (x1, y0)
                if loc_text in {"center left", "cl", "left"}:
                    return (x0, cy)
                if loc_text in {"center right", "cr", "right"}:
                    return (x1, cy)
                return (cx, cy)

            renderer = None
            try:
                canvas = fig.canvas
                if canvas is not None:
                    try:
                        canvas.draw_idle()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting
                        # the workflow.
                        pass
                    try:
                        canvas.draw()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting
                        # the workflow.
                        pass
                    try:
                        renderer = canvas.get_renderer()
                    except Exception:
                        renderer = None
            except Exception:
                renderer = None

            if is_combined_cycle and cycle_ref_axis is not None:
                try:
                    bbox_disp = lg.get_window_extent(renderer=renderer)
                except Exception:
                    bbox_disp = None
                if bbox_disp is not None:
                    try:
                        bbox_axes = bbox_disp.transformed(
                            cycle_ref_axis.transAxes.inverted()
                        )
                    except Exception:
                        bbox_axes = None
                    if bbox_axes is not None:
                        anchor_pair = _clamp_axes_anchor(
                            _anchor_from_bbox(bbox_axes, _legend_loc_text(lg))
                        )
                        if anchor_pair is not None:
                            return anchor_pair, "axes"

            if is_fig_legend:
                try:
                    bbox_disp = lg.get_window_extent(renderer=renderer)
                except Exception:
                    bbox_disp = None
                if bbox_disp is not None:
                    try:
                        bbox_fig = bbox_disp.transformed(fig.transFigure.inverted())
                    except Exception:
                        bbox_fig = None
                    if bbox_fig is not None:
                        anchor_pair = _validated_anchor_pair(
                            _anchor_from_bbox(bbox_fig, _legend_loc_text(lg))
                        )
                        if anchor_pair is not None:
                            return anchor_pair, "figure"

            bbox = None
            try:
                bbox = lg.get_bbox_to_anchor()
            except Exception:
                bbox = None
            if bbox is not None:
                transform = None
                anchor_space = None
                if is_fig_legend:
                    try:
                        transform = fig.transFigure
                        anchor_space = "figure"
                    except Exception:
                        transform = None
                if transform is None:
                    ax = getattr(lg, "axes", None)
                    if ax is not None:
                        transform = ax.transAxes
                        anchor_space = "axes"
                if transform is not None:
                    try:
                        anchor_bbox = bbox.transformed(transform.inverted())
                        anchor_pair = _validated_anchor_pair(
                            _anchor_from_bbox(anchor_bbox, _legend_loc_text(lg))
                        )
                        if anchor_pair is not None:
                            return anchor_pair, anchor_space
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting
                        # the workflow.
                        pass

            ax = getattr(lg, "axes", None)
            if ax is None and fig is None:
                return None, None
            if renderer is None:
                try:
                    canvas = lg.figure.canvas
                    if canvas is not None:
                        try:
                            canvas.draw_idle()
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting
                            # the workflow.
                            pass
                        renderer = canvas.get_renderer()
                except Exception:
                    renderer = None
            try:
                bbox = lg.get_window_extent(renderer=renderer)
            except Exception:
                bbox = None
            if bbox is None:
                return None, None
            try:
                if ax is not None:
                    bbox_axes = bbox.transformed(ax.transAxes.inverted())
                    anchor_pair = _validated_anchor_pair(
                        _anchor_from_bbox(bbox_axes, _legend_loc_text(lg))
                    )
                    if anchor_pair is not None:
                        return anchor_pair, "axes"
                bbox_fig = bbox.transformed(fig.transFigure.inverted())
                anchor_pair = _validated_anchor_pair(
                    _anchor_from_bbox(bbox_fig, _legend_loc_text(lg))
                )
                if anchor_pair is not None:
                    return anchor_pair, "figure"
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting
                # the workflow.
                return None, None
            return None, None

        # Iterate over cycle legends to apply the per-item logic.
        for lg in cycle_legends:
            try:
                if explicit_capture_source:
                    # Explicit sync/drag capture uses canonical lower-left axes tuple
                    # semantics and bypasses legacy anchor/loc translation logic.
                    if not (
                        cycle_capture_enabled
                        and (source != "drag" or cycle_drag_capture_enabled)
                    ):
                        continue
                    if self._capture_cycle_legend_loc_tuple_axes(
                        fig,
                        lg,
                        source=source,
                    ):
                        updated = True
                    continue
                anchor_loc, anchor_space = _legend_anchor_axes_fraction(lg)
                if anchor_loc is None:
                    anchor_loc = _validated_anchor_pair(getattr(lg, "_loc", ()))
                    if anchor_loc is not None and anchor_space is None:
                        if id(lg) in fig_legend_ids:
                            anchor_space = "figure"
                        elif getattr(lg, "axes", None) is not None:
                            anchor_space = "axes"
                loc_value = None
                try:
                    loc_value = lg.get_loc()
                except Exception:
                    loc_value = getattr(lg, "_loc", None)
                loc_is_tuple = isinstance(loc_value, tuple) and len(loc_value) == 2
                loc_tuple = None
                if loc_is_tuple:
                    try:
                        loc_tuple = (float(loc_value[0]), float(loc_value[1]))
                    except Exception:
                        loc_tuple = None
                normalized_loc = (
                    _normalize_legend_loc_value(loc_value) or "lower left"
                    if anchor_loc is not None
                    else None
                )
                if (
                    anchor_loc is not None
                    and cycle_capture_enabled
                    and (source != "drag" or cycle_drag_capture_enabled)
                ):
                    if explicit_capture_source and self._is_debug_category_enabled(
                        "plotting.legends"
                    ):
                        try:
                            fig_id = id(fig)
                        except Exception:
                            fig_id = None
                        try:
                            canvas = getattr(fig, "canvas", None)
                        except Exception:
                            canvas = None
                        canvas_id = id(canvas) if canvas is not None else None
                        try:
                            legend_id = id(lg)
                        except Exception:
                            legend_id = None
                        bbox_anchor_obj = None
                        try:
                            bbox_anchor_obj = lg.get_bbox_to_anchor()
                        except Exception:
                            bbox_anchor_obj = None
                        bbox_anchor_type = (
                            type(bbox_anchor_obj).__name__
                            if bbox_anchor_obj is not None
                            else None
                        )
                        bbox_bounds = None
                        if bbox_anchor_obj is not None:
                            try:
                                bbox_bounds = bbox_anchor_obj.bounds
                            except Exception:
                                bbox_bounds = None
                        try:
                            bbox_repr = repr(bbox_anchor_obj)
                        except Exception:
                            bbox_repr = None
                        self._dbg(
                            "plotting.legends",
                            "Capture pre fig_id=%s canvas_id=%s legend_id=%s "
                            "loc=%s loc_is_tuple=%s bbox_anchor_obj=%s "
                            "bbox_anchor_type=%s bbox_bounds=%s bbox_repr=%s",
                            fig_id,
                            canvas_id,
                            legend_id,
                            loc_value,
                            loc_is_tuple,
                            bbox_anchor_obj,
                            bbox_anchor_type,
                            bbox_bounds,
                            bbox_repr,
                        )
                    if explicit_capture_source and loc_tuple is not None:
                        persist_value = bool(
                            settings.get(
                                "combined_cycle_legend_persist_position", True
                            )
                        )
                        # Keep loc tuples in their native space so axes anchors stay
                        # locked to the plot area across refresh and DPI changes.
                        loc_tuple_to_store = loc_tuple
                        anchor_space_to_store = "figure"
                        if (
                            anchor_space == "axes"
                            and anchor_loc is not None
                            and cycle_ref_axis is not None
                        ):
                            loc_tuple_to_store = (
                                float(anchor_loc[0]),
                                float(anchor_loc[1]),
                            )
                            anchor_space_to_store = "axes"
                        self._dbg(
                            "plotting.legends",
                            "Capture persist write persist=%s mode=loc_tuple loc=%s space=%s",
                            persist_value,
                            loc_tuple_to_store,
                            anchor_space_to_store,
                        )
                    # Capture cycle legend placement only when persistence is allowed.
                    self._combined_cycle_legend_anchor = anchor_loc
                    settings["combined_cycle_legend_anchor"] = [
                        anchor_loc[0],
                        anchor_loc[1],
                    ]
                    if loc_tuple is not None and explicit_capture_source:
                        # Persist drag anchors in axes space when the cycle legend
                        # is axes-anchored; preserve figure-space for legacy anchors.
                        loc_tuple_to_store = loc_tuple
                        anchor_space_to_store = "figure"
                        if (
                            anchor_space == "axes"
                            and anchor_loc is not None
                            and cycle_ref_axis is not None
                        ):
                            loc_tuple_to_store = (
                                float(anchor_loc[0]),
                                float(anchor_loc[1]),
                            )
                            anchor_space_to_store = "axes"
                        self._combined_cycle_legend_anchor_space = anchor_space_to_store
                        settings[
                            "combined_cycle_legend_anchor_space"
                        ] = anchor_space_to_store
                        self._combined_cycle_legend_loc = loc_tuple_to_store
                        settings["combined_cycle_legend_loc"] = loc_tuple_to_store
                        settings["combined_cycle_legend_anchor_mode"] = "loc_tuple"
                        settings.pop("combined_cycle_legend_ref_dx_px", None)
                        settings.pop("combined_cycle_legend_ref_dy_px", None)
                        settings["combined_cycle_legend_persist_position"] = True
                        self._dbg(
                            "plotting.legends",
                            "Capture explicit source=%s write_type=tuple mode=%s "
                            "anchor_space=%s loc=%s dx=%s dy=%s",
                            source,
                            "loc_tuple",
                            anchor_space_to_store,
                            loc_tuple_to_store,
                            None,
                            None,
                        )
                        updated = True
                        continue
                    if anchor_space in {"figure", "axes"}:
                        self._combined_cycle_legend_anchor_space = anchor_space
                        settings["combined_cycle_legend_anchor_space"] = anchor_space
                    elif cycle_ref_axis is not None:
                        self._combined_cycle_legend_anchor_space = "axes"
                        settings["combined_cycle_legend_anchor_space"] = "axes"
                    else:
                        self._combined_cycle_legend_anchor_space = None
                        settings.pop("combined_cycle_legend_anchor_space", None)
                    self._combined_cycle_legend_loc = normalized_loc
                    if normalized_loc is not None:
                        settings["combined_cycle_legend_loc"] = normalized_loc
                    else:
                        settings.pop("combined_cycle_legend_loc", None)
                    offsets = _compute_cycle_legend_offsets_px(
                        lg, cycle_ref_axis, ref_corner_key, loc_value, renderer
                    )
                    if (
                        offsets is not None
                        and clamp_cycle_axes
                        and cycle_ref_axis is not None
                        and renderer is not None
                    ):
                        # Clamp offsets by constraining the captured anchor to axes
                        # bounds.
                        ref_point = _axis_anchor_point_display(
                            cycle_ref_axis, ref_corner_key, renderer
                        )
                        if ref_point is not None:
                            target_display = (
                                ref_point[0] + offsets[0],
                                ref_point[1] + offsets[1],
                            )
                            try:
                                target_axes = (
                                    cycle_ref_axis.transAxes.inverted().transform(
                                        target_display
                                    )
                                )
                            except Exception:
                                target_axes = None
                            clamped_axes = (
                                _clamp_axes_anchor(target_axes)
                                if target_axes is not None
                                else None
                            )
                            if clamped_axes is not None:
                                clamped_display = cycle_ref_axis.transAxes.transform(
                                    clamped_axes
                                )
                                offsets = (
                                    clamped_display[0] - ref_point[0],
                                    clamped_display[1] - ref_point[1],
                                )
                    if offsets is not None:
                        if explicit_capture_source:
                            persist_value = bool(
                                settings.get(
                                    "combined_cycle_legend_persist_position", True
                                )
                            )
                            if loc_is_tuple:
                                self._dbg(
                                    "plotting.legends",
                                    "Capture persist write persist=%s mode=loc_tuple loc=%s",
                                    persist_value,
                                    loc_value,
                                )
                            else:
                                self._dbg(
                                    "plotting.legends",
                                    "Capture persist write persist=%s mode=dxdy dx=%s dy=%s",
                                    persist_value,
                                    offsets[0],
                                    offsets[1],
                                )
                        settings["combined_cycle_legend_ref_dx_px"] = offsets[0]
                        settings["combined_cycle_legend_ref_dy_px"] = offsets[1]
                        settings["combined_cycle_legend_anchor_mode"] = "axis_offset"
                        if source == "drag":
                            # Drag capture implies persistence for the updated offsets.
                            settings["combined_cycle_legend_persist_position"] = True
                            self._dbg(
                                "plotting.legends",
                                "Persist write dx=%s dy=%s persist=True",
                                offsets[0],
                                offsets[1],
                            )
                            try:
                                self._debug_dump_cycle_legend(
                                    fig, "after_drag_persist_write"
                                )
                            except Exception:
                                # Best-effort guard; ignore failures to avoid interrupting
                                # the workflow.
                                pass
                        resolved_space = (
                            self._combined_cycle_legend_anchor_space
                            if self._combined_cycle_legend_anchor_space
                            in {"figure", "axes"}
                            else (
                                "axes"
                                if cycle_ref_axis is not None
                                else "figure"
                            )
                        )
                        self._dbg(
                            "plotting.legends",
                            "Capture explicit source=%s write_type=offset mode=%s "
                            "anchor_space=%s loc=%s dx=%s dy=%s",
                            source,
                            "axis_offset",
                            resolved_space,
                            normalized_loc,
                            offsets[0],
                            offsets[1],
                        )
                        # Debug: confirm capture source and offsets for persistence.
                        self._dbg(
                            "plotting.legends",
                            "Combined cycle legend capture source=%s dx_px=%s dy_px=%s",
                            source,
                            offsets[0],
                            offsets[1],
                        )
                    updated = True
            except Exception:
                continue
        if updated:
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting
                # the workflow.
                pass
            self._combined_layout_dirty = True
            if source == "refresh":
                try:
                    self._debug_dump_cycle_legend(fig, "after_refresh_capture")
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass

    # CRITICAL: This function MUST exist exactly once.
    # Do NOT duplicate or redefine below — this WILL break legend persistence.
    def _register_combined_legend_tracking(
        self,
        fig: Figure | None,
        *,
        force_draw: bool = True,
        defer_saved_anchor: bool = True,
    ) -> None:
        """Register draggable legend tracking for combined plots.

        Purpose:
            Attach drag handlers and capture logic for combined plot legends.
        Why:
            Combined plots rebuild legends frequently, so capture is needed to
            persist cycle legend placement without introducing extra redraws.

        Args:
            fig: Matplotlib Figure with combined legends to monitor.
            force_draw: When True, allow an initial draw to ensure a renderer exists.
            defer_saved_anchor: When True, queue saved anchors for post-draw apply.

        Returns:
            None.

        Side Effects:
            Enables legend dragging, recenters the main legend when centering
            is enabled, wires a canvas callback, and persists cycle anchors via
            _capture_combined_legend_anchor_from_fig. Optionally queues persisted
            cycle offsets for post-draw application when requested.

        Exceptions:
            Internal errors are caught to avoid breaking the UI.
        """
        if fig is None:
            return
        if defer_saved_anchor:
            try:
                fig._cycle_legend_anchor_applied = False
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        else:
            try:
                fig._cycle_legend_anchor_applied = True
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._cycle_leg_drag_active = False
        self._cycle_leg_drag_moved = False
        self._cycle_leg_drag_start_xy = None
        self._cycle_leg_drag_start_loc = None
        self._cycle_leg_pre_click_loc = None
        self._cycle_leg_pre_click_bbox = None
        self._cycle_leg_pre_click_is_tuple = False
        self._cycle_leg_drag_use_loc_tuple = False
        persist = bool(settings.get("combined_cycle_legend_persist_position", True))
        saved_dx = settings.get("combined_cycle_legend_ref_dx_px", None)
        saved_dy = settings.get("combined_cycle_legend_ref_dy_px", None)
        saved_offsets = _combined_cycle_axis_offset_values()
        stored_mode = None
        stored_loc = None
        stored_loc_tuple = None
        try:
            stored_mode = settings.get("combined_cycle_legend_anchor_mode")
            stored_loc = settings.get("combined_cycle_legend_loc")
            normalized_loc = _normalize_legend_loc_value(stored_loc)
            if isinstance(normalized_loc, tuple):
                stored_loc_tuple = normalized_loc
        except Exception:
            stored_mode = None
            stored_loc = None
            stored_loc_tuple = None
        pending_saved_anchor_apply = bool(
            defer_saved_anchor
            and (
                saved_offsets is not None
                or (stored_mode == "loc_tuple" and stored_loc_tuple is not None)
            )
        )
        # Defer cycle legend drag only while a saved loc-tuple anchor is queued
        # for draw-time application; otherwise leave drag enabled.
        defer_cycle_drag_enable = bool(
            pending_saved_anchor_apply and stored_mode == "loc_tuple"
        )
        self._dbg(
            "plotting.legends",
            "Apply saved anchor persist=%s dx=%s dy=%s fig_id=%s",
            persist,
            saved_dx,
            saved_dy,
            id(fig),
        )
        if pending_saved_anchor_apply:
            self._combined_cycle_legend_pending_apply = True
            self._combined_cycle_legend_pending_fig_id = id(fig)
            self._combined_cycle_legend_pending_offsets = saved_offsets
        else:
            self._combined_cycle_legend_pending_apply = False
            self._combined_cycle_legend_pending_fig_id = None
            self._combined_cycle_legend_pending_offsets = None
        try:
            if force_draw and defer_saved_anchor and fig.canvas is not None:
                fig.canvas.draw()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting
            # the workflow.
            pass
        legends = self._collect_combined_legends(fig)
        if not legends:
            return
        main_drag_enabled = bool(
            settings.get("combined_main_legend_enable_drag", False)
        )
        cycle_drag_enabled = bool(
            settings.get("combined_cycle_legend_enable_drag", True)
        )
        cycle_lock_enabled = bool(
            settings.get("combined_cycle_legend_lock_position", False)
        )
        effective_cycle_drag_enabled = bool(
            cycle_drag_enabled
            and not cycle_lock_enabled
            and not defer_cycle_drag_enable
        )
        self._dbg(
            "plotting.legends",
            "Cycle legend drag policy mode=%s defer_saved_anchor=%s "
            "pending_apply=%s drag_enabled=%s lock_enabled=%s "
            "defer_drag_enable=%s effective_drag=%s fig_id=%s",
            stored_mode,
            defer_saved_anchor,
            pending_saved_anchor_apply,
            cycle_drag_enabled,
            cycle_lock_enabled,
            defer_cycle_drag_enable,
            effective_cycle_drag_enabled,
            id(fig),
        )
        fig_expect_cycle = getattr(fig, "_gl260_expect_cycle_legend", None)
        if fig_expect_cycle is None:
            fig_expect_cycle = bool(
                settings.get("show_cycle_legend_on_core_plots", False)
            )
        overlay_present = getattr(fig, "_gl260_cycle_overlay_present", True)
        expect_cycle_legend = bool(fig_expect_cycle) and bool(overlay_present)
        has_cycle_legend = any(
            getattr(lg, "_combined_cycle_legend", False) is True for lg in legends
        )
        if expect_cycle_legend and not has_cycle_legend:
            self._log(
                "plotting.legends",
                logging.WARNING,
                "Combined cycle legend not discovered for draggability; check legend creation/markers.",
            )
        main_legend = None
        # Iterate over legends to apply the per-item logic.
        for lg in legends:
            if getattr(lg, "_combined_main_legend", False):
                main_legend = lg
                try:
                    lg._gl260_legend_role = "main"  # type: ignore[attr-defined]
                    lg._combined_cycle_legend = False  # type: ignore[attr-defined]
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
                if main_drag_enabled:
                    _make_legend_draggable(lg)
                else:
                    _make_legend_draggable(lg, enabled=False)
                continue
            if getattr(lg, "_combined_cycle_legend", False) is True:
                try:
                    lg._gl260_legend_role = "cycle"  # type: ignore[attr-defined]
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
                # Lock overrides drag to prevent accidental cycle legend movement.
                if cycle_drag_enabled and not cycle_lock_enabled:
                    if defer_cycle_drag_enable:
                        _make_legend_draggable(lg, enabled=False)
                    else:
                        _make_legend_draggable(lg)
                else:
                    _make_legend_draggable(lg, enabled=False)
                continue
            _make_legend_draggable(lg)
        if main_legend is not None:
            center_toggle = getattr(self, "center_combined_plot_legend", None)
            if center_toggle is not None:
                try:
                    center_enabled = bool(center_toggle.get())
                except Exception:
                    center_enabled = False
            else:
                center_enabled = bool(settings.get("combined_center_plot_legend"))
            layout_mgr = getattr(fig, "_gl260_layout_manager", None)
            explicit_anchor = getattr(layout_mgr, "legend_anchor", None)
            if center_enabled and explicit_anchor is None:
                axes_map = self._resolve_plot_element_axes(fig)
                primary_axis = axes_map.get("primary")
                main_center_x = fig.subplotpars.left + (
                    (fig.subplotpars.right - fig.subplotpars.left) / 2.0
                )
                if primary_axis is not None:
                    try:
                        pos = primary_axis.get_position()
                        main_center_x = pos.x0 + (pos.width / 2.0)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting
                        # the workflow.
                        pass
                anchor_y = None
                try:
                    bbox = main_legend.get_bbox_to_anchor()
                    if bbox is not None:
                        anchor_y = float(getattr(bbox, "y0", None))
                except Exception:
                    anchor_y = None
                if anchor_y is None:
                    # Preserve the layout-solved vertical anchor when possible.
                    anchor_y = fig.subplotpars.bottom
                try:
                    main_legend.set_loc("lower center")
                    main_legend.set_bbox_to_anchor(
                        (main_center_x, anchor_y), transform=fig.transFigure
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
        try:
            canvas = fig.canvas
        except Exception:
            canvas = None
        if canvas is None or not isinstance(canvas, FigureCanvasTkAgg):
            # Resolve the live Tk canvas so event wiring targets user input.
            try:
                for candidate in list(getattr(self, "_canvases", []) or []):
                    if getattr(candidate, "figure", None) is fig:
                        canvas = candidate
                        break
            except Exception:
                pass
        if canvas is not None and getattr(fig, "canvas", None) is not canvas:
            try:
                fig.set_canvas(canvas)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting
                # the workflow.
                pass
        canvas_type = type(canvas).__name__ if canvas is not None else "None"
        canvas_id = id(canvas) if canvas is not None else None
        self._dbg(
            "plotting.legends",
            "Legend tracking canvas type=%s id=%s",
            canvas_type,
            canvas_id,
        )
        if canvas is None or not isinstance(canvas, FigureCanvasTkAgg):
            self._log(
                "plotting.legends",
                logging.WARNING,
                "Combined legend tracking skipped; canvas is not FigureCanvasTkAgg.",
            )
            return
        try:
            prior_canvas = getattr(self, "_combined_legend_canvas", None)
            prior_cids = getattr(self, "_combined_legend_event_cids", None)
            if not isinstance(prior_cids, dict):
                prior_cids = {}
            if prior_canvas is not None:
                # Disconnect previously registered callbacks to avoid duplicates.
                for cid in prior_cids.values():
                    if cid:
                        try:
                            prior_canvas.mpl_disconnect(cid)
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting
                            # the workflow.
                            pass
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting
            # the workflow.
            pass
        self._combined_legend_cid = None
        self._combined_legend_event_cids = {}
        self._combined_legend_canvas = canvas
        if not cycle_drag_enabled:
            # Drag capture callbacks are only registered when cycle dragging is enabled.
            # draw_event remains active for post-draw refresh and anchor apply.
            cycle_drag_enabled = False
        if (
            self._combined_cycle_legend_capture_enabled()
            and saved_offsets is None
            and not (
                stored_mode == "loc_tuple" and stored_loc_tuple is not None
            )
        ):
            self._capture_combined_legend_anchor_from_fig(fig, source="auto")

        def _increment_combined_overlay_refresh_invoked_count(
            target_frame: ttk.Frame,
        ) -> int:
            """Increment the combined overlay refresh invocation count."""
            if target_frame is None:
                return 0
            count = getattr(target_frame, "_combined_overlay_refresh_invoked_count", 0)
            try:
                count = int(count)
            except Exception:
                count = 0
            count += 1
            try:
                target_frame._combined_overlay_refresh_invoked_count = count
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._update_plot_loading_overlay_progress(
                target_frame,
                progress=84.0 if count <= 1 else 94.0,
                message=(
                    "Running combined auto-refresh pass 1..."
                    if count <= 1
                    else "Running combined auto-refresh pass 2..."
                ),
            )
            return count

        def _finalize_post_first_draw_overlay(
            target_frame: ttk.Frame,
            *,
            force_clear: bool = False,
            from_debounce: bool = False,
        ) -> None:
            """Finalize the combined loading overlay after a post-draw refresh.

            Purpose:
                Clear the loading overlay only after the refresh-triggered draw.
            Why:
                The combined layout stabilizes after multiple refresh passes, so
                the overlay must remain until the final post-refresh draw finishes.
            Inputs:
                target_frame: Plot tab frame hosting the combined plot.
                force_clear: When True, clear even if readiness signals are missing.
            Outputs:
                None.
            Side Effects:
                Clears the overlay, resets auto-refresh state, and records logs.
            Exceptions:
                Errors are caught to avoid interrupting the UI workflow.
            """
            if target_frame is None:
                return
            if from_debounce:
                try:
                    target_frame._combined_overlay_finalize_after_id = None
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            hold_overlay = getattr(
                target_frame, "_post_first_draw_refresh_hold_overlay", False
            )
            if not hold_overlay:
                return
            settle_timeout_seconds = 2.0
            settle_debounce_ms = 40
            completed_count = getattr(
                target_frame, "_combined_overlay_refresh_completed_count", 0
            )
            try:
                completed_count = int(completed_count)
            except Exception:
                completed_count = 0
            target_refreshes = getattr(
                target_frame,
                "_combined_overlay_target_refreshes",
                self._combined_overlay_default_target_refreshes(),
            )
            try:
                target_refreshes = int(target_refreshes)
            except Exception:
                target_refreshes = self._combined_overlay_default_target_refreshes()
            if target_refreshes <= 0:
                target_refreshes = 1
            ready_seen = bool(
                getattr(target_frame, "_combined_overlay_ready_seen", False)
            )
            auto_refresh_after_id = getattr(target_frame, "_plot_auto_refresh_after_id", None)
            auto_refresh_pending = auto_refresh_after_id is not None
            combined_busy = bool(getattr(self, "_combined_render_busy", False))
            active_fig = self._resolve_combined_overlay_figure(
                target_frame, canvas=canvas, fig=fig
            )
            active_fig_id = id(active_fig) if active_fig is not None else None
            pending_apply = bool(
                getattr(self, "_combined_cycle_legend_pending_apply", False)
            )
            pending_fig_id = getattr(self, "_combined_cycle_legend_pending_fig_id", None)
            pending_apply_for_active = pending_apply and (
                active_fig_id is None or pending_fig_id == active_fig_id
            )
            redraw_queued = bool(
                getattr(active_fig, "_cycle_legend_redraw_queued", False)
                if active_fig is not None
                else False
            )
            base_requirements_met = (
                completed_count >= target_refreshes and ready_seen
            )
            settle_requirements_met = (
                base_requirements_met
                and not auto_refresh_pending
                and not combined_busy
                and not pending_apply_for_active
                and not redraw_queued
            )
            current_geometry_sig = self._combined_rendered_geometry_signature(active_fig)
            stable_count = getattr(target_frame, "_combined_overlay_stable_draw_count", 0)
            try:
                stable_count = int(stable_count)
            except Exception:
                stable_count = 0
            if settle_requirements_met:
                last_geometry_sig = getattr(
                    target_frame, "_combined_overlay_last_geometry_sig", None
                )
                if current_geometry_sig is not None and current_geometry_sig == last_geometry_sig:
                    stable_count += 1
                elif current_geometry_sig is not None:
                    stable_count = 1
                else:
                    stable_count = 0
                try:
                    target_frame._combined_overlay_last_geometry_sig = current_geometry_sig
                    target_frame._combined_overlay_stable_draw_count = stable_count
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            else:
                stable_count = 0
                try:
                    target_frame._combined_overlay_stable_draw_count = 0
                    target_frame._combined_overlay_last_geometry_sig = current_geometry_sig
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

            finalize_started_at = getattr(
                target_frame, "_combined_overlay_finalize_started_at", None
            )
            now_monotonic = time.monotonic()
            if settle_requirements_met:
                if finalize_started_at is None:
                    finalize_started_at = now_monotonic
                    try:
                        target_frame._combined_overlay_finalize_started_at = (
                            finalize_started_at
                        )
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
            else:
                finalize_started_at = None
                try:
                    target_frame._combined_overlay_finalize_started_at = None
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

            timed_out = False
            if (
                not force_clear
                and settle_requirements_met
                and finalize_started_at is not None
                and (now_monotonic - float(finalize_started_at)) >= settle_timeout_seconds
            ):
                timed_out = True
                force_clear = True
                self._log_plot_tab_debug(
                    "Combined overlay settle timeout reached (%.2fs); forcing clear."
                    % settle_timeout_seconds
                )

            if not force_clear:
                if not settle_requirements_met:
                    self._log_plot_tab_debug(
                        "Combined overlay hold; completed=%s target=%s ready_seen=%s after_pending=%s busy=%s pending_apply=%s redraw_queued=%s."
                        % (
                            completed_count,
                            target_refreshes,
                            ready_seen,
                            auto_refresh_pending,
                            combined_busy,
                            pending_apply_for_active,
                            redraw_queued,
                        )
                    )
                    return
                if stable_count < 2:
                    self._log_plot_tab_debug(
                        "Combined overlay hold; geometry not yet stable (stable_draws=%s)."
                        % stable_count
                    )
                    return
                if not from_debounce:
                    scheduled_finalize_after_id = getattr(
                        target_frame, "_combined_overlay_finalize_after_id", None
                    )
                    if scheduled_finalize_after_id is None:

                        def _debounced_finalize() -> None:
                            """Run one debounced combined-overlay finalize check."""
                            _finalize_post_first_draw_overlay(
                                target_frame,
                                force_clear=False,
                                from_debounce=True,
                            )

                        tk_widget = None
                        try:
                            tk_widget = canvas.get_tk_widget()
                        except Exception:
                            tk_widget = None
                        try:
                            if tk_widget is not None:
                                scheduled_finalize_after_id = tk_widget.after(
                                    settle_debounce_ms, _debounced_finalize
                                )
                            else:
                                scheduled_finalize_after_id = self.after(
                                    settle_debounce_ms, _debounced_finalize
                                )
                            target_frame._combined_overlay_finalize_after_id = (
                                scheduled_finalize_after_id
                            )
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            _debounced_finalize()
                    return
            try:
                target_frame._post_first_draw_refresh_hold_overlay = False
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                target_frame._plot_auto_refresh_state = "done"
                target_frame._plot_auto_refresh_after_id = None
                target_frame._plot_auto_refresh_in_progress = False
                target_frame._plot_auto_refresh_phase = None
                target_frame._combined_overlay_stable_draw_count = 0
                target_frame._combined_overlay_last_geometry_sig = None
                target_frame._combined_overlay_finalize_started_at = None
                target_frame._combined_overlay_finalize_after_id = None
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._log_plot_tab_debug(
                "Combined auto-refresh overlay cleared after completed=%s target=%s ready_seen=%s stable_draws=%s force=%s timeout=%s."
                % (
                    completed_count,
                    target_refreshes,
                    ready_seen,
                    stable_count,
                    force_clear,
                    timed_out,
                )
            )
            self._update_plot_loading_overlay_progress(
                target_frame,
                progress=100.0,
                message="Combined plot ready.",
            )
            self._clear_plot_loading_overlay(target_frame)

        def _schedule_post_first_draw_refresh(target_frame: ttk.Frame) -> None:
            """Schedule the Combined post-first-draw refresh callback.

            Purpose:
                Invoke the manual Refresh callback once after the first draw.
            Why:
                The first draw guarantees renderer and geometry availability, but
                the refresh command may not be assigned yet, so we retry briefly.
            Inputs:
                target_frame: Plot tab frame hosting the combined plot.
            Outputs:
                None.
            Side Effects:
                Schedules an idle callback to invoke the refresh command, or a
                short retry while the refresh callback is still wiring.
            Exceptions:
                Errors are caught to avoid interrupting the UI loop.
            """
            if target_frame is None:
                return
            try:
                if not target_frame.winfo_exists():
                    _finalize_post_first_draw_overlay(target_frame, force_clear=True)
                    return
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            refresh_command = getattr(target_frame, "_refresh_command", None)
            if not callable(refresh_command):
                retry_count = getattr(
                    target_frame, "_post_first_draw_refresh_retry_count", 0
                )
                if not isinstance(retry_count, int) or retry_count < 0:
                    retry_count = 0
                retry_delay_ms = 5
                retry_limit = 60
                if retry_count >= retry_limit:
                    self._log_plot_tab_debug(
                        "Combined auto-refresh retry limit reached; clearing overlay."
                    )
                    _finalize_post_first_draw_overlay(target_frame, force_clear=True)
                    return

                try:
                    target_frame._post_first_draw_refresh_retry_count = (
                        retry_count + 1
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass

                # Retry briefly so the splash overlay stays up until the
                # refresh command is available.
                def _retry_post_first_draw_refresh():
                    """Retry waiting for the combined refresh command.

                    Purpose:
                        Poll for the refresh command wiring without blocking UI.
                    Why:
                        The initial draw can fire before the command assignment.
                    Inputs:
                        None.
                    Outputs:
                        None.
                    Side Effects:
                        Re-enters the post-first-draw refresh scheduler.
                    Exceptions:
                        Errors are caught to avoid interrupting the UI loop.
                    """
                    _schedule_post_first_draw_refresh(target_frame)

                tk_widget = None
                try:
                    tk_widget = canvas.get_tk_widget()
                except Exception:
                    tk_widget = None
                try:
                    if tk_widget is not None:
                        tk_widget.after(retry_delay_ms, _retry_post_first_draw_refresh)
                    else:
                        self.after(retry_delay_ms, _retry_post_first_draw_refresh)
                except Exception:
                    _retry_post_first_draw_refresh()
                return
            try:
                target_frame._post_first_draw_refresh_retry_count = 0
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            def _invoke_refresh():
                """Invoke the stored Refresh command after the first draw.

                Purpose:
                    Run the manual Refresh callback once geometry is stable.
                Why:
                    Combined plots need a deterministic post-draw refresh.
                Inputs:
                    None.
                Outputs:
                    None.
                Side Effects:
                    Flags auto-refresh invocation and calls the refresh callback.
                Exceptions:
                    Errors are caught to avoid UI interruption and overlay stalls.
                """
                try:
                    target_frame._post_first_draw_refresh_invoked = True
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
                baseline_sig = getattr(
                    target_frame, "_combined_overlay_layout_sig_baseline", None
                )
                if baseline_sig is None:
                    self._capture_combined_overlay_layout_baseline(
                        target_frame, canvas=canvas, fig=fig
                    )
                invoked_count = _increment_combined_overlay_refresh_invoked_count(
                    target_frame
                )
                completed_count = getattr(
                    target_frame, "_combined_overlay_refresh_completed_count", 0
                )
                self._log_plot_tab_debug(
                    "Combined auto-refresh invoked after draw; invoked=%s completed=%s."
                    % (invoked_count, completed_count)
                )
                try:
                    refresh_command()
                except Exception:
                    # Fail closed: avoid leaving the overlay stuck if refresh fails.
                    _finalize_post_first_draw_overlay(target_frame, force_clear=True)

            tk_widget = None
            try:
                tk_widget = canvas.get_tk_widget()
            except Exception:
                tk_widget = None
            try:
                if tk_widget is not None:
                    tk_widget.after_idle(_invoke_refresh)
                else:
                    self.after_idle(_invoke_refresh)
            except Exception:
                try:
                    if tk_widget is not None:
                        tk_widget.after(1, _invoke_refresh)
                    else:
                        self.after(1, _invoke_refresh)
                except Exception:
                    _invoke_refresh()

        # Closure captures _register_combined_legend_tracking state for callback
        # wiring, kept nested to scope the handler, and invoked by bindings set below.
        def _on_draw(_event=None):
            """Handle draw event.

            Purpose:
                Apply queued cycle legend offsets once a renderer is available.
            Why:
                Legends rebuild on refresh/regenerate; offsets must be applied
                after a draw to ensure display-space anchors are stable.

            Args:
                _event: Matplotlib draw event payload (unused).

            Returns:
                None.

            Side Effects:
                Applies queued cycle legend offsets and triggers a redraw.

            Exceptions:
                None.
            """
            try:
                seen = getattr(self, "_debug_combined_draw_seen", set())
                if not isinstance(seen, set):
                    seen = set()
                if id(fig) not in seen:
                    seen.add(id(fig))
                    self._debug_combined_draw_seen = seen
                    self._debug_dump_cycle_legend(fig, "on_first_draw_event")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting
                # the workflow.
                pass
            frame = None
            try:
                frame = getattr(canvas, "_plot_frame", None)
            except Exception:
                frame = None
            if frame is not None and getattr(frame, "_plot_key", None) == "fig_combined":
                is_real_combined = bool(
                    getattr(frame, "_combined_real_figure_installed", False)
                )
                if not is_real_combined:
                    if not getattr(frame, "_combined_placeholder_draw_logged", False):
                        try:
                            frame._combined_placeholder_draw_logged = True
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting
                            # the workflow.
                            pass
                        self._log_plot_tab_debug(
                            "Combined placeholder draw ignored for auto-refresh scheduling."
                        )
                else:
                    renderer_ok = False
                    try:
                        renderer_ok = canvas.get_renderer() is not None
                    except Exception:
                        renderer_ok = False
                    if renderer_ok and not getattr(
                        frame, "_combined_overlay_ready_seen", False
                    ):
                        try:
                            frame._combined_overlay_ready_seen = True
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting
                            # the workflow.
                            pass
                        self._log_plot_tab_debug(
                            "Combined overlay ready signal observed (renderer ok)."
                        )
                    if not getattr(frame, "_post_first_draw_refresh_done", False):
                        # Schedule the combined Refresh callback after the first draw.
                        try:
                            frame._post_first_draw_refresh_done = True
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting
                            # the workflow.
                            pass
                        self._log_plot_tab_debug("Combined first draw event fired.")
                        _schedule_post_first_draw_refresh(frame)
                    hold_overlay = getattr(
                        frame, "_post_first_draw_refresh_hold_overlay", False
                    )
                    completed_count = getattr(
                        frame, "_combined_overlay_refresh_completed_count", 0
                    )
                    try:
                        completed_count = int(completed_count)
                    except Exception:
                        completed_count = 0
                    target_refreshes = getattr(
                        frame,
                        "_combined_overlay_target_refreshes",
                        self._combined_overlay_default_target_refreshes(),
                    )
                    try:
                        target_refreshes = int(target_refreshes)
                    except Exception:
                        target_refreshes = self._combined_overlay_default_target_refreshes()
                    if target_refreshes <= 0:
                        target_refreshes = 1
                    if (
                        hold_overlay
                        and completed_count >= 1
                        and completed_count < target_refreshes
                        and not getattr(
                            frame, "_combined_overlay_second_refresh_scheduled", False
                        )
                    ):
                        try:
                            frame._combined_overlay_second_refresh_scheduled = True
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting
                            # the workflow.
                            pass
                        self._log_plot_tab_debug(
                            "Combined auto-refresh scheduling pass 2; completed=%s target=%s."
                            % (completed_count, target_refreshes)
                        )
                        _schedule_post_first_draw_refresh(frame)
                    if (
                        getattr(frame, "_post_first_draw_refresh_invoked", False)
                        and hold_overlay
                    ):
                        # Clear overlay on the first draw after the refresh completes.
                        _finalize_post_first_draw_overlay(frame)
            try:
                if getattr(fig, "_cycle_legend_anchor_applied", False):
                    return
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting
                # the workflow.
                pass
            if not getattr(self, "_combined_cycle_legend_pending_apply", False):
                return
            if getattr(self, "_combined_cycle_legend_pending_fig_id", None) != id(fig):
                return
            event_canvas = getattr(_event, "canvas", None)
            if event_canvas is not None and event_canvas is not canvas:
                return
            cycle_legend = self._get_combined_cycle_legend(fig)
            if cycle_legend is None:
                return
            ref_axis = self._combined_cycle_reference_axis(fig)
            ref_corner = settings.get("combined_cycle_legend_ref_corner")
            loc_value = _resolve_combined_cycle_legend_loc()
            stored_mode = None
            try:
                stored_mode = settings.get("combined_cycle_legend_anchor_mode")
            except Exception:
                stored_mode = None
            stored_loc = None
            try:
                stored_loc = settings.get("combined_cycle_legend_loc")
            except Exception:
                stored_loc = None
            stored_loc_tuple = None
            normalized_loc = _normalize_legend_loc_value(stored_loc)
            if isinstance(normalized_loc, tuple):
                try:
                    stored_loc_tuple = (
                        float(normalized_loc[0]),
                        float(normalized_loc[1]),
                    )
                except Exception:
                    stored_loc_tuple = None
            offsets = getattr(self, "_combined_cycle_legend_pending_offsets", None)
            stored_dx = None
            stored_dy = None
            try:
                stored_dx = settings.get("combined_cycle_legend_ref_dx_px", None)
                stored_dy = settings.get("combined_cycle_legend_ref_dy_px", None)
            except Exception:
                stored_dx = None
                stored_dy = None
            self._dbg(
                "plotting.legends",
                "Apply pre fig_id=%s persist=%s mode=%s stored_loc=%s stored_dx=%s stored_dy=%s",
                id(fig),
                persist,
                stored_mode,
                stored_loc_tuple,
                stored_dx,
                stored_dy,
            )
            applied = False
            if stored_mode == "loc_tuple" and stored_loc_tuple is not None:
                try:
                    applied = self._apply_cycle_legend_loc_tuple_axes(
                        fig,
                        cycle_legend,
                        allow_draw=False,
                        clamp=True,
                    )
                except Exception:
                    applied = False
            else:
                if offsets is None:
                    self._combined_cycle_legend_pending_apply = False
                    return
                try:
                    applied = _apply_cycle_legend_axis_offset(
                        fig,
                        cycle_legend,
                        ref_axis,
                        ref_corner,
                        offsets[0],
                        offsets[1],
                        loc_value,
                        allow_draw=False,
                    )
                except Exception:
                    applied = False
                if applied:
                    try:
                        migrated = self._capture_cycle_legend_loc_tuple_axes(
                            fig,
                            cycle_legend,
                            source="sync",
                        )
                        if migrated:
                            _save_settings_to_disk()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting
                        # the workflow.
                        pass
            try:
                legend_id = id(cycle_legend)
            except Exception:
                legend_id = None
            try:
                loc_post = cycle_legend.get_loc()
            except Exception:
                loc_post = getattr(cycle_legend, "_loc", None)
            loc_is_tuple = isinstance(loc_post, tuple)
            bbox_anchor_obj = None
            try:
                bbox_anchor_obj = cycle_legend.get_bbox_to_anchor()
            except Exception:
                bbox_anchor_obj = None
            bbox_anchor_type = (
                type(bbox_anchor_obj).__name__ if bbox_anchor_obj is not None else None
            )
            bbox_bounds = None
            if bbox_anchor_obj is not None:
                try:
                    bbox_bounds = bbox_anchor_obj.bounds
                except Exception:
                    bbox_bounds = None
            self._dbg(
                "plotting.legends",
                "Apply post legend_id=%s loc=%s loc_is_tuple=%s bbox_anchor_type=%s bbox_bounds=%s",
                legend_id,
                loc_post,
                loc_is_tuple,
                bbox_anchor_type,
                bbox_bounds,
            )
            if applied:
                if (
                    defer_cycle_drag_enable
                    and cycle_drag_enabled
                    and not cycle_lock_enabled
                ):
                    # Re-enable drag after the saved anchor is applied once.
                    _make_legend_draggable(cycle_legend)
                try:
                    self._debug_dump_cycle_legend(fig, "after_apply_saved_anchor")
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
                # Clear pending apply before scheduling a redraw to avoid loops.
                self._combined_cycle_legend_pending_apply = False
                self._combined_cycle_legend_pending_fig_id = None
                self._combined_cycle_legend_pending_offsets = None
                try:
                    fig._cycle_legend_anchor_applied = True  # type: ignore[attr-defined]
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
                try:
                    redraw_canvas = getattr(cycle_legend.figure, "canvas", None)
                    if redraw_canvas is None:
                        redraw_canvas = canvas
                    if redraw_canvas is None:
                        return
                    tk_widget = None
                    if isinstance(redraw_canvas, FigureCanvasTkAgg):
                        try:
                            tk_widget = redraw_canvas.get_tk_widget()
                        except Exception:
                            tk_widget = None
                    if tk_widget is None:
                        redraw_canvas.draw_idle()
                        return
                    # One-shot guard prevents redraw storms during multi-pass draws.
                    if getattr(fig, "_cycle_legend_redraw_queued", False):
                        return
                    try:
                        fig._cycle_legend_redraw_queued = True  # type: ignore[attr-defined]
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting
                        # the workflow.
                        pass

                    def _run_cycle_legend_redraw():
                        """Perform a one-shot redraw after legend relocation.

                        Purpose:
                            Trigger a Tk-idle redraw once the draw stack unwinds.
                        Why:
                            Ensures the cycle legend visually updates after
                            persisted anchors are applied during a draw callback.

                        Args:
                            None.

                        Returns:
                            None.

                        Side Effects:
                            Calls draw_idle on the canvas and clears the redraw guard.

                        Exceptions:
                            None.
                        """
                        try:
                            redraw_canvas.draw_idle()
                        finally:
                            try:
                                fig._cycle_legend_redraw_queued = False  # type: ignore[attr-defined]
                            except Exception:
                                # Best-effort guard; ignore failures to avoid interrupting
                                # the workflow.
                                pass

                    # Defer redraw until Tk is idle to avoid re-entrant draw callbacks.
                    try:
                        tk_widget.after_idle(_run_cycle_legend_redraw)
                    except Exception:
                        try:
                            tk_widget.after(0, _run_cycle_legend_redraw)
                        except Exception:
                            _run_cycle_legend_redraw()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
            else:
                self._combined_cycle_legend_pending_apply = False
                self._combined_cycle_legend_pending_fig_id = None
                self._combined_cycle_legend_pending_offsets = None
                try:
                    fig._cycle_legend_anchor_applied = True  # type: ignore[attr-defined]
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
            return

        # Closure captures _register_combined_legend_tracking state for callback
        # wiring, kept nested to scope the handler, and invoked by bindings set below.
        def _on_press(_event=None):
            """Handle button press event.

            Purpose:
                Anchor a press-event callback for debug wiring.
            Why:
                Connection IDs confirm the active canvas wiring in logs.

            Args:
                _event: Matplotlib button press event payload (unused).

            Returns:
                None.

            Side Effects:
                None.

            Exceptions:
                None.
            """
            event_x = getattr(_event, "x", None)
            event_y = getattr(_event, "y", None)
            drag_active = False
            start_loc = None
            cycle_legend = self._get_combined_cycle_legend(fig)
            self._cycle_leg_pre_click_loc = None
            self._cycle_leg_pre_click_bbox = None
            self._cycle_leg_pre_click_is_tuple = False
            self._cycle_leg_drag_use_loc_tuple = False
            if cycle_legend is not None:
                pre_loc = None
                try:
                    pre_loc = cycle_legend.get_loc()
                except Exception:
                    pre_loc = getattr(cycle_legend, "_loc", None)
                pre_bbox = None
                try:
                    pre_bbox = cycle_legend.get_bbox_to_anchor()
                except Exception:
                    pre_bbox = None
                self._cycle_leg_pre_click_loc = pre_loc
                self._cycle_leg_pre_click_bbox = pre_bbox
                self._cycle_leg_pre_click_is_tuple = isinstance(pre_loc, tuple)
                try:
                    legend_id = id(cycle_legend)
                except Exception:
                    legend_id = None
                self._dbg(
                    "plotting.legends",
                    "Press capture legend_loc=%s is_tuple=%s legend_id=%s",
                    pre_loc,
                    self._cycle_leg_pre_click_is_tuple,
                    legend_id,
                )
            if cycle_legend is not None and event_x is not None and event_y is not None:
                contains = False
                try:
                    contains, _ = cycle_legend.contains(_event)
                except Exception:
                    contains = False
                if not contains:
                    try:
                        renderer = None
                        canvas = getattr(cycle_legend.figure, "canvas", None)
                        if canvas is not None:
                            try:
                                renderer = canvas.get_renderer()
                            except Exception:
                                renderer = None
                        bbox = cycle_legend.get_window_extent(renderer=renderer)
                        if bbox is not None:
                            contains = bbox.contains(event_x, event_y)
                    except Exception:
                        contains = False
                if contains and cycle_drag_enabled and not cycle_lock_enabled:
                    drag_active = True
                    try:
                        start_loc = cycle_legend.get_loc()
                    except Exception:
                        start_loc = getattr(cycle_legend, "_loc", None)
                    try:
                        self._cycle_leg_drag_use_loc_tuple = (
                            settings.get("combined_cycle_legend_anchor_mode")
                            == "loc_tuple"
                        )
                    except Exception:
                        self._cycle_leg_drag_use_loc_tuple = False
            self._cycle_leg_drag_active = drag_active
            self._cycle_leg_drag_start_xy = (
                (event_x, event_y) if drag_active else None
            )
            self._cycle_leg_drag_start_loc = start_loc if drag_active else None
            self._cycle_leg_drag_moved = False
            return

        # Closure captures _register_combined_legend_tracking state for callback
        # wiring, kept nested to scope the handler, and invoked by bindings set below.
        def _on_motion(_event=None):
            """Handle motion notify event.

            Purpose:
                Track whether a cycle-legend drag has moved past click jitter.
            Why:
                Movement thresholding avoids false drag captures while letting
                Matplotlib's draggable legend keep cursor-relative positioning.

            Args:
                _event: Matplotlib motion event payload with display coordinates.

            Returns:
                None.

            Side Effects:
                May set self._cycle_leg_drag_moved once drag distance exceeds
                the movement threshold.

            Exceptions:
                None. Early returns are used for invalid event payloads.
            """
            if not getattr(self, "_cycle_leg_drag_active", False):
                return
            start_xy = getattr(self, "_cycle_leg_drag_start_xy", None)
            event_x = getattr(_event, "x", None)
            event_y = getattr(_event, "y", None)
            if start_xy is None or event_x is None or event_y is None:
                return
            dx = event_x - start_xy[0]
            dy = event_y - start_xy[1]
            distance_sq = (dx * dx) + (dy * dy)
            if not getattr(self, "_cycle_leg_drag_moved", False):
                if distance_sq < 9.0:
                    return
                self._cycle_leg_drag_moved = True
            # Leave live movement to Matplotlib draggable legends so the cursor
            # grab-point offset is preserved without manual coordinate remapping.
            return

        # Closure captures _register_combined_legend_tracking state for callback
        # wiring, kept nested to scope the handler, and invoked by bindings set below.
        def _on_release(_event=None):
            """Handle legend drag completion for combined plots.

            Purpose:
                Capture legend anchors on mouse release after a drag.
            Why:
                Persisting anchors on drag completion prevents snap-back on
                refresh/regeneration.

            Args:
                _event: Matplotlib event payload (unused).

            Returns:
                None.

            Side Effects:
                Writes legend anchor state and updates settings persistence.

            Exceptions:
                Errors are caught by the caller to avoid UI interruption.
            """
            try:
                event_x = getattr(_event, "x", None)
                event_y = getattr(_event, "y", None)
                event_inaxes = getattr(_event, "inaxes", None)
                self._dbg(
                    "plotting.legends",
                    "Button release fired fig_id=%s x=%s y=%s inaxes=%s",
                    id(fig),
                    event_x,
                    event_y,
                    event_inaxes,
                )
                drag_active = bool(getattr(self, "_cycle_leg_drag_active", False))
                drag_moved = bool(getattr(self, "_cycle_leg_drag_moved", False))
                if not (drag_active and drag_moved):
                    cycle_legend = self._get_combined_cycle_legend(fig)
                    try:
                        legend_id = (
                            id(cycle_legend) if cycle_legend is not None else None
                        )
                    except Exception:
                        legend_id = None
                    try:
                        legend_loc = (
                            cycle_legend.get_loc()
                            if cycle_legend is not None
                            else None
                        )
                    except Exception:
                        legend_loc = getattr(cycle_legend, "_loc", None)
                    self._dbg(
                        "plotting.legends",
                        "Non-drag return legend_loc=%s legend_id=%s",
                        legend_loc,
                        legend_id,
                    )
                    pre_loc = getattr(self, "_cycle_leg_pre_click_loc", None)
                    pre_is_tuple = bool(
                        getattr(self, "_cycle_leg_pre_click_is_tuple", False)
                    )
                    if (
                        pre_is_tuple
                        and cycle_legend is not None
                        and pre_loc is not None
                        and not isinstance(legend_loc, tuple)
                    ):
                        try:
                            pre_tuple = tuple(map(float, pre_loc))
                            settings["combined_cycle_legend_anchor_mode"] = "loc_tuple"
                            settings["combined_cycle_legend_anchor_space"] = "axes"
                            settings["combined_cycle_legend_loc"] = [
                                pre_tuple[0],
                                pre_tuple[1],
                            ]
                            self._apply_cycle_legend_loc_tuple_axes(
                                fig,
                                cycle_legend,
                                allow_draw=False,
                                clamp=True,
                            )
                            if fig.canvas is not None:
                                fig.canvas.draw_idle()
                            self._dbg(
                                "plotting.legends",
                                "Non-drag restore from=%s to=%s legend_id=%s",
                                legend_loc,
                                pre_loc,
                                legend_id,
                            )
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting
                            # the workflow.
                            pass
                    self._dbg(
                        "plotting.legends",
                        "Skip persist reason=not_drag cycle_leg_drag_active=%s moved=%s",
                        drag_active,
                        drag_moved,
                    )
                    return
                try:
                    self._debug_dump_cycle_legend(fig, "after_button_release_event")
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
                if not self._combined_cycle_legend_capture_enabled(require_drag=True):
                    return
                self._capture_combined_legend_anchor_from_fig(fig, source="drag")
            finally:
                # Always reset drag state so non-drag releases can't leak flags.
                self._cycle_leg_drag_active = False
                self._cycle_leg_drag_moved = False
                self._cycle_leg_drag_start_xy = None
                self._cycle_leg_drag_start_loc = None
                self._cycle_leg_drag_use_loc_tuple = False
                self._cycle_leg_pre_click_loc = None
                self._cycle_leg_pre_click_bbox = None
                self._cycle_leg_pre_click_is_tuple = False

        try:
            draw_cid = canvas.mpl_connect("draw_event", _on_draw)
            press_cid = None
            motion_cid = None
            release_cid = None
            if cycle_drag_enabled:
                press_cid = canvas.mpl_connect("button_press_event", _on_press)
                motion_cid = canvas.mpl_connect("motion_notify_event", _on_motion)
                release_cid = canvas.mpl_connect("button_release_event", _on_release)
            self._combined_legend_event_cids = {
                "draw_event": draw_cid,
                "button_press_event": press_cid,
                "motion_notify_event": motion_cid,
                "button_release_event": release_cid,
            }
            self._combined_legend_cid = release_cid
            self._dbg(
                "plotting.legends",
                "Connect draw_event cid=%s",
                draw_cid,
            )
            self._dbg(
                "plotting.legends",
                "Connect button_press_event cid=%s",
                press_cid,
            )
            self._dbg(
                "plotting.legends",
                "Connect button_release_event cid=%s",
                release_cid,
            )
            self._dbg(
                "plotting.legends",
                "Connect motion_notify_event cid=%s",
                motion_cid,
            )
            if getattr(self, "_combined_cycle_legend_pending_apply", False):
                # Ensure a post-bind draw so pending offsets can apply.
                try:
                    canvas.draw_idle()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting
                    # the workflow.
                    pass
        except Exception:
            self._combined_legend_event_cids = {}
            self._combined_legend_cid = None

    def _set_cycle_summary(self, text):
        """Set cycle summary.
        Used to persist cycle summary into the current state."""

        normalized = text if text is not None else ""

        self._pending_cycle_summary = normalized

        widget = getattr(self, "_cycle_summary_box", None)

        if widget and widget.winfo_exists():

            widget.configure(state="normal")

            widget.delete("1.0", "end")

            widget.insert("1.0", normalized)

            widget.configure(state="disabled")

    def _show_cycle_ready_message(self):
        """Perform show cycle ready message.
        Used to keep the workflow logic localized and testable."""

        msg = (
            "Columns applied. Click 'Analyze Full Range' to process everything, or "
            "drag a range on the chart and click 'Analyze Selected Range'."
        )

        self._set_cycle_selection_text("Selection: (choose an analysis range)")
        self._set_cycle_summary(msg)

        ax = getattr(self, "_cycle_ax", None)

        canvas = getattr(self, "_cycle_canvas", None)

        if ax is not None:

            ax.clear()

            ax.text(
                0.5,
                0.5,
                "Click 'Analyze Full Range' to analyze all data\n"
                "or drag to select a range first.",
                ha="center",
                va="center",
                transform=ax.transAxes,
            )

        if canvas is not None:

            try:

                canvas.draw_idle()

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        try:

            self._shade_selection(None)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:
            self._update_cycle_fig_tab(None)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:

            self._set_cycle_summary(msg)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _cancel_cycle_focus_callback(self):
        """Perform cancel cycle focus callback.
        Used to keep the workflow logic localized and testable."""
        after_id = getattr(self, "_cycle_focus_after_id", None)
        if after_id is not None:
            try:
                self.after_cancel(after_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._cycle_focus_after_id = None

    def _focus_cycle_tab_when_ready(self):
        """Perform focus cycle tab when ready.
        Used to keep the workflow logic localized and testable."""
        self._cancel_cycle_focus_callback()

        if not getattr(self, "_pending_cycle_tab_focus", False):
            return

        tab = getattr(self, "tab_cycle", None)
        if tab is not None and getattr(self, "_cycle_ui_built", False):
            try:
                self.nb.select(tab)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._pending_cycle_tab_focus = False
            return

        self._cycle_focus_after_id = self.after(100, self._focus_cycle_tab_when_ready)

    def _focus_plot_tab(self):
        """Perform focus plot tab.
        Used to keep the workflow logic localized and testable."""
        tab = getattr(self, "tab_plot", None)

        if tab is None:

            return

        try:

            self.nb.select(tab)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _cache_cycle_markers(self, peaks, troughs, mask):
        """Perform cache cycle markers.
        Used to keep the workflow logic localized and testable."""
        if not self.file_path or not self.columns:
            return

        try:
            path = os.path.abspath(self.file_path)
        except Exception:
            path = str(self.file_path)

        try:
            data_len = len(globals().get("x") or [])
        except Exception:
            data_len = 0

        try:
            mask_true = int(np.count_nonzero(mask)) if mask is not None else None
        except Exception:
            mask_true = None

        cache = {
            "file": path,
            "sheet": self.selected_sheet.get() or "",
            "sheets": list(self.selected_sheets) if self.multi_sheet_enabled else None,
            "multi_sheet": bool(self.multi_sheet_enabled),
            "columns": {
                "x": self.columns.get("x"),
                "y1": self.columns.get("y1"),
            },
            "data_len": int(data_len),
            "mask_true": mask_true,
            "peaks": sorted(int(p) for p in peaks),
            "troughs": sorted(int(t) for t in troughs),
            "peak_params": {
                "prominence": float(self.pk_prominence.get()),
                "distance": int(self.pk_distance.get()),
                "width": int(self.pk_width.get()),
            },
            "min_cycle_drop": float(self.min_cycle_drop.get()),
            "timestamp": time.time(),
        }

        settings["cycle_cached_markers"] = cache
        self._cached_cycle_markers = cache
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _show_cycle_apply_prompt(self):
        """Apply prompt.
        Used by show cycle workflows to apply prompt."""

        msg = "Click 'Rerun Cycle Analysis' or 'Apply Column Selection' to populate this tab with the selected data."

        self._set_cycle_selection_text("Selection: (awaiting column apply)")
        self._set_cycle_summary(msg)

        ax = getattr(self, "_cycle_ax", None)

        canvas = getattr(self, "_cycle_canvas", None)

        if ax is not None:

            ax.clear()

            ax.text(
                0.5,
                0.5,
                "Click 'Apply Column Selection' in the bottom action bar\n"
                "to populate Cycle Analysis.",
                ha="center",
                va="center",
                transform=ax.transAxes,
            )

        if canvas is not None:

            try:

                canvas.draw_idle()

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        try:

            self._shade_selection(None)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:

            self._update_cycle_fig_tab(None)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:

            self._set_cycle_summary(msg)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _cycle_ready(self):
        """Perform cycle ready.
        Used to keep the workflow logic localized and testable."""

        if getattr(self, "_columns_applied", False):

            return True

        self._show_cycle_apply_prompt()

        return False

    def _debug_series_flow(self, stage: str, message: str) -> None:
        """Emit series-flow debug output with one-shot guards.

        Purpose:
            Track column/series lifecycle events for debugging.
        Why:
            Provides lightweight tracing of apply/refresh flows.
        Args:
            stage: Stage identifier for the series workflow.
            message: Detail message for the current stage.
        Returns:
            None.
        Side Effects:
            Writes to the debug logger when ui.events is enabled.
        Exceptions:
            Best-effort guards suppress logging failures.
        """
        apply_id = getattr(self, "_series_flow_apply_id", 0)
        seen = getattr(self, "_series_flow_debug_seen", set())
        token = (apply_id, stage)
        if token in seen:
            return
        seen.add(token)
        self._series_flow_debug_seen = seen
        self._dbg(
            "ui.events",
            "SeriesFlow %s %s %s",
            apply_id,
            stage,
            message,
        )

    def _mark_columns_dirty(
        self, reason: str = "", *, allow_during_apply: bool = False
    ):
        """Perform mark columns dirty.
        Used to keep the workflow logic localized and testable."""

        current_selection = None
        if getattr(self, "columns_vars", None):
            try:
                current_selection = {
                    key: var.get() for key, var in self.columns_vars.items()
                }
            except Exception:
                current_selection = None

        reason_label = (reason or "").strip() or "unspecified"
        y1_before = "y1" in globals()

        if getattr(self, "_is_applying_columns", False) and not allow_during_apply:
            self._debug_series_flow(
                f"dirty:{reason_label}",
                f"skipped apply_in_progress y1_present={y1_before}->{y1_before}",
            )
            return

        if (
            self._columns_applied
            and current_selection is not None
            and current_selection == getattr(self, "_last_applied_columns", None)
        ):
            return

        self._columns_applied = False
        self._last_applied_columns = None
        self._cycle_mask = None
        self._cycle_pending_range = None

        self._update_apply_columns_indicator("pending")

        # Clear cached global series so stale data isn't reused

        # Iterate over ("x", "y1", "y2", "y3", "z", "z2", "cycle_temp_series") to apply the per-item logic.
        for key in ("x", "y1", "y2", "y3", "z", "z2", "cycle_temp_series"):

            try:

                globals().pop(key)

            except KeyError:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        y1_after = "y1" in globals()
        self._debug_series_flow(
            f"dirty:{reason_label}",
            f"applied y1_present={y1_before}->{y1_after}",
        )

        if getattr(self, "_cycle_tab_added", False):

            self._show_cycle_apply_prompt()

        try:
            self._mark_plot_data_dirty()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _bind_vdw_dirty_traces(self) -> None:
        """Perform bind VDW dirty traces.
        Used to keep the workflow logic localized and testable."""
        # Closure captures _bind_vdw_dirty_traces state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _bind_vdw_dirty_traces.
        def _on_change(*_):
            """Handle change.
            Used as an event callback for change."""
            self._mark_vdw_dirty(reason="input change")

        tracked_vars = (
            self.v_volume,
            self.v_a,
            self.v_b,
            self.v_gas_molar_mass,
        )
        # Iterate over tracked_vars to apply the per-item logic.
        for var in tracked_vars:
            try:
                handle = var.trace_add("write", _on_change)
            except Exception:
                continue
            self._vdw_trace_ids.append((var, handle))

    def _mark_vdw_dirty(self, reason: str = "") -> None:
        """Perform mark VDW dirty.
        Used to keep the workflow logic localized and testable."""
        _ = reason  # reserved for future logging
        self._update_apply_vdw_indicator("pending")

    def _on_gas_selected(self, *_):
        """Handle gas selected.
        Used as an event callback for gas selected."""

        choice = self.v_gas.get()

        preset = GAS_PRESETS.get(choice)

        if preset:

            # Set a & b to the preset values (entries remain editable)

            self.v_a.set(preset["a"])

            self.v_b.set(preset["b"])

        override = self._gas_preset_overrides.get(choice) or {}
        molar = override.get("molar_mass")

        if molar is None and preset is not None:
            molar = preset.get("molar_mass")

        try:
            molar_val = float(molar)
        except (TypeError, ValueError):
            molar_val = None

        if molar_val is not None and math.isfinite(molar_val) and molar_val > 0.0:
            self.v_gas_molar_mass.set(molar_val)

    def _on_product_selected(self, *_):
        """Handle product selected.
        Used as an event callback for product selected."""

        preset_key = self.v_product_preset.get()

        preset = PRODUCT_PRESETS.get(preset_key)

        if preset:

            self.v_product_name.set(preset.get("name", DEFAULT_PRODUCT_NAME))

            self.v_product_molar_mass.set(
                preset.get("molar_mass", DEFAULT_PRODUCT_MOLAR_MASS)
            )

        else:

            if not self.v_product_name.get().strip():

                self.v_product_name.set(DEFAULT_PRODUCT_NAME)

            try:

                current_molar = float(self.v_product_molar_mass.get())

            except Exception:

                current_molar = 0.0

            if current_molar <= 0.0:

                self.v_product_molar_mass.set(DEFAULT_PRODUCT_MOLAR_MASS)

        # update globals so subsequent analyses pick up the new values

        self._prepare_series_globals()

    def _apply_auto_state(self, auto_var, entries):
        """Apply auto state.
        Used to apply auto state changes to live state."""

        state = "disabled" if auto_var.get() else "normal"

        # Iterate over entries to apply the per-item logic.
        for e in entries:

            e.configure(state=state)

    def _wire_auto_to_entries(self, auto_var, entries):
        """Perform wire auto to entries.
        Used to keep the workflow logic localized and testable."""

        # call once now + whenever the checkbox flips

        # Closure captures _wire_auto_to_entries state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _wire_auto_to_entries.
        def _on_change(*_):
            """Handle change.
            Used as an event callback for change."""

            self._apply_auto_state(auto_var, entries)

        auto_var.trace_add("write", _on_change)

    def _attach_tooltip(self, widget, text: str, delay_ms: int = 400):
        """Perform attach tooltip.
        Used to keep the workflow logic localized and testable."""

        tip_win = {"win": None}

        after_id = {"id": None}

        # Closure captures _attach_tooltip local context to keep helper logic scoped and invoked directly within _attach_tooltip.
        def show_tooltip():
            """Perform show tooltip.
            Used to keep the workflow logic localized and testable."""

            if tip_win["win"] or not widget.winfo_viewable():

                return

            x, y, cx, cy = (
                widget.bbox("insert")
                if widget.winfo_class() in ("Entry", "Text")
                else (0, 0, 0, 0)
            )

            x += widget.winfo_rootx() + 20

            y += widget.winfo_rooty() + 20

            tw = tk.Toplevel(widget)

            tw.wm_overrideredirect(True)

            tw.wm_geometry(f"+{x}+{y}")

            frm = ttk.Frame(tw, relief="solid", borderwidth=1)

            frm.pack(ipadx=6, ipady=4)

            lbl = ttk.Label(frm, text=text, justify="left", wraplength=360)

            lbl.pack()

            tip_win["win"] = tw

        # Closure captures _attach_tooltip local context to keep helper logic scoped and invoked directly within _attach_tooltip.
        def schedule_show(_e=None):
            """Schedule show.
            Used to queue show without blocking the UI."""

            cancel_show()

            after_id["id"] = widget.after(delay_ms, show_tooltip)

        # Closure captures _attach_tooltip state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _attach_tooltip.
        def cancel_show(_e=None):
            """Perform cancel show.
            Used to keep the workflow logic localized and testable."""

            if after_id["id"]:

                widget.after_cancel(after_id["id"])

                after_id["id"] = None

            hide_tooltip()

        # Closure captures _attach_tooltip local context to keep helper logic scoped and invoked directly within _attach_tooltip.
        def hide_tooltip(_e=None):
            """Perform hide tooltip.
            Used to keep the workflow logic localized and testable."""

            if tip_win["win"] is not None:

                try:

                    tip_win["win"].destroy()

                except Exception:

                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

                tip_win["win"] = None

        widget.bind("<Enter>", schedule_show)

        widget.bind("<Leave>", cancel_show)

        widget.bind("<Motion>", schedule_show)

    def _clear_numeric_cache(self):
        """Clear numeric cache.
        Used to reset numeric cache state safely."""

        self._numeric_cache.clear()

    def _register_var_default(self, var, default):
        """Return default value.
        Used by register var workflows to return value."""
        self._var_defaults[id(var)] = default

    def _default_value_from_var(
        self, var: tk.Variable | None, fallback: Any = None
    ) -> Any:
        """Return a stored default value for a Tk variable.

        Purpose:
            Resolve the startup default for a Tk variable when resetting state.
        Why:
            New Profile resets must use the original defaults, not the current values.
        Args:
            var: Tk variable to resolve.
            fallback: Value to use when no default is available.
        Returns:
            The stored default value or the fallback when unavailable.
        Side Effects:
            None.
        Exceptions:
            Returns the fallback when the variable cannot be read safely.
        """
        if var is None:
            return copy.deepcopy(fallback)
        var_id = id(var)
        if var_id in self._var_defaults:
            return copy.deepcopy(self._var_defaults[var_id])
        try:
            return copy.deepcopy(var.get())
        except Exception:
            # Best-effort guard; fall back to provided default.
            return copy.deepcopy(fallback)

    def _safe_get_var(self, var, cast=float):
        """Return var.
        Used by safe workflows to return var."""
        var_id = id(var)
        default = self._var_defaults.get(var_id)
        try:
            value = var.get()
        except tk.TclError:
            if default is None:
                raise
            var.set(default)
            return cast(default)

        try:
            casted = cast(value)
        except (TypeError, ValueError):
            if default is None:
                raise
            var.set(default)
            return cast(default)

        self._var_defaults[var_id] = casted
        return casted

    def _get_numeric_series(self, colname, *, dropna=False):
        """Return numeric series.
        Used to retrieve numeric series for downstream logic."""

        if self.df is None or not colname or colname == "None":

            return None

        key = (colname, bool(dropna))

        if key in self._numeric_cache:

            return self._numeric_cache[key]

        if dropna:

            base = self._get_numeric_series(colname, dropna=False)

            if base is None:

                result = None

            else:

                cleaned = base.dropna()

                result = None if cleaned.empty else cleaned

        else:

            try:

                result = pd.to_numeric(self.df[colname], errors="coerce")

            except Exception:

                result = None

        self._numeric_cache[key] = result

        return result

    def _get_title_type_choices(self) -> List[str]:
        """Return title type choices.
        Used to retrieve title type choices for downstream logic."""
        types = _normalize_title_type_list(settings.get("title_data_types"))
        settings["title_data_types"] = list(types)
        return types

    def _resolve_title_type_selection(self) -> str:
        """Resolve title type selection.
        Used to compute title type selection before rendering or export."""
        types = self._get_title_type_choices()
        selected = str(self.title_data_type_var.get() or "").strip()
        matched = None
        if selected:
            # Iterate over types to apply the per-item logic.
            for entry in types:
                if entry.casefold() == selected.casefold():
                    matched = entry
                    break
        if matched is None:
            matched = types[0]
        if matched != self.title_data_type_var.get():
            try:
                self.title_data_type_var.set(matched)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        settings["title_selected_type"] = matched
        return matched

    def _format_mmdd(self, dt_value: Any) -> str:
        """Format mmdd.
        Used to prepare mmdd for display or export."""
        try:
            return f"{dt_value.month}/{dt_value.day}"
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return ""

    def _safe_format_template(
        self, template: str, tokens: Dict[str, Any]
    ) -> Tuple[bool, str]:
        """Format template.
        Used by safe workflows to format template."""
        try:
            return True, template.format(**tokens)
        except Exception as exc:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return False, str(exc)

    def _emit_auto_title_warning(self, key: str, message: str) -> None:
        """Perform emit auto title warning.
        Used to keep the workflow logic localized and testable."""
        if key in self._auto_title_warning_cache:
            return
        self._auto_title_warning_cache.add(key)
        try:
            messagebox.showwarning("Auto Title", message)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _get_datetime_series_for_title_full_dataset(self):
        """Return datetime series for title full dataset.
        Used to retrieve datetime series for title full dataset for downstream logic."""
        if self.df is None:
            return None
        dt_col = None
        stitched_col = getattr(self, "_stitched_dt_col", None)
        if stitched_col and stitched_col in self.df.columns:
            dt_col = stitched_col
        else:
            dt_col = (self.columns or {}).get("dt")
        if not dt_col or dt_col == "None" or dt_col not in self.df.columns:
            return None
        series = self.df[dt_col]
        if not pd.api.types.is_datetime64_any_dtype(series.dtype):
            series = pd.to_datetime(series, errors="coerce")
        series = series.dropna()
        if series.empty:
            return None
        return series

    def _base_auto_title_tokens(self) -> Dict[str, Any]:
        """Perform base auto title tokens.
        Used to keep the workflow logic localized and testable."""
        return {
            "type": self._resolve_title_type_selection(),
            "day_start": 1,
            "day_end": 1,
            "date_start": "",
            "date_end": "",
        }

    def _tokens_from_dt_range(
        self, start_dt: Any, end_dt: Any
    ) -> Tuple[Dict[str, Any], Optional[str]]:
        """Perform tokens from dt range.
        Used to keep the workflow logic localized and testable."""
        tokens = self._base_auto_title_tokens()
        if start_dt is None or end_dt is None:
            return tokens, "Auto Title needs a valid Date & Time mapping to compute date range."
        if pd.isna(start_dt) or pd.isna(end_dt):
            return tokens, "Auto Title needs a valid Date & Time mapping to compute date range."
        try:
            start_date = start_dt.date()
            end_date = end_dt.date()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return tokens, "Auto Title needs a valid Date & Time mapping to compute date range."
        day_mode = (self.auto_title_day_mode_var.get() or AUTO_TITLE_DAY_DIFF).strip()
        delta_days = (end_date - start_date).days
        if day_mode == AUTO_TITLE_DAY_INCLUSIVE:
            day_end = max(1, delta_days + 1)
        else:
            day_end = max(1, delta_days)
        tokens.update(
            {
                "day_end": day_end,
                "date_start": self._format_mmdd(start_dt),
                "date_end": self._format_mmdd(end_dt),
                "start_dt_iso": start_dt.strftime("%Y-%m-%d"),
                "end_dt_iso": end_dt.strftime("%Y-%m-%d"),
                "start_year": getattr(start_dt, "year", ""),
                "end_year": getattr(end_dt, "year", ""),
            }
        )
        return tokens, None

    def _compute_tokens_from_full_dataset(self) -> Tuple[Dict[str, Any], Optional[str]]:
        """Compute tokens from full dataset.
        Used to derive tokens from full dataset for analysis or plotting."""
        dt_series = self._get_datetime_series_for_title_full_dataset()
        if dt_series is None:
            return (
                self._base_auto_title_tokens(),
                "Auto Title needs a valid Date & Time mapping to compute date range.",
            )
        try:
            start_dt = dt_series.min()
            end_dt = dt_series.max()
        except Exception:
            return (
                self._base_auto_title_tokens(),
                "Auto Title needs a valid Date & Time mapping to compute date range.",
            )
        return self._tokens_from_dt_range(start_dt, end_dt)

    def _get_current_plot_xlim(self) -> Optional[Tuple[float, float]]:
        """Return current plot xlim.
        Used to retrieve current plot xlim for downstream logic."""
        try:
            current_tab = self.nb.select()
        except Exception:
            current_tab = None
        if not current_tab:
            return None
        try:
            tab_index = self.nb.index(current_tab)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        try:
            canvas = self._canvases[tab_index]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        fig = getattr(canvas, "figure", None)
        if fig is None or not getattr(fig, "axes", None):
            return None
        ax = fig.axes[0]
        try:
            xlim = ax.get_xlim()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        try:
            return (float(xlim[0]), float(xlim[1]))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None

    def _compute_tokens_from_current_view(
        self,
    ) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:
        """Compute tokens from current view.
        Used to derive tokens from current view for analysis or plotting."""
        if self.df is None:
            return None, "Current view range unavailable; using full dataset."
        xlim = self._get_current_plot_xlim()
        if not xlim:
            return None, "Current view range unavailable; using full dataset."
        x0, x1 = xlim
        if not (math.isfinite(x0) and math.isfinite(x1)):
            return None, "Current view range unavailable; using full dataset."
        if x0 > x1:
            x0, x1 = x1, x0

        x_col = (self.columns or {}).get("x")
        if not x_col or x_col == "None" or x_col not in self.df.columns:
            return None, "Current view range unavailable; using full dataset."

        dt_col = None
        stitched_col = getattr(self, "_stitched_dt_col", None)
        if stitched_col and stitched_col in self.df.columns:
            dt_col = stitched_col
        else:
            dt_col = (self.columns or {}).get("dt")

        cache_key = (id(self.df), x_col, dt_col, round(x0, 6), round(x1, 6))
        cached = self._auto_title_view_cache.get(cache_key)
        if cached is not None:
            return cached

        x_series = self.df[x_col]
        if pd.api.types.is_datetime64_any_dtype(x_series.dtype):
            try:
                import matplotlib.dates as mdates

                start_dt = mdates.num2date(x0)
                end_dt = mdates.num2date(x1)
            except Exception:
                result = (None, "Current view range unavailable; using full dataset.")
            else:
                result = self._tokens_from_dt_range(start_dt, end_dt)
            self._auto_title_view_cache[cache_key] = result
            return result

        if not dt_col or dt_col == "None" or dt_col not in self.df.columns:
            result = (None, "Current view range unavailable; using full dataset.")
            self._auto_title_view_cache[cache_key] = result
            return result

        try:
            x_numeric = pd.to_numeric(x_series, errors="coerce")
            dt_series = pd.to_datetime(self.df[dt_col], errors="coerce")
            mask = x_numeric.notna() & dt_series.notna()
            if not mask.any():
                result = (None, "Current view range unavailable; using full dataset.")
            else:
                x_valid = x_numeric[mask]
                dt_valid = dt_series[mask]
                idx_start = (x_valid - x0).abs().idxmin()
                idx_end = (x_valid - x1).abs().idxmin()
                start_dt = dt_valid.loc[idx_start]
                end_dt = dt_valid.loc[idx_end]
                result = self._tokens_from_dt_range(start_dt, end_dt)
        except Exception:
            result = (None, "Current view range unavailable; using full dataset.")

        self._auto_title_view_cache[cache_key] = result
        return result

    def _get_auto_title_tokens(
        self, source_mode: str
    ) -> Tuple[Dict[str, Any], Optional[str], bool]:
        """Return auto title tokens.
        Used to retrieve auto title tokens for downstream logic."""
        source_mode = (source_mode or "").strip().lower()
        used_fallback = False
        if source_mode == AUTO_TITLE_SOURCE_CURRENT:
            tokens, warning = self._compute_tokens_from_current_view()
            if tokens is None:
                tokens, fallback_warning = self._compute_tokens_from_full_dataset()
                used_fallback = True
                if fallback_warning:
                    warning = fallback_warning
                elif warning is None:
                    warning = "Current view range unavailable; using full dataset."
        else:
            tokens, warning = self._compute_tokens_from_full_dataset()
        return tokens, warning, used_fallback

    def _compute_auto_title_text(
        self,
    ) -> Tuple[Optional[str], Optional[str], bool, Optional[str]]:
        """Compute auto title text.
        Used to derive auto title text for analysis or plotting."""
        tokens, warning, used_fallback = self._get_auto_title_tokens(
            self.auto_title_source_var.get()
        )
        template = (self.auto_title_template_var.get() or "").strip()
        if not template:
            template = DEFAULT_AUTO_TITLE_TEMPLATE
        ok, formatted = self._safe_format_template(template, tokens)
        if not ok:
            return None, warning, used_fallback, formatted
        return formatted, warning, used_fallback, None

    def _resolve_effective_title(self, manual_title: str, *, preview: bool = False) -> str:
        """Resolve effective title.
        Used to compute effective title before rendering or export."""
        if not self.auto_title_enabled_var.get():
            return manual_title
        computed, warning, _used_fallback, error = self._compute_auto_title_text()
        if computed is None:
            if not preview:
                self._emit_auto_title_warning(
                    f"template:{error}",
                    f"Auto Title template error: {error}",
                )
            return manual_title
        if warning and not preview:
            self._emit_auto_title_warning(f"data:{warning}", warning)
        return computed

    def _update_auto_title_controls_state(self, *_args) -> None:
        """Update auto title controls state.
        Used to keep auto title controls state in sync with current state."""
        title_entry = getattr(self, "_title_entry", None)
        if title_entry is None or not title_entry.winfo_exists():
            return
        state = "disabled" if self.auto_title_enabled_var.get() else "normal"
        try:
            title_entry.configure(state=state)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _update_auto_title_preview(self, *_args) -> None:
        """Update auto title preview.
        Used to keep auto title preview in sync with current state."""
        preview_var = getattr(self, "_auto_title_preview_var", None)
        if preview_var is None:
            return
        if not self.auto_title_enabled_var.get():
            preview_var.set("Auto Title disabled.")
            return
        computed, warning, used_fallback, error = self._compute_auto_title_text()
        if computed is None:
            preview_var.set(f"Template error: {error}")
            return
        preview_text = computed
        if used_fallback:
            preview_text += " (fallback: full dataset)"
        elif warning:
            preview_text += " (missing Date & Time mapping)"
        preview_var.set(preview_text)

    def _copy_auto_title_to_manual(self) -> None:
        """Perform copy auto title to manual.
        Used to keep the workflow logic localized and testable."""
        computed, warning, _used_fallback, error = self._compute_auto_title_text()
        if computed is None:
            try:
                messagebox.showwarning(
                    "Auto Title", f"Auto Title template error: {error}"
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        try:
            self.title_text.set(computed)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if warning:
            self._emit_auto_title_warning(f"data:{warning}", warning)
        self._update_auto_title_preview()

    def _open_auto_title_template_editor(self) -> None:
        """Open auto title template editor.
        Used by UI actions to open auto title template editor."""
        existing = getattr(self, "_auto_title_template_window", None)
        if existing is not None and existing.winfo_exists():
            try:
                existing.deiconify()
                existing.lift()
                existing.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        window = tk.Toplevel(self)
        window.title("Edit Auto Title Template")
        window.transient(self)
        window.resizable(True, True)
        window.grab_set()
        self._auto_title_template_window = window

        ttk.Label(
            window,
            text="Template placeholders:",
        ).grid(row=0, column=0, sticky="w", padx=12, pady=(12, 4))
        placeholders = (
            "{type}, {day_start}, {day_end}, {date_start}, {date_end}, "
            "{start_dt_iso}, {end_dt_iso}, {start_year}, {end_year}"
        )
        ttk.Label(window, text=placeholders, wraplength=520).grid(
            row=1, column=0, sticky="w", padx=12, pady=(0, 8)
        )

        text = tk.Text(window, height=5, width=72, wrap="word")
        text.grid(row=2, column=0, sticky="nsew", padx=12, pady=(0, 8))
        text.insert("1.0", self.auto_title_template_var.get() or "")

        window.grid_rowconfigure(2, weight=1)
        window.grid_columnconfigure(0, weight=1)

        button_frame = ttk.Frame(window)
        button_frame.grid(row=3, column=0, sticky="e", padx=12, pady=(0, 12))

        # Closure captures _open_auto_title_template_editor local context to keep helper logic scoped and invoked directly within _open_auto_title_template_editor.
        def _validate_template() -> bool:
            """Validate template.
            Used to guard template before processing."""
            candidate = text.get("1.0", "end").strip()
            if not candidate:
                try:
                    messagebox.showwarning(
                        "Template Validation", "Template cannot be empty."
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                return False
            dummy_tokens = {
                "type": "Reaction",
                "day_start": 1,
                "day_end": 6,
                "date_start": "1/13",
                "date_end": "1/19",
                "start_dt_iso": "2026-01-13",
                "end_dt_iso": "2026-01-19",
                "start_year": 2026,
                "end_year": 2026,
            }
            ok, formatted = self._safe_format_template(candidate, dummy_tokens)
            if not ok:
                try:
                    messagebox.showwarning(
                        "Template Validation", f"Invalid template: {formatted}"
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                return False
            try:
                messagebox.showinfo(
                    "Template Validation",
                    f"Template looks good.\nExample: {formatted}",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return True

        # Closure captures _open_auto_title_template_editor state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_auto_title_template_editor.
        def _apply():
            """Apply value.
            Used to apply value changes to live state."""
            candidate = text.get("1.0", "end").strip()
            if not candidate:
                try:
                    messagebox.showwarning(
                        "Template Validation", "Template cannot be empty."
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                return
            ok, formatted = self._safe_format_template(
                candidate,
                {
                    "type": "Reaction",
                    "day_start": 1,
                    "day_end": 6,
                    "date_start": "1/13",
                    "date_end": "1/19",
                    "start_dt_iso": "2026-01-13",
                    "end_dt_iso": "2026-01-19",
                    "start_year": 2026,
                    "end_year": 2026,
                },
            )
            if not ok:
                try:
                    messagebox.showwarning(
                        "Template Validation", f"Invalid template: {formatted}"
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                return
            self.auto_title_template_var.set(candidate)
            self._update_auto_title_preview()
            _close()

        # Closure captures _open_auto_title_template_editor state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_auto_title_template_editor.
        def _close():
            """Close value.
            Used by UI actions to close value safely."""
            try:
                window.grab_release()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._auto_title_template_window = None

        window.protocol("WM_DELETE_WINDOW", _close)

        ttk.Button(button_frame, text="Validate", command=_validate_template).grid(
            row=0, column=0, padx=(0, 6)
        )
        ttk.Button(button_frame, text="OK", command=_apply).grid(
            row=0, column=1, padx=(0, 6)
        )
        ttk.Button(button_frame, text="Cancel", command=_close).grid(
            row=0, column=2
        )

    def _apply_title_types_update(
        self, types_list: Sequence[str], selected_type: Optional[str]
    ) -> None:
        """Apply title types update.
        Used to apply title types update changes to live state."""
        types = _normalize_title_type_list(types_list)
        settings["title_data_types"] = list(types)
        selected_value = str(selected_type or "").strip()
        matched = None
        if selected_value:
            # Iterate over types to apply the per-item logic.
            for entry in types:
                if entry.casefold() == selected_value.casefold():
                    matched = entry
                    break
        if matched is None:
            matched = types[0]
        settings["title_selected_type"] = matched
        try:
            self.title_data_type_var.set(matched)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        combo = getattr(self, "_title_type_combo", None)
        if combo is not None and combo.winfo_exists():
            try:
                combo.configure(values=list(types))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._update_auto_title_preview()

    def _open_manage_title_types_dialog(self) -> None:
        """Open manage title types dialog.
        Used by UI actions to open manage title types dialog."""
        existing = getattr(self, "_manage_title_types_window", None)
        if existing is not None and existing.winfo_exists():
            try:
                existing.deiconify()
                existing.lift()
                existing.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        window = tk.Toplevel(self)
        window.title("Manage Title Types")
        window.transient(self)
        window.resizable(False, False)
        window.grab_set()
        self._manage_title_types_window = window

        types = list(self._get_title_type_choices())

        ttk.Label(window, text="Data Types:").grid(
            row=0, column=0, columnspan=2, sticky="w", padx=12, pady=(12, 6)
        )

        listbox = tk.Listbox(window, height=8, exportselection=False)
        listbox.grid(row=1, column=0, rowspan=5, sticky="nsew", padx=12, pady=(0, 12))

        button_frame = ttk.Frame(window)
        button_frame.grid(row=1, column=1, sticky="n", padx=(0, 12), pady=(0, 12))

        # Closure captures _open_manage_title_types_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_manage_title_types_dialog.
        def _refresh_listbox(selected: Optional[int] = None) -> None:
            """Refresh listbox.
            Used to sync listbox with current settings."""
            listbox.delete(0, tk.END)
            # Iterate over types to apply the per-item logic.
            for entry in types:
                listbox.insert(tk.END, entry)
            if not types:
                return
            if selected is None:
                selected = 0
            selected = max(0, min(selected, len(types) - 1))
            listbox.selection_clear(0, tk.END)
            listbox.selection_set(selected)
            listbox.activate(selected)
            listbox.see(selected)

        # Closure captures _open_manage_title_types_dialog local context to keep helper logic scoped and invoked directly within _open_manage_title_types_dialog.
        def _selected_index() -> Optional[int]:
            """Perform selected index.
            Used to keep the workflow logic localized and testable."""
            try:
                selection = listbox.curselection()
                return int(selection[0]) if selection else None
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None

        # Closure captures _open_manage_title_types_dialog local context to keep helper logic scoped and invoked directly within _open_manage_title_types_dialog.
        def _normalize_candidate(name: Optional[str]) -> str:
            """Normalize candidate.
            Used to keep candidate consistent across workflows and persistence."""
            return str(name or "").strip()

        # Closure captures _open_manage_title_types_dialog local context to keep helper logic scoped and invoked directly within _open_manage_title_types_dialog.
        def _has_duplicate(name: str, ignore_index: Optional[int] = None) -> bool:
            """Check whether it has duplicate.
            Used to gate conditional behavior in the workflow."""
            key = name.casefold()
            # Iterate over indexed elements from types to apply the per-item logic.
            for idx, entry in enumerate(types):
                if ignore_index is not None and idx == ignore_index:
                    continue
                if entry.casefold() == key:
                    return True
            return False

        # Closure captures _open_manage_title_types_dialog local context to keep helper logic scoped and invoked directly within _open_manage_title_types_dialog.
        def _add_type() -> None:
            """Perform add type.
            Used to keep the workflow logic localized and testable."""
            name = simpledialog.askstring(
                "Add Data Type", "Type name:", parent=window
            )
            name = _normalize_candidate(name)
            if not name:
                return
            if _has_duplicate(name):
                messagebox.showwarning(
                    "Duplicate Type", "Type names must be unique."
                )
                return
            types.append(name)
            _refresh_listbox(len(types) - 1)

        # Closure captures _open_manage_title_types_dialog local context to keep helper logic scoped and invoked directly within _open_manage_title_types_dialog.
        def _rename_type() -> None:
            """Perform rename type.
            Used to keep the workflow logic localized and testable."""
            idx = _selected_index()
            if idx is None:
                messagebox.showinfo("Rename Type", "Select a type to rename.")
                return
            current = types[idx]
            name = simpledialog.askstring(
                "Rename Data Type", "New name:", initialvalue=current, parent=window
            )
            name = _normalize_candidate(name)
            if not name:
                return
            if _has_duplicate(name, ignore_index=idx):
                messagebox.showwarning(
                    "Duplicate Type", "Type names must be unique."
                )
                return
            types[idx] = name
            _refresh_listbox(idx)

        # Closure captures _open_manage_title_types_dialog local context to keep helper logic scoped and invoked directly within _open_manage_title_types_dialog.
        def _delete_type() -> None:
            """Perform delete type.
            Used to keep the workflow logic localized and testable."""
            idx = _selected_index()
            if idx is None:
                messagebox.showinfo("Delete Type", "Select a type to delete.")
                return
            del types[idx]
            if not types:
                types[:] = list(DEFAULT_TITLE_TYPES)
            _refresh_listbox(min(idx, len(types) - 1))

        # Closure captures _open_manage_title_types_dialog local context to keep helper logic scoped and invoked directly within _open_manage_title_types_dialog.
        def _move(delta: int) -> None:
            """Perform move.
            Used to keep the workflow logic localized and testable."""
            idx = _selected_index()
            if idx is None:
                return
            new_idx = idx + delta
            if new_idx < 0 or new_idx >= len(types):
                return
            types[idx], types[new_idx] = types[new_idx], types[idx]
            _refresh_listbox(new_idx)

        ttk.Button(button_frame, text="Add", command=_add_type).grid(
            row=0, column=0, sticky="ew", pady=2
        )
        ttk.Button(button_frame, text="Rename", command=_rename_type).grid(
            row=1, column=0, sticky="ew", pady=2
        )
        ttk.Button(button_frame, text="Delete", command=_delete_type).grid(
            row=2, column=0, sticky="ew", pady=2
        )
        ttk.Button(button_frame, text="Move Up", command=lambda: _move(-1)).grid(
            row=3, column=0, sticky="ew", pady=2
        )
        ttk.Button(button_frame, text="Move Down", command=lambda: _move(1)).grid(
            row=4, column=0, sticky="ew", pady=2
        )

        # Closure captures _open_manage_title_types_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_manage_title_types_dialog.
        def _apply() -> None:
            """Apply value.
            Used to apply value changes to live state."""
            selected_idx = _selected_index()
            selected_value = None
            if selected_idx is not None and selected_idx < len(types):
                selected_value = types[selected_idx]
            self._apply_title_types_update(types, selected_value)
            _close()

        # Closure captures _open_manage_title_types_dialog state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_manage_title_types_dialog.
        def _close() -> None:
            """Close value.
            Used by UI actions to close value safely."""
            try:
                window.grab_release()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._manage_title_types_window = None

        _refresh_listbox(
            types.index(self._resolve_title_type_selection())
            if self._resolve_title_type_selection() in types
            else 0
        )

        window.protocol("WM_DELETE_WINDOW", _close)

        action_frame = ttk.Frame(window)
        action_frame.grid(row=6, column=0, columnspan=2, sticky="e", padx=12, pady=12)
        ttk.Button(action_frame, text="OK", command=_apply).grid(
            row=0, column=0, padx=(0, 6)
        )
        ttk.Button(action_frame, text="Cancel", command=_close).grid(
            row=0, column=1
        )

    def _refresh_gas_preset_choices(self, *, selected=None):
        """Refresh gas preset choices.
        Used to sync gas preset choices with current settings."""
        names = list(BASE_GAS_PRESETS.keys()) or ["Custom"]
        if selected is None:
            try:
                selected = self.v_gas.get()
            except Exception:
                selected = "Custom"
        if selected not in names:
            selected = "Custom"
        combo = getattr(self, "_gas_combo", None)
        if combo is not None and combo.winfo_exists():
            combo.configure(values=names)
        try:
            self.v_gas.set(selected)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._on_gas_selected()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _cycle_temp_choices(self):
        """Perform cycle temp choices.
        Used to keep the workflow logic localized and testable."""

        choices = [CYCLE_TEMP_DEFAULT_LABEL]

        if self.df is not None:

            choices.extend(str(col) for col in self.df.columns)

        return choices

    def _refresh_cycle_temp_choices(self):
        """Refresh cycle temp choices.
        Used to sync cycle temp choices with current settings."""

        combo = getattr(self, "_cycle_temp_combo", None)

        choices = self._cycle_temp_choices()

        desired = (
            self._requested_cycle_temp_column
            or self.cycle_temp_column.get()
            or CYCLE_TEMP_DEFAULT_LABEL
        )

        if combo is not None and combo.winfo_exists():

            combo.configure(values=choices)

        if desired in choices:

            self.cycle_temp_column.set(desired)

            self._requested_cycle_temp_column = desired

            if combo is not None and combo.winfo_exists():

                combo.set(desired)

        else:

            self._requested_cycle_temp_column = desired

            if combo is not None and combo.winfo_exists():

                combo.set(CYCLE_TEMP_DEFAULT_LABEL)

    def _on_toggle_auto_detection(self):
        """Handle toggle auto detection.
        Used as an event callback for toggle auto detection."""

        value = bool(self.auto_detect_cycles.get())
        settings["cycle_auto_detect_enabled"] = value

        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if not self._cycle_ready():
            return

        try:
            self._recompute_cycle_analysis(auto_detect=value, preserve_view=True)
        except Exception as exc:
            print(f"Cycle analysis refresh failed after auto-detect toggle: {exc}")

    def _on_cycle_temp_selected(self, _event=None):
        """Handle cycle temp selected.
        Used as an event callback for cycle temp selected."""

        selection = self.cycle_temp_column.get() or CYCLE_TEMP_DEFAULT_LABEL

        if selection not in self._cycle_temp_choices():

            selection = CYCLE_TEMP_DEFAULT_LABEL

            self.cycle_temp_column.set(selection)

        self._requested_cycle_temp_column = selection

        settings["cycle_temp_column"] = selection

        try:

            _save_settings_to_disk()

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        self._prepare_series_globals()

        if self._cycle_ready():

            try:

                self._recompute_cycle_analysis(auto_detect=False, preserve_view=True)

            except Exception as exc:

                print(f"Cycle analysis refresh failed after temp selection: {exc}")

    def _cycle_summary_missing_conversion_fields(self) -> List[str]:
        """Perform cycle summary missing conversion fields.
        Used to keep the workflow logic localized and testable."""
        missing: List[str] = []
        mass_val = _safe_float(
            getattr(self, "v_starting_mass", None).get()
            if hasattr(self, "v_starting_mass")
            else settings.get("starting_material_mass_g"),
            None,
        )
        if mass_val is None or not math.isfinite(mass_val) or mass_val <= 0.0:
            missing.append("starting_material_mass_g")

        mw_val = _safe_float(
            getattr(self, "v_product_molar_mass", None).get()
            if hasattr(self, "v_product_molar_mass")
            else settings.get("starting_material_mw_g_mol"),
            None,
        )
        if mw_val is None or not math.isfinite(mw_val) or mw_val <= 0.0:
            missing.append("starting_material_mw_g_mol")

        stoich_val = _safe_float(
            getattr(self, "v_starting_stoich", None).get()
            if hasattr(self, "v_starting_stoich")
            else settings.get("stoich_mol_gas_per_mol_starting"),
            None,
        )
        if stoich_val is None or not math.isfinite(stoich_val) or stoich_val <= 0.0:
            missing.append("stoich_mol_gas_per_mol_starting")
        return missing

    def _update_cycle_summary_conversion_status(self) -> None:
        """Update cycle summary conversion status.
        Used to keep cycle summary conversion status in sync with current state."""
        missing = self._cycle_summary_missing_conversion_fields()
        ready = not missing
        if ready:
            status = "Conversion estimate ready: Yes"
        else:
            status = "Conversion estimate ready: No (missing: " + ", ".join(missing) + ")"
        try:
            self._cycle_summary_conversion_status.set(status)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        chk = getattr(self, "_summary_include_conversion_chk", None)
        if chk is not None and chk.winfo_exists():
            chk.configure(state="normal" if ready else "disabled")
        if not ready and self.summary_include_conversion_estimate.get():
            self.summary_include_conversion_estimate.set(False)

    def _build_cycle_summary_from_snapshot(
        self, snapshot: Optional[Dict[str, Any]]
    ) -> Optional[str]:
        """Build cycle summary from snapshot.
        Used to assemble cycle summary from snapshot during UI or plot setup."""
        if not isinstance(snapshot, dict):
            return None
        cycles = snapshot.get("cycles") or []
        per_cycle = snapshot.get("per_cycle") or []
        total_drop = snapshot.get("total_drop_psi", snapshot.get("total_drop"))
        total_moles_ideal = snapshot.get("total_moles_ideal")
        total_moles_vdw = snapshot.get("total_moles_vdw")
        vdw_used = bool(snapshot.get("vdw_used"))
        scipy_available = bool(snapshot.get("scipy_available", fsolve is not None))
        cycle_context = snapshot.get("cycle_context") or {}
        selection_mode = cycle_context.get("selection_mode")
        if not selection_mode:
            if cycle_context.get("manual_only"):
                selection_mode = "Manual-only"
            else:
                selection_mode = "Auto"
        summary_context = {
            "selection_mode": selection_mode,
            "min_cycle_drop_psi": cycle_context.get(
                "min_cycle_drop_psi", cycle_context.get("min_cycle_drop")
            ),
            "ignore_min_drop": cycle_context.get("ignore_min_drop", False),
            "peak_prominence": cycle_context.get("peak_prominence"),
            "peak_distance": cycle_context.get("peak_distance"),
            "peak_width": cycle_context.get("peak_width"),
            "temp_column_label": cycle_context.get(
                "cycle_temp_column",
                settings.get("cycle_temp_column", CYCLE_TEMP_DEFAULT_LABEL),
            ),
            "per_cycle": per_cycle,
            "volume_l": cycle_context.get("volume_l"),
            "a_const": cycle_context.get("vdw_a"),
            "b_const": cycle_context.get("vdw_b"),
            "gas_molar_mass": snapshot.get("gas_molar_mass"),
            "scipy_available": scipy_available,
            "vdw_used": vdw_used,
        }
        resolved_inputs = resolve_cycle_summary_inputs(
            settings, globals_fallback=globals(), context=summary_context
        )
        options = resolve_cycle_summary_options(settings)
        return build_cycle_analysis_summary(
            cycles,
            per_cycle,
            total_drop,
            total_moles_ideal,
            total_moles_vdw,
            vdw_used=vdw_used,
            scipy_available=scipy_available,
            resolved_inputs=resolved_inputs,
            options=options,
        )

    def _refresh_cycle_summary_from_snapshot(self) -> None:
        """Refresh cycle summary from snapshot.
        Used to sync cycle summary from snapshot with current settings."""
        snapshot = getattr(self, "_cycle_last_transfer_payload", None)
        summary = self._build_cycle_summary_from_snapshot(snapshot)
        if not summary:
            return
        self._set_cycle_summary(summary)
        cb = globals().get("update_cycle_summary_callback")
        if callable(cb):
            cb(summary)

    def _on_cycle_summary_formatting_changed(self, *_):
        """Handle cycle summary formatting changed.
        Used as an event callback for cycle summary formatting changed."""
        self._update_cycle_summary_conversion_status()
        self._refresh_cycle_summary_from_snapshot()

    def _get_cycle_temp_series_by_name(self, column_name):
        """Return cycle temp series by name.
        Used to retrieve cycle temp series by name for downstream logic."""

        if not column_name or column_name == CYCLE_TEMP_DEFAULT_LABEL:

            return None

        if self.df is None or column_name not in self.df.columns:

            return None

        return self._get_numeric_series(column_name)

    def _get_cycle_temp_series(self):
        """Return cycle temp series.
        Used to retrieve cycle temp series for downstream logic."""

        name = (
            self.cycle_temp_column.get() if hasattr(self, "cycle_temp_column") else None
        )

        return self._get_cycle_temp_series_by_name(name)

    def _schedule_save_settings(self, delay_ms: int = 250) -> None:
        """Schedule save settings.
        Used to queue save settings without blocking the UI."""

        try:
            after_id = getattr(self, "_save_settings_after_id", None)
            if after_id is not None:
                self.after_cancel(after_id)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:
            self._save_settings_after_id = self.after(
                max(0, int(delay_ms)), self._flush_save_settings
            )
        except Exception:
            self._flush_save_settings()

    def _flush_save_settings(self) -> None:
        """Save settings.
        Used by flush workflows to save settings."""

        after_id = getattr(self, "_save_settings_after_id", None)
        if after_id is not None:
            try:
                self.after_cancel(after_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._save_settings_after_id = None
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _bind_setting_var(
        self,
        var: tk.Variable,
        key: Union[str, Tuple[str, str]],
        *,
        default: Any,
        to_setting: Optional[Callable[[Any], Any]] = None,
        from_setting: Optional[Callable[[Any], Any]] = None,
        on_change: Optional[Callable[[Any], None]] = None,
    ) -> tk.Variable:
        """Perform bind setting var.
        Used to keep the workflow logic localized and testable."""

        container: Dict[str, Any] = settings if isinstance(settings, dict) else {}
        setting_key: Union[str, Tuple[str, str]]
        setting_key = key
        if isinstance(key, (tuple, list)) and len(key) == 2:
            outer_key, inner_key = key
            outer_container = (
                settings.get(outer_key) if isinstance(settings, dict) else {}
            )
            if not isinstance(outer_container, dict):
                outer_container = {}
                if isinstance(settings, dict):
                    settings[outer_key] = outer_container
            container = outer_container
            setting_key = inner_key
        if not isinstance(container, dict):
            container = {}
        try:
            raw_value = container.get(setting_key, default)
        except Exception:
            raw_value = default
        try:
            initial_value = from_setting(raw_value) if from_setting else raw_value
        except Exception:
            initial_value = default
        if isinstance(var, tk.BooleanVar):
            initial_value = bool(initial_value)
        elif isinstance(var, tk.DoubleVar):
            try:
                initial_value = float(initial_value)
            except Exception:
                initial_value = float(default) if default not in (None, "") else 0.0
        else:
            if initial_value is None:
                initial_value = "" if default is None else default
            initial_value = str(initial_value)
        try:
            var.set(initial_value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        def _persist(*_args):
            """Perform persist.
            Used to keep the workflow logic localized and testable."""
            try:
                value = var.get()
            except Exception:
                value = initial_value
            try:
                stored_value = to_setting(value) if to_setting else value
            except Exception:
                stored_value = value
            target_container = container
            if not isinstance(target_container, dict):
                target_container = {}
                if isinstance(key, (tuple, list)) and len(key) == 2:
                    outer_key = key[0]
                    if isinstance(settings, dict):
                        settings[outer_key] = target_container
                elif isinstance(settings, dict) and isinstance(setting_key, str):
                    settings[setting_key] = target_container
            try:
                target_container[setting_key] = stored_value
            except Exception:
                if isinstance(setting_key, str):
                    settings[setting_key] = stored_value
            if on_change is not None:
                try:
                    on_change(value)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            self._schedule_save_settings()

        try:
            var.trace_add("write", _persist)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return var

    def _create_persistent_solubility_var(
        self, key: str, default: str = ""
    ) -> tk.StringVar:
        """Create persistent solubility var.
        Used to instantiate persistent solubility var during setup."""

        settings.setdefault("solubility_inputs", {})
        default_value = "" if default is None else str(default)
        var = tk.StringVar()
        self._bind_setting_var(
            var,
            ("solubility_inputs", key),
            default=default_value,
            to_setting=lambda v: "" if v is None else str(v),
            from_setting=lambda v: "" if v is None else str(v),
        )
        return var

    def _record_solubility_default(self, key: str, default: Optional[str]) -> None:
        """Record a solubility input default value.
        Purpose: Track the default string used for a solubility input field.
        Why: Input persistence logic needs to detect when a field was reset.
        Inputs:
            key (str): Solubility input key to record.
            default (Optional[str]): Default value (string or None).
        Outputs:
            None.
        Side Effects:
            - Updates self._solubility_default_values with the recorded default.
        Exceptions:
            - Best-effort; ignores errors when updating the cache.
        """
        if not key:
            return
        defaults = getattr(self, "_solubility_default_values", None)
        if defaults is None:
            defaults = {}
            self._solubility_default_values = defaults
        try:
            defaults[key] = "" if default is None else str(default)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _create_persistent_solubility_bool(
        self, key: str, default: bool = False
    ) -> tk.BooleanVar:
        """Create persistent solubility bool.
        Used to instantiate persistent solubility bool during setup."""

        settings.setdefault("solubility_inputs", {})
        var = tk.BooleanVar()
        self._bind_setting_var(
            var,
            ("solubility_inputs", key),
            default=bool(default),
            to_setting=lambda v: bool(v),
            from_setting=lambda v: bool(v),
        )
        return var

    def _register_solubility_observer(self, var: Optional[tk.Variable]) -> None:
        """Perform register solubility observer.
        Used to keep the workflow logic localized and testable."""

        if var is None:
            return
        handles = getattr(self, "_sol_observer_handles", None)
        if handles is None:
            handles = []
            self._sol_observer_handles = handles

        # Closure captures _register_solubility_observer local context to keep helper logic scoped and invoked directly within _register_solubility_observer.
        def _notify(*_args):
            """Perform notify.
            Used to keep the workflow logic localized and testable."""
            try:
                self._refresh_sol_mode_guidance()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        try:
            handle = var.trace_add("write", _notify)
            handles.append((var, handle))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _enable_text_mousewheel(self, widget: Optional[tk.Text]) -> None:
        """Perform enable text mousewheel.
        Used to keep the workflow logic localized and testable."""

        if widget is None:
            return

        # Closure captures _enable_text_mousewheel state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _enable_text_mousewheel.
        def _on_mousewheel(event):
            """Handle mousewheel.
            Used as an event callback for mousewheel."""
            delta = event.delta
            if delta == 0:
                return
            step = -1 if delta > 0 else 1
            if abs(delta) >= 120:
                step = int(-delta / 120)
            widget.yview_scroll(step, "units")
            return "break"

        widget.bind("<MouseWheel>", _on_mousewheel, add="+")
        widget.bind(
            "<Button-4>", lambda _event: widget.yview_scroll(-1, "units"), add="+"
        )
        widget.bind(
            "<Button-5>", lambda _event: widget.yview_scroll(1, "units"), add="+"
        )

    def _get_sol_var_float(self, key: str) -> Optional[float]:
        """Return sol var float.
        Used to retrieve sol var float for downstream logic."""

        var = getattr(self, "_solubility_vars", {}).get(key)
        if var is None:
            return None
        raw = var.get().strip()
        if not raw:
            return None
        try:
            value = float(raw)
        except ValueError:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        if not math.isfinite(value):
            return None
        return value

    def _sol_mode_step_complete(self, step_id: str) -> bool:
        """Perform sol mode step complete.
        Used to keep the workflow logic localized and testable."""

        # Closure captures _sol_mode_step_complete local context to keep helper logic scoped and invoked directly within _sol_mode_step_complete.
        def _positive(key: str) -> bool:
            """Perform positive.
            Used to keep the workflow logic localized and testable."""
            value = self._get_sol_var_float(key)
            return value is not None and value > 0

        include_var = getattr(self, "_sol_include_headspace_var", None)
        include_headspace = (
            bool(include_var.get()) if include_var is not None else False
        )
        headspace_ok = (
            include_headspace
            and _positive("headspace_pco2_atm")
            and _positive("headspace_kh_m_per_atm")
        )

        if step_id == "basis_inputs":
            mass_ok = _positive("mass_na_hco3_g")
            solvent_mass = self._get_sol_var_float("water_mass_g")
            solvent_vol = self._get_sol_var_float("solution_volume_l")
            solvent_ok = False
            if solvent_mass is not None and solvent_mass > 0:
                solvent_ok = True
            if solvent_vol is not None and solvent_vol > 0:
                solvent_ok = True
            return mass_ok and solvent_ok
        if step_id == "conditions_ready":
            temp_ok = _positive("temperature_c")
            return temp_ok and (not include_headspace or headspace_ok)
        if step_id == "reaction_charge":
            return _positive("reaction_naoh_mass_g") and _positive(
                "reaction_solution_volume_l"
            )
        if step_id == "goal_defined":
            forced = self._get_sol_var_float("forced_ph_target")
            target = self._get_sol_var_float("reaction_target_ph")
            forced_ok = forced is not None and 0.0 < forced < 14.0
            target_ok = target is not None and 0.0 < target < 14.0
            return forced_ok or target_ok
        if step_id == "co2_or_goal":
            co2 = self._get_sol_var_float("reaction_co2_charged_g")
            return (
                (co2 is not None and co2 >= 0.0)
                or self._sol_mode_step_complete("goal_defined")
                or headspace_ok
            )
        if step_id == "run_ready":
            return getattr(self, "_sol_last_structured", None) is not None
        return False

    def _refresh_sol_mode_guidance(self) -> None:
        """Refresh sol mode guidance.
        Used to sync sol mode guidance with current settings."""

        workflow_key = self._current_solubility_workflow()
        workflow_meta = SOL_WORKFLOW_TEMPLATES.get(workflow_key, {})
        desc_var = getattr(self, "_sol_mode_description_var", None)
        assumption_var = getattr(self, "_sol_mode_assumption_var", None)
        steps_var = getattr(self, "_sol_mode_steps_var", None)
        expectation_var = getattr(self, "_sol_mode_expectation_var", None)
        context_label = getattr(self, "_sol_context_label_var", None)

        if desc_var is not None:
            desc_var.set(
                workflow_meta.get(
                    "description", "Select a workflow to view guided steps."
                )
            )

        if assumption_var is not None:
            assumption = (
                workflow_meta.get("assumption") or "Assumptions will appear here."
            )
            assumption_var.set(assumption)

        if expectation_var is not None:
            expectation = (
                workflow_meta.get("expectations") or "Expectations will appear here."
            )
            expectation_var.set(expectation)

        if steps_var is not None:
            lines = []
            # Iterate over workflow_meta.get("steps", []) to apply the per-item logic.
            for step_id in workflow_meta.get("steps", []):
                label = SOL_MODE_STEP_LABELS.get(step_id, step_id)
                prefix = "[x]" if self._sol_mode_step_complete(step_id) else "[ ]"
                lines.append(f"{prefix} {label}")
            steps_var.set("\n".join(lines) if lines else "No guided steps defined.")

        if (
            context_label is not None
            and getattr(self, "_sol_last_structured", None) is None
        ):
            context_label.set(workflow_meta.get("label", "Select a workflow to begin."))
        self._update_sol_input_prompts()

    def _update_sol_input_prompts(self) -> None:
        """Update sol input prompts.
        Used to keep sol input prompts in sync with current state."""
        prompt_var = getattr(self, "_sol_prompt_var", None)
        if prompt_var is None:
            return
        mode_var = getattr(self, "_sol_mode_var", None)
        mode_key = mode_var.get() if mode_var is not None else SOL_DEFAULT_SIM_MODE
        workflow_key = self._current_solubility_workflow()
        workflow_meta = SOL_WORKFLOW_TEMPLATES.get(workflow_key, {})
        missing: List[str] = []
        tips: List[str] = []

        # Closure captures _update_sol_input_prompts local context to keep helper logic scoped and invoked directly within _update_sol_input_prompts.
        def _positive(key: str) -> bool:
            """Perform positive.
            Used to keep the workflow logic localized and testable."""
            value = self._get_sol_var_float(key)
            return value is not None and value > 0

        # Closure captures _update_sol_input_prompts local context to keep helper logic scoped and invoked directly within _update_sol_input_prompts.
        def _has_range(key: str, low: float, high: float) -> bool:
            """Check whether it has range.
            Used to gate conditional behavior in the workflow."""
            value = self._get_sol_var_float(key)
            if value is None:
                return False
            return low < value < high

        mass_val = self._get_sol_var_float("mass_na_hco3_g")
        mass_naoh_val = self._get_sol_var_float("mass_naoh_g")
        if (mass_val is None or mass_val <= 0) and (
            mass_naoh_val is None or mass_naoh_val <= 0
        ):
            missing.append("Mass NaOH or NaHCO₃")

        diag_slurry = self._get_sol_var_float("diag_slurry_ph")
        diag_mode = mode_key == "contaminated_bicarb_diagnostic"
        require_solvent = not (diag_mode and diag_slurry is None)
        water_val = self._get_sol_var_float("water_mass_g")
        volume_val = self._get_sol_var_float("solution_volume_l")
        if (
            require_solvent
            and (water_val is None or water_val <= 0)
            and (volume_val is None or volume_val <= 0)
        ):
            missing.append("Water mass or final volume")

        if mode_key == "naoh_reaction":
            if not _positive("reaction_naoh_mass_g"):
                missing.append("Initial NaOH mass")
            if not _positive("reaction_solution_volume_l"):
                missing.append("Process liquor volume")
            forced_val = self._get_sol_var_float("forced_ph_target")
            target_val = self._get_sol_var_float("reaction_target_ph")
            co2_val = self._get_sol_var_float("reaction_co2_charged_g")
            include_headspace = bool(
                getattr(self, "_sol_include_headspace_var", tk.BooleanVar()).get()
            )
            headspace_ready = (
                include_headspace
                and _positive("headspace_pco2_atm")
                and _positive("headspace_kh_m_per_atm")
            )
            if not any(
                [
                    co2_val is not None and co2_val >= 0.0,
                    forced_val is not None and 0.0 < forced_val < 14.0,
                    target_val is not None and 0.0 < target_val < 14.0,
                    headspace_ready,
                ]
            ):
                missing.append("CO₂ total, target pH, forced pH, or headspace settings")
        elif mode_key == "contaminated_feed":
            forced_val = self._get_sol_var_float("forced_ph_target")
            target_val = self._get_sol_var_float("reaction_target_ph")
            if not (
                forced_val is not None
                and 0.0 < forced_val < 14.0
                or target_val is not None
                and 0.0 < target_val < 14.0
            ):
                missing.append("Target pH or forced pH")
        elif diag_mode:
            failing_valid = diag_slurry is not None and 0.0 < diag_slurry < 14.5
            if diag_slurry is not None and not failing_valid:
                missing.append("Failing slurry pH must be between 0 and 14.5")
            if not failing_valid:
                missing.append("Failing slurry pH (atm)")
            target_val = self._get_sol_var_float("diag_target_ph")
            if target_val is None or not (0.0 < target_val < 14.0):
                missing.append("Target pass pH")

        workflow_label = workflow_meta.get("label", "Workflow")
        prompt_hint = workflow_meta.get("prompt", "")
        expectation_hint = workflow_meta.get("expectations", "")
        if not missing:
            message = "Inputs ready for this simulation basis."
            if tips:
                message += f" Tips: {'; '.join(tips)}"
        else:
            message = "Provide: " + "; ".join(missing)
            if tips:
                message += f". Optional: {'; '.join(tips)}"
        message = f"{workflow_label}: {message}"
        if prompt_hint:
            message = f"{message} {prompt_hint}"
        if expectation_hint:
            message = f"{message} Expectations: {expectation_hint}"
        prompt_var.set(message)
        self._update_sol_helper_contents()

    def _current_solubility_workflow(self) -> str:
        """Return current solubility workflow.
        Used to surface solubility workflow for downstream logic."""
        notebook = getattr(self, "_sol_workflow_nb", None)
        if notebook is None:
            return SOL_WORKFLOW_DEFAULT
        current = notebook.select()
        if not current:
            return SOL_WORKFLOW_DEFAULT
        text = notebook.tab(current, "text")
        if text in SOL_WORKFLOW_TEMPLATES:
            return text
        return SOL_WORKFLOW_DEFAULT

    def _cycle_state_for(self, workflow_key: Optional[str] = None) -> Dict[str, Any]:
        """Perform cycle state for.
        Used to keep the workflow logic localized and testable."""
        if not hasattr(self, "_sol_cycle_payloads"):
            self._sol_cycle_payloads = {}
        if not hasattr(self, "_sol_cycle_results_map"):
            self._sol_cycle_results_map = {}
        key = workflow_key or self._current_solubility_workflow()
        if key not in self._sol_cycle_payloads:
            self._sol_cycle_payloads[key] = None
        if key not in self._sol_cycle_results_map:
            self._sol_cycle_results_map[key] = None
        return {
            "payload": self._sol_cycle_payloads.get(key),
            "results": self._sol_cycle_results_map.get(key),
        }

    def _set_cycle_payload_for_workflow(
        self, workflow_key: str, payload: Optional[Dict[str, Any]]
    ) -> None:
        """Set cycle payload for workflow.
        Used to persist cycle payload for workflow into the current state."""
        self._cycle_state_for(workflow_key)
        self._sol_cycle_payloads[workflow_key] = payload
        if self._current_solubility_workflow() == workflow_key:
            self._sol_cycle_payload = payload

    def _set_cycle_result_for_workflow(
        self, workflow_key: str, result: Optional[Dict[str, Any]]
    ) -> None:
        """Set cycle result for workflow.
        Used to persist cycle result for workflow into the current state."""
        self._cycle_state_for(workflow_key)
        self._sol_cycle_results_map[workflow_key] = result
        if self._current_solubility_workflow() == workflow_key:
            self._sol_cycle_results = result

    def _get_cycle_payload_for_workflow(
        self, workflow_key: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """Return cycle payload for workflow.
        Used to retrieve cycle payload for workflow for downstream logic."""
        state = self._cycle_state_for(workflow_key)
        return state.get("payload")

    def _get_cycle_result_for_workflow(
        self, workflow_key: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """Return cycle result for workflow.
        Used to retrieve cycle result for workflow for downstream logic."""
        state = self._cycle_state_for(workflow_key)
        return state.get("results")

    def _active_sol_input_guide(
        self,
    ) -> Tuple[str, str, List[Dict[str, Any]], Dict[str, Any]]:
        """Perform active sol input guide.
        Used to keep the workflow logic localized and testable."""
        workflow_key = self._current_solubility_workflow()
        workflow_meta = SOL_WORKFLOW_TEMPLATES.get(workflow_key, {})
        guide_key = workflow_meta.get("guide_mode", SOL_DEFAULT_SIM_MODE)
        guide = SOL_MODE_INPUT_GUIDE.get(guide_key, SOL_MODE_INPUT_GUIDE["default"])
        return workflow_key, guide_key, guide, workflow_meta

    def _update_sol_helper_visibility(self) -> None:
        """Update helper panel visibility and focus-button availability.

        Purpose:
            Show or hide the solubility helper panel based on user preference.
        Why:
            The helper panel is optional, but its focus button state must stay
            consistent across ttk/CTk widgets when the panel is hidden/shown.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Updates `_sol_helper_visible`, toggles helper-frame visibility, and
            disables the helper focus button when helper UI is hidden.
        Exceptions:
            Uses best-effort guards around geometry updates.
        """
        frame = getattr(self, "_sol_helper_frame", None)
        btn = getattr(self, "_sol_helper_focus_btn", None)
        show = bool(
            getattr(self, "_sol_helper_pref_var", tk.BooleanVar(value=True)).get()
        )
        self._sol_helper_visible = show
        if frame is None:
            return
        try:
            if show:
                frame.grid()
            else:
                frame.grid_remove()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if not show and btn is not None:
            self._set_widget_enabled(btn, False)
        if show:
            self._update_sol_helper_contents()

    def _helper_spec_complete(self, spec: Dict[str, Any]) -> bool:
        """Perform helper spec complete.
        Used to keep the workflow logic localized and testable."""
        mode = spec.get("mode", "positive")
        keys = spec.get("keys", [])
        rng = spec.get("range", (0.0, float("inf")))
        optional = bool(spec.get("optional", False))
        workflow_key = self._current_solubility_workflow()
        visible_keys = keys
        if workflow_key == "Planning":
            visible_keys = [key for key in keys if self._planning_field_is_visible(key)]
            if not visible_keys:
                return True

        # Closure captures _helper_spec_complete local context to keep helper logic scoped and invoked directly within _helper_spec_complete.
        def _any_positive() -> bool:
            """Perform any positive.
            Used to keep the workflow logic localized and testable."""
            return any(self._field_positive(key) for key in visible_keys)

        # Closure captures _helper_spec_complete local context to keep helper logic scoped and invoked directly within _helper_spec_complete.
        def _all_positive() -> bool:
            """Perform all positive.
            Used to keep the workflow logic localized and testable."""
            return all(self._field_positive(key) for key in visible_keys)

        # Closure captures _helper_spec_complete local context to keep helper logic scoped and invoked directly within _helper_spec_complete.
        def _any_range() -> bool:
            """Perform any range.
            Used to keep the workflow logic localized and testable."""
            low, high = rng
            return any(self._field_in_range(key, low, high) for key in visible_keys)

        if mode == "positive":
            complete = _all_positive()
        elif mode == "any_positive":
            complete = _any_positive()
        elif mode == "nonempty":
            complete = any(self._field_nonempty(key) for key in keys)
        elif mode == "range":
            complete = _any_range()
        elif mode == "range_any":
            complete = _any_range()
        elif mode == "range_optional":
            if not any(self._field_nonempty(key) for key in visible_keys):
                return True
            complete = _any_range()
        elif mode == "naoh_goal":
            forced = self._get_sol_var_float("forced_ph_target")
            target = self._get_sol_var_float("reaction_target_ph")
            co2 = self._get_sol_var_float("reaction_co2_charged_g")
            include_headspace = bool(
                getattr(self, "_sol_include_headspace_var", tk.BooleanVar()).get()
            )
            headspace_ready = (
                include_headspace
                and self._field_positive("headspace_pco2_atm")
                and self._field_positive("headspace_kh_m_per_atm")
            )
            complete = any(
                [
                    co2 is not None and co2 >= 0.0,
                    forced is not None and 0.0 < forced < 14.0,
                    target is not None and 0.0 < target < 14.0,
                    headspace_ready,
                ]
            )
        else:
            complete = _all_positive()
        if optional:
            return True if not complete else complete
        return complete

    def _field_positive(self, key: str) -> bool:
        """Perform field positive.
        Used to keep the workflow logic localized and testable."""
        value = self._get_sol_var_float(key)
        return value is not None and value > 0

    def _field_nonempty(self, key: str) -> bool:
        """Perform field nonempty.
        Used to keep the workflow logic localized and testable."""
        var = getattr(self, "_solubility_vars", {}).get(key)
        if var is None:
            return False
        return bool(var.get().strip())

    def _field_in_range(self, key: str, low: float, high: float) -> bool:
        """Perform field in range.
        Used to keep the workflow logic localized and testable."""
        value = self._get_sol_var_float(key)
        if value is None:
            return False
        return low < value < high

    def _update_sol_helper_contents(self) -> None:
        """Recompute helper progress text and focus-button state.

        Purpose:
            Refresh guided-step completion status for the active solubility mode.
        Why:
            Users rely on helper progress and next-step focus cues while entering
            workflow inputs, and button state must remain toolkit-compatible.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Updates helper summary/steps textvars, tracks the next incomplete
            step in `_sol_helper_next_spec`, and enables/disables the helper
            focus button.
        Exceptions:
            None.
        """
        summary_var = getattr(self, "_sol_helper_summary_var", None)
        steps_var = getattr(self, "_sol_helper_steps_var", None)
        if summary_var is None or steps_var is None:
            return
        workflow_key = self._current_solubility_workflow()
        workflow_meta = SOL_WORKFLOW_TEMPLATES.get(workflow_key, {})
        guide_key = workflow_meta.get("guide_mode", SOL_DEFAULT_SIM_MODE)
        guide = SOL_MODE_INPUT_GUIDE.get(guide_key, SOL_MODE_INPUT_GUIDE["default"])
        meta_key = workflow_meta.get("mode_key", guide_key)
        meta = SOL_SIMULATION_MODES.get(meta_key, {})
        completed = 0
        required = 0
        lines: List[str] = []
        next_spec: Optional[Dict[str, Any]] = None
        # Iterate over guide to apply the per-item logic.
        for spec in guide:
            label = spec.get("label", "Field")
            if spec.get("optional"):
                label = f"{label} (optional)"
            spec_complete = self._helper_spec_complete(spec)
            if spec_complete and not spec.get("optional"):
                completed += 1
            if not spec.get("optional"):
                required += 1
            prefix = "✓" if spec_complete else "•"
            lines.append(f"{prefix} {label}")
            if not spec_complete and next_spec is None and not spec.get("optional"):
                next_spec = spec
        if required == 0:
            required = len(guide)
        workflow_label = workflow_meta.get("label") or meta.get(
            "label", "Advanced Solubility"
        )
        summary_var.set(
            f"{workflow_label}: {completed}/{required} required steps complete."
        )
        steps_var.set("\n".join(lines) if lines else "No guided steps available.")
        self._sol_helper_next_spec = next_spec
        btn = getattr(self, "_sol_helper_focus_btn", None)
        if btn is not None:
            if self._sol_helper_visible and next_spec is not None:
                self._set_widget_enabled(btn, True)
            else:
                self._set_widget_enabled(btn, False)
        extra_tips: List[str] = []
        if workflow_key == "Analysis":
            extra_tips.append(
                "Import validated cycles or enter CO₂ totals so the per-cycle speciation plot reflects real data."
            )
        elif workflow_key == "Reprocessing":
            extra_tips.extend(
                [
                    "Capture the measured slurry/dried-sample pH and the target pass pH to anchor the diagnosis.",
                    "Use the shared slider to dial the pass pH and then review the CO₂ guidance before applying it.",
                ]
            )
        if extra_tips:
            steps_var.set(
                steps_var.get() + "\n" + "\n".join(f"• {tip}" for tip in extra_tips)
            )

    def _focus_next_sol_helper_step(self) -> None:
        """Perform focus next sol helper step.
        Used to keep the workflow logic localized and testable."""
        spec = getattr(self, "_sol_helper_next_spec", None)
        if not spec:
            return
        # Iterate over spec.get("keys", []) to apply the per-item logic.
        for key in spec.get("keys", []):
            entry = (
                self._solubility_field_meta.get(key, {}).get("entry")
                if hasattr(self, "_solubility_field_meta")
                else None
            )
            if entry is not None:
                try:
                    entry.focus_set()
                    if hasattr(entry, "selection_range"):
                        entry.selection_range(0, "end")
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                return

    def _clear_sol_helper_inputs(self) -> None:
        """Clear sol helper inputs.
        Used to reset sol helper inputs state safely."""
        mode_var = getattr(self, "_sol_mode_var", None)
        mode_key = mode_var.get() if mode_var is not None else SOL_DEFAULT_SIM_MODE
        guide = SOL_MODE_INPUT_GUIDE.get(mode_key, SOL_MODE_INPUT_GUIDE["default"])
        cleared = False
        # Iterate over guide to apply the per-item logic.
        for spec in guide:
            # Iterate over spec.get("keys", []) to apply the per-item logic.
            for key in spec.get("keys", []):
                var = getattr(self, "_solubility_vars", {}).get(key)
                if var is None:
                    continue
                try:
                    var.set("")
                    cleared = True
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        if cleared:
            self._update_sol_input_prompts()

    def _planning_persist_input_keys(self) -> Set[str]:
        """Return planning persistence input keys.
        Purpose: Identify solubility inputs that must persist across Planning runs.
        Why: Planning projections can refresh UI state; preserve user-entered values.
        Inputs:
            None.
        Outputs:
            Set[str]: Input keys to capture and restore.
        Side Effects:
            None.
        Exceptions:
            - Best-effort; returns an empty set on failure.
        """
        try:
            keys: Set[str] = set()
            planning_meta = SOL_WORKFLOW_TEMPLATES.get("Planning", {}) or {}
            keys.update(planning_meta.get("input_include_keys") or [])
            keys.update(
                key
                for key, _label, _required in planning_meta.get("input_extra_fields")
                or []
            )
            keys.add("mass_na_hco3_g")
            keys.add("planning_speciation_ph")
            keys.update(["headspace_pco2_atm", "headspace_kh_m_per_atm"])
            analysis_meta = SOL_WORKFLOW_TEMPLATES.get("Analysis", {}) or {}
            analysis_keys = list(analysis_meta.get("input_include_keys") or [])
            analysis_keys.extend(
                key
                for key, _label, _required in analysis_meta.get("input_extra_fields")
                or []
            )
            for key in analysis_keys:
                if key == "reaction_co2_charged_g":
                    continue
                keys.add(key)
            return keys
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return set()

    def _capture_planning_inputs(self) -> None:
        """Capture Planning inputs for persistence.
        Purpose: Snapshot solubility inputs before executing a Planning run.
        Why: Prevent Planning runs from resetting user-entered values to defaults.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            - Updates self._planning_input_cache with captured values.
            - Sets self._planning_inputs_persisted to True.
        Exceptions:
            - Best-effort; ignores capture failures.
        """
        vars_map = getattr(self, "_solubility_vars", None)
        if not vars_map:
            return
        cache: Dict[str, str] = {}
        # Iterate over planned keys to capture the current entry values.
        for key in self._planning_persist_input_keys():
            var = vars_map.get(key)
            if var is None:
                continue
            try:
                cache[key] = var.get()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                continue
        self._planning_input_cache = cache
        self._planning_inputs_persisted = True

    def _restore_planning_inputs(self) -> None:
        """Restore cached Planning inputs after refresh.
        Purpose: Reapply user-entered Planning values after projection updates.
        Why: Planning runs can rebuild or refresh widgets and reset defaults.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            - Mutates Tk variables for cached solubility input keys.
        Exceptions:
            - Best-effort; ignores restore failures.
        """
        cache = getattr(self, "_planning_input_cache", None)
        if not cache:
            return
        vars_map = getattr(self, "_solubility_vars", None)
        if not vars_map:
            return
        defaults = getattr(self, "_solubility_default_values", {}) or {}
        # Restore only when a field appears reset (empty or default), to avoid
        # overwriting edits made after the planning run completes.
        for key in self._planning_persist_input_keys():
            cached_value = cache.get(key)
            if cached_value is None:
                continue
            var = vars_map.get(key)
            if var is None:
                continue
            try:
                current_value = var.get()
            except Exception:
                current_value = ""
            cached_str = "" if cached_value is None else str(cached_value)
            current_str = "" if current_value is None else str(current_value)
            if not cached_str or current_str == cached_str:
                continue
            default_str = "" if defaults.get(key) is None else str(defaults.get(key))
            if current_str and current_str != default_str:
                continue
            try:
                var.set(cached_str)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _on_toggle_sol_helper_pref(self) -> None:
        """Handle toggle sol helper pref.
        Used as an event callback for toggle sol helper pref."""
        value = bool(self._sol_helper_pref_var.get())
        settings["sol_show_helper"] = value
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._update_sol_helper_visibility()

    def _update_auto_jump_plot_pref(self) -> None:
        """Update auto jump plot pref.
        Used to keep auto jump plot pref in sync with current state."""
        settings["jump_to_plot_after_apply"] = bool(self._auto_jump_plot_var.get())
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _apply_display_mode(self, mode: str, *, persist: bool = True) -> None:
        """Apply the selected UI display mode and persist it if requested.

        Purpose:
            Synchronize the application's visual appearance mode with user
            preferences.
        Why:
            Keeps CTk-based controls readable and consistent across sessions by
            storing one global mode in settings.
        Args:
            mode: Requested display mode key (`"regular"` or `"dark"`).
            persist: True to save the normalized value to disk immediately.
        Returns:
            None.
        Side Effects:
            Updates `settings["ui_display_mode"]`, updates `_display_mode_var`,
            and changes CustomTkinter appearance mode when available.
        Exceptions:
            Uses best-effort guards so appearance updates do not break runtime use.
        """
        normalized_mode = _normalize_ui_display_mode(mode)
        appearance_mode = "dark" if normalized_mode == DISPLAY_MODE_DARK else "light"
        if ctk is not None:
            try:
                ctk.set_appearance_mode(appearance_mode)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        settings["ui_display_mode"] = normalized_mode
        mode_var = getattr(self, "_display_mode_var", None)
        if isinstance(mode_var, tk.StringVar):
            try:
                if mode_var.get() != normalized_mode:
                    mode_var.set(normalized_mode)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if not persist:
            return
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _on_display_mode_changed(self) -> None:
        """Handle display mode changes from Preferences menu selections.

        Purpose:
            React to user mode selections from the Display Mode submenu.
        Why:
            Centralizes mode normalization, appearance application, and persistence
            in one callback to avoid duplicated menu command logic.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Applies mode to CTk, updates settings, and writes settings to disk.
        Exceptions:
            Delegates guarded behavior to `_apply_display_mode`.
        """
        mode_var = getattr(self, "_display_mode_var", None)
        selected = mode_var.get() if isinstance(mode_var, tk.StringVar) else ""
        self._apply_display_mode(selected, persist=True)

    def _build_sol_mode_context(
        self,
        params: SolubilityInputs,
        form_data: Dict[str, Any],
        *,
        workflow_key: Optional[str] = None,
    ) -> Dict[str, str]:
        """Build sol mode context.
        Used to assemble sol mode context during UI or plot setup."""

        mode_var = getattr(self, "_sol_mode_var", None)
        mode_key = mode_var.get() if mode_var is not None else SOL_DEFAULT_SIM_MODE
        meta = SOL_SIMULATION_MODES.get(mode_key, {})
        workflow = (
            workflow_key
            or form_data.get("workflow_key")
            or self._current_solubility_workflow()
        )
        workflow_meta = SOL_WORKFLOW_TEMPLATES.get(workflow, {})

        def _fmt(value: Optional[float], unit: str) -> str:
            """Perform fmt.
            Used to keep the workflow logic localized and testable."""
            if value is None:
                return "unspecified"
            return f"{value:.2f} {unit}"

        starting: str
        goal: str
        if mode_key == "naoh_reaction":
            naoh = form_data.get("reaction_naoh_mass") or 0.0
            liquor = form_data.get("reaction_solution_volume") or 0.0
            co2 = form_data.get("reaction_co2_g")
            target_ph = form_data.get("reaction_target_ph")
            starting = (
                f"{naoh:.1f} g NaOH charged to {liquor:.2f} L liquor. "
                f"Logged CO\u2082: {_fmt(co2, 'g')}."
            )
            if params.headspace_pco2_atm:
                starting += f" Headspace set to {params.headspace_pco2_atm:.2f} atm."
            goal = (
                f"Predict speciation and pH after full conversion toward target pH {target_ph:.2f}."
                if target_ph is not None
                else "Predict speciation/pH for a full conversion with unlimited CO\u2082."
            )
        elif mode_key == "contaminated_feed":
            co2 = form_data.get("reaction_co2_g")
            target_ph = form_data.get("reaction_target_ph")
            forced = form_data.get("forced_target")
            volume = params.volume_l()
            starting = (
                f"{params.mass_na_hco3_g:.1f} g NaHCO\u2083 batch flagged for purification "
                f"in {volume:.2f} L liquor. Logged CO\u2082: {_fmt(co2, 'g')}."
            )
            target_value = forced if forced is not None else target_ph
            if target_value is not None:
                goal = f"Determine CO\u2082/headspace requirements to hit pH {target_value:.2f}."
            else:
                goal = "Determine CO\u2082/headspace requirements to reach the default purity target."
        elif mode_key == "contaminated_bicarb_diagnostic":
            diag = form_data.get("diagnostic_data") or {}
            sample_mass = diag.get("sample_mass_g") or params.mass_na_hco3_g
            measurement_value = diag.get("slurry_ph")
            measurement_label = (
                "Slurry pH" if measurement_value is not None else "Dried sample pH"
            )
            if measurement_value is None:
                measurement_value = diag.get("dried_ph")
            volume = params.volume_l()
            starting = (
                f"{sample_mass:.1f} g NaHCO\u2083 sample flagged at "
                f"{measurement_label} {measurement_value or params.initial_ph_guess:.2f}."
            )
            assumed_water = diag.get("assumed_water_mass_g")
            if assumed_water:
                starting += f" Assumed {assumed_water:.1f} g water for dissolution."
            else:
                starting += f" Slurry basis volume {volume:.2f} L."
            goal = (
                f"Quantify Na\u2082CO\u2083 contamination and CO\u2082 required to reach pH "
                f"{(diag.get('target_ph') or params.initial_ph_guess):.2f}."
            )
        else:
            volume = params.volume_l()
            starting = (
                f"{params.mass_na_hco3_g:.1f} g NaHCO\u2083 dissolving into {volume:.2f} L "
                f"at {params.temperature_c:.1f} \u00b0C."
            )
            if params.headspace_pco2_atm:
                starting += (
                    f" Headspace adds {params.headspace_pco2_atm:.2f} atm CO\u2082."
                )
            else:
                starting += " Headspace contribution disabled."
            forced = form_data.get("forced_target")
            goal = (
                f"Resolve speciation at forced pH {forced:.2f} and report ionic strength."
                if forced is not None
                else "Resolve equilibrium speciation, ionic strength, and carbonate contamination."
            )

        workflow_label = workflow_meta.get(
            "label", meta.get("label", "Advanced Solubility")
        )
        assumption_text = workflow_meta.get("context_assumption") or meta.get(
            "assumption", ""
        )
        starting_text = (workflow_meta.get("context_start") or starting).strip()
        goal_text = (workflow_meta.get("context_goal") or goal).strip()
        return {
            "mode": mode_key,
            "label": workflow_label,
            "starting": starting_text,
            "goal": goal_text,
            "assumption": assumption_text,
        }

    def _generate_chart_data(
        self,
        result: SolubilitySpeciationResult,
        *,
        forced_result: Optional[SolubilitySpeciationResult] = None,
        workflow_key: str = "",
    ) -> Dict[str, Any]:
        """Generate chart data.
        Used to produce chart data outputs for analysis or export."""
        source = (
            forced_result
            if workflow_key == "Planning" and forced_result is not None
            else result
        )
        return {
            "fractions": {
                "labels": ["H2CO3", "HCO3-", "CO3^2-"],
                "values": [
                    source.fractional_carbon.get("H2CO3", 0.0) * 100.0,
                    source.fractional_carbon.get("HCO3-", 0.0) * 100.0,
                    source.fractional_carbon.get("CO3^2-", 0.0) * 100.0,
                ],
            },
            "saturation": {
                "labels": list(source.saturation_indices.keys()),
                "values": list(source.saturation_indices.values()),
            },
        }

    def _build_structured_payload(
        self,
        solver_inputs: SolubilitySolverInputs,
        result: SolubilitySpeciationResult,
        forced_result: Optional[SolubilitySpeciationResult],
        closed_system_result: Optional[SolubilitySpeciationResult],
        measurement_warning: Optional[str],
        measurement_scale: Optional[float],
        reaction_guidance: Optional[Dict[str, Any]],
        sweep_data: List[Dict[str, float]],
        sensitivity_rows: List[Dict[str, str]],
        planner_context: List[str],
        tracking_entries: List[Dict[str, Any]],
        cycle_summary: Dict[str, Any],
        mode_context: Dict[str, str],
        chart_data: Dict[str, Any],
        math_sections: List[Dict[str, Any]],
        math_preview_lines: List[str],
        forced_error: Optional[str],
    ) -> SolubilityStructuredPayload:
        """Build structured payload.
        Used to assemble structured payload during UI or plot setup."""
        ordered_species = ["Na+", "H+", "HCO3-", "CO3^2-", "H2CO3", "OH-"]
        species_rows: List[Dict[str, str]] = []
        # Iterate over ordered_species to apply the per-item logic.
        for species in ordered_species:
            species_rows.append(
                {
                    "species": species,
                    "molar": f"{result.concentrations_m.get(species, 0.0):.6e}",
                    "mass": f"{result.mass_concentrations_g_per_l.get(species, 0.0):.6e}",
                    "moles": f"{result.moles.get(species, 0.0):.6e}",
                    "gamma": f"{result.activity_coefficients.get(species, 1.0):.4f}",
                }
            )
        saturation_rows: List[Dict[str, str]] = []
        # Iterate over items from result.saturation_indices to apply the per-item logic.
        for salt, ratio in result.saturation_indices.items():
            status = "Supersaturated" if ratio > 1.0 else "Stable"
            saturation_rows.append(
                {"salt": salt, "ratio": f"{ratio:.3f}", "status": status}
            )
        warnings: List[str] = list(result.warnings)
        if closed_system_result:
            warnings.extend(
                [f"Closed system: {warn}" for warn in closed_system_result.warnings]
            )
        if measurement_warning:
            warnings.append(measurement_warning)
        if forced_result and forced_result.warnings:
            warnings.extend(
                [
                    f"Forced ({forced_result.ph:.2f}): {warn}"
                    # Iterate to apply the per-item logic.
                    for warn in forced_result.warnings
                ]
            )
        if forced_error:
            warnings.append(forced_error)
        if reaction_guidance and reaction_guidance.get("warnings"):
            warnings.extend(
                [f"Reaction: {msg}" for msg in reaction_guidance["warnings"]]
            )
        if closed_system_result:
            warnings.append(
                "Closed-system equilibrium predicted "
                f"pH {closed_system_result.ph:.2f}; measurement-calibrated "
                f"state anchored at {result.ph:.2f}."
            )
        if measurement_scale is not None and abs(measurement_scale - 1.0) > 0.01:
            delta_pct = (measurement_scale - 1.0) * 100.0
            warnings.append(
                f"Measurement alignment adjusted dissolved NaHCO3 by {delta_pct:+.1f}% "
                f"relative to entered {solver_inputs.params.mass_na_hco3_g:.2f} g."
            )
        alkalinity_value = (
            f"{result.alkalinity_meq_per_l:.1f} meq/L (acid-neutralizing capacity)"
        )
        if closed_system_result:
            alkalinity_value += (
                f" | closed {closed_system_result.alkalinity_meq_per_l:.1f} meq/L"
            )
        charge_value = (
            f"{result.charge_balance_residual:+.2e} mol/L "
            "(positive minus negative ionic charge)"
        )
        ph_value = f"{result.ph:.2f}"
        if closed_system_result:
            ph_value += f" | closed {closed_system_result.ph:.2f}"
        dissolved_val = (
            f"{result.dissolved_mass_na_hco3_g:.2f} g"
            if result.dissolved_mass_na_hco3_g is not None
            else "—"
        )
        solids_val = (
            f"{result.undissolved_mass_na_hco3_g:.2f} g"
            if result.undissolved_mass_na_hco3_g is not None
            else "—"
        )
        highlight_map = {
            "ph": ph_value,
            "ionic_strength": f"{result.ionic_strength:.3e} M",
            "alkalinity": alkalinity_value,
            "carbonate": (
                f"{result.carbonate_as_na2co3_wt_percent:.3f} wt%"
                if result.carbonate_as_na2co3_wt_percent is not None
                else "—"
            ),
            "charge": charge_value,
            "dissolved": dissolved_val,
            "solids": solids_val,
        }
        sweep_rows = [
            {
                "ph": f"{row['ph']:.2f}",
                "hco3_pct": f"{row['hco3_pct']:.2f}",
                "co3_pct": f"{row['co3_pct']:.2f}",
                "h2co3_pct": f"{row['h2co3_pct']:.2f}",
            }
            # Iterate to apply the per-item logic.
            for row in sweep_data
        ]
        assumptions: List[str] = []
        seen: Set[str] = set()
        # Iterate to apply the per-item logic.
        for bucket in (
            result.assumptions,
            forced_result.assumptions if forced_result else [],
        ):
            # Iterate over bucket to apply the per-item logic.
            for note in bucket:
                if note not in seen:
                    seen.add(note)
                    assumptions.append(note)
        if reaction_guidance:
            # Iterate over reaction_guidance.get("notes", []) to apply the per-item logic.
            for note in reaction_guidance.get("notes", []):
                tagged = f"Reaction note: {note}"
                if tagged not in seen:
                    seen.add(tagged)
                    assumptions.append(tagged)
        if (
            solver_inputs.mode_key == "contaminated_bicarb_diagnostic"
            and solver_inputs.diagnostic_data
        ):
            assumed_water = solver_inputs.diagnostic_data.get("assumed_water_mass_g")
            sample_mass = solver_inputs.diagnostic_data.get("sample_mass_g")
            if assumed_water:
                note = (
                    f"Assumed {assumed_water:.1f} g water to dissolve "
                    f"{sample_mass or 0.0:.1f} g sample (no slurry pH provided)."
                )
            else:
                note = "Atmospheric slurry pH used directly for the diagnostic seed."
            if note not in seen:
                seen.add(note)
                assumptions.append(note)
        if solver_inputs.assumed_solution_volume_l:
            note = (
                f"Assumed {solver_inputs.assumed_solution_volume_l:.1f} L slurry volume "
                "for the reprocessing scenario."
            )
            if note not in seen:
                seen.add(note)
                assumptions.append(note)
        if closed_system_result:
            note = (
                f"Measurement-calibrated basis at pH {result.ph:.2f}; "
                f"closed-system prediction {closed_system_result.ph:.2f} kept for context."
            )
            if note not in seen:
                seen.add(note)
                assumptions.append(note)
        if measurement_scale is not None and abs(measurement_scale - 1.0) > 0.01:
            note = (
                f"Effective dissolved mass scaled by {measurement_scale:.3f}x "
                f"to match measured alkalinity."
            )
            if note not in seen:
                seen.add(note)
                assumptions.append(note)
        reprocessing_context = (
            reaction_guidance.get("reprocessing_workflow")
            if reaction_guidance
            else None
        )
        payload = SolubilityStructuredPayload(
            highlights=highlight_map,
            warnings=warnings,
            species_rows=species_rows,
            saturation_rows=saturation_rows,
            sensitivity_rows=sensitivity_rows,
            sweep_rows=sweep_rows,
            sweep_plot=sweep_data,
            assumptions=assumptions,
            chart_data=chart_data,
            reaction_guidance=reaction_guidance,
            tracking_entries=tracking_entries,
            cycle_timeline=cycle_summary.get("timeline"),
            planner_context=planner_context,
            math_sections=math_sections,
            math_preview_lines=math_preview_lines,
            mode_context=mode_context,
            workflow_key=solver_inputs.workflow_key,
            guide_key=solver_inputs.guide_key,
            assumed_solution_volume_l=solver_inputs.assumed_solution_volume_l,
            reprocessing_context=reprocessing_context,
        )
        return payload

    def _init_solubility_styles(self) -> None:
        """Initialize solubility styles.
        Used to configure solubility styles at creation time."""
        style = ttk.Style(self)
        try:
            base_font = tkfont.nametofont("TkDefaultFont")
        except Exception:
            base_font = None
        highlight_font = None
        help_font = None
        field_label_font = None
        field_help_font = None
        if base_font is not None:
            highlight_font = base_font.copy()
            highlight_font.configure(weight="bold")
            help_font = base_font.copy()
            help_font.configure(size=max(base_font.cget("size") - 1, 8))
            field_label_font = base_font.copy()
            field_label_font.configure(weight="bold")
            field_help_font = base_font.copy()
            field_help_font.configure(size=max(base_font.cget("size") - 2, 8))
        style.configure(
            "Sol.Highlight.TLabel",
            font=highlight_font,
            padding=(2, 0),
        )
        style.configure(
            "Sol.Help.TLabel",
            foreground="#555555",
            font=help_font,
            padding=(0, 0),
        )
        style.configure(
            "Sol.FieldLabel.TLabel",
            font=field_label_font,
            padding=(0, 0),
        )
        style.configure(
            "Sol.FieldHelp.TLabel",
            foreground="#777777",
            font=field_help_font,
            padding=(0, 0),
        )
        style.configure(
            "Sol.Warning.TLabel",
            foreground="#b22222",
            font=highlight_font,
            padding=(0, 2),
        )

    def _build_tab_solubility(self):
        """Build tab solubility.
        Used to assemble tab solubility during UI or plot setup."""
        frame = self.tab_solubility

        frame.grid_columnconfigure(0, weight=1)
        frame.grid_rowconfigure(0, weight=0)
        frame.grid_rowconfigure(1, weight=1)

        settings_container = ttk.Frame(frame)
        settings_container.grid(row=0, column=0, sticky="nsew")
        settings_container.grid_columnconfigure(0, weight=1)
        settings_container.grid_rowconfigure(0, weight=1)

        settings_canvas = tk.Canvas(settings_container, highlightthickness=0)
        settings_canvas.grid(row=0, column=0, sticky="nsew", padx=(12, 0), pady=(12, 6))

        settings_scrollbar = ttk.Scrollbar(
            settings_container, orient="vertical", command=settings_canvas.yview
        )
        settings_scrollbar.grid(
            row=0, column=1, sticky="ns", padx=(0, 12), pady=(12, 6)
        )

        settings_canvas.configure(yscrollcommand=settings_scrollbar.set, height=520)

        settings_frame = ttk.Frame(settings_canvas)
        settings_window = settings_canvas.create_window(
            (0, 0), window=settings_frame, anchor="nw"
        )

        # Closure captures _build_tab_solubility state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_tab_solubility.
        def _refresh_scroll_region(_event):
            """Refresh scroll region.
            Used to sync scroll region with current settings."""
            settings_canvas.configure(scrollregion=settings_canvas.bbox("all"))

        settings_frame.bind("<Configure>", _refresh_scroll_region)

        # Closure captures _build_tab_solubility local context to keep helper logic scoped and invoked directly within _build_tab_solubility.
        def _expand_settings_width(event):
            """Perform expand settings width.
            Used to keep the workflow logic localized and testable."""
            settings_canvas.itemconfigure(settings_window, width=event.width)

        settings_canvas.bind("<Configure>", _expand_settings_width)

        # Closure captures _build_tab_solubility state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_tab_solubility.
        def _on_mousewheel(event):
            """Handle mousewheel.
            Used as an event callback for mousewheel."""
            delta = event.delta
            if delta == 0:
                return
            step = -1 if delta > 0 else 1
            if abs(delta) >= 120:
                step = int(-delta / 120)
            settings_canvas.yview_scroll(step, "units")
            return "break"

        # Closure captures _build_tab_solubility local context to keep helper logic scoped and invoked directly within _build_tab_solubility.
        def _bind_mousewheel(widget):
            """Perform bind mousewheel.
            Used to keep the workflow logic localized and testable."""
            widget.bind("<MouseWheel>", _on_mousewheel, add="+")
            widget.bind(
                "<Button-4>",
                lambda _event: settings_canvas.yview_scroll(-1, "units"),
                add="+",
            )
            widget.bind(
                "<Button-5>",
                lambda _event: settings_canvas.yview_scroll(1, "units"),
                add="+",
            )
            # Iterate over widget.winfo_children() to apply the per-item logic.
            for child in widget.winfo_children():
                _bind_mousewheel(child)

        # Closure captures _build_tab_solubility local context to keep helper logic scoped and invoked directly within _build_tab_solubility.
        def _init_scroll_bindings():
            """Initialize scroll bindings.
            Used to configure scroll bindings at creation time."""
            _bind_mousewheel(settings_canvas)
            _bind_mousewheel(settings_frame)

        self.after_idle(_init_scroll_bindings)

        settings_frame.grid_columnconfigure(0, weight=1)
        settings_frame.grid_rowconfigure(3, weight=1)

        ttk.Label(
            settings_frame,
            text=(
                "Model sodium bicarbonate dissolution, speciation, and ionic strength "
                "using Debye-Hückel activity corrections."
            ),
            wraplength=850,
            justify="left",
        ).grid(row=0, column=0, sticky="w", padx=0, pady=(0, 6))

        model_selector = ttk.Frame(settings_frame)
        model_selector.grid(row=1, column=0, sticky="ew", padx=0, pady=(0, 2))
        ttk.Label(model_selector, text="Speciation Model").pack(
            side="left", padx=(0, 8)
        )
        available_models = list_speciation_models()
        if not available_models:
            available_models = [get_speciation_model(None)]
        self._sol_model_display_map = OrderedDict(
            (f"{model.label} [{model.key}]", model.key) for model in available_models
        )
        current_label = next(
            (
                label
                # Iterate to apply the per-item logic.
                for label, key in self._sol_model_display_map.items()
                if key == getattr(self, "_sol_model_key", DEFAULT_SPEC_MODEL_KEY)
            ),
            next(iter(self._sol_model_display_map.keys())),
        )
        self._sol_model_var = tk.StringVar(value=current_label)
        self._sol_model_combo = ttk.Combobox(
            model_selector,
            textvariable=self._sol_model_var,
            values=list(self._sol_model_display_map.keys()),
            state="readonly",
            width=32,
        )
        self._sol_model_combo.pack(side="left")
        self._sol_model_combo.bind("<<ComboboxSelected>>", self._on_select_sol_model)
        self._sol_model_info_var = tk.StringVar(value="")
        ttk.Label(
            settings_frame,
            textvariable=self._sol_model_info_var,
            style="Sol.Help.TLabel",
            wraplength=850,
            justify="left",
        ).grid(row=2, column=0, sticky="ew", padx=0, pady=(0, 4))
        self._solvent_mode_var = self._create_persistent_solubility_var(
            "solvent_basis_mode", "mass"
        )
        self._register_solubility_observer(self._solvent_mode_var)
        self._refresh_sol_model_info()

        planning_frame = ttk.Frame(settings_frame)
        planning_frame.grid(row=3, column=0, sticky="nsew", padx=0, pady=0)
        planning_frame.grid_columnconfigure(0, weight=1)

        analysis_frame = ttk.Frame(settings_frame)
        analysis_frame.grid(row=4, column=0, sticky="nsew", padx=0, pady=(6, 0))
        analysis_frame.grid_columnconfigure(0, weight=1)
        analysis_frame.grid_columnconfigure(1, weight=1)

        reprocessing_frame = ttk.Frame(settings_frame)
        reprocessing_frame.grid(row=5, column=0, sticky="nsew", padx=0, pady=6)
        reprocessing_frame.grid_columnconfigure(0, weight=1)

        mode_box = ttk.LabelFrame(planning_frame, text="Simulation Basis & Guidance")
        mode_box.grid(row=0, column=0, sticky="ew", padx=0, pady=6)
        mode_box.grid_columnconfigure(0, weight=1)
        mode_box.grid_columnconfigure(1, weight=0)
        self._sol_mode_var = self._create_persistent_solubility_var(
            "sol_simulation_mode", SOL_DEFAULT_SIM_MODE
        )
        self._register_solubility_observer(self._sol_mode_var)
        rb_frame = ttk.Frame(mode_box)
        rb_frame.grid(row=0, column=0, sticky="w", padx=8, pady=(4, 2))
        # Iterate over indexed elements from SOL_SIMULATION_MODES.items( to apply the per-item logic.
        for idx, (mode_key, meta) in enumerate(SOL_SIMULATION_MODES.items()):
            ttk.Radiobutton(
                rb_frame,
                text=meta.get("label", mode_key),
                value=mode_key,
                variable=self._sol_mode_var,
                command=self._refresh_sol_mode_guidance,
            ).grid(row=idx, column=0, sticky="w", pady=1)
        ttk.Button(
            mode_box,
            text="Mode Details",
            command=self._open_sol_mode_details,
        ).grid(row=0, column=1, sticky="ne", padx=8, pady=(4, 2))
        self._sol_mode_description_var = tk.StringVar(
            value="Select a simulation basis to view guided steps."
        )
        ttk.Label(
            mode_box,
            textvariable=self._sol_mode_description_var,
            style="Sol.Help.TLabel",
            wraplength=1700,
            justify="left",
        ).grid(row=1, column=0, sticky="ew", padx=8, pady=(2, 2))
        self._sol_mode_assumption_var = tk.StringVar(
            value="Assumptions will appear here."
        )
        ttk.Label(
            mode_box,
            textvariable=self._sol_mode_assumption_var,
            style="Sol.Help.TLabel",
            wraplength=1700,
            justify="left",
        ).grid(row=2, column=0, sticky="ew", padx=8, pady=(0, 2))
        self._sol_mode_steps_var = tk.StringVar(
            value="Guided steps will appear after selecting a mode."
        )
        ttk.Label(
            mode_box,
            textvariable=self._sol_mode_steps_var,
            justify="left",
            wraplength=1700,
        ).grid(row=3, column=0, sticky="ew", padx=8, pady=(0, 4))
        self._sol_prompt_var = tk.StringVar(
            value="Provide required inputs to unlock each simulation basis."
        )
        ttk.Label(
            mode_box,
            textvariable=self._sol_prompt_var,
            style="Sol.Warning.TLabel",
            wraplength=1700,
            justify="left",
        ).grid(row=4, column=0, sticky="ew", padx=8, pady=(0, 4))
        sol_defaults = DEFAULT_SOLUBILITY_INPUTS

        # Closure captures _build_tab_solubility local context to keep helper logic scoped and invoked directly within _build_tab_solubility.
        def _default(value):
            """Return default value.
            Used when callers need a safe fallback."""
            return "" if value is None else str(value)

        self._sol_helper_frame = ttk.LabelFrame(
            planning_frame, text="Guided Input Helper"
        )
        self._sol_helper_frame.grid(row=1, column=0, sticky="ew", padx=0, pady=6)
        self._sol_helper_frame.grid_columnconfigure(0, weight=1)
        self._sol_helper_summary_var = tk.StringVar(
            value="Select a simulation basis to see required inputs."
        )
        ttk.Label(
            self._sol_helper_frame,
            textvariable=self._sol_helper_summary_var,
            style="Sol.Help.TLabel",
            wraplength=1700,
            justify="left",
        ).grid(row=0, column=0, sticky="ew", padx=8, pady=(4, 2))
        self._sol_helper_steps_var = tk.StringVar(
            value="Checklist will appear after selecting a mode."
        )
        ttk.Label(
            self._sol_helper_frame,
            textvariable=self._sol_helper_steps_var,
            justify="left",
            wraplength=1700,
        ).grid(row=1, column=0, sticky="ew", padx=8, pady=(0, 4))
        helper_btns = ttk.Frame(self._sol_helper_frame)
        helper_btns.grid(row=2, column=0, sticky="ew", padx=8, pady=(0, 6))
        helper_btns.grid_columnconfigure(0, weight=0)
        helper_btns.grid_columnconfigure(1, weight=0)
        self._sol_helper_focus_btn = ttk.Button(
            helper_btns,
            text="Focus Next Field",
            command=self._focus_next_sol_helper_step,
            state="disabled",
        )
        self._sol_helper_focus_btn.grid(row=0, column=0, sticky="w")
        ttk.Button(
            helper_btns,
            text="Clear Inputs",
            command=self._clear_sol_helper_inputs,
        ).grid(row=0, column=1, sticky="w", padx=(8, 0))
        self._sol_helper_next_spec: Optional[Dict[str, Any]] = None
        self._update_sol_helper_visibility()

        input_box = ttk.LabelFrame(planning_frame, text="Input Parameters")
        input_box.grid(row=2, column=0, sticky="ew", padx=0, pady=6)
        input_box.grid_columnconfigure(1, weight=1)

        specs = [
            (
                "mass_na_hco3_g",
                "Mass NaHCO\u2083 (g)",
                _default(sol_defaults.mass_na_hco3_g),
                True,
            ),
            (
                "water_mass_g",
                "Water mass (g)",
                _default(sol_defaults.water_mass_g),
                False,
            ),
            (
                "solution_volume_l",
                "Total liquid volume after dissolution (L)",
                _default(sol_defaults.solution_volume_l),
                False,
            ),
            (
                "temperature_c",
                "Temperature (deg C)",
                _default(sol_defaults.temperature_c),
                True,
            ),
            (
                "initial_ph_guess",
                "Initial pH guess",
                _default(sol_defaults.initial_ph_guess),
                True,
            ),
        ]

        self._solubility_vars = {}
        self._solubility_field_meta = {}
        self._sol_observer_handles = []

        row_cursor = 0
        # Iterate over specs to apply the per-item logic.
        for key, label, default, required in specs:
            ttk.Label(input_box, text=label).grid(
                row=row_cursor, column=0, sticky="w", padx=(8, 8), pady=2
            )
            var = self._create_persistent_solubility_var(key, default)
            self._record_solubility_default(key, default)
            entry = ttk.Entry(input_box, textvariable=var)
            entry.grid(row=row_cursor, column=1, sticky="ew", padx=(0, 8), pady=2)
            self._solubility_vars[key] = var
            self._register_solubility_observer(var)
            self._solubility_field_meta[key] = {
                "label": label,
                "required": required,
                "entry": entry,
            }
            row_cursor += 1
            help_text = SOL_MODE_FIELD_HELP.get(key)
            if help_text:
                ttk.Label(
                    input_box,
                    text=help_text,
                    style="Sol.Help.TLabel",
                    wraplength=1700,
                    justify="left",
                ).grid(
                    row=row_cursor,
                    column=0,
                    columnspan=2,
                    sticky="w",
                    padx=(8, 8),
                    pady=(0, 4),
                )
                row_cursor += 1

        ttk.Label(
            input_box,
            text=(
                "Provide either a water mass or a final solution volume. The chosen basis "
                "auto-calculates the other field using 25 °C density."
            ),
            wraplength=1700,
            justify="left",
        ).grid(
            row=row_cursor,
            column=0,
            columnspan=2,
            sticky="w",
            padx=8,
            pady=(4, 8),
        )

        solvent_box = ttk.LabelFrame(planning_frame, text="Solvent Basis")
        solvent_box.grid(row=3, column=0, sticky="ew", padx=0, pady=6)
        solvent_var = getattr(self, "_solvent_mode_var", None)
        if solvent_var is None:
            solvent_var = self._create_persistent_solubility_var(
                "solvent_basis_mode", "mass"
            )
            self._register_solubility_observer(solvent_var)
            self._solvent_mode_var = solvent_var
        ttk.Radiobutton(
            solvent_box,
            text="Specify solvent by water mass",
            value="mass",
            variable=solvent_var,
            command=self._apply_solvent_basis_state,
        ).grid(row=0, column=0, sticky="w", padx=8, pady=2)
        ttk.Radiobutton(
            solvent_box,
            text="Specify solvent by final volume",
            value="volume",
            variable=solvent_var,
            command=self._apply_solvent_basis_state,
        ).grid(row=0, column=1, sticky="w", padx=8, pady=2)

        preset_box = ttk.LabelFrame(
            planning_frame, text="Scenario Presets & Management"
        )
        preset_box.grid(row=4, column=0, sticky="ew", padx=0, pady=6)
        preset_box.grid_columnconfigure(1, weight=1)

        ttk.Label(
            preset_box,
            text="Load curated presets or save your own scenarios for quick recall.",
            style="Sol.Help.TLabel",
            wraplength=1700,
            justify="left",
        ).grid(row=0, column=0, columnspan=3, sticky="w", padx=8, pady=(4, 2))

        self._sol_preset_combo = ttk.Combobox(preset_box, state="readonly", width=28)
        self._sol_preset_combo.grid(
            row=1, column=0, columnspan=2, sticky="ew", padx=8, pady=2
        )
        self._sol_preset_combo.bind(
            "<<ComboboxSelected>>", self._on_select_solubility_preset
        )
        ttk.Button(
            preset_box,
            text="Load Preset",
            command=self._load_selected_solubility_preset,
        ).grid(row=1, column=2, sticky="ew", padx=8, pady=2)

        self._sol_preset_description_var = tk.StringVar(
            value="Select a preset to view its description."
        )
        ttk.Label(
            preset_box,
            textvariable=self._sol_preset_description_var,
            style="Sol.Help.TLabel",
            wraplength=520,
            justify="left",
        ).grid(row=2, column=0, columnspan=3, sticky="w", padx=8, pady=(0, 6))

        ttk.Label(preset_box, text="Save current inputs as:").grid(
            row=3, column=0, sticky="w", padx=(8, 2), pady=2
        )
        self._sol_scenario_name_var = tk.StringVar()
        ttk.Entry(preset_box, textvariable=self._sol_scenario_name_var).grid(
            row=3, column=1, sticky="ew", padx=(0, 8), pady=2
        )
        ttk.Button(
            preset_box, text="Save Scenario", command=self._save_solubility_scenario
        ).grid(row=3, column=2, sticky="ew", padx=8, pady=2)

        ttk.Label(
            analysis_frame,
            text="Use these inputs when projecting NaOH conversion or reviewing Cycle Analysis transfers.",
            style="Sol.Help.TLabel",
            wraplength=1700,
            justify="left",
        ).grid(row=0, column=0, sticky="w", padx=0, pady=(6, 0))
        reaction_box = ttk.LabelFrame(
            analysis_frame, text="NaOH + CO\u2082 Reaction Inputs"
        )
        reaction_box.grid(row=1, column=0, columnspan=2, sticky="ew", padx=0, pady=6)
        reaction_box.grid_columnconfigure(1, weight=1)
        reaction_specs = [
            (
                "reaction_naoh_mass_g",
                "Initial NaOH mass (g)",
                "80.0",
                False,
                "Mass of solid NaOH charged to the 2 L make-up.",
            ),
            (
                "reaction_solution_volume_l",
                "Process liquor volume (L)",
                "2.0",
                False,
                "Total liquid volume used for the NaOH charge (default 2 L).",
            ),
            (
                "reaction_co2_charged_g",
                "CO\u2082 added so far (g)",
                "",
                False,
                "Running total of gaseous CO\u2082 fed to the batch.",
            ),
            (
                "reaction_final_ph",
                "Measured final pH",
                "",
                False,
                "Optional final product pH measurement.",
            ),
            (
                "reaction_slurry_ph",
                "Measured slurry pH",
                "",
                False,
                "Optional slurry pH mid-process.",
            ),
            (
                "reaction_target_ph",
                "Target pH",
                "8.0",
                False,
                "Desired acceptance pH for the finished bicarbonate.",
            ),
        ]
        reaction_row = 0
        # Iterate over reaction_specs to apply the per-item logic.
        for key, label, default, required, help_text in reaction_specs:
            ttk.Label(reaction_box, text=label).grid(
                row=reaction_row, column=0, sticky="w", padx=(8, 8), pady=2
            )
            var = self._create_persistent_solubility_var(key, default)
            self._record_solubility_default(key, default)
            entry = ttk.Entry(reaction_box, textvariable=var)
            entry.grid(row=reaction_row, column=1, sticky="ew", padx=(0, 8), pady=2)
            self._solubility_vars[key] = var
            self._register_solubility_observer(var)
            self._solubility_field_meta[key] = {
                "label": label,
                "required": required,
                "entry": entry,
            }
            reaction_row += 1
            if help_text:
                ttk.Label(
                    reaction_box,
                    text=help_text,
                    style="Sol.Help.TLabel",
                    wraplength=520,
                    justify="left",
                ).grid(
                    row=reaction_row,
                    column=0,
                    columnspan=2,
                    sticky="w",
                    padx=(8, 8),
                    pady=(0, 4),
                )
                reaction_row += 1

        ttk.Label(
            reprocessing_frame,
            text="Run diagnostics and reprocessing scenarios when batches fail pH checks.",
            style="Sol.Help.TLabel",
            wraplength=1700,
            justify="left",
        ).grid(row=0, column=0, sticky="w", padx=0, pady=(6, 0))
        diagnostic_box = ttk.LabelFrame(
            reprocessing_frame, text="Contaminated NaHCO\u2083 Diagnostic Inputs"
        )
        diagnostic_box.grid(row=1, column=0, sticky="ew", padx=0, pady=6)
        diagnostic_box.grid_columnconfigure(1, weight=1)
        diagnostic_specs = [
            (
                "diag_dried_sample_ph",
                "Dried sample pH (if no slurry reading)",
                "9.10",
                False,
                (
                    "Measured pH of the dried NaHCO\u2083 sample that failed QA. "
                    "Used when slurry pH is unavailable."
                ),
            ),
            (
                "diag_slurry_ph",
                "Atmospheric slurry pH (optional)",
                "",
                False,
                (
                    "Open-system slurry pH measured after venting CO\u2082. "
                    "Provides the most accurate speciation input."
                ),
            ),
            (
                "diag_sample_mass_g",
                "Dried sample mass (g, for dried pH only)",
                "5.0",
                False,
                (
                    "Mass of the solid that yielded the dried-sample pH measurement. "
                    "Leave blank when only a slurry pH measurement is provided."
                ),
            ),
            (
                "diag_slurry_degas_pct",
                "CO\u2082 vented fraction (%)",
                "10.0",
                False,
                (
                    "Percent of inorganic carbon assumed to leave as CO\u2082 gas "
                    "when venting prior to the slurry pH reading. "
                    "Set to zero when no degassing occurred."
                ),
            ),
            (
                "diag_target_ph",
                "Target pass pH",
                "8.00",
                False,
                "Desired acceptance pH for the corrected NaHCO\u2083 batch.",
            ),
        ]
        diag_row = 0
        # Iterate over diagnostic_specs to apply the per-item logic.
        for key, label, default, required, help_text in diagnostic_specs:
            ttk.Label(diagnostic_box, text=label).grid(
                row=diag_row, column=0, sticky="w", padx=(8, 8), pady=2
            )
            var = self._create_persistent_solubility_var(key, default)
            self._record_solubility_default(key, default)
            entry = ttk.Entry(diagnostic_box, textvariable=var)
            entry.grid(row=diag_row, column=1, sticky="ew", padx=(0, 8), pady=2)
            self._solubility_vars[key] = var
            self._register_solubility_observer(var)
            self._solubility_field_meta[key] = {
                "label": label,
                "required": required,
                "entry": entry,
            }
            diag_row += 1
            if help_text:
                ttk.Label(
                    diagnostic_box,
                    text=help_text,
                    style="Sol.Help.TLabel",
                    wraplength=520,
                    justify="left",
                ).grid(
                    row=diag_row,
                    column=0,
                    columnspan=2,
                    sticky="w",
                    padx=(8, 8),
                    pady=(0, 4),
                )
                diag_row += 1
        ttk.Label(
            diagnostic_box,
            text=(
                "Slurry pH is optional but yields a more accurate speciation snapshot. "
                "If omitted, the dried-sample pH seeds the solver."
            ),
            style="Sol.Help.TLabel",
            wraplength=850,
            justify="left",
        ).grid(row=diag_row, column=0, columnspan=2, sticky="w", padx=8, pady=(0, 4))
        diag_row += 1
        try:
            diag_slider_value = float(
                self._solubility_vars["diag_target_ph"].get() or 8.0
            )
        except ValueError:
            diag_slider_value = 8.0
        self._diag_target_slider = tk.DoubleVar(value=diag_slider_value)
        ttk.Scale(
            diagnostic_box,
            from_=6.5,
            to=9.0,
            orient="horizontal",
            variable=self._diag_target_slider,
            command=self._on_diag_target_slider,
        ).grid(row=diag_row, column=0, columnspan=2, sticky="ew", padx=8, pady=(2, 4))
        self._solubility_vars["diag_target_ph"].trace_add(
            "write", self._sync_diag_target_slider_from_entry
        )

        forced_box = ttk.LabelFrame(planning_frame, text="Forced pH Scenario")
        forced_box.grid(row=5, column=0, sticky="ew", padx=0, pady=6)
        forced_var = self._create_persistent_solubility_var("forced_ph_target", "")
        self._solubility_vars["forced_ph_target"] = forced_var
        self._register_solubility_observer(forced_var)
        self._solubility_field_meta["forced_ph_target"] = {
            "label": "Forced pH target",
            "required": False,
        }
        ttk.Label(forced_box, text="Forced pH target").grid(
            row=0, column=0, sticky="w", padx=8, pady=2
        )
        forced_entry = ttk.Entry(forced_box, textvariable=forced_var, width=10)
        forced_entry.grid(row=0, column=1, sticky="w", padx=(0, 8), pady=2)
        slider_value = sol_defaults.initial_ph_guess
        try:
            slider_value = float(forced_var.get() or slider_value)
        except ValueError:
            slider_value = sol_defaults.initial_ph_guess
        self._sol_forced_slider = tk.DoubleVar(value=slider_value)
        ttk.Scale(
            forced_box,
            from_=4.0,
            to=12.0,
            orient="horizontal",
            variable=self._sol_forced_slider,
            command=self._on_solubility_forced_slider,
        ).grid(row=0, column=2, sticky="ew", padx=8, pady=2)
        forced_box.grid_columnconfigure(2, weight=1)
        forced_var.trace_add("write", self._sync_target_slider_from_entry)

        advanced_box = ttk.LabelFrame(planning_frame, text="Advanced Options")
        advanced_box.grid(row=6, column=0, sticky="ew", padx=0, pady=6)
        advanced_box.grid_columnconfigure(1, weight=1)

        self._sol_use_temp_adjust_var = self._create_persistent_solubility_bool(
            "use_temp_adjust", False
        )
        ttk.Checkbutton(
            advanced_box,
            text="Temperature-adjust equilibrium constants",
            variable=self._sol_use_temp_adjust_var,
        ).grid(row=0, column=0, columnspan=2, sticky="w", padx=8, pady=2)

        self._sol_limit_ionic_var = self._create_persistent_solubility_bool(
            "limit_ionic_strength", False
        )
        ttk.Checkbutton(
            advanced_box,
            text="Cap ionic strength during Debye-Hückel iterations",
            variable=self._sol_limit_ionic_var,
            command=self._toggle_ionic_cap_state,
        ).grid(row=1, column=0, sticky="w", padx=8, pady=2)
        self._solubility_vars["ionic_strength_cap"] = (
            self._create_persistent_solubility_var("ionic_strength_cap", "")
        )
        self._register_solubility_observer(self._solubility_vars["ionic_strength_cap"])
        self._sol_ionic_cap_entry = ttk.Entry(
            advanced_box,
            textvariable=self._solubility_vars["ionic_strength_cap"],
            width=12,
        )
        self._solubility_field_meta["ionic_strength_cap"] = {
            "label": "Ionic strength cap (M)",
            "required": False,
        }
        self._sol_ionic_cap_entry.grid(row=1, column=1, sticky="w", padx=8, pady=2)

        self._sol_include_headspace_var = self._create_persistent_solubility_bool(
            "include_headspace", False
        )
        self._register_solubility_observer(self._sol_include_headspace_var)
        ttk.Checkbutton(
            advanced_box,
            text="Include CO\u2082 headspace contribution (Henry's law)",
            variable=self._sol_include_headspace_var,
            command=self._toggle_headspace_fields,
        ).grid(row=2, column=0, columnspan=2, sticky="w", padx=8, pady=2)
        headspace_frame = ttk.Frame(advanced_box)
        headspace_frame.grid(row=3, column=0, columnspan=2, sticky="ew", padx=8, pady=2)
        headspace_frame.grid_columnconfigure(1, weight=1)
        self._solubility_vars["headspace_pco2_atm"] = (
            self._create_persistent_solubility_var(
                "headspace_pco2_atm", str(SOL_HEADSPACE_DEFAULT_PCO2_ATM)
            )
        )
        self._register_solubility_observer(self._solubility_vars["headspace_pco2_atm"])
        self._solubility_field_meta["headspace_pco2_atm"] = {
            "label": "Headspace pCO\u2082 (atm)",
            "required": False,
        }
        ttk.Label(headspace_frame, text="pCO2 (atm)").grid(
            row=0, column=0, sticky="w", padx=(0, 6)
        )
        self._sol_headspace_pco2_entry = ttk.Entry(
            headspace_frame,
            textvariable=self._solubility_vars["headspace_pco2_atm"],
            width=12,
        )
        self._sol_headspace_pco2_entry.grid(row=0, column=1, sticky="w", padx=(0, 12))
        self._solubility_vars["headspace_kh_m_per_atm"] = (
            self._create_persistent_solubility_var("headspace_kh_m_per_atm", "0.033")
        )
        self._register_solubility_observer(
            self._solubility_vars["headspace_kh_m_per_atm"]
        )
        self._solubility_field_meta["headspace_kh_m_per_atm"] = {
            "label": "Henry constant (mol/L/atm)",
            "required": False,
        }
        ttk.Label(headspace_frame, text="Henry constant (mol/L/atm)").grid(
            row=0, column=2, sticky="w", padx=(0, 6)
        )
        self._sol_headspace_kh_entry = ttk.Entry(
            headspace_frame,
            textvariable=self._solubility_vars["headspace_kh_m_per_atm"],
            width=12,
        )
        self._sol_headspace_kh_entry.grid(row=0, column=3, sticky="w")

        sensitivity_box = ttk.LabelFrame(
            planning_frame, text="Sensitivity Analysis Toggles"
        )
        sensitivity_box.grid(row=7, column=0, sticky="ew", padx=0, pady=6)
        self._sol_sens_mass_var = self._create_persistent_solubility_bool(
            "sens_mass_enabled", True
        )
        self._sol_sens_solvent_var = self._create_persistent_solubility_bool(
            "sens_solvent_enabled", True
        )
        self._sol_sens_temp_var = self._create_persistent_solubility_bool(
            "sens_temp_enabled", True
        )
        sensitivity_box.grid_columnconfigure(0, weight=1)
        sensitivity_box.grid_columnconfigure(1, weight=1)
        sens_specs = [
            (self._sol_sens_mass_var, "Perturb NaHCO₃ mass ±5%"),
            (self._sol_sens_solvent_var, "Perturb solvent basis ±5%"),
            (self._sol_sens_temp_var, "Perturb temperature ±5%"),
        ]
        # Iterate over indexed elements from sens_specs to apply the per-item logic.
        for idx, (var, label) in enumerate(sens_specs):
            row = idx // 2
            col = idx % 2
            ttk.Checkbutton(
                sensitivity_box,
                text=label,
                variable=var,
            ).grid(row=row, column=col, sticky="w", padx=8, pady=2)

        sweep_box = ttk.LabelFrame(planning_frame, text="pH Sweep Settings")
        sweep_box.grid(row=8, column=0, sticky="ew", padx=0, pady=(0, 12))
        sweep_box.grid_columnconfigure(5, weight=1)
        sweep_defaults = {
            "ph_sweep_low": str(SOL_PH_SWEEP_DEFAULT[0]),
            "ph_sweep_high": str(SOL_PH_SWEEP_DEFAULT[1]),
            "ph_sweep_steps": str(SOL_PH_SWEEP_DEFAULT[2]),
        }
        # Iterate to apply the per-item logic.
        for idx, (key, label) in enumerate(
            [
                ("ph_sweep_low", "pH low"),
                ("ph_sweep_high", "pH high"),
                ("ph_sweep_steps", "Steps"),
            ]
        ):
            var = self._create_persistent_solubility_var(key, sweep_defaults[key])
            self._solubility_vars[key] = var
            self._solubility_field_meta[key] = {"label": label, "required": False}
            ttk.Label(sweep_box, text=label).grid(
                row=0, column=idx * 2, sticky="w", padx=8, pady=2
            )
            width = 8 if "steps" in key else 10
            ttk.Entry(sweep_box, textvariable=var, width=width).grid(
                row=0, column=idx * 2 + 1, sticky="w", padx=(0, 8), pady=2
            )
        ttk.Button(
            sweep_box, text="Glossary", command=self._open_solubility_glossary
        ).grid(row=0, column=6, sticky="e", padx=8, pady=2)

        summary_container = ttk.Frame(frame)
        summary_container.grid(row=1, column=0, sticky="nsew", padx=12, pady=(0, 12))
        summary_container.grid_columnconfigure(0, weight=1)
        summary_container.grid_rowconfigure(1, weight=1)
        summary_toolbar = ttk.Frame(summary_container)
        summary_toolbar.grid(row=0, column=0, columnspan=2, sticky="ew", pady=(0, 6))
        summary_toolbar.grid_columnconfigure(0, weight=1)
        toolbar_controls = ttk.Frame(summary_toolbar)
        toolbar_controls.grid(row=0, column=0, sticky="w")
        # Iterate to apply the per-item logic.
        for text, cmd in [
            ("Run Solubility Analysis", self._run_solubility_analysis),
            ("Export as PNG", self._save_solubility_summary_png),
            ("Copy Summary", self._copy_solubility_summary),
            ("Export CSV", self._export_solubility_csv),
            ("Export JSON", self._export_solubility_json),
            ("Send to Contamination", self._apply_solubility_to_contamination),
        ]:
            ttk.Button(toolbar_controls, text=text, command=cmd).pack(
                side="left", padx=(0, 8)
            )

        summary_canvas = tk.Canvas(summary_container, highlightthickness=0)
        summary_canvas.grid(row=1, column=0, sticky="nsew")
        summary_scrollbar = ttk.Scrollbar(
            summary_container, orient="vertical", command=summary_canvas.yview
        )
        summary_scrollbar.grid(row=1, column=1, sticky="ns", padx=(4, 0))
        summary_canvas.configure(yscrollcommand=summary_scrollbar.set)

        summary_inner = ttk.Frame(summary_canvas)
        summary_window = summary_canvas.create_window(
            (0, 0), window=summary_inner, anchor="nw"
        )
        summary_inner.grid_columnconfigure(0, weight=1)

        # Closure captures _build_tab_solubility state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_tab_solubility.
        def _refresh_summary_scroll(_event=None):
            """Refresh summary scroll.
            Used to sync summary scroll with current settings."""
            summary_canvas.configure(scrollregion=summary_canvas.bbox("all"))

        summary_inner.bind("<Configure>", _refresh_summary_scroll)

        # Closure captures _build_tab_solubility local context to keep helper logic scoped and invoked directly within _build_tab_solubility.
        def _expand_summary_width(event):
            """Perform expand summary width.
            Used to keep the workflow logic localized and testable."""
            summary_canvas.itemconfigure(summary_window, width=event.width)

        summary_canvas.bind("<Configure>", _expand_summary_width)

        # Closure captures _build_tab_solubility local context to keep helper logic scoped and invoked directly within _build_tab_solubility.
        def _summary_mousewheel(event):
            """Perform summary mousewheel.
            Used to keep the workflow logic localized and testable."""
            delta = event.delta
            if delta == 0:
                return
            step = -1 if delta > 0 else 1
            if abs(delta) >= 120:
                step = int(-delta / 120)
            summary_canvas.yview_scroll(step, "units")
            return "break"

        # Closure captures _build_tab_solubility local context to keep helper logic scoped and invoked directly within _build_tab_solubility.
        def _bind_summary_mousewheel(widget):
            """Perform bind summary mousewheel.
            Used to keep the workflow logic localized and testable."""
            widget.bind("<MouseWheel>", _summary_mousewheel, add="+")
            widget.bind(
                "<Button-4>",
                lambda _event: summary_canvas.yview_scroll(-1, "units"),
                add="+",
            )
            widget.bind(
                "<Button-5>",
                lambda _event: summary_canvas.yview_scroll(1, "units"),
                add="+",
            )
            # Iterate over widget.winfo_children() to apply the per-item logic.
            for child in widget.winfo_children():
                _bind_summary_mousewheel(child)

        self.after_idle(lambda: _bind_summary_mousewheel(summary_inner))

        summary_box = ttk.LabelFrame(summary_inner, text="Summary")
        summary_box.grid(row=0, column=0, sticky="nsew")
        summary_box.grid_columnconfigure(0, weight=1)
        summary_box.grid_rowconfigure(4, weight=2)
        summary_box.grid_rowconfigure(5, weight=1)
        summary_box.grid_rowconfigure(6, weight=1)
        summary_box.grid_rowconfigure(8, weight=1)
        summary_box.grid_rowconfigure(11, weight=1)
        summary_box.grid_rowconfigure(12, weight=1)
        summary_box.grid_rowconfigure(13, weight=1)
        summary_box.grid_rowconfigure(14, weight=0)

        context_frame = ttk.LabelFrame(summary_box, text="Simulation Narrative")
        context_frame.grid(row=1, column=0, sticky="ew", padx=8, pady=(6, 4))
        context_frame.grid_columnconfigure(0, weight=1)
        self._sol_context_label_var = tk.StringVar(
            value="Select a simulation mode to begin."
        )
        ttk.Label(
            context_frame,
            textvariable=self._sol_context_label_var,
            style="Sol.Highlight.TLabel",
            justify="left",
        ).grid(row=0, column=0, sticky="w", padx=8, pady=(4, 2))
        self._sol_context_start_var = tk.StringVar(
            value="Starting point will appear after running the analysis."
        )
        ttk.Label(
            context_frame,
            textvariable=self._sol_context_start_var,
            style="Sol.Help.TLabel",
            wraplength=760,
            justify="left",
        ).grid(row=1, column=0, sticky="ew", padx=8, pady=(0, 2))
        self._sol_context_goal_var = tk.StringVar(
            value="Solver goals and recommended actions will populate here."
        )
        ttk.Label(
            context_frame,
            textvariable=self._sol_context_goal_var,
            style="Sol.Help.TLabel",
            wraplength=760,
            justify="left",
        ).grid(row=2, column=0, sticky="ew", padx=8, pady=(0, 2))
        self._sol_context_assumption_var = tk.StringVar(
            value="Mode assumptions will be echoed here."
        )
        ttk.Label(
            context_frame,
            textvariable=self._sol_context_assumption_var,
            style="Sol.Help.TLabel",
            wraplength=760,
            justify="left",
        ).grid(row=3, column=0, sticky="ew", padx=8, pady=(0, 4))

        highlight_frame = ttk.Frame(summary_box)
        highlight_frame.grid(row=2, column=0, sticky="ew", padx=8, pady=(8, 4))
        highlight_frame.grid_columnconfigure((0, 1, 2), weight=1)
        self._sol_highlight_meta = OrderedDict(
            [
                ("ph", "Equilibrium pH"),
                ("ionic_strength", "Ionic strength"),
                ("alkalinity", "Alkalinity"),
                ("carbonate", "Na\u2082CO\u2083 equivalent"),
                ("charge", "Charge residual"),
                ("dissolved", "Dissolved NaHCO\u2083"),
                ("solids", "Undissolved NaHCO\u2083"),
            ]
        )
        self._sol_highlight_vars = {}
        # Iterate over indexed elements from self._sol_highlight_meta.items( to apply the per-item logic.
        for idx, (key, label) in enumerate(self._sol_highlight_meta.items()):
            var = tk.StringVar(value=f"{label}: --")
            self._sol_highlight_vars[key] = var
            ttk.Label(
                highlight_frame,
                textvariable=var,
                style="Sol.Highlight.TLabel",
                anchor="w",
                wraplength=240,
                justify="left",
            ).grid(row=idx // 3, column=idx % 3, sticky="ew", padx=4, pady=2)

        self._sol_reaction_guidance = {}

        self._sol_warning_var = tk.StringVar(
            value="Warnings will appear after running the analysis."
        )
        ttk.Label(
            summary_box,
            textvariable=self._sol_warning_var,
            style="Sol.Warning.TLabel",
            wraplength=740,
            justify="left",
        ).grid(row=3, column=0, sticky="ew", padx=8, pady=(0, 4))

        table_frame = ttk.Frame(summary_box)
        table_frame.grid(row=4, column=0, sticky="nsew", padx=8, pady=4)
        table_frame.grid_columnconfigure(0, weight=3)
        table_frame.grid_columnconfigure(1, weight=2)
        table_frame.grid_rowconfigure(0, weight=1)

        species_frame = ttk.LabelFrame(table_frame, text="Species Table")
        species_frame.grid(row=0, column=0, sticky="nsew", padx=(0, 8))
        species_frame.grid_rowconfigure(0, weight=1)
        species_frame.grid_columnconfigure(0, weight=1)
        self._sol_species_columns = ("species", "molar", "mass", "moles", "gamma")
        self._sol_species_tree = ttk.Treeview(
            species_frame,
            columns=self._sol_species_columns,
            show="headings",
            height=8,
        )
        headings = ["Species", "[C] / M", "g/L", "n / mol", "gamma"]
        # Iterate over paired elements from multiple sequences to apply the per-item logic.
        for col, heading in zip(self._sol_species_columns, headings):
            self._sol_species_tree.heading(col, text=heading)
            self._sol_species_tree.column(col, anchor="e", stretch=True, width=110)
        species_scroll = ttk.Scrollbar(
            species_frame, orient="vertical", command=self._sol_species_tree.yview
        )
        self._sol_species_tree.configure(yscrollcommand=species_scroll.set)
        self._sol_species_tree.grid(row=0, column=0, sticky="nsew")
        species_scroll.grid(row=0, column=1, sticky="ns")

        plot_frame = ttk.LabelFrame(table_frame, text="Speciation & Saturation Plots")
        plot_frame.grid(row=0, column=1, sticky="nsew")
        self._sol_plot_fig = Figure(figsize=(5.2, 3.0), dpi=100)
        pie_ax = self._sol_plot_fig.add_subplot(121)
        bar_ax = self._sol_plot_fig.add_subplot(122)
        self._sol_plot_axes = (pie_ax, bar_ax)
        self._sol_plot_canvas = FigureCanvasTkAgg(self._sol_plot_fig, master=plot_frame)
        self._sol_plot_canvas.get_tk_widget().pack(fill="both", expand=True)
        self._sol_plot_canvas.draw()

        diagnostic_frame = ttk.Frame(summary_box)
        diagnostic_frame.grid(row=5, column=0, sticky="nsew", padx=8, pady=4)
        diagnostic_frame.grid_columnconfigure(0, weight=1)
        diagnostic_frame.grid_columnconfigure(1, weight=1)

        saturation_frame = ttk.LabelFrame(diagnostic_frame, text="Saturation Indices")
        saturation_frame.grid(row=0, column=0, sticky="nsew", padx=(0, 8))
        self._sol_saturation_columns = ("salt", "ratio", "status")
        self._sol_saturation_tree = ttk.Treeview(
            saturation_frame,
            columns=self._sol_saturation_columns,
            show="headings",
            height=4,
        )
        # Iterate to apply the per-item logic.
        for col, heading in zip(
            self._sol_saturation_columns, ["Salt", "Ratio", "Status"]
        ):
            self._sol_saturation_tree.heading(col, text=heading)
            self._sol_saturation_tree.column(
                col, anchor="center", stretch=True, width=90
            )
        self._sol_saturation_tree.pack(fill="both", expand=True)

        sensitivity_frame = ttk.LabelFrame(
            diagnostic_frame, text="Sensitivity Snapshots"
        )
        sensitivity_frame.grid(row=0, column=1, sticky="nsew")
        self._sol_sensitivity_columns = ("label", "ph", "ionic_strength", "na2co3_si")
        self._sol_sensitivity_tree = ttk.Treeview(
            sensitivity_frame,
            columns=self._sol_sensitivity_columns,
            show="headings",
            height=4,
        )
        # Iterate to apply the per-item logic.
        for col, heading in zip(
            self._sol_sensitivity_columns,
            ["Scenario", "pH", "I", "Na2CO3 SI"],
        ):
            anchor = "w" if col == "label" else "center"
            width = 160 if col == "label" else 90
            self._sol_sensitivity_tree.heading(col, text=heading)
            self._sol_sensitivity_tree.column(col, anchor=anchor, width=width)
        self._sol_sensitivity_tree.pack(fill="both", expand=True)

        sweep_frame = ttk.LabelFrame(
            summary_box, text="pH Sweep (% HCO3- / % CO3^2- / % H2CO3)"
        )
        sweep_frame.grid(row=6, column=0, sticky="nsew", padx=8, pady=4)
        sweep_frame.grid_rowconfigure(1, weight=1)
        sweep_frame.grid_columnconfigure(0, weight=1)
        self._sol_sweep_fig = Figure(figsize=(5.4, 2.2), dpi=100)
        self._sol_sweep_plot_ax = self._sol_sweep_fig.add_subplot(111)
        self._sol_sweep_plot_canvas = FigureCanvasTkAgg(
            self._sol_sweep_fig, master=sweep_frame
        )
        self._sol_sweep_plot_canvas.get_tk_widget().grid(
            row=0, column=0, sticky="ew", padx=4, pady=(4, 2)
        )
        self._sol_sweep_plot_canvas.draw()
        self._sol_sweep_columns = ("ph", "hco3_pct", "co3_pct", "h2co3_pct")
        self._sol_sweep_tree = ttk.Treeview(
            sweep_frame,
            columns=self._sol_sweep_columns,
            show="headings",
            height=4,
        )
        # Iterate over self._sol_sweep_columns to apply the per-item logic.
        for col in self._sol_sweep_columns:
            self._sol_sweep_tree.heading(col, text=col.upper())
            self._sol_sweep_tree.column(col, anchor="center", width=110)
        self._sol_sweep_tree.grid(row=1, column=0, sticky="nsew", padx=4, pady=(0, 4))

        self._sol_assumptions_var = tk.StringVar(
            value="Assumptions will be listed after running the module."
        )
        ttk.Label(
            summary_box,
            textvariable=self._sol_assumptions_var,
            style="Sol.Help.TLabel",
            wraplength=760,
            justify="left",
        ).grid(row=7, column=0, sticky="ew", padx=8, pady=(0, 4))
        summary_text = scrolledtext.ScrolledText(
            summary_box, height=12, wrap="word", state="disabled"
        )
        summary_text.grid(row=8, column=0, sticky="nsew", padx=8, pady=(4, 8))

        self._solubility_summary = summary_text
        self._enable_text_mousewheel(summary_text)
        self._sol_highlight_defaults = {
            key: f"{label}: ??" for key, label in self._sol_highlight_meta.items()
        }

    def _ensure_analysis_progress_vars(self) -> None:
        """Perform ensure analysis progress vars.
        Used to keep the workflow logic localized and testable."""
        if self._analysis_progress_pct_var is None:
            self._analysis_progress_pct_var = tk.StringVar(
                value=(
                    "Run Cycle Analysis and send results to Analysis mode "
                    "to estimate reaction progress."
                )
            )
        if self._analysis_regime_var is None:
            self._analysis_regime_var = tk.StringVar(
                value="Regime: Unknown (pH unavailable)"
            )
        if self._analysis_co2_g_var is None:
            self._analysis_co2_g_var = tk.StringVar(
                value="CO2 added (cycle): -- g (-- mol)"
            )
        if self._analysis_co2_mol_var is None:
            self._analysis_co2_mol_var = tk.StringVar(value="--")
        if self._analysis_mapped_ph_var is None:
            self._analysis_mapped_ph_var = tk.StringVar(value="Mapped predicted pH: --")
        if self._analysis_equivalence_pct_var is None:
            self._analysis_equivalence_pct_var = tk.StringVar(
                value="Equivalence completion: --"
            )
        if self._analysis_planning_final_co2_g_var is None:
            self._analysis_planning_final_co2_g_var = tk.StringVar(value="--")
        if self._analysis_planning_completion_var is None:
            self._analysis_planning_completion_var = tk.StringVar(
                value="Planning target completion: --"
            )

    def _build_tab_solubility_new(self):
        """Build the solubility modeling tab UI.
        Purpose: Construct the scrollable Advanced Solubility workflow layout.
        Why: Centralize Planning/Analysis/Reprocessing input wiring and defaults.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            - Creates Tk widgets, binds callbacks, and populates solubility state.
            - Records default values and registers observers for input persistence.
        Exceptions:
            - Best-effort; returns early if the tab frame is unavailable.
        """
        frame = getattr(self, "tab_solubility_new", None)
        if frame is None:
            return

        frame.grid_columnconfigure(0, weight=1)
        frame.grid_rowconfigure(0, weight=1)

        # Scrollable canvas: Tkinter requires a canvas window + inner frame so
        # large solubility panels can scroll without nesting full frames.
        container = ttk.Frame(frame)
        container.grid(row=0, column=0, sticky="nsew")
        container.grid_columnconfigure(0, weight=1)
        container.grid_rowconfigure(0, weight=1)

        canvas = tk.Canvas(container, highlightthickness=0)
        canvas.grid(row=0, column=0, sticky="nsew")
        scrollbar = _ui_scrollbar(container, orient="vertical", command=canvas.yview)
        scrollbar.grid(row=0, column=1, sticky="ns")
        canvas.configure(yscrollcommand=scrollbar.set)

        inner = ttk.Frame(canvas)
        window = canvas.create_window((0, 0), window=inner, anchor="nw")
        inner.grid_columnconfigure(0, weight=1)

        # Closure captures _build_tab_solubility_new state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_tab_solubility_new.
        def _refresh_scroll(_event=None):
            """Refresh scroll.
            Used to sync scroll with current settings."""
            canvas.configure(scrollregion=canvas.bbox("all"))

        inner.bind("<Configure>", _refresh_scroll)

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _expand_width(event):
            """Perform expand width.
            Used to keep the workflow logic localized and testable."""
            canvas.itemconfigure(window, width=event.width)

        canvas.bind("<Configure>", _expand_width)

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        # Recursive mousewheel binding ensures any nested widget scrolls the
        # canvas, a fragile but necessary Tkinter pattern for complex panels.
        def _bind_mousewheel(widget):
            """Perform bind mousewheel.
            Used to keep the workflow logic localized and testable."""
            widget.bind(
                "<MouseWheel>",
                lambda evt: canvas.yview_scroll(int(-1 * (evt.delta / 120)), "units"),
                add="+",
            )
            widget.bind(
                "<Button-4>", lambda _event: canvas.yview_scroll(-1, "units"), add="+"
            )
            widget.bind(
                "<Button-5>", lambda _event: canvas.yview_scroll(1, "units"), add="+"
            )
            # Iterate over widget.winfo_children() to apply the per-item logic.
            for child in widget.winfo_children():
                _bind_mousewheel(child)

        self.after_idle(lambda: _bind_mousewheel(inner))

        ttk.Label(
            inner,
            text="Advanced Speciation & Equilibrium Engine (workflow preview) — plan, analyze, and reprocess batches with guided steps.",
            wraplength=900,
            justify="left",
        ).grid(row=0, column=0, sticky="ew", padx=12, pady=(12, 6))

        mode_var = getattr(self, "_sol_mode_var", None)
        if mode_var is None:
            self._sol_mode_var = self._create_persistent_solubility_var(
                "sol_simulation_mode", SOL_DEFAULT_SIM_MODE
            )
            mode_var = self._sol_mode_var
            self._register_solubility_observer(mode_var)

        guidance_box = ttk.LabelFrame(inner, text="Guided Steps")
        guidance_box.grid(row=3, column=0, sticky="ew", padx=12, pady=6)
        guidance_box.grid_columnconfigure(0, weight=1)
        ttk.Label(
            guidance_box,
            textvariable=getattr(
                self,
                "_sol_mode_description_var",
                tk.StringVar(value="Select a simulation basis to view guided steps."),
            ),
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=0, column=0, sticky="ew", padx=8, pady=2)
        ttk.Label(
            guidance_box,
            textvariable=getattr(
                self,
                "_sol_mode_assumption_var",
                tk.StringVar(value="Assumptions will appear here."),
            ),
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=1, column=0, sticky="ew", padx=8, pady=2)
        self._sol_mode_expectation_var = tk.StringVar(
            value="Expectations will appear here."
        )
        ttk.Label(
            guidance_box,
            textvariable=self._sol_mode_expectation_var,
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=2, column=0, sticky="ew", padx=8, pady=2)
        ttk.Label(
            guidance_box,
            textvariable=getattr(
                self,
                "_sol_mode_steps_var",
                tk.StringVar(value="Checklist will appear here."),
            ),
            justify="left",
            wraplength=900,
        ).grid(row=3, column=0, sticky="ew", padx=8, pady=(0, 4))

        workflow_box = ttk.LabelFrame(inner, text="Workflow Inputs")
        workflow_box.grid(row=4, column=0, sticky="ew", padx=12, pady=6)
        workflow_box.grid_columnconfigure(0, weight=1)
        workflow_nb = ttk.Notebook(workflow_box)
        workflow_nb.grid(row=0, column=0, sticky="ew")
        self._sol_workflow_nb = workflow_nb
        workflow_tabs: Dict[str, ttk.Frame] = {}
        self._sol_workflow_tabs = workflow_tabs

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _workflow_input_specs(workflow_key: str):
            """Perform workflow input specs.
            Used to keep the workflow logic localized and testable."""
            workflow_meta = SOL_WORKFLOW_TEMPLATES.get(workflow_key, {})
            guide_mode = workflow_meta.get(
                "guide_mode", workflow_meta.get("mode_key", SOL_DEFAULT_SIM_MODE)
            )
            return _guide_workflow_specs(
                guide_mode,
                include_keys=workflow_meta.get("input_include_keys"),
                extra=workflow_meta.get("input_extra_fields"),
            )

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _adjust_sol_workflow_height():
            """Perform adjust sol workflow height.
            Used to keep the workflow logic localized and testable."""
            nb = workflow_nb
            current = nb.select()
            if not current:
                return
            try:
                nb.update_idletasks()
                tab = nb.nametowidget(current)
                height = tab.winfo_reqheight()
                if height <= 0:
                    return
                nb.configure(height=height + 5)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Closure captures _build_tab_solubility_new state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_tab_solubility_new.
        def _on_workflow_tab_changed(_event=None):
            """Handle workflow tab changed.
            Used as an event callback for workflow tab changed."""
            workflow_key = self._current_solubility_workflow()
            settings["sol_last_workflow"] = workflow_key
            try:
                self._schedule_save_settings()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            state = self._cycle_state_for(workflow_key)
            self._sol_cycle_payload = state.get("payload")
            self._sol_cycle_results = state.get("results")
            try:
                self._sync_workflow_model_state(
                    workflow_key, refresh_ui=True, save=False
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._refresh_sol_mode_guidance()
            self._update_cycle_solubility_widgets(
                state.get("results"), workflow_key=workflow_key
            )
            if workflow_key == "Planning":
                self._refresh_planning_model_fields_visibility()
            _adjust_sol_workflow_height()

        workflow_nb.bind("<<NotebookTabChanged>>", _on_workflow_tab_changed)
        self.after_idle(_adjust_sol_workflow_height)

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _ensure_sol_var(key: str, default: str = "") -> tk.StringVar:
            """Perform ensure sol var.
            Used to keep the workflow logic localized and testable."""
            vars_map = getattr(self, "_solubility_vars", {})
            var = vars_map.get(key)
            if var is None:
                var = self._create_persistent_solubility_var(key, default)
                vars_map[key] = var
                self._solubility_vars = vars_map
                self._register_solubility_observer(var)
            return var

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _guide_workflow_specs(
            guide_key: str,
            *,
            include_keys: Optional[Sequence[str]] = None,
            extra: Optional[Sequence[Tuple[str, str, bool]]] = None,
        ) -> List[Tuple[str, str, bool]]:
            """Perform guide workflow specs.
            Used to keep the workflow logic localized and testable."""
            include_set = set(include_keys) if include_keys else None
            guide = SOL_MODE_INPUT_GUIDE.get(guide_key, SOL_MODE_INPUT_GUIDE["default"])
            specs: List[Tuple[str, str, bool]] = []
            seen: Set[str] = set()
            # Iterate over guide to apply the per-item logic.
            for spec in guide:
                optional = bool(spec.get("optional", False))
                spec_label = spec.get("label", "Field")
                # Iterate over spec.get("keys", []) to apply the per-item logic.
                for key in spec.get("keys", []):
                    if include_set is not None and key not in include_set:
                        continue
                    if key in seen:
                        continue
                    label = SOL_MODE_FIELD_LABELS.get(key, spec_label)
                    if optional:
                        label = f"{label} (optional)"
                    specs.append((key, label, not optional))
                    seen.add(key)
            if extra:
                # Iterate over extra to apply the per-item logic.
                for key, label, required in extra:
                    if key in seen:
                        continue
                    specs.append((key, label, required))
                    seen.add(key)
            return specs

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _register_planning_field(
            field_id: str,
            frame: ttk.Frame,
            var: tk.Variable,
            entry: ttk.Entry,
        ) -> None:
            """Perform register planning field.
            Used to keep the workflow logic localized and testable."""
            registry = getattr(self, "_planning_field_registry", {})
            registry[field_id] = {"frame": frame, "var": var, "entry": entry}
            self._planning_field_registry = registry

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _build_input_grid(
            parent: ttk.Frame,
            specs: Sequence[Tuple[str, str, bool]],
            *,
            start_row: int = 0,
            workflow_key: Optional[str] = None,
        ) -> int:
            """Build input grid.
            Purpose: Create labeled entry rows for workflow-specific inputs.
            Why: Reuse consistent input wiring across Planning/Analysis/Reprocessing tabs.
            Inputs:
                parent (ttk.Frame): Container to receive the input rows.
                specs (Sequence[Tuple[str, str, bool]]): Input key/label/required specs.
                start_row (int): Starting grid row index.
                workflow_key (Optional[str]): Workflow name for default handling.
            Outputs:
                int: Next row index after the grid is populated.
            Side Effects:
                - Creates Tk widgets and updates self._solubility_field_meta.
                - Applies cached Planning inputs or defaults when appropriate.
            Exceptions:
                - Best-effort; continues when widget construction fails.
            """
            parent.grid_columnconfigure(1, weight=1)
            row_cursor = start_row
            # Iterate over specs to apply the per-item logic.
            for key, label, required in specs:
                row_frame = ttk.Frame(parent)
                row_frame.grid(
                    row=row_cursor,
                    column=0,
                    columnspan=2,
                    sticky="ew",
                    padx=8,
                    pady=(1, 2),
                )
                row_frame.grid_columnconfigure(1, weight=1)
                ttk.Label(row_frame, text=label, style="Sol.FieldLabel.TLabel").grid(
                    row=0, column=0, sticky="w", padx=(0, 8)
                )
                var = _ensure_sol_var(key)
                entry = _ui_entry(row_frame, textvariable=var, width=18)
                entry.grid(row=0, column=1, sticky="ew", padx=(0, 12))
                default_value = SOL_PLANNING_DEFAULTS.get(key)
                self._record_solubility_default(key, default_value)
                try:
                    current_value = var.get().strip()
                except Exception:
                    current_value = ""
                if workflow_key == "Planning":
                    # Planning runs can rebuild fields; prefer cached values over defaults.
                    cached_inputs = getattr(self, "_planning_input_cache", {}) or {}
                    cached_value = cached_inputs.get(key)
                    if (
                        cached_value is not None
                        and str(cached_value).strip()
                        and not current_value
                    ):
                        var.set(str(cached_value))
                    elif (
                        default_value
                        and not current_value
                        and not getattr(self, "_planning_inputs_persisted", False)
                    ):
                        var.set(default_value)
                elif default_value and not current_value:
                    var.set(default_value)
                self._solubility_field_meta[key] = {
                    "label": label,
                    "required": required,
                    "entry": entry,
                    "frame": row_frame,
                }
                if workflow_key == "Planning":
                    _register_planning_field(key, row_frame, var, entry)
                help_text = SOL_MODE_FIELD_HELP.get(key)
                if help_text:
                    ttk.Label(
                        row_frame,
                        text=help_text,
                        style="Sol.FieldHelp.TLabel",
                        wraplength=560,
                        justify="left",
                    ).grid(
                        row=1,
                        column=0,
                        columnspan=2,
                        sticky="w",
                        pady=(0, 2),
                    )
                row_cursor += 1
            return row_cursor

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _insert_shared_slider(tab, row_index):
            """Perform insert shared slider.
            Used to keep the workflow logic localized and testable."""
            slider_frame = ttk.Frame(tab)
            slider_frame.grid_columnconfigure(1, weight=1)
            slider_frame.grid(
                row=row_index,
                column=0,
                columnspan=2,
                sticky="ew",
                padx=8,
                pady=(6, 4),
            )
            ttk.Label(slider_frame, text="Target pH slider").grid(
                row=0, column=0, sticky="w"
            )
            _ui_scale(
                slider_frame,
                from_=6.5,
                to=9.5,
                orient="horizontal",
                variable=self._sol_forced_slider,
                command=self._on_solubility_forced_slider,
            ).grid(row=0, column=1, sticky="ew", padx=(8, 8))
            ttk.Label(
                slider_frame,
                textvariable=self._sol_target_ph_display_var,
                style="Sol.Help.TLabel",
            ).grid(row=0, column=2, sticky="w", padx=(8, 0))
            return slider_frame

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _insert_workflow_helper_section(tab, start_row):
            """Perform insert workflow helper section.
            Used to keep the workflow logic localized and testable."""
            row = start_row
            summary_var = getattr(
                self,
                "_sol_helper_summary_var",
                tk.StringVar(value="Select a simulation basis to see required inputs."),
            )
            ttk.Label(
                tab,
                textvariable=summary_var,
                style="Sol.Help.TLabel",
                wraplength=900,
                justify="left",
            ).grid(row=row, column=0, columnspan=2, sticky="ew", padx=8, pady=(4, 2))
            row += 1
            steps_var = getattr(
                self,
                "_sol_helper_steps_var",
                tk.StringVar(value="Checklist will appear after selecting a mode."),
            )
            ttk.Label(
                tab,
                textvariable=steps_var,
                wraplength=900,
                justify="left",
            ).grid(row=row, column=0, columnspan=2, sticky="ew", padx=8, pady=(0, 4))
            row += 1
            prompt_var = getattr(
                self,
                "_sol_prompt_var",
                tk.StringVar(value="Unable to determine prompt status."),
            )
            ttk.Label(
                tab,
                textvariable=prompt_var,
                style="Sol.Help.TLabel",
                wraplength=900,
                justify="left",
            ).grid(row=row, column=0, columnspan=2, sticky="ew", padx=8, pady=(0, 4))
            return row + 1

        available_models = list_speciation_models()
        if not available_models:
            available_models = [get_speciation_model(None)]
        self._workflow_model_display_map = OrderedDict(
            (f"{model.label} [{model.key}]", model.key) for model in available_models
        )
        self._workflow_model_vars = {}

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _build_workflow_models_frame(parent: ttk.Frame, workflow_key: str) -> None:
            """Build workflow models frame.
            Used to assemble workflow models frame during UI or plot setup."""
            model_frame = ttk.LabelFrame(parent, text="Workflow Models")
            model_frame.grid(
                row=0, column=0, columnspan=2, sticky="ew", padx=8, pady=(6, 4)
            )
            model_frame.grid_columnconfigure(1, weight=1)
            spec_attr, ph_attr, use_attr = self._workflow_model_attribute_keys(
                workflow_key
            )
            spec_key = getattr(self, spec_attr, DEFAULT_SPEC_MODEL_KEY)
            ph_key = getattr(self, ph_attr, spec_key)
            spec_label = self._workflow_model_label_for_key(spec_key)
            ph_label = self._workflow_model_label_for_key(ph_key)
            spec_var = tk.StringVar(value=spec_label)
            ph_var = tk.StringVar(value=ph_label)
            use_same_var = tk.BooleanVar(value=bool(getattr(self, use_attr, True)))
            ttk.Label(model_frame, text="Speciation model").grid(
                row=0, column=0, sticky="w", padx=(8, 6), pady=2
            )
            spec_combo = _ui_combobox(
                model_frame,
                textvariable=spec_var,
                values=list(self._workflow_model_display_map.keys()),
                state="readonly",
                width=40,
            )
            spec_combo.grid(row=0, column=1, sticky="ew", padx=(0, 8), pady=2)
            spec_combo.bind(
                "<<ComboboxSelected>>",
                lambda event, key=workflow_key: self._on_select_workflow_spec_model(
                    key, event
                ),
            )
            _ui_checkbutton(
                model_frame,
                text="Use same model for speciation and predicted pH",
                variable=use_same_var,
                command=lambda key=workflow_key: self._toggle_workflow_same_model(key),
            ).grid(row=1, column=0, columnspan=2, sticky="w", padx=8, pady=(2, 4))
            ph_frame = ttk.Frame(model_frame)
            ph_frame.grid(
                row=2, column=0, columnspan=2, sticky="ew", padx=8, pady=(0, 2)
            )
            ph_frame.grid_columnconfigure(1, weight=1)
            ttk.Label(ph_frame, text="Predicted pH model").grid(
                row=0, column=0, sticky="w", padx=(0, 6), pady=2
            )
            ph_combo = _ui_combobox(
                ph_frame,
                textvariable=ph_var,
                values=list(self._workflow_model_display_map.keys()),
                state="readonly",
                width=40,
            )
            ph_combo.grid(row=0, column=1, sticky="ew", padx=(0, 8), pady=2)
            ph_combo.bind(
                "<<ComboboxSelected>>",
                lambda event, key=workflow_key: self._on_select_workflow_ph_model(
                    key, event
                ),
            )
            self._workflow_model_vars[workflow_key] = {
                "spec_var": spec_var,
                "ph_var": ph_var,
                "use_same_var": use_same_var,
                "ph_frame": ph_frame,
            }
            self._sync_workflow_model_state(workflow_key, refresh_ui=True, save=True)

        planning_tab = ttk.Frame(workflow_nb)
        planning_tab.grid_columnconfigure(0, weight=1)
        workflow_nb.add(planning_tab, text="Planning")
        workflow_tabs["Planning"] = planning_tab
        _build_workflow_models_frame(planning_tab, "Planning")
        planning_specs = _workflow_input_specs("Planning")
        planning_rows = _build_input_grid(
            planning_tab,
            planning_specs,
            start_row=1,
            workflow_key="Planning",
        )
        _ensure_sol_var("mass_na_hco3_g")
        mass_naoh_var = self._solubility_vars.get("mass_naoh_g")
        if mass_naoh_var is not None:
            mass_naoh_var.trace_add("write", self._sync_planning_mass)
            self._sync_planning_mass()
        helper_end_row = _insert_workflow_helper_section(planning_tab, planning_rows)
        button_row = helper_end_row
        _ui_button(
            planning_tab,
            text="Run Planning Scenario",
            command=self._run_planning_scenario,
        ).grid(row=button_row, column=0, sticky="w", padx=8, pady=(2, 4))
        _ui_button(
            planning_tab, text="Clear Inputs", command=self._clear_sol_helper_inputs
        ).grid(row=button_row, column=1, sticky="e", padx=8, pady=(2, 4))

        plot_ph_label = "Speciation plot pH (default 8.0)"
        planning_plot_var = self._create_persistent_solubility_var(
            "planning_speciation_ph", "8.0"
        )
        self._record_solubility_default("planning_speciation_ph", "8.0")
        self._solubility_vars["planning_speciation_ph"] = planning_plot_var
        self._register_solubility_observer(planning_plot_var)
        self._solubility_field_meta["planning_speciation_ph"] = {
            "label": plot_ph_label,
            "required": False,
        }
        ttk.Label(planning_tab, text=plot_ph_label).grid(
            row=button_row + 1, column=0, sticky="w", padx=8, pady=(6, 2)
        )
        _ui_entry(planning_tab, textvariable=planning_plot_var, width=10).grid(
            row=button_row + 1, column=1, sticky="w", padx=(0, 12), pady=(6, 2)
        )

        target_box = ttk.LabelFrame(planning_tab, text="Target pH & Headspace")
        target_box.grid(
            row=button_row + 2, column=0, columnspan=2, sticky="ew", padx=8, pady=(8, 4)
        )
        target_box.grid_columnconfigure(0, weight=0)
        target_box.grid_columnconfigure(1, weight=1)

        slider_var = getattr(
            self,
            "_sol_forced_slider",
            tk.DoubleVar(value=DEFAULT_SOLUBILITY_INPUTS.initial_ph_guess),
        )
        self._sol_forced_slider = slider_var
        ttk.Label(target_box, text="Target pH slider").grid(
            row=0, column=0, sticky="w", padx=(8, 4), pady=2
        )
        _ui_scale(
            target_box,
            from_=6.5,
            to=9.5,
            orient="horizontal",
            variable=slider_var,
            command=self._on_solubility_forced_slider,
        ).grid(row=0, column=1, sticky="ew", padx=(0, 8), pady=2)
        self._sol_target_ph_display_var = tk.StringVar(
            value=f"Target pH slider: {slider_var.get():.2f}"
        )
        ttk.Label(
            target_box,
            textvariable=self._sol_target_ph_display_var,
            style="Sol.Help.TLabel",
        ).grid(
            row=1,
            column=0,
            columnspan=2,
            sticky="w",
            padx=8,
            pady=(0, 4),
        )
        forced_var = self._solubility_vars.get("forced_ph_target")
        if forced_var is not None:
            forced_var.trace_add("write", self._sync_target_slider_from_entry)

        headspace_frame = ttk.Frame(planning_tab)
        headspace_frame.grid(
            row=button_row + 3, column=0, columnspan=2, sticky="ew", padx=8, pady=(0, 8)
        )
        headspace_frame.grid_columnconfigure(1, weight=1)

        # Closure captures _build_tab_solubility_new local context to keep helper logic scoped and invoked directly within _build_tab_solubility_new.
        def _ensure_headspace_var(key: str, default: str) -> tk.StringVar:
            """Ensure a headspace input variable exists.
            Purpose: Create or reuse headspace input variables for Planning.
            Why: Headspace fields must persist and remain observable across refreshes.
            Inputs:
                key (str): Headspace input key.
                default (str): Default string value to apply on first init.
            Outputs:
                tk.StringVar: The variable bound to the input field.
            Side Effects:
                - Creates a new persistent variable when missing.
                - Registers observers and records field metadata defaults.
            Exceptions:
                - Best-effort; returns existing variables on failure.
            """
            var = self._solubility_vars.get(key)
            if var is None:
                var = self._create_persistent_solubility_var(key, default)
                self._record_solubility_default(key, default)
                self._solubility_vars[key] = var
                self._register_solubility_observer(var)
                self._solubility_field_meta[key] = {
                    "label": key.replace("_", " ").title(),
                    "required": False,
                    "entry": None,
                }
            return var

        pco2_var = _ensure_headspace_var(
            "headspace_pco2_atm", str(SOL_HEADSPACE_DEFAULT_PCO2_ATM)
        )
        kh_var = _ensure_headspace_var("headspace_kh_m_per_atm", "0.033")
        planning_headspace_volume_var = _ensure_headspace_var(
            "planning_headspace_volume_l", "1.0"
        )
        pco2_frame = ttk.Frame(headspace_frame)
        pco2_frame.grid(row=0, column=0, sticky="w", padx=(0, 12))
        ttk.Label(pco2_frame, text="pCO2 (atm)").grid(
            row=0, column=0, sticky="w", padx=(0, 4)
        )
        pco2_entry = _ui_entry(pco2_frame, textvariable=pco2_var, width=12)
        pco2_entry.grid(row=0, column=1, sticky="w")
        self._solubility_field_meta["headspace_pco2_atm"]["entry"] = pco2_entry
        _register_planning_field("headspace_pco2_atm", pco2_frame, pco2_var, pco2_entry)

        kh_frame = ttk.Frame(headspace_frame)
        kh_frame.grid(row=0, column=1, sticky="w")
        ttk.Label(kh_frame, text="Henry constant (mol/L/atm)").grid(
            row=0, column=0, sticky="w", padx=(0, 4)
        )
        kh_entry = _ui_entry(kh_frame, textvariable=kh_var, width=12)
        kh_entry.grid(row=0, column=1, sticky="w")
        self._solubility_field_meta["headspace_kh_m_per_atm"]["entry"] = kh_entry
        _register_planning_field("headspace_kh_m_per_atm", kh_frame, kh_var, kh_entry)

        headspace_vol_frame = ttk.Frame(headspace_frame)
        headspace_vol_frame.grid(row=1, column=0, columnspan=2, sticky="w", pady=(4, 0))
        ttk.Label(headspace_vol_frame, text="Headspace Volume (L)").grid(
            row=0, column=0, sticky="w", padx=(0, 4)
        )
        headspace_vol_entry = _ui_entry(
            headspace_vol_frame, textvariable=planning_headspace_volume_var, width=12
        )
        headspace_vol_entry.grid(row=0, column=1, sticky="w", padx=(0, 12))
        self._solubility_field_meta["planning_headspace_volume_l"][
            "entry"
        ] = headspace_vol_entry
        _register_planning_field(
            "planning_headspace_volume_l",
            headspace_vol_frame,
            planning_headspace_volume_var,
            headspace_vol_entry,
        )

        self._refresh_planning_model_fields_visibility()

        analysis_tab = ttk.Frame(workflow_nb)
        analysis_tab.grid_columnconfigure(0, weight=1)
        workflow_nb.add(analysis_tab, text="Analysis")
        workflow_tabs["Analysis"] = analysis_tab
        _build_workflow_models_frame(analysis_tab, "Analysis")
        analysis_specs = _workflow_input_specs("Analysis")
        analysis_rows = _build_input_grid(
            analysis_tab, analysis_specs, start_row=1, workflow_key="Analysis"
        )
        helper_end_row = _insert_workflow_helper_section(analysis_tab, analysis_rows)
        analysis_slider_row = helper_end_row
        _insert_shared_slider(analysis_tab, analysis_slider_row)
        analysis_button_row = analysis_slider_row + 1
        _ui_button(
            analysis_tab,
            text="Import from Cycle Analysis",
            command=self._send_cycle_to_solubility,
        ).grid(
            row=analysis_button_row,
            column=0,
            sticky="w",
            padx=8,
            pady=(4, 2),
        )
        _ui_button(
            analysis_tab, text="Run Analysis", command=self._run_analysis_scenario
        ).grid(
            row=analysis_button_row,
            column=1,
            sticky="e",
            padx=8,
            pady=(4, 2),
        )
        self._ensure_analysis_progress_vars()
        progress_row = analysis_button_row + 1
        progress_frame = ttk.LabelFrame(analysis_tab, text="Reaction Progress")
        progress_frame.grid(
            row=progress_row,
            column=0,
            columnspan=2,
            sticky="ew",
            padx=8,
            pady=(6, 4),
        )
        progress_frame.grid_columnconfigure(0, weight=1)
        ttk.Label(
            progress_frame,
            textvariable=self._analysis_progress_pct_var,
            style="Sol.Highlight.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=0, column=0, sticky="ew", padx=8, pady=(4, 2))
        ttk.Label(
            progress_frame,
            textvariable=self._analysis_regime_var,
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=1, column=0, sticky="ew", padx=8, pady=(0, 2))
        ttk.Label(
            progress_frame,
            textvariable=self._analysis_co2_g_var,
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=2, column=0, sticky="ew", padx=8, pady=(0, 2))
        ttk.Label(
            progress_frame,
            textvariable=self._analysis_mapped_ph_var,
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=3, column=0, sticky="ew", padx=8, pady=(0, 2))
        ttk.Label(
            progress_frame,
            textvariable=self._analysis_equivalence_pct_var,
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=4, column=0, sticky="ew", padx=8, pady=(0, 2))
        ttk.Label(
            progress_frame,
            textvariable=self._analysis_planning_completion_var,
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=5, column=0, sticky="ew", padx=8, pady=(0, 6))
        reaction_target_var = self._solubility_vars.get("reaction_target_ph")
        if reaction_target_var is not None:
            reaction_target_var.trace_add("write", self._sync_target_slider_from_entry)

        reprocess_tab = ttk.Frame(workflow_nb)
        reprocess_tab.grid_columnconfigure(0, weight=1)
        workflow_nb.add(reprocess_tab, text="Reprocessing")
        workflow_tabs["Reprocessing"] = reprocess_tab
        _build_workflow_models_frame(reprocess_tab, "Reprocessing")
        reprocess_specs = _workflow_input_specs("Reprocessing")
        reprocess_rows = _build_input_grid(
            reprocess_tab, reprocess_specs, start_row=1, workflow_key="Reprocessing"
        )
        helper_end_row = _insert_workflow_helper_section(reprocess_tab, reprocess_rows)
        reprocess_slider_row = helper_end_row
        _insert_shared_slider(reprocess_tab, reprocess_slider_row)
        reprocess_button_row = reprocess_slider_row + 1
        _ui_button(
            reprocess_tab,
            text="Run Reprocessing Plan",
            command=self._run_reprocessing_scenario,
        ).grid(
            row=reprocess_button_row,
            column=0,
            sticky="w",
            padx=8,
            pady=(4, 2),
        )
        _ui_button(
            reprocess_tab, text="Log Measurement", command=self._log_sol_measurement
        ).grid(
            row=reprocess_button_row,
            column=1,
            sticky="e",
            padx=8,
            pady=(4, 2),
        )
        _ui_button(
            reprocess_tab,
            text="Import from Cycle Analysis",
            command=self._import_cycle_to_reprocessing,
        ).grid(
            row=reprocess_button_row,
            column=2,
            sticky="e",
            padx=8,
            pady=(4, 2),
        )
        diag_target_var = self._solubility_vars.get("diag_target_ph")
        if diag_target_var is not None:
            diag_target_var.trace_add("write", self._sync_target_slider_from_entry)

        last_workflow = settings.get("sol_last_workflow")
        if last_workflow in workflow_tabs:
            workflow_nb.select(workflow_tabs[last_workflow])
        _on_workflow_tab_changed()

        action_bar = ttk.Frame(inner)
        action_bar.grid(row=5, column=0, sticky="ew", padx=12, pady=(6, 2))
        action_items = [
            ("Export PNG", self._save_solubility_summary_png),
            ("Copy Summary", self._copy_solubility_summary),
            ("Export CSV", self._export_solubility_csv),
            ("Export JSON", self._export_solubility_json),
            ("Export Planner Narrative", self._export_planner_narrative_png),
            ("Export CO₂ Guidance", self._export_co2_guidance_png),
            ("Export Math Preview", self._export_math_preview_png),
        ]
        # Iterate over indexed elements from action_items to apply the per-item logic.
        for idx, (text, cmd) in enumerate(action_items):
            _ui_button(action_bar, text=text, command=cmd).grid(
                row=0, column=idx, sticky="w", padx=(0, 8)
            )

        status_box = ttk.LabelFrame(inner, text="Planner Status")
        status_box.grid(row=6, column=0, sticky="ew", padx=12, pady=6)
        status_box.grid_columnconfigure(0, weight=1)
        ttk.Label(
            status_box,
            textvariable=getattr(
                self,
                "_sol_context_label_var",
                tk.StringVar(value="Select a simulation mode to begin."),
            ),
            style="Sol.Highlight.TLabel",
            justify="left",
            wraplength=900,
        ).grid(row=0, column=0, sticky="ew", padx=8, pady=(2, 2))
        ttk.Label(
            status_box,
            textvariable=getattr(
                self,
                "_sol_context_start_var",
                tk.StringVar(
                    value="Starting point will appear after running the analysis."
                ),
            ),
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=1, column=0, sticky="ew", padx=8, pady=(0, 2))
        ttk.Label(
            status_box,
            textvariable=getattr(
                self,
                "_sol_context_goal_var",
                tk.StringVar(
                    value="Solver goals and recommendations will be shown here."
                ),
            ),
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=2, column=0, sticky="ew", padx=8, pady=(0, 2))
        ttk.Label(
            status_box,
            textvariable=getattr(
                self,
                "_sol_context_assumption_var",
                tk.StringVar(value="Mode assumptions will be echoed here."),
            ),
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=3, column=0, sticky="ew", padx=8, pady=(0, 4))

        highlight_box = ttk.LabelFrame(inner, text="Speciation Snapshot")
        highlight_box.grid(row=7, column=0, sticky="ew", padx=12, pady=6)
        highlight_box.grid_columnconfigure(0, weight=1)
        # Iterate to apply the per-item logic.
        for idx, (key, label) in enumerate(
            getattr(self, "_sol_highlight_meta", {}).items()
        ):
            var = self._sol_highlight_vars.get(key)
            if var is None:
                var = tk.StringVar(value=f"{label}: --")
                self._sol_highlight_vars[key] = var
            ttk.Label(
                highlight_box,
                textvariable=var,
                style="Sol.Highlight.TLabel",
                justify="left",
                wraplength=280,
            ).grid(row=idx // 3, column=idx % 3, sticky="ew", padx=8, pady=2)

        plot_box = ttk.LabelFrame(inner, text="Speciation Visuals")
        plot_box.grid(row=8, column=0, sticky="ew", padx=12, pady=6)
        plot_box.grid_columnconfigure(0, weight=1)
        self._sol_new_plot_fig = Figure(figsize=(5.8, 2.8), dpi=100)
        pie_ax = self._sol_new_plot_fig.add_subplot(1, 2, 1)
        sat_ax = self._sol_new_plot_fig.add_subplot(1, 2, 2)
        pie_ax.set_title("Carbon Distribution", fontsize=9)
        sat_ax.set_title("Saturation Index", fontsize=9)
        sat_ax.set_xlabel("Index")
        sat_ax.set_ylabel("Salt")
        sat_ax.set_xlim(0, 2)
        self._sol_new_plot_axes = (pie_ax, sat_ax)
        self._sol_new_plot_canvas = FigureCanvasTkAgg(
            self._sol_new_plot_fig, master=plot_box
        )
        self._sol_new_plot_canvas.get_tk_widget().grid(
            row=0, column=0, sticky="ew", padx=8, pady=4
        )

        sweep_box = ttk.LabelFrame(inner, text="pH Sweep Preview")
        sweep_box.grid(row=9, column=0, sticky="ew", padx=12, pady=6)
        sweep_box.grid_columnconfigure(0, weight=1)
        self._sol_new_sweep_fig = Figure(figsize=(5.8, 2.4), dpi=100)
        self._sol_new_sweep_ax = self._sol_new_sweep_fig.add_subplot(111)
        self._sol_new_sweep_canvas = FigureCanvasTkAgg(
            self._sol_new_sweep_fig, master=sweep_box
        )
        self._sol_new_sweep_canvas.get_tk_widget().grid(
            row=0, column=0, sticky="ew", padx=8, pady=4
        )

        warning_box = ttk.LabelFrame(inner, text="Warnings & Assumptions")
        warning_box.grid(row=10, column=0, sticky="ew", padx=12, pady=6)
        warning_box.grid_columnconfigure(0, weight=1)
        ttk.Label(
            warning_box,
            textvariable=getattr(
                self,
                "_sol_warning_var",
                tk.StringVar(value="Warnings will appear after running the analysis."),
            ),
            style="Sol.Warning.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=0, column=0, sticky="ew", padx=8, pady=(2, 4))
        ttk.Label(
            warning_box,
            textvariable=getattr(
                self,
                "_sol_assumptions_var",
                tk.StringVar(
                    value="Assumptions will be listed after running the module."
                ),
            ),
            style="Sol.Help.TLabel",
            wraplength=900,
            justify="left",
        ).grid(row=1, column=0, sticky="ew", padx=8, pady=(0, 4))

        metrics_box = ttk.LabelFrame(inner, text="Key Metrics")
        metrics_box.grid(row=11, column=0, sticky="ew", padx=12, pady=6)
        metrics_box.grid_columnconfigure(0, weight=1)
        columns = ("metric", "value")
        self._sol_new_metric_columns = columns
        metrics_tree = ttk.Treeview(
            metrics_box, columns=columns, show="headings", height=6
        )
        # Iterate over columns to apply the per-item logic.
        for col in columns:
            metrics_tree.heading(col, text=col.title())
            metrics_tree.column(col, anchor="w", width=180 if col == "metric" else 220)
        metrics_tree.grid(row=0, column=0, sticky="ew", padx=8, pady=4)
        self._sol_new_metric_tree = metrics_tree

        summary_box = ttk.LabelFrame(inner, text="Planner Narrative")
        summary_box.grid(row=12, column=0, sticky="ew", padx=12, pady=6)
        summary_box.grid_columnconfigure(0, weight=1)
        summary_text = scrolledtext.ScrolledText(
            summary_box, height=10, wrap="word", state="disabled"
        )
        summary_text.grid(row=0, column=0, sticky="ew", padx=8, pady=4)
        self._solubility_summary_new = summary_text
        self._enable_text_mousewheel(summary_text)

        guidance_panel = ttk.LabelFrame(inner, text="CO\u2082 Dosing Guidance")
        guidance_panel.grid(row=13, column=0, sticky="ew", padx=12, pady=(6, 12))
        guidance_panel.grid_columnconfigure(0, weight=1)
        self._sol_new_reaction_summary_var = tk.StringVar(
            value="Enter NaOH/CO\u2082 inputs to activate the guidance overlay."
        )
        ttk.Label(
            guidance_panel,
            textvariable=self._sol_new_reaction_summary_var,
            wraplength=900,
            justify="left",
        ).grid(row=0, column=0, sticky="ew", padx=8, pady=4)

        cycle_panel = ttk.LabelFrame(inner, text="Cycle Speciation Timeline")
        cycle_panel.grid(
            row=14,
            column=0,
            sticky="ew",
            padx=12,
            pady=(0, 6),
        )
        cycle_panel.grid_columnconfigure(0, weight=1)
        cycle_panel.grid_rowconfigure(1, weight=1)

        tree_frame = ttk.Frame(cycle_panel)
        tree_frame.grid(row=0, column=0, sticky="nsew", padx=8, pady=(4, 4))
        tree_frame.grid_columnconfigure(0, weight=1)
        tree_frame.grid_rowconfigure(0, weight=1)
        self._sol_cycle_tree_frame = tree_frame
        cycle_columns = (
            "cycle",
            "co2_cycle_g",
            "co2_g",
            "co2_to_target",
            "ph",
            "pco2_atm",
            "h2co3_pct",
            "hco3_pct",
            "co3_pct",
            "solid_na2co3_g",
            "solid_nahco3_g",
            "warnings",
        )
        timeline_tree = ttk.Treeview(
            tree_frame, columns=cycle_columns, show="headings", height=5
        )
        # Iterate to apply the per-item logic.
        for col, heading in (
            ("cycle", "Cycle"),
            ("co2_cycle_g", "CO₂ per cycle (g)"),
            ("co2_g", "CO₂ total (g)"),
            ("co2_to_target", "CO₂ to target (g)"),
            ("ph", "Predicted pH"),
            ("h2co3_pct", "H₂CO₃ %"),
            ("hco3_pct", "HCO₃- %"),
            ("co3_pct", "CO₃²- %"),
            ("solid_na2co3_g", "Solid Na₂CO₃ (g)"),
            ("solid_nahco3_g", "Solid NaHCO₃ (g)"),
            ("pco2_atm", "pCO₂ (atm)"),
            ("warnings", "Notes"),
        ):
            timeline_tree.heading(col, text=heading)
            timeline_tree.column(col, anchor="center", width=100)
        vscroll = _ui_scrollbar(
            tree_frame, orient="vertical", command=timeline_tree.yview
        )
        timeline_tree.configure(yscrollcommand=vscroll.set)
        timeline_tree.grid(row=0, column=0, sticky="nsew")
        vscroll.grid(row=0, column=1, sticky="ns", pady=0)
        self._sol_cycle_timeline_tree = timeline_tree
        self._sol_cycle_timeline_columns = cycle_columns

        plot_frame = ttk.Frame(cycle_panel)
        plot_frame.grid(row=1, column=0, sticky="nsew", padx=8, pady=(0, 4))
        plot_frame.grid_columnconfigure(0, weight=1)
        plot_frame.grid_rowconfigure(0, weight=1)
        spec_fig = Figure(figsize=(9, 4.5), dpi=110)
        spec_ax = spec_fig.add_subplot(111)
        spec_ax2 = spec_ax.twinx()
        spec_ax3 = spec_ax.twinx()
        spec_ax.set_xlabel(r"Total CO$_2$ added (g)", fontsize=11, labelpad=8)
        spec_ax.set_ylabel("Carbon species (%)", fontsize=11, labelpad=10)
        spec_ax2.set_ylabel("Predicted pH", fontsize=11, labelpad=20, rotation=180)
        spec_ax2.spines["right"].set_position(("axes", 1.02))
        spec_ax2.yaxis.set_label_coords(1.08, 0.5)
        spec_ax3.set_ylabel(
            "Headspace pCO2 (atm)", fontsize=10, labelpad=16, rotation=180
        )
        spec_ax3.spines["right"].set_position(("axes", 1.12))
        spec_ax3.yaxis.set_label_coords(1.18, 0.5)
        spec_ax.tick_params(axis="both", labelsize=9, pad=4)
        spec_ax2.tick_params(axis="both", labelsize=9, pad=4)
        spec_canvas = FigureCanvasTkAgg(spec_fig, master=plot_frame)
        spec_canvas.get_tk_widget().pack(fill="both", expand=True)
        self._sol_cycle_spec_fig = spec_fig
        self._sol_cycle_spec_ax = spec_ax
        self._sol_cycle_spec_ax2 = spec_ax2
        self._sol_cycle_spec_ax3 = spec_ax3
        self._sol_cycle_spec_canvas = spec_canvas
        self._sol_cycle_spec_plot_frame = plot_frame

        callout_frame = ttk.LabelFrame(cycle_panel, text="Predicted pH Callouts")
        callout_frame.grid(row=2, column=0, sticky="ew", padx=8, pady=(0, 8))
        callout_frame.grid_columnconfigure(0, weight=1)
        # Iterate over the configured range to apply the per-item logic.
        for idx in range(1, 6):
            callout_frame.grid_columnconfigure(idx, weight=0)
        callout_frame.grid_rowconfigure(0, weight=1)
        callout_text = scrolledtext.ScrolledText(
            callout_frame, height=8, wrap="word", state="disabled"
        )
        callout_text.grid(row=0, column=0, columnspan=5, sticky="nsew")
        self._enable_text_mousewheel(callout_text)
        self._sol_cycle_callouts = callout_text
        export_csv_btn = _ui_button(
            callout_frame,
            text="Export Timeline CSV",
            command=self._export_cycle_timeline_csv,
        )
        export_csv_btn.grid(row=1, column=0, sticky="w", padx=4, pady=4)
        export_plot_btn = _ui_button(
            callout_frame,
            text="Export Timeline Plot",
            command=self._export_cycle_timeline_plot,
        )
        export_plot_btn.grid(row=1, column=1, sticky="w", padx=4, pady=4)
        export_table_btn = _ui_button(
            callout_frame,
            text="Export Timeline Table",
            command=self._export_cycle_timeline_table,
        )
        export_table_btn.grid(row=1, column=2, sticky="w", padx=4, pady=4)
        export_opts_btn = _ui_button(
            callout_frame,
            text="Export Options...",
            command=self._open_timeline_export_options,
        )
        export_opts_btn.grid(row=1, column=3, sticky="w", padx=4, pady=4)
        expand_btn = _ui_button(
            callout_frame,
            text="Expand Timeline",
            command=self._open_timeline_viewer,
        )
        expand_btn.grid(row=1, column=4, sticky="w", padx=4, pady=4)
        _ui_button(
            callout_frame,
            text="Scroll to Latest",
            command=self._scroll_callouts_to_latest,
        ).grid(row=1, column=5, sticky="e", padx=4, pady=4)
        self._sol_cycle_export_csv_btn = export_csv_btn
        self._sol_cycle_export_plot_btn = export_plot_btn
        self._sol_cycle_export_table_btn = export_table_btn
        self._sol_cycle_export_opts_btn = export_opts_btn
        self._sol_cycle_expand_btn = expand_btn
        self._set_timeline_action_state(False)

        math_box = ttk.LabelFrame(inner, text="Detailed Math Preview")
        math_box.grid(row=15, column=0, sticky="ew", padx=12, pady=(0, 12))
        math_box.grid_columnconfigure(0, weight=1)
        math_box.grid_columnconfigure(1, weight=0)
        self._sol_show_math_var = tk.BooleanVar(value=False)
        _ui_checkbutton(
            math_box,
            text="Show detailed math calculations",
            variable=self._sol_show_math_var,
            command=self._toggle_sol_math_block,
        ).grid(row=0, column=0, sticky="w", padx=8, pady=(4, 2))
        self._sol_math_view_btn = _ui_button(
            math_box,
            text="Open math viewer",
            command=self._open_sol_math_viewer,
            state="disabled",
        )
        self._sol_math_view_btn.grid(row=0, column=1, sticky="e", padx=8, pady=(4, 2))
        math_text = scrolledtext.ScrolledText(
            math_box, height=8, wrap="word", state="disabled"
        )
        math_text.grid(
            row=1,
            column=0,
            columnspan=2,
            sticky="ew",
            padx=8,
            pady=(0, 8),
        )
        self._sol_math_text = math_text
        self._sol_math_preview_ready = False
        self._toggle_sol_math_block()
        self._refresh_math_viewer_state()

    def _on_select_sol_model(self, _event: Optional[tk.Event] = None) -> None:
        """Handle select sol model.
        Used as an event callback for select sol model."""

        display_value = (
            self._sol_model_var.get() if hasattr(self, "_sol_model_var") else None
        )
        key = (
            self._sol_model_display_map.get(display_value)
            if display_value and hasattr(self, "_sol_model_display_map")
            else None
        )
        if not key:
            key = DEFAULT_SPEC_MODEL_KEY
        self._sol_model_key = key
        settings_ref = self._settings_dict()
        if isinstance(settings_ref, dict):
            settings_ref["solubility_model_key"] = key
        # Invalidate cached inputs so downstream simulations recompute with the new model.
        self._sol_last_form_data = None
        self._refresh_sol_model_info()
        try:
            self._schedule_save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _normalize_speciation_model_key(
        self, key: Optional[str], *, fallback: Optional[str] = None
    ) -> str:
        """Normalize speciation model key.
        Used to keep speciation model key consistent across workflows and persistence."""
        available = {model.key for model in list_speciation_models()}
        if key and key in available:
            return key
        if fallback and fallback in available:
            return fallback
        if DEFAULT_SPEC_MODEL_KEY in available:
            return DEFAULT_SPEC_MODEL_KEY
        return next(iter(available)) if available else DEFAULT_SPEC_MODEL_KEY

    def _workflow_model_setting_keys(self, workflow_key: str) -> Tuple[str, str, str]:
        """Perform workflow model setting keys.
        Used to keep the workflow logic localized and testable."""
        if workflow_key == "Analysis":
            return (
                "sol_analysis_spec_model_key",
                "sol_analysis_ph_model_key",
                "sol_analysis_use_same_model",
            )
        if workflow_key == "Reprocessing":
            return (
                "sol_reprocessing_spec_model_key",
                "sol_reprocessing_ph_model_key",
                "sol_reprocessing_use_same_model",
            )
        return (
            "sol_planning_spec_model_key",
            "sol_planning_ph_model_key",
            "sol_planning_use_same_model",
        )

    def _workflow_model_attribute_keys(self, workflow_key: str) -> Tuple[str, str, str]:
        """Perform workflow model attribute keys.
        Used to keep the workflow logic localized and testable."""
        if workflow_key == "Analysis":
            return (
                "_analysis_spec_model_key",
                "_analysis_ph_model_key",
                "_analysis_use_same_model",
            )
        if workflow_key == "Reprocessing":
            return (
                "_reprocessing_spec_model_key",
                "_reprocessing_ph_model_key",
                "_reprocessing_use_same_model",
            )
        return (
            "_planning_spec_model_key",
            "_planning_ph_model_key",
            "_planning_use_same_model",
        )

    def _workflow_model_label_for_key(self, model_key: str) -> str:
        """Perform workflow model label for key.
        Used to keep the workflow logic localized and testable."""
        display_map = getattr(self, "_workflow_model_display_map", {})
        # Iterate over items from display_map to apply the per-item logic.
        for label, key in display_map.items():
            if key == model_key:
                return label
        return next(iter(display_map.keys()), model_key)

    def _settings_dict(self) -> Dict[str, Any]:
        """Perform settings dict.
        Used to keep the workflow logic localized and testable."""
        ref = getattr(self, "settings", None)
        return ref if isinstance(ref, dict) else settings

    def _sync_workflow_model_state(
        self,
        workflow_key: str,
        *,
        spec_key: Optional[str] = None,
        ph_key: Optional[str] = None,
        use_same: Optional[bool] = None,
        refresh_ui: bool = True,
        save: bool = True,
    ) -> Tuple[str, str, bool]:
        """Perform sync workflow model state.
        Used to keep the workflow logic localized and testable."""
        settings_ref = self._settings_dict()
        spec_attr, ph_attr, use_attr = self._workflow_model_attribute_keys(workflow_key)
        setting_spec, setting_ph, setting_use = self._workflow_model_setting_keys(
            workflow_key
        )
        default_spec = getattr(self, "_sol_model_key", DEFAULT_SPEC_MODEL_KEY)
        current_spec = getattr(self, spec_attr, default_spec)
        current_ph = getattr(self, ph_attr, current_spec)
        current_use = bool(getattr(self, use_attr, True))
        resolved_spec = self._normalize_speciation_model_key(
            spec_key if spec_key is not None else current_spec,
            fallback=default_spec,
        )
        resolved_use_same = current_use if use_same is None else bool(use_same)
        if resolved_use_same:
            resolved_ph = resolved_spec
        else:
            resolved_ph = self._normalize_speciation_model_key(
                ph_key if ph_key is not None else current_ph, fallback=resolved_spec
            )
        setattr(self, spec_attr, resolved_spec)
        setattr(self, ph_attr, resolved_ph)
        setattr(self, use_attr, resolved_use_same)
        if isinstance(settings_ref, dict):
            settings_ref[setting_spec] = resolved_spec
            settings_ref[setting_ph] = resolved_ph
            settings_ref[setting_use] = resolved_use_same
        if refresh_ui:
            vars_map = getattr(self, "_workflow_model_vars", {})
            entry = vars_map.get(workflow_key, {})
            spec_var = entry.get("spec_var")
            ph_var = entry.get("ph_var")
            use_same_var = entry.get("use_same_var")
            ph_frame = entry.get("ph_frame")
            try:
                label = self._workflow_model_label_for_key(resolved_spec)
                if spec_var is not None:
                    spec_var.set(label)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                ph_label = self._workflow_model_label_for_key(resolved_ph)
                if ph_var is not None:
                    ph_var.set(ph_label)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if use_same_var is not None:
                try:
                    use_same_var.set(resolved_use_same)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            if ph_frame is not None:
                try:
                    if resolved_use_same:
                        ph_frame.grid_remove()
                    else:
                        ph_frame.grid()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        if save:
            try:
                self._schedule_save_settings()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        return resolved_spec, resolved_ph, resolved_use_same

    def _resolve_workflow_model_keys(
        self, workflow_key: str, form_data: Optional[Dict[str, Any]] = None
    ) -> Tuple[str, str, bool]:
        """Resolve workflow model keys.
        Used to compute workflow model keys before rendering or export."""
        spec_attr, ph_attr, use_attr = self._workflow_model_attribute_keys(workflow_key)
        setting_spec, setting_ph, setting_use = self._workflow_model_setting_keys(
            workflow_key
        )
        use_same = None
        if isinstance(form_data, dict):
            use_same = form_data.get(setting_use.replace("sol_", ""))
            if use_same is None:
                use_same = form_data.get(setting_use)
        if use_same is None:
            use_same = bool(getattr(self, use_attr, True))
        spec_key = None
        ph_key = None
        if isinstance(form_data, dict):
            spec_key = form_data.get(setting_spec.replace("sol_", ""))
            ph_key = form_data.get(setting_ph.replace("sol_", ""))
            if spec_key is None:
                spec_key = form_data.get(setting_spec)
            if ph_key is None:
                ph_key = form_data.get(setting_ph)
        if not spec_key:
            spec_key = getattr(self, spec_attr, None)
        if not ph_key:
            ph_key = getattr(self, ph_attr, None)
        spec_key = self._normalize_speciation_model_key(
            spec_key, fallback=getattr(self, "_sol_model_key", None)
        )
        if use_same:
            ph_key = spec_key
        else:
            ph_key = self._normalize_speciation_model_key(ph_key, fallback=spec_key)
        return spec_key, ph_key, bool(use_same)

    def _resolve_planning_model_keys(
        self, form_data: Optional[Dict[str, Any]] = None
    ) -> Tuple[str, str, bool]:
        """Resolve planning model keys.
        Used to compute planning model keys before rendering or export."""
        return self._resolve_workflow_model_keys("Planning", form_data)

    def _planning_field_is_visible(self, field_id: str) -> bool:
        """Check whether it is visible.
        Used by planning field workflows to check visible."""
        registry = getattr(self, "_planning_field_registry", {})
        meta = registry.get(field_id)
        if not meta:
            return True
        frame = meta.get("frame")
        if frame is None:
            return True
        try:
            return bool(frame.winfo_ismapped())
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return True

    def _refresh_planning_model_fields_visibility(self) -> None:
        """Refresh planning model fields visibility.
        Used to sync planning model fields visibility with current settings."""
        registry = getattr(self, "_planning_field_registry", {})
        if not registry:
            return
        spec_key, ph_key, use_same = self._resolve_planning_model_keys()
        active_keys = {spec_key} if use_same else {spec_key, ph_key}

        # Closure captures _refresh_planning_model_fields_visibility local context to keep helper logic scoped and invoked directly within _refresh_planning_model_fields_visibility.
        def _visible_fields_for(model_key: str) -> Optional[Set[str]]:
            """Perform visible fields for.
            Used to keep the workflow logic localized and testable."""
            required = MODEL_REQUIRED_FIELDS.get(model_key)
            optional = MODEL_OPTIONAL_FIELDS.get(model_key)
            if required is None and optional is None:
                return None
            combined = set(required or set())
            combined.update(optional or set())
            return combined

        visible_fields: Optional[Set[str]] = set()
        # Iterate over active_keys to apply the per-item logic.
        for model_key in active_keys:
            fields = _visible_fields_for(model_key)
            if fields is None:
                visible_fields = None
                break
            visible_fields.update(fields)
        # Iterate over items from registry to apply the per-item logic.
        for field_id, meta in registry.items():
            frame = meta.get("frame")
            if frame is None:
                continue
            try:
                if visible_fields is None or field_id in visible_fields:
                    frame.grid()
                else:
                    frame.grid_remove()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _on_select_planning_spec_model(self, _event: Optional[tk.Event] = None) -> None:
        """Handle select planning spec model.
        Used as an event callback for select planning spec model."""
        self._on_select_workflow_spec_model("Planning", _event)

    def _on_select_planning_ph_model(self, _event: Optional[tk.Event] = None) -> None:
        """Handle select planning pH model.
        Used as an event callback for select planning pH model."""
        self._on_select_workflow_ph_model("Planning", _event)

    def _toggle_planning_same_model(self) -> None:
        """Toggle planning same model.
        Used to flip planning same model and refresh dependent views."""
        self._toggle_workflow_same_model("Planning")

    def _on_select_workflow_spec_model(
        self, workflow_key: str, _event: Optional[tk.Event] = None
    ) -> None:
        """Handle select workflow spec model.
        Used as an event callback for select workflow spec model."""
        vars_map = getattr(self, "_workflow_model_vars", {})
        entry = vars_map.get(workflow_key, {})
        spec_var = entry.get("spec_var")
        display_value = spec_var.get() if spec_var is not None else None
        display_map = getattr(self, "_workflow_model_display_map", {})
        key = display_map.get(display_value) if display_value else None
        key = self._normalize_speciation_model_key(
            key, fallback=getattr(self, "_sol_model_key", None)
        )
        use_same_var = entry.get("use_same_var")
        use_same = bool(use_same_var.get()) if use_same_var is not None else True
        self._sync_workflow_model_state(
            workflow_key,
            spec_key=key,
            use_same=use_same,
            refresh_ui=True,
            save=False,
        )
        self._sol_last_form_data = None
        if workflow_key == "Planning":
            self._refresh_planning_model_fields_visibility()
        try:
            self._schedule_save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _on_select_workflow_ph_model(
        self, workflow_key: str, _event: Optional[tk.Event] = None
    ) -> None:
        """Handle select workflow pH model.
        Used as an event callback for select workflow pH model."""
        vars_map = getattr(self, "_workflow_model_vars", {})
        entry = vars_map.get(workflow_key, {})
        ph_var = entry.get("ph_var")
        display_value = ph_var.get() if ph_var is not None else None
        display_map = getattr(self, "_workflow_model_display_map", {})
        key = display_map.get(display_value) if display_value else None
        spec_attr, _ph_attr, _use_attr = self._workflow_model_attribute_keys(
            workflow_key
        )
        key = self._normalize_speciation_model_key(
            key, fallback=getattr(self, spec_attr, None)
        )
        self._sync_workflow_model_state(
            workflow_key,
            ph_key=key,
            use_same=False,
            refresh_ui=True,
            save=False,
        )
        self._sol_last_form_data = None
        if workflow_key == "Planning":
            self._refresh_planning_model_fields_visibility()
        try:
            self._schedule_save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _toggle_workflow_same_model(self, workflow_key: str) -> None:
        """Toggle workflow same model.
        Used to flip workflow same model and refresh dependent views."""
        vars_map = getattr(self, "_workflow_model_vars", {})
        entry = vars_map.get(workflow_key, {})
        use_same_var = entry.get("use_same_var")
        use_same = bool(use_same_var.get()) if use_same_var is not None else True
        self._sync_workflow_model_state(
            workflow_key,
            use_same=use_same,
            refresh_ui=True,
            save=False,
        )
        self._sol_last_form_data = None
        if workflow_key == "Planning":
            self._refresh_planning_model_fields_visibility()
        try:
            self._schedule_save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _refresh_sol_model_info(self) -> None:
        """Refresh sol model info.
        Used to sync sol model info with current settings."""

        info_var = getattr(self, "_sol_model_info_var", None)
        if info_var is None:
            return
        try:
            model = get_speciation_model(getattr(self, "_sol_model_key", None))
        except KeyError:
            model = get_speciation_model(None)
        meta = getattr(model, "metadata", None)
        temperature_c = None
        params = (
            getattr(self, "_sol_last_form_data", {}).get("params")
            if getattr(self, "_sol_last_form_data", None)
            else None
        )
        if params is not None:
            temperature_c = params.temperature_c
        result = getattr(self, "_sol_last_result", None)
        ionic_strength = getattr(result, "ionic_strength", None) if result else None
        details = [model.description.strip()]
        warnings: List[str] = []
        if meta:
            details.append(f"Reference: {meta.reference}.")
            temp_range = getattr(meta, "temperature_range_c", None)
            if temp_range:
                details.append(
                    f"Valid between {temp_range[0]:.0f}-{temp_range[1]:.0f} °C."
                )
                if temperature_c is not None and not (
                    temp_range[0] <= temperature_c <= temp_range[1]
                ):
                    warnings.append(
                        f"Temperature {temperature_c:.1f} °C outside validated range."
                    )
            ionic_limit = getattr(meta, "ionic_strength_limit", None)
            if ionic_limit is not None:
                details.append(f"Ionic strength capped at {ionic_limit:.2f} M.")
                if ionic_strength is not None and ionic_strength > ionic_limit:
                    warnings.append(
                        f"Ionic strength {ionic_strength:.3f} M exceeds the model limit."
                    )
            notes = getattr(meta, "notes", "")
            if notes:
                details.append(notes.strip())
        info_text = " ".join(details)
        if warnings:
            info_text = f"{info_text} Warnings: {'; '.join(warnings)}"
        info_var.set(info_text)

    def _cycle_preserved_entries_and_total(
        self, *, prefix: str = CYCLE_TRACKER_NOTE_PREFIX
    ) -> Tuple[List[Dict[str, Any]], float]:
        """Perform cycle preserved entries and total.
        Used to keep the workflow logic localized and testable."""
        existing_entries = list(getattr(self, "_sol_tracking_entries", []))
        preserved = [
            record
            # Iterate to apply the per-item logic.
            for record in existing_entries
            if prefix not in str(record.get("notes", ""))
        ]
        running_total = 0.0
        # Iterate over preserved to apply the per-item logic.
        for record in preserved:
            val = _safe_float(record.get("co2_g"))
            if val is not None and math.isfinite(val):
                running_total = max(running_total, float(val))
        return preserved, running_total

    def _build_cycle_entries_from_payload(
        self,
        payload: Optional[Dict[str, Any]],
        *,
        starting_total: float = 0.0,
        timestamp: str,
        gas_molar_mass: Optional[float] = None,
        prefix: str = CYCLE_TRACKER_NOTE_PREFIX,
    ) -> Tuple[List[Dict[str, Any]], float]:
        """Build cycle entries from payload.
        Used to assemble cycle entries from payload during UI or plot setup."""
        if not payload:
            return [], starting_total
        running_total = float(starting_total or 0.0)
        try:
            gas_molar_mass = float(
                gas_molar_mass
                or payload.get("gas_molar_mass")
                or DEFAULT_GAS_MOLAR_MASS
            )
            if not math.isfinite(gas_molar_mass) or gas_molar_mass <= 0:
                raise ValueError
        except Exception:
            gas_molar_mass = DEFAULT_GAS_MOLAR_MASS
        entries: List[Dict[str, Any]] = []
        cycles = payload.get("cycle_transfer") or []
        # Iterate over indexed elements from cycles, 1 to apply the per-item logic.
        for idx, cycle in enumerate(cycles, 1):
            cycle_id = cycle.get("cycle_id", idx)
            mass = _safe_float(cycle.get("selected_mass_g"))
            if mass is None:
                mass = _safe_float(cycle.get("co2_mass_g"))
            if mass is None:
                moles_val = _safe_float(
                    cycle.get("selected_moles") or cycle.get("co2_moles")
                )
                if moles_val is not None and math.isfinite(moles_val):
                    mass = moles_val * gas_molar_mass
            if mass is None or not math.isfinite(mass) or mass <= 0:
                continue
            cumulative_mass = _safe_float(cycle.get("cumulative_co2_mass_g"))
            if cumulative_mass is not None and math.isfinite(cumulative_mass):
                running_total = float(cumulative_mass)
            else:
                running_total += float(mass)
            cycle_moles = _safe_float(
                cycle.get("selected_moles") or cycle.get("co2_moles")
            )
            deltaP = _safe_float(cycle.get("delta_pressure_psi") or cycle.get("deltaP"))
            temp_c = _safe_float(cycle.get("mean_temperature_c"))
            basis = cycle.get("moles_basis")
            note_parts = [prefix, f"Cycle {cycle_id}"]
            if deltaP is not None and math.isfinite(deltaP):
                note_parts.append(f"DeltaP {deltaP:.2f} PSI")
            if temp_c is not None and math.isfinite(temp_c):
                note_parts.append(f"T {temp_c:.1f} C")
            if basis:
                note_parts.append(f"Basis {basis}")
            entries.append(
                {
                    "timestamp": timestamp,
                    "co2_g": float(running_total),
                    "ph": None,
                    "notes": " | ".join(note_parts),
                    "cycle_id": cycle_id,
                    "cycle_mass_g": float(mass),
                    "cycle_moles": (
                        float(cycle_moles)
                        if cycle_moles is not None and math.isfinite(cycle_moles)
                        else None
                    ),
                    "delta_pressure_psi": deltaP,
                    "temperature_c": temp_c,
                    "basis": basis,
                }
            )
        return entries, running_total

    def _send_cycles_to_speciation_engine(self) -> None:
        """Perform send cycles to speciation engine.
        Used to keep the workflow logic localized and testable."""
        payload = getattr(self, "_cycle_last_transfer_payload", None)
        success = self._apply_cycle_payload_to_solubility(
            payload=payload,
            notify=True,
            run_simulation=False,
            workflow_key="Analysis",
        )
        if not success:
            return
        self._select_sol_workflow_tab("Analysis")
        self._run_analysis_scenario(skip_apply=True)

    def _send_cycles_to_reaction_tracker(self) -> None:
        """Perform send cycles to reaction tracker.
        Used to keep the workflow logic localized and testable."""
        payload = getattr(self, "_cycle_last_transfer_payload", None)
        if not payload:
            try:
                messagebox.showinfo(
                    "Cycle Analysis",
                    "Run Cycle Analysis before sending cycles to the Reaction Progress tracker.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        cycles = payload.get("cycle_transfer") or []
        if not cycles:
            try:
                messagebox.showwarning(
                    "Cycle Analysis",
                    "No per-cycle data available. Re-run Cycle Analysis to refresh the transfer payload.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        gas_molar_mass = payload.get("gas_molar_mass") or DEFAULT_GAS_MOLAR_MASS
        try:
            gas_molar_mass = float(gas_molar_mass)
            if not math.isfinite(gas_molar_mass) or gas_molar_mass <= 0:
                raise ValueError
        except Exception:
            gas_molar_mass = DEFAULT_GAS_MOLAR_MASS
        timestamp = payload.get("timestamp")
        if timestamp:
            try:
                timestamp = datetime.fromisoformat(str(timestamp)).strftime(
                    "%Y-%m-%d %H:%M"
                )
            except Exception:
                timestamp = str(timestamp)
        if not timestamp:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
        preserved_entries, running_total = self._cycle_preserved_entries_and_total()
        imported_entries, _ = self._build_cycle_entries_from_payload(
            payload,
            starting_total=running_total,
            timestamp=timestamp,
            gas_molar_mass=gas_molar_mass,
        )
        if not imported_entries:
            try:
                messagebox.showwarning(
                    "Cycle Analysis",
                    "Unable to derive CO2 mass for any cycles. Check the analysis results.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        combined = preserved_entries + imported_entries
        self._sol_tracking_entries = combined
        self._apply_sol_tracking_entries_to_structured()
        try:
            self.nb.select(self.tab_solubility)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            messagebox.showinfo(
                "Cycle Analysis",
                f"{len(imported_entries)} cycle entries sent to the Reaction Progress tracker.",
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _apply_cycle_payload_to_solubility(
        self,
        *,
        payload: dict[str, Any] | None = None,
        notify: bool = False,
        run_simulation: bool = True,
        workflow_key: str | None = None,
    ) -> bool:
        """Apply cycle payload to solubility.
        Purpose: Transfer Cycle Analysis payload data into solubility inputs/tracking.
        Why: Keep Analysis/Planning/Reprocessing workflows synchronized with cycle runs.
        Inputs:
            payload (dict[str, Any] | None): Cycle payload to apply (None uses last).
            notify (bool): When True, show user notifications for applied transfers.
            run_simulation (bool): When True, run the cycle simulation after applying.
            workflow_key (str | None): Target workflow key (None uses current).
        Outputs:
            bool: True if payload was applied; False if payload was missing/invalid.
        Side Effects:
            - Updates solubility Tk variables and cycle tracking state.
            - Stores payloads for the target workflow.
            - May trigger simulations or refresh cycle views.
        Exceptions:
            - Best-effort; handles notification/UI failures without raising.
        """
        payload = payload or getattr(self, "_cycle_last_transfer_payload", None)
        if not payload:
            if notify:
                try:
                    messagebox.showinfo(
                        "Cycle Analysis",
                        "Run Cycle Analysis before sending results "
                        "to Advanced Solubility.",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the
                    # workflow.
                    pass
            return False
        workflow = workflow_key or self._current_solubility_workflow()

        moles = payload.get("total_moles_vdw")
        if moles is None:
            moles = payload.get("total_moles_ideal")
        gas_molar_mass = payload.get("gas_molar_mass") or DEFAULT_GAS_MOLAR_MASS
        if moles is None or gas_molar_mass is None:
            if notify:
                try:
                    messagebox.showwarning(
                        "Cycle Analysis",
                        "Unable to determine CO2 mass from the last run.",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the
                    # workflow.
                    pass
            return False

        try:
            co2_g = float(moles) * float(gas_molar_mass)
        except Exception:
            co2_g = 0.0

        co2_autofilled = False
        target_var = self._solubility_vars.get("reaction_co2_charged_g")
        if target_var is not None:
            try:
                current_value = target_var.get()
            except Exception:
                current_value = ""
            current_str = "" if current_value is None else str(current_value)
            # Analysis: preserve user-entered CO2 unless the field is blank.
            if workflow != "Analysis" or not current_str.strip():
                target_var.set(f"{co2_g:.2f}")
                co2_autofilled = True

        reaction_naoh_var = self._solubility_vars.get("reaction_naoh_mass_g")
        planning_naoh_var = self._solubility_vars.get("mass_naoh_g")
        if reaction_naoh_var is not None and planning_naoh_var is not None:
            try:
                naoh_value = float(reaction_naoh_var.get())
            except Exception:
                naoh_value = None
            if naoh_value is not None and math.isfinite(naoh_value) and naoh_value > 0:
                try:
                    planning_value = planning_naoh_var.get()
                except Exception:
                    planning_value = ""
                planning_str = "" if planning_value is None else str(planning_value)
                # Planning: do not overwrite user-entered NaOH mass after a run.
                if workflow != "Planning" or not planning_str.strip():
                    planning_naoh_var.set(f"{naoh_value:.4f}")

        timestamp = payload.get("timestamp")
        if timestamp:
            try:
                timestamp = datetime.fromisoformat(str(timestamp)).strftime(
                    "%Y-%m-%d %H:%M"
                )
            except Exception:
                timestamp = str(timestamp)
        if not timestamp:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")

        entry = {
            "timestamp": timestamp,
            "co2_g": co2_g,
            "ph": None,
            "notes": "Imported from Cycle Analysis",
        }
        preserved_entries, running_total = self._cycle_preserved_entries_and_total()
        imported_entries, _ = self._build_cycle_entries_from_payload(
            payload,
            starting_total=running_total,
            timestamp=timestamp,
            gas_molar_mass=gas_molar_mass,
        )
        if not imported_entries:
            if notify:
                try:
                    messagebox.showwarning(
                        "Cycle Analysis",
                        "Unable to derive CO2 mass for any cycles. "
                        "Check the analysis results.",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the
                    # workflow.
                    pass
            return False

        combined = preserved_entries + imported_entries + [entry]
        self._sol_tracking_entries = combined
        self._apply_sol_tracking_entries_to_structured()
        try:
            self.nb.select(self.tab_solubility)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._set_cycle_payload_for_workflow(workflow, payload)
        if run_simulation:
            self._run_cycle_solubility_simulation(
                payload=payload, notify=notify, workflow_key=workflow
            )
        elif workflow == self._current_solubility_workflow():
            self._refresh_cycle_views()
        if notify:
            try:
                messagebox.showinfo(
                    "Cycle Analysis",
                    f"{len(imported_entries)} cycle entries sent to the "
                    "Reaction Progress tracker.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if co2_autofilled:
                try:
                    messagebox.showinfo(
                        "Cycle Analysis",
                        f"Estimated {co2_g:.2f} g CO2 sent to Advanced Solubility.",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the
                    # workflow.
                    pass
        return True

    def _send_cycle_to_solubility(self) -> None:
        """Perform send cycle to solubility.
        Used to keep the workflow logic localized and testable."""
        payload = getattr(self, "_cycle_last_transfer_payload", None)
        success = self._apply_cycle_payload_to_solubility(
            payload=payload,
            notify=True,
            run_simulation=False,
            workflow_key="Analysis",
        )
        if not success:
            return
        self._select_sol_workflow_tab("Analysis")
        self._run_analysis_scenario(skip_apply=True)

    def _import_cycle_to_reprocessing(self) -> None:
        """Import cycle to reprocessing.
        Used to ingest cycle to reprocessing into the application."""
        payload = getattr(self, "_cycle_last_transfer_payload", None)
        success = self._apply_cycle_payload_to_solubility(
            payload=payload,
            notify=True,
            run_simulation=False,
            workflow_key="Reprocessing",
        )
        if not success:
            return
        self._select_sol_workflow_tab("Reprocessing")
        self._run_reprocessing_scenario()
        self._run_cycle_solubility_simulation(
            payload=payload, notify=False, workflow_key="Reprocessing"
        )

    def _run_cycle_solubility_simulation(
        self,
        payload: Optional[Dict[str, Any]] = None,
        *,
        notify: bool = False,
        workflow_key: Optional[str] = None,
    ) -> None:
        """Run cycle solubility simulation.
        Used to execute cycle solubility simulation and coordinate results."""
        workflow = workflow_key or self._current_solubility_workflow()
        treat_excess_as_headspace = workflow == "Planning"
        payload = payload or self._get_cycle_payload_for_workflow(workflow)
        status_var = getattr(self, "_sol_cycle_status_var", None)
        if payload is None:
            if status_var is not None:
                status_var.set("No cycle dataset available. Run Cycle Analysis first.")
            return
        cycles = payload.get("cycle_transfer") or []
        if not cycles:
            if status_var is not None:
                status_var.set("Cycle payload did not include per-cycle data.")
            return
        planning_measured_note: Optional[str] = None
        try:
            form_data = getattr(self, "_sol_last_form_data", None)
            if form_data is None:
                form_data = self._collect_solubility_form_data()
                self._sol_last_form_data = form_data
            planning_measured_note = self._scrub_planning_measured_fields(form_data)
            params = form_data["params"]
        except Exception as exc:
            if status_var is not None:
                status_var.set(f"Unable to gather solubility inputs: {exc}")
            if notify:
                try:
                    messagebox.showwarning(
                        "Advanced Solubility Module",
                        f"Unable to gather solubility inputs: {exc}",
                    )
                except Exception:
                    pass
            return
        try:
            factor = float(
                getattr(self, "_sol_cycle_supersat_var", tk.DoubleVar(value=1.0)).get()
            )
        except Exception:
            factor = 1.0
        slurry_mode = bool(
            getattr(self, "_sol_cycle_slurry_var", tk.BooleanVar(value=True)).get()
        )
        # Always honor the currently selected speciation model for cycle simulations.
        # Cached form data may carry an older model_key if the user changed the selection
        # after the last solve; refresh it here so the timeline uses the live choice.
        available_models = {model.key for model in list_speciation_models()}
        spec_key, ph_key, use_same = self._resolve_workflow_model_keys(
            workflow, form_data
        )
        model_key = spec_key
        if model_key not in available_models:
            aqion_key = "aqion_closed"
            model_key = (
                aqion_key if aqion_key in available_models else DEFAULT_SPEC_MODEL_KEY
            )
            spec_key = model_key
            if use_same:
                ph_key = model_key
            elif ph_key not in available_models:
                ph_key = model_key
            self._sol_model_key = model_key
        setting_spec, setting_ph, setting_use = self._workflow_model_setting_keys(
            workflow
        )
        try:
            form_data[setting_spec.replace("sol_", "")] = spec_key
            form_data[setting_ph.replace("sol_", "")] = ph_key
            form_data[setting_use.replace("sol_", "")] = use_same
            form_data["workflow_spec_model_key"] = spec_key
            form_data["workflow_ph_model_key"] = ph_key
            form_data["workflow_use_same_model"] = use_same
            form_data["model_key"] = model_key
            if isinstance(self._sol_last_form_data, dict):
                self._sol_last_form_data["model_key"] = model_key
        except Exception:
            form_data = dict(form_data or {})
            form_data[setting_spec.replace("sol_", "")] = spec_key
            form_data[setting_ph.replace("sol_", "")] = ph_key
            form_data[setting_use.replace("sol_", "")] = use_same
            form_data["workflow_spec_model_key"] = spec_key
            form_data["workflow_ph_model_key"] = ph_key
            form_data["workflow_use_same_model"] = use_same
            form_data["model_key"] = model_key
            self._sol_last_form_data = form_data
        context_workflow_key = form_data.get("workflow_key") or workflow
        naoh_mass_entry = form_data.get("reaction_naoh_mass")
        if naoh_mass_entry is None:
            naoh_mass_entry = form_data.get("naoh_mass_basis")
        solution_volume_entry = form_data.get("reaction_solution_volume")
        if solution_volume_entry is None:
            try:
                solution_volume_entry = params.solution_volume_l
            except Exception:
                solution_volume_entry = None
        reaction_context = {
            "naoh_mass_g": naoh_mass_entry,
            "solution_volume_l": solution_volume_entry,
            "target_ph": form_data.get("reaction_target_ph"),
            "measured_ph": form_data.get("reaction_final_ph"),
            "slurry_ph": form_data.get("reaction_slurry_ph"),
            "temperature_c": params.temperature_c,
            "use_temp_adjusted_constants": params.use_temperature_adjusted_constants,
            "ionic_strength_cap": params.ionic_strength_cap,
            "workflow_key": context_workflow_key,
            "planning_cycle_delta_p_psi": form_data.get("planning_cycle_delta_p_psi"),
            "planning_headspace_volume_l": form_data.get("planning_headspace_volume_l"),
            "planning_headspace_pressure_high_psi": form_data.get(
                "planning_headspace_pressure_high_psi"
            ),
            "planning_cycle_co2_g": form_data.get("planning_cycle_co2_g"),
            "planning_stop_co2_added_g": form_data.get("planning_stop_co2_added_g"),
            "planning_stop_ph": form_data.get("planning_stop_ph"),
            "planning_measured_note": planning_measured_note,
        }
        workflow_key = context_workflow_key
        if workflow_key == "Reprocessing":
            diag = form_data.get("diagnostic_data") or {}
            reproc_guidance = getattr(self, "_sol_reaction_guidance", {}) or {}
            reproc_context = reproc_guidance.get("reprocessing_workflow") or {}
            reaction_context.update(
                {
                    "reprocessing_mode": True,
                    "batch_mass_g": params.mass_na_hco3_g,
                    "solvent_basis": form_data.get("solvent_basis"),
                    "solvent_basis_value": form_data.get("solvent_basis_value"),
                    "failing_ph": form_data.get("failing_ph"),
                    "target_ph": diag.get("target_ph"),
                    "recommended_co2_g": reproc_context.get("recommended_co2_g"),
                    "baseline_spec": reproc_context.get("baseline_spec"),
                    "target_spec": reproc_context.get("target_spec"),
                    "measured_alk_meq": diag.get("slurry_alk_meq_l"),
                    "dissolved_limit_moles": reproc_context.get(
                        "dissolved_limit_moles"
                    ),
                    "baseline_carbon_m": reproc_context.get("baseline_carbon_m"),
                }
            )
            # Ensure reprocessing context always has a baseline/target spec and CO2 capacity.
            failing_ph = form_data.get("failing_ph")
            target_ph_val = diag.get("target_ph")
            measured_alk = diag.get("slurry_alk_meq_l")
            baseline_spec_ctx = reaction_context.get("baseline_spec")
            target_spec_ctx = reaction_context.get("target_spec")
            rec_co2_g = reaction_context.get("recommended_co2_g")
            dissolved_limit_moles = reaction_context.get("dissolved_limit_moles")
            baseline_carbon_m = reaction_context.get("baseline_carbon_m")
            try:
                volume_l = max(params.volume_l(), 1e-9)
            except Exception:
                volume_l = max(params.solution_volume_l or 1e-9, 1e-9)
            constants = None
            try:
                constants = _resolve_solubility_constants(
                    params, math_logger=None, section="Reprocessing timeline constants"
                )
            except Exception:
                constants = None
            if baseline_spec_ctx is None and failing_ph is not None:
                try:
                    baseline_spec_ctx, baseline_carbon_m = (
                        _reprocessing_speciation_from_ph(
                            params,
                            failing_ph,
                            constants=constants,
                            measured_alk_meq=measured_alk,
                            math_section="Reprocessing baseline (timeline)",
                        )
                    )
                except Exception:
                    baseline_spec_ctx = baseline_spec_ctx or reproc_context.get(
                        "baseline_spec"
                    )
            if baseline_carbon_m is None and baseline_spec_ctx is not None:
                baseline_carbon_m = getattr(baseline_spec_ctx, "total_carbon_m", None)
            if target_spec_ctx is None and target_ph_val is not None:
                try:
                    target_spec_ctx, target_carbon = _reprocessing_speciation_from_ph(
                        params,
                        target_ph_val,
                        constants=constants,
                        measured_alk_meq=measured_alk,
                        math_section="Reprocessing target (timeline)",
                    )
                    if rec_co2_g is None and baseline_carbon_m is not None:
                        delta_m = max(target_carbon - baseline_carbon_m, 0.0) * volume_l
                        rec_co2_g = delta_m * SOL_MW_CO2
                        dissolved_limit_moles = max(
                            delta_m, dissolved_limit_moles or 0.0
                        )
                except Exception:
                    target_spec_ctx = target_spec_ctx or reproc_context.get(
                        "target_spec"
                    )
            if (
                dissolved_limit_moles is None
                and rec_co2_g is not None
                and math.isfinite(rec_co2_g)
            ):
                dissolved_limit_moles = max(rec_co2_g / SOL_MW_CO2, 0.0)
            reaction_context.update(
                {
                    "baseline_spec": baseline_spec_ctx,
                    "target_spec": target_spec_ctx,
                    "recommended_co2_g": rec_co2_g,
                    "baseline_carbon_m": baseline_carbon_m,
                    "dissolved_limit_moles": dissolved_limit_moles,
                }
            )
        if status_var is not None:
            status_var.set("Simulating cycles...")

        # Snapshot inputs for thread safety/no-GIL readiness.
        model_key_value = spec_key
        ph_model_key_value = ph_key
        model_options_snapshot = form_data.get("model_options")
        params_snapshot = params
        cycles_snapshot = list(cycles)
        reaction_context_snapshot = copy.deepcopy(reaction_context)

        def _compute_cycle_result() -> Dict[str, Any]:
            """Compute cycle result.
            Used to derive cycle result for analysis or plotting."""
            try:
                spec_model_obj = get_speciation_model(model_key_value)
            except KeyError:
                spec_model_obj = get_speciation_model(None)
            try:
                ph_model_obj = get_speciation_model(ph_model_key_value)
            except KeyError:
                ph_model_obj = spec_model_obj
            return solubility_simulate_cycle_timeline(
                params_snapshot,
                cycles_snapshot,
                supersaturation_factor=factor,
                slurry_mode=slurry_mode,
                reaction_context=reaction_context_snapshot,
                model=spec_model_obj,
                ph_model=ph_model_obj,
                model_options=model_options_snapshot,
                treat_excess_as_headspace=treat_excess_as_headspace,
            )

        def _on_ok(result):
            """Handle ok.
            Used as an event callback for ok."""
            if payload and payload.get("reference_ledgers"):
                result["planning_reference_ledgers"] = payload.get("reference_ledgers")
            target_workflow = workflow_key or workflow
            self._set_cycle_result_for_workflow(target_workflow, result)
            self._set_cycle_payload_for_workflow(target_workflow, payload)
            self._update_cycle_solubility_widgets(result, workflow_key=target_workflow)
            if notify and result.get("timeline"):
                try:
                    messagebox.showinfo(
                        "Advanced Solubility Module",
                        "Cycle-resolved solubility simulation completed.",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        def _on_err(exc):
            """Handle err.
            Used as an event callback for err."""
            if status_var is not None:
                status_var.set(f"Cycle simulation failed: {exc}")
            if notify:
                try:
                    messagebox.showerror(
                        "Advanced Solubility Module",
                        f"Cycle simulation failed:\n{exc}",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        self._task_runner.submit(
            "cycle_solubility", _compute_cycle_result, _on_ok, _on_err
        )

    def _update_cycle_solubility_widgets(
        self, result: Optional[Dict[str, Any]], *, workflow_key: Optional[str] = None
    ) -> None:
        """Update cycle solubility widgets.
        Used to keep cycle solubility widgets in sync with current state."""
        tree = getattr(self, "_sol_cycle_tree", None) or getattr(
            self, "_sol_cycle_timeline_tree", None
        )
        status_var = getattr(self, "_sol_cycle_status_var", None)
        summary_var = getattr(self, "_sol_cycle_summary_var", None)
        if tree is None:
            return
        timeline = (result or {}).get("timeline") or []
        rows: List[Dict[str, str]] = []
        # Iterate over timeline to apply the per-item logic.
        for entry in timeline:
            if entry.get("error"):
                continue
            rows.append(
                {
                    "cycle": str(entry.get("cycle_id")),
                    "temp_c": f"{_safe_float(entry.get('temperature_c'), float('nan')):.2f}",
                    "deltaP": f"{_safe_float(entry.get('delta_pressure_psi'), float('nan')):.2f}",
                    "co2_mol": f"{_safe_float(entry.get('co2_moles'), float('nan')):.4f}",
                    "solid_g": f"{_safe_float(entry.get('solid_mass_g'), float('nan')):.2f}",
                    "ph": f"{_safe_float(entry.get('solution_ph'), float('nan')):.2f}",
                    "si": f"{_safe_float(entry.get('saturation_index'), float('nan')):.3f}",
                }
            )
        if tree is not None:
            columns = getattr(self, "_sol_cycle_timeline_columns", ())
            self._populate_treeview(tree, rows, columns)
        if status_var is not None:
            if not rows:
                if (
                    workflow_key or self._current_solubility_workflow()
                ) == "Reprocessing":
                    status_var.set(
                        "Import cycles to view the timeline. Showing pass/fail speciation preview."
                    )
                else:
                    status_var.set(
                        "Cycle simulation produced no usable rows. Check for solver errors."
                    )
            else:
                mode = "Slurry" if result.get("slurry_mode") else "Solution"
                status_var.set(
                    f"{len(rows)} cycles simulated ({mode}, factor {result.get('supersaturation_factor', 1.0):.2f})."
                )
        if summary_var is not None:
            if not rows:
                if (
                    workflow_key or self._current_solubility_workflow()
                ) == "Reprocessing":
                    summary_var.set(
                        "Cycle timeline unavailable until cycles are imported."
                    )
                else:
                    summary_var.set("Cycle timeline unavailable.")
            else:
                final_ph = result.get("final_ph")
                final_solid = result.get("final_solid_mass_g")
                total_mol = result.get("total_added_moles", 0.0)
                summary_var.set(
                    "Total CO2 added (cycles): "
                    f"{total_mol:.4f} mol ({total_mol * SOL_MW_CO2:.2f} g). "
                    f"Final slurry solids ≈ {final_solid or 0.0:.2f} g NaHCO₃ "
                    f"at pH {final_ph or float('nan'):.2f}."
                )
        self._update_cycle_spec_view(
            timeline, workflow_key=workflow_key or self._current_solubility_workflow()
        )

    def _collect_planning_timeline_legend_entries(
        self, axes: Sequence[Any]
    ) -> Tuple[List[Any], List[str]]:
        """Collect Planning timeline legend entries.
        Purpose: Gather unique handles/labels across timeline axes.
        Why: Planning plots use a consolidated legend for clarity and exports.
        Inputs:
            axes (Sequence[Any]): Axes to scan for legend entries.
        Outputs:
            Tuple[List[Any], List[str]]: Handles and labels in display order.
        Side Effects:
            None.
        Exceptions:
            - Best-effort; skips axes that fail to report legend entries.
        """
        handles: List[Any] = []
        labels: List[str] = []
        # Collect handles across axes so Planning exports are self-explanatory.
        for axis in axes:
            try:
                axis_handles, axis_labels = axis.get_legend_handles_labels()
            except Exception:
                continue
            for handle, label in zip(axis_handles, axis_labels):
                if not label or label.startswith("_") or label in labels:
                    continue
                handles.append(handle)
                labels.append(label)
        return handles, labels

    def _planning_timeline_legend_loc(
        self,
    ) -> Optional[Union[str, int, Tuple[float, float]]]:
        """Return Planning timeline legend location.
        Purpose: Reuse user-dragged legend placement in export figures.
        Why: Exports should reflect the on-screen legend position.
        Inputs:
            None.
        Outputs:
            Optional[Union[str, int, Tuple[float, float]]]: Legend loc or None.
        Side Effects:
            None.
        Exceptions:
            - Best-effort; returns None on lookup failure.
        """
        legend = getattr(self, "_planning_timeline_legend", None)
        if legend is None:
            return None
        try:
            return legend.get_loc()
        except Exception:
            return getattr(legend, "_loc", None)

    def _refresh_planning_timeline_legend(
        self,
        legend: Any,
        handles: Sequence[Any],
        labels: Sequence[str],
        host_axis: Any,
    ) -> None:
        """Refresh Planning timeline legend entries in place.
        Purpose: Update legend handles/labels without recreating the legend.
        Why: Preserves drag state and avoids repeated layout registration.
        Inputs:
            legend (Any): Existing legend instance to update.
            handles (Sequence[Any]): Legend handles to display.
            labels (Sequence[str]): Legend labels to display.
            host_axis (Any): Axis hosting the legend.
        Outputs:
            None.
        Side Effects:
            - Reattaches the legend to the axis and updates its entries.
        Exceptions:
            - Best-effort; ignores legend update failures.
        """
        if legend is None:
            return
        try:
            host_axis.add_artist(legend)
            host_axis.legend_ = legend
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            legend.set_visible(True)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            markerfirst = getattr(legend, "_markerfirst", True)
            # Update the legend box in place to preserve drag position.
            legend._init_legend_box(list(handles), list(labels), markerfirst=markerfirst)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _update_cycle_spec_view(
        self, timeline: Sequence[Dict[str, Any]], *, workflow_key: Optional[str] = None
    ) -> None:
        """Update cycle spec view.
        Purpose: Render the cycle timeline plot and associated callouts.
        Why: Keep the on-screen cycle speciation view aligned with the latest results.
        Inputs:
            timeline (Sequence[Dict[str, Any]]): Cycle timeline rows to plot.
            workflow_key (Optional[str]): Workflow identifier for plot context.
        Outputs:
            None.
        Side Effects:
            - Clears and redraws axes, legends, and callout widgets.
            - Updates the Planning legend in place when applicable.
        Exceptions:
            - Best-effort; exits early when plot widgets are unavailable.
        """
        workflow = workflow_key or self._current_solubility_workflow()
        timeline = list(timeline or [])
        reaction_guidance = getattr(self, "_sol_reaction_guidance", {}) or {}
        preview_mode = False
        if workflow == "Reprocessing" and not timeline:
            reproc = reaction_guidance.get("reprocessing_workflow") or {}
            baseline_spec = reproc.get("baseline_spec")
            target_spec = reproc.get("target_spec")
            recommended_co2 = reproc.get("recommended_co2_g")
            target_ph_hint = reproc.get("target_ph")
            fail_ph = reproc.get("failing_ph")

            def _spec_value(spec: Any, key: str, default: Any = None) -> Any:
                """Perform spec value.
                Used to keep the workflow logic localized and testable."""
                if spec is None:
                    return default
                if isinstance(spec, Mapping):
                    return spec.get(key, default)
                return getattr(spec, key, default)

            def _spec_fractions(spec: Any) -> Dict[str, float]:
                """Perform spec fractions.
                Used to keep the workflow logic localized and testable."""
                if spec is None:
                    return {}
                if isinstance(spec, Mapping):
                    return spec.get("fractional_carbon", {}) or spec.get(
                        "fractions", {}
                    )
                return getattr(spec, "fractional_carbon", {}) or {}

            def _spec_moles(spec: Any) -> Dict[str, float]:
                """Perform spec moles.
                Used to keep the workflow logic localized and testable."""
                if spec is None:
                    return {}
                if isinstance(spec, Mapping):
                    return spec.get("moles", {}) or {}
                return getattr(spec, "moles", {}) or {}

            preview_entries: List[Dict[str, Any]] = []
            if baseline_spec is not None:
                base_moles = _spec_moles(baseline_spec)
                preview_entries.append(
                    {
                        "cycle_id": "Fail",
                        "co2_g": 0.0,
                        "co2_mass_g": 0.0,
                        "co2_to_target_g": recommended_co2,
                        "solution_ph": _spec_value(
                            baseline_spec, "ph", default=fail_ph
                        ),
                        "fractions": _spec_fractions(baseline_spec),
                        "solid_na2co3_g": base_moles.get("CO3^2-", 0.0) * SOL_MW_NA2CO3,
                        "solid_nahco3_g": base_moles.get("HCO3-", 0.0) * SOL_MW_NAHCO3,
                    }
                )
            if target_spec is not None:
                target_moles = _spec_moles(target_spec)
                preview_entries.append(
                    {
                        "cycle_id": "Pass",
                        "co2_g": recommended_co2 or 0.0,
                        "co2_mass_g": recommended_co2 or 0.0,
                        "co2_to_target_g": 0.0,
                        "solution_ph": _spec_value(
                            target_spec, "ph", default=target_ph_hint
                        ),
                        "fractions": _spec_fractions(target_spec),
                        "solid_na2co3_g": target_moles.get("CO3^2-", 0.0)
                        * SOL_MW_NA2CO3,
                        "solid_nahco3_g": target_moles.get("HCO3-", 0.0)
                        * SOL_MW_NAHCO3,
                    }
                )
            if preview_entries:
                timeline = preview_entries
                preview_mode = True
        tree = getattr(self, "_sol_cycle_timeline_tree", None)
        columns = getattr(self, "_sol_cycle_timeline_columns", ())
        rows: List[Dict[str, Any]] = []
        target_ph = reaction_guidance.get("target_ph")
        recommended_co2 = reaction_guidance.get("recommended_co2_g")
        # Iterate over timeline to apply the per-item logic.
        for entry in timeline:
            if entry.get("error"):
                continue
            fractions = entry.get("fractions") or {}
            warnings = list(entry.get("warnings") or [])
            co2_total = (
                _safe_float(entry.get("co2_g"))
                or _safe_float(entry.get("co2_mass_g"))
                or 0.0
            )
            ph_value = entry.get("solution_ph")
            remaining_value = entry.get("co2_to_target_g")
            pco2_value = entry.get("pco2_atm")
            rows.append(
                {
                    "cycle": str(entry.get("cycle_id")),
                    "co2_cycle_g": f"{_safe_float(entry.get('co2_mass_g'), 0.0):.2f}",
                    "co2_g": f"{co2_total:.2f}",
                    "co2_to_target": (
                        f"{remaining_value:.2f}" if remaining_value is not None else ""
                    ),
                    "ph": f"{ph_value:.2f}" if ph_value is not None else "",
                    "pco2_atm": f"{pco2_value:.3g}" if pco2_value is not None else "",
                    "h2co3_pct": f"{fractions.get('H2CO3', 0.0) * 100:.1f}",
                    "hco3_pct": f"{fractions.get('HCO3-', 0.0) * 100:.1f}",
                    "co3_pct": f"{fractions.get('CO3^2-', 0.0) * 100:.1f}",
                    "solid_na2co3_g": f"{entry.get('solid_na2co3_g', 0.0):.2f}",
                    "solid_nahco3_g": f"{entry.get('solid_nahco3_g', 0.0):.2f}",
                    "warnings": " | ".join(warnings),
                }
            )
        show_tree = not (workflow == "Reprocessing" and (preview_mode or not timeline))
        if tree is not None:
            if show_tree:
                self._populate_treeview(tree, rows, columns)
            else:
                self._populate_treeview(tree, [], columns)
            self._toggle_cycle_tree_visibility(show_tree)
        self._resize_cycle_timeline_tree(len(rows) if show_tree else 0)
        self._set_timeline_action_state(bool(rows) and show_tree)

        ax = getattr(self, "_sol_cycle_spec_ax", None)
        ax2 = getattr(self, "_sol_cycle_spec_ax2", None)
        ax3 = getattr(self, "_sol_cycle_spec_ax3", None)
        canvas = getattr(self, "_sol_cycle_spec_canvas", None)
        if ax is None or ax2 is None or ax3 is None or canvas is None:
            return
        ax.clear()
        ax2.clear()
        ax3.clear()
        prefs = self._get_cycle_plot_prefs()
        ax.set_xlabel(r"Total CO$_2$ added (g)", fontsize=11, labelpad=8)
        ax.set_ylabel("Carbon species (%)", fontsize=11, labelpad=10)
        ax.tick_params(axis="both", labelsize=9, pad=4)
        ax2.set_ylabel("Predicted pH", fontsize=11, labelpad=10, rotation=-90)
        ax2.spines["right"].set_position(("axes", 1.02))
        ax2.yaxis.set_label_coords(1.08, 0.5)
        ax2.tick_params(axis="both", labelsize=9, pad=4)
        ax3.set_ylabel("Headspace pCO2 (atm)", fontsize=11, labelpad=10, rotation=-90)
        ax3.spines["right"].set_position(("axes", 1.12))
        ax3.yaxis.set_label_coords(1.18, 0.5)
        ax3.tick_params(axis="both", labelsize=8, pad=3)
        if not timeline:
            ax.text(0.5, 0.5, "No cycle data", ha="center", va="center")
            ax2.text(
                0.5,
                0.5,
                "Run a timeline simulation to preview speciation.",
                ha="center",
                va="center",
            )
            ax3.text(0.5, 0.5, "Headspace pCO2 unavailable", ha="center", va="center")
            canvas.draw_idle()
            return
        xs = []
        h2co3_vals = []
        hco3_vals = []
        co3_vals = []
        ph_values = []
        pco2_values: List[float] = []
        # Iterate over timeline to apply the per-item logic.
        for entry in timeline:
            xs.append(
                _safe_float(entry.get("co2_g"))
                or _safe_float(entry.get("co2_mass_g"))
                or 0.0
            )
            fractions = entry.get("fractions") or {}
            h2co3_vals.append(fractions.get("H2CO3", 0.0) * 100.0)
            hco3_vals.append(fractions.get("HCO3-", 0.0) * 100.0)
            co3_vals.append(fractions.get("CO3^2-", 0.0) * 100.0)
            ph = entry.get("solution_ph")
            ph_values.append(ph if ph is not None else float("nan"))
            try:
                pco2_values.append(float(entry.get("pco2_atm")))
            except Exception:
                pco2_values.append(float("nan"))
        show_legend = bool(prefs.get("show_legend"))
        if workflow == "Planning":
            species = [
                ("Carbonic acid (H2CO3)", h2co3_vals, "#55a868"),
                ("Bicarbonate (HCO3-)", hco3_vals, "#4c72b0"),
                ("Carbonate (CO3^2-)", co3_vals, "#dd8452"),
            ]
        else:
            species = [
                ("H2CO3", h2co3_vals, "#55a868"),
                ("HCO3-", hco3_vals, "#4c72b0"),
                ("CO3^2-", co3_vals, "#dd8452"),
            ]
        ax.stackplot(
            xs,
            h2co3_vals,
            hco3_vals,
            co3_vals,
            colors=[color for _, _, color in species],
            alpha=0.35,
        )
        # Iterate over species to apply the per-item logic.
        for label, values, color in species:
            ax.plot(
                xs,
                [val if val is not None else 0.0 for val in values],
                label=label,
                color=color,
            )
        species_min = prefs.get("species_min")
        species_max = prefs.get("species_max")
        if species_min is not None or species_max is not None:
            ax.set_ylim(
                species_min if species_min is not None else 0.0,
                species_max if species_max is not None else 100.0,
            )
        else:
            ax.set_ylim(0, 100)
        ax.grid(True, alpha=0.3)
        ax2.plot(xs, ph_values, color="#c44e52", marker="o", label="Predicted pH")
        ax3.plot(
            xs,
            pco2_values,
            color="#1b7b6b",
            marker="s",
            linestyle="--",
            linewidth=1.2,
            label="Headspace pCO2 (atm)" if workflow == "Planning" else "pCO2 (atm)",
        )
        if workflow == "Analysis":
            reference = getattr(self, "_analysis_reference_trace", None) or {}
            ref_x = reference.get("x_co2_g_series") or []
            ref_ph = reference.get("ph_series") or []
            ref_pairs = [
                (x_val, ph_val)
                # Iterate to apply the per-item logic.
                for x_val, ph_val in zip(ref_x, ref_ph)
                if x_val is not None
                and ph_val is not None
                and math.isfinite(x_val)
                and math.isfinite(ph_val)
            ]
            if ref_pairs:
                ref_xs, ref_phs = zip(*ref_pairs)
                ax2.plot(
                    ref_xs,
                    ref_phs,
                    color="#7a7a7a",
                    alpha=0.35,
                    linewidth=1.4,
                    label="Planning reference",
                    zorder=2,
                )
            marker = getattr(self, "_analysis_overlay_marker", None) or {}
            marker_x = marker.get("x")
            marker_ph = marker.get("ph")
            if (
                marker_x is not None
                and marker_ph is not None
                and math.isfinite(marker_x)
                and math.isfinite(marker_ph)
            ):
                ax2.scatter(
                    [marker_x],
                    [marker_ph],
                    s=140,
                    color="#f28e2b",
                    edgecolor="#222222",
                    linewidths=0.8,
                    label="Current state",
                    zorder=4,
                )
                label = marker.get("label") or "Current state (cycle-derived)"
                ax2.annotate(
                    label,
                    (marker_x, marker_ph),
                    textcoords="offset points",
                    xytext=(0, 12),
                    ha="center",
                    fontsize=8,
                    color="#333333",
                )
        ph_min = prefs.get("ph_min")
        ph_max = prefs.get("ph_max")
        if ph_min is not None or ph_max is not None:
            ax2.set_ylim(
                ph_min if ph_min is not None else 6.0,
                ph_max if ph_max is not None else 14.5,
            )
        else:
            ax2.set_ylim(6.0, 14.5)
        if target_ph is not None:
            ax2.axhline(target_ph, color="#2a9d8f", linestyle="--", linewidth=1.25)
            ax2.text(
                0.98,
                target_ph,
                f"Target pH {target_ph:.2f}",
                va="bottom",
                ha="right",
                fontsize=7,
                color="#2a9d8f",
            )
        # Iterate over paired elements from multiple sequences to apply the per-item logic.
        for x, ph, entry in zip(xs, ph_values, timeline):
            if not math.isfinite(ph):
                continue
            ax2.annotate(
                f"{entry.get('cycle_id')}",
                (x, ph),
                textcoords="offset points",
                xytext=(0, 6),
                ha="center",
                fontsize=7,
            )
        if workflow == "Planning":
            # Planning timeline legend is consolidated and draggable for clarity.
            handles, labels = self._collect_planning_timeline_legend_entries(
                (ax, ax2, ax3)
            )
            legend = getattr(self, "_planning_timeline_legend", None)
            if handles:
                if legend is None:
                    legend = ax.legend(
                        handles=handles, labels=labels, loc="upper left", fontsize=8
                    )
                    self._planning_timeline_legend = legend
                    _make_legend_draggable(legend)
                    layout_mgr = getattr(ax.figure, "_gl260_layout_manager", None)
                    if layout_mgr is not None:
                        layout_mgr.register_artist("plot_legend", legend)
                else:
                    self._refresh_planning_timeline_legend(
                        legend, handles, labels, ax
                    )
            elif legend is not None:
                try:
                    legend.set_visible(False)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        elif show_legend:
            ax.legend(loc="upper left", fontsize=8)
            ax2.legend(loc="upper right", fontsize=8)
            ax3.legend(loc="center right", fontsize=8)
        canvas.draw_idle()

        callout = getattr(self, "_sol_cycle_callouts", None)
        if callout is None:
            return
        try:
            view_state = callout.yview()
            visible_span = view_state[1] - view_state[0]
            stick_to_bottom = (1.0 - view_state[1]) <= max(0.02, visible_span * 0.25)
            preserve_top = view_state[0]
        except Exception:
            stick_to_bottom = True
            preserve_top = 0.0
        callout.configure(state="normal")
        callout.delete("1.0", "end")
        if not timeline:
            callout.insert("end", "No cycle speciation data available.")
        else:
            # Iterate over timeline to apply the per-item logic.
            for entry in timeline:
                co2_total = (
                    _safe_float(entry.get("co2_g"))
                    or _safe_float(entry.get("co2_mass_g"))
                    or 0.0
                )
                ph_value = entry.get("solution_ph")
                ph_text = f"{ph_value:.2f}" if ph_value is not None else "n/a"
                line = f"Cycle {entry.get('cycle_id')}: {co2_total:.2f} g CO2 -> pH {ph_text}"
                forecast_value = entry.get("forecast_ph")
                if forecast_value is not None:
                    line += f" (forecast {forecast_value:.2f})"
                remaining = entry.get("co2_to_target_g")
                if remaining is None and recommended_co2 is not None:
                    remaining = max(0.0, recommended_co2 - co2_total)
                if remaining is not None:
                    line += f" | CO2 to target: {remaining:.2f} g"
                warnings = entry.get("warnings") or []
                solid_na2co3 = entry.get("solid_na2co3_g", 0.0)
                solid_nahco3 = entry.get("solid_nahco3_g", 0.0)
                if solid_na2co3 or solid_nahco3:
                    line += (
                        f" | solids: {solid_na2co3:.2f} g Na2CO3 / "
                        f"{solid_nahco3:.2f} g NaHCO3"
                    )
                prediction = entry.get("analysis_prediction")
                if isinstance(prediction, Mapping):
                    target_ph_value = _safe_float(prediction.get("target_ph"))
                    co2_to_target_value = _safe_float(prediction.get("co2_to_target_g"))
                else:
                    target_ph_value = None
                    co2_to_target_value = None
                if target_ph_value is not None or co2_to_target_value is not None:
                    extras = []
                    if target_ph_value is not None:
                        extras.append(f"target pH {target_ph_value:.2f}")
                    if co2_to_target_value is not None:
                        extras.append(f"CO2 to target {co2_to_target_value:.2f} g")
                    line += " | " + ", ".join(extras)
        if warnings:
            line += f" (warnings: {'; '.join(warnings)})"
        callout.insert("end", line + "\n")
        callout.configure(state="disabled")
        try:
            if stick_to_bottom:
                callout.see("end")
            else:
                callout.yview_moveto(preserve_top)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _resize_cycle_timeline_tree(self, row_count: int) -> None:
        """Perform resize cycle timeline tree.
        Used to keep the workflow logic localized and testable."""
        tree = getattr(self, "_sol_cycle_timeline_tree", None)
        if tree is None:
            return
        try:
            current_height = int(tree.cget("height"))
        except Exception:
            current_height = 8
        try:
            base_height = 8
            max_height = 28
            desired = base_height if row_count <= 0 else min(max_height, row_count + 2)
            if row_count > 0:
                desired = max(desired, current_height)
            tree.configure(height=desired)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _set_timeline_action_state(self, enabled: bool) -> None:
        """Set timeline action state.
        Used to persist timeline action state into the current state."""
        state = "normal" if enabled else "disabled"
        # Iterate to apply the per-item logic.
        for attr in (
            "_sol_cycle_export_csv_btn",
            "_sol_cycle_export_plot_btn",
            "_sol_cycle_export_table_btn",
            "_sol_cycle_expand_btn",
        ):
            btn = getattr(self, attr, None)
            if btn is None:
                continue
            try:
                btn.configure(state=state)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _scroll_callouts_to_latest(self) -> None:
        """Perform scroll callouts to latest.
        Used to keep the workflow logic localized and testable."""
        callout = getattr(self, "_sol_cycle_callouts", None)
        if callout is None:
            return
        try:
            callout.see("end")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _get_current_timeline_table_data(
        self,
    ) -> Tuple[List[str], List[List[Any]], List[str]]:
        """Return current timeline table data.
        Used to retrieve current timeline table data for downstream logic."""

        tree = getattr(self, "_sol_cycle_timeline_tree", None)
        column_ids = list(getattr(self, "_sol_cycle_timeline_columns", ()))
        if tree is None or not column_ids:
            return [], [], []
        headers: List[str] = []
        # Iterate over column_ids to apply the per-item logic.
        for col in column_ids:
            try:
                label = tree.heading(col).get("text") or str(col)
            except Exception:
                label = str(col)
            headers.append(label)
        rows: List[List[Any]] = []
        try:
            children = tree.get_children("")
        except Exception:
            children = []
        # Iterate over children to apply the per-item logic.
        for iid in children:
            try:
                values = list(tree.item(iid).get("values", []))
            except Exception:
                values = []
            padded = values + [""] * (len(column_ids) - len(values))
            rows.append(padded[: len(column_ids)])
        return headers, rows, column_ids

    def _open_timeline_export_options(self) -> None:
        """Open timeline export options.
        Used by UI actions to open timeline export options."""
        headers, _rows, column_ids = self._get_current_timeline_table_data()
        if not column_ids:
            try:
                messagebox.showinfo(
                    "Cycle Speciation Timeline",
                    "Timeline columns are unavailable until a workflow is run.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        existing = getattr(self, "_timeline_export_opts_win", None)
        if existing is not None and existing.winfo_exists():
            existing.deiconify()
            existing.lift()
            return

        settings_ref = self._settings_dict()
        enabled_map = settings_ref.get("timeline_table_columns_enabled")
        if not isinstance(enabled_map, dict):
            enabled_map = {}
        normalized_map = {
            col_id: bool(enabled_map.get(col_id, True)) for col_id in column_ids
        }
        orientation = settings_ref.get("timeline_table_export_orientation", "portrait")
        if orientation not in {"portrait", "landscape"}:
            orientation = "portrait"
        acs_quality = bool(settings_ref.get("timeline_table_export_acs_quality", False))

        window = tk.Toplevel(self)
        window.title("Timeline Table Export Options")
        window.transient(self)
        window.resizable(False, False)
        window.protocol("WM_DELETE_WINDOW", window.destroy)
        self._timeline_export_opts_win = window

        container = ttk.Frame(window, padding=10)
        container.grid(row=0, column=0, sticky="nsew")
        container.columnconfigure(0, weight=1)

        ttk.Label(container, text="Select columns to include:").grid(
            row=0, column=0, sticky="w"
        )
        columns_frame = ttk.Frame(container)
        columns_frame.grid(row=1, column=0, sticky="w", pady=(4, 8))

        vars_by_id: Dict[str, tk.BooleanVar] = {}
        # Iterate over indexed elements from zip(column_ids, headers to apply the per-item logic.
        for idx, (col_id, header) in enumerate(zip(column_ids, headers)):
            var = tk.BooleanVar(value=normalized_map.get(col_id, True))
            vars_by_id[col_id] = var
            ttk.Checkbutton(columns_frame, text=header, variable=var).grid(
                row=idx, column=0, sticky="w", pady=2
            )

        ttk.Label(container, text="Page orientation:").grid(row=2, column=0, sticky="w")
        orientation_var = tk.StringVar(value=orientation)
        orientation_frame = ttk.Frame(container)
        orientation_frame.grid(row=3, column=0, sticky="w", pady=(4, 8))
        ttk.Radiobutton(
            orientation_frame,
            text="Portrait (8.5 x 11 in)",
            value="portrait",
            variable=orientation_var,
        ).grid(row=0, column=0, sticky="w", pady=2)
        ttk.Radiobutton(
            orientation_frame,
            text="Landscape (11 x 8.5 in)",
            value="landscape",
            variable=orientation_var,
        ).grid(row=1, column=0, sticky="w", pady=2)

        acs_var = tk.BooleanVar(value=acs_quality)
        ttk.Checkbutton(
            container,
            text="ACS publication-quality styling",
            variable=acs_var,
        ).grid(row=4, column=0, sticky="w", pady=(2, 8))

        button_frame = ttk.Frame(container)
        button_frame.grid(row=5, column=0, sticky="e")

        # Closure captures _open_timeline_export_options state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_timeline_export_options.
        def _apply() -> None:
            """Apply value.
            Used to apply value changes to live state."""
            new_map = {col_id: var.get() for col_id, var in vars_by_id.items()}
            if not any(new_map.values()):
                try:
                    messagebox.showwarning(
                        "Timeline Export Options",
                        "Select at least one column to export.",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                return
            settings_ref["timeline_table_columns_enabled"] = new_map
            settings_ref["timeline_table_export_orientation"] = orientation_var.get()
            settings_ref["timeline_table_export_acs_quality"] = bool(acs_var.get())
            try:
                self._schedule_save_settings()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        ttk.Button(button_frame, text="Cancel", command=window.destroy).grid(
            row=0, column=0, padx=4
        )
        ttk.Button(button_frame, text="Apply", command=_apply).grid(
            row=0, column=1, padx=4
        )

    def _open_timeline_viewer(self) -> None:
        """Open timeline viewer.
        Used by UI actions to open timeline viewer."""

        headers, rows, column_ids = self._get_current_timeline_table_data()
        if not rows:
            try:
                messagebox.showinfo(
                    "Cycle Speciation Timeline",
                    "Run a workflow to generate timeline results before expanding the table.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        window = tk.Toplevel(self)
        window.title("Cycle Speciation Timeline Viewer")
        window.geometry("1100x600")
        container = ttk.Frame(window)
        container.pack(fill="both", expand=True, padx=8, pady=8)
        container.grid_rowconfigure(0, weight=1)
        container.grid_columnconfigure(0, weight=1)
        tree = ttk.Treeview(
            container, columns=column_ids, show="headings", height=min(len(rows), 20)
        )
        # Iterate over paired elements from multiple sequences to apply the per-item logic.
        for col_id, header in zip(column_ids, headers):
            tree.heading(col_id, text=header)
            tree.column(col_id, anchor="center", width=140)
        yscroll = ttk.Scrollbar(container, orient="vertical", command=tree.yview)
        xscroll = ttk.Scrollbar(container, orient="horizontal", command=tree.xview)
        tree.configure(yscrollcommand=yscroll.set, xscrollcommand=xscroll.set)
        tree.grid(row=0, column=0, sticky="nsew")
        yscroll.grid(row=0, column=1, sticky="ns")
        xscroll.grid(row=1, column=0, sticky="ew")
        # Iterate over rows to apply the per-item logic.
        for row in rows:
            tree.insert("", "end", values=row)
        try:
            window.transient(self)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        window.focus_set()

    def _get_cycle_plot_prefs(self) -> Dict[str, Any]:
        """Return cycle plot prefs.
        Used to retrieve cycle plot prefs for downstream logic."""
        defaults = {
            "species_min": None,
            "species_max": None,
            "ph_min": None,
            "ph_max": None,
            "show_legend": False,
            "export_title": CYCLE_TIMELINE_EXPORT_DEFAULT_TITLE,
        }
        prefs = getattr(self, "_cycle_plot_prefs", {}) or {}
        merged = dict(defaults)
        if isinstance(prefs, dict):
            merged.update({k: prefs.get(k, v) for k, v in defaults.items()})
        self._cycle_plot_prefs = merged
        settings = getattr(self, "settings", None)
        if isinstance(settings, dict):
            settings["cycle_plot_prefs"] = merged
            try:
                self._schedule_save_settings()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        return merged

    def _open_cycle_plot_options(self) -> None:
        """Open cycle plot options.
        Used by UI actions to open cycle plot options."""

        # Closure captures _open_cycle_plot_options state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_cycle_plot_options.
        def _close() -> None:
            """Close value.
            Used by UI actions to close value safely."""
            if hasattr(self, "_cycle_plot_opts_win"):
                try:
                    self._cycle_plot_opts_win.destroy()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                self._cycle_plot_opts_win = None

        if getattr(self, "_cycle_plot_opts_win", None):
            try:
                self._cycle_plot_opts_win.lift()
                return
            except Exception:
                self._cycle_plot_opts_win = None

        prefs = self._get_cycle_plot_prefs()
        top = tk.Toplevel(self)
        top.title("Cycle Plot Options")
        top.resizable(False, False)
        self._cycle_plot_opts_win = top

        # Closure captures _open_cycle_plot_options local context to keep helper logic scoped and invoked directly within _open_cycle_plot_options.
        def _make_entry(row: int, label: str, initial: Optional[float]) -> tk.StringVar:
            """Perform make entry.
            Used to keep the workflow logic localized and testable."""
            ttk.Label(top, text=label).grid(
                row=row, column=0, sticky="w", padx=6, pady=4
            )
            var = tk.StringVar(value="" if initial is None else f"{initial}")
            ttk.Entry(top, textvariable=var, width=10).grid(
                row=row, column=1, sticky="w", padx=6, pady=4
            )
            return var

        species_min_var = _make_entry(0, "Species y-min", prefs.get("species_min"))
        species_max_var = _make_entry(1, "Species y-max", prefs.get("species_max"))
        ph_min_var = _make_entry(2, "pH y-min", prefs.get("ph_min"))
        ph_max_var = _make_entry(3, "pH y-max", prefs.get("ph_max"))
        export_title_var = tk.StringVar(
            value=prefs.get("export_title") or CYCLE_TIMELINE_EXPORT_DEFAULT_TITLE
        )
        ttk.Label(top, text="Export title").grid(
            row=4, column=0, sticky="w", padx=6, pady=4
        )
        ttk.Entry(top, textvariable=export_title_var, width=32).grid(
            row=4, column=1, sticky="w", padx=6, pady=4
        )
        show_legend_var = tk.BooleanVar(value=bool(prefs.get("show_legend", False)))
        ttk.Checkbutton(top, text="Show legend", variable=show_legend_var).grid(
            row=5, column=0, columnspan=2, sticky="w", padx=6, pady=4
        )

        # Closure captures _open_cycle_plot_options local context to keep helper logic scoped and invoked directly within _open_cycle_plot_options.
        def _parse_field(var: tk.StringVar) -> Optional[float]:
            """Parse field.
            Used to interpret field inputs safely."""
            raw = var.get().strip()
            if not raw:
                return None
            try:
                value = float(raw)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return None
            if not math.isfinite(value):
                return None
            return value

        # Closure captures _open_cycle_plot_options state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_cycle_plot_options.
        def _apply(reset: bool = False) -> None:
            """Apply value.
            Used to apply value changes to live state."""
            new_prefs = self._get_cycle_plot_prefs()
            if reset:
                new_prefs.update(
                    {
                        "species_min": None,
                        "species_max": None,
                        "ph_min": None,
                        "ph_max": None,
                        "show_legend": False,
                        "export_title": CYCLE_TIMELINE_EXPORT_DEFAULT_TITLE,
                    }
                )
            else:
                new_prefs.update(
                    {
                        "species_min": _parse_field(species_min_var),
                        "species_max": _parse_field(species_max_var),
                        "ph_min": _parse_field(ph_min_var),
                        "ph_max": _parse_field(ph_max_var),
                        "show_legend": bool(show_legend_var.get()),
                        "export_title": export_title_var.get().strip(),
                    }
                )
            self._cycle_plot_prefs = new_prefs
            settings = getattr(self, "settings", None)
            if isinstance(settings, dict):
                settings["cycle_plot_prefs"] = new_prefs
                try:
                    _save_settings_to_disk()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            try:
                self._refresh_cycle_views()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        btn_frame = ttk.Frame(top)
        btn_frame.grid(row=6, column=0, columnspan=2, sticky="e", padx=6, pady=6)
        ttk.Button(btn_frame, text="Apply", command=lambda: _apply(False)).grid(
            row=0, column=0, padx=4
        )
        ttk.Button(btn_frame, text="Reset to Auto", command=lambda: _apply(True)).grid(
            row=0, column=1, padx=4
        )
        ttk.Button(btn_frame, text="Close", command=_close).grid(
            row=0, column=2, padx=4
        )

        top.protocol("WM_DELETE_WINDOW", _close)

    def _toggle_cycle_tree_visibility(self, show: bool) -> None:
        """Toggle cycle tree visibility.
        Used to flip cycle tree visibility and refresh dependent views."""
        frame = getattr(self, "_sol_cycle_tree_frame", None)
        if frame is None:
            return
        try:
            if show:
                frame.grid()
            else:
                frame.grid_remove()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _refresh_cycle_views(
        self, timeline: Optional[Sequence[Dict[str, Any]]] = None
    ) -> None:
        """Refresh cycle views.
        Used to sync cycle views with current settings."""

        if timeline is None:
            state_result = self._get_cycle_result_for_workflow(
                self._current_solubility_workflow()
            )
            cycle_results = state_result or {}
            timeline = cycle_results.get("timeline", [])
        self._update_cycle_spec_view(
            timeline, workflow_key=self._current_solubility_workflow()
        )
        self._update_sol_simulation_plot(
            getattr(self, "_sol_reaction_guidance", {}) or {},
            getattr(self, "_sol_tracking_entries", []),
        )

    def _export_cycle_timeline_csv(self) -> None:
        """Export cycle timeline CSV.
        Used to serialize cycle timeline CSV for external workflows."""
        result = self._get_cycle_result_for_workflow(
            self._current_solubility_workflow()
        )
        timeline = (result or {}).get("timeline") or []
        if not timeline:
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module",
                    "Run the cycle simulation before exporting.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        path = filedialog.asksaveasfilename(
            title="Export Cycle Timeline",
            defaultextension=".csv",
            filetypes=[("CSV file", "*.csv")],
            initialfile="cycle_solubility_timeline.csv",
        )
        if not path:
            return
        fieldnames = [
            "cycle_id",
            "temperature_c",
            "delta_pressure_psi",
            "co2_moles",
            "co2_mass_g",
            "co2_added_moles",
            "co2_added_mass_g",
            "co2_consumed_moles",
            "co2_consumed_mass_g",
            "co2_unconsumed_moles",
            "co2_unconsumed_mass_g",
            "co2_total_moles",
            "co2_g",
            "cumulative_co2_added_moles",
            "cumulative_co2_added_mass_g",
            "cumulative_co2_consumed_moles",
            "cumulative_co2_consumed_mass_g",
            "cumulative_co2_unconsumed_moles",
            "cumulative_co2_unconsumed_mass_g",
            "co2_to_target_g",
            "solution_ph",
            "speciation_ph",
            "ionic_strength",
            "dissolved_mass_g",
            "effective_dissolved_mass_g",
            "solid_mass_g",
            "solid_na2co3_g",
            "solid_nahco3_g",
            "na2co3_total_mol",
            "nahco3_total_mol",
            "na2co3_dissolved_mol",
            "na2co3_solid_mol",
            "nahco3_dissolved_mol",
            "nahco3_solid_mol",
            "na2co3_dissolved_g",
            "nahco3_dissolved_g",
            "saturation_index",
            "headspace_pressure_psi",
            "pco2_atm",
            "headspace_co2_mol",
            "headspace_co2_g",
            "supersaturated",
            "regime",
            "error",
        ]
        try:
            with open(path, "w", newline="", encoding="utf-8") as handle:
                writer = csv.DictWriter(handle, fieldnames=fieldnames)
                writer.writeheader()
                # Iterate over timeline to apply the per-item logic.
                for row in timeline:
                    writer.writerow({key: row.get(key, "") for key in fieldnames})
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Advanced Solubility Module",
                    f"Failed to export timeline: {exc}",
                )
            except Exception:
                pass
            return
        try:
            messagebox.showinfo(
                "Advanced Solubility Module",
                f"Cycle timeline exported to {path}",
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _export_cycle_timeline_plot(self) -> None:
        """Export cycle timeline plot.
        Used to serialize cycle timeline plot for external workflows."""
        fig = self._build_cycle_timeline_export_figure((11.0, 8.5))
        if fig is None:
            try:
                messagebox.showinfo(
                    "Cycle Speciation Timeline",
                    "Run the cycle simulation before exporting the plot.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        path = filedialog.asksaveasfilename(
            title="Export Cycle Timeline Plot",
            defaultextension=".png",
            filetypes=[("PNG", "*.png"), ("PDF", "*.pdf"), ("SVG", "*.svg")],
            initialfile="cycle_speciation_timeline.png",
        )
        if not path:
            try:
                plt.close(fig)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        try:
            if path.lower().endswith(".pdf"):
                fig.savefig(path, format="pdf", bbox_inches="tight")
            elif path.lower().endswith(".svg"):
                fig.savefig(path, format="svg", bbox_inches="tight")
            else:
                fig.savefig(path, format="png", dpi=220, bbox_inches="tight")
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Cycle Speciation Timeline",
                    f"Failed to export timeline plot: {exc}",
                )
            except Exception:
                pass
            return
        finally:
            try:
                plt.close(fig)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            messagebox.showinfo(
                "Cycle Speciation Timeline",
                f"Timeline plot exported to {path}",
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _export_cycle_timeline_table(self) -> None:
        """Export cycle timeline table.
        Used to serialize cycle timeline table for external workflows."""
        settings_ref = self._settings_dict()
        headers, rows, column_ids = self._get_current_timeline_table_data()
        if not rows:
            try:
                messagebox.showinfo(
                    "Cycle Speciation Timeline",
                    "Run a workflow to generate the Cycle Speciation Timeline before exporting the table.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        initial_dir = settings_ref.get("timeline_table_export_dir") or os.getcwd()
        path = filedialog.asksaveasfilename(
            title="Export Cycle Timeline Table",
            defaultextension="",
            filetypes=[
                ("PDF", "*.pdf"),
                ("PNG", "*.png"),
                ("LaTeX", "*.tex"),
                ("All files", "*.*"),
            ],
            initialfile=f"cycle_speciation_timeline_table_{timestamp}",
            initialdir=initial_dir,
        )
        if not path:
            return
        try:
            settings_ref["timeline_table_export_dir"] = str(Path(path).parent)
            self._schedule_save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        target_path = Path(path)
        suffix = target_path.suffix.lower()
        if suffix not in {".pdf", ".png", ".tex"}:
            target_path = target_path.with_suffix(".pdf")
            suffix = ".pdf"
        if suffix == ".pdf":
            target_format = "pdf"
        elif suffix == ".png":
            target_format = "png"
        else:
            target_format = "tex"

        enabled_map = settings_ref.get("timeline_table_columns_enabled")
        if not isinstance(enabled_map, dict):
            enabled_map = {}
        selected_indices = [
            idx
            # Iterate to apply the per-item logic.
            for idx, col_id in enumerate(column_ids)
            if bool(enabled_map.get(col_id, True))
        ]
        if not selected_indices:
            try:
                messagebox.showwarning(
                    "Cycle Speciation Timeline",
                    "Export options disable all columns. Enable at least one column.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        export_headers = [headers[idx] for idx in selected_indices]
        export_rows = [
            [row[idx] if idx < len(row) else "" for idx in selected_indices]
            # Iterate to apply the per-item logic.
            for row in rows
        ]
        export_column_ids = [column_ids[idx] for idx in selected_indices]
        orientation = settings_ref.get("timeline_table_export_orientation", "portrait")
        if orientation not in {"portrait", "landscape"}:
            orientation = "portrait"
        acs_quality = bool(settings_ref.get("timeline_table_export_acs_quality", False))

        numeric_specs: Dict[str, Union[int, str]] = {
            "CO₂ per cycle (g)": 2,
            "CO₂ total (g)": 2,
            "CO₂ to target (g)": 2,
            "Predicted pH": 2,
            "pCO₂ (atm)": "sig3",
            "H₂CO₃ %": 1,
            "HCO₃- %": 1,
            "CO₃²- %": 1,
            "Solid Na₂CO₃ (g)": 2,
            "Solid NaHCO₃ (g)": 2,
        }
        placeholder_map = {
            "CHEMCO2": r"CO$_2$",
            "CHEMHCO3": r"HCO$_3^{-}$",
            "CHEMCO3": r"CO$_3^{2-}$",
            "CHEMH2CO3": r"H$_2$CO$_3$",
            "CHEMNA2CO3": r"Na$_2$CO$_3$",
            "CHEMNAHCO3": r"NaHCO$_3$",
            "CHEMNA": r"Na$^{+}$",
            "CHEMPCO2": r"pCO$_2$",
        }
        placeholder_patterns = [
            (r"CO₂|CO2", "CHEMCO2"),
            (r"HCO₃-?|HCO3-?", "CHEMHCO3"),
            (r"CO₃²-|CO3--|CO3\\^?2-?", "CHEMCO3"),
            (r"H₂CO₃|H2CO3", "CHEMH2CO3"),
            (r"Na₂CO₃|Na2CO3", "CHEMNA2CO3"),
            (r"NaHCO₃|NaHCO3", "CHEMNAHCO3"),
            (r"Na\\+|Na⁺|Na\\^\\+|Na\\^\\{\\+\\}", "CHEMNA"),
            (r"pCO₂|pCO2", "CHEMPCO2"),
        ]

        # Closure captures _export_cycle_timeline_table local context to keep helper logic scoped and invoked directly within _export_cycle_timeline_table.
        def _escape_text(text: str) -> str:
            """Perform escape text.
            Used to keep the workflow logic localized and testable."""
            safe = text
            # Iterate to apply the per-item logic.
            for char, esc in {
                "\\": r"\\",
                "&": r"\&",
                "%": r"\%",
                "$": r"\$",
                "#": r"\#",
                "_": r"\_",
                "{": r"\{",
                "}": r"\}",
                "~": r"\textasciitilde{}",
                "^": r"\^{}",
            }.items():
                safe = safe.replace(char, esc)
            return safe

        # Closure captures _export_cycle_timeline_table local context to keep helper logic scoped and invoked directly within _export_cycle_timeline_table.
        def _placeholderize(value: Any) -> str:
            """Perform placeholderize.
            Used to keep the workflow logic localized and testable."""
            text = "" if value is None else str(value)
            # Iterate over placeholder_patterns to apply the per-item logic.
            for pattern, token in placeholder_patterns:
                try:
                    text = re.sub(pattern, token, text)
                except re.error:
                    continue
            return _escape_text(text)

        # Closure captures _export_cycle_timeline_table local context to keep helper logic scoped and invoked directly within _export_cycle_timeline_table.
        def _replace_placeholders(text: str) -> str:
            """Perform replace placeholders.
            Used to keep the workflow logic localized and testable."""
            result = text
            # Iterate over items from placeholder_map to apply the per-item logic.
            for token, latex in placeholder_map.items():
                result = result.replace(token, latex)
            return result

        # Closure captures _export_cycle_timeline_table local context to keep helper logic scoped and invoked directly within _export_cycle_timeline_table.
        def _build_latex_doc(latex_table: str, include_inputenc: bool) -> str:
            """Build latex doc.
            Used to assemble latex doc during UI or plot setup."""
            inputenc = ""
            if include_inputenc:
                inputenc = "\\usepackage[utf8]{inputenc}\n\\usepackage[T1]{fontenc}\n"
            return _replace_placeholders(
                textwrap.dedent(
                    f"""
                    \\documentclass[11pt]{{article}}
                    {inputenc}\\usepackage[margin=0.85in]{{geometry}}
                    \\usepackage{{booktabs}}
                    \\usepackage{{longtable}}
                    \\usepackage{{array}}
                    \\usepackage{{caption}}
                    \\usepackage{{mathptmx}}
                    \\begin{{document}}
                    {latex_table}
                    \\end{{document}}
                    """
                )
            )

        subtitle_parts = []
        workflow_key = self._current_solubility_workflow()
        if workflow_key:
            subtitle_parts.append(f"Workflow: {workflow_key}")
        try:
            spec_key, ph_key, use_same = self._resolve_workflow_model_keys(workflow_key)
            subtitle_parts.append(
                f"Speciation model: {self._workflow_model_label_for_key(spec_key)}"
            )
            ph_label = (
                "Same as speciation model"
                if use_same
                else self._workflow_model_label_for_key(ph_key)
            )
            subtitle_parts.append(f"Predicted pH model: {ph_label}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        subtitle_text = " | ".join(subtitle_parts)
        export_dpi = max(1, self._get_export_dpi())
        output_dir = target_path.parent

        # Legacy LaTeX/longtable exports degraded Unicode labels and produced unstable
        # wrapping for long Notes while requiring external toolchains.
        if target_format in {"pdf", "png"}:
            try:
                figures = _render_timeline_table_matplotlib_pages(
                    export_headers,
                    export_rows,
                    numeric_specs,
                    CYCLE_TIMELINE_EXPORT_DEFAULT_TITLE,
                    subtitle_text,
                    export_dpi,
                    orientation=orientation,
                    column_ids=export_column_ids,
                    font_family=settings_ref.get("font_family"),
                    acs_quality=acs_quality,
                )
            except Exception as exc:
                try:
                    messagebox.showerror(
                        "Cycle Speciation Timeline",
                        f"Matplotlib export failed (render): {exc}\n"
                        f"Output folder: {output_dir}",
                    )
                except Exception:
                    pass
                return
            if not figures:
                try:
                    messagebox.showerror(
                        "Cycle Speciation Timeline",
                        "Matplotlib export failed (render): no pages were generated.\n"
                        f"Output folder: {output_dir}",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                return
            saved_paths: List[Path] = []
            try:
                if target_format == "pdf":
                    with PdfPages(target_path) as pdf:
                        # Iterate over figures to apply the per-item logic.
                        for fig in figures:
                            pdf.savefig(fig)
                            plt.close(fig)
                    saved_paths.append(target_path)
                    messagebox.showinfo(
                        "Cycle Speciation Timeline",
                        f"Timeline table exported to {target_path}",
                    )
                else:
                    base_path = target_path
                    if len(figures) == 1:
                        fig = figures[0]
                        fig.savefig(base_path, dpi=export_dpi)
                        plt.close(fig)
                        saved_paths.append(base_path)
                    else:
                        stem = base_path.with_suffix("")
                        # Iterate over indexed elements from figures, start=1 to apply the per-item logic.
                        for idx, fig in enumerate(figures, start=1):
                            page_path = stem.parent / f"{stem.name}_p{idx:02d}.png"
                            fig.savefig(page_path, dpi=export_dpi)
                            plt.close(fig)
                            saved_paths.append(page_path)
                    if len(saved_paths) == 1:
                        messagebox.showinfo(
                            "Cycle Speciation Timeline",
                            f"Timeline table exported to {saved_paths[0]}",
                        )
                    else:
                        messagebox.showinfo(
                            "Cycle Speciation Timeline",
                            f"Timeline table exported to {saved_paths[0].parent}\n"
                            f"Saved {len(saved_paths)} pages with suffixes _p01, _p02, ...",
                        )
            except Exception as exc:
                # Iterate over figures to apply the per-item logic.
                for fig in figures:
                    try:
                        plt.close(fig)
                    except Exception:
                        pass
                partial = [str(path) for path in saved_paths]
                if target_path.exists() and str(target_path) not in partial:
                    partial.append(str(target_path))
                partial_text = ""
                if partial:
                    partial_text = "\nSaved partial artifacts:\n" + "\n".join(partial)
                try:
                    messagebox.showerror(
                        "Cycle Speciation Timeline",
                        f"Matplotlib export failed (save): {exc}\n"
                        f"Output folder: {output_dir}{partial_text}",
                    )
                except Exception:
                    pass
            return

        try:
            df = pd.DataFrame(export_rows, columns=export_headers)
            label_map = {col: _placeholderize(col) for col in export_headers}
            text_columns = [col for col in export_headers if col not in numeric_specs]
            # Iterate over text_columns to apply the per-item logic.
            for col in text_columns:
                df[col] = [_placeholderize(val) for val in df[col]]
            # Iterate over items from numeric_specs to apply the per-item logic.
            for col, decimals in numeric_specs.items():
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce")

            timeline_table = gt.GT(df)
            timeline_table = timeline_table.cols_label(label_map)
            numeric_columns = [col for col in numeric_specs if col in df.columns]
            if numeric_columns:
                timeline_table = timeline_table.cols_align(
                    columns=numeric_columns, align="right"
                )
            if text_columns:
                timeline_table = timeline_table.cols_align(
                    columns=text_columns, align="left"
                )
            two_dec_cols = [
                col
                # Iterate to apply the per-item logic.
                for col, dec in numeric_specs.items()
                if dec == 2 and col in df.columns
            ]
            one_dec_cols = [
                col
                # Iterate to apply the per-item logic.
                for col, dec in numeric_specs.items()
                if dec == 1 and col in df.columns
            ]
            three_dec_cols = [
                col
                # Iterate to apply the per-item logic.
                for col, dec in numeric_specs.items()
                if dec == 3 and col in df.columns
            ]
            sig3_cols = [
                col
                # Iterate to apply the per-item logic.
                for col, dec in numeric_specs.items()
                if dec == "sig3" and col in df.columns
            ]
            if two_dec_cols:
                timeline_table = timeline_table.fmt_number(
                    columns=two_dec_cols, decimals=2
                )
            if one_dec_cols:
                timeline_table = timeline_table.fmt_number(
                    columns=one_dec_cols, decimals=1
                )
            if three_dec_cols:
                timeline_table = timeline_table.fmt_number(
                    columns=three_dec_cols, decimals=3
                )
            if sig3_cols:
                timeline_table = timeline_table.fmt(
                    fns=lambda value: (
                        ""
                        if value is None
                        or (isinstance(value, float) and math.isnan(value))
                        else f"{float(value):.3g}"
                    ),
                    columns=sig3_cols,
                )
            timeline_table = timeline_table.opt_row_striping()
            timeline_table = timeline_table.opt_align_table_header(align="center")
            timeline_table = timeline_table.opt_horizontal_padding(2)
            timeline_table = timeline_table.opt_vertical_padding(2)
            timeline_table = timeline_table.sub_missing(
                columns=export_headers, missing_text=""
            )
            if subtitle_text:
                timeline_table = timeline_table.tab_header(
                    title="Cycle Speciation Timeline",
                    subtitle=_placeholderize(subtitle_text),
                )
            else:
                timeline_table = timeline_table.tab_header(
                    title="Cycle Speciation Timeline"
                )
            latex_table = timeline_table.as_latex(use_longtable=True)
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Cycle Speciation Timeline",
                    f"LaTeX source export failed (build): {exc}\n"
                    f"Output folder: {output_dir}",
                )
            except Exception:
                pass
            return

        latex_table = _replace_placeholders(latex_table)
        latex_doc = _build_latex_doc(latex_table, include_inputenc=True)

        if target_format == "tex":
            try:
                target_path.write_text(latex_doc, encoding="utf-8")
                messagebox.showinfo(
                    "Cycle Speciation Timeline",
                    f"LaTeX source saved to {target_path}",
                )
            except Exception as exc:
                try:
                    messagebox.showerror(
                        "Cycle Speciation Timeline",
                        f"LaTeX source export failed (write): {exc}\n"
                        f"Output folder: {output_dir}",
                    )
                except Exception:
                    pass
            return

    def _run_inverse_co2_design(self) -> None:
        """Run inverse CO2 design.
        Used to execute inverse CO2 design and coordinate results."""
        summary_var = getattr(self, "_sol_inverse_summary_var", None)
        if summary_var is None:
            return
        try:
            form_data = getattr(self, "_sol_last_form_data", None)
            if form_data is None:
                form_data = self._collect_solubility_form_data()
                self._sol_last_form_data = form_data
        except Exception as exc:
            summary_var.set(f"Unable to gather inputs: {exc}")
            try:
                messagebox.showwarning(
                    "Advanced Solubility Module",
                    f"Unable to gather inputs: {exc}",
                )
            except Exception:
                pass
            return
        reaction_naoh_mass = form_data.get("reaction_naoh_mass")
        reaction_solution_volume = form_data.get("reaction_solution_volume")
        reaction_co2_g = form_data.get("reaction_co2_g")
        reaction_final_ph = form_data.get("reaction_final_ph")
        reaction_slurry_ph = form_data.get("reaction_slurry_ph")
        reaction_target_ph = form_data.get("reaction_target_ph")
        measurement_ph = (
            reaction_final_ph if reaction_final_ph is not None else (reaction_slurry_ph)
        )
        if reaction_naoh_mass is None or reaction_solution_volume is None:
            summary_var.set("Set the NaOH charge and process liquor volume first.")
            return
        if measurement_ph is None:
            summary_var.set("Enter a final product pH or slurry pH measurement.")
            return
        guidance = analyze_bicarbonate_reaction(
            naoh_mass_g=reaction_naoh_mass,
            co2_charged_g=reaction_co2_g,
            solution_volume_l=reaction_solution_volume,
            measured_ph=reaction_final_ph,
            slurry_ph=reaction_slurry_ph,
            target_ph=reaction_target_ph,
            temperature_c=form_data["params"].temperature_c,
            use_temp_adjusted_constants=form_data[
                "params"
            ].use_temperature_adjusted_constants,
            ionic_strength_cap=form_data["params"].ionic_strength_cap,
        )
        if not guidance:
            summary_var.set(
                "Unable to evaluate the dosing ledger with the provided inputs."
            )
            return
        ledger = guidance.get("ledger") or {}
        na2_mol = max(float(ledger.get("na2co3_mol", 0.0)), 0.0)
        nah_mol = max(float(ledger.get("nahco3_mol", 0.0)), 0.0)
        total_carbon = na2_mol + nah_mol
        current_purity = nah_mol / total_carbon if total_carbon > 0 else 0.0
        try:
            purity_pct = float(self._sol_inverse_purity_var.get() or 99.5)
        except Exception:
            purity_pct = 99.5
        target_purity = max(0.0, min(purity_pct / 100.0, 0.9999))
        if target_purity <= current_purity or na2_mol <= 0:
            summary_var.set(
                f"Current NaHCO₃ purity ≈ {current_purity*100:.2f}% (target {target_purity*100:.2f}%). "
                "No additional CO₂ required."
            )
            return
        denominator = 2.0 - target_purity
        numerator = target_purity * total_carbon - nah_mol
        conversion_mol = max(0.0, numerator / denominator)
        conversion_mol = min(conversion_mol, na2_mol)
        supersat_factor = 1.0
        if bool(getattr(self, "_sol_inverse_supersat_var", tk.BooleanVar()).get()):
            try:
                supersat_factor = float(
                    getattr(
                        self,
                        "_sol_inverse_supersat_factor_var",
                        tk.StringVar(value="1.05"),
                    ).get()
                )
            except Exception:
                supersat_factor = 1.0
            supersat_factor = max(1.0, supersat_factor)
        recommended_mol = min(conversion_mol * supersat_factor, na2_mol)
        recommended_g = recommended_mol * SOL_MW_CO2
        projected_purity = (
            (nah_mol + 2.0 * recommended_mol)
            / (na2_mol - recommended_mol + nah_mol + 2.0 * recommended_mol)
            if (na2_mol + nah_mol) > 0
            else 0.0
        )
        summary_lines = [
            f"Current NaHCO₃ purity ≈ {current_purity*100:.2f}% with "
            f"{na2_mol:.4f} mol Na₂CO₃ and {nah_mol:.4f} mol NaHCO₃.",
            f"Target purity: {target_purity*100:.2f}% (supersaturation factor {supersat_factor:.2f}).",
            f"Recommended additional CO₂: {recommended_mol:.4f} mol ({recommended_g:.2f} g).",
            f"Projected purity after dosing ≈ {projected_purity*100:.2f}% "
            "assuming complete conversion of the indicated Na₂CO₃.",
        ]
        if guidance.get("warnings"):
            summary_lines.append("Ledger warnings: " + "; ".join(guidance["warnings"]))
        summary_var.set("\n".join(summary_lines))

    def _refresh_solubility_scenario_choices(self) -> None:
        """Refresh solubility scenario choices.
        Used to sync solubility scenario choices with current settings."""
        combo = getattr(self, "_sol_preset_combo", None)
        if combo is None:
            return
        stored = settings.setdefault("solubility_scenarios", {})
        values = list(SOLUBILITY_PRESETS.keys()) + sorted(stored.keys())
        combo["values"] = values

    def _on_select_solubility_preset(self, _event=None) -> None:
        """Handle select solubility preset.
        Used as an event callback for select solubility preset."""
        name = self._sol_preset_combo.get()
        if not name:
            return
        desc_var = getattr(self, "_sol_preset_description_var", None)
        if desc_var is None:
            return
        if name in SOLUBILITY_PRESETS:
            desc_var.set(SOLUBILITY_PRESETS[name].get("description", "Preset loaded."))
        else:
            desc_var.set("User-defined scenario.")

    def _load_selected_solubility_preset(self) -> None:
        """Load selected solubility preset.
        Used when restoring selected solubility preset from storage."""
        name = self._sol_preset_combo.get()
        if not name:
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module", "Select a preset before loading."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        self._apply_solubility_preset_by_name(name)

    def _apply_solubility_preset_by_name(self, name: str) -> None:
        """Apply solubility preset by name.
        Used to apply solubility preset by name changes to live state."""
        values: Optional[Dict[str, Any]] = None
        if name in SOLUBILITY_PRESETS:
            values = SOLUBILITY_PRESETS[name].get("values")
        else:
            values = settings.setdefault("solubility_scenarios", {}).get(name)
        if not values:
            return
        # Iterate over items from self._solubility_vars to apply the per-item logic.
        for key, var in self._solubility_vars.items():
            if key not in values:
                continue
            value = values[key]
            var.set("" if value is None else str(value))
        if "use_temperature_adjusted_constants" in values:
            self._sol_use_temp_adjust_var.set(
                bool(values["use_temperature_adjusted_constants"])
            )
        if "limit_ionic_strength" in values:
            self._sol_limit_ionic_var.set(bool(values["limit_ionic_strength"]))
        if "include_headspace" in values:
            self._sol_include_headspace_var.set(bool(values["include_headspace"]))
        if "solvent_basis_mode" in values:
            self._solvent_mode_var.set(str(values["solvent_basis_mode"]))
        # Iterate to apply the per-item logic.
        for key, target in [
            ("sens_mass_enabled", self._sol_sens_mass_var),
            ("sens_solvent_enabled", self._sol_sens_solvent_var),
            ("sens_temp_enabled", self._sol_sens_temp_var),
        ]:
            if key in values:
                target.set(bool(values[key]))
        self._apply_solvent_basis_state()
        self._sync_solvent_entries()
        self._toggle_ionic_cap_state()
        self._toggle_headspace_fields()

    def _collect_solubility_snapshot(self) -> Dict[str, Any]:
        """Collect solubility snapshot.
        Used to gather solubility snapshot into a structured payload."""
        snapshot: Dict[str, Any] = {}
        # Iterate over items from self._solubility_vars to apply the per-item logic.
        for key, var in self._solubility_vars.items():
            raw = var.get().strip()
            if not raw:
                snapshot[key] = None
                continue
            try:
                snapshot[key] = float(raw)
            except ValueError:
                snapshot[key] = raw
        snapshot["use_temperature_adjusted_constants"] = bool(
            self._sol_use_temp_adjust_var.get()
        )
        snapshot["limit_ionic_strength"] = bool(self._sol_limit_ionic_var.get())
        snapshot["include_headspace"] = bool(self._sol_include_headspace_var.get())
        snapshot["sens_mass_enabled"] = bool(self._sol_sens_mass_var.get())
        snapshot["sens_solvent_enabled"] = bool(self._sol_sens_solvent_var.get())
        snapshot["sens_temp_enabled"] = bool(self._sol_sens_temp_var.get())
        snapshot["solvent_basis_mode"] = self._solvent_mode_var.get()
        return snapshot

    def _slider_target_keys(self) -> List[str]:
        """Perform slider target keys.
        Used to keep the workflow logic localized and testable."""
        workflow_key = self._current_solubility_workflow()
        if workflow_key == "Planning":
            return ["forced_ph_target"]
        if workflow_key == "Analysis":
            return ["reaction_target_ph", "forced_ph_target"]
        if workflow_key == "Reprocessing":
            return ["diag_target_ph"]
        return ["forced_ph_target", "reaction_target_ph", "diag_target_ph"]

    def _save_solubility_scenario(self) -> None:
        """Save solubility scenario.
        Used when persisting solubility scenario to storage."""
        name = self._sol_scenario_name_var.get().strip()
        if not name:
            try:
                messagebox.showwarning(
                    "Advanced Solubility Module",
                    "Provide a scenario name before saving.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        snapshot = self._collect_solubility_snapshot()
        settings.setdefault("solubility_scenarios", {})[name] = snapshot
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._refresh_solubility_scenario_choices()
        self._sol_scenario_name_var.set("")
        try:
            messagebox.showinfo(
                "Advanced Solubility Module", f"Scenario '{name}' saved successfully."
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _apply_solvent_basis_state(self, *_args) -> None:
        """Apply solvent basis state.
        Used to apply solvent basis state changes to live state."""
        mode = getattr(self, "_solvent_mode_var", None)
        if mode is None:
            return
        mode_value = mode.get()
        water_entry = self._solubility_field_meta.get("water_mass_g", {}).get("entry")
        volume_entry = self._solubility_field_meta.get("solution_volume_l", {}).get(
            "entry"
        )
        if water_entry:
            water_entry.configure(
                state="normal" if mode_value == "mass" else "disabled"
            )
        if volume_entry:
            volume_entry.configure(
                state="normal" if mode_value == "volume" else "disabled"
            )

    def _sync_solvent_entries(self, *_args) -> None:
        """Perform sync solvent entries.
        Used to keep the workflow logic localized and testable."""
        if self._solvent_sync_lock:
            return
        water_var = self._solubility_vars.get("water_mass_g")
        volume_var = self._solubility_vars.get("solution_volume_l")
        mode = getattr(self, "_solvent_mode_var", None)
        if not water_var or not volume_var or mode is None:
            return
        try:
            self._solvent_sync_lock = True
            if mode.get() == "mass":
                mass = float(water_var.get() or 0)
                if mass > 0:
                    volume = (mass / SOL_WATER_DENSITY_25C_G_PER_ML) / 1000.0
                    volume_var.set(f"{volume:.6f}")
            else:
                volume = float(volume_var.get() or 0)
                if volume > 0:
                    mass = volume * 1000.0 * SOL_WATER_DENSITY_25C_G_PER_ML
                    water_var.set(f"{mass:.3f}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        finally:
            self._solvent_sync_lock = False

    def _toggle_ionic_cap_state(self) -> None:
        """Toggle ionic cap state.
        Used to flip ionic cap state and refresh dependent views."""
        entry = getattr(self, "_sol_ionic_cap_entry", None)
        if entry is None:
            return
        state = "normal" if self._sol_limit_ionic_var.get() else "disabled"
        entry.configure(state=state)

    def _toggle_headspace_fields(self) -> None:
        """Toggle headspace fields.
        Used to flip headspace fields and refresh dependent views."""
        enable = bool(self._sol_include_headspace_var.get())
        # Iterate to apply the per-item logic.
        for entry in (
            getattr(self, "_sol_headspace_pco2_entry", None),
            getattr(self, "_sol_headspace_kh_entry", None),
        ):
            if entry is not None:
                entry.configure(state="normal" if enable else "disabled")

    def _on_solubility_forced_slider(self, value: str) -> None:
        """Handle solubility forced slider.
        Used as an event callback for solubility forced slider."""
        try:
            target_value = float(value)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        try:
            self._forced_slider_lock = True
            # Iterate over self._slider_target_keys() to apply the per-item logic.
            for key in self._slider_target_keys():
                var = self._solubility_vars.get(key)
                if var is None:
                    continue
                var.set(f"{target_value:.2f}")
                break
        finally:
            self._forced_slider_lock = False
        display_var = getattr(self, "_sol_target_ph_display_var", None)
        if display_var is not None:
            display_var.set(f"Target pH slider: {target_value:.2f}")

    def _sync_target_slider_from_entry(self, *_args) -> None:
        """Perform sync target slider from entry.
        Used to keep the workflow logic localized and testable."""
        if self._forced_slider_lock:
            return
        slider = getattr(self, "_sol_forced_slider", None)
        if slider is None:
            return
        target_value: Optional[float] = None
        # Iterate over self._slider_target_keys() to apply the per-item logic.
        for key in self._slider_target_keys():
            var = self._solubility_vars.get(key)
            if var is None:
                continue
            try:
                candidate = float(var.get())
            except Exception:
                continue
            target_value = candidate
            break
        if target_value is None:
            return
        slider.set(max(6.5, min(9.5, target_value)))
        display_var = getattr(self, "_sol_target_ph_display_var", None)
        if display_var is not None:
            display_var.set(f"Target pH slider: {target_value:.2f}")

    def _sync_planning_mass(self, *_args) -> None:
        """Perform sync planning mass.
        Used to keep the workflow logic localized and testable."""
        if getattr(self, "_planning_mass_lock", False):
            return
        naoh_var = self._solubility_vars.get("mass_naoh_g")
        nahco3_var = self._solubility_vars.get("mass_na_hco3_g")
        if naoh_var is None or nahco3_var is None:
            return
        try:
            value = float(naoh_var.get())
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        try:
            self._planning_mass_lock = True
            equivalent = value * SOL_MW_NAHCO3 / SOL_MW_NAOH
            nahco3_var.set(f"{equivalent:.4f}")
        finally:
            self._planning_mass_lock = False

    def _on_diag_target_slider(self, value: str) -> None:
        """Handle diag target slider.
        Used as an event callback for diag target slider."""
        var = self._solubility_vars.get("diag_target_ph")
        if var is None:
            return
        try:
            var.set(f"{float(value):.2f}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _sync_diag_target_slider_from_entry(self, *_args) -> None:
        """Perform sync diag target slider from entry.
        Used to keep the workflow logic localized and testable."""
        slider = getattr(self, "_diag_target_slider", None)
        var = self._solubility_vars.get("diag_target_ph")
        if slider is None or var is None:
            return
        try:
            value = float(var.get())
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        slider.set(min(max(value, 6.5), 9.0))

    def _copy_solubility_summary(self) -> None:
        """Perform copy solubility summary.
        Used to keep the workflow logic localized and testable."""
        widget = getattr(self, "_solubility_summary", None)
        if widget is None or not widget.winfo_exists():
            return
        try:
            text = widget.get("1.0", "end").strip()
        except Exception:
            text = ""
        if not text:
            return
        try:
            self.clipboard_clear()
            self.clipboard_append(text)
            messagebox.showinfo(
                "Advanced Solubility Module", "Summary copied to clipboard."
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _export_solubility_csv(self) -> None:
        """Export solubility CSV.
        Used to serialize solubility CSV for external workflows."""
        structured = getattr(self, "_sol_last_structured", None)
        if not structured:
            try:
                messagebox.showwarning(
                    "Advanced Solubility Module",
                    "Run the solubility analysis before exporting data.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        path = filedialog.asksaveasfilename(
            title="Export Solubility Species CSV",
            defaultextension=".csv",
            filetypes=[("CSV files", "*.csv")],
            initialfile="solubility_species.csv",
        )
        if not path:
            return
        # Export pipeline serializes the latest structured solver payload.
        rows = structured.get("species_rows", [])
        if not rows:
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module", "No species data available to export."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        try:
            with open(path, "w", newline="", encoding="utf-8") as handle:
                writer = csv.DictWriter(handle, fieldnames=self._sol_species_columns)
                writer.writeheader()
                # Iterate over rows to apply the per-item logic.
                for row in rows:
                    writer.writerow(row)
                timeline = structured.get("cycle_timeline") or []
                if timeline:
                    handle.write("\nCycle timeline\n")
                    timeline_fields = [
                        "cycle_id",
                        "co2_total_g",
                        "solution_ph",
                        "h2co3_pct",
                        "hco3_pct",
                        "co3_pct",
                        "warnings",
                    ]
                    timeline_writer = csv.DictWriter(handle, fieldnames=timeline_fields)
                    timeline_writer.writeheader()
                    # Iterate over timeline to apply the per-item logic.
                    for entry in timeline:
                        fractions = entry.get("fractions") or {}
                        warnings = entry.get("warnings") or []
                        ph_val = entry.get("solution_ph")
                        timeline_writer.writerow(
                            {
                                "cycle_id": entry.get("cycle_id", ""),
                                "co2_total_g": f"{entry.get('co2_g', 0.0):.2f}",
                                "solution_ph": (
                                    f"{ph_val:.2f}" if ph_val is not None else ""
                                ),
                                "h2co3_pct": f"{fractions.get('H2CO3', 0.0) * 100:.1f}",
                                "hco3_pct": f"{fractions.get('HCO3-', 0.0) * 100:.1f}",
                                "co3_pct": f"{fractions.get('CO3^2-', 0.0) * 100:.1f}",
                                "warnings": " | ".join(warnings),
                            }
                        )
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Advanced Solubility Module",
                    f"Failed to export CSV: {exc}",
                )
            except Exception:
                pass

    def _export_solubility_json(self) -> None:
        """Export solubility JSON.
        Used to serialize solubility JSON for external workflows."""
        structured = getattr(self, "_sol_last_structured", None)
        if not structured:
            try:
                messagebox.showwarning(
                    "Advanced Solubility Module",
                    "Run the solubility analysis before exporting data.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        path = filedialog.asksaveasfilename(
            title="Export Solubility Summary JSON",
            defaultextension=".json",
            filetypes=[("JSON files", "*.json")],
            initialfile="solubility_summary.json",
        )
        if not path:
            return
        try:
            with open(path, "w", encoding="utf-8") as handle:
                json.dump(structured, handle, indent=2, ensure_ascii=False)
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Advanced Solubility Module",
                    f"Failed to export JSON: {exc}",
                )
            except Exception:
                pass

    def _apply_solubility_to_contamination(self) -> None:
        """Apply solubility to contamination.
        Used to apply solubility to contamination changes to live state."""
        try:
            messagebox.showinfo(
                "Advanced Solubility Module",
                "Carbonate wt% reporting has been removed from the solubility module.",
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _open_solubility_glossary(self) -> None:
        """Open solubility glossary.
        Used by UI actions to open solubility glossary."""
        window = getattr(self, "_sol_glossary_window", None)
        if window is not None and window.winfo_exists():
            window.lift()
            return
        window = tk.Toplevel(self)
        window.title("Solubility Glossary")
        window.geometry("520x320")
        text_widget = scrolledtext.ScrolledText(window, wrap="word", state="normal")
        text_widget.pack(fill="both", expand=True, padx=8, pady=8)
        # Iterate over items from SOL_GLOSSARY_ENTRIES to apply the per-item logic.
        for term, definition in SOL_GLOSSARY_ENTRIES.items():
            text_widget.insert("end", f"{term}\n", ("term",))
            text_widget.insert("end", f"  {definition}\n\n")
        text_widget.tag_configure("term", font=("TkDefaultFont", 10, "bold"))
        text_widget.configure(state="disabled")
        window.protocol("WM_DELETE_WINDOW", self._close_solubility_glossary)
        self._sol_glossary_window = window

    def _close_solubility_glossary(self) -> None:
        """Close solubility glossary.
        Used by UI actions to close solubility glossary safely."""
        window = getattr(self, "_sol_glossary_window", None)
        if window is not None:
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._sol_glossary_window = None

    def _open_sol_mode_details(self) -> None:
        """Open sol mode details.
        Used by UI actions to open sol mode details."""
        window = getattr(self, "_sol_mode_details_window", None)
        if window is not None and window.winfo_exists():
            window.lift()
            return
        window = tk.Toplevel(self)
        window.title("Simulation Basis Details")
        window.geometry("620x420")
        text_widget = scrolledtext.ScrolledText(window, wrap="word", state="normal")
        text_widget.pack(fill="both", expand=True, padx=8, pady=8)
        # Iterate over items from SOL_SIMULATION_MODES to apply the per-item logic.
        for key, meta in SOL_SIMULATION_MODES.items():
            label = meta.get("label", key)
            desc = meta.get("description", "")
            assumption = meta.get("assumption", "")
            steps = meta.get("steps", [])
            text_widget.insert("end", f"{label}\n", ("mode",))
            if desc:
                text_widget.insert("end", f"  Purpose: {desc}\n")
            if assumption:
                text_widget.insert("end", f"  Assumptions: {assumption}\n")
            if steps:
                text_widget.insert("end", "  Guided steps:\n")
                # Iterate over steps to apply the per-item logic.
                for step_id in steps:
                    text_widget.insert(
                        "end",
                        f"    • {SOL_MODE_STEP_LABELS.get(step_id, step_id)}\n",
                    )
            text_widget.insert("end", "\n")
        text_widget.tag_configure("mode", font=("TkDefaultFont", 10, "bold"))
        text_widget.configure(state="disabled")
        window.protocol("WM_DELETE_WINDOW", self._close_sol_mode_details)
        self._sol_mode_details_window = window

    def _close_sol_mode_details(self) -> None:
        """Close sol mode details.
        Used by UI actions to close sol mode details safely."""
        window = getattr(self, "_sol_mode_details_window", None)
        if window is not None:
            try:
                window.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._sol_mode_details_window = None

    def _solubility_export_metadata(self) -> List[str]:
        """Export metadata.
        Used by solubility workflows to export metadata."""
        vars_map = getattr(self, "_solubility_vars", {})

        # Closure captures _solubility_export_metadata local context to keep helper logic scoped and invoked directly within _solubility_export_metadata.
        def _val(key: str, suffix: str = "") -> str:
            """Perform val.
            Used to keep the workflow logic localized and testable."""
            var = vars_map.get(key)
            if var is None:
                return "n/a"
            value = var.get().strip()
            return f"{value}{suffix}" if value else "n/a"

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        metadata = [
            f"Exported: {timestamp}",
            f"App version: {APP_VERSION}",
            f"Mass NaHCO\u2082: {_val('mass_na_hco3_g', ' g')}",
            f"Water mass: {_val('water_mass_g', ' g')}",
            f"Solution volume: {_val('solution_volume_l', ' L')}",
            f"Temperature: {_val('temperature_c', ' °C')}",
            f"Forced pH target: {_val('forced_ph_target')}",
            f"Solvent basis: {getattr(self, '_solvent_mode_var', tk.StringVar(value='mass')).get()}",
        ]
        return metadata

    def _populate_treeview(
        self,
        tree: Optional[ttk.Treeview],
        rows: List[Dict[str, Any]],
        columns: Tuple[str, ...],
    ) -> None:
        """Perform populate treeview.
        Used to keep the workflow logic localized and testable."""
        if tree is None:
            return
        # Iterate over tree.get_children() to apply the per-item logic.
        for child in tree.get_children():
            tree.delete(child)
        # Iterate over rows to apply the per-item logic.
        for row in rows:
            values = [row.get(col, "") for col in columns]
            tree.insert("", "end", values=values)

    def _update_solubility_plots(self, chart_data: Optional[Dict[str, Any]]) -> None:
        """Update solubility plots.
        Used to keep solubility plots in sync with current state."""
        axes = getattr(self, "_sol_plot_axes", None)
        canvas = getattr(self, "_sol_plot_canvas", None)
        if axes is None or canvas is None:
            return
        pie_ax, bar_ax = axes
        pie_ax.clear()
        bar_ax.clear()
        if chart_data:
            fractions = chart_data.get("fractions", {})
            values = fractions.get("values", [])
            labels = fractions.get("labels", [])
            if values and sum(values) > 0:
                pie_ax.pie(values, labels=labels, autopct="%1.0f%%", startangle=90)
            else:
                pie_ax.text(0.5, 0.5, "No speciation data", ha="center", va="center")
            bar = chart_data.get("saturation", {})
            bar_labels = bar.get("labels", [])
            bar_values = bar.get("values", [])
            if bar_labels:
                bar_ax.bar(bar_labels, bar_values, color=["#4c72b0", "#dd8452"])
                bar_ax.axhline(1.0, color="#555555", linestyle="--", linewidth=1)
                bar_ax.set_ylim(0, max(bar_values + [1.0]) * 1.2)
                bar_ax.set_ylabel("Ionic product / Ksp")
            else:
                bar_ax.text(0.5, 0.5, "No saturation data", ha="center", va="center")
        else:
            pie_ax.text(0.5, 0.5, "No data", ha="center", va="center")
            bar_ax.text(0.5, 0.5, "No data", ha="center", va="center")
        canvas.draw_idle()

    def _update_solubility_sweep_plot(
        self, sweep_data: Optional[List[Dict[str, float]]]
    ) -> None:
        """Update solubility sweep plot.
        Used to keep solubility sweep plot in sync with current state."""
        targets = [
            (
                getattr(self, "_sol_sweep_plot_ax", None),
                getattr(self, "_sol_sweep_plot_canvas", None),
            ),
            (
                getattr(self, "_sol_new_sweep_ax", None),
                getattr(self, "_sol_new_sweep_canvas", None),
            ),
        ]

        def _render(axis: Axes) -> None:
            """Render value.
            Used to draw value for preview or export workflows."""
            axis.clear()
            if not sweep_data:
                axis.text(0.5, 0.5, "No sweep data", ha="center", va="center")
                return
            ph_values = [float(row["ph"]) for row in sweep_data]
            hco3_vals = [float(row["hco3_pct"]) for row in sweep_data]
            co3_vals = [float(row["co3_pct"]) for row in sweep_data]
            h2co3_vals = [float(row["h2co3_pct"]) for row in sweep_data]
            species = [
                ("H2CO3", h2co3_vals, "#55a868"),
                ("HCO3-", hco3_vals, "#4c72b0"),
                ("CO3^2-", co3_vals, "#dd8452"),
            ]
            axis.stackplot(
                ph_values,
                h2co3_vals,
                hco3_vals,
                co3_vals,
                colors=[color for _, _, color in species],
                alpha=0.35,
            )
            # Iterate over species to apply the per-item logic.
            for label, values, color in species:
                axis.plot(ph_values, values, label=label, color=color)
            axis.set_xlabel("pH")
            axis.set_ylabel("Percent of inorganic C")
            axis.set_ylim(0, 100)
            ph_min = min(ph_values) if ph_values else 6.0
            ph_max = max(ph_values) if ph_values else 9.5
            axis.set_xlim(min(6.0, ph_min), max(9.5, ph_max))
            axis.legend(loc="upper right", fontsize=8)

        # Iterate over targets to apply the per-item logic.
        for axis, canvas in targets:
            if axis is None or canvas is None:
                continue
            _render(axis)
            canvas.draw_idle()

    def _update_solubility_preview_plots(
        self, chart_data: Optional[Dict[str, Any]]
    ) -> None:
        """Update solubility preview plots.
        Used to keep solubility preview plots in sync with current state."""
        axes = getattr(self, "_sol_new_plot_axes", None)
        canvas = getattr(self, "_sol_new_plot_canvas", None)
        if axes is None or canvas is None:
            return
        pie_ax, sat_ax = axes
        pie_ax.clear()
        sat_ax.clear()
        pie_ax.set_title("Carbon Distribution", fontsize=9)
        sat_ax.set_title("Saturation Index", fontsize=9)
        sat_ax.set_xlabel("Index")
        sat_ax.set_ylabel("Salt")
        sat_ax.set_xlim(0, 2)
        if chart_data:
            fractions = chart_data.get("fractions", {})
            labels = fractions.get("labels", [])
            values = fractions.get("values", [])
            if values and sum(values) > 0:
                pie_ax.pie(values, labels=labels, autopct="%1.0f%%", startangle=90)
            else:
                pie_ax.text(0.5, 0.5, "No speciation data", ha="center", va="center")
            saturation = chart_data.get("saturation", {})
            sat_labels = saturation.get("labels", [])
            sat_values = saturation.get("values", [])
            if sat_labels and sat_values:
                sat_ax.barh(sat_labels, sat_values, color="#4c72b0")
                sat_ax.axvline(1.0, color="#b22222", linestyle="--", linewidth=1)
            else:
                sat_ax.text(0.5, 0.5, "No saturation data", ha="center", va="center")
        else:
            pie_ax.text(0.5, 0.5, "No speciation data", ha="center", va="center")
            sat_ax.text(0.5, 0.5, "No saturation data", ha="center", va="center")
        canvas.draw_idle()

    def _update_solubility_structured_widgets(
        self, structured: Optional[Dict[str, Any]]
    ) -> None:
        """Update solubility structured widgets.
        Used to keep solubility structured widgets in sync with current state."""
        self._sol_last_structured = structured
        existing_entries = list(getattr(self, "_sol_tracking_entries", []))
        context_label = getattr(self, "_sol_context_label_var", None)
        context_start = getattr(self, "_sol_context_start_var", None)
        context_goal = getattr(self, "_sol_context_goal_var", None)
        context_assumption = getattr(self, "_sol_context_assumption_var", None)
        preview_tree = getattr(self, "_sol_new_metric_tree", None)
        preview_columns = getattr(self, "_sol_new_metric_columns", ())
        preview_summary_var = getattr(self, "_sol_new_reaction_summary_var", None)

        def _payload_from_struct(data: Dict[str, Any]) -> SolubilityStructuredPayload:
            """Perform payload from struct.
            Used to keep the workflow logic localized and testable."""
            return SolubilityStructuredPayload(
                highlights=data.get("highlights") or {},
                warnings=data.get("warnings") or [],
                species_rows=data.get("species_rows") or [],
                saturation_rows=data.get("saturation_rows") or [],
                sensitivity_rows=data.get("sensitivity_rows") or [],
                sweep_rows=data.get("sweep_rows") or [],
                sweep_plot=data.get("sweep_plot") or [],
                assumptions=data.get("assumptions") or [],
                chart_data=data.get("chart_data") or {},
                reaction_guidance=data.get("reaction_guidance"),
                tracking_entries=data.get("tracking_entries") or [],
                cycle_timeline=data.get("cycle_timeline"),
                planner_context=data.get("planner_context") or [],
                math_sections=data.get("math_sections") or [],
                math_preview_lines=data.get("math_preview_lines") or [],
                mode_context=data.get("mode_context") or {},
                workflow_key=data.get("workflow_key", ""),
                guide_key=data.get("guide_key", ""),
                assumed_solution_volume_l=data.get("assumed_solution_volume_l"),
                co2_guidance=data.get("co2_guidance", ""),
            )

        if structured is None:
            self._sol_math_sections = []
            # Iterate over items from self._sol_highlight_defaults to apply the per-item logic.
            for key, default in self._sol_highlight_defaults.items():
                var = self._sol_highlight_vars.get(key)
                if var is not None:
                    var.set(default)
            self._sol_warning_var.set(
                "Warnings will appear after running the analysis."
            )
            self._populate_treeview(
                self._sol_species_tree, [], self._sol_species_columns
            )
            self._populate_treeview(
                self._sol_saturation_tree, [], self._sol_saturation_columns
            )
            self._populate_treeview(
                self._sol_sensitivity_tree, [], self._sol_sensitivity_columns
            )
            self._populate_treeview(self._sol_sweep_tree, [], self._sol_sweep_columns)
            self._update_solubility_plots(None)
            self._update_solubility_preview_plots(None)
            self._update_solubility_sweep_plot(None)
            self._sol_assumptions_var.set(
                "Assumptions will be listed after running the module."
            )
            summary_var = getattr(self, "_sol_reaction_summary_var", None)
            default_msg = getattr(
                self,
                "_sol_reaction_default_msg",
                "Enter NaOH/CO2 inputs to activate the guidance overlay.",
            )
            if summary_var is not None:
                summary_var.set(default_msg)
            if preview_tree is not None:
                self._populate_treeview(preview_tree, [], preview_columns)
            if preview_summary_var is not None:
                preview_summary_var.set(default_msg)
            self._update_sol_math_text_lines([])
            self._refresh_math_viewer_state()
            self._refresh_sol_tracking_table(existing_entries)
            self._update_sol_simulation_plot(None, existing_entries)
            self._update_cycle_spec_view([])
            mode_var = getattr(self, "_sol_mode_var", None)
            mode_key = mode_var.get() if mode_var is not None else SOL_DEFAULT_SIM_MODE
            meta = SOL_SIMULATION_MODES.get(mode_key, {})
            if context_label is not None:
                context_label.set(meta.get("label", "Advanced Solubility"))
            placeholder = "Starting point will appear after running the analysis."
            if context_start is not None:
                context_start.set(placeholder)
            if context_goal is not None:
                context_goal.set("Solver goals and recommendations will be shown here.")
            if context_assumption is not None:
                context_assumption.set(
                    meta.get("assumption", "Mode assumptions will be echoed here.")
                )
            self._refresh_sol_mode_guidance()
            return

        payload = (
            structured
            if isinstance(structured, SolubilityStructuredPayload)
            else _payload_from_struct(structured)
        )
        self._sol_reaction_guidance = payload.reaction_guidance or {}

        # Iterate over items from self._sol_highlight_meta to apply the per-item logic.
        for key, label in self._sol_highlight_meta.items():
            var = self._sol_highlight_vars.get(key)
            if var is None:
                continue
            value = payload.highlights.get(key, "—")
            var.set(f"{label}: {value}")

        if payload.warnings:
            self._sol_warning_var.set("\n".join(payload.warnings))
        else:
            self._sol_warning_var.set("No warnings detected.")

        preview_rows: List[Dict[str, Any]] = []
        # Iterate over items from self._sol_highlight_meta to apply the per-item logic.
        for key, label in self._sol_highlight_meta.items():
            value = payload.highlights.get(key)
            if value is not None:
                preview_rows.append({"metric": label, "value": value})
        workflow_label = ""
        workflow_meta = SOL_WORKFLOW_TEMPLATES.get(payload.workflow_key, {})
        if workflow_meta:
            workflow_label = workflow_meta.get("label", payload.workflow_key)
        elif payload.workflow_key:
            workflow_label = payload.workflow_key
        if workflow_label:
            preview_rows.insert(0, {"metric": "Workflow", "value": workflow_label})
        if payload.planner_context:
            preview_rows.append(
                {
                    "metric": "Planner context",
                    "value": " | ".join(payload.planner_context),
                }
            )
        if preview_tree is not None:
            self._populate_treeview(preview_tree, preview_rows, preview_columns)

        self._populate_treeview(
            self._sol_species_tree, payload.species_rows, self._sol_species_columns
        )
        self._populate_treeview(
            self._sol_saturation_tree,
            payload.saturation_rows,
            self._sol_saturation_columns,
        )
        self._populate_treeview(
            self._sol_sensitivity_tree,
            payload.sensitivity_rows,
            self._sol_sensitivity_columns,
        )
        self._populate_treeview(
            self._sol_sweep_tree, payload.sweep_rows, self._sol_sweep_columns
        )

        self._update_solubility_plots(payload.chart_data)
        self._update_solubility_preview_plots(payload.chart_data)
        self._update_solubility_sweep_plot(payload.sweep_plot)

        if payload.assumptions:
            bullet = "\n".join(f"• {item}" for item in payload.assumptions)
            self._sol_assumptions_var.set(bullet)
        else:
            self._sol_assumptions_var.set(
                "Assumptions will be listed after running the module."
            )

        summary_var = getattr(self, "_sol_reaction_summary_var", None)
        default_msg = getattr(
            self,
            "_sol_reaction_default_msg",
            "Enter NaOH/CO2 inputs to activate the guidance overlay.",
        )
        guidance_text = payload.co2_guidance or default_msg
        if payload.planner_context:
            guidance_text = f"{guidance_text}\n\nPlan inputs:\n" + "\n".join(
                payload.planner_context
            )
        if summary_var is not None:
            summary_var.set(guidance_text)
        if preview_summary_var is not None:
            preview_summary_var.set(guidance_text)

        math_preview = payload.math_preview_lines
        if not math_preview and payload.reaction_guidance:
            math_preview = payload.reaction_guidance.get("math_lines", [])
        self._sol_math_sections = payload.math_sections
        self._update_sol_math_text_lines(math_preview)
        self._refresh_math_viewer_state()
        self._refresh_math_viewer_contents()

        cycle_timeline = payload.cycle_timeline or []
        self._update_cycle_spec_view(cycle_timeline)
        entries = payload.tracking_entries or existing_entries
        self._sol_tracking_entries = list(entries)
        self._refresh_sol_tracking_table(entries)
        self._update_sol_simulation_plot(payload.reaction_guidance, entries)

        mode_context = payload.mode_context or {}
        if mode_context:
            if context_label is not None:
                context_label.set(mode_context.get("label", "Advanced Solubility"))
            if context_start is not None:
                context_start.set(mode_context.get("starting", ""))
            if context_goal is not None:
                context_goal.set(mode_context.get("goal", ""))
            if context_assumption is not None:
                context_assumption.set(
                    mode_context.get(
                        "assumption", "Mode assumptions will be echoed here."
                    )
                )
        self._refresh_sol_mode_guidance()

    def _update_sol_math_text_lines(self, lines: Sequence[str]) -> None:
        """Update sol math text lines.
        Used to keep sol math text lines in sync with current state."""
        widget = getattr(self, "_sol_math_text", None)
        if widget is None:
            return
        ready_lines = [line for line in lines if line and line.strip()]
        self._sol_math_preview_ready = bool(ready_lines)
        display_lines = (
            ready_lines
            if ready_lines
            else [
                "Detailed math preview warming up. Keep "
                "'Show detailed math calculations' enabled and rerun to capture the steps."
            ]
        )
        widget.configure(state="normal")
        widget.delete("1.0", "end")
        widget.insert("end", "\n".join(display_lines))
        widget.configure(state="disabled")
        self._toggle_sol_math_block()

    def _refresh_sol_tracking_table(self, entries: Sequence[Dict[str, Any]]) -> None:
        """Refresh sol tracking table.
        Used to sync sol tracking table with current settings."""
        tree = getattr(self, "_sol_tracking_tree", None)
        if tree is None:
            return
        # Iterate over tree.get_children() to apply the per-item logic.
        for child in tree.get_children():
            tree.delete(child)
        # Iterate over entries to apply the per-item logic.
        for entry in entries:
            ph_value = entry.get("ph")
            if ph_value is None:
                ph_display = ""
            else:
                try:
                    ph_display = f"{float(ph_value):.2f}"
                except (TypeError, ValueError):
                    ph_display = f"{ph_value}"
            tree.insert(
                "",
                "end",
                values=(
                    entry.get("timestamp", ""),
                    ph_display,
                    f"{entry.get('co2_g', '')}",
                    entry.get("notes", ""),
                ),
            )

    def _update_sol_simulation_plot(
        self,
        reaction_data: Optional[Dict[str, Any]],
        tracking_entries: Sequence[Dict[str, Any]],
    ) -> None:
        """Update sol simulation plot.
        Used to keep sol simulation plot in sync with current state."""
        self._sol_sim_plot_cache = {
            "reaction": reaction_data,
            "entries": list(tracking_entries or []),
        }
        slider = getattr(self, "_sol_sim_slider", None)
        slider_var = getattr(self, "_sol_sim_slider_var", None)
        slider_label = getattr(self, "_sol_sim_slider_label", None)
        payload = reaction_data.get("evaluation") if reaction_data else None
        slider_max = (
            float(reaction_data.get("slider_max_g", 0.0)) if reaction_data else 0.0
        )
        if slider and slider_var and slider_label:
            if payload and slider_max > 0:
                slider.configure(state="normal", to=max(slider_max, 0.5))
                slider_var.set(0.0)
                slider_label.set("Add 0.00 g CO2 -> predicted pH --")
                self._sol_reaction_eval_payload = payload
            else:
                slider.configure(state="disabled", to=1.0)
                slider_var.set(0.0)
                slider_label.set("Add 0.00 g CO2 -> predicted pH --")
                self._sol_reaction_eval_payload = None
        self._sol_sim_slider_preview = None
        self._render_sol_simulation_plot()

    def _render_sol_simulation_plot(self) -> None:
        """Render sol simulation plot.
        Used to draw sol simulation plot for preview or export workflows."""
        ax = getattr(self, "_sol_sim_ax", None)
        canvas = getattr(self, "_sol_sim_canvas", None)
        if ax is None or canvas is None:
            return
        cache = getattr(self, "_sol_sim_plot_cache", None) or {}
        reaction = cache.get("reaction")
        entries = cache.get("entries") or []
        ax.clear()
        target_ph = reaction.get("target_ph") if reaction else None
        if target_ph is not None:
            ax.axhspan(
                target_ph - 0.05,
                target_ph + 0.05,
                color="#e0f2e9",
                alpha=0.4,
                label="Target band",
            )
        if reaction and reaction.get("simulation_curve"):
            xs = [pt.get("total_co2_g", 0.0) for pt in reaction["simulation_curve"]]
            ys = [pt.get("ph", float("nan")) for pt in reaction["simulation_curve"]]
            ax.plot(xs, ys, color="#4c72b0", label="Simulation")
        measurement_points: List[Tuple[float, float, str]] = []
        if reaction and reaction.get("measurement_point"):
            mp = reaction["measurement_point"]
            measurement_points.append(
                (
                    mp.get("co2_g", 0.0),
                    mp.get("ph", float("nan")),
                    mp.get("label", "Measurement"),
                )
            )
        # Iterate over entries to apply the per-item logic.
        for entry in entries:
            try:
                co2_val = float(entry.get("co2_g", 0.0))
            except (TypeError, ValueError):
                co2_val = 0.0
            ph_raw = entry.get("ph")
            try:
                ph_val = float(ph_raw)
            except (TypeError, ValueError):
                ph_val = float("nan")
            measurement_points.append((co2_val, ph_val, entry.get("timestamp", "Log")))
        if measurement_points:
            ax.scatter(
                [pt[0] for pt in measurement_points],
                [pt[1] for pt in measurement_points],
                color="#dd8452",
                label="Measurements",
            )
        recommended = None
        if reaction:
            rec_g = reaction.get("recommended_co2_g")
            base_g = reaction.get("base_co2_g", 0.0)
            rec_ph = reaction.get("predicted_ph_after")
            if rec_g is not None and rec_ph is not None:
                recommended = (base_g + rec_g, rec_ph)
        if recommended:
            ax.scatter(
                [recommended[0]],
                [recommended[1]],
                marker="D",
                color="#55a868",
                s=60,
                label="Recommended",
            )
        preview = getattr(self, "_sol_sim_slider_preview", None)
        if preview:
            ax.scatter(
                [preview.get("co2_g", 0.0)],
                [preview.get("ph", float("nan"))],
                marker="*",
                color="#c44e52",
                s=100,
                label="Slider preview",
            )
        ax.set_xlabel(r"Total CO$_2$ added (g)")
        ax.set_ylabel("pH")
        ax.grid(True, alpha=0.3)
        if ax.get_legend_handles_labels()[0]:
            ax.legend(loc="best", fontsize=8)
        canvas.draw_idle()

    def _on_sol_sim_slider(self, value: str) -> None:
        """Handle sol sim slider.
        Used as an event callback for sol sim slider."""
        payload = getattr(self, "_sol_reaction_eval_payload", None)
        slider_label = getattr(self, "_sol_sim_slider_label", None)
        if payload is None or slider_label is None:
            return
        try:
            delta_g = float(value)
        except (TypeError, ValueError):
            delta_g = 0.0
        pka2 = float(payload.get("pka2", 0.0))
        ledger = payload.get("ledger") or {}
        base_co2 = float(payload.get("base_co2_g", 0.0))
        state = _simulate_reaction_state(
            ledger,
            delta_g / SOL_MW_CO2,
            pka2,
            solution_volume_l=payload.get("volume_l"),
            temperature_c=payload.get("temperature_c"),
            ionic_strength_cap=payload.get("ionic_strength_cap"),
            use_temp_adjusted_constants=bool(
                payload.get("use_temp_adjusted_constants")
            ),
            initial_ph_guess=payload.get("initial_ph_guess"),
            constants=payload.get("constants"),
        )
        if math.isfinite(state.get("ph", float("nan"))):
            payload["initial_ph_guess"] = state["ph"]
        ph = state.get("ph", float("nan"))
        total = base_co2 + delta_g
        slider_label.set(
            f"Add {delta_g:.2f} g CO2 -> predicted pH {ph:.2f} (total {total:.2f} g)"
        )
        self._sol_sim_slider_preview = {"co2_g": total, "ph": ph}
        self._render_sol_simulation_plot()

    def _toggle_sol_math_block(self) -> None:
        """Toggle sol math block.
        Used to flip sol math block and refresh dependent views."""
        widget = getattr(self, "_sol_math_text", None)
        toggle_var = getattr(self, "_sol_show_math_var", None)
        if widget is None or toggle_var is None:
            return
        if toggle_var.get():
            widget.grid()
        else:
            widget.grid_remove()
        self._refresh_math_viewer_state()

    def _refresh_math_viewer_state(self) -> None:
        """Synchronize math-viewer button availability with current prerequisites.

        Purpose:
            Enable the math-viewer launch button only when detailed math output
            is enabled and populated.
        Why:
            The button may be ttk or CTk after staged migration, so state updates
            must use toolkit-agnostic handling.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Enables/disables `_sol_math_view_btn` and closes an open viewer when
            prerequisites are not met.
        Exceptions:
            None.
        """
        button = getattr(self, "_sol_math_view_btn", None)
        sections = getattr(self, "_sol_math_sections", [])
        if button is None:
            return
        toggle_var = getattr(self, "_sol_show_math_var", None)
        if not toggle_var or not toggle_var.get() or not sections:
            # Use shared state helper so ttk and CTk buttons behave consistently.
            self._set_widget_enabled(button, False)
            self._close_sol_math_window()
            return
        self._set_widget_enabled(button, True)

    def _open_sol_math_viewer(self) -> None:
        """Open sol math viewer.
        Used by UI actions to open sol math viewer."""
        toggle_var = getattr(self, "_sol_show_math_var", None)
        if toggle_var is not None and not toggle_var.get():
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module",
                    "Enable 'Show detailed math calculations' before opening the math viewer.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        sections = getattr(self, "_sol_math_sections", [])
        if not sections:
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module",
                    "Run the analysis with 'Show detailed math calculations' enabled "
                    "to populate this viewer.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        window = getattr(self, "_sol_math_window", None)
        if window is not None and window.winfo_exists():
            window.deiconify()
            window.lift()
            self._refresh_math_viewer_contents()
            return
        window = tk.Toplevel(self)
        window.title("Advanced Solubility Math Details")
        window.geometry("900x620")
        window.columnconfigure(1, weight=1)
        window.rowconfigure(0, weight=1)
        window.protocol("WM_DELETE_WINDOW", self._close_sol_math_window)
        self._sol_math_window = window
        listbox = tk.Listbox(window, exportselection=False)
        listbox.grid(row=0, column=0, sticky="ns", padx=(12, 6), pady=12)
        listbox.bind(
            "<<ListboxSelect>>", lambda _evt: self._update_math_viewer_selection()
        )
        self._sol_math_section_list = listbox
        text = scrolledtext.ScrolledText(window, wrap="word", state="disabled")
        text.grid(row=0, column=1, sticky="nsew", padx=(0, 12), pady=12)
        self._enable_text_mousewheel(text)
        self._sol_math_view_text = text
        btn_frame = ttk.Frame(window)
        btn_frame.grid(row=1, column=1, sticky="e", padx=12, pady=(0, 12))
        btn_frame.grid_columnconfigure(0, weight=1)
        render_var = getattr(self, "_sol_math_render_var", None)
        if render_var is None:
            render_var = tk.BooleanVar(value=False)
            self._sol_math_render_var = render_var
        ttk.Checkbutton(
            btn_frame,
            text="Render LaTeX (beta)",
            variable=render_var,
            command=self._refresh_math_viewer_contents,
        ).grid(row=0, column=0, sticky="w", padx=(0, 12))
        ttk.Button(
            btn_frame, text="Copy Section", command=self._copy_current_math_section
        ).grid(row=0, column=1, padx=(0, 6))
        ttk.Button(
            btn_frame, text="Save Section...", command=self._export_math_viewer_section
        ).grid(row=0, column=2, padx=(0, 6))
        ttk.Button(btn_frame, text="Close", command=self._close_sol_math_window).grid(
            row=0, column=3
        )
        self._refresh_math_viewer_contents()

    def _close_sol_math_window(self) -> None:
        """Close sol math window.
        Used by UI actions to close sol math window safely."""
        window = getattr(self, "_sol_math_window", None)
        if window is None:
            return
        if window.winfo_exists():
            window.destroy()
        self._sol_math_window = None
        self._sol_math_section_list = None
        self._sol_math_view_text = None
        self._sol_math_rendered_images = []

    def _refresh_math_viewer_contents(self) -> None:
        """Refresh math viewer contents.
        Used to sync math viewer contents with current settings."""
        window = getattr(self, "_sol_math_window", None)
        listbox = getattr(self, "_sol_math_section_list", None)
        if window is None or not window.winfo_exists() or listbox is None:
            return
        sections = getattr(self, "_sol_math_sections", [])
        listbox.delete(0, "end")
        # Iterate over sections to apply the per-item logic.
        for section in sections:
            listbox.insert("end", section.get("name", "Section"))
        if sections:
            listbox.selection_set(0)
            self._display_math_section_text(0)
        else:
            self._display_math_section_text(None)

    def _update_math_viewer_selection(self) -> None:
        """Update math viewer selection.
        Used to keep math viewer selection in sync with current state."""
        listbox = getattr(self, "_sol_math_section_list", None)
        if listbox is None:
            return
        selection = listbox.curselection()
        index = selection[0] if selection else None
        self._display_math_section_text(index)

    def _render_math_section_text(self, section: Dict[str, Any]) -> str:
        """Render math section text.
        Used to draw math section text for preview or export workflows."""
        lines = [f"=== {section.get('name', 'Section')} ==="]
        # Iterate over section.get("entries", []) to apply the per-item logic.
        for entry in section.get("entries", []):
            description = entry.get("description", "")
            expression = entry.get("expression") or ""
            result = entry.get("result") or ""
            units = entry.get("units") or ""
            steps = entry.get("steps") or []
            line_parts = [description] if description else []
            if expression:
                line_parts.append(expression)
            if result:
                line_parts.append(f"= {result}")
            if units:
                line_parts.append(f"[{units}]")
            header_line = " ".join(line_parts).strip()
            if steps:
                if header_line:
                    lines.append(header_line)
                # Iterate over indexed elements from steps, start=1 to apply the per-item logic.
                for idx, raw_step in enumerate(steps, start=1):
                    title = raw_step.get("title") or f"Step {idx}"
                    latex = raw_step.get("latex") or ""
                    step_expr = raw_step.get("expression") or ""
                    detail = raw_step.get("detail") or ""
                    step_units = raw_step.get("units") or ""
                    prefix = f"  {idx}. {title}"
                    lines.append(prefix)
                    payload = latex if latex and not step_expr else step_expr
                    if payload:
                        lines.append(f"     {payload}")
                    if step_units:
                        lines.append(f"     Units: {step_units}")
                    if detail:
                        # Iterate over detail.splitlines() to apply the per-item logic.
                        for detail_line in detail.splitlines():
                            lines.append(f"     {detail_line}")
            elif header_line:
                lines.append(header_line)
        return "\n".join(lines)

    def _insert_math_section_rich(
        self, widget: tk.Text, section: Dict[str, Any]
    ) -> None:
        """Perform insert math section rich.
        Used to keep the workflow logic localized and testable."""
        widget.insert("end", f"=== {section.get('name', 'Section')} ===\n\n")
        # Iterate over section.get("entries", []) to apply the per-item logic.
        for entry in section.get("entries", []):
            description = entry.get("description") or ""
            expression = entry.get("expression") or ""
            result = entry.get("result") or ""
            units = entry.get("units") or ""
            parts = [description]
            if expression:
                parts.append(expression)
            if result:
                parts.append(f"= {result}")
            if units:
                parts.append(f"[{units}]")
            header = " ".join(part for part in parts if part).strip()
            if header:
                widget.insert("end", header + "\n")
            steps = entry.get("steps") or []
            if not steps:
                widget.insert("end", "  (No detailed steps captured)\n\n")
                continue
            # Iterate over indexed elements from steps, start=1 to apply the per-item logic.
            for idx, step in enumerate(steps, start=1):
                title = step.get("title") or f"Step {idx}"
                widget.insert("end", f"  {idx}. {title}\n")
                latex_expr = (step.get("latex") or "").strip()
                plain_expr = (step.get("expression") or "").strip()
                if latex_expr:
                    image = self._get_latex_photoimage(latex_expr)
                    if image is not None:
                        widget.insert("end", "     ")
                        widget.image_create("end", image=image)
                        widget.insert("end", "\n")
                        self._sol_math_rendered_images.append(image)
                    if plain_expr:
                        widget.insert("end", f"     {plain_expr}\n")
                elif plain_expr:
                    widget.insert("end", f"     {plain_expr}\n")
                units_text = (step.get("units") or "").strip()
                if units_text:
                    widget.insert("end", f"     Units: {units_text}\n")
                detail = (step.get("detail") or "").strip()
                if detail:
                    # Iterate over detail.splitlines() to apply the per-item logic.
                    for detail_line in detail.splitlines():
                        widget.insert("end", f"     {detail_line}\n")
            widget.insert("end", "\n")

    def _get_latex_photoimage(self, latex: str) -> Optional[tk.PhotoImage]:
        """Return latex photoimage.
        Used to retrieve latex photoimage for downstream logic."""
        latex = latex.strip()
        if not latex:
            return None
        cache = getattr(self, "_sol_math_latex_cache", None)
        if cache is None:
            cache = {}
            self._sol_math_latex_cache = cache
        image = cache.get(latex)
        if image is not None:
            return image
        rendered = self._create_latex_photoimage(latex)
        if rendered is not None:
            cache[latex] = rendered
        return rendered

    def _create_latex_photoimage(self, latex: str) -> Optional[tk.PhotoImage]:
        """Create latex photoimage.
        Used to instantiate latex photoimage during setup."""
        latex = latex.strip()
        if not latex:
            return None
        expression = latex if latex.startswith("$") else f"${latex}$"
        buffer = io.BytesIO()
        try:
            mathtext.math_to_image(expression, buffer, dpi=180, format="png")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        buffer.seek(0)
        try:
            encoded = base64.b64encode(buffer.read()).decode("ascii")
            return tk.PhotoImage(data=encoded, master=self)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None

    def _display_math_section_text(self, index: Optional[int]) -> None:
        """Perform display math section text.
        Used to keep the workflow logic localized and testable."""
        text_widget = getattr(self, "_sol_math_view_text", None)
        if text_widget is None:
            return
        sections = getattr(self, "_sol_math_sections", [])
        render_var = getattr(self, "_sol_math_render_var", None)
        render_with_latex = bool(render_var.get()) if render_var else False
        if index is None or not sections or index < 0 or index >= len(sections):
            content = (
                "No math entries available. Enable 'Show detailed math calculations' "
                "and rerun the analysis."
            )
            selected_section = None
        else:
            selected_section = sections[index]
            content = self._render_math_section_text(selected_section)
        text_widget.configure(state="normal")
        text_widget.delete("1.0", "end")
        self._sol_math_rendered_images = []
        if render_with_latex and selected_section:
            self._insert_math_section_rich(text_widget, selected_section)
        else:
            text_widget.insert("end", content.strip())
        text_widget.configure(state="disabled")

    def _copy_current_math_section(self) -> None:
        """Return current math section.
        Used by copy workflows to return math section."""
        text_widget = getattr(self, "_sol_math_view_text", None)
        if text_widget is None:
            return
        content = text_widget.get("1.0", "end").strip()
        if not content:
            return
        try:
            self.clipboard_clear()
            self.clipboard_append(content)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _export_math_viewer_section(self) -> None:
        """Export math viewer section.
        Used to serialize math viewer section for external workflows."""
        listbox = getattr(self, "_sol_math_section_list", None)
        sections = getattr(self, "_sol_math_sections", [])
        if (
            listbox is None
            or not listbox.winfo_exists()
            or not sections
            or len(sections) == 0
        ):
            try:
                messagebox.showwarning(
                    "Advanced Solubility Module",
                    "No math sections are available to export yet.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        selection = listbox.curselection()
        index = int(selection[0]) if selection else None
        if index is None or index < 0 or index >= len(sections):
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module",
                    "Select a math section in the list before exporting.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        section = sections[index]
        render_var = getattr(self, "_sol_math_render_var", None)
        include_latex = bool(render_var.get()) if render_var else False
        export_text = self._build_math_viewer_export_text(
            section, include_latex
        ).strip()
        if not export_text:
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module",
                    "The selected math section is empty.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        section_name = section.get("name", "math_section")
        safe_name = re.sub(r"[^A-Za-z0-9]+", "_", section_name).strip("_")
        initial_name = f"{safe_name or 'math_section'}.png"
        path = filedialog.asksaveasfilename(
            title="Save Detailed Math Section",
            defaultextension=".png",
            filetypes=[("PNG Image", "*.png"), ("PDF Document", "*.pdf")],
            initialfile=initial_name,
        )
        if not path:
            return
        metadata = self._math_viewer_export_metadata(section, include_latex)
        try:
            self._export_text_summary_png(
                export_text,
                path,
                metadata=metadata,
                profile_key="sol_math_detail_export",
            )
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Advanced Solubility Module",
                    f"Failed to export math section: {exc}",
                )
            except Exception:
                pass

    def _build_math_viewer_export_text(
        self, section: Dict[str, Any], include_latex: bool
    ) -> str:
        """Build math viewer export text.
        Used to assemble math viewer export text during UI or plot setup."""
        base_text = self._render_math_section_text(section).strip()
        if not include_latex:
            return base_text
        latex_lines: List[str] = []
        # Iterate over indexed elements from section.get("entries", []), start=1 to apply the per-item logic.
        for entry_idx, entry in enumerate(section.get("entries", []), start=1):
            entry_label = entry.get("description") or f"Entry {entry_idx}"
            # Iterate over indexed elements from entry.get("steps") or [], start=1 to apply the per-item logic.
            for step_idx, step in enumerate(entry.get("steps") or [], start=1):
                latex_expr = (step.get("latex") or "").strip()
                if not latex_expr:
                    continue
                step_title = step.get("title") or f"Step {step_idx}"
                latex_lines.append(f"{entry_label} | {step_title}: {latex_expr}")
        if not latex_lines:
            return base_text
        latex_section = "\n".join(
            ["", "---", "LaTeX expressions:"] + [f"  {line}" for line in latex_lines]
        )
        combined = (
            f"{base_text}{latex_section}" if base_text else latex_section.lstrip()
        )
        return combined.strip()

    def _math_viewer_export_metadata(
        self, section: Dict[str, Any], include_latex: bool
    ) -> List[str]:
        """Export metadata.
        Used by math viewer workflows to export metadata."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return [
            f"Exported: {timestamp}",
            f"App version: {APP_VERSION}",
            f"Section: {section.get('name', 'Section')}",
            f"Render mode: {'Text + LaTeX' if include_latex else 'Text only'}",
        ]

    def _log_sol_measurement(self) -> None:
        """Perform log sol measurement.
        Used to keep the workflow logic localized and testable."""
        default_co2 = ""
        co2_var = self._solubility_vars.get("reaction_co2_charged_g")
        if co2_var is not None:
            default_co2 = co2_var.get().strip()
        try:
            co2_value = simpledialog.askfloat(
                "Reaction Progress",
                "Enter total CO2 added so far (g):",
                initialvalue=default_co2 or None,
                parent=self,
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        if co2_value is None:
            return
        try:
            ph_value = simpledialog.askfloat(
                "Reaction Progress",
                "Enter measured pH:",
                parent=self,
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        if ph_value is None:
            return
        try:
            notes = simpledialog.askstring(
                "Reaction Progress", "Optional notes for this entry:", parent=self
            )
        except Exception:
            notes = ""
        entry = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
            "co2_g": float(co2_value),
            "ph": float(ph_value),
            "notes": notes or "",
        }
        self._sol_tracking_entries.append(entry)
        self._apply_sol_tracking_entries_to_structured()

    def _clear_sol_measurements(self) -> None:
        """Clear sol measurements.
        Used to reset sol measurements state safely."""
        if not getattr(self, "_sol_tracking_entries", []):
            return
        self._sol_tracking_entries.clear()
        self._apply_sol_tracking_entries_to_structured()

    def _apply_sol_tracking_entries_to_structured(self) -> None:
        """Apply sol tracking entries to structured.
        Used to apply sol tracking entries to structured changes to live state."""
        structured = getattr(self, "_sol_last_structured", None)
        if structured is None:
            self._refresh_sol_tracking_table(self._sol_tracking_entries)
            self._update_sol_simulation_plot(None, self._sol_tracking_entries)
            return
        updated = dict(structured)
        updated["tracking_entries"] = list(self._sol_tracking_entries)
        self._update_solubility_structured_widgets(updated)

    def _update_solubility_summary(
        self, message: str, structured: Optional[Dict[str, Any]] = None
    ) -> None:
        """Update solubility summary.
        Used to keep solubility summary in sync with current state."""

        widget = getattr(self, "_solubility_summary", None)

        if widget is None or not widget.winfo_exists():

            return

        widget.configure(state="normal")
        widget.delete("1.0", "end")
        widget.insert("end", message.strip() if message else "")
        widget.configure(state="disabled")
        widget.see("end")
        preview_widget = getattr(self, "_solubility_summary_new", None)
        if preview_widget is not None and preview_widget.winfo_exists():
            preview_widget.configure(state="normal")
            preview_widget.delete("1.0", "end")
            preview_widget.insert("end", message.strip() if message else "")
            preview_widget.configure(state="disabled")
            preview_widget.see("end")
        self._update_solubility_structured_widgets(structured)

    def _collect_solubility_form_data(self) -> Dict[str, Any]:
        """Collect solubility form data.
        Used to gather solubility form data into a structured payload."""
        vars_map = getattr(self, "_solubility_vars", {})
        field_meta = getattr(self, "_solubility_field_meta", {})
        if not vars_map:
            raise ValueError("Solubility inputs are not initialized yet.")

        workflow_key, guide_key, guide, workflow_meta = self._active_sol_input_guide()
        workflow_label = workflow_meta.get("label", workflow_key)
        workflow_mode_key = workflow_meta.get("mode_key", guide_key)
        include_keys = set(workflow_meta.get("input_include_keys") or [])
        extra_fields = list(workflow_meta.get("input_extra_fields") or [])
        allowed_keys: Set[str] = set()
        optional_keys: Set[str] = set()
        # Iterate over guide to apply the per-item logic.
        for spec in guide:
            keys = list(spec.get("keys", []))
            allowed_keys.update(keys)
            if spec.get("optional"):
                optional_keys.update(keys)
        allowed_keys.update(include_keys)
        # Iterate over extra_fields to apply the per-item logic.
        for key, _label, required in extra_fields:
            allowed_keys.add(key)
            if not required:
                optional_keys.add(key)
        shared_keys = {
            "initial_ph_guess",
            "forced_ph_target",
            "ionic_strength_cap",
            "headspace_pco2_atm",
            "headspace_kh_m_per_atm",
            "ph_sweep_low",
            "ph_sweep_high",
            "ph_sweep_steps",
        }
        allowed_keys.update(shared_keys)
        if workflow_key == "Planning":
            allowed_keys.update(
                {"planning_headspace_volume_l", "planning_speciation_ph"}
            )
        missing_specs: List[str] = []
        # Iterate over guide to apply the per-item logic.
        for spec in guide:
            if spec.get("optional"):
                continue
            spec_keys = [key for key in spec.get("keys", []) if key in allowed_keys]
            if not spec_keys:
                continue
            scoped_spec = dict(spec)
            scoped_spec["keys"] = spec_keys
            if not self._helper_spec_complete(scoped_spec):
                missing_specs.append(spec.get("label", "Field"))
        if missing_specs:
            raise ValueError(f"{workflow_label}: Provide {', '.join(missing_specs)}")

        parsed_values: Dict[str, Optional[float]] = {}

        # Closure captures _collect_solubility_form_data local context to keep helper logic scoped and invoked directly within _collect_solubility_form_data.
        def _field_label(key: str) -> str:
            """Perform field label.
            Used to keep the workflow logic localized and testable."""
            return field_meta.get(key, {}).get(
                "label", SOL_MODE_FIELD_LABELS.get(key, key)
            )

        # Closure captures _collect_solubility_form_data local context to keep helper logic scoped and invoked directly within _collect_solubility_form_data.
        def _parse(key: str) -> Optional[float]:
            """Parse value.
            Used to interpret value inputs safely."""
            meta = field_meta.get(key, {})
            label = meta.get("label", key)
            var = vars_map.get(key)
            raw = var.get().strip() if var is not None else ""
            if key not in allowed_keys:
                if not raw:
                    parsed_values[key] = None
                    return None
                try:
                    value = float(raw)
                except ValueError:
                    parsed_values[key] = None
                    return None
                parsed_values[key] = value
                return value
            required = bool(meta.get("required", False)) and key not in optional_keys
            if workflow_key == "Planning" and not self._planning_field_is_visible(key):
                required = False
            if not raw:
                if required:
                    raise ValueError(f"{label} is required.")
                parsed_values[key] = None
                return None
            try:
                value = float(raw)
            except ValueError as exc:
                raise ValueError(f"{label} must be numeric.") from exc
            parsed_values[key] = value
            return value

        # Closure captures _collect_solubility_form_data local context to keep helper logic scoped and invoked directly within _collect_solubility_form_data.
        def _parse_scoped(key: str) -> Optional[float]:
            """Parse scoped.
            Used to interpret scoped inputs safely."""
            if key not in allowed_keys:
                return None
            return _parse(key)

        if getattr(self, "_sol_input_scope_debug", False):
            required_keys: List[str] = []
            # Iterate over sorted(allowed_keys) to apply the per-item logic.
            for key in sorted(allowed_keys):
                meta = field_meta.get(key, {})
                if not meta.get("required", False):
                    continue
                if key in optional_keys:
                    continue
                if workflow_key == "Planning" and not self._planning_field_is_visible(
                    key
                ):
                    continue
                required_keys.append(key)
            print(
                "Solubility workflow required keys:",
                workflow_key,
                required_keys,
            )

        # Closure captures _collect_solubility_form_data local context to keep helper logic scoped and invoked directly within _collect_solubility_form_data.
        def _ensure_positive(value: Optional[float], label: str) -> None:
            """Perform ensure positive.
            Used to keep the workflow logic localized and testable."""
            if value is None or value <= 0:
                raise ValueError(f"{label} must be positive.")

        # Closure captures _collect_solubility_form_data local context to keep helper logic scoped and invoked directly within _collect_solubility_form_data.
        def _ensure_range(
            value: Optional[float], label: str, low: float, high: float
        ) -> None:
            """Perform ensure range.
            Used to keep the workflow logic localized and testable."""
            if value is None:
                return
            if not (low < value < high):
                raise ValueError(f"{label} must be between {low} and {high}.")

        mode_var = getattr(self, "_sol_mode_var", None)
        mode_value = mode_var.get() if mode_var is not None else SOL_DEFAULT_SIM_MODE
        mode_key = (
            mode_value if mode_value in SOL_SIMULATION_MODES else SOL_DEFAULT_SIM_MODE
        )
        planning_spec_key, planning_ph_key, planning_use_same = (
            self._resolve_workflow_model_keys("Planning")
        )
        analysis_spec_key, analysis_ph_key, analysis_use_same = (
            self._resolve_workflow_model_keys("Analysis")
        )
        reprocessing_spec_key, reprocessing_ph_key, reprocessing_use_same = (
            self._resolve_workflow_model_keys("Reprocessing")
        )
        workflow_models = {
            "Planning": (planning_spec_key, planning_ph_key, planning_use_same),
            "Analysis": (analysis_spec_key, analysis_ph_key, analysis_use_same),
            "Reprocessing": (
                reprocessing_spec_key,
                reprocessing_ph_key,
                reprocessing_use_same,
            ),
        }
        workflow_spec_key, workflow_ph_key, workflow_use_same = workflow_models.get(
            workflow_key, (planning_spec_key, planning_ph_key, planning_use_same)
        )
        planning_model_keys = (
            {planning_spec_key}
            if planning_use_same
            else {planning_spec_key, planning_ph_key}
        )
        planning_visible_fields: Set[str] = set()
        # Iterate over planning_model_keys to apply the per-item logic.
        for model_key in planning_model_keys:
            planning_visible_fields.update(MODEL_REQUIRED_FIELDS.get(model_key, set()))
            planning_visible_fields.update(MODEL_OPTIONAL_FIELDS.get(model_key, set()))
        if not planning_visible_fields:
            planning_visible_fields = set(PLANNING_STANDARD_REQUIRED_FIELDS)
            planning_visible_fields.update(PLANNING_STANDARD_OPTIONAL_FIELDS)

        mass = _parse_scoped("mass_na_hco3_g")
        mass_naoh = _parse_scoped("mass_naoh_g")
        if mass is None and mass_naoh is not None:
            mass = mass_naoh * SOL_MW_NAHCO3 / SOL_MW_NAOH
            parsed_values["mass_na_hco3_g"] = mass
        water_mass = _parse_scoped("water_mass_g")
        solution_volume = _parse_scoped("solution_volume_l")
        temperature = _parse_scoped("temperature_c")
        initial_ph = _parse_scoped("initial_ph_guess")
        forced_ph_value = _parse_scoped("forced_ph_target")

        reaction_naoh_mass: Optional[float] = None
        reaction_solution_volume: Optional[float] = None
        reaction_co2_g: Optional[float] = None
        reaction_final_ph: Optional[float] = None
        reaction_slurry_ph: Optional[float] = None
        reaction_target_ph: Optional[float] = None

        diag_dried_ph: Optional[float] = None
        diag_slurry_ph: Optional[float] = None
        diag_sample_mass: Optional[float] = None
        diag_target_ph_entry: Optional[float] = None
        target_diag_ph: Optional[float] = None
        diag_slurry_degas_pct: Optional[float] = None

        planning_cycle_delta_p_psi: Optional[float] = None
        planning_headspace_pressure_high_psi: Optional[float] = None
        planning_cycle_co2: Optional[float] = None
        planning_speciation_ph: Optional[float] = None
        planning_stop_added_g: Optional[float] = None
        planning_stop_ph: Optional[float] = None

        analysis_headspace_volume: Optional[float] = None
        planning_headspace_volume: Optional[float] = None
        headspace_pco2: Optional[float] = None
        headspace_kh: Optional[float] = None

        assumed_solution_volume_l: Optional[float] = None
        manual_cycle_override = False
        planning_headspace_required = False
        analysis_headspace_required = False
        include_headspace_fields = workflow_meta.get("include_headspace", False)
        headspace_ready = False
        forced_ready = False
        degassed_fraction = 0.0

        if workflow_key == "Planning":
            planning_cycle_delta_p_psi = _parse_scoped("planning_cycle_delta_p_psi")
            planning_headspace_pressure_high_psi = _parse_scoped(
                "planning_headspace_pressure_high_psi"
            )
            planning_cycle_co2 = _parse_scoped("planning_cycle_co2_g")
            planning_speciation_ph = _parse_scoped("planning_speciation_ph")
            planning_stop_added_g = _parse_scoped("planning_stop_co2_added_g")
            planning_stop_ph = _parse_scoped("planning_stop_ph")
            planning_headspace_volume = _parse_scoped("planning_headspace_volume_l")
            headspace_pco2 = _parse_scoped("headspace_pco2_atm")
            headspace_kh = _parse_scoped("headspace_kh_m_per_atm")

            if planning_speciation_ph is None:
                planning_speciation_ph = 8.0
                parsed_values["planning_speciation_ph"] = planning_speciation_ph
            manual_cycle_override = (
                planning_cycle_co2 is not None and planning_cycle_co2 > 0
            )
            if planning_cycle_co2 is not None and planning_cycle_co2 <= 0:
                planning_cycle_co2 = None
                parsed_values["planning_cycle_co2_g"] = None
            if planning_stop_added_g is None or planning_stop_added_g <= 0:
                planning_stop_added_g = PLANNING_DEFAULT_STOP_CO2_ADDED_G
                parsed_values["planning_stop_co2_added_g"] = planning_stop_added_g
            if planning_stop_ph is None or not (0.0 < planning_stop_ph < 14.5):
                planning_stop_ph = PLANNING_DEFAULT_STOP_PH
                parsed_values["planning_stop_ph"] = planning_stop_ph
            planning_headspace_required = not manual_cycle_override

            if not manual_cycle_override:
                _ensure_positive(
                    planning_cycle_delta_p_psi,
                    _field_label("planning_cycle_delta_p_psi"),
                )
            elif (
                planning_cycle_delta_p_psi is not None
                and planning_cycle_delta_p_psi <= 0
            ):
                planning_cycle_delta_p_psi = None
                parsed_values["planning_cycle_delta_p_psi"] = None
            if "planning_speciation_ph" in allowed_keys:
                _ensure_range(
                    planning_speciation_ph,
                    _field_label("planning_speciation_ph"),
                    0.0,
                    14.0,
                )
            if "planning_stop_ph" in allowed_keys:
                _ensure_range(
                    planning_stop_ph,
                    _field_label("planning_stop_ph"),
                    0.0,
                    14.5,
                )
            if (
                "planning_headspace_pressure_high_psi" in planning_visible_fields
                and "planning_headspace_pressure_high_psi" in allowed_keys
            ):
                _ensure_positive(
                    planning_headspace_pressure_high_psi,
                    _field_label("planning_headspace_pressure_high_psi"),
                )
            if forced_ph_value is None:
                forced_ph_value = planning_speciation_ph
                parsed_values["forced_ph_target"] = forced_ph_value
            headspace_ready = (
                include_headspace_fields
                and headspace_pco2 is not None
                and headspace_pco2 > 0
                and headspace_kh is not None
                and headspace_kh > 0
            )
            forced_ready = forced_ph_value is not None and 0.0 < forced_ph_value < 14.0
            if workflow_mode_key == "nahco3_dissolution" and not (
                forced_ready or headspace_ready
            ):
                raise ValueError(
                    f"{workflow_label}: Provide a forced target pH or valid headspace data (pCO₂ & Henry constant)."
                )

        elif workflow_key == "Analysis":
            reaction_naoh_mass = _parse_scoped("reaction_naoh_mass_g")
            reaction_solution_volume = _parse_scoped("reaction_solution_volume_l")
            reaction_co2_g = _parse_scoped("reaction_co2_charged_g")
            reaction_final_ph = _parse_scoped("reaction_final_ph")
            reaction_slurry_ph = _parse_scoped("reaction_slurry_ph")
            reaction_target_ph = _parse_scoped("reaction_target_ph")
            analysis_headspace_volume = _parse_scoped("analysis_headspace_volume_l")
            headspace_pco2 = _parse_scoped("headspace_pco2_atm")
            headspace_kh = _parse_scoped("headspace_kh_m_per_atm")
            analysis_headspace_required = True

            has_cycles = bool(self._get_cycle_payload_for_workflow(workflow_key))
            if not has_cycles and reaction_co2_g is None:
                raise ValueError(
                    "Analysis: import cycle data or record the CO₂ total before running."
                )

            headspace_ready = (
                include_headspace_fields
                and headspace_pco2 is not None
                and headspace_pco2 > 0
                and headspace_kh is not None
                and headspace_kh > 0
            )
            forced_ready = forced_ph_value is not None and 0.0 < forced_ph_value < 14.0
            if workflow_mode_key == "naoh_reaction":
                _ensure_positive(
                    reaction_naoh_mass, _field_label("reaction_naoh_mass_g")
                )
                _ensure_positive(
                    reaction_solution_volume,
                    _field_label("reaction_solution_volume_l"),
                )
                target_ready = (
                    reaction_target_ph is not None and 0.0 < reaction_target_ph < 14.0
                )
                co2_ready = reaction_co2_g is not None and reaction_co2_g >= 0.0
                if not any([forced_ready, target_ready, co2_ready, headspace_ready]):
                    raise ValueError(
                        f"{workflow_label}: Provide a CO₂ total, target/forced pH, or headspace settings for sodium hydroxide cycles."
                    )

        elif workflow_key == "Reprocessing":
            diag_dried_ph = _parse_scoped("diag_dried_sample_ph")
            diag_slurry_ph = _parse_scoped("diag_slurry_ph")
            diag_sample_mass = _parse_scoped("diag_sample_mass_g")
            diag_target_ph_entry = _parse_scoped("diag_target_ph")
            target_diag_ph = diag_target_ph_entry
            diag_slurry_degas_pct = _parse_scoped("diag_slurry_degas_pct")

            if (
                workflow_mode_key == "contaminated_bicarb_diagnostic"
                and water_mass is None
                and solution_volume is None
            ):
                solution_volume = 2.5
                assumed_solution_volume_l = 2.5

            if mode_key == "contaminated_bicarb_diagnostic":
                if diag_slurry_ph is None:
                    raise ValueError(
                        "Provide the failing slurry pH measurement for Reprocessing."
                    )
                if "diag_slurry_ph" in allowed_keys:
                    _ensure_range(
                        diag_slurry_ph,
                        _field_label("diag_slurry_ph"),
                        0.0,
                        14.5,
                    )
                if (
                    diag_sample_mass is not None
                    and "diag_sample_mass_g" in allowed_keys
                ):
                    _ensure_positive(
                        diag_sample_mass, _field_label("diag_sample_mass_g")
                    )
                if (
                    diag_slurry_degas_pct is not None
                    and "diag_slurry_degas_pct" in allowed_keys
                ):
                    if not (0.0 <= diag_slurry_degas_pct < 100.0):
                        raise ValueError(
                            "CO2 vented fraction must be between 0 and 100%."
                        )
                    degassed_fraction = diag_slurry_degas_pct / 100.0
                target_diag_ph = (
                    diag_target_ph_entry if diag_target_ph_entry is not None else 8.0
                )
                if "diag_target_ph" in allowed_keys:
                    _ensure_range(
                        target_diag_ph,
                        _field_label("diag_target_ph"),
                        0.0,
                        14.0,
                    )
                initial_ph = diag_slurry_ph
                if forced_ph_value is None:
                    forced_ph_value = target_diag_ph

            if diag_target_ph_entry is None:
                raise ValueError("Reprocessing: provide the target pass pH.")
            if diag_slurry_ph is None:
                raise ValueError(
                    "Reprocessing: supply the failing slurry pH measurement."
                )

        if headspace_pco2 is None:
            headspace_pco2 = _parse_scoped("headspace_pco2_atm")
        if headspace_kh is None:
            headspace_kh = _parse_scoped("headspace_kh_m_per_atm")

        ionic_cap_raw = _parse_scoped("ionic_strength_cap")
        sweep_low = _parse_scoped("ph_sweep_low")
        sweep_high = _parse_scoped("ph_sweep_high")
        sweep_steps = _parse_scoped("ph_sweep_steps")

        if "mass_na_hco3_g" in allowed_keys or "mass_naoh_g" in allowed_keys:
            _ensure_positive(mass, _field_label("mass_na_hco3_g"))
        if "temperature_c" in allowed_keys:
            _ensure_positive(temperature, _field_label("temperature_c"))

        if water_mass is not None and "water_mass_g" in allowed_keys:
            _ensure_positive(water_mass, _field_label("water_mass_g"))
        if solution_volume is not None and "solution_volume_l" in allowed_keys:
            _ensure_positive(solution_volume, _field_label("solution_volume_l"))
        if (
            "water_mass_g" in allowed_keys
            and "solution_volume_l" in allowed_keys
            and water_mass is None
            and solution_volume is None
        ):
            raise ValueError("Provide either a water mass or a final solution volume.")

        headspace_volume: Optional[float] = None
        headspace_label: Optional[str] = None
        headspace_key: Optional[str] = None
        if workflow_key == "Planning":
            headspace_volume = planning_headspace_volume
            headspace_label = _field_label("planning_headspace_volume_l")
            headspace_key = "planning_headspace_volume_l"
        elif workflow_key == "Analysis":
            headspace_volume = analysis_headspace_volume
            headspace_label = _field_label("analysis_headspace_volume_l")
            headspace_key = "analysis_headspace_volume_l"
        if headspace_key and headspace_key in allowed_keys:
            if planning_headspace_required or analysis_headspace_required:
                _ensure_positive(headspace_volume, headspace_label)
            elif headspace_volume is not None and headspace_volume <= 0:
                raise ValueError(f"{headspace_label} must be positive.")

        diagnostic_data: Optional[Dict[str, Any]] = None
        diag_assumed_water: Optional[float] = None
        solvent_basis = "water_mass" if water_mass is not None else "solution_volume"
        solvent_basis_value = (
            water_mass if solvent_basis == "water_mass" else solution_volume
        )
        diagnostic_data = {
            "dried_ph": diag_dried_ph,
            "slurry_ph": diag_slurry_ph,
            "target_ph": target_diag_ph,
            "sample_mass_g": diag_sample_mass,
            "assumed_water_mass_g": diag_assumed_water,
            "degassed_fraction": degassed_fraction,
            "failing_ph": diag_slurry_ph,
            "solvent_basis": solvent_basis,
            "solvent_basis_value": solvent_basis_value,
        }

        planning_initial_naoh_mol: Optional[float] = None
        if workflow_key == "Planning" and mass_naoh is not None and mass_naoh > 0:
            planning_initial_naoh_mol = mass_naoh / SOL_MW_NAOH
            parsed_values["planning_initial_naoh_mol"] = planning_initial_naoh_mol

        if "forced_ph_target" in allowed_keys:
            _ensure_range(forced_ph_value, _field_label("forced_ph_target"), 0.0, 14.0)
        if "reaction_target_ph" in allowed_keys:
            _ensure_range(
                reaction_target_ph, _field_label("reaction_target_ph"), 0.0, 14.0
            )
        limit_ionic = bool(getattr(self, "_sol_limit_ionic_var", tk.BooleanVar()).get())
        include_headspace = bool(
            getattr(self, "_sol_include_headspace_var", tk.BooleanVar()).get()
        )
        if workflow_key == "Planning":
            include_headspace = True
            if (
                "headspace_pco2_atm" not in planning_visible_fields
                and "headspace_kh_m_per_atm" not in planning_visible_fields
            ):
                include_headspace = False

        ionic_cap = ionic_cap_raw if limit_ionic else None
        if ionic_cap is not None and ionic_cap <= 0:
            raise ValueError("Ionic strength cap must be positive.")

        headspace_pco2_value = headspace_pco2 if include_headspace else None
        headspace_kh_value = headspace_kh if include_headspace else None
        if include_headspace:
            if headspace_pco2_value is None or headspace_pco2_value <= 0:
                raise ValueError("Headspace pCO2 must be positive when enabled.")
            if headspace_kh_value is None or headspace_kh_value <= 0:
                raise ValueError(
                    "Henry constant must be positive when headspace is enabled."
                )

        sweep_low_value = (
            sweep_low if sweep_low is not None else SOL_PH_SWEEP_DEFAULT[0]
        )
        sweep_high_value = (
            sweep_high if sweep_high is not None else SOL_PH_SWEEP_DEFAULT[1]
        )
        sweep_steps_value = (
            int(round(sweep_steps))
            if sweep_steps is not None
            else SOL_PH_SWEEP_DEFAULT[2]
        )
        if sweep_high_value <= sweep_low_value:
            raise ValueError(
                "pH sweep upper bound must be greater than the lower bound."
            )
        if sweep_steps_value < 3:
            sweep_steps_value = SOL_PH_SWEEP_DEFAULT[2]

        forced_target = forced_ph_value if forced_ph_value is not None else None
        if mode_key == "naoh_reaction":
            if reaction_naoh_mass is None or reaction_naoh_mass <= 0:
                raise ValueError(
                    "Initial NaOH mass is required when using the NaOH + CO2 mode."
                )
            if reaction_solution_volume is None or reaction_solution_volume <= 0:
                raise ValueError(
                    "Process liquor volume is required when using the NaOH + CO2 mode."
                )
            if (
                reaction_co2_g is None
                and forced_target is None
                and reaction_target_ph is None
                and headspace_pco2_value is None
            ):
                raise ValueError(
                    "Provide a CO2 total, forced pH target, target pH, or headspace pressure when simulating the NaOH + CO2 mode."
                )
        elif mode_key == "contaminated_feed":
            if reaction_target_ph is None and forced_target is None:
                raise ValueError(
                    "Provide a target pH or forced pH when purifying a contaminated NaHCO3 feed."
                )
        params = SolubilityInputs(
            mass_na_hco3_g=mass,
            water_mass_g=water_mass,
            solution_volume_l=solution_volume,
            temperature_c=temperature,
            initial_ph_guess=initial_ph,
            forced_ph_target=forced_target,
            use_temperature_adjusted_constants=bool(
                getattr(self, "_sol_use_temp_adjust_var", tk.BooleanVar()).get()
            ),
            ionic_strength_cap=ionic_cap,
            headspace_pco2_atm=headspace_pco2_value,
            headspace_kh_m_per_atm=headspace_kh_value,
            degassed_fraction=degassed_fraction,
            headspace_volume_l=headspace_volume,
            speciation_mode=SPEC_MODE_FIXED_PCO2,
        )

        model_key = workflow_spec_key
        available_models = {model.key for model in list_speciation_models()}
        if model_key not in available_models:
            aqion_key = "aqion_closed"
            model_key = (
                aqion_key if aqion_key in available_models else DEFAULT_SPEC_MODEL_KEY
            )
            self._sol_model_key = model_key
        model_options = ModelOptions(
            override_ionic_strength_cap=ionic_cap,
            extra={
                "include_headspace": include_headspace,
                "slurry_mode": mode_key == "contaminated_bicarb_diagnostic",
            },
        )

        return {
            "params": params,
            "forced_target": forced_target,
            "sweep_low": sweep_low_value,
            "sweep_high": sweep_high_value,
            "sweep_steps": sweep_steps_value,
            "reaction_naoh_mass": reaction_naoh_mass,
            "reaction_solution_volume": reaction_solution_volume,
            "reaction_co2_g": reaction_co2_g,
            "reaction_final_ph": reaction_final_ph,
            "reaction_slurry_ph": reaction_slurry_ph,
            "reaction_target_ph": reaction_target_ph,
            "diagnostic_data": diagnostic_data,
            "failing_ph": diag_slurry_ph,
            "solvent_basis": solvent_basis,
            "solvent_basis_value": solvent_basis_value,
            "naoh_mass_basis": mass_naoh,
            "planning_initial_naoh_mol": planning_initial_naoh_mol,
            "planning_cycle_co2_g": planning_cycle_co2,
            "planning_cycle_delta_p_psi": planning_cycle_delta_p_psi,
            "planning_headspace_pressure_high_psi": planning_headspace_pressure_high_psi,
            "planning_stop_co2_added_g": planning_stop_added_g,
            "planning_stop_ph": planning_stop_ph,
            "planning_plot_ph": planning_speciation_ph,
            "mode": mode_key,
            "model_key": model_key,
            "planning_spec_model_key": planning_spec_key,
            "planning_ph_model_key": planning_ph_key,
            "planning_use_same_model": planning_use_same,
            "analysis_spec_model_key": analysis_spec_key,
            "analysis_ph_model_key": analysis_ph_key,
            "analysis_use_same_model": analysis_use_same,
            "reprocessing_spec_model_key": reprocessing_spec_key,
            "reprocessing_ph_model_key": reprocessing_ph_key,
            "reprocessing_use_same_model": reprocessing_use_same,
            "workflow_spec_model_key": workflow_spec_key,
            "workflow_ph_model_key": workflow_ph_key,
            "workflow_use_same_model": workflow_use_same,
            "model_options": model_options,
            "guide_key": guide_key,
            "workflow_key": workflow_key,
            "assumed_solution_volume_l": assumed_solution_volume_l,
            "headspace_volume_l": headspace_volume,
            "planning_headspace_volume_l": planning_headspace_volume,
        }

    def _save_solubility_summary_png(self) -> None:
        """Save solubility summary PNG.
        Used when persisting solubility summary PNG to storage."""

        widget = getattr(self, "_solubility_summary", None)

        if widget is None or not widget.winfo_exists():

            try:

                messagebox.showwarning(
                    "Advanced Solubility Module",
                    "The solubility summary is not available yet.",
                )

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            return

        try:

            text = widget.get("1.0", "end").strip()

        except Exception:

            text = ""

        if not text:

            try:

                messagebox.showinfo(
                    "Advanced Solubility Module",
                    "The solubility summary is currently empty. "
                    "Run the analysis before exporting.",
                )

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            return

        path = filedialog.asksaveasfilename(
            title="Save Solubility Summary as PNG",
            defaultextension=".png",
            filetypes=[("PNG Image", "*.png")],
            initialfile="solubility_summary.png",
        )

        if not path:

            return

        metadata = self._solubility_export_metadata()

        try:

            self._export_text_summary_png(
                text,
                path,
                metadata=metadata,
                profile_key="solubility_summary_png",
            )

        except Exception as exc:

            try:

                messagebox.showerror(
                    "Advanced Solubility Module",
                    f"Failed to save solubility summary: {exc}",
                )

            except Exception:

                pass

    def _export_planner_narrative_png(self) -> None:
        """Export planner narrative PNG.
        Used to serialize planner narrative PNG for external workflows."""
        widget = getattr(self, "_solubility_summary_new", None)
        if widget is None or not widget.winfo_exists():
            try:
                messagebox.showwarning(
                    "Advanced Solubility Module",
                    "Planner narrative is not available yet.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        text = widget.get("1.0", "end").strip()
        if not text:
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module",
                    "Planner narrative is empty. Run the analysis before exporting.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        path = filedialog.asksaveasfilename(
            title="Export Planner Narrative",
            defaultextension=".png",
            filetypes=[("PNG Image", "*.png")],
            initialfile="planner_narrative.png",
        )
        if not path:
            return
        self._export_text_summary_png(
            text,
            path,
            metadata=self._solubility_export_metadata(),
            profile_key="sol_planner_narrative_png",
        )

    def _export_co2_guidance_png(self) -> None:
        """Export CO2 guidance PNG.
        Used to serialize CO2 guidance PNG for external workflows."""
        guidance_var = getattr(self, "_sol_new_reaction_summary_var", None)
        if guidance_var is None:
            return
        text = guidance_var.get().strip()
        if not text:
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module",
                    "CO₂ guidance is unavailable. Run the analysis before exporting.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        path = filedialog.asksaveasfilename(
            title="Export CO₂ Guidance",
            defaultextension=".png",
            filetypes=[("PNG Image", "*.png")],
            initialfile="co2_guidance.png",
        )
        if not path:
            return
        self._export_text_summary_png(
            text,
            path,
            metadata=self._solubility_export_metadata(),
            profile_key="sol_co2_guidance_png",
        )

    def _export_math_preview_png(self) -> None:
        """Export math preview PNG.
        Used to serialize math preview PNG for external workflows."""
        widget = getattr(self, "_sol_math_text", None)
        if widget is None:
            return
        if not getattr(self, "_sol_math_preview_ready", False):
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module",
                    "Math preview is still warming up. Enable the math option and rerun.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        text = widget.get("1.0", "end").strip()
        if not text:
            try:
                messagebox.showinfo(
                    "Advanced Solubility Module",
                    "Math preview is empty. Capture math by rerunning with the option enabled.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        path = filedialog.asksaveasfilename(
            title="Export Math Preview",
            defaultextension=".png",
            filetypes=[("PNG Image", "*.png")],
            initialfile="math_preview.png",
        )
        if not path:
            return
        self._export_text_summary_png(
            text,
            path,
            metadata=self._solubility_export_metadata(),
            profile_key="sol_math_preview_png",
        )

    def _canonicalize_planning_inputs(
        self, form_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Perform canonicalize planning inputs.
        Used to keep the workflow logic localized and testable."""

        canonical = dict(form_data or {})
        canonical["planning_cycle_delta_p_psi"] = _safe_float(
            canonical.get("planning_cycle_delta_p_psi")
        )
        canonical["planning_headspace_volume_l"] = _safe_float(
            canonical.get("planning_headspace_volume_l")
        )
        canonical["planning_headspace_pressure_high_psi"] = _safe_float(
            canonical.get("planning_headspace_pressure_high_psi")
        )
        manual_cycle = _safe_float(canonical.get("planning_cycle_co2_g"))
        if manual_cycle is not None and manual_cycle <= 0:
            manual_cycle = None
        canonical["planning_cycle_co2_g"] = manual_cycle

        stop_added = _safe_float(canonical.get("planning_stop_co2_added_g"))
        canonical["planning_stop_co2_added_g"] = (
            stop_added
            if stop_added is not None and math.isfinite(stop_added) and stop_added > 0
            else PLANNING_DEFAULT_STOP_CO2_ADDED_G
        )
        stop_ph = _safe_float(canonical.get("planning_stop_ph"))
        canonical["planning_stop_ph"] = (
            stop_ph
            if stop_ph is not None and 0.0 < stop_ph < 14.5
            else PLANNING_DEFAULT_STOP_PH
        )

        initial_naoh = _safe_float(canonical.get("planning_initial_naoh_mol"))
        if initial_naoh is None:
            naoh_mass_basis = _safe_float(canonical.get("naoh_mass_basis"))
            if (
                naoh_mass_basis is not None
                and math.isfinite(naoh_mass_basis)
                and naoh_mass_basis > 0
            ):
                initial_naoh = naoh_mass_basis / SOL_MW_NAOH
        if initial_naoh is None:
            naoh_mass = _safe_float(canonical.get("mass_naoh_g"))
            if naoh_mass is not None and math.isfinite(naoh_mass) and naoh_mass > 0:
                initial_naoh = naoh_mass / SOL_MW_NAOH
        canonical["planning_initial_naoh_mol"] = initial_naoh
        # Planning inputs source-of-truth: planning_cycle_delta_p_psi, planning_cycle_co2_g,
        # planning_headspace_volume_l, planning_stop_co2_added_g, planning_stop_ph,
        # planning_initial_naoh_mol.
        return canonical

    def _scrub_planning_measured_fields(
        self, form_data: Dict[str, Any]
    ) -> Optional[str]:
        """Perform scrub planning measured fields.
        Used to keep the workflow logic localized and testable."""

        if form_data.get("workflow_key") != "Planning":
            return None

        ignored_fields: List[str] = []
        # Iterate over ("reaction_final_ph", "reaction_slurry_ph", "failing_ph") to apply the per-item logic.
        for key in ("reaction_final_ph", "reaction_slurry_ph", "failing_ph"):
            if key in form_data and form_data.get(key) not in (None, ""):
                form_data[key] = None
                ignored_fields.append(key)
        diagnostic = form_data.get("diagnostic_data")
        if isinstance(diagnostic, dict):
            # Iterate over ("slurry_ph", "reaction_final_ph", "final_ph") to apply the per-item logic.
            for diag_key in ("slurry_ph", "reaction_final_ph", "final_ph"):
                if diagnostic.get(diag_key) not in (None, ""):
                    diagnostic[diag_key] = None
                    ignored_fields.append(f"diagnostic.{diag_key}")
        if ignored_fields:
            form_data["_planning_measured_fields_ignored"] = True
            return "Ignoring measured pH fields in Planning mode (Reprocessing-only)."
        return None

    def _planning_cycle_moles_from_pressure(
        self,
        delta_psi: float,
        headspace_volume_l: float,
        temperature_c: Optional[float],
    ) -> float:
        """Perform planning cycle moles from pressure.
        Used to keep the workflow logic localized and testable."""

        delta_atm = _pressure_psi_to_atm(delta_psi)
        if delta_atm is None or not math.isfinite(delta_atm) or delta_atm <= 0:
            raise ValueError(
                "Planning: unable to convert delta-P to atm for CO2 uptake."
            )
        try:
            temp_k = (temperature_c if temperature_c is not None else 25.0) + 273.15
        except Exception:
            temp_k = 298.15
        if (
            headspace_volume_l is None
            or not math.isfinite(headspace_volume_l)
            or headspace_volume_l <= 0
        ):
            raise ValueError(
                "Planning: headspace volume is required to compute CO2 uptake."
            )
        moles_per_cycle = (
            delta_atm
            * headspace_volume_l
            / (_SOL_IDEAL_GAS_R_L_ATM_PER_MOLK * max(temp_k, 1e-6))
        )
        if moles_per_cycle <= 0 or not math.isfinite(moles_per_cycle):
            raise ValueError("Planning: computed CO2 per cycle is non-positive.")
        return moles_per_cycle

    def _generate_planning_cycle_payload(
        self,
        form_data: Dict[str, Any],
        solver_inputs: SolubilitySolverInputs,
    ) -> Optional[Dict[str, Any]]:
        """Generate planning cycle payload.
        Used to produce planning cycle payload outputs for analysis or export."""
        workflow_key = form_data.get("workflow_key")
        if workflow_key != "Planning":
            return None

        measured_scrub_note = self._scrub_planning_measured_fields(form_data)
        canonical_inputs = self._canonicalize_planning_inputs(form_data)
        form_data.update(
            {
                "planning_cycle_delta_p_psi": canonical_inputs.get(
                    "planning_cycle_delta_p_psi"
                ),
                "planning_headspace_volume_l": canonical_inputs.get(
                    "planning_headspace_volume_l"
                ),
                "planning_headspace_pressure_high_psi": canonical_inputs.get(
                    "planning_headspace_pressure_high_psi"
                ),
                "planning_stop_co2_added_g": canonical_inputs.get(
                    "planning_stop_co2_added_g"
                ),
                "planning_stop_ph": canonical_inputs.get("planning_stop_ph"),
                "planning_cycle_co2_g": canonical_inputs.get("planning_cycle_co2_g"),
                "planning_initial_naoh_mol": canonical_inputs.get(
                    "planning_initial_naoh_mol"
                ),
            }
        )

        manual_cycle_co2_g = canonical_inputs.get("planning_cycle_co2_g")
        delta_psi = canonical_inputs.get("planning_cycle_delta_p_psi")
        headspace_volume_l = canonical_inputs.get("planning_headspace_volume_l")
        headspace_pressure_high_psi = canonical_inputs.get(
            "planning_headspace_pressure_high_psi"
        )
        stop_added_g = (
            canonical_inputs.get("planning_stop_co2_added_g")
            or PLANNING_DEFAULT_STOP_CO2_ADDED_G
        )
        stop_ph = canonical_inputs.get("planning_stop_ph") or PLANNING_DEFAULT_STOP_PH
        initial_naoh_mol = canonical_inputs.get("planning_initial_naoh_mol")
        if initial_naoh_mol is None or initial_naoh_mol <= 0:
            raise ValueError(
                "Planning: provide a valid NaOH mass to define total sodium."
            )
        equivalence_moles = initial_naoh_mol / 2.0

        temp_c = solver_inputs.params.temperature_c
        solution_volume_l = getattr(solver_inputs.params, "solution_volume_l", None)
        try:
            if solution_volume_l is None:
                solution_volume_l = solver_inputs.params.solution_volume_l
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            if solution_volume_l is None:
                solution_volume_l = solver_inputs.params.volume_l()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if solution_volume_l is None or solution_volume_l <= 0:
            solution_volume_l = 1.0

        use_temp_constants = bool(
            solver_inputs.params.use_temperature_adjusted_constants
        )
        ionic_cap = solver_inputs.params.ionic_strength_cap
        pka2_value = _resolve_pka2_value(temp_c, use_temp_constants)
        ledger_constants = _basic_carbonate_constants(temp_c, use_temp_constants)
        _planning_spec_key, planning_ph_key, _ = self._resolve_planning_model_keys(
            form_data
        )
        try:
            ph_model = get_speciation_model(planning_ph_key)
        except KeyError:
            ph_model = get_speciation_model(None)
            planning_ph_key = getattr(ph_model, "key", DEFAULT_SPEC_MODEL_KEY)
        planning_context = {
            "naoh_mass_g": _safe_float(form_data.get("mass_naoh_g"))
            or (initial_naoh_mol * SOL_MW_NAOH if initial_naoh_mol else None),
            "water_mass_g": solver_inputs.params.water_mass_g,
            "solution_volume_l": solution_volume_l,
            "temperature_c": temp_c,
            "headspace_volume_l": headspace_volume_l,
            "planning_headspace_pressure_high_psi": headspace_pressure_high_psi,
            "planning_cycle_delta_p_psi": delta_psi,
            "planning_cycle_co2_g": manual_cycle_co2_g,
        }

        if manual_cycle_co2_g is not None and manual_cycle_co2_g > 0:
            moles_per_cycle = manual_cycle_co2_g / SOL_MW_CO2
            moles_basis = "manual_override"
        else:
            if delta_psi is None or not math.isfinite(delta_psi) or delta_psi <= 0:
                raise ValueError(
                    "Planning: provide a positive pressure drop per cycle or a manual CO2-per-cycle override."
                )
            moles_per_cycle = self._planning_cycle_moles_from_pressure(
                delta_psi, headspace_volume_l, temp_c
            )
            moles_basis = "delta_p_headspace"

        sodium_total_moles = max(initial_naoh_mol, 0.0)
        ledger_state = {
            "naoh_remaining_mol": sodium_total_moles,
            "na2co3_mol": 0.0,
            "nahco3_mol": 0.0,
            "co2_excess_mol": 0.0,
        }
        reference_ledgers: List[Dict[str, Any]] = []
        if sodium_total_moles > 0:
            # Iterate to apply the per-item logic.
            for label, frac in (
                ("11.9% carbonate", 0.119),
                ("5% carbonate", 0.05),
                ("2% carbonate", 0.02),
            ):
                ledger_ref = _ledger_from_sodium_and_carbonate_fraction(
                    sodium_total_moles, frac
                )
                ref_ph = _estimate_ledger_ph(
                    ledger_ref,
                    pka2_value,
                    solution_volume_l=solution_volume_l,
                    temperature_c=temp_c,
                    ionic_strength_cap=ionic_cap,
                    use_temp_adjusted_constants=use_temp_constants,
                    constants=ledger_constants,
                )
                reference_ledgers.append(
                    {
                        "label": label,
                        "carbonate_fraction": frac,
                        "ph": ref_ph,
                    }
                )
        projection_warning: Optional[str] = measured_scrub_note
        cycle_entries: List[Dict[str, Any]] = []
        cumulative_moles = 0.0
        cumulative_mass = 0.0
        cumulative_consumed_moles = 0.0
        cumulative_unconsumed_moles = 0.0
        stop_reason: Optional[str] = None
        recent_ph_values: List[float] = []
        recent_post_eq_ph: List[float] = []
        # Iterate over the configured range to apply the per-item logic.
        for idx in range(1, MAX_PLANNING_SYNTH_CYCLES + 1):
            previous_ph = recent_ph_values[-1] if recent_ph_values else None
            cumulative_moles += moles_per_cycle
            cumulative_mass = cumulative_moles * SOL_MW_CO2
            entry: Dict[str, Any] = {
                "cycle_id": idx,
                "delta_pressure_psi": delta_psi,
                "mean_temperature_c": temp_c,
                "selected_moles": moles_per_cycle,
                "selected_mass_g": moles_per_cycle * SOL_MW_CO2,
                "co2_mass_g": moles_per_cycle * SOL_MW_CO2,
                "cumulative_co2_moles": cumulative_moles,
                "cumulative_co2_mass_g": cumulative_mass,
                "moles_basis": moles_basis,
            }
            entry_warnings: List[str] = []
            if measured_scrub_note and idx == 1:
                entry_warnings.append(measured_scrub_note)
            try:
                state, accounting = _simulate_reaction_state_with_accounting(
                    ledger_state,
                    moles_per_cycle,
                    pka2_value,
                    solution_volume_l=solution_volume_l,
                    temperature_c=temp_c,
                    ionic_strength_cap=ionic_cap,
                    use_temp_adjusted_constants=use_temp_constants,
                    constants=ledger_constants,
                    planning_mode=True,
                )
                ledger_state = {
                    "naoh_remaining_mol": max(
                        state.get("naoh_remaining_mol", 0.0), 0.0
                    ),
                    "na2co3_mol": max(state.get("na2co3_mol", 0.0), 0.0),
                    "nahco3_mol": max(state.get("nahco3_mol", 0.0), 0.0),
                    "co2_excess_mol": max(state.get("co2_excess_mol", 0.0), 0.0),
                }
                consumed_cycle = accounting.get("co2_consumed_total_mol", 0.0)
                unconsumed_cycle = accounting.get("co2_unconsumed_mol", 0.0)
                cumulative_consumed_moles += consumed_cycle
                cumulative_unconsumed_moles = ledger_state.get("co2_excess_mol", 0.0)
                naoh_remaining = ledger_state["naoh_remaining_mol"]
                carbonate_remaining = ledger_state["na2co3_mol"]
                bicarbonate_remaining = ledger_state["nahco3_mol"]
                carbon_pool = (
                    carbonate_remaining
                    + bicarbonate_remaining
                    + ledger_state["co2_excess_mol"]
                )
                ledger_h2co3_fraction = (
                    ledger_state["co2_excess_mol"] / carbon_pool
                    if carbon_pool > 0
                    else None
                )
                regime_label = "naoh_to_carbonate"
                if naoh_remaining <= 1e-12:
                    regime_label = "carbonate_to_bicarbonate"
                    if carbonate_remaining <= PLANNING_PLATEAU_CARBONATE_THRESHOLD:
                        regime_label = "excess_co2"
                ph_after = state.get("ph")
                ph_after, model_species, ph_source, model_warning = (
                    _predict_planning_ph_for_model(
                        ph_model,
                        planning_context=planning_context,
                        cumulative_co2_moles=cumulative_moles,
                        cycle_index=idx,
                        fallback_ph=ph_after,
                    )
                )
                if model_warning:
                    entry_warnings.append(model_warning)
                if idx % 5 == 0:
                    na2co3_dissolved, na2co3_solid = _split_by_solubility_na2co3(
                        carbonate_remaining, solution_volume_l, temp_c
                    )
                    nahco3_dissolved, nahco3_solid = _split_by_solubility_nahco3(
                        bicarbonate_remaining, solution_volume_l, temp_c
                    )
                    print(
                        "[Planning dbg]"
                        f" cyc={idx:03d} total_g={cumulative_mass:.2f}"
                        f" eq={'Y' if cumulative_moles >= equivalence_moles - 1e-12 else 'N'}"
                        f" na2co3={carbonate_remaining:.4f}mol nahco3={bicarbonate_remaining:.4f}mol"
                        f" ph_aq={_safe_float(ph_after) or float('nan'):.3f}"
                        f" solids_g={na2co3_solid * SOL_MW_NA2CO3:.2f}/{nahco3_solid * SOL_MW_NAHCO3:.2f}",
                        flush=True,
                    )
                entry.update(
                    {
                        "co2_added_moles": moles_per_cycle,
                        "co2_added_mass_g": moles_per_cycle * SOL_MW_CO2,
                        "co2_consumed_moles": consumed_cycle,
                        "co2_consumed_mass_g": consumed_cycle * SOL_MW_CO2,
                        "co2_unconsumed_moles": unconsumed_cycle,
                        "co2_unconsumed_mass_g": unconsumed_cycle * SOL_MW_CO2,
                        "co2_consumed_to_carbonate_moles": accounting.get(
                            "co2_consumed_to_carbonate_mol", 0.0
                        ),
                        "co2_consumed_to_bicarbonate_moles": accounting.get(
                            "co2_consumed_to_bicarbonate_mol", 0.0
                        ),
                        "cumulative_co2_added_moles": cumulative_moles,
                        "cumulative_co2_added_mass_g": cumulative_mass,
                        "cumulative_co2_consumed_moles": cumulative_consumed_moles,
                        "cumulative_co2_consumed_mass_g": cumulative_consumed_moles
                        * SOL_MW_CO2,
                        "cumulative_co2_unconsumed_moles": cumulative_unconsumed_moles,
                        "cumulative_co2_unconsumed_mass_g": cumulative_unconsumed_moles
                        * SOL_MW_CO2,
                        "naoh_remaining_mol": naoh_remaining,
                        "na2co3_mol": carbonate_remaining,
                        "nahco3_mol": bicarbonate_remaining,
                        "co2_excess_mol": ledger_state["co2_excess_mol"],
                        "ph_after": ph_after,
                        "ph_source": ph_source,
                        "regime": regime_label,
                        "ledger_h2co3_fraction": ledger_h2co3_fraction,
                    }
                )
                if model_species:
                    entry["ph_model_species_m"] = model_species
            except Exception as exc:
                ph_after = None
                entry_warnings.append(f"Planning ledger update failed: {exc}")
                entry.setdefault("co2_added_moles", moles_per_cycle)
                entry.setdefault("co2_added_mass_g", moles_per_cycle * SOL_MW_CO2)
                entry.setdefault("cumulative_co2_added_moles", cumulative_moles)
                entry.setdefault("cumulative_co2_added_mass_g", cumulative_mass)
                entry.setdefault("co2_consumed_moles", 0.0)
                entry.setdefault("co2_consumed_mass_g", 0.0)
                entry.setdefault("co2_unconsumed_moles", cumulative_unconsumed_moles)
                entry.setdefault(
                    "co2_unconsumed_mass_g", cumulative_unconsumed_moles * SOL_MW_CO2
                )
                entry.setdefault(
                    "cumulative_co2_consumed_moles", cumulative_consumed_moles
                )
                entry.setdefault(
                    "cumulative_co2_consumed_mass_g",
                    cumulative_consumed_moles * SOL_MW_CO2,
                )
                entry.setdefault(
                    "cumulative_co2_unconsumed_moles", cumulative_unconsumed_moles
                )
                entry.setdefault(
                    "cumulative_co2_unconsumed_mass_g",
                    cumulative_unconsumed_moles * SOL_MW_CO2,
                )
                ph_after, model_species, ph_source, model_warning = (
                    _predict_planning_ph_for_model(
                        ph_model,
                        planning_context=planning_context,
                        cumulative_co2_moles=cumulative_moles,
                        cycle_index=idx,
                        fallback_ph=ph_after,
                    )
                )
                if model_warning:
                    entry_warnings.append(model_warning)
                entry.setdefault("ph_after", ph_after)
                if ph_source:
                    entry.setdefault("ph_source", ph_source)
                if model_species:
                    entry["ph_model_species_m"] = model_species
            plateau_note: Optional[str] = None
            carbonate_remaining = max(ledger_state.get("na2co3_mol", 0.0), 0.0)
            if (
                ph_after is not None
                and math.isfinite(ph_after)
                and cumulative_moles >= equivalence_moles
                and carbonate_remaining > PLANNING_PLATEAU_CARBONATE_THRESHOLD
            ):
                recent_post_eq_ph.append(ph_after)
                if len(recent_post_eq_ph) > PLANNING_PLATEAU_WINDOW:
                    recent_post_eq_ph.pop(0)
                if len(recent_post_eq_ph) == PLANNING_PLATEAU_WINDOW:
                    drop = recent_post_eq_ph[0] - recent_post_eq_ph[-1]
                    if drop < PLANNING_MIN_PH_DROP:
                        plateau_note = (
                            "Planning plateau detected post-equivalence "
                            f"(ΔpH {drop:.3f} over {PLANNING_PLATEAU_WINDOW} cycles)."
                        )
            if (
                ph_after is not None
                and math.isfinite(ph_after)
                and carbonate_remaining <= PLANNING_PLATEAU_CARBONATE_THRESHOLD
                and previous_ph is not None
            ):
                tail_delta = abs(ph_after - previous_ph)
                if tail_delta < 0.005:
                    note = "Carbonate depleted and pH tail is flat; continuing until pH/CO₂ caps."
                    plateau_note = f"{plateau_note} {note}" if plateau_note else note
            if plateau_note:
                entry_warnings.append(plateau_note)
                projection_warning = (
                    plateau_note
                    if projection_warning is None
                    else f"{projection_warning} {plateau_note}"
                )

            if (
                ph_after is not None
                and math.isfinite(ph_after)
                and ph_after <= stop_ph + 1e-12
            ):
                stop_reason = (
                    f"Planning stop: pH <= {stop_ph:.2f} reached after {idx} cycle(s)."
                )
            elif cumulative_mass >= stop_added_g - 1e-12:
                stop_reason = (
                    f"Planning stop: cumulative CO2 added cap reached "
                    f"({cumulative_mass:.2f} g >= {stop_added_g:.2f} g)."
                )
            if entry_warnings:
                entry["warnings"] = entry_warnings
            cycle_entries.append(entry)
            if ph_after is not None and math.isfinite(ph_after):
                recent_ph_values.append(ph_after)
            if stop_reason:
                break
        if len(cycle_entries) >= MAX_PLANNING_SYNTH_CYCLES and stop_reason is None:
            projection_warning = (
                "Planning projection hit the safety cap before reaching the target pH (~8); "
                "check delta-P, headspace setpoint, NaOH basis, and volume assumptions."
            )
        if stop_reason and projection_warning is None:
            projection_warning = stop_reason
        if not cycle_entries:
            return None
        return {
            "cycle_transfer": cycle_entries,
            "total_moles_vdw": cumulative_moles,
            "total_moles_ideal": cumulative_moles,
            "gas_molar_mass": SOL_MW_CO2,
            "timestamp": datetime.now().isoformat(),
            "projection_warning": projection_warning,
            "reference_ledgers": reference_ledgers,
        }

    def _build_planning_reference_trace_for_analysis(
        self, form_data: Dict[str, Any], solver_inputs: SolubilitySolverInputs
    ) -> Dict[str, Any]:
        """Build planning reference trace for analysis.
        Used to assemble planning reference trace for analysis during UI or plot setup."""
        analysis_spec_key, analysis_ph_key, analysis_use_same = (
            self._resolve_workflow_model_keys("Analysis", form_data)
        )
        planning_form = dict(form_data or {})
        planning_form["workflow_key"] = "Planning"
        planning_form["planning_spec_model_key"] = analysis_spec_key
        planning_form["planning_ph_model_key"] = analysis_ph_key
        planning_form["planning_use_same_model"] = analysis_use_same
        reaction_naoh_mass = planning_form.get("reaction_naoh_mass")
        if not planning_form.get("mass_naoh_g") and reaction_naoh_mass:
            planning_form["mass_naoh_g"] = reaction_naoh_mass
        if not planning_form.get("naoh_mass_basis") and reaction_naoh_mass:
            planning_form["naoh_mass_basis"] = reaction_naoh_mass
        if planning_form.get("planning_initial_naoh_mol") in (
            None,
            0,
        ) and planning_form.get("mass_naoh_g"):
            try:
                planning_form["planning_initial_naoh_mol"] = (
                    float(planning_form["mass_naoh_g"]) / SOL_MW_NAOH
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        canonical_inputs = self._canonicalize_planning_inputs(planning_form)
        initial_naoh_mol = canonical_inputs.get("planning_initial_naoh_mol")
        equivalence_co2_g = (
            (initial_naoh_mol / 2.0) * SOL_MW_CO2
            if initial_naoh_mol is not None and initial_naoh_mol > 0
            else None
        )
        warning: Optional[str] = None
        try:
            payload = self._generate_planning_cycle_payload(
                planning_form, solver_inputs
            )
        except Exception as exc:
            payload = None
            warning = str(exc)
        if payload is None:
            payload = self._get_cycle_payload_for_workflow("Planning")
            if payload is None:
                return {
                    "warning": warning
                    or "Unable to generate planning reference curve.",
                }
            if warning is None:
                warning = (
                    "Planning reference curve unavailable; using last Planning payload."
                )
        cycles = payload.get("cycle_transfer") or []
        if not cycles:
            return {
                "warning": warning
                or "Planning reference curve unavailable (empty payload).",
            }
        temp_c = solver_inputs.params.temperature_c
        solution_volume_l = getattr(solver_inputs.params, "solution_volume_l", None)
        try:
            if solution_volume_l is None:
                solution_volume_l = solver_inputs.params.volume_l()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if solution_volume_l is None or solution_volume_l <= 0:
            solution_volume_l = 1.0
        planning_context = {
            "naoh_mass_g": _safe_float(planning_form.get("mass_naoh_g"))
            or (initial_naoh_mol * SOL_MW_NAOH if initial_naoh_mol else None),
            "water_mass_g": solver_inputs.params.water_mass_g,
            "solution_volume_l": solution_volume_l,
            "temperature_c": temp_c,
            "headspace_volume_l": canonical_inputs.get("planning_headspace_volume_l"),
            "planning_headspace_pressure_high_psi": canonical_inputs.get(
                "planning_headspace_pressure_high_psi"
            ),
            "planning_cycle_delta_p_psi": canonical_inputs.get(
                "planning_cycle_delta_p_psi"
            ),
            "planning_cycle_co2_g": canonical_inputs.get("planning_cycle_co2_g"),
        }
        try:
            ph_model = get_speciation_model(analysis_ph_key)
        except Exception:
            ph_model = get_speciation_model(None)
        x_series: List[float] = []
        ph_series: List[Optional[float]] = []
        # Iterate over indexed elements from cycles, start=1 to apply the per-item logic.
        for idx, entry in enumerate(cycles, start=1):
            x_val = _safe_float(entry.get("cumulative_co2_added_mass_g"))
            if x_val is None:
                x_val = _safe_float(entry.get("cumulative_co2_mass_g"))
            if x_val is None:
                x_val = _safe_float(entry.get("cumulative_co2_added_g"))
            if x_val is None:
                x_val = _safe_float(entry.get("co2_g"))
            if x_val is None or not math.isfinite(x_val):
                continue
            fallback_ph = entry.get("ph_after")
            if fallback_ph is None:
                fallback_ph = entry.get("solution_ph")
            ph_value, _species, _source, _warn = _predict_planning_ph_for_model(
                ph_model,
                planning_context=planning_context,
                cumulative_co2_moles=x_val / SOL_MW_CO2,
                cycle_index=idx,
                fallback_ph=fallback_ph,
            )
            x_series.append(float(x_val))
            ph_series.append(ph_value)
        if not x_series:
            return {
                "warning": warning
                or "Planning reference curve unavailable (no valid CO2 values).",
            }
        final_co2_g = x_series[-1]
        eq_index = None
        if equivalence_co2_g is not None:
            # Iterate over indexed elements from x_series to apply the per-item logic.
            for idx, value in enumerate(x_series):
                if value >= equivalence_co2_g:
                    eq_index = idx
                    break
        trace = {
            "x_co2_g_series": x_series,
            "ph_series": ph_series,
            "final_co2_g": final_co2_g,
            "equivalence_co2_g": equivalence_co2_g,
            "equivalence_index": eq_index,
        }
        if warning:
            trace["warning"] = warning
        return trace

    def _schedule_planning_projection(
        self,
        form_data: Dict[str, Any],
        solver_inputs: SolubilitySolverInputs,
    ) -> None:
        """Schedule planning projection.
        Used to queue planning projection without blocking the UI."""
        status_var = getattr(self, "_sol_cycle_status_var", None)
        if status_var is not None:
            status_var.set("Running planning projection...")

        def _worker() -> None:
            """Perform worker.
            Used to keep the workflow logic localized and testable."""
            try:
                payload = self._generate_planning_cycle_payload(
                    form_data, solver_inputs
                )
            except Exception as exc:
                self.after(
                    0,
                    lambda exc=exc: self._handle_planning_projection_result(
                        None, exc, form_data
                    ),
                )
                return
            self.after(
                0,
                lambda: self._handle_planning_projection_result(
                    payload, None, form_data
                ),
            )

        threading.Thread(target=_worker, daemon=True).start()

    def _handle_planning_projection_result(
        self,
        payload: Optional[Dict[str, Any]],
        error: Optional[BaseException],
        form_data: Dict[str, Any],
    ) -> None:
        """Handle planning projection result.
        Purpose: Apply Planning projection results to the UI and cycle timeline.
        Why: Update status, payload, and downstream plots after the async projection.
        Inputs:
            payload (Optional[Dict[str, Any]]): Projection payload, if available.
            error (Optional[BaseException]): Exception raised by the projection, if any.
            form_data (Dict[str, Any]): Planning form data used for the run.
        Outputs:
            None.
        Side Effects:
            - Updates status messages, payload state, and cycle simulations.
            - Restores cached Planning inputs to prevent default resets.
        Exceptions:
            - Best-effort; handles UI update errors without raising.
        """
        status_var = getattr(self, "_sol_cycle_status_var", None)
        if error is not None:
            if status_var is not None:
                status_var.set(f"Planning projection failed: {error}")
            try:
                messagebox.showerror(
                    "Planning Projection", f"Planning projection failed:\n{error}"
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._restore_planning_inputs()
            return
        if payload is None:
            if status_var is not None:
                status_var.set("Planning projection unavailable.")
            self._restore_planning_inputs()
            return
        projection_warning = payload.get("projection_warning")
        self._cycle_last_transfer_payload = payload
        self._apply_cycle_payload_to_solubility(
            payload=payload,
            notify=False,
            run_simulation=False,
            workflow_key=form_data.get("workflow_key"),
        )
        if projection_warning:
            if status_var is not None:
                status_var.set(projection_warning)
            try:
                messagebox.showwarning("Planning Projection", projection_warning)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._run_cycle_solubility_simulation(
            payload=payload, notify=False, workflow_key=form_data.get("workflow_key")
        )
        self._restore_planning_inputs()

    def _ensure_solubility_loading_overlay(self) -> None:
        """Ensure solubility loading overlay exists.
        Purpose: Create the overlay widgets used for solubility job feedback.
        Why: The Advanced Speciation tab needs a visible splash during heavy work.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            - Creates and stores overlay widgets on the solubility tab.
            - Initializes overlay label/progress bar references on self.
        Exceptions:
            - Best-effort; returns early if the tab or widgets are unavailable.
        """
        overlay = getattr(self, "_sol_loading_overlay", None)
        if overlay is not None:
            try:
                if overlay.winfo_exists():
                    return
            except Exception:
                # Best-effort guard; rebuild the overlay if state is unknown.
                pass
        frame = getattr(self, "tab_solubility_new", None)
        if frame is None:
            return
        try:
            base_bg = frame.cget("background")
        except Exception:
            base_bg = "#f2f2f2"
        overlay = tk.Frame(frame, background=base_bg)
        label = tk.Label(
            overlay,
            text="Running speciation...",
            background=base_bg,
        )
        label.pack(pady=(18, 6))
        bar = ttk.Progressbar(overlay, mode="indeterminate", length=180)
        bar.pack(pady=(0, 16))
        overlay.place(relx=0.0, rely=0.0, relwidth=1.0, relheight=1.0)
        overlay.place_forget()
        self._sol_loading_overlay = overlay
        self._sol_loading_label = label
        self._sol_loading_bar = bar

    def _show_solubility_loading_overlay(self, message: str) -> None:
        """Show the solubility loading overlay.
        Purpose: Display a blocking splash while solubility jobs run.
        Why: Make background solver work visible and prevent accidental edits.
        Inputs:
            message (str): Status text to display on the overlay.
        Outputs:
            None.
        Side Effects:
            - Displays overlay widgets and starts the indeterminate progress bar.
        Exceptions:
            - Best-effort; ignores UI failures to avoid interrupting the workflow.
        """
        self._ensure_solubility_loading_overlay()
        overlay = getattr(self, "_sol_loading_overlay", None)
        label = getattr(self, "_sol_loading_label", None)
        bar = getattr(self, "_sol_loading_bar", None)
        if overlay is None:
            return
        try:
            if label is not None:
                label.configure(text=str(message))
            overlay.place(relx=0.0, rely=0.0, relwidth=1.0, relheight=1.0)
            overlay.lift()
            if bar is not None:
                bar.start(12)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _hide_solubility_loading_overlay(self, *, defer: bool = True) -> None:
        """Hide the solubility loading overlay.
        Purpose: Remove the splash after solver UI updates finish.
        Why: Ensure the overlay is cleared only after main-thread updates complete.
        Inputs:
            defer (bool): When True, hide via after_idle to wait for UI updates.
        Outputs:
            None.
        Side Effects:
            - Stops the indeterminate progress bar and hides the overlay frame.
        Exceptions:
            - Best-effort; ignores UI failures to avoid interrupting the workflow.
        """

        def _do_hide() -> None:
            """Hide overlay widgets.
            Purpose: Centralize teardown of overlay widgets after a solver run.
            Why: Keeps the overlay cleanup consistent across success/error paths.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                - Stops the progress bar and removes the overlay from view.
            Exceptions:
                - Best-effort; ignores UI failures to avoid interruption.
            """
            overlay = getattr(self, "_sol_loading_overlay", None)
            bar = getattr(self, "_sol_loading_bar", None)
            if overlay is None:
                return
            try:
                if bar is not None:
                    bar.stop()
                overlay.place_forget()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        if defer:
            # Defer hide so UI updates from the solver callback complete first.
            self.after_idle(_do_hide)
        else:
            _do_hide()

    def _submit_solubility_job(
        self,
        worker: Callable[[], Any],
        on_ok: Callable[[Any], None] | None,
        on_err: Callable[[BaseException], None] | None,
    ) -> None:
        """Submit a solubility job to a background worker.
        Purpose: Run heavy solubility calculations off the Tk main thread.
        Why: Keep the Advanced Speciation tab responsive during solver work.
        Inputs:
            worker (Callable[[], Any]): Background callable returning a solver result.
            on_ok (Callable[[Any], None] | None): Success callback for main thread.
            on_err (Callable[[BaseException], None] | None): Error callback for main
                thread.
        Outputs:
            None.
        Side Effects:
            - Uses TkTaskRunner when available or falls back to threading.Thread.
            - Schedules callbacks via Tk `after` on the main thread.
        Exceptions:
            - Worker exceptions are routed to on_err; no exception is raised here.
        """
        runner = getattr(self, "_task_runner", None)
        if runner is not None and hasattr(runner, "submit"):
            runner.submit("solubility_solver", worker, on_ok, on_err)
            return

        def _thread_worker() -> None:
            """Run solubility worker fallback.
            Purpose: Execute the solver in a plain thread when no task runner exists.
            Why: Provide a safe fallback that preserves UI responsiveness.
            Inputs:
                None.
            Outputs:
                None.
            Side Effects:
                - Executes worker in a background thread.
                - Enqueues UI callbacks via `after` on the Tk main thread.
            Exceptions:
                - Captures worker exceptions and routes them to on_err.
            """
            try:
                result = worker()
            except Exception as exc:
                if on_err is not None:
                    self.after(0, lambda exc=exc: on_err(exc))
                return
            if on_ok is not None:
                self.after(0, lambda result=result: on_ok(result))

        # Fallback: run the solver worker in a daemon thread and marshal UI updates.
        threading.Thread(target=_thread_worker, daemon=True).start()

    def _run_solubility_analysis(self) -> None:
        """Run the solubility analysis workflow asynchronously.
        Purpose: Orchestrate solver execution, projection scheduling, and UI updates.
        Why: Keep the Advanced Speciation tab responsive while running heavy solvers.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            - Updates stored form data, solver state, and summary outputs.
            - Schedules background solver execution and UI callbacks.
            - Updates status messages and overlay visibility.
        Exceptions:
            - Best-effort; handles input errors without raising.
        """
        form_data: dict[str, Any] = {}
        try:
            form_data = self._collect_solubility_form_data()
        except Exception as exc:
            self._update_solubility_summary(
                f"Advanced Solubility Module error: {exc}", structured=None
            )
            try:
                messagebox.showerror(
                    "Advanced Solubility Module", f"Unable to run analysis:\\n{exc}"
                )
            except Exception:
                pass
            return
        self._sol_last_form_data = form_data
        solver_inputs = self._prepare_solver_inputs(form_data)
        mode_context = self._build_sol_mode_context(
            solver_inputs.params,
            form_data,
            workflow_key=form_data.get("workflow_key"),
        )
        if form_data.get("workflow_key") == "Planning":
            self._schedule_planning_projection(form_data, solver_inputs)
        enabled_axes = self._read_sensitivity_axes()
        tracking_entries = list(getattr(self, "_sol_tracking_entries", []))
        cycle_summary = (
            self._get_cycle_result_for_workflow(form_data.get("workflow_key")) or {}
        ).copy()
        capture_math = bool(
            getattr(self, "_sol_show_math_var", tk.BooleanVar(value=False)).get()
        )
        default_guidance = getattr(
            self,
            "_sol_reaction_default_msg",
            "Enter NaOH/CO₂ inputs to activate the guidance overlay.",
        )
        model_key = solver_inputs.model_key
        settings = getattr(self, "settings", {})
        self._sol_model_key = model_key
        if isinstance(settings, dict):
            settings["solubility_model_key"] = model_key
        model = get_speciation_model(model_key)
        solver_inputs_snapshot = solver_inputs
        enabled_axes_snapshot = dict(enabled_axes)
        tracking_entries_snapshot = copy.deepcopy(tracking_entries)
        cycle_summary_snapshot = copy.deepcopy(cycle_summary)
        mode_context_snapshot = dict(mode_context)
        default_guidance_snapshot = str(default_guidance)
        capture_math_snapshot = bool(capture_math)

        # Solver pipeline runs in a background worker to keep the UI responsive
        # while capturing structured outputs for plots, summaries, and exports.
        # Closure captures _run_solubility_analysis state for callback wiring,
        # kept nested to scope the handler, and invoked by bindings set in
        # _run_solubility_analysis.
        def _worker():
            """Perform worker.
            Used to keep the workflow logic localized and testable."""
            return self._execute_solubility_job(
                solver_inputs_snapshot,
                model,
                solver_inputs_snapshot.model_options,
                enabled_axes_snapshot,
                tracking_entries_snapshot,
                cycle_summary_snapshot,
                mode_context_snapshot,
                default_guidance_snapshot,
                capture_math_snapshot,
            )

        # Closure captures _run_solubility_analysis state for callback wiring,
        # kept nested to scope the handler, and invoked by bindings set in
        # _run_solubility_analysis.
        def _on_ok(result):
            """Handle ok.
            Used as an event callback for ok."""
            summary, payload, co2_guidance, last_result = result
            self._set_solver_progress(False)
            self._sol_last_result = last_result
            guidance_var = getattr(self, "_sol_new_reaction_summary_var", None)
            if guidance_var is not None:
                guidance_var.set(co2_guidance)
            self._sol_math_sections = payload.math_sections
            self._update_solubility_summary(summary, structured=payload.to_dict())

        # Closure captures _run_solubility_analysis state for callback wiring,
        # kept nested to scope the handler, and invoked by bindings set in
        # _run_solubility_analysis.
        def _on_err(exc):
            """Handle err.
            Used as an event callback for err."""
            self._set_solver_progress(False)
            self._update_solubility_summary(
                f"Advanced Solubility Module error: {exc}", structured=None
            )
            try:
                messagebox.showerror(
                    "Advanced Solubility Module", f"Unable to run analysis:\\n{exc}"
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Submit async job so UI progress and callbacks can update when ready.
        self._set_solver_progress(True)
        self._submit_solubility_job(_worker, _on_ok, _on_err)

    def _prepare_solver_inputs(
        self, form_data: Dict[str, Any]
    ) -> SolubilitySolverInputs:
        """Prepare solver inputs.
        Used to assemble solver inputs inputs for downstream calculations."""
        return SolubilitySolverInputs(
            params=form_data["params"],
            forced_target=form_data.get("forced_target"),
            sweep_low=form_data.get("sweep_low", SOL_PH_SWEEP_DEFAULT[0]),
            sweep_high=form_data.get("sweep_high", SOL_PH_SWEEP_DEFAULT[1]),
            sweep_steps=form_data.get("sweep_steps", SOL_PH_SWEEP_DEFAULT[2]),
            reaction_naoh_mass=form_data.get("reaction_naoh_mass"),
            reaction_solution_volume=form_data.get("reaction_solution_volume"),
            reaction_co2_g=form_data.get("reaction_co2_g"),
            reaction_final_ph=form_data.get("reaction_final_ph"),
            reaction_slurry_ph=form_data.get("reaction_slurry_ph"),
            reaction_target_ph=form_data.get("reaction_target_ph"),
            diagnostic_data=form_data.get("diagnostic_data"),
            mode_key=form_data.get("mode", SOL_DEFAULT_SIM_MODE),
            model_key=form_data.get("model_key") or DEFAULT_SPEC_MODEL_KEY,
            model_options=form_data.get("model_options"),
            guide_key=form_data.get("guide_key", SOL_DEFAULT_SIM_MODE),
            workflow_key=form_data.get(
                "workflow_key", self._current_solubility_workflow()
            ),
            assumed_solution_volume_l=form_data.get("assumed_solution_volume_l"),
            failing_ph=form_data.get("failing_ph"),
            solvent_basis=form_data.get("solvent_basis"),
            solvent_basis_value=form_data.get("solvent_basis_value"),
        )

    def _read_sensitivity_axes(self) -> Dict[str, bool]:
        """Perform read sensitivity axes.
        Used to keep the workflow logic localized and testable."""
        return {
            "mass": bool(getattr(self, "_sol_sens_mass_var", tk.BooleanVar()).get()),
            "solvent": bool(
                getattr(self, "_sol_sens_solvent_var", tk.BooleanVar()).get()
            ),
            "temperature": bool(
                getattr(self, "_sol_sens_temp_var", tk.BooleanVar()).get()
            ),
        }

    def _set_solver_progress(self, active: bool) -> None:
        """Set solver progress.
        Purpose: Update solver status messaging and loading overlay state.
        Why: Provide clear feedback during long-running solubility calculations.
        Inputs:
            active (bool): True while solver work is running; False when complete.
        Outputs:
            None.
        Side Effects:
            - Updates the solubility context label.
            - Shows or hides the solubility loading overlay.
        Exceptions:
            - Best-effort; ignores UI update failures.
        """
        label_var = getattr(self, "_sol_context_label_var", None)
        if active:
            if label_var is not None:
                label_var.set("Solving speciation - please wait...")
            self._show_solubility_loading_overlay("Running speciation...")
            return
        if label_var is not None:
            workflow_meta = SOL_WORKFLOW_TEMPLATES.get(
                self._current_solubility_workflow(), {}
            )
            label_var.set(workflow_meta.get("label", "Advanced Solubility"))
        self._hide_solubility_loading_overlay(defer=True)

    def _handle_solver_future_result(
        self, future, executor: ThreadPoolExecutor
    ) -> None:
        """Handle solver future result.
        Used as an event callback for solver future result."""
        self._set_solver_progress(False)
        try:
            summary, payload, co2_guidance, last_result = future.result()
        except Exception as exc:
            executor.shutdown(wait=False)
            self._update_solubility_summary(
                f"Advanced Solubility Module error: {exc}", structured=None
            )
            try:
                messagebox.showerror(
                    "Advanced Solubility Module", f"Unable to run analysis:\\n{exc}"
                )
            except Exception:
                pass
            return
        executor.shutdown(wait=False)
        self._sol_last_result = last_result
        guidance_var = getattr(self, "_sol_new_reaction_summary_var", None)
        if guidance_var is not None:
            guidance_var.set(co2_guidance)
        self._sol_math_sections = payload.math_sections
        self._update_solubility_summary(summary, structured=payload.to_dict())

    def _execute_solubility_job(
        self,
        solver_inputs: SolubilitySolverInputs,
        model: SpeciationModel,
        model_options: Optional[ModelOptions],
        enabled_axes: Dict[str, bool],
        tracking_entries: List[Dict[str, Any]],
        cycle_summary: Dict[str, Any],
        mode_context: Dict[str, str],
        default_guidance: str,
        capture_math: bool,
    ) -> Tuple[
        str,
        SolubilityStructuredPayload,
        str,
        SolubilitySpeciationResult,
    ]:
        """Execute the solubility job and coordinate results.

        Purpose:
            Run the advanced speciation workflow end-to-end for a solver request.
        Why:
            Centralizes speciation, calibration, sweeps, and guidance assembly.
        Args:
            solver_inputs: Prepared inputs for the solver run.
            model: Speciation model implementation to use.
            model_options: Optional model options overrides.
            enabled_axes: Sensitivity axes enable flags.
            tracking_entries: Per-step tracking entries for output assembly.
            cycle_summary: Cycle summary payload for guidance.
            mode_context: Mode metadata for summary rendering.
            default_guidance: Fallback guidance text.
            capture_math: Enable math logger capture when True.
        Returns:
            Tuple of summary text, structured payload, guidance text, and result.
        Side Effects:
            Records debug/perf output and updates math logger sections.
        Exceptions:
            Exceptions propagate to the caller for worker handling.
        """
        model_key = getattr(model, "key", None)
        self._dbg(
            "speciation.engine",
            "Speciation job start mode=%s model=%s capture_math=%s",
            solver_inputs.mode_key,
            model_key,
            capture_math,
        )
        with self._perf_time("speciation.engine", "speciation_job"):
            math_logger = SolubilityMathLogger(enabled=capture_math)
            params = solver_inputs.params
            result = self._solve_base_speciation(
                model, params, model_options, math_logger
            )
            (
                result,
                params,
                measurement_warning,
                closed_system_result,
                measurement_scale,
            ) = self._apply_measurement_calibration(
                model,
                solver_inputs,
                result,
                params,
                math_logger,
                model_options,
            )
            forced_result, forced_error = self._solve_forced_ph(
                model, params, solver_inputs, math_logger, model_options
            )
            sweep_model = model
            sweep_params = params
            if solver_inputs.mode_key == "contaminated_bicarb_diagnostic":
                inventory_mol = (
                    params.total_inorganic_carbon_mol
                    if params.total_inorganic_carbon_mol is not None
                    else params.total_moles()
                )
                sweep_params = replace(
                    params,
                    mass_na_hco3_g=inventory_mol * SOL_MW_NAHCO3,
                    headspace_pco2_atm=None,
                    headspace_kh_m_per_atm=None,
                )
                try:
                    sweep_model = get_speciation_model("aqion_closed")
                except KeyError:
                    sweep_model = model
            sweep_data = sweep_model.generate_ph_sweep(
                sweep_params,
                solver_inputs.sweep_low,
                solver_inputs.sweep_high,
                solver_inputs.sweep_steps,
                math_logger=math_logger,
                model_options=model_options,
            )
            sensitivity_rows = model.generate_sensitivity_rows(
                params,
                enabled_axes,
                math_logger=math_logger,
                model_options=model_options,
            )
            reproc_guidance: Optional[Dict[str, Any]] = None
            measured_headspace_pressure_psi, measured_headspace_pco2_atm = (
                _timeline_headspace_measurement(cycle_summary.get("timeline") or [])
            )
            if solver_inputs.mode_key == "contaminated_bicarb_diagnostic":
                reaction_guidance = analyze_contaminated_bicarb_diagnostic(
                    params=params,
                    result=result,
                    forced_result=forced_result,
                    diagnostic=solver_inputs.diagnostic_data,
                    math_logger=math_logger,
                )
                reproc_guidance = analyze_reprocessing_workflow(
                    params=params,
                    result=result,
                    forced_result=forced_result,
                    failing_ph=solver_inputs.failing_ph,
                    forced_ph=(
                        solver_inputs.forced_target
                        if solver_inputs.forced_target is not None
                        else solver_inputs.reaction_target_ph
                    ),
                    solvent_basis=solver_inputs.solvent_basis,
                    solvent_basis_value=solver_inputs.solvent_basis_value,
                    diagnostic_data=solver_inputs.diagnostic_data,
                    math_logger=math_logger,
                    model_options=model_options,
                    measured_headspace_pco2_atm=measured_headspace_pco2_atm,
                    measured_headspace_pressure_psi=measured_headspace_pressure_psi,
                )
            else:
                reaction_guidance = analyze_bicarbonate_reaction(
                    naoh_mass_g=solver_inputs.reaction_naoh_mass,
                    co2_charged_g=solver_inputs.reaction_co2_g,
                    solution_volume_l=solver_inputs.reaction_solution_volume,
                    measured_ph=solver_inputs.reaction_final_ph,
                    slurry_ph=solver_inputs.reaction_slurry_ph,
                    target_ph=solver_inputs.reaction_target_ph,
                    temperature_c=params.temperature_c,
                    use_temp_adjusted_constants=params.use_temperature_adjusted_constants,
                    ionic_strength_cap=params.ionic_strength_cap,
                    math_logger=math_logger,
                )
        if reproc_guidance:
            reaction_guidance = reaction_guidance or {}
            summary_parts: List[str] = []
            reproc_summary = reproc_guidance.get("summary")
            if reproc_summary:
                summary_parts.append(reproc_summary)
            if reaction_guidance.get("summary"):
                summary_parts.append(reaction_guidance["summary"])
            combined_summary = "\n\n".join(
                part for part in summary_parts if part
            ).strip()
            if combined_summary:
                reaction_guidance["summary"] = combined_summary
            reaction_guidance.setdefault("warnings", [])
            reaction_guidance["warnings"].extend(reproc_guidance.get("warnings") or [])
            reaction_guidance.setdefault("notes", [])
            reaction_guidance["notes"].extend(reproc_guidance.get("notes") or [])
            if reproc_guidance.get("math_lines"):
                reaction_guidance.setdefault("math_lines", [])
                reaction_guidance["math_lines"].extend(reproc_guidance["math_lines"])
            if reproc_guidance.get("recommended_co2_g") is not None:
                reaction_guidance["recommended_co2_g"] = reproc_guidance[
                    "recommended_co2_g"
                ]
            if reproc_guidance.get("target_ph") is not None:
                reaction_guidance["target_ph"] = reproc_guidance["target_ph"]
            reaction_guidance["reprocessing_workflow"] = reproc_guidance
        planner_context = self._build_planner_context(
            solver_inputs,
            cycle_summary,
            reaction_guidance=reaction_guidance,
        )
        chart_data = self._generate_chart_data(
            result,
            forced_result=forced_result,
            workflow_key=solver_inputs.workflow_key,
        )
        _log_reaction_tracker_math(math_logger, tracking_entries)
        _log_cycle_timeline_math(math_logger, cycle_summary)
        math_sections = math_logger.export_sections()
        math_preview_lines = math_logger.preview_lines()
        payload = self._build_structured_payload(
            solver_inputs=solver_inputs,
            result=result,
            forced_result=forced_result,
            closed_system_result=closed_system_result,
            measurement_warning=measurement_warning,
            measurement_scale=measurement_scale,
            reaction_guidance=reaction_guidance,
            sweep_data=sweep_data,
            sensitivity_rows=sensitivity_rows,
            planner_context=planner_context,
            tracking_entries=tracking_entries,
            cycle_summary=cycle_summary,
            mode_context=mode_context,
            chart_data=chart_data,
            math_sections=math_sections,
            math_preview_lines=math_preview_lines,
            forced_error=forced_error,
        )
        summary = format_solubility_summary(
            params,
            result,
            forced_result=forced_result,
            forced_error=forced_error,
            sweep_summary=sweep_data,
            sensitivity_rows=sensitivity_rows,
            mode_context=mode_context,
        )
        co2_guidance = (
            reaction_guidance.get("summary")
            if reaction_guidance and reaction_guidance.get("summary")
            else default_guidance
        )

        payload.co2_guidance = co2_guidance
        summary = summary + "\n\n=== CO2 Dosing Guidance ===\n" + co2_guidance
        if planner_context:
            summary += "\n\nPlan inputs:\n" + "\n".join(planner_context)
        self._dbg(
            "speciation.results",
            "Speciation job done summary_len=%s forced_error=%s",
            len(summary),
            forced_error,
        )
        return summary, payload, co2_guidance, result

    def _solve_base_speciation(
        self,
        model: SpeciationModel,
        params: SolubilityInputs,
        model_options: Optional[ModelOptions],
        math_logger: SolubilityMathLogger,
    ) -> SolubilitySpeciationResult:
        """Solve base speciation with the selected model.

        Purpose:
            Execute the core speciation solver for the current inputs.
        Why:
            Provides the baseline speciation result used by downstream steps.
        Args:
            model: Speciation model implementation to use.
            params: Solubility input parameters.
            model_options: Optional model options overrides.
            math_logger: Math logger for optional step capture.
        Returns:
            SolubilitySpeciationResult from the model solver.
        Side Effects:
            Records perf timing and debug logs when enabled.
        Exceptions:
            Exceptions propagate to the caller after being logged.
        """
        model_key = getattr(model, "key", None)
        self._dbg(
            "speciation.solver",
            "Base speciation solve start model=%s",
            model_key,
        )
        try:
            with self._perf_time("speciation.solver", "base_speciation"):
                return model.solve(
                    params,
                    model_options=model_options,
                    math_logger=math_logger,
                    math_section="Speciation",
                )
        except Exception as exc:
            self._dbg_exc("speciation.solver", "Base speciation solve failed", exc)
            raise

    def _apply_measurement_calibration(
        self,
        model: SpeciationModel,
        solver_inputs: SolubilitySolverInputs,
        result: SolubilitySpeciationResult,
        params: SolubilityInputs,
        math_logger: SolubilityMathLogger,
        model_options: Optional[ModelOptions],
    ) -> Tuple[
        SolubilitySpeciationResult,
        SolubilityInputs,
        Optional[str],
        Optional[SolubilitySpeciationResult],
        Optional[float],
    ]:
        """Apply measurement calibration when diagnostics are provided.

        Purpose:
            Adjust speciation using measured slurry pH diagnostics.
        Why:
            Aligns model output with measured conditions for diagnostics.
        Args:
            model: Speciation model implementation to use.
            solver_inputs: Solver inputs including diagnostic payloads.
            result: Current speciation result to adjust.
            params: Current solubility parameters.
            math_logger: Math logger for optional step capture.
            model_options: Optional model options overrides.
        Returns:
            Tuple of (result, params, warning, closed_system_result, scale).
        Side Effects:
            Records perf timing and debug logs when enabled.
        Exceptions:
            Exceptions are caught and returned as warnings.
        """
        measurement_warning: Optional[str] = None
        closed_system_result: Optional[SolubilitySpeciationResult] = None
        measurement_scale: Optional[float] = None
        diagnostic = solver_inputs.diagnostic_data
        if (
            solver_inputs.mode_key == "contaminated_bicarb_diagnostic"
            and diagnostic
            and diagnostic.get("slurry_ph") is not None
        ):
            self._dbg(
                "speciation.chemistry",
                "Measurement calibration start mode=%s",
                solver_inputs.mode_key,
            )
            try:
                try:
                    closed_model = get_speciation_model("aqion_closed")
                    closed_system_result = closed_model.solve(
                        params,
                        model_options=model_options,
                        math_logger=None,
                        math_section="Closed System (Aqion)",
                    )
                except Exception:
                    closed_system_result = result
                with self._perf_time(
                    "speciation.chemistry", "measurement_calibration"
                ):
                    measurement_result, measurement_params, measurement_scale = (
                        solubility_speciation_calibrated_to_measurement(
                            params,
                            float(diagnostic.get("slurry_ph")),
                            measured_alkalinity_meq=diagnostic.get(
                                "slurry_alk_meq_l"
                            ),
                            math_logger=math_logger,
                            model_options=model_options,
                        )
                    )
                result = measurement_result
                params = measurement_params
            except Exception as exc:
                measurement_warning = (
                    f"Measurement-calibrated speciation skipped: {exc}"
                )
                self._dbg_exc(
                    "speciation.chemistry",
                    "Measurement calibration failed",
                    exc,
                )
        return (
            result,
            params,
            measurement_warning,
            closed_system_result,
            measurement_scale,
        )

    def _solve_forced_ph(
        self,
        model: SpeciationModel,
        params: SolubilityInputs,
        solver_inputs: SolubilitySolverInputs,
        math_logger: SolubilityMathLogger,
        model_options: Optional[ModelOptions],
    ) -> Tuple[
        Optional[SolubilitySpeciationResult],
        Optional[str],
    ]:
        """Solve speciation at a forced pH target.

        Purpose:
            Run the forced-pH solver pass when a target pH is provided.
        Why:
            Supplies forced-pH results for guidance and diagnostics.
        Args:
            model: Speciation model implementation to use.
            params: Solubility input parameters.
            solver_inputs: Solver inputs containing target pH values.
            math_logger: Math logger for optional step capture.
            model_options: Optional model options overrides.
        Returns:
            Tuple of (forced_result, forced_error).
        Side Effects:
            Records perf timing and debug logs when enabled.
        Exceptions:
            Exceptions are caught and returned as error strings.
        """
        forced_result: Optional[SolubilitySpeciationResult] = None
        forced_error: Optional[str] = None
        forced_target = (
            solver_inputs.forced_target
            if solver_inputs.forced_target is not None
            else (
                solver_inputs.reaction_target_ph
                if solver_inputs.reaction_target_ph is not None
                else params.initial_ph_guess
            )
        )
        if forced_target is not None:
            try:
                self._dbg(
                    "speciation.solver",
                    "Forced pH solve start target=%s",
                    forced_target,
                )
                with self._perf_time("speciation.solver", "forced_ph_speciation"):
                    forced_result = model.solve_forced_ph(
                        params,
                        forced_target,
                        math_logger=math_logger,
                        math_section="Forced pH Speciation",
                        model_options=model_options,
                    )
            except Exception as exc:
                forced_error = f"Forced-pH speciation skipped: {exc}"
                self._dbg_exc(
                    "speciation.solver",
                    "Forced pH speciation failed",
                    exc,
                )
        return forced_result, forced_error

    def _build_planner_context(
        self,
        solver_inputs: SolubilitySolverInputs,
        cycle_summary: Dict[str, Any],
        *,
        reaction_guidance: Optional[Dict[str, Any]] = None,
    ) -> List[str]:
        """Build planner context.
        Used to assemble planner context during UI or plot setup."""
        context: List[str] = []
        workflow_key = getattr(solver_inputs, "workflow_key", None)
        mode_key = getattr(solver_inputs, "mode_key", None)
        if (
            mode_key != "contaminated_bicarb_diagnostic"
            and workflow_key != "Planning"
            and solver_inputs.reaction_naoh_mass is not None
        ):
            line = f"NaOH charged: {solver_inputs.reaction_naoh_mass:.2f} g"
            if solver_inputs.reaction_solution_volume is not None:
                line += f" into {solver_inputs.reaction_solution_volume:.2f} L liquor"
            context.append(line)
        headspace_parts: List[str] = []
        if solver_inputs.params.headspace_pco2_atm is not None:
            headspace_parts.append(
                f"pCO₂ {solver_inputs.params.headspace_pco2_atm:.2f} atm"
            )
        if solver_inputs.params.headspace_kh_m_per_atm is not None:
            headspace_parts.append(
                f"KH {solver_inputs.params.headspace_kh_m_per_atm:.3f} mol/L/atm"
            )
        headspace_volume = getattr(solver_inputs.params, "headspace_volume_l", None)
        if headspace_volume is not None:
            headspace_parts.append(f"Volume {headspace_volume:.2f} L")
        if headspace_parts:
            context.append("Headspace: " + ", ".join(headspace_parts))
        reproc_context = (
            reaction_guidance.get("reprocessing_workflow")
            if reaction_guidance
            else None
        )
        if reproc_context and workflow_key == "Reprocessing":
            failing_ph = reproc_context.get("failing_ph")
            if failing_ph is not None:
                context.append(f"Failing slurry pH: {failing_ph:.2f}")
            context.append(f"Batch size: {solver_inputs.params.mass_na_hco3_g:.1f} g")
            solvent_basis = reproc_context.get("solvent_basis")
            solvent_value = reproc_context.get("solvent_basis_value")
            if solvent_basis and solvent_value is not None:
                if solvent_basis == "water_mass":
                    context.append(f"Solvent: {solvent_value:.1f} g water")
                elif solvent_basis == "solution_volume":
                    context.append(f"Solvent: {solvent_value:.2f} L liquor")
            recommended = reproc_context.get("recommended_co2_g")
            if recommended is not None:
                context.append(f"CO₂ to target: {recommended:.2f} g")
            target_ph = reproc_context.get("target_ph")
            if target_ph is not None:
                context.append(f"Target pH: {target_ph:.2f}")
        slider_value = solver_inputs.forced_target
        if slider_value is not None:
            context.append(f"Target slider: pH {slider_value:.2f}")
        reaction_target_ph = solver_inputs.reaction_target_ph
        if (
            reaction_target_ph is not None
            and slider_value is not None
            and abs(reaction_target_ph - slider_value) > 1e-9
        ):
            context.append(f"Reaction target pH: {reaction_target_ph:.2f}")
        elif reaction_target_ph is not None and slider_value is None:
            context.append(f"Reaction target pH: {reaction_target_ph:.2f}")
        if solver_inputs.assumed_solution_volume_l is not None:
            context.append(
                f"Assumed slurry volume: {solver_inputs.assumed_solution_volume_l:.1f} L"
            )
        cycle_total_mass = cycle_summary.get("total_added_mass_g")
        cycle_count = cycle_summary.get("total_cycles")
        cycle_final_ph = cycle_summary.get("final_ph")
        cycle_parts: List[str] = []
        if cycle_total_mass is not None:
            cycle_parts.append(f"{cycle_total_mass:.2f} g CO₂")
        if cycle_count:
            try:
                cycle_parts.append(f"{int(cycle_count)} cycles")
            except Exception:
                cycle_parts.append(f"{cycle_count} cycles")
        if cycle_final_ph is not None:
            cycle_parts.append(f"final pH ≈ {cycle_final_ph:.2f}")
        if cycle_parts:
            context.append("Cycle summary: " + ", ".join(cycle_parts))
        references = cycle_summary.get("planning_reference_ledgers") or []
        if references and workflow_key == "Planning":
            # Iterate over references to apply the per-item logic.
            for ref in references:
                ref_label = (
                    ref.get("label")
                    or f"{ref.get('carbonate_fraction', 0.0):.1%} carbonate"
                )
                ref_ph = ref.get("ph")
                if ref_ph is not None and math.isfinite(ref_ph):
                    context.append(f"{ref_label} reference pH: {ref_ph:.2f}")
        diag = solver_inputs.diagnostic_data or {}
        measured_ph = (
            _safe_float(diag.get("slurry_ph"))
            if diag.get("slurry_ph") is not None
            else _safe_float(diag.get("dried_ph"))
        )
        if workflow_key != "Planning":
            sample_mass = (
                diag.get("sample_mass_g") or solver_inputs.params.mass_na_hco3_g
            )
            if (
                sample_mass is not None
                and math.isfinite(sample_mass)
                and sample_mass > 0
            ):
                context.append(f"Sample mass: {sample_mass:.2f} g")
            if measured_ph is not None:
                context.append(f"Current pH: {measured_ph:.2f}")
            target_ph = diag.get("target_ph")
            if target_ph is not None:
                context.append(f"Target pH: {target_ph:.2f}")
            recommended_co2 = (
                reaction_guidance.get("recommended_co2_g")
                if reaction_guidance
                else None
            )
            if recommended_co2 is not None and math.isfinite(recommended_co2):
                context.append(f"CO\u2082 demand: {recommended_co2:.2f} g")
        return context

    def _run_solubility_workflow(self, mode_key: str) -> None:
        """Run solubility workflow.
        Used to execute solubility workflow and coordinate results."""
        mode_var = getattr(self, "_sol_mode_var", None)
        if mode_var is not None:
            mode_var.set(mode_key)
        self._refresh_sol_mode_guidance()
        self._run_solubility_analysis()

    def _select_sol_workflow_tab(self, workflow_key: str) -> None:
        """Perform select sol workflow tab.
        Used to keep the workflow logic localized and testable."""
        nb = getattr(self, "_sol_workflow_nb", None)
        tabs = getattr(self, "_sol_workflow_tabs", None)
        if nb is None or not tabs:
            return
        target = tabs.get(workflow_key)
        if target is None:
            return
        nb.select(target)
        settings["sol_last_workflow"] = workflow_key
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _run_planning_scenario(self) -> None:
        """Run planning scenario.
        Purpose: Trigger the Planning workflow execution from the UI.
        Why: Capture Planning inputs and run the solver in planning mode.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            - Captures planning input values for persistence.
            - Updates workflow mode and starts the analysis pipeline.
        Exceptions:
            - Best-effort; downstream workflow handles errors.
        """
        self._capture_planning_inputs()
        self._run_solubility_workflow("nahco3_dissolution")

    def _run_analysis_scenario(self, *, skip_apply: bool = False) -> None:
        """Run analysis scenario.
        Used to execute analysis scenario and coordinate results."""
        self._select_sol_workflow_tab("Analysis")
        if not skip_apply:
            self._apply_cycle_payload_to_solubility(
                notify=False, run_simulation=False, workflow_key="Analysis"
            )
        self._run_solubility_workflow("naoh_reaction")
        self._ensure_analysis_progress_vars()
        payload = self._get_cycle_payload_for_workflow("Analysis")
        if payload is None:
            self._analysis_reference_trace = None
            self._analysis_overlay_marker = None
            self._analysis_progress_pct_var.set(
                "Run Cycle Analysis and send results to Analysis mode to estimate reaction progress."
            )
            self._analysis_regime_var.set("Regime: Unknown (pH unavailable)")
            self._analysis_co2_g_var.set("CO2 added (cycle): -- g (-- mol)")
            self._analysis_co2_mol_var.set("--")
            self._analysis_mapped_ph_var.set("Mapped predicted pH: --")
            self._analysis_equivalence_pct_var.set("Equivalence completion: --")
            self._analysis_planning_completion_var.set("Planning target completion: --")
            self._analysis_planning_final_co2_g_var.set("--")
            self._refresh_cycle_views()
            return

        moles = payload.get("total_moles_vdw")
        if moles is None:
            moles = payload.get("total_moles_ideal")
        gas_molar_mass = payload.get("gas_molar_mass") or DEFAULT_GAS_MOLAR_MASS
        co2_mol = None
        co2_g = None
        if moles is not None and gas_molar_mass is not None:
            try:
                co2_mol = float(moles)
                co2_g = co2_mol * float(gas_molar_mass)
            except Exception:
                co2_mol = None
                co2_g = None
        if (
            co2_g is not None
            and co2_mol is not None
            and math.isfinite(co2_g)
            and math.isfinite(co2_mol)
        ):
            self._analysis_co2_g_var.set(
                f"CO2 added (cycle): {co2_g:.2f} g ({co2_mol:.4f} mol)"
            )
            self._analysis_co2_mol_var.set(f"{co2_mol:.4f}")
        else:
            self._analysis_co2_g_var.set("CO2 added (cycle): unavailable")
            self._analysis_co2_mol_var.set("--")

        form_data = getattr(self, "_sol_last_form_data", None)
        if (
            not isinstance(form_data, dict)
            or form_data.get("workflow_key") != "Analysis"
        ):
            form_data = None
        planning_warning: Optional[str] = None
        if form_data is None:
            try:
                form_data = self._collect_solubility_form_data()
            except Exception as exc:
                planning_warning = (
                    "Unable to generate planning reference curve; "
                    f"check Analysis inputs ({exc})."
                )
                form_data = None
        trace: Optional[Dict[str, Any]] = None
        if form_data is not None:
            solver_inputs = self._prepare_solver_inputs(form_data)
            trace = self._build_planning_reference_trace_for_analysis(
                form_data, solver_inputs
            )
            if isinstance(trace, dict) and trace.get("warning"):
                planning_warning = trace.get("warning")
        if not trace or not trace.get("x_co2_g_series"):
            self._analysis_reference_trace = None
            self._analysis_overlay_marker = None
            self._analysis_progress_pct_var.set(
                planning_warning
                or "Unable to generate planning reference curve; check Planning inputs (delta-P/headspace/NaOH basis)."
            )
            self._analysis_regime_var.set("Regime: Unknown (pH unavailable)")
            self._analysis_mapped_ph_var.set("Mapped predicted pH: unavailable")
            self._analysis_equivalence_pct_var.set("Equivalence completion: --")
            self._analysis_planning_completion_var.set("Planning target completion: --")
            self._analysis_planning_final_co2_g_var.set("--")
        else:
            self._analysis_reference_trace = trace
            x_series = trace.get("x_co2_g_series") or []
            ph_series = trace.get("ph_series") or []
            final_co2_g = trace.get("final_co2_g")
            eq_co2_g = trace.get("equivalence_co2_g")
            mapped_x, mapped_ph, _ = _map_current_state_to_planning_curve(
                co2_g, x_series, ph_series
            )
            overall_pct = None
            if (
                co2_g is not None
                and final_co2_g is not None
                and math.isfinite(co2_g)
                and math.isfinite(final_co2_g)
                and final_co2_g > 0
            ):
                overall_pct = max(0.0, min(co2_g / final_co2_g, 1.0)) * 100.0
            eq_pct = None
            if (
                co2_g is not None
                and eq_co2_g is not None
                and math.isfinite(co2_g)
                and math.isfinite(eq_co2_g)
                and eq_co2_g > 0
            ):
                eq_pct = max(0.0, min(co2_g / eq_co2_g, 1.0)) * 100.0
            if overall_pct is not None:
                self._analysis_progress_pct_var.set(
                    "Based on cycle analysis data, your reaction is "
                    f"{overall_pct:.1f}% complete."
                )
                self._analysis_planning_completion_var.set(
                    f"Planning target completion: {overall_pct:.1f}%"
                )
            else:
                self._analysis_progress_pct_var.set(
                    "Based on cycle analysis data, your reaction progress is unavailable."
                )
                self._analysis_planning_completion_var.set(
                    "Planning target completion: --"
                )
            if mapped_ph is not None and math.isfinite(mapped_ph):
                self._analysis_mapped_ph_var.set(
                    f"Mapped predicted pH: {mapped_ph:.2f}"
                )
            else:
                self._analysis_mapped_ph_var.set("Mapped predicted pH: unavailable")
            self._analysis_regime_var.set(_analysis_regime_label(mapped_ph))
            if eq_pct is not None:
                self._analysis_equivalence_pct_var.set(
                    f"Equivalence completion: {eq_pct:.1f}%"
                )
            else:
                self._analysis_equivalence_pct_var.set("Equivalence completion: --")
            if final_co2_g is not None and math.isfinite(final_co2_g):
                self._analysis_planning_final_co2_g_var.set(f"{final_co2_g:.2f}")
            else:
                self._analysis_planning_final_co2_g_var.set("--")
            marker_label = "Current state (cycle-derived)"
            if overall_pct is not None:
                marker_label = f"{marker_label}\n{overall_pct:.1f}% complete"
            if (
                mapped_x is not None
                and mapped_ph is not None
                and math.isfinite(mapped_x)
                and math.isfinite(mapped_ph)
            ):
                self._analysis_overlay_marker = {
                    "x": mapped_x,
                    "ph": mapped_ph,
                    "label": marker_label,
                }
            else:
                self._analysis_overlay_marker = None

        self._run_cycle_solubility_simulation(
            payload=payload,
            notify=False,
            workflow_key="Analysis",
        )

    def _run_reprocessing_scenario(self) -> None:
        """Run reprocessing scenario.
        Used to execute reprocessing scenario and coordinate results."""
        self._run_solubility_workflow("contaminated_bicarb_diagnostic")

    def _build_tab_final_report(self) -> None:
        """Purpose: Build the Final Report tab UI and wire callbacks.
        Why: Centralize layout controls so report settings and previews stay in sync.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            - Creates and packs Tk widgets for the Final Report tab.
            - Binds variable traces and command callbacks for live preview updates.
            - Refreshes template lists and preview thumbnails.
        Exceptions:
            - UI errors are handled by Tkinter; this method does not raise explicitly.
        """
        final_state = settings.get("final_report", {})
        frame = self.tab_final_report
        frame.grid_rowconfigure(0, weight=1)
        frame.grid_columnconfigure(0, weight=1)

        self._final_report_section_vars = {}
        self._final_orientation_vars = {}
        self._final_report_section_header_vars = {}
        self._final_report_section_caption_vars = {}
        self._final_report_section_caption_placement_vars = {}
        self._final_report_section_order = []

        outer = ttk.Frame(frame)
        outer.grid(row=0, column=0, sticky="nsew")
        outer.grid_columnconfigure(0, weight=1)
        outer.grid_rowconfigure(0, weight=1)

        # Tkinter does not provide a native scrollable frame; use a canvas wrapper to
        # enable full-tab vertical scrolling without changing inner layout logic.
        final_report_canvas = tk.Canvas(outer, highlightthickness=0)
        final_report_canvas.grid(row=0, column=0, sticky="nsew")
        final_report_scrollbar = _ui_scrollbar(
            outer, orient="vertical", command=final_report_canvas.yview
        )
        final_report_scrollbar.grid(row=0, column=1, sticky="ns")
        final_report_canvas.configure(yscrollcommand=final_report_scrollbar.set)

        scroll_content = ttk.Frame(final_report_canvas)
        scroll_window = final_report_canvas.create_window(
            (0, 0), window=scroll_content, anchor="nw"
        )

        # Closure captures _build_tab_final_report local context to keep helper logic scoped and invoked directly within _build_tab_final_report.
        def _refresh_final_report_scroll(_event=None):
            """Refresh final report scroll region.
            Used to keep the canvas scroll region aligned with the content size."""
            # Sync scrollregion to the interior frame height so content is not clipped.
            final_report_canvas.configure(
                scrollregion=final_report_canvas.bbox("all")
            )

        scroll_content.bind("<Configure>", _refresh_final_report_scroll)

        # Closure captures _build_tab_final_report local context to keep helper logic scoped and invoked directly within _build_tab_final_report.
        def _expand_final_report_width(event):
            """Perform expand final report width.
            Used to keep the scroll frame width aligned with the canvas."""
            final_report_canvas.itemconfigure(scroll_window, width=event.width)

        final_report_canvas.bind("<Configure>", _expand_final_report_width)

        # Closure captures _build_tab_final_report local context to keep helper logic scoped and invoked directly within _build_tab_final_report.
        def _skip_final_report_scroll(widget):
            """Return whether the widget should keep its own scroll handling.
            Used to avoid hijacking mousewheel behavior for text or list widgets."""
            return isinstance(widget, (tk.Text, tk.Listbox))

        # Closure captures _build_tab_final_report local context to keep helper logic scoped and invoked directly within _build_tab_final_report.
        def _on_final_report_mousewheel(event):
            """Handle final report mousewheel.
            Used to scroll the tab canvas without overriding text widget scrolling."""
            if _skip_final_report_scroll(event.widget):
                return None
            delta = event.delta
            if delta == 0:
                return None
            step = -1 if delta > 0 else 1
            if abs(delta) >= 120:
                step = int(-delta / 120)
            final_report_canvas.yview_scroll(step, "units")
            return "break"

        # Closure captures _build_tab_final_report local context to keep helper logic scoped and invoked directly within _build_tab_final_report.
        def _on_final_report_scroll_up(event):
            """Scroll final report canvas up.
            Used to support Linux-style mousewheel events."""
            if _skip_final_report_scroll(event.widget):
                return None
            final_report_canvas.yview_scroll(-1, "units")
            return "break"

        # Closure captures _build_tab_final_report local context to keep helper logic scoped and invoked directly within _build_tab_final_report.
        def _on_final_report_scroll_down(event):
            """Scroll final report canvas down.
            Used to support Linux-style mousewheel events."""
            if _skip_final_report_scroll(event.widget):
                return None
            final_report_canvas.yview_scroll(1, "units")
            return "break"

        # Closure captures _build_tab_final_report local context to keep helper logic scoped and invoked directly within _build_tab_final_report.
        def _bind_final_report_mousewheel(widget):
            """Bind mousewheel events for final report scrolling.
            Used to enable scrolling when the pointer is over any tab widget."""
            widget.bind("<MouseWheel>", _on_final_report_mousewheel, add="+")
            widget.bind("<Button-4>", _on_final_report_scroll_up, add="+")
            widget.bind("<Button-5>", _on_final_report_scroll_down, add="+")
            # Iterate over widget.winfo_children() to apply the per-item logic.
            for child in widget.winfo_children():
                _bind_final_report_mousewheel(child)

        # Closure captures _build_tab_final_report local context to keep helper logic scoped and invoked directly within _build_tab_final_report.
        def _init_final_report_mousewheel():
            """Initialize mousewheel bindings for the Final Report tab.
            Used to keep scrolling active only within Final Report widgets."""
            _bind_final_report_mousewheel(scroll_content)

        self.after_idle(_init_final_report_mousewheel)

        top_frame = ttk.Frame(scroll_content)
        top_frame.pack(fill="x", padx=8, pady=(8, 4))
        top_frame.grid_columnconfigure(1, weight=1)

        ttk.Label(top_frame, text="Final Report Title:").grid(
            row=0, column=0, sticky="w"
        )
        self._final_report_title_var = tk.StringVar()
        _ui_entry(
            top_frame,
            textvariable=self._final_report_title_var,
        ).grid(row=0, column=1, sticky="ew", padx=(8, 0))
        ttk.Label(
            top_frame,
            text="Combined Triple-Axis Title (Final Report only):",
        ).grid(row=1, column=0, sticky="w", pady=(4, 0))
        self._final_report_combined_title_var = tk.StringVar(
            value=final_state.get("combined_plot_title_override", "")
        )
        _ui_entry(
            top_frame,
            textvariable=self._final_report_combined_title_var,
        ).grid(row=1, column=1, sticky="ew", padx=(8, 0), pady=(4, 0))

        template_frame = ttk.Frame(top_frame)
        template_frame.grid(
            row=2,
            column=0,
            columnspan=2,
            sticky="ew",
            pady=(8, 0),
        )
        template_frame.grid_columnconfigure(1, weight=1)
        ttk.Label(template_frame, text="Template:").grid(row=0, column=0, sticky="w")
        self._final_report_template_var = tk.StringVar(
            value=FINAL_REPORT_TEMPLATE_PLACEHOLDER
        )
        self._final_report_template_combo = _ui_combobox(
            template_frame,
            textvariable=self._final_report_template_var,
            state="readonly",
        )
        self._final_report_template_combo.grid(
            row=0,
            column=1,
            sticky="ew",
            padx=4,
        )
        template_button_bar = ttk.Frame(template_frame)
        template_button_bar.grid(row=0, column=2, padx=(8, 0))
        _ui_button(
            template_button_bar,
            text="Save As Template",
            command=self._save_final_report_template,
        ).pack(side="left", padx=2)
        _ui_button(
            template_button_bar,
            text="Update Template",
            command=self._update_final_report_template,
        ).pack(side="left", padx=2)
        _ui_button(
            template_button_bar,
            text="Delete Template",
            command=self._delete_final_report_template,
        ).pack(side="left", padx=2)

        layout_frame = ttk.LabelFrame(scroll_content, text="Layout & Orientation")
        layout_frame.pack(fill="x", padx=8, pady=(0, 4))
        layout_frame.grid_columnconfigure(1, weight=1)
        layout_frame.grid_columnconfigure(3, weight=1)
        ttk.Label(layout_frame, text="Layout mode:").grid(
            row=0, column=0, sticky="w", padx=4, pady=4
        )
        self._final_report_layout_mode_var = tk.StringVar()
        _ui_combobox(
            layout_frame,
            textvariable=self._final_report_layout_mode_var,
            values=list(FINAL_REPORT_LAYOUT_MODES),
            state="readonly",
        ).grid(row=0, column=1, sticky="ew", padx=4, pady=4)
        ttk.Label(layout_frame, text="Fit mode:").grid(
            row=1, column=0, sticky="w", padx=4, pady=4
        )
        self._final_report_fit_mode_var = tk.StringVar()
        _ui_combobox(
            layout_frame,
            textvariable=self._final_report_fit_mode_var,
            values=list(FINAL_REPORT_FIT_MODES),
            state="readonly",
        ).grid(row=1, column=1, sticky="ew", padx=4, pady=4)
        ttk.Label(layout_frame, text="Safe margins:").grid(
            row=1, column=2, sticky="w", padx=4, pady=4
        )
        self._final_report_safe_margins_var = tk.StringVar()
        _ui_combobox(
            layout_frame,
            textvariable=self._final_report_safe_margins_var,
            values=list(FINAL_REPORT_SAFE_MARGIN_PRESETS),
            state="readonly",
        ).grid(row=1, column=3, sticky="ew", padx=4, pady=4)

        typography_frame = ttk.LabelFrame(scroll_content, text="Typography & Margins")
        typography_frame.pack(fill="x", padx=8, pady=(0, 8))
        typography_frame.grid_columnconfigure(1, weight=1)
        ttk.Label(typography_frame, text="Font scale:").grid(
            row=0, column=0, sticky="w", padx=4, pady=4
        )
        self._final_report_font_scale_var = tk.DoubleVar()
        ttk.Spinbox(
            typography_frame,
            from_=0.5,
            to=2.0,
            increment=0.05,
            textvariable=self._final_report_font_scale_var,
            width=6,
        ).grid(row=0, column=1, sticky="w", padx=4, pady=4)

        ttk.Label(typography_frame, text="Margins (in):").grid(
            row=0, column=2, sticky="w", padx=4, pady=4
        )
        self._final_report_margin_in_var = tk.DoubleVar()
        ttk.Spinbox(
            typography_frame,
            from_=0.25,
            to=1.5,
            increment=0.05,
            textvariable=self._final_report_margin_in_var,
            width=6,
        ).grid(row=0, column=3, sticky="w", padx=4, pady=4)

        self._final_report_show_page_numbers_var = tk.BooleanVar()
        _ui_checkbutton(
            typography_frame,
            text="Show page numbers",
            variable=self._final_report_show_page_numbers_var,
        ).grid(
            row=1,
            column=0,
            columnspan=2,
            sticky="w",
            padx=4,
            pady=4,
        )

        self._final_report_show_section_headers_var = tk.BooleanVar()
        _ui_checkbutton(
            typography_frame,
            text="Show section headers",
            variable=self._final_report_show_section_headers_var,
        ).grid(
            row=1,
            column=2,
            columnspan=2,
            sticky="w",
            padx=4,
            pady=(4, 8),
        )
        ttk.Label(typography_frame, text="Table style:").grid(
            row=2, column=0, sticky="w", padx=4, pady=(0, 8)
        )
        self._final_report_table_style_var = tk.StringVar()
        _ui_combobox(
            typography_frame,
            textvariable=self._final_report_table_style_var,
            values=list(FINAL_REPORT_TABLE_STYLE_PRESETS),
            state="readonly",
            width=14,
        ).grid(row=2, column=1, sticky="w", padx=4, pady=(0, 8))

        action_frame = ttk.Frame(scroll_content)
        action_frame.pack(fill="x", padx=8, pady=(0, 8))
        _ui_button(
            action_frame,
            text="Report Preview",
            command=self._open_final_report_preview_window,
            padding=(12, 4),
        ).pack(side="left", padx=(0, 8))
        _ui_button(
            action_frame,
            text="Generate Final Report...",
            command=self._prompt_final_report_generation,
            padding=(12, 4),
        ).pack(side="left")

        # Closure captures _build_tab_final_report local context to keep helper logic scoped and invoked directly within _build_tab_final_report.
        def _report_preview_trigger(*_):
            """Perform report preview trigger.
            Used to keep the workflow logic localized and testable."""
            self._schedule_final_report_preview_refresh()

        # Iterate to apply the per-item logic.
        for var in (
            self._final_report_title_var,
            self._final_report_layout_mode_var,
            self._final_report_fit_mode_var,
            self._final_report_font_scale_var,
            self._final_report_margin_in_var,
            self._final_report_safe_margins_var,
            self._final_report_show_page_numbers_var,
            self._final_report_show_section_headers_var,
            self._final_report_table_style_var,
            self._final_report_combined_title_var,
        ):
            var.trace_add("write", _report_preview_trigger)

        paned = ttk.Panedwindow(scroll_content, orient="horizontal")
        paned.pack(fill="both", expand=True, padx=8, pady=(0, 8))

        left_panel = ttk.Frame(paned)
        right_panel = ttk.Frame(paned)
        paned.add(left_panel, weight=1)
        paned.add(right_panel, weight=2)

        sections_frame = ttk.LabelFrame(left_panel, text="Sections Included")
        sections_frame.pack(fill="both", expand=True, pady=(0, 8), padx=0)
        sections_frame.grid_columnconfigure(0, weight=1)
        orientation_defaults = final_state.get("section_orientation", {})
        # Iterate over items from FINAL_REPORT_SECTION_GROUPS to apply the per-item logic.
        for group_name, section_ids in FINAL_REPORT_SECTION_GROUPS.items():
            group_frame = ttk.LabelFrame(sections_frame, text=group_name)
            group_frame.pack(fill="x", pady=(4, 0), padx=4)
            # Iterate over section_ids to apply the per-item logic.
            for section_id in section_ids:
                metadata = FINAL_REPORT_SECTION_METADATA.get(section_id, {})
                row_frame = ttk.Frame(group_frame)
                row_frame.pack(fill="x", padx=4, pady=2)
                var = tk.BooleanVar()
                self._final_report_section_vars[section_id] = var
                _ui_checkbutton(
                    row_frame,
                    text=metadata.get("label", section_id),
                    variable=var,
                    command=partial(self._on_final_section_toggle, section_id),
                ).pack(side="left", fill="x", expand=True)
                controls_frame = ttk.Frame(row_frame)
                controls_frame.pack(side="right")
                control_col = 0
                header_var = tk.BooleanVar()
                self._final_report_section_header_vars[section_id] = header_var
                _ui_checkbutton(
                    controls_frame,
                    text="Header",
                    variable=header_var,
                    command=self._final_report_section_layout_changed,
                ).grid(row=0, column=control_col, padx=(4, 0))
                control_col += 1
                if metadata.get("type") in ("figure", "table"):
                    caption_var = tk.BooleanVar()
                    self._final_report_section_caption_vars[section_id] = caption_var
                    _ui_checkbutton(
                        controls_frame,
                        text="Caption",
                        variable=caption_var,
                        command=self._final_report_section_layout_changed,
                    ).grid(row=0, column=control_col, padx=(4, 0))
                    control_col += 1
                    placement_var = tk.StringVar(
                        value=FINAL_REPORT_CAPTION_PLACEMENTS[0]
                    )
                    self._final_report_section_caption_placement_vars[section_id] = (
                        placement_var
                    )
                    placement_combo = _ui_combobox(
                        controls_frame,
                        values=FINAL_REPORT_CAPTION_PLACEMENTS,
                        textvariable=placement_var,
                        state="readonly",
                        width=10,
                    )
                    placement_combo.grid(row=0, column=control_col, padx=(4, 0))
                    placement_var.trace_add(
                        "write", lambda *_: self._final_report_section_layout_changed()
                    )
                    control_col += 1
                if metadata.get("type") == "figure":
                    orientation_var = tk.StringVar(
                        value=orientation_defaults.get(section_id, "inherit")
                    )
                    self._final_orientation_vars[section_id] = orientation_var
                    ttk.Label(controls_frame, text="Orientation:").grid(
                        row=0, column=control_col, padx=(4, 0)
                    )
                    control_col += 1
                    _ui_combobox(
                        controls_frame,
                        values=FINAL_REPORT_ORIENTATION_OPTIONS,
                        textvariable=orientation_var,
                        state="readonly",
                        width=10,
                    ).grid(row=0, column=control_col, padx=(4, 0))
                    orientation_var.trace_add(
                        "write",
                        lambda *args, sid=section_id, var=orientation_var: self._final_report_orientation_changed(
                            sid, var
                        ),
                    )

        order_frame = ttk.LabelFrame(left_panel, text="Section Order")
        order_frame.pack(fill="both", expand=True, pady=(0, 0))
        self._final_report_section_order_listbox = tk.Listbox(
            order_frame, activestyle="none", height=8
        )
        self._final_report_section_order_listbox.pack(
            side="left", fill="both", expand=True, padx=(4, 0), pady=4
        )
        order_scroll = _ui_scrollbar(
            order_frame,
            orient="vertical",
            command=self._final_report_section_order_listbox.yview,
        )
        order_scroll.pack(side="left", fill="y", pady=4, padx=(0, 4))
        self._final_report_section_order_listbox.configure(
            yscrollcommand=order_scroll.set
        )
        reorder_buttons = ttk.Frame(order_frame)
        reorder_buttons.pack(side="right", fill="y", padx=(0, 4), pady=4)
        _ui_button(
            reorder_buttons,
            text="Move Up",
            command=self._move_final_report_section_up,
        ).pack(fill="x", pady=2)
        _ui_button(
            reorder_buttons,
            text="Move Down",
            command=self._move_final_report_section_down,
        ).pack(fill="x", pady=2)

        narrative_frame = ttk.LabelFrame(
            right_panel, text="Report Narrative (optional)"
        )
        narrative_frame.pack(fill="both", expand=True, pady=(0, 8))
        self._final_report_narrative_text = scrolledtext.ScrolledText(
            narrative_frame, wrap="word", height=10
        )
        self._final_report_narrative_text.pack(fill="both", expand=True, padx=6, pady=4)
        self._enable_text_mousewheel(self._final_report_narrative_text)
        self._final_report_narrative_text.bind(
            "<<Modified>>", self._on_final_report_narrative_changed
        )

        preview_frame = ttk.LabelFrame(right_panel, text="Preview & Generation")
        preview_frame.pack(fill="both", expand=True)
        preview_canvas_container = ttk.Frame(preview_frame)
        preview_canvas_container.pack(fill="both", expand=True, padx=6, pady=(6, 4))
        preview_canvas_container.grid_rowconfigure(0, weight=1)
        preview_canvas_container.grid_columnconfigure(0, weight=1)
        preview_canvas = tk.Canvas(
            preview_canvas_container, bg="white", highlightthickness=0, height=220
        )
        preview_canvas.grid(row=0, column=0, sticky="nsew")
        preview_canvas_scroll_y = _ui_scrollbar(
            preview_canvas_container, orient="vertical", command=preview_canvas.yview
        )
        preview_canvas_scroll_y.grid(row=0, column=1, sticky="ns")
        preview_canvas_scroll_x = _ui_scrollbar(
            preview_canvas_container, orient="horizontal", command=preview_canvas.xview
        )
        preview_canvas_scroll_x.grid(row=1, column=0, sticky="ew")
        preview_canvas.configure(
            yscrollcommand=preview_canvas_scroll_y.set,
            xscrollcommand=preview_canvas_scroll_x.set,
        )
        self._final_report_preview_canvas = preview_canvas

        ttk.Label(preview_frame, text="Layout Summary:").pack(anchor="w", padx=6)
        self._final_report_preview_text = scrolledtext.ScrolledText(
            preview_frame,
            wrap="word",
            height=8,
            state="disabled",
        )
        self._final_report_preview_text.pack(
            fill="both", expand=True, padx=6, pady=(0, 4)
        )
        self._enable_text_mousewheel(self._final_report_preview_text)
        preview_buttons = ttk.Frame(preview_frame)
        preview_buttons.pack(fill="x", padx=6, pady=(0, 6))
        _ui_button(
            preview_buttons,
            text="Open Preview Window",
            command=self._open_final_report_preview_window,
        ).pack(side="left", padx=(0, 4))
        _ui_button(
            preview_buttons,
            text="Render Selected Page Preview",
            command=self._final_report_render_selected_page_preview,
        ).pack(side="left", padx=(0, 4))
        _ui_button(
            preview_buttons,
            text="Update Layout Preview",
            command=self._refresh_final_report_preview,
        ).pack(side="left")

        self._final_report_template_combo.bind(
            "<<ComboboxSelected>>", self._final_report_template_selected
        )
        self._apply_final_report_state_to_ui(final_state)
        self._refresh_final_report_template_list()
        self._refresh_final_report_preview()

    def _prompt_final_report_generation(self) -> None:
        """Open the final-report export format prompt and dispatch generation.

        Purpose:
            Ask the user for output format before generating the Final Report.
        Why:
            The report pipeline supports multiple formats and needs an explicit
            format choice at execution time.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Creates a modal dialog, captures format choice, and triggers report
            generation callbacks on confirmation.
        Exceptions:
            Dialog callbacks use best-effort guards to avoid UI interruption.
        """
        dialog = tk.Toplevel(self)
        dialog.title("Generate Final Report")
        dialog.transient(self)
        dialog.resizable(False, False)
        dialog.grab_set()

        pad_x = self._scale_length(20)
        pad_y = self._scale_length(10)

        ttk.Label(dialog, text="Choose output format:").pack(
            padx=pad_x, pady=(pad_y, self._scale_length(6))
        )

        choice_var = tk.StringVar(value="pdf")
        options_frame = ttk.Frame(dialog)
        options_frame.pack(fill="x", padx=pad_x)
        _ui_radiobutton(
            options_frame, text="PDF", variable=choice_var, value="pdf"
        ).pack(anchor="w")
        _ui_radiobutton(
            options_frame, text="PNG", variable=choice_var, value="png"
        ).pack(anchor="w")
        _ui_radiobutton(
            options_frame, text="PDF + PNG", variable=choice_var, value="both"
        ).pack(anchor="w")

        button_frame = ttk.Frame(dialog)
        button_frame.pack(fill="x", padx=pad_x, pady=(self._scale_length(8), pad_y))

        # Closure captures _prompt_final_report_generation state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _prompt_final_report_generation.
        def _close_dialog() -> None:
            """Close dialog.
            Used by UI actions to close dialog safely."""
            try:
                dialog.grab_release()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            dialog.destroy()

        # Closure captures _prompt_final_report_generation local context to keep helper logic scoped and invoked directly within _prompt_final_report_generation.
        def _generate() -> None:
            """Generate value.
            Used to produce value outputs for analysis or export."""
            choice = (choice_var.get() or "").strip().lower()
            _close_dialog()
            if choice == "png":
                self._generate_final_report_png()
            elif choice == "both":
                self._generate_final_report_pdf()
                self._generate_final_report_png()
            else:
                self._generate_final_report_pdf()

        # Closure captures _prompt_final_report_generation state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _prompt_final_report_generation.
        def _cancel() -> None:
            """Perform cancel.
            Used to keep the workflow logic localized and testable."""
            _close_dialog()

        generate_btn = _ui_button(button_frame, text="Generate", command=_generate)
        generate_btn.pack(side="right")
        _ui_button(button_frame, text="Cancel", command=_cancel).pack(
            side="right", padx=(0, 8)
        )

        dialog.bind("<Return>", lambda _event: _generate())
        dialog.bind("<Escape>", lambda _event: _cancel())
        dialog.protocol("WM_DELETE_WINDOW", _cancel)

        try:
            generate_btn.focus_set()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        dialog.wait_window(dialog)

    def _apply_final_report_state_to_ui(self, state: Dict[str, Any]) -> None:
        """Purpose: Apply stored final report state to UI widgets.
        Why: Keep settings, templates, and live controls synchronized.
        Args:
            state (Dict[str, Any]): Final report settings payload to apply.
        Returns:
            None.
        Side Effects:
            - Updates Tk variables and text widgets.
            - Refreshes section order listbox state.
        Exceptions:
            - Best-effort; invalid values fall back to defaults.
        """
        if not state:
            return
        title = state.get("title") or FINAL_REPORT_DEFAULT_STATE["title"]
        self._final_report_title_var.set(title)
        combined_override = state.get("combined_plot_title_override", "")
        self._final_report_combined_title_var.set(combined_override)
        layout_mode = state.get(
            "global_layout_mode", FINAL_REPORT_DEFAULT_STATE["global_layout_mode"]
        )
        self._final_report_layout_mode_var.set(layout_mode)
        fit_mode = state.get("fit_mode", FINAL_REPORT_DEFAULT_STATE["fit_mode"])
        if fit_mode not in FINAL_REPORT_FIT_MODES:
            fit_mode = FINAL_REPORT_DEFAULT_STATE["fit_mode"]
        self._final_report_fit_mode_var.set(fit_mode)
        font_scale = state.get("font_scale", FINAL_REPORT_DEFAULT_STATE["font_scale"])
        self._final_report_font_scale_var.set(font_scale)
        margin_in = state.get("margin_in", FINAL_REPORT_DEFAULT_STATE["margin_in"])
        self._final_report_margin_in_var.set(margin_in)
        safe_margin = state.get(
            "safe_margin_preset", FINAL_REPORT_DEFAULT_STATE["safe_margin_preset"]
        )
        if safe_margin not in FINAL_REPORT_SAFE_MARGIN_PRESETS:
            safe_margin = FINAL_REPORT_DEFAULT_STATE["safe_margin_preset"]
        self._final_report_safe_margins_var.set(safe_margin)
        self._final_report_show_page_numbers_var.set(
            bool(
                state.get(
                    "show_page_numbers", FINAL_REPORT_DEFAULT_STATE["show_page_numbers"]
                )
            )
        )
        self._final_report_show_section_headers_var.set(
            bool(
                state.get(
                    "show_section_headers",
                    FINAL_REPORT_DEFAULT_STATE["show_section_headers"],
                )
            )
        )
        table_style = state.get(
            "table_style_preset", FINAL_REPORT_DEFAULT_STATE["table_style_preset"]
        )
        if table_style not in FINAL_REPORT_TABLE_STYLE_PRESETS:
            table_style = FINAL_REPORT_DEFAULT_STATE["table_style_preset"]
        self._final_report_table_style_var.set(table_style)
        narrative = state.get("narrative", "")
        self._final_report_narrative_text.delete("1.0", "end")
        self._final_report_narrative_text.insert("1.0", narrative)
        selected_sections = [
            section_id
            # Iterate to apply the per-item logic.
            for section_id in (state.get("selected_sections") or [])
            if isinstance(section_id, str)
        ]
        selected_set = set(selected_sections)
        order = self._final_report_ordered_sections(state)
        self._final_report_section_order = order
        orientation_state = state.get("section_orientation", {})
        # Iterate over items from self._final_report_section_vars to apply the per-item logic.
        for section_id, var in self._final_report_section_vars.items():
            var.set(section_id in selected_set)
        # Iterate over items from self._final_orientation_vars to apply the per-item logic.
        for section_id, orientation_var in self._final_orientation_vars.items():
            orientation_var.set(orientation_state.get(section_id, "inherit"))
        header_state = state.get("section_header_enabled", {})
        # Iterate over items from self._final_report_section_header_vars to apply the per-item logic.
        for section_id, header_var in self._final_report_section_header_vars.items():
            header_var.set(
                bool(
                    header_state.get(
                        section_id,
                        FINAL_REPORT_SECTION_HEADER_DEFAULTS.get(section_id, True),
                    )
                )
            )
        caption_state = state.get("section_caption_enabled", {})
        # Iterate over items from self._final_report_section_caption_vars to apply the per-item logic.
        for section_id, caption_var in self._final_report_section_caption_vars.items():
            caption_var.set(
                bool(
                    caption_state.get(
                        section_id,
                        FINAL_REPORT_SECTION_CAPTION_DEFAULTS.get(section_id, False),
                    )
                )
            )
        placement_state = state.get("section_caption_placement", {})
        # Iterate over items from self._final_report_section_caption_placement_vars to apply the per-item logic.
        for section_id, placement_var in (
            self._final_report_section_caption_placement_vars.items()
        ):
            placement = placement_state.get(
                section_id,
                FINAL_REPORT_SECTION_CAPTION_PLACEMENT_DEFAULTS.get(
                    section_id, "Same Page"
                ),
            )
            if placement not in FINAL_REPORT_CAPTION_PLACEMENTS:
                placement = FINAL_REPORT_SECTION_CAPTION_PLACEMENT_DEFAULTS.get(
                    section_id, "Same Page"
                )
            placement_var.set(placement)
        self._refresh_final_report_section_order_listbox()

    def _collect_final_report_state_from_ui(self) -> Dict[str, Any]:
        """Purpose: Collect Final Report state from UI widgets.
        Why: Build a normalized settings payload for previews and exports.
        Args:
            None.
        Returns:
            Dict[str, Any]: Final Report settings snapshot derived from UI values.
        Side Effects:
            - None; reads UI state only.
        Exceptions:
            - Invalid numeric inputs fall back to defaults.
        """
        # Closure captures _collect_final_report_state_from_ui local context to keep helper logic scoped and invoked directly within _collect_final_report_state_from_ui.
        def _safe_float(var: tk.Variable, fallback: float) -> float:
            """Perform safe float.
            Used to keep the workflow logic localized and testable."""
            try:
                value = float(var.get())
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return fallback
            if not math.isfinite(value):
                return fallback
            return value

        title = self._final_report_title_var.get().strip()
        if not title:
            title = FINAL_REPORT_DEFAULT_STATE["title"]
        layout_mode = self._final_report_layout_mode_var.get()
        if not layout_mode:
            layout_mode = FINAL_REPORT_DEFAULT_STATE["global_layout_mode"]
        fit_mode = self._final_report_fit_mode_var.get()
        if fit_mode not in FINAL_REPORT_FIT_MODES:
            fit_mode = FINAL_REPORT_DEFAULT_STATE["fit_mode"]
        profile_key = settings.get("final_report", {}).get(
            "profile_key", FINAL_REPORT_DEFAULT_STATE["profile_key"]
        )
        safe_margin = self._final_report_safe_margins_var.get()
        if safe_margin not in FINAL_REPORT_SAFE_MARGIN_PRESETS:
            safe_margin = FINAL_REPORT_DEFAULT_STATE["safe_margin_preset"]
        table_style = self._final_report_table_style_var.get()
        if table_style not in FINAL_REPORT_TABLE_STYLE_PRESETS:
            table_style = FINAL_REPORT_DEFAULT_STATE["table_style_preset"]
        return {
            "title": title,
            "combined_plot_title_override": self._final_report_combined_title_var.get().strip(),
            "selected_sections": list(self._final_report_section_order),
            "section_order": list(self._final_report_section_order),
            "narrative": self._final_report_narrative_text.get("1.0", "end").strip(),
            "global_layout_mode": layout_mode,
            "fit_mode": fit_mode,
            "font_scale": _safe_float(
                self._final_report_font_scale_var,
                FINAL_REPORT_DEFAULT_STATE["font_scale"],
            ),
            "margin_in": _safe_float(
                self._final_report_margin_in_var,
                FINAL_REPORT_DEFAULT_STATE["margin_in"],
            ),
            "safe_margin_preset": safe_margin,
            "show_page_numbers": bool(self._final_report_show_page_numbers_var.get()),
            "show_section_headers": bool(
                self._final_report_show_section_headers_var.get()
            ),
            "table_style_preset": table_style,
            "section_header_enabled": {
                section_id: bool(var.get())
                # Iterate to apply the per-item logic.
                for section_id, var in self._final_report_section_header_vars.items()
            },
            "section_caption_enabled": {
                section_id: bool(var.get())
                # Iterate to apply the per-item logic.
                for section_id, var in self._final_report_section_caption_vars.items()
            },
            "section_caption_placement": {
                section_id: (
                    var.get()
                    if var.get() in FINAL_REPORT_CAPTION_PLACEMENTS
                    else FINAL_REPORT_SECTION_CAPTION_PLACEMENT_DEFAULTS.get(
                        section_id, "Same Page"
                    )
                )
                # Iterate to apply the per-item logic.
                for section_id, var in (
                    self._final_report_section_caption_placement_vars.items()
                )
            },
            "section_orientation": {
                section_id: var.get()
                # Iterate to apply the per-item logic.
                for section_id, var in self._final_orientation_vars.items()
            },
            "profile_key": profile_key,
        }

    def _refresh_final_report_section_order_listbox(self) -> None:
        """Refresh final report section order listbox.
        Used to sync final report section order listbox with current settings."""
        listbox = getattr(self, "_final_report_section_order_listbox", None)
        if listbox is None:
            return
        listbox.delete(0, "end")
        # Iterate over self._final_report_section_order to apply the per-item logic.
        for section_id in self._final_report_section_order:
            label = FINAL_REPORT_SECTION_METADATA.get(section_id, {}).get(
                "label", section_id
            )
            listbox.insert("end", label)

    def _on_final_section_toggle(self, section_id: str) -> None:
        """Handle final section toggle.
        Used as an event callback for final section toggle."""
        var = self._final_report_section_vars.get(section_id)
        if var is None:
            return
        included = bool(var.get())
        if included:
            if section_id not in self._final_report_section_order:
                self._final_report_section_order.append(section_id)
        else:
            if section_id in self._final_report_section_order:
                self._final_report_section_order.remove(section_id)
        self._refresh_final_report_section_order_listbox()
        self._refresh_final_report_preview()

    def _on_final_report_narrative_changed(self, event=None) -> None:
        """Handle final report narrative changed.
        Used as an event callback for final report narrative changed."""
        widget = None
        if event is not None:
            widget = getattr(event, "widget", None)
        if widget is None:
            widget = getattr(self, "_final_report_narrative_text", None)
        if widget is None:
            return
        try:
            if widget.edit_modified():
                widget.edit_modified(False)
                self._schedule_final_report_preview_refresh()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _move_final_report_section(self, direction: int) -> None:
        """Perform move final report section.
        Used to keep the workflow logic localized and testable."""
        listbox = getattr(self, "_final_report_section_order_listbox", None)
        if listbox is None:
            return
        selection = listbox.curselection()
        if not selection:
            return
        index = selection[0]
        target = index + direction
        if target < 0 or target >= len(self._final_report_section_order):
            return
        (
            self._final_report_section_order[index],
            self._final_report_section_order[target],
        ) = (
            self._final_report_section_order[target],
            self._final_report_section_order[index],
        )
        self._refresh_final_report_section_order_listbox()
        listbox.selection_clear(0, "end")
        listbox.selection_set(target)
        self._refresh_final_report_preview()

    def _move_final_report_section_up(self) -> None:
        """Perform move final report section up.
        Used to keep the workflow logic localized and testable."""
        self._move_final_report_section(-1)

    def _move_final_report_section_down(self) -> None:
        """Perform move final report section down.
        Used to keep the workflow logic localized and testable."""
        self._move_final_report_section(1)

    def _refresh_final_report_template_list(self) -> None:
        """Refresh final report template list.
        Used to sync final report template list with current settings."""
        combo = getattr(self, "_final_report_template_combo", None)
        if combo is None:
            return
        presets = settings.get("final_report_presets", {}) or {}
        names = sorted(
            name for name in presets.keys() if isinstance(name, str) and name.strip()
        )
        values = [FINAL_REPORT_TEMPLATE_PLACEHOLDER] + names
        combo["values"] = values
        current = self._final_report_template_var.get()
        if current not in values:
            self._final_report_template_var.set(FINAL_REPORT_TEMPLATE_PLACEHOLDER)

    def _final_report_template_selected(self, _event=None) -> None:
        """Perform final report template selected.
        Used to keep the workflow logic localized and testable."""
        name = self._final_report_template_var.get()
        if not name or name == FINAL_REPORT_TEMPLATE_PLACEHOLDER:
            return
        self._load_final_report_template(name)

    def _load_final_report_template(self, name: str) -> None:
        """Load final report template.
        Used when restoring final report template from storage."""
        presets = settings.setdefault("final_report_presets", {})
        template = presets.get(name)
        if not isinstance(template, dict):
            return
        settings["final_report"] = copy.deepcopy(template)
        self._apply_final_report_state_to_ui(settings["final_report"])
        self._refresh_final_report_template_list()
        self._final_report_template_var.set(name)
        self._refresh_final_report_preview()
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _save_final_report_template(self) -> None:
        """Save final report template.
        Used when persisting final report template to storage."""
        name = simpledialog.askstring("Save Final Report Template", "Template name:")
        if not name:
            return
        name = name.strip()
        if not name:
            return
        presets = settings.setdefault("final_report_presets", {})
        if name in presets:
            try:
                messagebox.showwarning(
                    "Final Report Templates",
                    "A template with that name already exists. Use Update Template to overwrite it.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        state = copy.deepcopy(self._collect_final_report_state_from_ui())
        presets[name] = state
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._refresh_final_report_template_list()
        self._final_report_template_var.set(name)

    def _update_final_report_template(self) -> None:
        """Update final report template.
        Used to keep final report template in sync with current state."""
        name = self._final_report_template_var.get()
        if not name or name == FINAL_REPORT_TEMPLATE_PLACEHOLDER:
            try:
                messagebox.showinfo(
                    "Final Report Templates", "Select a template to update."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        presets = settings.setdefault("final_report_presets", {})
        if name not in presets:
            try:
                messagebox.showwarning(
                    "Final Report Templates",
                    "The selected template is no longer available.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._refresh_final_report_template_list()
            return
        confirm = False
        try:
            confirm = messagebox.askyesno(
                "Update Final Report Template",
                f"Overwrite template '{name}' with the current layout?",
            )
        except Exception:
            confirm = False
        if not confirm:
            return
        presets[name] = copy.deepcopy(self._collect_final_report_state_from_ui())
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._refresh_final_report_template_list()
        self._final_report_template_var.set(name)

    def _delete_final_report_template(self) -> None:
        """Perform delete final report template.
        Used to keep the workflow logic localized and testable."""
        name = self._final_report_template_var.get()
        if not name or name == FINAL_REPORT_TEMPLATE_PLACEHOLDER:
            try:
                messagebox.showinfo(
                    "Final Report Templates", "Select a template to delete."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        presets = settings.setdefault("final_report_presets", {})
        if name not in presets:
            try:
                messagebox.showwarning(
                    "Final Report Templates",
                    "The selected template no longer exists.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._refresh_final_report_template_list()
            return
        confirm = False
        try:
            confirm = messagebox.askyesno(
                "Delete Final Report Template",
                f"Delete the template '{name}'?",
            )
        except Exception:
            confirm = False
        if not confirm:
            return
        try:
            del presets[name]
        except KeyError:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._refresh_final_report_template_list()
        self._final_report_template_var.set(FINAL_REPORT_TEMPLATE_PLACEHOLDER)

    def _final_report_orientation_changed(
        self, section_id: str, var: tk.StringVar
    ) -> None:
        """Perform final report orientation changed.
        Used to keep the workflow logic localized and testable."""
        orientation_state = settings.setdefault("final_report", {}).setdefault(
            "section_orientation", {}
        )
        orientation_state[section_id] = var.get()
        self._refresh_final_report_preview()

    def _final_report_section_layout_changed(self) -> None:
        """Purpose: React to per-section layout control changes.
        Why: Keep the report preview aligned with section header/caption toggles.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            - Schedules a preview refresh.
        Exceptions:
            - None; this method is a simple UI callback.
        """
        self._schedule_final_report_preview_refresh()

    def _refresh_final_report_preview(self) -> None:
        """Refresh final report preview.
        Used to sync final report preview with current settings."""
        if getattr(self, "_final_report_preview_after_id", None) is not None:
            self._final_report_preview_after_id = None
        state = self._collect_final_report_state_from_ui()
        settings["final_report"].clear()
        settings["final_report"].update(copy.deepcopy(state))
        title = state.get("title", FINAL_REPORT_DEFAULT_STATE["title"])
        segments: List[str] = []
        segments.append(title)
        segments.append("=" * max(len(title), 1))
        segments.append("")
        segments.append("Layout:")
        segments.append(f"- Global mode: {state['global_layout_mode']}")
        segments.append(f"- Font scale: {state['font_scale']:.2f}")
        segments.append(f"- Margins: {state['margin_in']:.2f} in")
        segments.append(
            f"- Page numbers: {'yes' if state['show_page_numbers'] else 'no'}"
        )
        segments.append(
            f"- Section headers: {'yes' if state['show_section_headers'] else 'no'}"
        )
        segments.append("")
        segments.append("Narrative:")
        segments.append(
            "- User narrative present"
            if state["narrative"]
            else "- Narrative not provided"
        )
        segments.append("")
        segments.append("Sections in order:")
        sequence = self._final_report_compute_layout_sequence(state)
        if sequence:
            # Iterate over indexed elements from sequence, 1 to apply the per-item logic.
            for idx, entry in enumerate(sequence, 1):
                metadata = entry.get("metadata") or {}
                label = metadata.get("label") or entry.get("section_id") or "Summary"
                page_type = entry.get("page_type", "text")
                orientation = entry.get("orientation", "portrait")
                type_label = {
                    "title": "Title",
                    "figure": "Figure",
                    "table": "Table",
                    "text": "Text",
                }.get(page_type, page_type.title())
                segments.append(
                    f"{idx}. {label} ({type_label}, orientation: {orientation})"
                )
        else:
            segments.append("No sections selected.")
        preview = "\n".join(segments)
        widget = getattr(self, "_final_report_preview_text", None)
        if widget is not None:
            widget.configure(state="normal")
            widget.delete("1.0", "end")
            widget.insert("1.0", preview)
            widget.configure(state="disabled")
        self._final_report_render_layout_preview(sequence)

    def _schedule_final_report_preview_refresh(self) -> None:
        """Schedule final report preview refresh.
        Used to queue final report preview refresh without blocking the UI."""
        after_id = getattr(self, "_final_report_preview_after_id", None)
        if after_id is not None:
            try:
                self.after_cancel(after_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        try:
            self._final_report_preview_after_id = self.after_idle(
                self._refresh_final_report_preview
            )
        except Exception:
            self._final_report_preview_after_id = None
            self._refresh_final_report_preview()

    def _final_report_render_layout_preview(
        self, sequence: List[Dict[str, Any]]
    ) -> None:
        """Render layout preview.
        Used by final report workflows to render layout preview."""
        canvas = getattr(self, "_final_report_preview_canvas", None)
        if canvas is None:
            return
        canvas.delete("all")
        canvas.update_idletasks()
        width = canvas.winfo_width() or int(canvas["width"])
        if width <= 1:
            width = 360
        spacing = 14
        x = spacing
        y = spacing
        max_row_height = 0
        # Iterate over indexed elements from sequence to apply the per-item logic.
        for idx, entry in enumerate(sequence):
            orientation = entry.get("orientation", "portrait")
            if orientation == "landscape":
                thumb_width, thumb_height = 110, 70
            else:
                thumb_width, thumb_height = 70, 110
            if x + thumb_width + spacing > width and x > spacing:
                x = spacing
                y += max_row_height + spacing
                max_row_height = 0
            canvas.create_rectangle(
                x,
                y,
                x + thumb_width,
                y + thumb_height,
                fill="#fdfdfd",
                outline="#777777",
            )
            label = self._final_report_preview_page_label(entry, idx + 1)
            canvas.create_text(
                x + thumb_width / 2,
                y + thumb_height / 2,
                text=label,
                font=("TkDefaultFont", 9, "bold"),
                fill="#222222",
            )
            orientation_label = "L" if orientation == "landscape" else "P"
            canvas.create_text(
                x + thumb_width - 4,
                y + thumb_height - 4,
                text=orientation_label,
                anchor="se",
                font=("TkDefaultFont", 7),
                fill="#555555",
            )
            x += thumb_width + spacing
            max_row_height = max(max_row_height, thumb_height)
        if not sequence:
            canvas.create_text(
                width / 2,
                40,
                text="No pages selected",
                fill="#888888",
                font=("TkDefaultFont", 10, "italic"),
            )
        bbox = canvas.bbox("all")
        if bbox is None:
            bbox = (0, 0, width, y + max_row_height + spacing)
        canvas.configure(scrollregion=bbox)

    def _final_report_preview_page_label(
        self, entry: Dict[str, Any], page_number: int
    ) -> str:
        """Purpose: Build a short label for the layout preview thumbnail.
        Why: Provide a quick page-type summary in the preview strip.
        Args:
            entry (Dict[str, Any]): Layout entry describing a page.
            page_number (int): 1-based page index for display.
        Returns:
            str: Label string for the preview thumbnail.
        Side Effects:
            - None.
        Exceptions:
            - None; unknown page types fall back to title-cased keys.
        """
        page_type = entry.get("page_type", "text")
        type_map = {
            "title": "Title",
            "figure": "Figure",
            "table": "Table",
            "text": "Text",
            "caption": "Caption",
        }
        type_label = type_map.get(page_type, page_type.title())
        return f"{page_number}. {type_label}"

    def _slugify_final_report_title(self, title: str) -> str:
        """Perform slugify final report title.
        Used to keep the workflow logic localized and testable."""
        normalized = unicodedata.normalize("NFKD", title)
        slug = "".join(ch for ch in normalized if ch.isalnum() or ch in (" ", "-", "_"))
        slug = slug.replace(" ", "-").strip("-").lower()
        if not slug:
            slug = "final-report"
        return slug

    def _final_report_page_dimensions(self, orientation: str) -> Tuple[float, float]:
        """Perform final report page dimensions.
        Used to keep the workflow logic localized and testable."""
        if orientation == "landscape":
            return (11.0, 8.5)
        return (8.5, 11.0)

    def _final_report_resolved_orientation(
        self, section_id: str, state: Dict[str, Any]
    ) -> str:
        """Perform final report resolved orientation.
        Used to keep the workflow logic localized and testable."""
        state = self._final_report_safe_state(state)
        orientation = state.get("section_orientation", {}).get(section_id, "inherit")
        if orientation in ("portrait", "landscape"):
            return orientation
        if section_id == "combined_plot":
            return "landscape"
        layout_mode = state.get("global_layout_mode", "mixed_pages")
        if layout_mode == "single_page_portrait":
            return "portrait"
        if (
            layout_mode == "plots_landscape_pages"
            and FINAL_REPORT_SECTION_METADATA.get(section_id, {}).get("type")
            == "figure"
        ):
            return "landscape"
        return "portrait"

    def _final_report_safe_state(
        self, state: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Perform final report safe state.
        Used to keep the workflow logic localized and testable."""
        if isinstance(state, dict):
            return state
        return FINAL_REPORT_DEFAULT_STATE

    def _final_report_section_header_enabled(
        self, section_id: Optional[str], state: Dict[str, Any]
    ) -> bool:
        """Purpose: Decide whether to draw a section header for a page.
        Why: Centralize global and per-section header toggles.
        Args:
            section_id (Optional[str]): Section identifier for lookup.
            state (Dict[str, Any]): Final report settings state.
        Returns:
            bool: True if a header should be rendered for the section.
        Side Effects:
            - None.
        Exceptions:
            - None; invalid state falls back to defaults.
        """
        if not section_id:
            return False
        state = self._final_report_safe_state(state)
        if not state.get("show_section_headers", True):
            return False
        header_state = state.get("section_header_enabled", {})
        default_value = FINAL_REPORT_SECTION_HEADER_DEFAULTS.get(section_id, True)
        return bool(header_state.get(section_id, default_value))

    def _final_report_section_caption_enabled(
        self, section_id: Optional[str], state: Dict[str, Any]
    ) -> bool:
        """Purpose: Decide whether a section caption should be used.
        Why: Apply per-section caption enablement consistently.
        Args:
            section_id (Optional[str]): Section identifier for lookup.
            state (Dict[str, Any]): Final report settings state.
        Returns:
            bool: True if the caption should be generated for the section.
        Side Effects:
            - None.
        Exceptions:
            - None; invalid state falls back to defaults.
        """
        if not section_id:
            return False
        state = self._final_report_safe_state(state)
        caption_state = state.get("section_caption_enabled", {})
        default_value = FINAL_REPORT_SECTION_CAPTION_DEFAULTS.get(section_id, False)
        return bool(caption_state.get(section_id, default_value))

    def _final_report_section_caption_placement(
        self, section_id: Optional[str], state: Dict[str, Any]
    ) -> str:
        """Purpose: Resolve the caption placement for a section.
        Why: Keep caption placement logic consistent across preview and export.
        Args:
            section_id (Optional[str]): Section identifier for lookup.
            state (Dict[str, Any]): Final report settings state.
        Returns:
            str: Caption placement label ("Same Page" or "Next Page").
        Side Effects:
            - None.
        Exceptions:
            - None; invalid state falls back to defaults.
        """
        if not section_id:
            return FINAL_REPORT_SECTION_CAPTION_PLACEMENT_DEFAULTS.get(
                section_id, "Same Page"
            )
        state = self._final_report_safe_state(state)
        placement_state = state.get("section_caption_placement", {})
        default_value = FINAL_REPORT_SECTION_CAPTION_PLACEMENT_DEFAULTS.get(
            section_id, "Same Page"
        )
        placement = placement_state.get(section_id, default_value)
        if placement not in FINAL_REPORT_CAPTION_PLACEMENTS:
            return default_value
        return placement

    def _final_report_header_band(
        self,
        state: Dict[str, Any],
        margins: Dict[str, float],
        page_size: Tuple[float, float],
        *,
        include_group_label: bool,
        include_section_header: bool,
        include_table_caption: bool,
    ) -> float:
        """Purpose: Compute the vertical band needed for headers.
        Why: Reserve space above plots/tables to prevent overlap with header text.
        Args:
            state (Dict[str, Any]): Final report settings state.
            margins (Dict[str, float]): Normalized margin values for the page.
            page_size (Tuple[float, float]): Page size in inches (width, height).
            include_group_label (bool): Whether the group label will be drawn.
            include_section_header (bool): Whether the section header will be drawn.
            include_table_caption (bool): Whether a table caption is drawn at the top.
        Returns:
            float: Header band height in normalized figure coordinates.
        Side Effects:
            - None.
        Exceptions:
            - None; returns a best-effort computed band height.
        """
        state = self._final_report_safe_state(state)
        page_height = page_size[1]
        font_scale = state.get("font_scale", 1.0)
        top_anchor = 1 - margins["top"]

        def _line_height_norm(font_size: float, spacing: float = 1.2) -> float:
            """Purpose: Convert a font size to normalized line height.
            Why: Estimate header band height using font size and page height.
            Args:
                font_size (float): Font size in points.
                spacing (float): Line spacing multiplier.
            Returns:
                float: Normalized line height in figure coordinates.
            Side Effects:
                - None.
            Exceptions:
                - None; uses safe defaults for small page heights.
            """
            return (font_size * spacing) / 72.0 / max(page_height, 0.1)

        header_band = 0.0
        if include_group_label:
            group_font_size = max(10.0, 11.0 * font_scale)
            group_y = min(0.98, top_anchor + 0.02)
            group_bottom = group_y - _line_height_norm(group_font_size)
            header_band = max(header_band, max(0.0, top_anchor - group_bottom))
        if include_section_header:
            header_font_size = max(13.0, 14.0 * font_scale)
            header_y = top_anchor - 0.02
            header_line_y = header_y - 0.01
            header_bottom = min(
                header_line_y, header_y - _line_height_norm(header_font_size)
            )
            header_band = max(header_band, top_anchor - header_bottom)
        if include_table_caption:
            caption_font_size = max(9.0, 10.0 * font_scale)
            caption_y = top_anchor + 0.005
            caption_bottom = caption_y - _line_height_norm(caption_font_size)
            header_band = max(header_band, max(0.0, top_anchor - caption_bottom))
        if header_band > 0:
            header_band += 0.004
        return header_band

    def _final_report_content_rect(
        self,
        state: Dict[str, Any],
        page_size: Tuple[float, float],
        *,
        has_caption: bool,
        include_group_label: bool,
        include_section_header: bool,
        include_table_caption: bool,
    ) -> Tuple[float, float, float, float]:
        """Purpose: Compute the content rectangle for report elements.
        Why: Ensure plots and tables respect margins, headers, captions, and footers.
        Args:
            state (Dict[str, Any]): Final report settings state.
            page_size (Tuple[float, float]): Page size in inches (width, height).
            has_caption (bool): Whether a bottom caption band is reserved.
            include_group_label (bool): Whether the group label will be drawn.
            include_section_header (bool): Whether the section header will be drawn.
            include_table_caption (bool): Whether a table caption is drawn at the top.
        Returns:
            Tuple[float, float, float, float]: (left, bottom, right, top) normalized.
        Side Effects:
            - None.
        Exceptions:
            - None; returns a best-effort rectangle.
        """
        state = self._final_report_safe_state(state)
        margins = self._final_report_page_margins(state, page_size)
        caption_space = margins["caption"] if has_caption else 0.0
        header_band = self._final_report_header_band(
            state,
            margins,
            page_size,
            include_group_label=include_group_label,
            include_section_header=include_section_header,
            include_table_caption=include_table_caption,
        )
        left = margins["left"]
        right = 1 - margins["right"]
        bottom = margins["bottom"] + margins["footer"] + caption_space
        top = (1 - margins["top"]) - header_band
        if top <= bottom + 0.02:
            top = min(0.98, bottom + 0.05)
        return (left, bottom, right, top)

    def _final_report_fit_axes_to_rect(
        self, fig: Figure, rect: Tuple[float, float, float, float]
    ) -> None:
        """Purpose: Fit existing axes into a target rectangle.
        Why: Preserve multi-axis layouts (e.g., combined plots) without tight_layout.
        Args:
            fig (Figure): Matplotlib figure containing axes to reposition.
            rect (Tuple[float, float, float, float]): Target rect in figure coords.
        Returns:
            None.
        Side Effects:
            - Updates axes positions on the figure.
        Exceptions:
            - Best-effort; returns early on invalid axes geometry.
        """
        if fig is None:
            return
        axes = [ax for ax in fig.axes if isinstance(ax, Axes)]
        if not axes:
            return
        try:
            union = Bbox.union([ax.get_position() for ax in axes])
        except Exception:
            return
        if union.width <= 0 or union.height <= 0:
            return
        target_left, target_bottom, target_right, target_top = rect
        target_width = max(0.01, target_right - target_left)
        target_height = max(0.01, target_top - target_bottom)
        scale_x = target_width / union.width
        scale_y = target_height / union.height
        # Rescale each axis into the content rectangle without reflow.
        for ax in axes:
            try:
                pos = ax.get_position()
                new_left = target_left + (pos.x0 - union.x0) * scale_x
                new_bottom = target_bottom + (pos.y0 - union.y0) * scale_y
                new_width = pos.width * scale_x
                new_height = pos.height * scale_y
                ax.set_position([new_left, new_bottom, new_width, new_height])
            except Exception:
                continue

    def _final_report_table_style_settings(self, state: Dict[str, Any]) -> Dict[str, float]:
        """Purpose: Resolve table style preset settings.
        Why: Keep table font sizing and padding consistent per preset.
        Args:
            state (Dict[str, Any]): Final report settings state.
        Returns:
            Dict[str, float]: Style settings for tables (font size, padding, ratios).
        Side Effects:
            - None.
        Exceptions:
            - None; invalid presets fall back to defaults.
        """
        state = self._final_report_safe_state(state)
        preset = state.get(
            "table_style_preset", FINAL_REPORT_DEFAULT_STATE["table_style_preset"]
        )
        if preset not in FINAL_REPORT_TABLE_STYLE_PRESETS:
            preset = FINAL_REPORT_DEFAULT_STATE["table_style_preset"]
        font_scale = state.get("font_scale", 1.0)
        preset_scale = {"Compact": 0.92, "Normal": 1.0, "Large": 1.08}.get(preset, 1.0)
        return {
            "font_size": max(7.0, 8.5 * font_scale * preset_scale),
            "min_font_size": max(6.0, 7.0 * font_scale * preset_scale),
            "cell_pad": {"Compact": 0.02, "Normal": 0.04, "Large": 0.06}.get(
                preset, 0.04
            ),
            "line_spacing": {"Compact": 1.05, "Normal": 1.15, "Large": 1.2}.get(
                preset, 1.15
            ),
            "width_ratio": {"Compact": 0.95, "Normal": 0.92, "Large": 0.9}.get(
                preset, 0.92
            ),
            "height_ratio": {"Compact": 0.92, "Normal": 0.9, "Large": 0.88}.get(
                preset, 0.9
            ),
        }

    def _final_report_build_export_image_page(
        self,
        plot_kind: str,
        plot_id: str,
        page_size: Tuple[float, float],
        state: Dict[str, Any],
        *,
        include_group_label: bool,
        include_section_header: bool,
        has_caption: bool,
    ) -> Optional[Figure]:
        """Purpose: Render an export plot into a report page as an image.
        Why: Preserve export layout for complex plots while reserving report bands.
        Args:
            plot_kind (str): Plot kind passed to the export renderer.
            plot_id (str): Plot identifier for layout/profile application.
            page_size (Tuple[float, float]): Page size in inches (width, height).
            state (Dict[str, Any]): Final report settings state.
            include_group_label (bool): Whether the group label will be drawn.
            include_section_header (bool): Whether the section header will be drawn.
            has_caption (bool): Whether a bottom caption band is reserved.
        Returns:
            Optional[Figure]: A report figure with the plot image embedded.
        Side Effects:
            - Creates and closes an intermediate export figure.
        Exceptions:
            - Best-effort; returns None if rendering fails.
        """
        export_fig = self._build_export_figure_for_final_report(
            plot_kind, plot_id, page_size
        )
        if export_fig is None:
            return None
        try:
            canvas = FigureCanvasAgg(export_fig)
            export_fig.set_canvas(canvas)
            canvas.draw()
            image = np.asarray(canvas.buffer_rgba())
        except Exception:
            try:
                plt.close(export_fig)
            except Exception:
                pass
            return None
        try:
            plt.close(export_fig)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        report_fig = Figure(figsize=page_size)
        ax = report_fig.add_subplot(111)
        ax.axis("off")
        rect = self._final_report_content_rect(
            state,
            page_size,
            has_caption=has_caption,
            include_group_label=include_group_label,
            include_section_header=include_section_header,
            include_table_caption=False,
        )
        left, bottom, right, top = rect
        content_width = max(0.01, right - left)
        content_height = max(0.01, top - bottom)
        img_height = float(image.shape[0]) if image is not None else 1.0
        img_width = float(image.shape[1]) if image is not None else 1.0
        img_aspect = img_width / img_height if img_height else 1.0
        content_aspect = content_width / content_height if content_height else 1.0
        if img_aspect >= content_aspect:
            fit_width = content_width
            fit_height = content_width / img_aspect if img_aspect else content_height
        else:
            fit_height = content_height
            fit_width = content_height * img_aspect
        fit_left = left + (content_width - fit_width) / 2.0
        fit_bottom = bottom + (content_height - fit_height) / 2.0
        ax.set_position((fit_left, fit_bottom, fit_width, fit_height))
        ax.imshow(image)
        ax.set_xlim(0, img_width)
        ax.set_ylim(img_height, 0)
        report_fig._gl260_report_skip_tight_layout = True
        return report_fig

    def _final_report_build_caption_page(
        self, caption_text: str, page_size: Tuple[float, float], state: Dict[str, Any]
    ) -> Figure:
        """Purpose: Build a caption-only report page.
        Why: Support captions placed on the next page without layout overlap.
        Args:
            caption_text (str): Caption content to render.
            page_size (Tuple[float, float]): Page size in inches (width, height).
            state (Dict[str, Any]): Final report settings state.
        Returns:
            Figure: Matplotlib figure containing the caption text.
        Side Effects:
            - Creates a new Matplotlib figure.
        Exceptions:
            - None; best-effort rendering for provided text.
        """
        fig = Figure(figsize=page_size)
        state = self._final_report_safe_state(state)
        margins = self._final_report_page_margins(state, page_size)
        ax = fig.add_subplot(111)
        ax.axis("off")
        caption_font_size = max(9.0, 10.0 * state.get("font_scale", 1.0))
        caption_text = self._final_report_sanitize_text(caption_text or "")
        start_y = 1 - margins["top"] - 0.02
        self._final_report_render_justified_text(
            fig,
            page_size,
            caption_text,
            margins["left"],
            start_y,
            1 - margins["left"] - margins["right"],
            1.15,
            self._final_report_font_properties(caption_font_size),
            caption_font_size,
            hyphenate=True,
            y_limit=margins["bottom"] + margins["footer"],
        )
        return fig

    def _final_report_sanitize_text(self, text: str) -> str:
        """Sanitize text.
        Used by final report workflows to sanitize text."""
        if not text:
            return text

        # Closure captures _final_report_sanitize_text local context to keep helper logic scoped and invoked directly within _final_report_sanitize_text.
        def _sub_replace(match: re.Match[str]) -> str:
            """Perform sub replace.
            Used to keep the workflow logic localized and testable."""
            digits = "".join(_FINAL_REPORT_SUBSCRIPT_MAP.get(ch, "") for ch in match.group(0))
            return f"$_{digits}$" if digits else match.group(0)

        # Closure captures _final_report_sanitize_text local context to keep helper logic scoped and invoked directly within _final_report_sanitize_text.
        def _sup_replace(match: re.Match[str]) -> str:
            """Perform sup replace.
            Used to keep the workflow logic localized and testable."""
            digits = "".join(_FINAL_REPORT_SUPERSCRIPT_MAP.get(ch, "") for ch in match.group(0))
            return f"$^{digits}$" if digits else match.group(0)

        value = _FINAL_REPORT_SUBSCRIPT_RE.sub(_sub_replace, text)
        return _FINAL_REPORT_SUPERSCRIPT_RE.sub(_sup_replace, value)

    def _final_report_build_cycle_plot_figure(
        self, page_size: Tuple[float, float]
    ) -> Optional[Figure]:
        """Build cycle plot figure.
        Used by final report workflows to build cycle plot figure."""
        if self.df is None:
            return None
        return self._build_export_figure_for_final_report(
            "fig_peaks",
            self._plot_key_to_plot_id("fig_peaks"),
            page_size,
        )

    def _build_cycle_timeline_export_figure(
        self,
        page_size: Tuple[float, float],
        *,
        workflow_key: Optional[str] = None,
    ) -> Optional[Figure]:
        """Build cycle timeline export figure.
        Purpose: Assemble the export-grade timeline figure for plots and reports.
        Why: Ensure exports match the on-screen timeline styling and legend placement.
        Inputs:
            page_size (Tuple[float, float]): Target figure size in inches.
            workflow_key (Optional[str]): Workflow to source timeline data from.
        Outputs:
            Optional[Figure]: Matplotlib figure, or None if no timeline data exists.
        Side Effects:
            - Creates a new Matplotlib figure and axes.
            - Applies legend placement from the Planning timeline when available.
        Exceptions:
            - Best-effort; returns None when data is missing or invalid.
        """
        timeline = []
        structured = getattr(self, "_sol_last_structured", None)
        if structured is not None:
            timeline = getattr(structured, "cycle_timeline", None) or []
        workflow = workflow_key or self._current_solubility_workflow()
        if not timeline:
            result = self._get_cycle_result_for_workflow(workflow)
            timeline = (result or {}).get("timeline", []) or []
        reaction_guidance = getattr(self, "_sol_reaction_guidance", {}) or {}
        timeline = list(timeline or [])
        if workflow == "Reprocessing" and not timeline:
            reproc = reaction_guidance.get("reprocessing_workflow") or {}
            baseline_spec = reproc.get("baseline_spec")
            target_spec = reproc.get("target_spec")
            recommended_co2 = reproc.get("recommended_co2_g")
            target_ph_hint = reproc.get("target_ph")
            fail_ph = reproc.get("failing_ph")

            def _spec_value(spec: Any, key: str, default: Any = None) -> Any:
                """Perform spec value.
                Used to keep the workflow logic localized and testable."""
                if spec is None:
                    return default
                if isinstance(spec, Mapping):
                    return spec.get(key, default)
                return getattr(spec, key, default)

            def _spec_fractions(spec: Any) -> Dict[str, float]:
                """Perform spec fractions.
                Used to keep the workflow logic localized and testable."""
                if spec is None:
                    return {}
                if isinstance(spec, Mapping):
                    return spec.get("fractional_carbon", {}) or spec.get(
                        "fractions", {}
                    )
                return getattr(spec, "fractional_carbon", {}) or {}

            def _spec_moles(spec: Any) -> Dict[str, float]:
                """Perform spec moles.
                Used to keep the workflow logic localized and testable."""
                if spec is None:
                    return {}
                if isinstance(spec, Mapping):
                    return spec.get("moles", {}) or {}
                return getattr(spec, "moles", {}) or {}

            preview_entries: List[Dict[str, Any]] = []
            if baseline_spec is not None:
                base_moles = _spec_moles(baseline_spec)
                preview_entries.append(
                    {
                        "cycle_id": "Fail",
                        "co2_g": 0.0,
                        "co2_mass_g": 0.0,
                        "co2_to_target_g": recommended_co2,
                        "solution_ph": _spec_value(
                            baseline_spec, "ph", default=fail_ph
                        ),
                        "fractions": _spec_fractions(baseline_spec),
                        "solid_na2co3_g": base_moles.get("CO3^2-", 0.0)
                        * SOL_MW_NA2CO3,
                        "solid_nahco3_g": base_moles.get("HCO3-", 0.0)
                        * SOL_MW_NAHCO3,
                    }
                )
            if target_spec is not None:
                target_moles = _spec_moles(target_spec)
                preview_entries.append(
                    {
                        "cycle_id": "Pass",
                        "co2_g": recommended_co2 or 0.0,
                        "co2_mass_g": recommended_co2 or 0.0,
                        "co2_to_target_g": 0.0,
                        "solution_ph": _spec_value(
                            target_spec, "ph", default=target_ph_hint
                        ),
                        "fractions": _spec_fractions(target_spec),
                        "solid_na2co3_g": target_moles.get("CO3^2-", 0.0)
                        * SOL_MW_NA2CO3,
                        "solid_nahco3_g": target_moles.get("HCO3-", 0.0)
                        * SOL_MW_NAHCO3,
                    }
                )
            if preview_entries:
                timeline = preview_entries
        if not timeline:
            return None
        prefs = self._get_cycle_plot_prefs()
        fig = Figure(figsize=page_size)
        ax = fig.add_subplot(111)
        ax2 = ax.twinx()
        ax3 = ax.twinx()
        ax.set_xlabel(r"Total CO$_2$ added (g)", fontsize=11, labelpad=8)
        ax.set_ylabel("Carbon species (%)", fontsize=11, labelpad=10)
        ax.tick_params(axis="both", labelsize=9, pad=4)
        ax2.set_ylabel("Predicted pH", fontsize=11, labelpad=10, rotation=-90)
        ax2.spines["right"].set_position(("axes", 1.02))
        ax2.yaxis.set_label_coords(1.08, 0.5)
        ax2.tick_params(axis="both", labelsize=9, pad=4)
        ax3.set_ylabel("Headspace pCO2 (atm)", fontsize=11, labelpad=10, rotation=-90)
        ax3.spines["right"].set_position(("axes", 1.12))
        ax3.yaxis.set_label_coords(1.18, 0.5)
        ax3.tick_params(axis="both", labelsize=8, pad=3)
        xs = []
        h2co3_vals = []
        hco3_vals = []
        co3_vals = []
        ph_values = []
        pco2_values: List[float] = []
        # Iterate over timeline to apply the per-item logic.
        for entry in timeline:
            xs.append(
                _safe_float(entry.get("co2_g"))
                or _safe_float(entry.get("co2_mass_g"))
                or 0.0
            )
            fractions = entry.get("fractions") or {}
            h2co3_vals.append(fractions.get("H2CO3", 0.0) * 100.0)
            hco3_vals.append(fractions.get("HCO3-", 0.0) * 100.0)
            co3_vals.append(fractions.get("CO3^2-", 0.0) * 100.0)
            ph_val = entry.get("solution_ph")
            ph_values.append(ph_val if ph_val is not None else float("nan"))
            try:
                pco2_values.append(float(entry.get("pco2_atm")))
            except Exception:
                pco2_values.append(float("nan"))
        if not xs:
            return None
        show_legend = bool(prefs.get("show_legend"))
        if workflow == "Planning":
            species = [
                ("Carbonic acid (H2CO3)", h2co3_vals, "#55a868"),
                ("Bicarbonate (HCO3-)", hco3_vals, "#4c72b0"),
                ("Carbonate (CO3^2-)", co3_vals, "#dd8452"),
            ]
        else:
            species = [
                ("H2CO3", h2co3_vals, "#55a868"),
                ("HCO3-", hco3_vals, "#4c72b0"),
                ("CO3^2-", co3_vals, "#dd8452"),
            ]
        ax.stackplot(
            xs,
            h2co3_vals,
            hco3_vals,
            co3_vals,
            colors=[color for _, _, color in species],
            alpha=0.35,
        )
        # Iterate over species to apply the per-item logic.
        for label, values, color in species:
            ax.plot(
                xs,
                [val if val is not None else 0.0 for val in values],
                label=label,
                color=color,
            )
        if prefs.get("species_min") is not None or prefs.get("species_max") is not None:
            ax.set_ylim(prefs.get("species_min", 0.0), prefs.get("species_max", 100.0))
        else:
            ax.set_ylim(0, 100)
        ax.grid(True, alpha=0.3)
        ax2.plot(
            xs,
            [v if v is not None else float("nan") for v in ph_values],
            color="#c44e52",
            marker="o",
            label="Predicted pH",
        )
        ax3.plot(
            xs,
            pco2_values,
            color="#1b7b6b",
            marker="s",
            linestyle="--",
            linewidth=1.2,
            label="Headspace pCO2 (atm)" if workflow == "Planning" else "pCO2 (atm)",
        )
        if workflow == "Analysis":
            reference = getattr(self, "_analysis_reference_trace", None) or {}
            ref_x = reference.get("x_co2_g_series") or []
            ref_ph = reference.get("ph_series") or []
            ref_pairs = [
                (x_val, ph_val)
                # Iterate to apply the per-item logic.
                for x_val, ph_val in zip(ref_x, ref_ph)
                if x_val is not None
                and ph_val is not None
                and math.isfinite(x_val)
                and math.isfinite(ph_val)
            ]
            if ref_pairs:
                ref_xs, ref_phs = zip(*ref_pairs)
                ax2.plot(
                    ref_xs,
                    ref_phs,
                    color="#7a7a7a",
                    alpha=0.35,
                    linewidth=1.4,
                    label="Planning reference",
                    zorder=2,
                )
            marker = getattr(self, "_analysis_overlay_marker", None) or {}
            marker_x = marker.get("x")
            marker_ph = marker.get("ph")
            if (
                marker_x is not None
                and marker_ph is not None
                and math.isfinite(marker_x)
                and math.isfinite(marker_ph)
            ):
                ax2.scatter(
                    [marker_x],
                    [marker_ph],
                    s=140,
                    color="#f28e2b",
                    edgecolor="#222222",
                    linewidths=0.8,
                    label="Current state",
                    zorder=4,
                )
                label = marker.get("label") or "Current state (cycle-derived)"
                ax2.annotate(
                    label,
                    (marker_x, marker_ph),
                    textcoords="offset points",
                    xytext=(0, 12),
                    ha="center",
                    fontsize=8,
                    color="#333333",
                )
        if prefs.get("ph_min") is not None or prefs.get("ph_max") is not None:
            ax2.set_ylim(prefs.get("ph_min", 6.0), prefs.get("ph_max", 14.5))
        else:
            ax2.set_ylim(6.0, 14.5)
        target_ph = reaction_guidance.get("target_ph")
        if target_ph is not None:
            ax2.axhline(target_ph, color="#2a9d8f", linestyle="--", linewidth=1.25)
            ax2.text(
                0.98,
                target_ph,
                f"Target pH {target_ph:.2f}",
                va="bottom",
                ha="right",
                fontsize=7,
                color="#2a9d8f",
            )
        # Iterate over paired elements from multiple sequences to apply the per-item logic.
        for x, ph, entry in zip(xs, ph_values, timeline):
            if not math.isfinite(ph):
                continue
            ax2.annotate(
                f"{entry.get('cycle_id')}",
                (x, ph),
                textcoords="offset points",
                xytext=(0, 6),
                ha="center",
                fontsize=7,
            )
        if workflow == "Planning":
            # Planning timeline legend is consolidated and draggable for clarity.
            handles, labels = self._collect_planning_timeline_legend_entries(
                (ax, ax2, ax3)
            )
            if handles:
                legend_loc = self._planning_timeline_legend_loc() or "upper left"
                legend = ax.legend(
                    handles=handles, labels=labels, loc=legend_loc, fontsize=8
                )
                layout_mgr = getattr(fig, "_gl260_layout_manager", None)
                if layout_mgr is not None:
                    layout_mgr.register_artist("plot_legend", legend)
        elif show_legend:
            ax.legend(loc="upper left", fontsize=8)
            ax2.legend(loc="upper right", fontsize=8)
            ax3.legend(loc="center right", fontsize=8)
        title_text = (prefs.get("export_title") or "").strip()
        if title_text:
            font_family = (settings.get("font_family") or "").strip()
            _center_titles_to_axes_union(
                fig,
                list(fig.axes),
                None,
                title_text,
                None,
                13,
                font_family,
                0.0,
                0.0,
                suptitle_y=0.99,
            )
        # Iterate over indexed elements from fig.axes[1 to apply the per-item logic.
        for idx, axis in enumerate(fig.axes[1:], start=1):
            try:
                axis.yaxis.get_label().set_labelpad(18 + 4 * idx)
                axis.yaxis.set_label_coords(1.02 + 0.1 * idx, 0.5)
            except Exception:
                continue
        fig.subplots_adjust(left=0.08, right=0.88, top=0.90, bottom=0.12)
        return fig

    def _build_export_figure_for_final_report(
        self,
        plot_kind: str,
        plot_id: Optional[str],
        page_size: Tuple[float, float],
    ) -> Optional[Figure]:
        """Purpose: Build an export-quality figure for the Final Report.
        Why: Ensure report pages reuse the export pipeline with consistent styling.
        Args:
            plot_kind (str): Plot key passed to the renderer (e.g., fig1/combined).
            plot_id (Optional[str]): Plot identifier used for layout/profile rules.
            page_size (Tuple[float, float]): Page size in inches (width, height).
        Returns:
            Optional[Figure]: Matplotlib figure ready for report layout or None.
        Side Effects:
            - Applies layout profiles and plot element settings to the figure.
            - Initializes an Agg canvas and forces a draw for layout stability.
        Exceptions:
            - Best-effort; returns None if rendering fails.
        """
        fig = self.render_plot(
            plot_kind or "",
            target="export",
            mode="export",
            plot_id=plot_id,
            fig_size=page_size,
        )
        if fig is None:
            return None
        plot_elements_applied = bool(
            getattr(fig, "_gl260_plot_elements_applied", False)
        )
        if plot_id and not plot_elements_applied:
            try:
                _apply_layout_profile_to_figure(fig, plot_id, "export")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                self._apply_plot_elements(fig, plot_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            fig._gl260_plot_elements_applied = True
        try:
            self._apply_gl260_legend_sizing(fig, plot_id=plot_id, plot_key=plot_kind)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            from matplotlib.backends.backend_agg import FigureCanvasAgg
        except Exception:
            FigureCanvasAgg = None
        export_canvas = None
        try:
            export_canvas = fig.canvas
        except Exception:
            export_canvas = None
        if FigureCanvasAgg is not None and (
            export_canvas is None or not isinstance(export_canvas, FigureCanvasAgg)
        ):
            try:
                export_canvas = FigureCanvasAgg(fig)
            except Exception:
                export_canvas = getattr(fig, "canvas", None)
        if export_canvas is None:
            return fig
        try:
            fig.set_canvas(export_canvas)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._finalize_matplotlib_canvas_layout(
                canvas=export_canvas,
                fig=fig,
                tk_widget=None,
                keep_export_size=True,
                trigger_resize_event=False,
                force_draw=True,
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            export_canvas.draw()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return fig

    def _final_report_combined_preflight(self) -> Tuple[bool, str]:
        """Perform final report combined preflight.
        Used to keep the workflow logic localized and testable."""
        if self.df is None:
            return False, "Load data before generating the combined plot section."
        if not self.columns:
            return False, "Select columns on the Columns tab before generating the report."
        try:
            _, data_ctx = self._resolve_prepared_data_context(apply_globals=True)
        except Exception:
            data_ctx = {}
        series_map = data_ctx.get("series") or {}
        selected_columns = data_ctx.get("selected_columns") or globals().get(
            "selected_columns", {}
        )
        x_values = series_map.get("x", globals().get("x"))
        y1_values = series_map.get("y1", globals().get("y1"))
        missing_basic = []
        if x_values is None:
            missing_basic.append("X-axis")
        if y1_values is None:
            missing_basic.append("Primary Y")
        if missing_basic:
            return (
                False,
                "Combined plot requires the following selections: "
                + ", ".join(missing_basic)
                + ".",
            )
        required_series = {
            "y1": series_map.get("y1", globals().get("y1")),
            "y3": series_map.get("y3", globals().get("y3")),
            "y2": series_map.get("y2", globals().get("y2")),
            "z": series_map.get("z", globals().get("z")),
            "z2": series_map.get("z2", globals().get("z2")),
        }
        missing_required = [
            self._combined_dataset_label(key)
            # Iterate to apply the per-item logic.
            for key, series in required_series.items()
            if series is None and _is_selected(selected_columns.get(key, key))
        ]
        if missing_required:
            return (
                False,
                "Combined plot requires the following datasets: "
                + ", ".join(missing_required)
                + ".",
            )
        return True, ""

    def _final_report_columns_ready(self) -> Tuple[bool, str]:
        """Perform final report columns ready.
        Used to keep the workflow logic localized and testable."""
        if getattr(self, "_apply_columns_task_id", None) is not None:
            return (
                False,
                "Column selection is still applying. Wait for it to complete before generating the report.",
            )
        if not getattr(self, "_columns_applied", False):
            return False, "Apply Column Selection before generating the Final Report."
        last_applied = getattr(self, "_last_applied_columns", None)
        if isinstance(last_applied, dict):
            current = dict(self.columns or {})
            if current != last_applied:
                self._columns_applied = False
                self._update_apply_columns_indicator("pending")
                return (
                    False,
                    "Column selection changed since it was last applied. Apply Column Selection again before generating the report.",
                )
        return True, ""

    def _final_report_combined_title_override(self, state: Dict[str, Any]) -> str:
        """Perform final report combined title override.
        Used to keep the workflow logic localized and testable."""
        override = self._final_report_sanitize_text(
            state.get("combined_plot_title_override", "").strip()
        )
        return _svg_safe_text(override)

    def _combined_export_cache_key(
        self,
        *,
        fig_size: Tuple[float, float],
        export_profile: str,
        title_override: str,
    ) -> Optional[Tuple[Any, ...]]:
        """Export cache key.
        Used by combined workflows to export cache key."""
        try:
            data_fingerprint, data_ctx = self._resolve_prepared_data_context(
                apply_globals=True
            )
            _, overlay_ctx = self._resolve_cycle_context(data_ctx, data_fingerprint)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return None
        gates_ctx = {
            "show_cycle_markers": bool(
                self.show_cycle_markers_on_core.get()
                if hasattr(self, "show_cycle_markers_on_core")
                else settings.get("show_cycle_markers_on_core_plots", False)
            ),
            "show_cycle_legend": bool(
                self.show_cycle_legend_on_core.get()
                if hasattr(self, "show_cycle_legend_on_core")
                else settings.get("show_cycle_legend_on_core_plots", False)
            ),
            "include_moles": bool(
                self.include_moles_core_legend.get()
                if hasattr(self, "include_moles_core_legend")
                else settings.get("include_moles_in_core_plot_legend", False)
            ),
        }
        style_ctx = {
            "scatter_config": self._gather_scatter_settings(),
            "scatter_series_configs": self._gather_series_scatter_settings(),
        }
        args = self._collect_plot_args()
        args = self._override_plot_args_gates(args, gates_ctx)
        args = self._override_plot_args_title(args)
        config = self._combined_plot_config(args, "export")
        if config is None:
            return None
        # Structure signature controls when the full figure must be rebuilt
        # (axis roles, overlays, scatter config). Data-only changes reuse axes.
        structure_sig = self._combined_structure_signature(
            config,
            args,
            cycle_overlay=overlay_ctx.get("cycle_overlay"),
            scatter_config=style_ctx.get("scatter_config"),
            scatter_series_configs=style_ctx.get("scatter_series_configs"),
        )
        layout_sig = self._combined_layout_signature(config, args, fig_size)
        return (
            export_profile,
            title_override or "",
            self._get_export_dpi(),
            data_fingerprint,
            structure_sig,
            layout_sig,
        )

    def _apply_combined_title_override(
        self, fig: Figure, title_override: str
    ) -> None:
        """Apply combined title override.
        Used to apply combined title override changes to live state."""
        if not title_override:
            return
        try:
            axes = fig.get_axes()
            if not axes:
                return
            title_state = getattr(fig, "_gl260_title_state", {}) or {}
            primary_axis = None
            # Iterate over axes to apply the per-item logic.
            for axis in axes:
                if getattr(axis, "_gl260_axis_role", None) == "primary":
                    primary_axis = axis
                    break
            if primary_axis is None:
                primary_axis = axes[0]
            primary_axis.set_title(
                title_override,
                fontsize=title_state.get(
                    "title_fs", DEFAULT_COMBINED_TITLE_FONTSIZE
                ),
                fontfamily=title_state.get(
                    "font_family",
                    (settings.get("font_family") or "").strip(),
                ),
                pad=title_state.get(
                    "title_pad_pts", DEFAULT_COMBINED_TITLE_PAD_PTS
                ),
            )
            layout_mgr = getattr(fig, "_gl260_layout_manager", None)
            if layout_mgr is not None:
                layout_mgr.solve()
                if fig.canvas is not None:
                    fig.canvas.draw()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _export_combined_plot_artifact(
        self, export_profile: str, ctx: Dict[str, Any]
    ) -> Optional[Path]:
        """Export combined plot artifact.
        Used to serialize combined plot artifact for external workflows."""
        self._final_report_combined_failure_reason = None

        ok, message = self._final_report_columns_ready()
        if not ok:
            self._final_report_combined_failure_reason = message
            return None
        ok, message = self._final_report_combined_preflight()
        if not ok:
            self._final_report_combined_failure_reason = message
            return None

        state = self._final_report_safe_state(
            ctx.get("state") or getattr(self, "_final_report_current_state", None)
        )
        override = self._final_report_combined_title_override(state)
        fig_size = ctx.get("fig_size") or (11.0, 8.5)
        cache_key = self._combined_export_cache_key(
            fig_size=fig_size,
            export_profile=export_profile,
            title_override=override,
        )
        if cache_key is None:
            self._final_report_combined_failure_reason = (
                "Combined plot export could not resolve a cache key."
            )
            return None
        cached = getattr(self, "_combined_export_artifact", None)
        if isinstance(cached, dict):
            cached_key = cached.get("key")
            cached_path = cached.get("path")
            if cached_key == cache_key and cached_path:
                try:
                    path = Path(cached_path)
                except Exception:
                    path = None
                if path is not None and path.exists():
                    return path

        fig = self.render_plot(
            plot_kind="fig_combined",
            mode="export",
            target="export",
            plot_id="fig_combined_triple_axis",
            fig_size=fig_size,
        )
        if fig is None:
            self._final_report_combined_failure_reason = (
                "Combined plot could not be generated for this run."
            )
            return None
        self._apply_combined_title_override(fig, override)
        if not self._assert_combined_export_size(fig, expected=fig_size):
            try:
                plt.close(fig)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._final_report_combined_failure_reason = (
                "Combined plot export size mismatch."
            )
            return None

        tmp_fd = None
        tmp_path = None
        try:
            tmp_fd, tmp_path = tempfile.mkstemp(
                prefix="gl260_final_report_combined_", suffix=".pdf"
            )
        except Exception as exc:
            self._final_report_combined_failure_reason = (
                f"Failed to allocate a temporary file for the combined plot: {exc}"
            )
            try:
                plt.close(fig)
            except Exception:
                pass
            return None
        if tmp_fd is not None:
            try:
                os.close(tmp_fd)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        try:
            fig.savefig(tmp_path, format="pdf", dpi=self._get_export_dpi())
        except Exception as exc:
            self._final_report_combined_failure_reason = (
                f"Combined plot export failed: {exc}"
            )
            try:
                os.remove(tmp_path)
            except Exception:
                pass
            try:
                plt.close(fig)
            except Exception:
                pass
            return None

        try:
            plt.close(fig)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:
            previous = getattr(self, "_combined_export_artifact", None)
            if isinstance(previous, dict):
                prev_path = previous.get("path")
                if prev_path and prev_path != tmp_path:
                    try:
                        Path(prev_path).unlink()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._combined_export_artifact = {"key": cache_key, "path": tmp_path}
        return Path(tmp_path)

    def _export_plot_artifact(
        self, plot_id: str, export_profile: str, ctx: Dict[str, Any]
    ) -> Optional[Path]:
        """Export plot artifact.
        Used to serialize plot artifact for external workflows."""
        if plot_id == "fig_combined_triple_axis":
            return self._export_combined_plot_artifact(export_profile, ctx)
        fig = ctx.get("figure")
        if fig is None:
            return None
        return self._final_report_export_page_pdf(fig, export_profile)

    def _final_report_export_page_pdf(
        self, fig: Figure, export_profile: str
    ) -> Optional[Path]:
        """Purpose: Export a single report page to a temporary PDF.
        Why: Provide per-page artifacts for stitched Final Report output.
        Args:
            fig (Figure): Matplotlib figure to export.
            export_profile (str): Export profile key (currently informational).
        Returns:
            Optional[Path]: Path to the exported PDF page, or None on failure.
        Side Effects:
            - Writes a temporary PDF file to disk.
            - Closes the Matplotlib figure after export.
            - Records debug/performance output when enabled.
        Exceptions:
            - Best-effort; returns None if export fails.
        """
        if fig is None:
            return None
        tmp_fd = None
        tmp_path = None
        try:
            tmp_fd, tmp_path = tempfile.mkstemp(
                prefix="gl260_final_report_page_", suffix=".pdf"
            )
        except Exception as exc:
            try:
                plt.close(fig)
            except Exception:
                pass
            self._final_report_combined_failure_reason = (
                f"Failed to allocate a temporary file: {exc}"
            )
            return None
        if tmp_fd is not None:
            try:
                os.close(tmp_fd)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._dbg("report.export", "Final report page export start path=%s", tmp_path)
        try:
            with self._perf_time("report.export", "final_report_page_pdf"):
                fig.savefig(tmp_path, format="pdf", dpi=self._get_export_dpi())
        except Exception as exc:
            self._dbg_exc("report.export", "Final report page export failed", exc)
            try:
                os.remove(tmp_path)
            except Exception:
                pass
            try:
                plt.close(fig)
            except Exception:
                pass
            return None
        try:
            plt.close(fig)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        return Path(tmp_path)

    def _final_report_confirm_degraded_combined(self, reason: str) -> bool:
        """Perform final report confirm degraded combined.
        Used to keep the workflow logic localized and testable."""
        message = (
            "Combined plot export failed:\n"
            f"{reason}\n\n"
            "Generate a degraded report without the combined plot?"
        )
        try:
            return bool(
                messagebox.askyesno(
                    "Final Report PDF",
                    message,
                    default=messagebox.NO,
                )
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return False

    def _export_combined_plot_for_final_report(self) -> Optional[Path]:
        """Export combined plot for final report.
        Used to serialize combined plot for final report for external workflows."""
        state = self._final_report_safe_state(
            getattr(self, "_final_report_current_state", None)
        )
        export_profile = state.get(
            "profile_key", FINAL_REPORT_DEFAULT_STATE["profile_key"]
        )
        return self._export_combined_plot_artifact(
            export_profile,
            {"state": state},
        )

    def _final_report_build_standard_plot(
        self, section_id: str, page_size: Tuple[float, float]
    ) -> Optional[Figure]:
        """Build standard plot.
        Used by final report workflows to build standard plot."""
        if self.df is None:
            return None
        return self._build_export_figure_for_final_report(
            section_id,
            self._plot_key_to_plot_id(section_id),
            page_size,
        )

    def _final_report_build_cycle_timeline_figure(
        self, page_size: Tuple[float, float]
    ) -> Optional[Figure]:
        """Build cycle timeline figure.
        Used by final report workflows to build cycle timeline figure."""
        return self._build_cycle_timeline_export_figure(page_size)

    def _final_report_build_table_figure(
        self,
        rows: List[Dict[str, Any]],
        columns: List[str],
        page_size: Tuple[float, float],
        state: Dict[str, Any],
        *,
        include_group_label: bool,
        include_section_header: bool,
        include_table_caption: bool,
    ) -> Optional[Figure]:
        """Purpose: Build a centered, wrapped table figure for the report.
        Why: Ensure tables are readable, centered, and never clipped in export.
        Args:
            rows (List[Dict[str, Any]]): Table row dictionaries.
            columns (List[str]): Column keys to render in order.
            page_size (Tuple[float, float]): Page size in inches (width, height).
            state (Dict[str, Any]): Final report settings state.
            include_group_label (bool): Whether the group label will be drawn.
            include_section_header (bool): Whether the section header will be drawn.
            include_table_caption (bool): Whether a table caption is drawn at the top.
        Returns:
            Optional[Figure]: Matplotlib figure with a table, or None if empty.
        Side Effects:
            - Creates a new Matplotlib figure and axes.
            - Applies font settings and sizing to table cells.
        Exceptions:
            - Best-effort; returns None if rendering fails.
        """
        if not rows or not columns:
            return None
        fig = Figure(figsize=page_size)
        ax = fig.add_subplot(111)
        ax.axis("off")
        state = self._final_report_safe_state(state)
        rect = self._final_report_content_rect(
            state,
            page_size,
            has_caption=False,
            include_group_label=include_group_label,
            include_section_header=include_section_header,
            include_table_caption=include_table_caption,
        )
        content_left, content_bottom, content_right, content_top = rect
        ax.set_position(
            (
                content_left,
                content_bottom,
                max(0.05, content_right - content_left),
                max(0.05, content_top - content_bottom),
            )
        )
        column_keys = list(columns)
        table_data_raw = [
            [
                self._final_report_sanitize_text(str(row.get(col, "")))
                if row.get(col, "") is not None
                else ""
                # Iterate to apply the per-item logic.
                for col in column_keys
            ]
            # Iterate to apply the per-item logic.
            for row in rows
        ]
        style = self._final_report_table_style_settings(state)
        table_font_size = style["font_size"]
        min_font_size = style["min_font_size"]
        line_spacing = style["line_spacing"]
        cell_pad = style["cell_pad"]
        table_width_ratio = min(0.95, max(0.9, style["width_ratio"]))
        table_height_ratio = min(0.95, max(0.85, style["height_ratio"]))
        table_bbox = (
            (1.0 - table_width_ratio) / 2.0,
            (1.0 - table_height_ratio) / 2.0,
            table_width_ratio,
            table_height_ratio,
        )

        content_width_in = page_size[0] * max(0.1, content_right - content_left)
        content_height_in = page_size[1] * max(0.1, content_top - content_bottom)
        column_lengths = []
        # Iterate over column_keys to apply the per-item logic.
        for col in column_keys:
            lengths = [len(str(col))]
            # Iterate over rows to apply the per-item logic.
            for row in rows:
                value = row.get(col, "")
                if value is None:
                    value = ""
                lengths.append(len(str(value)))
            column_lengths.append(max(4, min(max(lengths), 48)))
        total_length = sum(column_lengths) or len(column_lengths)
        column_fracs = [length / total_length for length in column_lengths]

        def _wrap_cell(text: str, max_chars: int) -> Tuple[str, int]:
            """Purpose: Wrap a cell value to a maximum character width.
            Why: Pre-wrap table text to avoid clipping and improve readability.
            Args:
                text (str): Cell text value to wrap.
                max_chars (int): Maximum characters per line for the cell.
            Returns:
                Tuple[str, int]: Wrapped text and resulting line count.
            Side Effects:
                - None.
            Exceptions:
                - None; empty text returns a single-line placeholder.
            """
            if not text:
                return "", 1
            lines = textwrap.wrap(
                text,
                width=max_chars,
                break_long_words=True,
                break_on_hyphens=True,
            )
            if not lines:
                return text, 1
            return "\n".join(lines), len(lines)

        def _wrap_table(font_size: float) -> Tuple[List[str], List[List[str]], List[int]]:
            """Purpose: Wrap header labels and row values for a font size.
            Why: Ensure wrapping matches the current font size and column widths.
            Args:
                font_size (float): Font size in points for wrapping estimates.
            Returns:
                Tuple[List[str], List[List[str]], List[int]]: Wrapped labels, rows,
                and per-row line counts (including header).
            Side Effects:
                - None.
            Exceptions:
                - None; fallback wrapping returns original text.
            """
            approx_char_width = max(4.5, font_size * 0.55)
            table_width_in = content_width_in * table_width_ratio
            header_line_counts = []
            wrapped_labels = []
            for label, frac in zip(column_keys, column_fracs):
                max_chars = max(
                    6,
                    int((table_width_in * frac * 72.0) / approx_char_width),
                )
                wrapped_label, line_count = _wrap_cell(str(label), max_chars)
                wrapped_labels.append(self._final_report_sanitize_text(wrapped_label))
                header_line_counts.append(line_count)
            row_line_counts = []
            wrapped_rows = []
            # Iterate over table_data_raw to apply the per-item logic.
            for row in table_data_raw:
                wrapped_row = []
                line_counts = []
                # Iterate over row values to apply the per-item logic.
                for value, frac in zip(row, column_fracs):
                    max_chars = max(
                        6,
                        int((table_width_in * frac * 72.0) / approx_char_width),
                    )
                    wrapped_value, line_count = _wrap_cell(str(value), max_chars)
                    wrapped_row.append(self._final_report_sanitize_text(wrapped_value))
                    line_counts.append(line_count)
                wrapped_rows.append(wrapped_row)
                row_line_counts.append(max(line_counts) if line_counts else 1)
            header_lines = max(header_line_counts) if header_line_counts else 1
            line_counts = [header_lines] + row_line_counts
            return wrapped_labels, wrapped_rows, line_counts

        for _ in range(4):
            wrapped_labels, wrapped_rows, line_counts = _wrap_table(table_font_size)
            line_height_in = (table_font_size / 72.0) * line_spacing
            pad_in = (table_font_size / 72.0) * (cell_pad * 2.0)
            required_height_in = sum(
                line_height_in * max(1, count) + pad_in for count in line_counts
            )
            available_height_in = content_height_in * table_height_ratio
            if required_height_in <= available_height_in:
                break
            scale = available_height_in / required_height_in if required_height_in else 1.0
            next_size = max(min_font_size, table_font_size * scale)
            if abs(next_size - table_font_size) < 0.1:
                table_font_size = next_size
                break
            table_font_size = next_size

        wrapped_labels, wrapped_rows, line_counts = _wrap_table(table_font_size)
        tbl = ax.table(
            cellText=wrapped_rows,
            colLabels=wrapped_labels,
            loc="center",
            cellLoc="center",
            bbox=table_bbox,
        )
        tbl.auto_set_font_size(False)
        tbl.set_fontsize(table_font_size)
        table_font_family = self._final_report_font_family()
        total_units = sum(line_counts) if line_counts else 1.0
        header_units = line_counts[0] if line_counts else 1.0
        row_units = line_counts[1:] if len(line_counts) > 1 else []
        row_heights = [header_units / total_units] + [
            units / total_units for units in row_units
        ]
        # Iterate over table cells to apply formatting and sizing.
        for (row_idx, col_idx), cell in tbl.get_celld().items():
            try:
                cell.get_text().set_wrap(True)
                if table_font_family:
                    cell.get_text().set_fontfamily(table_font_family)
                cell.PAD = cell_pad
                if col_idx < len(column_fracs):
                    cell.set_width(column_fracs[col_idx] * table_bbox[2])
                if row_idx < len(row_heights):
                    cell.set_height(row_heights[row_idx] * table_bbox[3])
            except Exception:
                continue
        canvas = FigureCanvasAgg(fig)
        fig.set_canvas(canvas)
        # Best-effort pass to keep the table within the axes bounds.
        for _ in range(3):
            try:
                canvas.draw()
                renderer = canvas.get_renderer()
                bbox = tbl.get_window_extent(renderer=renderer)
                ax_bbox = ax.get_window_extent(renderer=renderer)
            except Exception:
                break
            if bbox.width <= ax_bbox.width and bbox.height <= ax_bbox.height:
                break
            scale_w = ax_bbox.width / bbox.width if bbox.width else 1.0
            scale_h = ax_bbox.height / bbox.height if bbox.height else 1.0
            scale = min(scale_w, scale_h, 1.0) * 0.98
            if scale >= 0.99:
                break
            table_font_size = max(min_font_size, table_font_size * scale)
            tbl.set_fontsize(table_font_size)
            try:
                tbl.scale(scale, scale)
            except Exception:
                break
        fig._gl260_report_skip_tight_layout = True
        return fig

    def _final_report_build_text_page(
        self, title: str, body: str, page_size: Tuple[float, float], state: Dict[str, Any]
    ) -> Figure:
        """Build text page.
        Used by final report workflows to build text page."""
        fig = Figure(figsize=page_size)
        state = self._final_report_safe_state(state)
        margins = self._final_report_page_margins(state, page_size)
        ax = fig.add_subplot(111)
        ax.axis("off")
        title_font_size = max(14.0, 15.0 * state.get("font_scale", 1.0))
        title = self._final_report_sanitize_text(title or "")
        title_props = self._final_report_font_properties(title_font_size, weight="bold")
        fig.text(
            margins["left"],
            1 - margins["top"] + 0.0,
            title,
            ha="left",
            va="top",
            fontproperties=title_props,
        )
        body_text = body.strip() if body else ""
        body_text = body_text or "No content available for this section."
        body_text = self._final_report_sanitize_text(body_text)
        body_font_size = max(10.0, 11.0 * state.get("font_scale", 1.0))
        body_props = self._final_report_font_properties(body_font_size)
        start_y = 1 - margins["top"] - 0.04
        available_width = 1 - margins["left"] - margins["right"]
        y_limit = margins["bottom"] + margins["footer"] + 0.01
        self._final_report_render_justified_text(
            fig,
            page_size,
            body_text,
            margins["left"],
            start_y,
            available_width,
            1.15,
            body_props,
            body_font_size,
            hyphenate=True,
            y_limit=y_limit,
        )
        return fig

    def _final_report_font_properties(
        self,
        size: float,
        *,
        weight: Optional[str] = None,
        style: Optional[str] = None,
    ) -> font_manager.FontProperties:
        """Perform final report font properties.
        Used to keep the workflow logic localized and testable."""
        return font_manager.FontProperties(
            family=self._final_report_font_family(),
            size=size,
            weight=weight or "regular",
            style=style or "normal",
        )

    def _final_report_font_family(self) -> List[str]:
        """Perform final report font family.
        Used to keep the workflow logic localized and testable."""
        stack: List[str] = []
        family_value = (settings.get("font_family") or "").strip()
        if isinstance(_FINAL_REPORT_FONT_FAMILY, (list, tuple)):
            stack = list(_FINAL_REPORT_FONT_FAMILY)
        elif _FINAL_REPORT_FONT_FAMILY:
            stack = [str(_FINAL_REPORT_FONT_FAMILY)]
        if family_value:
            if family_value in stack:
                stack.remove(family_value)
            stack.insert(0, family_value)
        return stack

    def _final_report_page_margins(
        self, state: Dict[str, Any], page_size: Tuple[float, float]
    ) -> Dict[str, float]:
        """Purpose: Compute normalized page margins for the Final Report.
        Why: Keep layout margins consistent across report pages and presets.
        Args:
            state (Dict[str, Any]): Final report settings state.
            page_size (Tuple[float, float]): Page size in inches (width, height).
        Returns:
            Dict[str, float]: Normalized margins and reserved caption/footer bands.
        Side Effects:
            - None.
        Exceptions:
            - None; invalid inputs fall back to defaults.
        """
        state = self._final_report_safe_state(state)
        page_width, page_height = page_size
        requested_margin = state.get(
            "margin_in", FINAL_REPORT_DEFAULT_STATE["margin_in"]
        )
        safe_preset = state.get(
            "safe_margin_preset", FINAL_REPORT_DEFAULT_STATE["safe_margin_preset"]
        )
        if safe_preset == "Extra-Safe":
            requested_margin *= 1.2
        requested_margin = float(
            requested_margin
            if requested_margin > 0
            else FINAL_REPORT_DEFAULT_STATE["margin_in"]
        )
        requested_margin = min(requested_margin, min(page_width, page_height) / 2 - 0.1)
        left = max(0.04, min(requested_margin / page_width, 0.35))
        right = max(0.04, min(requested_margin / page_width, 0.35))
        top = max(0.04, min(requested_margin / page_height, 0.35))
        bottom = max(0.04, min(requested_margin / page_height, 0.35))
        caption_height = min(requested_margin * 0.8, page_height * 0.12)
        footer_height = min(requested_margin * 0.45, page_height * 0.06)
        caption_norm = min(caption_height / page_height, bottom * 0.7)
        footer_norm = min(footer_height / page_height, bottom * 0.5)
        reserved = caption_norm + footer_norm
        max_reserved = bottom * 0.85
        if reserved > max_reserved and reserved > 0:
            scale = max_reserved / reserved
            caption_norm *= scale
            footer_norm *= scale
        return {
            "left": left,
            "right": right,
            "top": top,
            "bottom": bottom,
            "caption": caption_norm,
            "footer": footer_norm,
        }

    def _final_report_render_justified_text(
        self,
        fig: Figure,
        page_size: Tuple[float, float],
        text: str,
        x: float,
        y: float,
        width: float,
        line_spacing: float,
        font_properties: font_manager.FontProperties,
        font_size: float,
        *,
        hyphenate: bool = True,
        y_limit: float = 0.0,
    ) -> float:
        """Render justified text.
        Used by final report workflows to render justified text."""
        if not text or not text.strip():
            return y
        page_width, page_height = page_size
        width_in_inches = max(0.5, width * page_width)
        max_chars = max(32, int(width_in_inches * 8.0))
        paragraphs = [
            paragraph.strip()
            # Iterate to apply the per-item logic.
            for paragraph in re.split(r"\n\s*\n", text)
            if paragraph.strip()
        ]
        line_height = (font_size / 72.0) * line_spacing / page_height
        cursor_y = y
        # Iterate over paragraphs to apply the per-item logic.
        for paragraph in paragraphs:
            lines = self._final_report_break_paragraph(paragraph, max_chars, hyphenate)
            # Iterate over indexed elements from lines to apply the per-item logic.
            for idx, line in enumerate(lines):
                is_last_line = idx == len(lines) - 1
                rendered = self._final_report_justify_line(
                    line, max_chars, is_last_line
                )
                fig.text(
                    x,
                    cursor_y,
                    rendered,
                    ha="left",
                    va="top",
                    fontproperties=font_properties,
                    fontsize=font_size,
                    color="#1a1a1a",
                )
                cursor_y -= line_height
                if y_limit and cursor_y < y_limit:
                    return cursor_y
            cursor_y -= line_height * 0.35
            if y_limit and cursor_y < y_limit:
                return cursor_y
        return cursor_y

    def _final_report_break_paragraph(
        self, paragraph: str, max_chars: int, hyphenate: bool
    ) -> List[str]:
        """Perform final report break paragraph.
        Used to keep the workflow logic localized and testable."""
        words = paragraph.split()
        lines: List[str] = []
        # Repeat while words to advance the looped workflow.
        while words:
            line_words: List[str] = []
            current_length = 0
            # Repeat while words to advance the looped workflow.
            while words:
                next_word = words[0]
                spacing = 1 if line_words else 0
                prospective_length = current_length + len(next_word) + spacing
                if prospective_length <= max_chars:
                    line_words.append(words.pop(0))
                    current_length = prospective_length
                    continue
                if len(next_word) > max_chars and hyphenate:
                    part, remainder = self._final_report_hyphenate_word(
                        next_word, max_chars
                    )
                    line_words.append(part)
                    words[0] = remainder
                    current_length = len(part)
                    break
                break
            if not line_words and words:
                word = words.pop(0)
                if hyphenate and len(word) > max_chars:
                    part, remainder = self._final_report_hyphenate_word(word, max_chars)
                    lines.append(part)
                    if remainder:
                        words.insert(0, remainder)
                    continue
                lines.append(word[:max_chars])
                if len(word) > max_chars:
                    words.insert(0, word[max_chars:])
                continue
            lines.append(" ".join(line_words))
        if not lines:
            lines.append(paragraph)
        return lines

    def _final_report_hyphenate_word(
        self, word: str, max_chars: int
    ) -> Tuple[str, str]:
        """Perform final report hyphenate word.
        Used to keep the workflow logic localized and testable."""
        clean_word = word.strip()
        if len(clean_word) <= max_chars:
            return clean_word, ""
        split_pos = max(1, min(len(clean_word) - 1, max_chars - 1))
        prefix = clean_word[:split_pos] + "-"
        remainder = clean_word[split_pos:]
        return prefix, remainder

    def _final_report_justify_line(
        self, line: str, target_chars: int, is_last_line: bool
    ) -> str:
        """Perform final report justify line.
        Used to keep the workflow logic localized and testable."""
        if is_last_line or " " not in line:
            return line
        words = line.split()
        total_spaces = len(words) - 1
        char_count = sum(len(word) for word in words) + total_spaces
        extra_spaces = max(0, target_chars - char_count)
        if extra_spaces == 0:
            return line
        base_extra, remainder = divmod(extra_spaces, total_spaces)
        parts: List[str] = []
        # Iterate over indexed elements from words to apply the per-item logic.
        for index, word in enumerate(words):
            parts.append(word)
            if index < total_spaces:
                spaces = 1 + base_extra + (1 if index < remainder else 0)
                parts.append(" " * spaces)
        return "".join(parts).strip()

    def _final_report_ordered_sections(self, state: Dict[str, Any]) -> List[str]:
        """Perform final report ordered sections.
        Used to keep the workflow logic localized and testable."""
        state = self._final_report_safe_state(state)
        selected_sections = [
            section_id
            # Iterate to apply the per-item logic.
            for section_id in (state.get("selected_sections") or [])
            if isinstance(section_id, str)
        ]
        selected_set = set(selected_sections)
        order_source = state.get("section_order") or selected_sections
        if not order_source:
            order_source = FINAL_REPORT_DEFAULT_SECTION_ORDER
        normalized_order = _normalize_final_report_section_order(
            order_source, warn_missing=False
        )
        if not selected_set:
            return []
        return [
            section_id for section_id in normalized_order if section_id in selected_set
        ]

    def _final_report_compute_layout_sequence(
        self, state: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Purpose: Compute the ordered layout sequence for report pages.
        Why: Build a deterministic page list, including optional caption pages.
        Args:
            state (Dict[str, Any]): Final report settings state.
        Returns:
            List[Dict[str, Any]]: Ordered layout entries for report assembly.
        Side Effects:
            - None.
        Exceptions:
            - None; invalid metadata entries are skipped.
        """
        state = self._final_report_safe_state(state)
        ordered = self._final_report_ordered_sections(state)
        sequence: List[Dict[str, Any]] = []
        layout_mode = state.get(
            "global_layout_mode", FINAL_REPORT_DEFAULT_STATE["global_layout_mode"]
        )
        if layout_mode == "single_page_portrait":
            major_section = None
            # Iterate over ordered to apply the per-item logic.
            for section_id in ordered:
                metadata = FINAL_REPORT_SECTION_METADATA.get(section_id, {})
                if metadata.get("type") == "figure":
                    major_section = section_id
                    break
            orientation = (
                self._final_report_resolved_orientation(major_section, state)
                if major_section
                else "portrait"
            )
            major_metadata = FINAL_REPORT_SECTION_METADATA.get(major_section)
            sequence.append(
                {
                    "page_type": "title",
                    "section_id": major_section,
                    "orientation": orientation,
                    "metadata": major_metadata,
                    "group": (major_metadata or {}).get("group", "Final Report"),
                    "is_title": True,
                }
            )
            if (
                major_section
                and major_metadata
                and major_metadata.get("type") in ("figure", "table")
                and self._final_report_section_caption_enabled(major_section, state)
                and self._final_report_section_caption_placement(major_section, state)
                == "Next Page"
            ):
                sequence.append(
                    {
                        "page_type": "caption",
                        "section_id": major_section,
                        "caption_kind": major_metadata.get("type"),
                        "orientation": orientation,
                        "metadata": major_metadata,
                        "group": major_metadata.get("group"),
                        "is_title": False,
                        "is_caption_page": True,
                    }
                )
            if major_section:
                ordered = [sec for sec in ordered if sec != major_section]
        # Iterate over ordered to apply the per-item logic.
        for section_id in ordered:
            metadata = FINAL_REPORT_SECTION_METADATA.get(section_id)
            if not metadata:
                continue
            orientation = self._final_report_resolved_orientation(section_id, state)
            page_type = metadata.get("type", "text")
            sequence.append(
                {
                    "page_type": page_type,
                    "section_id": section_id,
                    "orientation": orientation,
                    "metadata": metadata,
                    "group": metadata.get("group"),
                    "is_title": False,
                }
            )
            if (
                page_type in ("figure", "table")
                and self._final_report_section_caption_enabled(section_id, state)
                and self._final_report_section_caption_placement(section_id, state)
                == "Next Page"
            ):
                sequence.append(
                    {
                        "page_type": "caption",
                        "section_id": section_id,
                        "caption_kind": page_type,
                        "orientation": orientation,
                        "metadata": metadata,
                        "group": metadata.get("group"),
                        "is_title": False,
                        "is_caption_page": True,
                    }
                )
        return sequence

    def _final_report_create_section_figure(
        self, section_id: str, page_size: Tuple[float, float]
    ) -> Optional[Figure]:
        """Create section figure.
        Used by final report workflows to create section figure."""
        if not section_id:
            return None
        if section_id in FINAL_REPORT_EXCLUDED_SECTIONS:
            return None
        if section_id == "cycle_plot":
            return self._final_report_build_cycle_plot_figure(page_size)
        if section_id in ("fig1", "fig2"):
            return self._final_report_build_standard_plot(section_id, page_size)
        if section_id == FINAL_REPORT_COMBINED_SECTION_ID:
            ok, message = self._final_report_columns_ready()
            if not ok:
                self._final_report_combined_failure_reason = message
                return None
            ok, message = self._final_report_combined_preflight()
            if not ok:
                self._final_report_combined_failure_reason = message
                return None
            fig = self._build_export_figure_for_final_report(
                "fig_combined",
                "fig_combined_triple_axis",
                page_size,
            )
            if fig is None:
                self._final_report_combined_failure_reason = (
                    "Combined plot could not be generated for this run."
                )
            return fig
        if section_id == "cycle_timeline_plot":
            return self._final_report_build_cycle_timeline_figure(page_size)
        return None

    def _final_report_collect_key_metrics_text(self) -> str:
        """Collect key metrics text.
        Used by final report workflows to collect key metrics text."""
        rows, _ = self._final_report_get_key_metrics_rows()
        if not rows:
            return "No key metrics available."
        lines = []
        # Iterate over rows[ to apply the per-item logic.
        for row in rows[:4]:
            label = row.get("Metric") or row.get("metric") or "Metric"
            value = row.get("Value") or row.get("value") or ""
            lines.append(f"{label}: {value}")
        return "\n".join(lines)

    def _final_report_build_title_page(
        self,
        page_size: Tuple[float, float],
        state: Dict[str, Any],
        major_section_id: Optional[str],
    ) -> Tuple[Figure, bool]:
        """Build title page.
        Used by final report workflows to build title page."""
        state = self._final_report_safe_state(state)
        title = state.get("title", FINAL_REPORT_DEFAULT_STATE["title"])
        fig = (
            self._final_report_create_section_figure(major_section_id, page_size)
            if major_section_id
            else None
        )
        if fig is None:
            narrative = state.get("narrative", "")
            body = narrative or "Narrative is not available."
            return (
                self._final_report_build_text_page(title, body, page_size, state),
                False,
            )
        margins = self._final_report_page_margins(state, page_size)
        font_scale = state.get("font_scale", 1.0)
        title_font_size = max(20.0, 22.0 * font_scale)
        title = self._final_report_sanitize_text(title or "")
        fig.text(
            0.5,
            1 - margins["top"] + 0.01,
            title,
            ha="center",
            va="top",
            fontproperties=self._final_report_font_properties(
                title_font_size, weight="bold"
            ),
            fontsize=title_font_size,
            color="#111111",
        )
        meta_lines = [
            f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"Layout mode: {state.get('global_layout_mode')}",
            f"Font scale: {state.get('font_scale', 1.0):.2f}",
            f"Margins: {state.get('margin_in', FINAL_REPORT_DEFAULT_STATE['margin_in']):.2f} in",
        ]
        meta_text = "\n".join(meta_lines)
        meta_font_size = max(9.0, 10.5 * font_scale)
        body_width = (1 - margins["left"] - margins["right"]) / 2 - 0.02
        self._final_report_render_justified_text(
            fig,
            page_size,
            meta_text,
            margins["left"],
            1 - margins["top"] - 0.01,
            body_width,
            1.15,
            self._final_report_font_properties(meta_font_size, weight="bold"),
            meta_font_size,
            hyphenate=True,
            y_limit=0.7,
        )
        narrative_text = (
            state.get("narrative", "").strip() or "Narrative is not available."
        )
        narrative_text = self._final_report_sanitize_text(narrative_text)
        narrative_font_size = max(10.0, 11.0 * font_scale)
        narrative_x = margins["left"] + body_width + 0.04
        self._final_report_render_justified_text(
            fig,
            page_size,
            narrative_text,
            narrative_x,
            1 - margins["top"] - 0.01,
            body_width,
            1.15,
            self._final_report_font_properties(narrative_font_size),
            narrative_font_size,
            hyphenate=True,
            y_limit=0.55,
        )
        metrics_text = self._final_report_collect_key_metrics_text()
        metrics_font_size = max(9.0, 10.0 * font_scale)
        metric_block = self._final_report_sanitize_text(
            "Key metrics:\n" + metrics_text
        )
        self._final_report_render_justified_text(
            fig,
            page_size,
            metric_block,
            margins["left"],
            0.62,
            1 - margins["left"] - margins["right"],
            1.15,
            self._final_report_font_properties(metrics_font_size),
            metrics_font_size,
            hyphenate=True,
            y_limit=margins["bottom"] + margins["footer"] + margins["caption"] + 0.02,
        )
        return fig, True

    def _final_report_finalize_figure_layout(
        self,
        fig: Figure,
        state: Dict[str, Any],
        page_size: Tuple[float, float],
        has_caption: bool,
        *,
        section_id: Optional[str],
        page_type: str,
        include_group_label: bool,
        include_section_header: bool,
        include_table_caption: bool,
    ) -> Dict[str, float]:
        """Purpose: Finalize figure layout within report margins and bands.
        Why: Prevent overlaps between plots/tables and headers/captions/footers.
        Args:
            fig (Figure): Matplotlib figure to adjust.
            state (Dict[str, Any]): Final report settings state.
            page_size (Tuple[float, float]): Page size in inches (width, height).
            has_caption (bool): Whether a bottom caption band is reserved.
            section_id (Optional[str]): Section identifier for layout decisions.
            page_type (str): Page type label (figure/table/text/title/caption).
            include_group_label (bool): Whether a group label will be drawn.
            include_section_header (bool): Whether a section header will be drawn.
            include_table_caption (bool): Whether a table caption is drawn at the top.
        Returns:
            Dict[str, float]: Normalized margins used for layout.
        Side Effects:
            - Updates axes positions and figure layout parameters.
        Exceptions:
            - Best-effort; falls back to subplots_adjust on layout errors.
        """
        state = self._final_report_safe_state(state)
        margins = self._final_report_page_margins(state, page_size)
        rect = self._final_report_content_rect(
            state,
            page_size,
            has_caption=has_caption,
            include_group_label=include_group_label,
            include_section_header=include_section_header,
            include_table_caption=include_table_caption,
        )
        if getattr(fig, "_gl260_report_skip_tight_layout", False):
            return margins
        if section_id == FINAL_REPORT_COMBINED_SECTION_ID and page_type != "caption":
            self._final_report_fit_axes_to_rect(fig, rect)
            return margins
        try:
            fig.tight_layout(rect=rect)
        except Exception:
            fig.subplots_adjust(
                left=rect[0], right=rect[2], top=rect[3], bottom=rect[1]
            )
        else:
            fig.subplots_adjust(
                left=rect[0], right=rect[2], top=rect[3], bottom=rect[1]
            )
        return margins

    def _final_report_draw_figure_caption(
        self,
        fig: Figure,
        caption: str,
        figure_index: int,
        page_size: Tuple[float, float],
        state: Dict[str, Any],
    ) -> None:
        """Perform final report draw figure caption.
        Used to keep the workflow logic localized and testable."""
        state = self._final_report_safe_state(state)
        if not caption:
            return
        margins = self._final_report_page_margins(state, page_size)
        caption_font_size = max(8.5, 9.0 * state.get("font_scale", 1.0))
        caption_text = self._final_report_sanitize_text(
            f"Figure {figure_index}. {caption}"
        )
        start_y = margins["bottom"] + margins["footer"] + margins["caption"] - 0.01
        self._final_report_render_justified_text(
            fig,
            page_size,
            caption_text,
            margins["left"],
            start_y,
            1 - margins["left"] - margins["right"],
            1.15,
            self._final_report_font_properties(caption_font_size),
            caption_font_size,
            hyphenate=True,
            y_limit=margins["bottom"] + margins["footer"],
        )

    def _final_report_draw_table_caption(
        self,
        fig: Figure,
        table_index: int,
        caption: str,
        page_size: Tuple[float, float],
        state: Dict[str, Any],
    ) -> None:
        """Perform final report draw table caption.
        Used to keep the workflow logic localized and testable."""
        state = self._final_report_safe_state(state)
        if not caption:
            return
        margins = self._final_report_page_margins(state, page_size)
        caption_font_size = max(9.0, 10.0 * state.get("font_scale", 1.0))
        text = self._final_report_sanitize_text(f"Table {table_index}. {caption}")
        self._final_report_render_justified_text(
            fig,
            page_size,
            text,
            margins["left"],
            1 - margins["top"] + 0.005,
            1 - margins["left"] - margins["right"],
            1.15,
            self._final_report_font_properties(caption_font_size, weight="bold"),
            caption_font_size,
            hyphenate=True,
            y_limit=1 - margins["top"] - 0.01,
        )

    def _final_report_draw_page_footer(
        self,
        fig: Figure,
        page_number: int,
        page_size: Tuple[float, float],
        state: Dict[str, Any],
    ) -> None:
        """Perform final report draw page footer.
        Used to keep the workflow logic localized and testable."""
        state = self._final_report_safe_state(state)
        margins = self._final_report_page_margins(state, page_size)
        font_size = max(8.0, 9.5 * state.get("font_scale", 1.0))
        footer_y = max(0.02, margins["bottom"] * 0.5)
        fig.text(
            0.5,
            footer_y,
            f"GL-260 Final Report – Page {page_number}",
            ha="center",
            va="center",
            fontproperties=self._final_report_font_properties(font_size),
            fontsize=font_size,
            color="#333333",
        )
        line_y = margins["bottom"] + margins["footer"] - 0.015
        fig.lines.append(
            Line2D(
                [margins["left"], 1 - margins["right"]],
                [line_y, line_y],
                transform=fig.transFigure,
                color="#aaaaaa",
                linewidth=0.6,
                alpha=0.5,
            )
        )

    def _final_report_draw_group_label(
        self,
        fig: Figure,
        group_label: Optional[str],
        page_size: Tuple[float, float],
        state: Dict[str, Any],
    ) -> None:
        """Perform final report draw group label.
        Used to keep the workflow logic localized and testable."""
        state = self._final_report_safe_state(state)
        if not group_label:
            return
        margins = self._final_report_page_margins(state, page_size)
        font_size = max(10.0, 11.0 * state.get("font_scale", 1.0))
        y = min(0.98, 1 - margins["top"] + 0.02)
        group_label = self._final_report_sanitize_text(group_label)
        fig.text(
            margins["left"],
            y,
            group_label,
            ha="left",
            va="top",
            fontproperties=self._final_report_font_properties(
                font_size, style="italic"
            ),
            fontsize=font_size,
            color="#444444",
        )

    def _final_report_draw_section_header(
        self,
        fig: Figure,
        metadata: Optional[Dict[str, Any]],
        section_id: Optional[str],
        page_size: Tuple[float, float],
        state: Dict[str, Any],
    ) -> None:
        """Purpose: Draw the section header label on the report page.
        Why: Provide clear section labeling without overlapping plot content.
        Args:
            fig (Figure): Matplotlib figure to draw on.
            metadata (Optional[Dict[str, Any]]): Section metadata (label, group).
            section_id (Optional[str]): Section identifier for toggle lookup.
            page_size (Tuple[float, float]): Page size in inches (width, height).
            state (Dict[str, Any]): Final report settings state.
        Returns:
            None.
        Side Effects:
            - Adds header text and separator line to the figure.
        Exceptions:
            - None; silently returns on invalid metadata or disabled header.
        """
        state = self._final_report_safe_state(state)
        if not metadata:
            return
        if not self._final_report_section_header_enabled(section_id, state):
            return
        margins = self._final_report_page_margins(state, page_size)
        font_size = max(13.0, 14.0 * state.get("font_scale", 1.0))
        label = self._final_report_sanitize_text(metadata.get("label", ""))
        y = 1 - margins["top"] - 0.02
        fig.text(
            margins["left"],
            y,
            label,
            ha="left",
            va="top",
            fontproperties=self._final_report_font_properties(font_size, weight="bold"),
            fontsize=font_size,
            color="#222222",
        )
        line_y = y - 0.01
        fig.lines.append(
            Line2D(
                [margins["left"], 1 - margins["right"]],
                [line_y, line_y],
                transform=fig.transFigure,
                color="#bbbbbb",
                linewidth=0.6,
                alpha=0.5,
            )
        )

    def _final_report_get_cycle_summary_text(self) -> str:
        """Return cycle summary text.
        Used by final report workflows to return cycle summary text."""
        widget = getattr(self, "_cycle_summary_box", None)
        if widget and getattr(widget, "winfo_exists", lambda: False)():
            try:
                return widget.get("1.0", "end").strip()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        return "Cycle analysis summary is not available."

    def _final_report_cycle_duration_column_header(
        self, payload: Optional[Dict[str, Any]]
    ) -> str:
        """Resolve a unit-bearing Duration column header for cycle statistics.

        Purpose:
            Build the Final Report cycle-statistics Duration header with explicit units.
        Why:
            Keeps the table header aligned with the internal x-axis units used by
            `duration_x` without changing cycle duration values or rounding behavior.
        Args:
            payload: Cycle transfer payload containing `cycle_context` and/or
                `cycle_transfer` row metadata with the x-axis label.
        Returns:
            A display header string like `Duration (days)` or `Duration (hours)`.
        Side Effects:
            None.
        Exceptions:
            Parsing failures are handled defensively by returning a generic
            `Duration (x-axis units)` label.
        """
        if not payload:
            return "Duration (x-axis units)"
        x_label = ""
        cycle_context = payload.get("cycle_context") or {}
        if isinstance(cycle_context, dict):
            x_label = str(cycle_context.get("x_label") or "").strip()
        if not x_label:
            cycle_rows = payload.get("cycle_transfer") or []
            if cycle_rows:
                # Fall back to per-row metadata when cycle_context is unavailable.
                x_label = str((cycle_rows[0] or {}).get("x_label") or "").strip()
        unit = ""
        if x_label:
            match = re.search(r"\(([^()]+)\)\s*$", x_label)
            if match:
                unit = match.group(1).strip()
            else:
                x_label_lower = x_label.lower()
                # Use known elapsed-time units when they appear in the axis label.
                for candidate in ELAPSED_TIME_UNITS:
                    if candidate in x_label_lower:
                        unit = candidate
                        break
        if not unit:
            unit = "x-axis units"
        return f"Duration ({unit})"

    def _final_report_get_cycle_stats_rows(
        self,
    ) -> Tuple[List[Dict[str, Any]], List[str]]:
        """Return cycle statistics rows and column labels for Final Report tables.

        Purpose:
            Assemble cycle statistics table data for Final Report rendering.
        Why:
            Centralizes report table preparation so on-screen previews and exports
            use the same data rows and headers, including the Duration unit label.
        Args:
            None.
        Returns:
            A tuple of (`rows`, `columns`) where `rows` contains formatted cycle
            statistics dictionaries and `columns` defines table display order.
        Side Effects:
            None.
        Exceptions:
            Missing payload data returns an empty table instead of raising.
        """
        payload = getattr(self, "_cycle_last_transfer_payload", None)
        rows = []
        if not payload:
            return rows, []
        duration_header = self._final_report_cycle_duration_column_header(payload)
        # Iterate over payload.get("cycle_transfer", []) to apply the per-item logic.
        for entry in payload.get("cycle_transfer", []):
            delta = entry.get("delta_pressure_psi")
            duration = entry.get("duration_x") or entry.get("duration")
            rows.append(
                {
                    "Cycle": entry.get("cycle_id") or "",
                    "ΔP (PSI)": f"{delta:.2f}" if delta is not None else "",
                    duration_header: f"{duration:.3f}" if duration is not None else "",
                    "Peak PSI": (
                        f"{entry.get('peak_pressure_psi', ''):.2f}"
                        if entry.get("peak_pressure_psi") is not None
                        else ""
                    ),
                    "Trough PSI": (
                        f"{entry.get('trough_pressure_psi', ''):.2f}"
                        if entry.get("trough_pressure_psi") is not None
                        else ""
                    ),
                    "Mean T (°C)": (
                        f"{entry.get('mean_temperature_c', ''):.2f}"
                        if entry.get("mean_temperature_c") is not None
                        else ""
                    ),
                    "CO₂ (g)": (
                        f"{entry.get('cumulative_co2_mass_g', ''):.2f}"
                        if entry.get("cumulative_co2_mass_g") is not None
                        else ""
                    ),
                }
            )
        columns = [
            "Cycle",
            "ΔP (PSI)",
            duration_header,
            "Peak PSI",
            "Trough PSI",
            "Mean T (°C)",
            "CO₂ (g)",
        ]
        return rows, columns

    def _final_report_get_cycle_timeline_rows(
        self,
    ) -> Tuple[List[Dict[str, Any]], List[str]]:
        """Return cycle timeline rows.
        Used by final report workflows to return cycle timeline rows."""
        structured = getattr(self, "_sol_last_structured", None)
        timeline = getattr(structured, "cycle_timeline", None) or []
        if not timeline:
            result = self._get_cycle_result_for_workflow(
                self._current_solubility_workflow()
            )
            timeline = (result or {}).get("timeline", []) or []
        if not timeline:
            return [], []
        rows = []
        # Iterate over timeline to apply the per-item logic.
        for entry in timeline:
            co2_total = (
                _safe_float(entry.get("co2_g"))
                or _safe_float(entry.get("co2_mass_g"))
                or 0.0
            )
            fractions = entry.get("fractions") or {}
            rows.append(
                {
                    "Cycle": entry.get("cycle_id") or "",
                    "CO₂ total (g)": f"{co2_total:.2f}",
                    "pH": (
                        f"{entry.get('solution_ph', ''):.2f}"
                        if entry.get("solution_ph") is not None
                        else ""
                    ),
                    "H₂CO₃ (%)": f"{fractions.get('H2CO3', 0.0) * 100:.1f}",
                    "HCO₃⁻ (%)": f"{fractions.get('HCO3-', 0.0) * 100:.1f}",
                    "CO₃²⁻ (%)": f"{fractions.get('CO3^2-', 0.0) * 100:.1f}",
                }
            )
        columns = [
            "Cycle",
            "CO₂ total (g)",
            "pH",
            "H₂CO₃ (%)",
            "HCO₃⁻ (%)",
            "CO₃²⁻ (%)",
        ]
        return rows, columns

    def _final_report_get_key_metrics_rows(
        self,
    ) -> Tuple[List[Dict[str, str]], List[str]]:
        """Return key metrics rows.
        Used by final report workflows to return key metrics rows."""
        structured = getattr(self, "_sol_last_structured", None)
        highlights = {}
        if structured is not None:
            highlights = getattr(structured, "highlights", {}) or {}
        rows = []
        meta = getattr(self, "_sol_highlight_meta", {})
        # Iterate over items from meta to apply the per-item logic.
        for key, label in meta.items():
            value = highlights.get(key)
            if value:
                rows.append({"Metric": label, "Value": value})
        if not rows and highlights:
            # Iterate over items from highlights to apply the per-item logic.
            for key, value in highlights.items():
                rows.append({"Metric": key.replace("_", " ").title(), "Value": value})
        if rows:
            return rows, ["Metric", "Value"]
        return [], []

    def _final_report_get_predicted_ph_callouts_text(self) -> str:
        """Return predicted pH callouts text.
        Used by final report workflows to return predicted pH callouts text."""
        guidance = getattr(self, "_sol_reaction_guidance", {}) or {}
        lines = []
        target_ph = guidance.get("target_ph")
        if target_ph is not None:
            lines.append(f"Target pH: {target_ph:.2f}")
        recommended = guidance.get("recommended_co2_g")
        if recommended is not None:
            lines.append(f"CO₂ to target: {recommended:.2f} g")
        pco2_value = guidance.get("pco2_atm")
        if pco2_value is not None:
            lines.append(f"Predicted pCO₂: {pco2_value:.3g} atm")
        notes = guidance.get("notes") or []
        if notes:
            lines.extend(notes)
        if not lines:
            lines.append("Predicted pH callouts are not available.")
        return "\n".join(lines)

    def _final_report_get_co2_guidance_text(self) -> str:
        """Return CO2 guidance text.
        Used by final report workflows to return CO2 guidance text."""
        structured = getattr(self, "_sol_last_structured", None)
        guidance = ""
        if structured is not None:
            guidance = getattr(structured, "co2_guidance", "") or ""
        return guidance.strip() or "CO₂ dosing guidance is not available."

    def _final_report_get_planner_narrative_text(self) -> str:
        """Return planner narrative text.
        Used by final report workflows to return planner narrative text."""
        structured = getattr(self, "_sol_last_structured", None)
        context = []
        if structured is not None:
            context = getattr(structured, "planner_context", []) or []
        if context:
            return "\n".join(context)
        return "Planner narrative is not available."

    def _final_report_get_sol_summary_text(self) -> str:
        """Return sol summary text.
        Used by final report workflows to return sol summary text."""
        var = getattr(self, "_sol_reaction_summary_var", None)
        if var is not None:
            text = var.get().strip()
            if text:
                return text
        return "Solubility summary is not available."

    def _final_report_get_math_preview_text(self) -> str:
        """Return math preview text.
        Used by final report workflows to return math preview text."""
        structured = getattr(self, "_sol_last_structured", None)
        lines: List[str] = []
        if structured is not None:
            lines = getattr(structured, "math_preview_lines", []) or []
            if not lines:
                sections = getattr(structured, "math_sections", []) or []
                # Iterate over sections to apply the per-item logic.
                for section in sections:
                    heading = section.get("title")
                    body = section.get("content")
                    if heading and body:
                        lines.append(f"{heading}: {body}")
        if not lines:
            return "Math preview content is not available."
        return "\n".join(lines)

    def _final_report_section_body_text(self, section_id: Optional[str]) -> str:
        """Perform final report section body text.
        Used to keep the workflow logic localized and testable."""
        if section_id == "cycle_summary":
            return self._final_report_get_cycle_summary_text()
        if section_id == "predicted_ph_callouts":
            return self._final_report_get_predicted_ph_callouts_text()
        if section_id == "co2_dosing_guidance":
            return self._final_report_get_co2_guidance_text()
        if section_id == "planner_narrative":
            return self._final_report_get_planner_narrative_text()
        if section_id == "sol_summary":
            return self._final_report_get_sol_summary_text()
        if section_id == "math_preview":
            return self._final_report_get_math_preview_text()
        return "Content is not available for this section."

    def _final_report_figure_caption(self, section_id: str) -> str:
        """Perform final report figure caption.
        Used to keep the workflow logic localized and testable."""
        captions = {
            "cycle_plot": "Cycle analysis plot with detected peaks and troughs.",
            "fig1": "Figure 1: Pressure and temperature data.",
            "fig2": "Figure 2: Pressure derivative overview.",
            "cycle_timeline_plot": "Cycle speciation timeline.",
        }
        return captions.get(
            section_id,
            FINAL_REPORT_SECTION_METADATA.get(section_id, {}).get("label", section_id),
        )

    def _final_report_build_page_entry(
        self,
        entry: Dict[str, Any],
        state: Dict[str, Any],
        counters: Dict[str, int],
        last_group: Optional[str],
    ) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:
        """Purpose: Build a single Final Report page entry.
        Why: Assemble figures/text, apply layout rules, and track numbering.
        Args:
            entry (Dict[str, Any]): Layout entry describing the page to build.
            state (Dict[str, Any]): Final report settings state.
            counters (Dict[str, int]): Running counters (page/figure/table + maps).
            last_group (Optional[str]): Last rendered group label, if any.
        Returns:
            Tuple[Optional[Dict[str, Any]], Optional[str]]: Page info and group label.
        Side Effects:
            - Increments counters and may update combined failure state.
        Exceptions:
            - Best-effort; returns (None, last_group) on build failures.
        """
        page_type = entry.get("page_type", "text")
        orientation = entry.get("orientation", "portrait")
        page_size = self._final_report_page_dimensions(orientation)
        metadata = entry.get("metadata") or {}
        section_id = entry.get("section_id")
        group_label = entry.get("group")
        fig: Optional[Figure] = None
        has_caption = False
        figure_caption_text = ""
        table_caption_text = ""
        table_rendered = False
        used_figure = False
        caption_kind = entry.get("caption_kind") or metadata.get("type")
        caption_enabled = False
        caption_placement = "Same Page"
        caption_on_page = False
        include_table_caption = False
        caption_display_text = ""
        combined_failed = False
        combined_failure_reason = ""
        if section_id in FINAL_REPORT_EXCLUDED_SECTIONS:
            return None, last_group
        state = self._final_report_safe_state(state)
        fit_mode = state.get("fit_mode", FINAL_REPORT_DEFAULT_STATE["fit_mode"])
        draw_group_label = bool(group_label and group_label != last_group)
        show_section_header = self._final_report_section_header_enabled(
            section_id, state
        ) and page_type != "title"
        if section_id and caption_kind in ("figure", "table"):
            caption_enabled = self._final_report_section_caption_enabled(
                section_id, state
            )
            caption_placement = self._final_report_section_caption_placement(
                section_id, state
            )
            caption_on_page = caption_enabled and caption_placement == "Same Page"
            has_caption = caption_on_page and caption_kind == "figure"
            include_table_caption = caption_on_page and caption_kind == "table"
            if caption_enabled and caption_kind == "figure":
                figure_caption_text = self._final_report_figure_caption(section_id)
            elif caption_enabled and caption_kind == "table":
                table_caption_text = self._final_report_table_caption(section_id)
        if page_type == "caption":
            caption_text = ""
            if caption_kind == "figure":
                figure_index = counters.get("section_figures", {}).get(section_id)
                if figure_index is None:
                    return None, last_group
                figure_caption_text = (
                    figure_caption_text
                    or self._final_report_figure_caption(section_id)
                )
                caption_text = f"Figure {figure_index}. {figure_caption_text}"
            elif caption_kind == "table":
                table_index = counters.get("section_tables", {}).get(section_id)
                if table_index is None:
                    return None, last_group
                table_caption_text = (
                    table_caption_text
                    or self._final_report_table_caption(section_id)
                )
                caption_text = f"Table {table_index}. {table_caption_text}"
            else:
                caption_text = metadata.get("label", "") or ""
            caption_display_text = caption_text
            fig = self._final_report_build_caption_page(caption_text, page_size, state)
            if fig is None:
                return None, last_group
        elif page_type == "title":
            fig, used_figure = self._final_report_build_title_page(
                page_size, state, section_id
            )
            if used_figure and section_id and caption_kind == "figure":
                caption_enabled = self._final_report_section_caption_enabled(
                    section_id, state
                )
                caption_placement = self._final_report_section_caption_placement(
                    section_id, state
                )
                caption_on_page = caption_enabled and caption_placement == "Same Page"
                has_caption = caption_on_page
                if caption_enabled and not figure_caption_text:
                    figure_caption_text = self._final_report_figure_caption(section_id)
            else:
                caption_enabled = False
                caption_on_page = False
                has_caption = False
                if section_id == FINAL_REPORT_COMBINED_SECTION_ID and not used_figure:
                    combined_failed = True
                    combined_failure_reason = (
                        self._final_report_combined_failure_reason
                        or "Combined plot could not be generated for this run."
                    )
        elif page_type == "figure":
            if (
                section_id == FINAL_REPORT_COMBINED_SECTION_ID
                and fit_mode == "Preserve Export Layout"
            ):
                fig = self._final_report_build_export_image_page(
                    "fig_combined",
                    "fig_combined_triple_axis",
                    page_size,
                    state,
                    include_group_label=draw_group_label,
                    include_section_header=show_section_header,
                    has_caption=has_caption,
                )
                if fig is None:
                    combined_failed = True
                    combined_failure_reason = (
                        self._final_report_combined_failure_reason
                        or "Combined plot could not be generated for this run."
                    )
            if fig is None:
                fig = self._final_report_create_section_figure(section_id, page_size)
                if section_id == FINAL_REPORT_COMBINED_SECTION_ID and fig is None:
                    combined_failed = True
                    combined_failure_reason = (
                        self._final_report_combined_failure_reason
                        or "Combined plot could not be generated for this run."
                    )
            if fig is not None and section_id == FINAL_REPORT_COMBINED_SECTION_ID:
                combined_failed = False
                combined_failure_reason = ""
            if fig is None:
                page_type = "text"
                fig = self._final_report_build_text_page(
                    metadata.get("label", section_id) or "",
                    "Section omitted - no data available for this run.",
                    page_size,
                    state,
                )
                caption_enabled = False
                caption_on_page = False
                has_caption = False
        elif page_type == "table":
            rows, columns = [], []
            if section_id == "cycle_stats_table":
                rows, columns = self._final_report_get_cycle_stats_rows()
            elif section_id == "cycle_timeline_table":
                rows, columns = self._final_report_get_cycle_timeline_rows()
            elif section_id == "key_metrics":
                rows, columns = self._final_report_get_key_metrics_rows()
            fig = self._final_report_build_table_figure(
                rows,
                columns,
                page_size,
                state,
                include_group_label=draw_group_label,
                include_section_header=show_section_header,
                include_table_caption=include_table_caption,
            )
            if fig is not None:
                table_rendered = True
            else:
                page_type = "text"
                fallback_title = (
                    table_caption_text
                    or metadata.get("label", section_id)
                    or "Table"
                )
                fig = self._final_report_build_text_page(
                    fallback_title,
                    "Table data is not available for this section.",
                    page_size,
                    state,
                )
                caption_enabled = False
                caption_on_page = False
                include_table_caption = False
                table_rendered = False
        else:
            body = self._final_report_section_body_text(section_id)
            fig = self._final_report_build_text_page(
                metadata.get("label", section_id) or "",
                body,
                page_size,
                state,
            )
        if fig is None:
            return None, last_group
        counters["page_number"] += 1
        figure_index = None
        table_index = None
        if (
            caption_enabled
            and caption_kind == "figure"
            and page_type in ("figure", "title")
            and (page_type != "title" or used_figure)
        ):
            counters["figure_number"] += 1
            figure_index = counters["figure_number"]
            if section_id:
                counters.setdefault("section_figures", {})[section_id] = figure_index
        elif caption_enabled and caption_kind == "table" and table_rendered:
            counters["table_number"] += 1
            table_index = counters["table_number"]
            if section_id:
                counters.setdefault("section_tables", {})[section_id] = table_index
        self._final_report_finalize_figure_layout(
            fig,
            state,
            page_size,
            has_caption,
            section_id=section_id,
            page_type=page_type,
            include_group_label=draw_group_label,
            include_section_header=show_section_header,
            include_table_caption=include_table_caption,
        )
        if draw_group_label:
            self._final_report_draw_group_label(fig, group_label, page_size, state)
            last_group = group_label
        if show_section_header:
            self._final_report_draw_section_header(
                fig, metadata, section_id, page_size, state
            )
        if has_caption and figure_index is not None and caption_on_page:
            self._final_report_draw_figure_caption(
                fig,
                figure_caption_text,
                figure_index,
                page_size,
                state,
            )
        elif include_table_caption and table_rendered and table_index is not None:
            self._final_report_draw_table_caption(
                fig,
                table_index,
                table_caption_text,
                page_size,
                state,
            )
        if state.get("show_page_numbers"):
            self._final_report_draw_page_footer(
                fig, counters["page_number"], page_size, state
            )
        if page_type == "caption":
            display_caption = caption_display_text
        elif has_caption and figure_index is not None and caption_on_page:
            display_caption = f"Figure {figure_index}. {figure_caption_text}"
        elif include_table_caption and table_index is not None:
            display_caption = f"Table {table_index}. {table_caption_text}"
        else:
            display_caption = metadata.get("label", "") or section_id or ""
        return (
            {
                "figure": fig,
                "page_type": page_type,
                "section_id": section_id,
                "group_label": group_label,
                "page_number": counters["page_number"],
                "figure_number": figure_index,
                "table_number": table_index,
                "orientation": orientation,
                "page_size": page_size,
                "caption_text": figure_caption_text,
                "table_caption": table_caption_text if table_rendered else "",
                "display_caption": display_caption,
                "has_caption": has_caption,
                "table_rendered": table_rendered,
                "used_figure": used_figure,
                "caption_enabled": caption_enabled,
                "caption_placement": caption_placement,
                "caption_on_page": caption_on_page,
                "is_caption_page": bool(entry.get("is_caption_page")),
                "combined_failed": combined_failed,
                "combined_failure_reason": combined_failure_reason,
            },
            last_group,
        )

    def _final_report_build_page_figures(
        self, state: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Purpose: Build Matplotlib figures for each report page.
        Why: Provide page figures for preview and export workflows.
        Args:
            state (Dict[str, Any]): Final report settings state.
        Returns:
            List[Dict[str, Any]]: Page info entries containing figures and metadata.
        Side Effects:
            - Creates Matplotlib figures and updates numbering counters.
        Exceptions:
            - None; invalid pages are skipped.
        """
        state = self._final_report_safe_state(state)
        sequence = self._final_report_compute_layout_sequence(state)
        results: List[Dict[str, Any]] = []
        if not sequence:
            return results
        self._dbg(
            "report.figures",
            "Final report build pages start entries=%s",
            len(sequence),
        )
        counters = {
            "page_number": 0,
            "figure_number": 0,
            "table_number": 0,
            "section_figures": {},
            "section_tables": {},
        }
        last_group: Optional[str] = None
        with self._perf_time("report.figures", "final_report_build_pages"):
            # Iterate over sequence to apply the per-item logic.
            for entry in sequence:
                page_info, last_group = self._final_report_build_page_entry(
                    entry, state, counters, last_group
                )
                if page_info is None:
                    continue
                results.append(page_info)
        self._dbg(
            "report.figures",
            "Final report build pages done pages=%s",
            len(results),
        )
        return results

    def _generate_final_report_png(self) -> None:
        """Generate the Final Report summary PNG.

        Purpose:
            Export a summary PNG representing the final report configuration.
        Why:
            Provides a lightweight visual artifact for sharing or records.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Writes a PNG file to disk and updates settings persistence.
        Exceptions:
            Best-effort guards suppress export failures.
        """
        state = self._collect_final_report_state_from_ui()
        sections = state.get("selected_sections") or []
        self._dbg(
            "report.build",
            "Final report PNG generation start sections=%s",
            len(sections),
        )
        if not sections:
            try:
                messagebox.showwarning(
                    "Final Report PNG", "Select at least one section for the report."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        settings["final_report"].clear()
        settings["final_report"].update(copy.deepcopy(state))
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        title = state.get("title", FINAL_REPORT_DEFAULT_STATE["title"])
        slug = self._slugify_final_report_title(title)
        default_name = f"{slug}.png"
        path = filedialog.asksaveasfilename(
            title="Save Final Report Summary PNG",
            defaultextension=".png",
            filetypes=[("PNG Image", "*.png")],
            initialfile=default_name,
        )
        if not path:
            return
        with self._perf_time("report.export", "final_report_png_export"):
            width, height = self._compute_output_dimensions(
                "final_report_png", 8.5, 11.0
            )
            fig = Figure(figsize=(width, height))
            ax = fig.add_subplot(111)
            ax.axis("off")
            fig.patch.set_facecolor("white")
            ax.set_facecolor("white")
            fig.text(
                0.5,
                0.92,
                title,
                ha="center",
                va="top",
                fontsize=20,
                weight="bold",
            )
            structured = getattr(self, "_sol_last_structured", None)
            highlights = {}
            if structured is not None:
                highlights = getattr(structured, "highlights", {}) or {}
            metrics = []
            highlight_meta = getattr(self, "_sol_highlight_meta", {})
            # Iterate over items from highlight_meta to apply the per-item logic.
            for key, label in highlight_meta.items():
                value = highlights.get(key)
                if value:
                    metrics.append(f"{label}: {value}")
            if not metrics and highlights:
                # Iterate over items from highlights to apply the per-item logic.
                for key, value in highlights.items():
                    metrics.append(f"{key.replace('_', ' ').title()}: {value}")
            if not metrics:
                metrics.append("No key metrics available.")
            fig.text(
                0.02,
                0.78,
                "Key metrics:\n" + "\n".join(metrics[:4]),
                ha="left",
                va="top",
                fontsize=10,
            )
            narrative = state.get("narrative", "").strip()
            snippet = narrative if len(narrative) <= 300 else narrative[:300] + "..."
            fig.text(
                0.02,
                0.56,
                "Narrative:\n" + (snippet or "No narrative provided."),
                ha="left",
                va="top",
                fontsize=10,
            )
            sections_text = "\n".join(
                f"{idx+1}. {FINAL_REPORT_SECTION_METADATA.get(section_id, {}).get('label', section_id)}"
                # Iterate to apply the per-item logic.
                for idx, section_id in enumerate(sections)
            )
            fig.text(
                0.02,
                0.34,
                "Sections:\n" + sections_text,
                ha="left",
                va="top",
                fontsize=10,
            )
            dpi = self._get_export_dpi()
            try:
                fig.savefig(path, dpi=dpi)
            finally:
                plt.close(fig)
        self._dbg("report.export", "Final report PNG saved path=%s", path)
        try:
            messagebox.showinfo(
                "Final Report PNG", f"Final report summary PNG saved to {path}"
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _merge_final_report_pdfs(
        self, output_path: str, sources: Sequence[Path]
    ) -> Tuple[bool, str]:
        """Merge final report pdfs.
        Used to combine final report pdfs into a single result."""
        try:
            from pypdf import PdfMerger
        except Exception:
            try:
                from PyPDF2 import PdfMerger
            except Exception as exc:
                return False, f"PDF merge library unavailable: {exc}"

        merger = PdfMerger()
        try:
            # Iterate over sources to apply the per-item logic.
            for source in sources:
                if source is None:
                    continue
                merger.append(str(source))
            with open(output_path, "wb") as handle:
                merger.write(handle)
        except Exception as exc:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return False, str(exc)
        finally:
            try:
                merger.close()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        return True, ""

    def _generate_final_report_pdf(self) -> None:
        """Purpose: Generate the Final Report PDF export.
        Why: Provide a single stitched PDF matching the configured layout rules.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            - Opens file dialogs and writes PDF files to disk.
            - Updates settings and uses temporary PDF artifacts.
        Exceptions:
            - Errors are surfaced via message boxes; failures abort export.
        """
        state = self._collect_final_report_state_from_ui()
        sections = state.get("selected_sections") or []
        self._dbg(
            "report.build",
            "Final report PDF generation start sections=%s",
            len(sections),
        )
        if not sections:
            try:
                messagebox.showwarning(
                    "Final Report PDF", "Select at least one section for the report."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        ok, message = self._final_report_columns_ready()
        if not ok:
            try:
                messagebox.showerror("Final Report PDF", message)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        settings["final_report"].clear()
        settings["final_report"].update(copy.deepcopy(state))
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        title = state.get("title", FINAL_REPORT_DEFAULT_STATE["title"])
        slug = self._slugify_final_report_title(title)
        default_name = f"{slug}.pdf"
        path = filedialog.asksaveasfilename(
            title="Save Final Report PDF",
            defaultextension=".pdf",
            filetypes=[("PDF Document", "*.pdf")],
            initialfile=default_name,
        )
        if not path:
            return
        state = self._final_report_safe_state(state)
        self._final_report_current_state = state
        export_profile = state.get(
            "profile_key", FINAL_REPORT_DEFAULT_STATE["profile_key"]
        )
        temp_paths: List[Path] = []
        report_paths: List[Path] = []
        try:
            with self._perf_time("report.export", "final_report_pdf_export"):
                sequence = self._final_report_compute_layout_sequence(state)
                if not sequence:
                    raise RuntimeError("Final report layout could not be assembled.")
                counters = {
                    "page_number": 0,
                    "figure_number": 0,
                    "table_number": 0,
                    "section_figures": {},
                    "section_tables": {},
                }
                last_group: Optional[str] = None
                # Iterate over sequence to apply the per-item logic.
                for entry in sequence:
                    section_id = entry.get("section_id")
                    page_type = entry.get("page_type", "text")
                    if section_id in FINAL_REPORT_EXCLUDED_SECTIONS:
                        continue
                    page_info, last_group = self._final_report_build_page_entry(
                        entry, state, counters, last_group
                    )
                    if page_info is None:
                        continue
                    if page_info.get("combined_failed"):
                        failure_reason = (
                            page_info.get("combined_failure_reason")
                            or "Combined plot could not be generated for this run."
                        )
                        if not self._final_report_confirm_degraded_combined(
                            failure_reason
                        ):
                            return
                        continue
                    fig = page_info["figure"]
                    page_path = self._final_report_export_page_pdf(fig, export_profile)
                    if page_path is None:
                        raise RuntimeError("Failed to export a report page.")
                    report_paths.append(page_path)
                    temp_paths.append(page_path)

                if not report_paths:
                    raise RuntimeError("No report sections were exported.")

                ok, merge_error = self._merge_final_report_pdfs(path, report_paths)
                if not ok:
                    raise RuntimeError(
                        merge_error or "Failed to stitch the final report PDF."
                    )
        except Exception as exc:
            try:
                messagebox.showerror(
                    "Final Report PDF",
                    f"Failed to generate PDF: {exc}",
                )
            except Exception:
                pass
            return
        finally:
            self._final_report_current_state = None
            # Iterate over temp_paths to apply the per-item logic.
            for tmp_path in temp_paths:
                try:
                    tmp_path.unlink()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        try:
            messagebox.showinfo("Final Report PDF", f"Final report PDF saved to {path}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._dbg(
            "report.export",
            "Final report PDF saved path=%s pages=%s",
            path,
            len(report_paths),
        )

    def _final_report_preview_clear_figures(self) -> None:
        """Clear figures.
        Used by final report preview workflows to clear figures."""
        # Iterate over list(self._final_report_preview_pages) to apply the per-item logic.
        for info in list(self._final_report_preview_pages):
            fig = info.get("figure")
            if fig is not None:
                try:
                    plt.close(fig)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        self._final_report_preview_pages = []
        self._final_report_preview_index = 0
        self._final_report_preview_photo = None

    def _final_report_preview_update_navigation_buttons(self) -> None:
        """Update navigation buttons.
        Used by final report preview workflows to update navigation buttons."""
        count = len(self._final_report_preview_pages)
        prev_btn = self._final_report_preview_nav_prev
        next_btn = self._final_report_preview_nav_next
        if prev_btn is not None:
            prev_btn.configure(
                state="normal" if self._final_report_preview_index > 0 else "disabled"
            )
        if next_btn is not None:
            next_btn.configure(
                state=(
                    "normal"
                    if self._final_report_preview_index < count - 1
                    else "disabled"
                )
            )

    def _final_report_preview_effective_dpi(self, fig: Figure) -> float:
        """Purpose: Compute preview-only DPI for the current Final Report page.
        Why: Keep preview zoom screen-reasonable without changing export DPI behavior.
        Args:
            fig (Figure): Matplotlib page figure used for preview rendering.
        Returns:
            float: Effective preview DPI after applying base-DPI and screen-fit clamps.
        Side Effects:
            - None.
        Exceptions:
            - Best-effort guards fall back to defaults when figure/screen metrics fail.
        """
        zoom_factor = self._final_report_preview_zoom_value / 100.0
        base_dpi = float(FINAL_REPORT_PREVIEW_BASE_DPI)
        screen_width = 0
        screen_height = 0
        preview_window = getattr(self, "_final_report_preview_window", None)
        try:
            if preview_window is not None and preview_window.winfo_exists():
                screen_width = int(preview_window.winfo_screenwidth())
                screen_height = int(preview_window.winfo_screenheight())
            else:
                screen_width = int(self.winfo_screenwidth())
                screen_height = int(self.winfo_screenheight())
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            screen_width = 0
            screen_height = 0
        try:
            fig_width_in, fig_height_in = fig.get_size_inches()
        except Exception:
            fig_width_in = 0.0
            fig_height_in = 0.0
        if (
            screen_width > 0
            and screen_height > 0
            and fig_width_in > 0
            and fig_height_in > 0
        ):
            # Clamp 100% preview against current display so preview zoom tracks a
            # screen-native baseline instead of export DPI.
            screen_fit_dpi = min(
                (screen_width * FINAL_REPORT_PREVIEW_BASE_SCREEN_WIDTH_RATIO)
                / fig_width_in,
                (screen_height * FINAL_REPORT_PREVIEW_BASE_SCREEN_HEIGHT_RATIO)
                / fig_height_in,
            )
            if math.isfinite(screen_fit_dpi) and screen_fit_dpi > 0:
                base_dpi = min(base_dpi, screen_fit_dpi)
        base_dpi = max(FINAL_REPORT_PREVIEW_MIN_DPI, base_dpi)
        return max(1.0, base_dpi * zoom_factor)

    def _final_report_preview_apply_initial_geometry(
        self, image_width: int, image_height: int
    ) -> None:
        """Purpose: Apply one-time preview window geometry from rendered image size.
        Why: Open the preview window at a usable page-sized geometry without
            resize loops.
        Args:
            image_width (int): Rendered preview page width in pixels.
            image_height (int): Rendered preview page height in pixels.
        Returns:
            None.
        Side Effects:
            - Updates the preview toplevel geometry once, clamped to screen bounds.
            - Centers the preview window on the current display.
            - Clears the one-time auto-size latch after geometry is applied.
        Exceptions:
            - Best-effort guards keep preview rendering alive if geometry probing fails.
        """
        if not getattr(self, "_final_report_preview_needs_initial_geometry", False):
            return
        window = getattr(self, "_final_report_preview_window", None)
        canvas = getattr(self, "_final_report_preview_canvas", None)
        try:
            if (
                window is None
                or canvas is None
                or not window.winfo_exists()
                or image_width <= 0
                or image_height <= 0
            ):
                return
            try:
                window.update_idletasks()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            # Measure non-canvas chrome/controls so the page image is fully visible.
            non_canvas_width = max(
                0, int(window.winfo_reqwidth()) - int(canvas.winfo_reqwidth())
            )
            non_canvas_height = max(
                0, int(window.winfo_reqheight()) - int(canvas.winfo_reqheight())
            )
            target_width = int(image_width + non_canvas_width)
            target_height = int(image_height + non_canvas_height)
            screen_width = int(window.winfo_screenwidth())
            screen_height = int(window.winfo_screenheight())
            max_width = max(
                FINAL_REPORT_PREVIEW_MIN_WINDOW_WIDTH,
                int(screen_width * FINAL_REPORT_PREVIEW_WINDOW_MAX_SCREEN_RATIO)
                - (FINAL_REPORT_PREVIEW_WINDOW_SCREEN_MARGIN_PX * 2),
            )
            max_height = max(
                FINAL_REPORT_PREVIEW_MIN_WINDOW_HEIGHT,
                int(screen_height * FINAL_REPORT_PREVIEW_WINDOW_MAX_SCREEN_RATIO)
                - (FINAL_REPORT_PREVIEW_WINDOW_SCREEN_MARGIN_PX * 2),
            )
            clamped_width = max(
                FINAL_REPORT_PREVIEW_MIN_WINDOW_WIDTH, min(target_width, max_width)
            )
            clamped_height = max(
                FINAL_REPORT_PREVIEW_MIN_WINDOW_HEIGHT, min(target_height, max_height)
            )
            pos_x = max(0, (screen_width - clamped_width) // 2)
            pos_y = max(0, (screen_height - clamped_height) // 2)
            window.geometry(f"{clamped_width}x{clamped_height}+{pos_x}+{pos_y}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        finally:
            self._final_report_preview_needs_initial_geometry = False

    def _final_report_preview_render_current_page(self) -> None:
        """Purpose: Render the current Final Report preview page into the
            preview canvas.
        Why: Keep page navigation and zoom changes synchronized with a single
            preview render.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            - Writes a rendered page image into the preview canvas.
            - Updates page labels, caption text, save button state, and nav controls.
            - Applies one-time initial preview window geometry when opening the window.
        Exceptions:
            - Render/encode failures are swallowed to avoid interrupting the UI
              workflow.
        """
        pages = self._final_report_preview_pages
        if not pages:
            canvas = self._final_report_preview_canvas
            if canvas is not None:
                canvas.delete("all")
            label_widget = self._final_report_preview_page_label_widget
            if label_widget is not None:
                label_widget.configure(text="")
            caption = self._final_report_preview_caption_label
            if caption is not None:
                caption.configure(text="")
            save_btn = self._final_report_preview_save_button
            if save_btn is not None:
                save_btn.configure(state="disabled")
            self._final_report_preview_update_navigation_buttons()
            return
        index = max(0, min(len(pages) - 1, self._final_report_preview_index))
        self._final_report_preview_index = index
        info = pages[index]
        fig = info["figure"]
        buffer = io.BytesIO()
        dpi = self._final_report_preview_effective_dpi(fig)
        try:
            fig.savefig(buffer, format="png", dpi=dpi)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        buffer.seek(0)
        encoded = base64.b64encode(buffer.getvalue()).decode("ascii")
        photo = tk.PhotoImage(data=encoded)
        self._final_report_preview_photo = photo
        width = photo.width()
        height = photo.height()
        self._final_report_preview_apply_initial_geometry(width, height)
        canvas = self._final_report_preview_canvas
        if canvas is not None:
            canvas.delete("all")
            canvas.create_image(0, 0, anchor="nw", image=photo)
            canvas.configure(scrollregion=(0, 0, width, height))
            canvas.xview_moveto(0)
            canvas.yview_moveto(0)
        page_label_widget = self._final_report_preview_page_label_widget
        if page_label_widget is not None:
            page_type = info.get("page_type") or ""
            label_text = f"Page {index + 1} of {len(pages)}"
            if page_type:
                label_text += f" ({page_type.title()})"
            page_label_widget.configure(text=label_text)
        caption_label = self._final_report_preview_caption_label
        if caption_label is not None:
            caption_label.configure(text=info.get("display_caption", ""))
        save_btn = self._final_report_preview_save_button
        if save_btn is not None:
            save_btn.configure(state="normal")
        self._final_report_preview_update_navigation_buttons()

    def _final_report_preview_prev_page(self) -> None:
        """Perform final report preview prev page.
        Used to keep the workflow logic localized and testable."""
        if self._final_report_preview_index <= 0:
            return
        self._final_report_preview_index -= 1
        self._final_report_preview_render_current_page()

    def _final_report_preview_next_page(self) -> None:
        """Perform final report preview next page.
        Used to keep the workflow logic localized and testable."""
        if (
            self._final_report_preview_index
            >= len(self._final_report_preview_pages) - 1
        ):
            return
        self._final_report_preview_index += 1
        self._final_report_preview_render_current_page()

    def _final_report_preview_zoom_changed(self, _event=None) -> None:
        """Perform final report preview zoom changed.
        Used to keep the workflow logic localized and testable."""
        combo_var = self._final_report_preview_zoom_combo_var
        if combo_var is None:
            return
        text = combo_var.get() or ""
        try:
            value = int(text.strip().rstrip("%"))
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return
        value = max(25, min(400, value))
        self._final_report_preview_zoom_value = value
        combo_var.set(f"{value}%")
        settings["final_report_preview_zoom"] = value
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        if self._final_report_preview_pages:
            self._final_report_preview_render_current_page()

    def _final_report_preview_save_current(self) -> None:
        """Save current.
        Used by final report preview workflows to save current."""
        if not self._final_report_preview_pages:
            return
        info = self._final_report_preview_pages[self._final_report_preview_index]
        fig = info["figure"]
        section_id = info.get("section_id") or "page"
        current_title = settings.get("final_report", {}).get("title", "final report")
        slug = self._slugify_final_report_title(current_title)
        default_name = f"{slug}_{section_id}.png"
        path = filedialog.asksaveasfilename(
            title="Save Final Report Preview",
            defaultextension=".png",
            filetypes=[
                ("PNG Image", "*.png"),
                ("PDF Document", "*.pdf"),
                ("SVG Vector", "*.svg"),
            ],
            initialfile=default_name,
        )
        if not path:
            return
        fmt = os.path.splitext(path)[1].lstrip(".").lower()
        if fmt not in ("png", "pdf", "svg"):
            fmt = "png"
        try:
            fig.savefig(path, dpi=self._get_export_dpi(), format=fmt)
            messagebox.showinfo("Preview Save", f"Preview saved to {path}")
        except Exception as exc:
            try:
                messagebox.showerror("Preview Save", f"Failed to save preview: {exc}")
            except Exception:
                pass

    def _final_report_build_selected_page(
        self, section_id: str, state: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """Purpose: Build a single report page for a selected section.
        Why: Enable targeted preview without rendering the full report.
        Args:
            section_id (str): Section identifier selected in the UI.
            state (Dict[str, Any]): Final report settings state.
        Returns:
            Optional[Dict[str, Any]]: Page info dict, or None if unavailable.
        Side Effects:
            - Creates and closes interim figures for skipped pages.
        Exceptions:
            - None; best-effort rendering returns None on failure.
        """
        state = self._final_report_safe_state(state)
        sequence = self._final_report_compute_layout_sequence(state)
        if not sequence:
            return None
        counters = {
            "page_number": 0,
            "figure_number": 0,
            "table_number": 0,
            "section_figures": {},
            "section_tables": {},
        }
        last_group: Optional[str] = None
        # Iterate over sequence to build pages until the target section is reached.
        for entry in sequence:
            if entry.get("section_id") in FINAL_REPORT_EXCLUDED_SECTIONS:
                continue
            page_info, last_group = self._final_report_build_page_entry(
                entry, state, counters, last_group
            )
            if page_info is None:
                continue
            if (
                page_info.get("section_id") == section_id
                and not page_info.get("is_caption_page")
            ):
                return page_info
            fig = page_info.get("figure")
            if fig is not None:
                try:
                    plt.close(fig)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        return None

    def _final_report_render_selected_page_preview(self) -> None:
        """Purpose: Render a single selected page preview.
        Why: Allow focused inspection of one report section layout.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            - Updates preview window with a single page figure.
            - Updates persisted final report settings.
        Exceptions:
            - Errors are shown via message boxes when selection is invalid.
        """
        listbox = getattr(self, "_final_report_section_order_listbox", None)
        if listbox is None:
            return
        selection = listbox.curselection()
        if not selection:
            try:
                messagebox.showwarning(
                    "Final Report Preview", "Select a section to render first."
                )
            except Exception:
                pass
            return
        index = selection[0]
        if index >= len(self._final_report_section_order):
            return
        section_id = self._final_report_section_order[index]
        state = self._collect_final_report_state_from_ui()
        settings["final_report"].clear()
        settings["final_report"].update(copy.deepcopy(state))
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        page_info = self._final_report_build_selected_page(section_id, state)
        if page_info is None:
            try:
                messagebox.showwarning(
                    "Final Report Preview",
                    "Selected section could not be rendered for preview.",
                )
            except Exception:
                pass
            return
        self._open_final_report_preview_window([page_info])

    def _open_final_report_preview_window(
        self, page_figures: Optional[List[Dict[str, Any]]] = None
    ) -> None:
        """Purpose: Open or refresh the live Final Report preview window.
        Why: Show rendered report pages for visual inspection.
        Args:
            page_figures (Optional[List[Dict[str, Any]]]): Prebuilt page figures.
        Returns:
            None.
        Side Effects:
            - Builds report figures and opens/updates the preview window.
        Exceptions:
            - Errors are surfaced via message boxes.
        """
        if page_figures is None:
            page_figures = self._final_report_build_page_figures(
                self._collect_final_report_state_from_ui()
            )
        if not page_figures:
            try:
                messagebox.showwarning(
                    "Live Preview", "No sections are available for preview."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        if (
            self._final_report_preview_window is not None
            and self._final_report_preview_window.winfo_exists()
        ):
            self._final_report_preview_clear_figures()
            self._final_report_preview_pages = page_figures
            self._final_report_preview_index = 0
            self._final_report_preview_render_current_page()
            try:
                self._final_report_preview_window.deiconify()
                self._final_report_preview_window.lift()
                self._final_report_preview_window.focus_force()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return
        self._final_report_preview_clear_figures()
        self._final_report_preview_pages = page_figures
        window = tk.Toplevel(self)
        window.title("Live Final Report Preview")
        window.transient(self)
        window.minsize(
            FINAL_REPORT_PREVIEW_MIN_WINDOW_WIDTH,
            FINAL_REPORT_PREVIEW_MIN_WINDOW_HEIGHT,
        )
        window.protocol("WM_DELETE_WINDOW", self._close_final_report_preview_window)
        self._final_report_preview_window = window
        self._final_report_preview_needs_initial_geometry = True

        container = ttk.Frame(window, padding=8)
        container.pack(fill="both", expand=True)

        canvas_container = ttk.Frame(container)
        canvas_container.pack(fill="both", expand=True)
        canvas_container.grid_rowconfigure(0, weight=1)
        canvas_container.grid_columnconfigure(0, weight=1)
        canvas = tk.Canvas(canvas_container, bg="white", highlightthickness=0)
        canvas.grid(row=0, column=0, sticky="nsew")
        vert_scroll = ttk.Scrollbar(
            canvas_container, orient="vertical", command=canvas.yview
        )
        vert_scroll.grid(row=0, column=1, sticky="ns")
        horiz_scroll = ttk.Scrollbar(
            canvas_container, orient="horizontal", command=canvas.xview
        )
        horiz_scroll.grid(row=1, column=0, sticky="ew")
        canvas.configure(
            yscrollcommand=vert_scroll.set, xscrollcommand=horiz_scroll.set
        )
        self._final_report_preview_canvas = canvas

        caption_label = ttk.Label(
            container, text="", wraplength=620, justify="left", anchor="w"
        )
        caption_label.pack(fill="x", pady=(4, 0))
        self._final_report_preview_caption_label = caption_label

        controls = ttk.Frame(container)
        controls.pack(fill="x", pady=(4, 0))
        prev_btn = ttk.Button(
            controls,
            text="Previous Page",
            command=self._final_report_preview_prev_page,
        )
        prev_btn.pack(side="left")
        next_btn = ttk.Button(
            controls,
            text="Next Page",
            command=self._final_report_preview_next_page,
        )
        next_btn.pack(side="left", padx=(4, 0))
        self._final_report_preview_nav_prev = prev_btn
        self._final_report_preview_nav_next = next_btn
        page_label = ttk.Label(controls, text="")
        page_label.pack(side="left", padx=(8, 0))
        self._final_report_preview_page_label_widget = page_label
        ttk.Label(controls, text="Zoom:").pack(side="left", padx=(16, 0))
        zoom_options = [50, 75, 100, 150, 200]
        zoom_var = tk.StringVar(value=f"{self._final_report_preview_zoom_value}%")
        combo = ttk.Combobox(
            controls,
            values=[f"{value}%" for value in zoom_options],
            textvariable=zoom_var,
            state="readonly",
            width=6,
        )
        combo.pack(side="left", padx=(4, 0))
        combo.bind("<<ComboboxSelected>>", self._final_report_preview_zoom_changed)
        self._final_report_preview_zoom_combo_var = zoom_var
        save_btn = ttk.Button(
            controls,
            text="Save Current Page",
            command=self._final_report_preview_save_current,
        )
        save_btn.pack(side="right")
        self._final_report_preview_save_button = save_btn

        self._final_report_preview_render_current_page()

    def _close_final_report_preview_window(self) -> None:
        """Close final report preview window.
        Used by UI actions to close final report preview window safely."""
        window = getattr(self, "_final_report_preview_window", None)
        if window is None:
            return
        try:
            window.destroy()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        self._final_report_preview_window = None
        self._final_report_preview_canvas = None
        self._final_report_preview_nav_prev = None
        self._final_report_preview_nav_next = None
        self._final_report_preview_page_label_widget = None
        self._final_report_preview_caption_label = None
        self._final_report_preview_zoom_combo_var = None
        self._final_report_preview_save_button = None
        self._final_report_preview_needs_initial_geometry = False
        self._final_report_preview_clear_figures()

    def _final_report_table_caption(self, section_id: str) -> str:
        """Perform final report table caption.
        Used to keep the workflow logic localized and testable."""
        captions = {
            "cycle_stats_table": "Cycle statistics.",
            "cycle_timeline_table": "Cycle speciation timeline.",
            "key_metrics": "Key metrics summary.",
        }
        return captions.get(
            section_id,
            FINAL_REPORT_SECTION_METADATA.get(section_id, {}).get("label", section_id),
        )

    def _build_tab_contamination(self):
        """Build tab contamination.
        Used to assemble tab contamination during UI or plot setup."""

        frame = self.tab_contamination

        frame.grid_columnconfigure(0, weight=1)
        frame.grid_rowconfigure(0, weight=0)
        frame.grid_rowconfigure(1, weight=1)

        settings_container = ttk.Frame(frame)
        settings_container.grid(row=0, column=0, sticky="nsew")
        settings_container.grid_columnconfigure(0, weight=1)
        settings_container.grid_rowconfigure(0, weight=1)

        settings_canvas = tk.Canvas(settings_container, highlightthickness=0)
        settings_canvas.grid(row=0, column=0, sticky="nsew", padx=(12, 0), pady=(12, 6))

        settings_scrollbar = ttk.Scrollbar(
            settings_container, orient="vertical", command=settings_canvas.yview
        )
        settings_scrollbar.grid(
            row=0, column=1, sticky="ns", padx=(0, 12), pady=(12, 6)
        )

        settings_canvas.configure(yscrollcommand=settings_scrollbar.set, height=360)

        settings_frame = ttk.Frame(settings_canvas)
        settings_window = settings_canvas.create_window(
            (0, 0), window=settings_frame, anchor="nw"
        )

        # Closure captures _build_tab_contamination state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_tab_contamination.
        def _refresh_scroll_region(_event):
            """Refresh scroll region.
            Used to sync scroll region with current settings."""
            settings_canvas.configure(scrollregion=settings_canvas.bbox("all"))

        settings_frame.bind("<Configure>", _refresh_scroll_region)

        # Closure captures _build_tab_contamination local context to keep helper logic scoped and invoked directly within _build_tab_contamination.
        def _expand_settings_width(event):
            """Perform expand settings width.
            Used to keep the workflow logic localized and testable."""
            settings_canvas.itemconfigure(settings_window, width=event.width)

        settings_canvas.bind("<Configure>", _expand_settings_width)

        # Closure captures _build_tab_contamination state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _build_tab_contamination.
        def _on_mousewheel(event):
            """Handle mousewheel.
            Used as an event callback for mousewheel."""
            delta = event.delta
            if delta == 0:
                return
            step = -1 if delta > 0 else 1
            if abs(delta) >= 120:
                step = int(-delta / 120)
            settings_canvas.yview_scroll(step, "units")
            return "break"

        # Closure captures _build_tab_contamination local context to keep helper logic scoped and invoked directly within _build_tab_contamination.
        def _bind_mousewheel(widget):
            """Perform bind mousewheel.
            Used to keep the workflow logic localized and testable."""
            widget.bind("<MouseWheel>", _on_mousewheel, add="+")
            widget.bind(
                "<Button-4>",
                lambda _event: settings_canvas.yview_scroll(-1, "units"),
                add="+",
            )
            widget.bind(
                "<Button-5>",
                lambda _event: settings_canvas.yview_scroll(1, "units"),
                add="+",
            )
            # Iterate over widget.winfo_children() to apply the per-item logic.
            for child in widget.winfo_children():
                _bind_mousewheel(child)

        # Closure captures _build_tab_contamination local context to keep helper logic scoped and invoked directly within _build_tab_contamination.
        def _init_scroll_bindings():
            """Initialize scroll bindings.
            Used to configure scroll bindings at creation time."""
            _bind_mousewheel(settings_canvas)
            _bind_mousewheel(settings_frame)

        self.after_idle(_init_scroll_bindings)

        settings_frame.grid_columnconfigure(0, weight=1)

        ttk.Label(
            settings_frame,
            text=(
                "Estimate sodium carbonate contamination with optional solid-liquid "
                "equilibrium and CO2 diagnostics."
            ),
            wraplength=620,
            justify="left",
        ).grid(row=0, column=0, sticky="w", padx=0, pady=(0, 6))

        base_font = tkfont.nametofont("TkDefaultFont")
        bold_font = base_font.copy()
        bold_font.configure(weight="bold")

        ph_box = tk.LabelFrame(
            settings_frame, text="Sodium Bicarbonate Sample pH", font=bold_font
        )
        ph_box.grid(row=1, column=0, sticky="ew", padx=0, pady=(0, 6))
        ph_box.grid_columnconfigure(0, weight=1)

        ph_var = tk.StringVar(value="9.10")
        ttk.Entry(ph_box, textvariable=ph_var, font=bold_font, justify="center").grid(
            row=0, column=0, sticky="ew", padx=12, pady=8
        )

        input_box = ttk.LabelFrame(settings_frame, text="Additional Inputs")
        input_box.grid(row=2, column=0, sticky="ew", padx=0, pady=6)
        input_box.grid_columnconfigure(1, weight=1)

        core_specs = [
            ("mass_naoh_g", "NaOH Pellet Mass (g)", "700", False),
            ("purity_wt_percent", "NaOH Purity (wt%)", "99.99", False),
            ("temp_c", "Measurement Temperature (C)", "25.0", False),
            ("final_volume_l", "Final Volume (L)", "2.5", False),
            ("pka2", "pKa2 (second dissociation of carbonic acid)", "10.33", False),
            (
                "naoh_carbonate_wt_percent",
                "CoA Carbonate as Na2CO3 (wt%)",
                "",
                True,
            ),
        ]

        equilibrium_specs = [
            ("slurry_ph", "Slurry pH override (measured slurry pH)", "", True),
            ("pka1", "pKa1 (first dissociation of carbonic acid)", "6.35", False),
            ("kh_co2_m_per_atm", "Henry constant for CO2 (mol/L/atm)", "0.033", False),
            ("pco2_atm", "pCO2 for Henry's law (atm)", "", True),
            ("s_hco3_max_m", "Dissolved [HCO3-] cap (mol/L)", "1.10", True),
            ("s_co3_max_m", "Dissolved [CO3^2-] cap (mol/L)", "2.00", True),
            ("max_iter", "SLE max iterations", "100", False),
            ("tol_mol", "SLE convergence tolerance (mol)", "1e-9", False),
        ]
        self._equilibrium_keys = [key for key, *_ in equilibrium_specs]
        self._equilibrium_entries = []
        self._equilibrium_enabled = tk.BooleanVar(
            value=bool(settings.get("contam_equilibrium_enabled", False))
        )

        self._contam_vars = {}
        self._contam_field_meta = {}

        self._contam_vars["ph"] = ph_var
        self._contam_field_meta["ph"] = {
            "label": "Mother Liquor pH",
            "optional": False,
        }

        # Iterate over indexed elements from core_specs to apply the per-item logic.
        for row_index, (key, label, default, optional) in enumerate(core_specs):
            ttk.Label(input_box, text=label).grid(
                row=row_index, column=0, sticky="w", padx=(8, 8), pady=4
            )
            var = tk.StringVar(value=default)
            ttk.Entry(input_box, textvariable=var).grid(
                row=row_index, column=1, sticky="ew", padx=(0, 8), pady=4
            )
            self._contam_vars[key] = var
            self._contam_field_meta[key] = {"label": label, "optional": optional}

        ttk.Label(
            input_box,
            text="Leave the CoA carbonate field blank if the value is unavailable.",
            wraplength=520,
            justify="left",
        ).grid(
            row=len(core_specs),
            column=0,
            columnspan=2,
            sticky="w",
            padx=8,
            pady=(4, 8),
        )

        ttk.Checkbutton(
            settings_frame,
            text="Enable Equilibrium Options (SLE + CO2 diagnostics)",
            variable=self._equilibrium_enabled,
            command=self._toggle_equilibrium_inputs,
        ).grid(row=3, column=0, sticky="w", padx=0, pady=(0, 0))

        equilibrium_box = ttk.LabelFrame(
            settings_frame, text="Equilibrium Options (optional)"
        )
        equilibrium_box.grid(row=4, column=0, sticky="ew", padx=0, pady=6)
        equilibrium_box.grid_columnconfigure(1, weight=1)

        # Iterate over indexed elements from equilibrium_specs to apply the per-item logic.
        for row_index, (key, label, default, optional) in enumerate(equilibrium_specs):
            ttk.Label(equilibrium_box, text=label).grid(
                row=row_index, column=0, sticky="w", padx=(8, 8), pady=4
            )
            var = tk.StringVar(value=default)
            entry = ttk.Entry(equilibrium_box, textvariable=var)
            entry.grid(row=row_index, column=1, sticky="ew", padx=(0, 8), pady=4)
            self._contam_vars[key] = var
            self._contam_field_meta[key] = {"label": label, "optional": optional}
            self._equilibrium_entries.append(entry)

        ttk.Label(
            equilibrium_box,
            text=(
                "Leave slurry pH blank to reuse the mother liquor value. Clear a "
                "solubility cap to disable precipitation limits."
            ),
            wraplength=520,
            justify="left",
        ).grid(
            row=len(equilibrium_specs),
            column=0,
            columnspan=2,
            sticky="w",
            padx=8,
            pady=(4, 8),
        )

        summary_box = ttk.LabelFrame(frame, text="Summary")
        summary_box.grid(row=1, column=0, sticky="nsew", padx=12, pady=(0, 12))

        summary_controls = ttk.Frame(summary_box)
        summary_controls.pack(side="top", fill="x", padx=8, pady=(8, 0))

        ttk.Button(
            summary_controls,
            text="Run Contamination Calculation",
            command=self._run_contamination_calculation,
        ).pack(side="left", padx=(0, 8))

        ttk.Button(
            summary_controls,
            text="Save as PNG",
            command=self._save_contamination_summary_png,
        ).pack(side="right")

        summary_text = scrolledtext.ScrolledText(
            summary_box, height=22, wrap="word", state="disabled"
        )
        summary_text.pack(fill="both", expand=True, padx=8, pady=(4, 8))

        self._contam_summary = summary_text
        self._update_contamination_summary(
            "Enter process inputs above and select Run Contamination Calculation "
            "to see the contamination summary."
        )
        self._toggle_equilibrium_inputs()

    def _update_contamination_summary(self, message):
        """Update contamination summary.
        Used to keep contamination summary in sync with current state."""

        widget = getattr(self, "_contam_summary", None)

        if widget is None or not widget.winfo_exists():

            return

        widget.configure(state="normal")
        widget.delete("1.0", "end")
        widget.insert("end", message.strip() if message else "")
        widget.configure(state="disabled")
        widget.see("end")

    def _save_contamination_summary_png(self):
        """Save contamination summary PNG.
        Used when persisting contamination summary PNG to storage."""

        widget = getattr(self, "_contam_summary", None)

        if widget is None or not widget.winfo_exists():

            try:

                messagebox.showwarning(
                    "Contamination Calculator",
                    "The contamination summary is not available yet.",
                )

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            return

        try:

            text = widget.get("1.0", "end").strip()

        except Exception:

            text = ""

        if not text:

            try:

                messagebox.showinfo(
                    "Contamination Calculator",
                    "The contamination summary is currently empty. "
                    "Run the calculation before saving.",
                )

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            return

        path = filedialog.asksaveasfilename(
            title="Save Contamination Summary as PNG",
            defaultextension=".png",
            filetypes=[("PNG Image", "*.png")],
            initialfile="contamination_summary.png",
        )

        if not path:

            return

        try:
            self._export_text_summary_png(
                text, path, profile_key="contamination_summary_png"
            )

        except Exception as exc:

            try:

                messagebox.showerror(
                    "Contamination Calculator",
                    f"Failed to save contamination summary: {exc}",
                )

            except Exception:

                pass

            return

    def _toggle_equilibrium_inputs(self):
        """Toggle equilibrium inputs.
        Used to flip equilibrium inputs and refresh dependent views."""

        enabled = bool(
            getattr(self, "_equilibrium_enabled", tk.BooleanVar(value=False)).get()
        )
        # Iterate over getattr(self, "_equilibrium_entries", []) to apply the per-item logic.
        for entry in getattr(self, "_equilibrium_entries", []):
            try:
                entry.configure(state="normal" if enabled else "disabled")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        settings["contam_equilibrium_enabled"] = enabled
        try:
            _save_settings_to_disk()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _run_contamination_calculation(self):
        """Run contamination calculation.
        Used to execute contamination calculation and coordinate results."""

        field_meta = getattr(self, "_contam_field_meta", {})

        vars_map = getattr(self, "_contam_vars", {})

        if not field_meta or not vars_map:

            return

        # Closure captures _run_contamination_calculation local context to keep helper logic scoped and invoked directly within _run_contamination_calculation.
        def _parse_field(key):
            """Parse field.
            Used to interpret field inputs safely."""
            meta = field_meta.get(key, {})
            label = meta.get("label", key)
            optional = bool(meta.get("optional"))
            var = vars_map.get(key)
            raw_value = var.get().strip() if var is not None else ""
            if not raw_value:
                if optional:
                    return None
                raise ValueError(f"{label} is required.")
            try:
                value = float(raw_value)
            except ValueError as exc:
                raise ValueError(f"{label} must be numeric.") from exc
            if not math.isfinite(value):
                raise ValueError(f"{label} must be a finite number.")
            return value

        equilibrium_enabled = bool(self._equilibrium_enabled.get())
        slurry_ph = None
        pka1_value = None
        henry_constant = None
        pco2_value = None
        s_hco3_cap = None
        s_co3_cap = None
        max_iter_int = None
        tol_value = None

        try:
            mass_naoh = _parse_field("mass_naoh_g")
            if mass_naoh <= 0.0:
                raise ValueError("NaOH Pellet Mass (g) must be greater than zero.")

            purity = _parse_field("purity_wt_percent")
            if not (0.0 < purity <= 100.0):
                raise ValueError("NaOH Purity (wt%) must be between 0 and 100.")

            ph_value = _parse_field("ph")
            if not (0.0 <= ph_value <= 14.5):
                raise ValueError("Mother Liquor pH must be between 0 and 14.5.")

            temp_c = _parse_field("temp_c")

            final_volume = _parse_field("final_volume_l")
            if final_volume <= 0.0:
                raise ValueError("Final Volume (L) must be greater than zero.")

            pka2_value = _parse_field("pka2")
            if pka2_value <= 0.0:
                raise ValueError("pKa2 must be greater than zero.")

            carbonate_wt = _parse_field("naoh_carbonate_wt_percent")
            if carbonate_wt is not None and not (0.0 <= carbonate_wt <= 100.0):
                raise ValueError(
                    "CoA Carbonate as Na2CO3 (wt%) must be between 0 and 100."
                )

            if equilibrium_enabled:
                slurry_ph = _parse_field("slurry_ph")
                if slurry_ph is not None and not (0.0 <= slurry_ph <= 14.5):
                    raise ValueError("Slurry pH override must be between 0 and 14.5.")

                pka1_value = _parse_field("pka1")
                if pka1_value is None or pka1_value <= 0.0:
                    raise ValueError("pKa1 must be greater than zero.")

                henry_constant = _parse_field("kh_co2_m_per_atm")
                if henry_constant is None or henry_constant < 0.0:
                    raise ValueError("Henry constant for CO2 must be non-negative.")

                pco2_value = _parse_field("pco2_atm")
                if pco2_value is not None and pco2_value < 0.0:
                    raise ValueError("pCO2 must be non-negative.")

                s_hco3_cap = _parse_field("s_hco3_max_m")
                if s_hco3_cap is not None and s_hco3_cap < 0.0:
                    raise ValueError("[HCO3-] cap must be non-negative.")

                s_co3_cap = _parse_field("s_co3_max_m")
                if s_co3_cap is not None and s_co3_cap < 0.0:
                    raise ValueError("[CO3^2-] cap must be non-negative.")

                max_iter_value = _parse_field("max_iter")
                if max_iter_value is None or max_iter_value <= 0.0:
                    raise ValueError("SLE max iterations must be greater than zero.")
                if abs(max_iter_value - round(max_iter_value)) > 1e-9:
                    raise ValueError("SLE max iterations must be an integer.")
                max_iter_int = int(round(max_iter_value))

                tol_value = _parse_field("tol_mol")
                if tol_value is None or tol_value <= 0.0:
                    raise ValueError(
                        "SLE convergence tolerance must be greater than zero."
                    )

        except ValueError as exc:
            messagebox.showerror("Invalid Input", str(exc))
            return

        inputs = CarbonateInputs(
            mass_naoh_g=mass_naoh,
            purity_wt_percent=purity,
            ph=ph_value,
            temp_c=temp_c,
            final_volume_l=final_volume,
            pka2=pka2_value,
            naoh_carbonate_wt_percent=carbonate_wt,
        )

        if equilibrium_enabled:
            options = CarbonateEquilibriumOptions(
                pka1=pka1_value,
                kh_co2_m_per_atm=henry_constant,
                pco2_atm=pco2_value,
                slurry_ph=slurry_ph,
                s_hco3_max_m=s_hco3_cap,
                s_co3_max_m=s_co3_cap,
                max_iter=max_iter_int,
                tol_mol=tol_value,
            )
            augmented = compute_carbonate_contamination_augmented(inputs, options)
            base_results = augmented.baseline
            sle_ph = options.slurry_ph if options.slurry_ph is not None else inputs.ph
        else:
            options = None
            augmented = None
            base_results = compute_carbonate_contamination(inputs)
            sle_ph = None

        pkw = carbonate_pkw_from_temp(inputs.temp_c)

        lines = [
            "Inputs:",
            f"  NaOH pellet mass: {inputs.mass_naoh_g:.3f} g",
            f"  NaOH purity: {inputs.purity_wt_percent:.3f} wt%",
            f"  Mother liquor pH: {inputs.ph:.3f}",
            f"  Measurement temperature: {inputs.temp_c:.3f} C",
            f"  Final volume: {inputs.final_volume_l:.3f} L",
            f"  pKa2: {inputs.pka2:.3f}",
        ]

        if inputs.naoh_carbonate_wt_percent is None:
            lines.append("  CoA carbonate (Na2CO3): not provided")
        else:
            lines.append(
                "  CoA carbonate (Na2CO3): "
                f"{inputs.naoh_carbonate_wt_percent:.3f} wt%"
            )

        lines.extend(
            [
                "",
                "Derived values:",
                f"  pKw at {inputs.temp_c:.3f} C: {pkw:.4f}",
                f"  [H+] moles: {base_results.hydrogen_moles:.6e}",
                f"  [OH-] moles: {base_results.hydroxide_moles:.6e}",
                f"  Ratio [CO3^2-]/[HCO3-]: {base_results.ratio:.6f}",
                "",
                "Speciation and contamination:",
                f"  Total Na+ (mol): {base_results.sodium_moles:.6f}",
                f"  n(HCO3-) (mol): {base_results.bicarbonate_moles:.6f}",
                f"  n(CO3^2-) (mol): {base_results.carbonate_moles:.6f}",
                f"  n(NaHCO3) (mol): {base_results.sodium_bicarbonate_moles:.6f}",
                f"  n(Na2CO3) (mol): {base_results.sodium_carbonate_moles:.6f}",
                f"  Na2CO3 contamination mass: {base_results.sodium_carbonate_mass_g:.4f} g",
            ]
        )

        if base_results.pellet_sodium_carbonate_moles > 0.0:
            lines.append(
                "  Na2CO3 from pellets: "
                f"{base_results.pellet_sodium_carbonate_mass_g:.4f} g "
                f"({base_results.pellet_sodium_carbonate_moles:.6f} mol)"
            )
        else:
            lines.append("  Na2CO3 from pellets: not provided")

        if equilibrium_enabled and augmented is not None:

            # Closure captures _run_contamination_calculation local context to keep helper logic scoped and invoked directly within _run_contamination_calculation.
            def _fmt_optional(value, fmt="{:.3f}", default="not provided"):
                """Perform fmt optional.
                Used to keep the workflow logic localized and testable."""
                return default if value is None else fmt.format(value)

            lines.extend(
                [
                    "",
                    "Equilibrium options:",
                    f"  Slurry pH override: {_fmt_optional(slurry_ph)}",
                    f"  pKa1: {pka1_value:.3f}",
                    f"  Henry constant (mol/L/atm): {henry_constant:.5f}",
                    f"  pCO2 (atm): {_fmt_optional(pco2_value)}",
                    f"  [HCO3-] cap (mol/L): {_fmt_optional(s_hco3_cap)}",
                    f"  [CO3^2-] cap (mol/L): {_fmt_optional(s_co3_cap)}",
                    f"  SLE max iterations: {max_iter_int:d}",
                    f"  SLE tolerance (mol): {tol_value:.2e}",
                ]
            )

            lines.extend(
                [
                    "",
                    f"SLE at pH {sle_ph:.3f} (iterations: {augmented.iterations}):",
                    f"  Na+ dissolved after SLE: {augmented.sodium_dissolved_moles:.6f} mol",
                    f"  n(HCO3-) dissolved: {augmented.bicarbonate_aqueous_moles:.6f} mol",
                    f"  n(CO3^2-) dissolved: {augmented.carbonate_aqueous_moles:.6f} mol",
                    (
                        "  NaHCO3(s): "
                        f"{augmented.sodium_bicarbonate_solid_moles:.6f} mol "
                        f"({augmented.sodium_bicarbonate_solid_mass_g:.4f} g)"
                    ),
                    (
                        "  Na2CO3(s): "
                        f"{augmented.sodium_carbonate_solid_moles:.6f} mol "
                        f"({augmented.sodium_carbonate_solid_mass_g:.4f} g)"
                    ),
                    f"  Solid total mass: {augmented.solid_total_mass_g:.4f} g",
                    (
                        "  Na2CO3 mass fraction in solids: "
                        f"{100.0 * augmented.solid_sodium_carbonate_mass_fraction:.2f} %"
                    ),
                ]
            )

            lines.extend(
                [
                    "",
                    "CO2 / DIC diagnostics:",
                    f"  CO2* implied (mol): {augmented.co2star_moles:.6f}",
                    f"  Dissolved inorganic carbon (mol): {augmented.dic_moles:.6f}",
                ]
            )

            if augmented.co2star_henry_moles is not None:
                lines.append(
                    "  CO2* (Henry's law) (mol): "
                    f"{augmented.co2star_henry_moles:.6f}"
                )
                if augmented.co2star_consistency_ratio is not None:
                    lines.append(
                        "  Implied/Henry ratio: "
                        f"{augmented.co2star_consistency_ratio:.3f}"
                    )

            lines.extend(
                [
                    "",
                    "Notes:",
                    "  Charge balance uses measured pH with a temperature adjusted pKw.",
                    "  Solid-liquid equilibrium applies when solubility caps are provided.",
                    "  Provide a pCO2 value to compare implied CO2* against Henry's law.",
                ]
            )
        else:
            lines.extend(
                [
                    "",
                    "Equilibrium options:",
                    "  Disabled (SLE and CO2 diagnostics not evaluated).",
                    "",
                    "Notes:",
                    "  Charge balance uses measured pH with a temperature adjusted pKw.",
                    "  Enable equilibrium options to model precipitation limits or Henry-law comparisons.",
                ]
            )

        self._update_contamination_summary("\n".join(lines))

    def _build_tab_data(self):
        """Build the Data tab with CTk controls and ttk/tk fallbacks.

        Purpose:
            Assemble file, sheet, and multi-sheet loading controls for the Data tab.
        Why:
            Stage-two migration introduces CTk interactive widgets here while
            retaining existing callback wiring and listbox-based sheet selection.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Creates Data-tab widgets, stores widget references used by load/apply
            flows, and refreshes initial mode/list state.
        Exceptions:
            Widget construction uses fallback paths when CTk is unavailable.
        """
        ctk_module = ctk
        f = self.tab_data

        def _make_button(parent, text: str, command):
            """Create one button using CTk when available, else ttk."""
            if ctk_module is not None:
                return ctk_module.CTkButton(parent, text=text, command=command)
            return ttk.Button(parent, text=text, command=command)

        def _make_entry(parent, *, textvariable=None):
            """Create one text entry using CTk when available, else ttk."""
            if ctk_module is not None:
                return ctk_module.CTkEntry(parent, textvariable=textvariable)
            return ttk.Entry(parent, textvariable=textvariable)

        def _make_radio(parent, *, text: str, value: str, variable, command):
            """Create one radio button using CTk when available, else ttk."""
            if ctk_module is not None:
                return ctk_module.CTkRadioButton(
                    parent, text=text, value=value, variable=variable, command=command
                )
            return ttk.Radiobutton(
                parent,
                text=text,
                value=value,
                variable=variable,
                command=command,
            )

        def _make_combo(
            parent, *, variable, values: List[str], state: str = "readonly"
        ):
            """Create one combobox using CTk when available, else ttk."""
            if ctk_module is not None:
                return ctk_module.CTkComboBox(
                    parent, variable=variable, values=list(values), state=state
                )
            return ttk.Combobox(
                parent, textvariable=variable, state=state, values=list(values)
            )

        def _make_scrollbar(parent, *, orient: str, command):
            """Create one scrollbar using CTk when compatible, else ttk."""
            if ctk_module is not None:
                return ctk_module.CTkScrollbar(
                    parent, orientation=orient, command=command
                )
            return ttk.Scrollbar(parent, orient=orient, command=command)

        f.grid_columnconfigure(1, weight=1)

        ttk.Label(f, text="Excel file").grid(
            row=0, column=0, sticky="w", padx=6, pady=6
        )

        self.e_file = _make_entry(f)
        self.e_file.grid(row=0, column=1, sticky="ew", padx=6, pady=6)

        _make_button(f, "Browse...", self._browse_file).grid(
            row=0, column=2, padx=6, pady=6
        )
        _make_button(f, "Rescan File", self._load_sheets_from_current_path).grid(
            row=0, column=3, padx=6, pady=6
        )

        mode_frame = ttk.Frame(f)
        mode_frame.grid(row=1, column=0, columnspan=4, sticky="w", padx=6, pady=(0, 6))
        ttk.Label(mode_frame, text="Mode").pack(side="left", padx=(0, 8))
        _make_radio(
            mode_frame,
            text="Single Sheet",
            value="single",
            variable=self._multi_sheet_mode_var,
            command=self._on_multi_sheet_mode_change,
        ).pack(side="left", padx=(0, 8))
        _make_radio(
            mode_frame,
            text="Multiple Sheets",
            value="multiple",
            variable=self._multi_sheet_mode_var,
            command=self._on_multi_sheet_mode_change,
        ).pack(side="left")

        self._data_single_frame = ttk.Frame(f)
        self._data_single_frame.grid(row=2, column=0, columnspan=4, sticky="ew")
        self._data_single_frame.grid_columnconfigure(1, weight=1)

        ttk.Label(self._data_single_frame, text="Sheet").grid(
            row=0, column=0, sticky="w", padx=6, pady=6
        )
        self.om_sheet = _make_combo(
            self._data_single_frame,
            variable=self.selected_sheet,
            values=list(self.sheet_names),
            state="readonly",
        )
        self.om_sheet.grid(row=0, column=1, sticky="ew", padx=6, pady=6)

        _make_button(
            self._data_single_frame, "Load Sheet Data", self._load_dataframe
        ).grid(row=0, column=2, padx=6, pady=6)
        _make_button(
            self._data_single_frame,
            "Import GL-260 CSV...",
            self._open_csv_import_dialog,
        ).grid(row=0, column=3, padx=6, pady=6)
        _make_button(
            self._data_single_frame,
            "Open Profiles",
            self._open_profile_manager,
        ).grid(row=0, column=4, padx=6, pady=6)

        self._data_multi_frame = ttk.Frame(f)
        self._data_multi_frame.grid(row=3, column=0, columnspan=4, sticky="nsew")
        self._data_multi_frame.grid_columnconfigure(0, weight=1)

        list_frame = ttk.Frame(self._data_multi_frame)
        list_frame.grid(row=0, column=0, sticky="ew", padx=6, pady=6)
        list_frame.grid_columnconfigure(0, weight=1)
        list_frame.grid_columnconfigure(2, weight=1)

        available_frame = ttk.Frame(list_frame)
        available_frame.grid(row=0, column=0, sticky="nsew")
        available_frame.grid_columnconfigure(0, weight=1)
        available_frame.grid_rowconfigure(1, weight=1)
        ttk.Label(available_frame, text="Available Sheets").grid(
            row=0, column=0, sticky="w", padx=(0, 4)
        )
        self._available_sheets_listbox = tk.Listbox(
            available_frame,
            selectmode="extended",
            exportselection=False,
            height=8,
        )
        self._available_sheets_listbox.grid(row=1, column=0, sticky="nsew", padx=(0, 4))
        available_scroll = _make_scrollbar(
            available_frame,
            orient="vertical",
            command=self._available_sheets_listbox.yview,
        )
        available_scroll.grid(row=1, column=1, sticky="ns")
        self._available_sheets_listbox.configure(yscrollcommand=available_scroll.set)

        add_remove_frame = ttk.Frame(list_frame)
        add_remove_frame.grid(row=0, column=1, sticky="n", padx=6, pady=(18, 0))
        _make_button(add_remove_frame, "Add >>", self._add_selected_sheets).pack(
            fill="x", pady=2
        )
        _make_button(add_remove_frame, "<< Remove", self._remove_selected_sheets).pack(
            fill="x", pady=2
        )
        _make_button(
            add_remove_frame, "Remove All Sheets", self._remove_all_sheets
        ).pack(fill="x", pady=2)

        included_frame = ttk.Frame(list_frame)
        included_frame.grid(row=0, column=2, sticky="nsew")
        included_frame.grid_columnconfigure(0, weight=1)
        included_frame.grid_rowconfigure(1, weight=1)
        ttk.Label(included_frame, text="Included Sheets (ordered)").grid(
            row=0, column=0, sticky="w", padx=(4, 0)
        )
        self._included_sheets_listbox = tk.Listbox(
            included_frame,
            selectmode="extended",
            exportselection=False,
            height=8,
        )
        self._included_sheets_listbox.grid(row=1, column=0, sticky="nsew", padx=(4, 0))
        included_scroll = _make_scrollbar(
            included_frame,
            orient="vertical",
            command=self._included_sheets_listbox.yview,
        )
        included_scroll.grid(row=1, column=1, sticky="ns")
        self._included_sheets_listbox.configure(yscrollcommand=included_scroll.set)

        move_frame = ttk.Frame(list_frame)
        move_frame.grid(row=0, column=3, sticky="n", padx=(6, 0), pady=(18, 0))
        _make_button(move_frame, "Move Up", lambda: self._move_selected_sheet(-1)).pack(
            fill="x", pady=2
        )
        _make_button(
            move_frame, "Move Down", lambda: self._move_selected_sheet(1)
        ).pack(fill="x", pady=2)

        multi_actions = ttk.Frame(self._data_multi_frame)
        multi_actions.grid(row=1, column=0, sticky="w", padx=6, pady=(0, 6))
        _make_button(multi_actions, "Load Selected Sheets", self._load_dataframe).pack(
            side="left"
        )
        _make_button(
            multi_actions, "Import GL-260 CSV...", self._open_csv_import_dialog
        ).pack(side="left", padx=(6, 0))
        _make_button(multi_actions, "Open Profiles", self._open_profile_manager).pack(
            side="left", padx=(6, 0)
        )

        self.lbl_status = ttk.Label(f, text="No file loaded.")
        self.lbl_status.grid(row=4, column=0, columnspan=4, sticky="w", padx=6, pady=6)

        self._update_data_tab_mode()
        self._refresh_multi_sheet_lists()

    def _on_multi_sheet_mode_change(self):
        """Handle multi sheet mode change.
        Used as an event callback for multi sheet mode change."""
        mode = self._multi_sheet_mode_var.get()
        self._set_multi_sheet_enabled(mode == "multiple")

    def _set_multi_sheet_enabled(self, enabled: bool, *, persist: bool = True):
        """Set multi sheet enabled.
        Used to persist multi sheet enabled into the current state."""
        self.multi_sheet_enabled = bool(enabled)
        settings["multi_sheet_enabled"] = self.multi_sheet_enabled
        settings["selected_sheets"] = list(self.selected_sheets)
        if persist:
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._update_data_tab_mode()
        self._refresh_multi_sheet_lists()
        if self.df is not None:
            self._mark_columns_dirty(
                reason="multi-sheet mode changed", allow_during_apply=True
            )

    def _update_data_tab_mode(self):
        """Update data tab mode.
        Used to keep data tab mode in sync with current state."""
        single_frame = getattr(self, "_data_single_frame", None)
        multi_frame = getattr(self, "_data_multi_frame", None)
        if self.multi_sheet_enabled:
            if single_frame is not None and single_frame.winfo_exists():
                single_frame.grid_remove()
            if multi_frame is not None and multi_frame.winfo_exists():
                multi_frame.grid()
        else:
            if multi_frame is not None and multi_frame.winfo_exists():
                multi_frame.grid_remove()
            if single_frame is not None and single_frame.winfo_exists():
                single_frame.grid()

    def _set_selected_sheets(self, sheets, *, persist: bool = True):
        """Set selected sheets.
        Used to persist selected sheets into the current state."""
        self.selected_sheets = list(sheets)
        settings["selected_sheets"] = list(self.selected_sheets)
        if persist:
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._columns_schema_preview = []
        self._columns_schema_preview_sheet = None
        self._columns_schema_preview_path = None
        if getattr(self, "columns_frame", None) is not None:
            try:
                self._refresh_columns_ui()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _sync_selected_sheets(self, *, persist: bool = True):
        """Perform sync selected sheets.
        Used to keep the workflow logic localized and testable."""
        if not getattr(self, "_sheet_names_loaded", False):
            if persist:
                settings["selected_sheets"] = list(self.selected_sheets)
                try:
                    _save_settings_to_disk()
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            return
        if not self.sheet_names:
            normalized = []
        else:
            available = set(self.sheet_names)
            normalized = []
            seen = set()
            # Iterate over self.selected_sheets to apply the per-item logic.
            for name in self.selected_sheets:
                if name in available and name not in seen:
                    normalized.append(name)
                    seen.add(name)
        self.selected_sheets = normalized
        settings["selected_sheets"] = list(self.selected_sheets)
        if persist:
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _refresh_multi_sheet_lists(self):
        """Refresh multi sheet lists.
        Used to sync multi sheet lists with current settings."""
        available_listbox = getattr(self, "_available_sheets_listbox", None)
        included_listbox = getattr(self, "_included_sheets_listbox", None)
        if available_listbox is None or included_listbox is None:
            return
        self._sync_selected_sheets(persist=False)
        available_listbox.delete(0, tk.END)
        included_listbox.delete(0, tk.END)
        # Iterate over self.sheet_names to apply the per-item logic.
        for name in self.sheet_names:
            if name not in self.selected_sheets:
                available_listbox.insert(tk.END, name)
        # Iterate over self.selected_sheets to apply the per-item logic.
        for name in self.selected_sheets:
            included_listbox.insert(tk.END, name)

    def _add_selected_sheets(self):
        """Perform add selected sheets.
        Used to keep the workflow logic localized and testable."""
        available_listbox = getattr(self, "_available_sheets_listbox", None)
        if available_listbox is None:
            return
        selections = list(available_listbox.curselection())
        if not selections:
            return
        updated = list(self.selected_sheets)
        # Iterate over selections to apply the per-item logic.
        for idx in selections:
            name = available_listbox.get(idx)
            if name not in updated:
                updated.append(name)
        self._set_selected_sheets(updated)
        self._refresh_multi_sheet_lists()

    def _remove_selected_sheets(self):
        """Perform remove selected sheets.
        Used to keep the workflow logic localized and testable."""
        included_listbox = getattr(self, "_included_sheets_listbox", None)
        if included_listbox is None:
            return
        selections = list(included_listbox.curselection())
        if not selections:
            return
        remove_names = {included_listbox.get(idx) for idx in selections}
        updated = [name for name in self.selected_sheets if name not in remove_names]
        self._set_selected_sheets(updated)
        self._refresh_multi_sheet_lists()

    def _remove_all_sheets(self) -> None:
        """Remove every included sheet and return it to the available list.

        Purpose:
            Provide a one-click reset for multi-sheet inclusion selections.
        Why:
            Users often need to clear all included sheets before rebuilding a new
            stitched ordering, and repeated per-row removal is inefficient.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Clears `self.selected_sheets`, persists that state through
            `_set_selected_sheets`, and refreshes both multi-sheet listboxes.
        Exceptions:
            None. Empty included-state is treated as a no-op.
        """
        if not self.selected_sheets:
            return
        self._set_selected_sheets([])
        self._refresh_multi_sheet_lists()

    def _move_selected_sheet(self, direction: int):
        """Move selected included sheets up or down as one contiguous action.

        Purpose:
            Reorder selected entries in the Included Sheets list.
        Why:
            Multi-select workflows need deterministic group moves while preserving
            relative ordering between selected rows.
        Args:
            direction: Negative values move up; positive values move down.
        Returns:
            None.
        Side Effects:
            Mutates `self.selected_sheets`, persists order via
            `_set_selected_sheets`, refreshes listboxes, and restores row
            selection after re-render.
        Exceptions:
            None. Invalid or empty selection requests are ignored.
        """
        included_listbox = getattr(self, "_included_sheets_listbox", None)
        if included_listbox is None:
            return
        indices = sorted(list(included_listbox.curselection()))
        if not indices:
            return
        updated = list(self.selected_sheets)
        count = len(updated)
        # Keep group semantics strict: if any selected row is at a boundary,
        # block the full move so the selected group stays coherent.
        if direction < 0 and indices[0] <= 0:
            return
        if direction > 0 and indices[-1] >= (count - 1):
            return
        if direction < 0:
            # Iterate over sorted(indices) to apply the per-item logic.
            for idx in indices:
                updated[idx - 1], updated[idx] = updated[idx], updated[idx - 1]
            new_indices = [max(0, idx - 1) for idx in indices]
        else:
            # Iterate over sorted(indices, reverse=True) to apply the per-item logic.
            for idx in sorted(indices, reverse=True):
                updated[idx + 1], updated[idx] = updated[idx], updated[idx + 1]
            new_indices = [min(count - 1, idx + 1) for idx in indices]
        self._set_selected_sheets(updated)
        self._refresh_multi_sheet_lists()
        # Iterate over new_indices to apply the per-item logic.
        for idx in new_indices:
            included_listbox.selection_set(idx)

    def _build_tab_columns(self):
        """Build tab columns.
        Used to assemble tab columns during UI or plot setup."""

        self.columns_vars = {}

        self.columns_frame = self.tab_columns

        self._refresh_columns_ui()

    def _get_schema_preview_columns(self) -> List[str]:
        """Return schema preview columns.
        Used to retrieve schema preview columns for downstream logic."""
        if (
            not self.multi_sheet_enabled
            or not self.file_path
            or not self.selected_sheets
        ):
            self._columns_schema_preview = []
            self._columns_schema_preview_sheet = None
            self._columns_schema_preview_path = None
            return []
        first_sheet = self.selected_sheets[0]
        if (
            self._columns_schema_preview
            and self._columns_schema_preview_sheet == first_sheet
            and self._columns_schema_preview_path == self.file_path
        ):
            return list(self._columns_schema_preview)
        try:
            preview_df = pd.read_excel(self.file_path, sheet_name=first_sheet, nrows=0)
            cols = [str(col) for col in preview_df.columns]
        except Exception:
            cols = []
        self._columns_schema_preview = cols
        self._columns_schema_preview_sheet = first_sheet
        self._columns_schema_preview_path = self.file_path
        return list(cols)

    def _refresh_columns_ui(self):
        """Refresh the Columns tab controls using CTk widgets when available.

        Purpose:
            Rebuild the main Columns-tab selector grid and action controls.
        Why:
            Stage-two migration moves the tab's interactive controls to CTk while
            preserving existing variable bindings, callbacks, and business logic.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Destroys and recreates child widgets in `self.columns_frame`, updates
            `self.columns_vars` / `self.scatter_series_vars`, and re-registers the
            Apply button and indicator canvas.
        Exceptions:
            Uses ttk fallbacks when CTk is unavailable; no exceptions are raised for
            fallback selection wiring.
        """
        ctk_module = ctk
        f = self.columns_frame

        def _make_combo(
            parent,
            *,
            variable: tk.StringVar,
            values: Sequence[str],
            ctk_width: Optional[int] = None,
            ttk_width: Optional[int] = None,
            on_select: Optional[Callable[[], None]] = None,
        ):
            """Create one readonly combo widget with CTk/ttk selection wiring."""
            resolved_values = [str(v) for v in values]
            if ctk_module is not None:
                kwargs: Dict[str, Any] = {
                    "variable": variable,
                    "values": resolved_values,
                    "state": "readonly",
                }
                if ctk_width is not None:
                    kwargs["width"] = ctk_width
                if callable(on_select):
                    kwargs["command"] = lambda _value: on_select()
                return ctk_module.CTkComboBox(parent, **kwargs)
            kwargs = {
                "textvariable": variable,
                "values": resolved_values,
                "state": "readonly",
            }
            if ttk_width is not None:
                kwargs["width"] = ttk_width
            combo = ttk.Combobox(parent, **kwargs)
            if callable(on_select):
                combo.bind("<<ComboboxSelected>>", lambda _e: on_select(), add="+")
            return combo

        def _make_entry(
            parent,
            *,
            textvariable: tk.StringVar,
            ctk_width: Optional[int] = None,
            ttk_width: Optional[int] = None,
        ):
            """Create one text entry with CTk/ttk compatibility options."""
            if ctk_module is not None:
                kwargs: Dict[str, Any] = {"textvariable": textvariable}
                if ctk_width is not None:
                    kwargs["width"] = ctk_width
                return ctk_module.CTkEntry(parent, **kwargs)
            kwargs = {"textvariable": textvariable}
            if ttk_width is not None:
                kwargs["width"] = ttk_width
            return ttk.Entry(parent, **kwargs)

        def _make_button(
            parent,
            *,
            text: str,
            command: Callable[[], Any],
            ctk_width: Optional[int] = None,
        ):
            """Create one push button with CTk/ttk fallback behavior."""
            if ctk_module is not None:
                kwargs: Dict[str, Any] = {"text": text, "command": command}
                if ctk_width is not None:
                    kwargs["width"] = ctk_width
                return ctk_module.CTkButton(parent, **kwargs)
            return ttk.Button(parent, text=text, command=command)

        # Iterate over f.winfo_children() to apply the per-item logic.
        for w in f.winfo_children():
            w.destroy()

        self.scatter_series_vars = {}
        self._series_label_map = {}

        preview_only = False
        preview_cols: List[str] = []

        if self.df is None:
            if self.multi_sheet_enabled and self.file_path and self.selected_sheets:
                preview_cols = self._get_schema_preview_columns()
                if preview_cols:
                    preview_only = True
            if not preview_only:
                ttk.Label(f, text="Load a sheet on the Data tab first.").pack(
                    anchor="w", padx=8, pady=8
                )
                self._refresh_cycle_temp_choices()
                self._update_scatter_globals()
                return

        cols = list(preview_cols if preview_only else self.df.columns)
        cols_with_none = ["None"] + cols
        labels = self._column_variable_label_map()

        if preview_only:
            ttk.Label(
                f,
                text=(
                    "Multi-sheet preview loaded. Select columns and apply to stitch data."
                ),
            ).pack(anchor="w", padx=8, pady=(8, 0))

        grid = ttk.Frame(f)
        grid.pack(fill="x", padx=8, pady=(8, 0))
        grid.grid_columnconfigure(0, weight=0)
        grid.grid_columnconfigure(1, weight=1)
        grid.grid_columnconfigure(2, weight=1)

        row = 0

        # Iterate over items from labels to apply the per-item logic.
        for key, label in labels.items():
            self._series_label_map[key] = label
            current_row = row

            ttk.Label(grid, text=label).grid(
                row=current_row, column=0, sticky="w", padx=6, pady=6
            )

            optional_keys = {"y2", "y3", "z", "z2", "dt"}
            choices = cols_with_none if key in optional_keys else cols
            default_val = self.columns.get(
                key,
                ("None" if key in optional_keys else (cols[0] if cols else "")),
            )
            var = tk.StringVar(value=default_val)
            self.columns_vars[key] = var

            def _on_combo(k=key) -> None:
                """Mirror one selector value and mark the column state as dirty."""
                self.columns[k] = self.columns_vars[k].get()
                self._mark_columns_dirty(
                    reason="user selection changed", allow_during_apply=True
                )

            cb = _make_combo(
                grid,
                variable=var,
                values=choices,
                on_select=_on_combo,
            )
            cb.grid(row=current_row, column=1, sticky="ew", padx=6, pady=6)

            if key in SCATTER_SERIES_KEYS:
                series_settings = self._stored_scatter_series.get(key, {})
                size_val = series_settings.get("size")
                if isinstance(size_val, (int, float)) and math.isfinite(size_val):
                    size_str = f"{float(size_val):g}"
                else:
                    size_str = ""
                linewidth_val = series_settings.get("linewidth")
                if (
                    isinstance(linewidth_val, (int, float))
                    and math.isfinite(linewidth_val)
                    and linewidth_val > 0.0
                ):
                    linewidth_str = f"{float(linewidth_val):g}"
                else:
                    linewidth_str = ""
                color_val = series_settings.get("color", "")
                color_str = color_val if isinstance(color_val, str) else ""
                linestyle_val = _canonicalize_linestyle_name(
                    series_settings.get("linestyle")
                )
                if linestyle_val:
                    linestyle_display = (
                        linestyle_val
                        if linestyle_val in LINE_STYLE_CHOICES
                        else "Default"
                    )
                else:
                    linestyle_display = "Default"

                size_var = tk.StringVar(value=size_str)
                linewidth_var = tk.StringVar(value=linewidth_str)
                color_var = tk.StringVar(value=color_str)
                linestyle_var = tk.StringVar(value=linestyle_display)
                self.scatter_series_vars[key] = {
                    "size": size_var,
                    "linewidth": linewidth_var,
                    "color": color_var,
                    "linestyle": linestyle_var,
                }

                scatter_frame = ttk.Frame(grid)
                scatter_frame.grid(
                    row=current_row, column=2, sticky="ew", padx=6, pady=6
                )
                scatter_frame.grid_columnconfigure(9, weight=1)

                ttk.Label(scatter_frame, text="Size").grid(row=0, column=0, sticky="w")
                size_entry = _make_entry(
                    scatter_frame,
                    textvariable=size_var,
                    ctk_width=72,
                    ttk_width=6,
                )
                size_entry.grid(row=0, column=1, sticky="w", padx=(2, 6))
                size_entry.bind(
                    "<FocusOut>", lambda _e, k=key: self._on_series_size_change(k)
                )
                size_entry.bind(
                    "<Return>",
                    lambda _e, k=key: (self._on_series_size_change(k), "break")[1],
                )
                self._attach_tooltip(
                    size_entry,
                    (
                        "Adjusts marker size for both scatter points (in pt^2) and the "
                        "corresponding markers on line plots. Leave blank to inherit the global setting."
                    ),
                )

                ttk.Label(scatter_frame, text="Line Width (pt)").grid(
                    row=0, column=2, sticky="w"
                )
                linewidth_entry = _make_entry(
                    scatter_frame,
                    textvariable=linewidth_var,
                    ctk_width=80,
                    ttk_width=7,
                )
                linewidth_entry.grid(row=0, column=3, sticky="w", padx=(2, 6))
                linewidth_entry.bind(
                    "<FocusOut>",
                    lambda _e, k=key: self._on_series_linewidth_change(k),
                )
                linewidth_entry.bind(
                    "<Return>",
                    lambda _e, k=key: (
                        self._on_series_linewidth_change(k),
                        "break",
                    )[1],
                )

                # Use a trace wrapper to avoid clearing partial input while typing.
                def _on_linewidth_trace(*_args, k=key):
                    """Run linewidth validation safely during active user typing."""
                    self._series_linewidth_trace_active = True
                    try:
                        self._on_series_linewidth_change(k)
                    finally:
                        self._series_linewidth_trace_active = False

                linewidth_var.trace_add("write", _on_linewidth_trace)
                self._attach_tooltip(
                    linewidth_entry,
                    (
                        "Controls the thickness of the line connecting data points (in points). "
                        "Leave blank to use the default linewidth."
                    ),
                )

                ttk.Label(scatter_frame, text="Color").grid(row=0, column=4, sticky="w")
                color_preview = tk.Label(
                    scatter_frame,
                    width=4,
                    relief="groove",
                    borderwidth=1,
                    text="Auto",
                )
                color_preview.grid(row=0, column=5, sticky="w", padx=(2, 2))
                self._bind_color_preview(color_var, color_preview)
                self._attach_tooltip(
                    color_preview,
                    "Preview of the color applied to this series for both scatter points and line plots (blank uses the default line color).",
                )

                color_button = _make_button(
                    scatter_frame,
                    text="Pick",
                    command=lambda k=key: self._choose_series_color(k),
                    ctk_width=58,
                )
                color_button.grid(row=0, column=6, padx=(2, 2))
                self._attach_tooltip(
                    color_button,
                    "Choose a custom color for this series that will be used on both scatter and line plots.",
                )

                color_clear_btn = _make_button(
                    scatter_frame,
                    text="Clear",
                    command=lambda k=key: self._clear_series_color(k),
                    ctk_width=62,
                )
                color_clear_btn.grid(row=0, column=7)
                self._attach_tooltip(
                    color_clear_btn,
                    "Clear any custom color so the series reverts to the default line color.",
                )

                ttk.Label(scatter_frame, text="Line Style").grid(
                    row=0, column=8, sticky="w", padx=(8, 2)
                )
                linestyle_combo = _make_combo(
                    scatter_frame,
                    variable=linestyle_var,
                    values=LINE_STYLE_CHOICES,
                    ctk_width=220,
                    ttk_width=24,
                    on_select=lambda k=key: self._on_series_linestyle_change(k),
                )
                linestyle_combo.grid(row=0, column=9, sticky="ew")
                self._attach_tooltip(
                    linestyle_combo,
                    "Select the line style used when this series is drawn as a line (choose Default to inherit settings).",
                )

            row += 1

        self._update_scatter_globals()

        button_frame = ttk.Frame(f)
        button_frame.pack(fill="x", padx=8, pady=8)
        mapping_button = _make_button(
            button_frame,
            text="Per-Sheet Column Mapping...",
            command=self._open_per_sheet_column_mapping_window,
        )
        mapping_button.pack(side="left")
        if (
            (not self.multi_sheet_enabled)
            or (not self.selected_sheets)
            or (not self.file_path)
        ):
            self._set_widget_enabled(mapping_button, False)

        apply_frame = ttk.Frame(button_frame)
        apply_frame.pack(side="left", padx=(8, 0))
        apply_button = _make_button(
            apply_frame,
            text="Apply Column Selection",
            command=lambda: self._apply_columns(auto_refresh_axes=True),
        )
        apply_button.pack(side="left")
        self._register_apply_button(apply_button)
        self._create_apply_indicator(
            apply_frame, layout="pack", side="left", padx=(6, 0)
        )

        self._refresh_cycle_temp_choices()

    def _column_variable_label_map(self) -> Dict[str, str]:
        """Map value.
        Used by column variable label workflows to map value."""
        return {
            "x": f"X-Axis (Elapsed Time, {self._elapsed_unit_label()}) [Required]",
            "dt": "Date & Time (for multi-sheet stitching)",
            "y1": "Primary Y (Reactor, PSI) [Required]",
            "y3": "Primary Y (Manifold, PSI) [Optional]",
            "y2": "Secondary Y (Derivative) [Optional]",
            "z": "Temperature Trace (Internal) [Optional]",
            "z2": "Temperature Trace 2 (External) [Optional]",
        }

    def _column_variable_keys(self) -> List[str]:
        """Perform column variable keys.
        Used to keep the workflow logic localized and testable."""
        return list(self._column_variable_label_map().keys())

    def _column_variable_label(self, var_key: str) -> str:
        """Perform column variable label.
        Used to keep the workflow logic localized and testable."""
        return self._column_variable_label_map().get(var_key, var_key)

    def _normalize_column_choice(self, value: Any) -> str:
        """Normalize column choice.
        Used to keep column choice consistent across workflows and persistence."""
        if value is None:
            return ""
        if not isinstance(value, str):
            value = str(value)
        value = value.strip()
        if value in ("None", "(None)", "(Global)"):
            return ""
        return value

    def _get_global_column_map(self) -> Dict[str, str]:
        """Return global column map.
        Used to retrieve global column map for downstream logic."""
        columns = self.columns if isinstance(self.columns, dict) else {}
        mapping = {}
        # Iterate over self._column_variable_keys() to apply the per-item logic.
        for key in self._column_variable_keys():
            value = columns.get(key, "")
            if value is None:
                value = ""
            if not isinstance(value, str):
                value = str(value)
            mapping[key] = value
        return mapping

    def _set_global_column_map(self, mapping: Dict[str, str]) -> None:
        """Set global column map.
        Used to persist global column map into the current state."""
        if not isinstance(mapping, dict):
            return
        if not isinstance(self.columns, dict):
            self.columns = {}
        # Iterate over self._column_variable_keys() to apply the per-item logic.
        for key in self._column_variable_keys():
            if key not in mapping:
                continue
            value = mapping.get(key)
            if value is None:
                value = ""
            if not isinstance(value, str):
                value = str(value)
            self.columns[key] = value
            var = self.columns_vars.get(key) if hasattr(self, "columns_vars") else None
            if isinstance(var, tk.StringVar):
                var.set(value)
        settings["columns"] = dict(self.columns)

    def _get_per_sheet_column_map(self) -> Dict[str, Dict[str, str]]:
        """Return per sheet column map.
        Used to retrieve per sheet column map for downstream logic."""
        cached = getattr(self, "_per_sheet_column_map_cache", None)
        if isinstance(cached, dict):
            return cached
        raw = settings.get("per_sheet_column_map", {})
        normalized = {}
        if isinstance(raw, dict):
            valid_keys = set(self._column_variable_keys())
            # Iterate over items from raw to apply the per-item logic.
            for sheet_name, mapping in raw.items():
                if not isinstance(mapping, dict):
                    continue
                sheet_key = str(sheet_name)
                sheet_map = {}
                # Iterate over items from mapping to apply the per-item logic.
                for key, value in mapping.items():
                    key_str = str(key)
                    if key_str not in valid_keys:
                        continue
                    sheet_map[key_str] = self._normalize_column_choice(value)
                normalized[sheet_key] = sheet_map
        self._per_sheet_column_map_cache = normalized
        return normalized

    def _set_per_sheet_column_map(
        self, sheet_name: str, mapping: Dict[str, str]
    ) -> None:
        """Set per sheet column map.
        Used to persist per sheet column map into the current state."""
        if not sheet_name:
            return
        if not isinstance(settings.get("per_sheet_column_map"), dict):
            settings["per_sheet_column_map"] = {}
        normalized = {}
        # Iterate over self._column_variable_keys() to apply the per-item logic.
        for key in self._column_variable_keys():
            normalized[key] = self._normalize_column_choice(mapping.get(key, ""))
        settings["per_sheet_column_map"][sheet_name] = normalized
        self._per_sheet_column_map_cache = None

    def _get_effective_sheet_column_map(self, sheet_name: str) -> Dict[str, str]:
        """Return effective sheet column map.
        Used to retrieve effective sheet column map for downstream logic."""
        effective = self._get_global_column_map()
        overrides = self._get_per_sheet_column_map().get(sheet_name, {})
        # Iterate over items from overrides to apply the per-item logic.
        for key, value in overrides.items():
            if value:
                effective[key] = value
        return effective

    def _build_stitched_series_for_var(
        self, var_key: str, selected_sheets: List[str]
    ) -> Optional[pd.Series]:
        """Build stitched series for var.
        Used to assemble stitched series for var during UI or plot setup."""
        if not selected_sheets:
            return None
        if not isinstance(self.sheet_dfs, dict):
            return None
        parts: List[pd.Series] = []
        # Iterate over indexed elements from selected_sheets to apply the per-item logic.
        for idx, sheet_name in enumerate(selected_sheets):
            df = self.sheet_dfs.get(sheet_name)
            if df is None and self.file_path:
                try:
                    df = _read_excel_dataframe(self.file_path, sheet_name)
                except Exception:
                    df = None
            if df is None:
                continue
            mapping = self._get_effective_sheet_column_map(sheet_name)
            colname = mapping.get(var_key)
            if not colname or colname == "None" or colname not in df.columns:
                part = pd.Series([np.nan] * len(df), dtype=float)
            else:
                try:
                    part = pd.to_numeric(df[colname], errors="coerce")
                except Exception:
                    part = pd.Series([np.nan] * len(df), dtype=float)
            parts.append(part)
            if idx < len(selected_sheets) - 1:
                parts.append(pd.Series([np.nan], dtype=float))
        if not parts:
            return None
        return pd.concat(parts, ignore_index=True)

    def _open_per_sheet_column_mapping_window(self) -> None:
        """Open per sheet column mapping window.
        Used by UI actions to open per sheet column mapping window."""
        existing = getattr(self, "_per_sheet_mapping_window", None)
        if existing is not None and existing.winfo_exists():
            existing.deiconify()
            existing.lift()
            existing.focus_force()
            return

        if not self.file_path:
            messagebox.showerror("Missing Data", "Load a file first.")
            return

        selected_sheets = (
            list(self.selected_sheets)
            if self.multi_sheet_enabled
            else [self.selected_sheet.get()]
        )
        selected_sheets = [name for name in selected_sheets if name]
        if not selected_sheets:
            messagebox.showerror(
                "Missing Data", "Select at least one sheet to include."
            )
            return

        sheet_columns: Dict[str, List[str]] = {}
        # Iterate over selected_sheets to apply the per-item logic.
        for sheet_name in selected_sheets:
            df = self.sheet_dfs.get(sheet_name)
            if df is None:
                try:
                    df = _read_excel_dataframe(self.file_path, sheet_name)
                except Exception:
                    df = None
            sheet_columns[sheet_name] = list(df.columns) if df is not None else []

        global_map = self._get_global_column_map()
        per_sheet_map = self._get_per_sheet_column_map()
        working_map = {
            sheet_name: dict(per_sheet_map.get(sheet_name, {}))
            # Iterate to apply the per-item logic.
            for sheet_name in selected_sheets
        }
        var_keys = self._column_variable_keys()
        sentinel = "(Global)"

        win = tk.Toplevel(self)
        win.title("Per-Sheet Column Mapping")
        win.transient(self)
        win.resizable(True, True)
        self._per_sheet_mapping_window = win

        # Closure captures _open_per_sheet_column_mapping_window state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_per_sheet_column_mapping_window.
        def _close_window():
            """Close window.
            Used by UI actions to close window safely."""
            self._per_sheet_mapping_window = None
            try:
                win.destroy()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        win.protocol("WM_DELETE_WINDOW", _close_window)

        container = ttk.Frame(win)
        container.grid(row=0, column=0, sticky="nsew")
        win.grid_rowconfigure(0, weight=1)
        win.grid_columnconfigure(0, weight=1)
        container.grid_columnconfigure(1, weight=1)
        container.grid_rowconfigure(1, weight=1)

        ttk.Label(
            container,
            text=(
                "These mappings override the global Columns selection for each sheet. "
                "Choose '(Global)' to use the global mapping."
            ),
            wraplength=self._scale_length(640),
        ).grid(row=0, column=0, columnspan=2, sticky="w", padx=10, pady=(10, 6))

        list_frame = ttk.Frame(container)
        list_frame.grid(row=1, column=0, sticky="nsw", padx=(10, 6), pady=(0, 10))
        list_frame.grid_rowconfigure(0, weight=1)

        listbox = tk.Listbox(
            list_frame,
            height=min(10, max(3, len(selected_sheets))),
            exportselection=False,
        )
        listbox.grid(row=0, column=0, sticky="nsew")
        list_scroll = ttk.Scrollbar(
            list_frame, orient="vertical", command=listbox.yview
        )
        list_scroll.grid(row=0, column=1, sticky="ns")
        listbox.configure(yscrollcommand=list_scroll.set)

        detail_frame = ttk.Frame(container)
        detail_frame.grid(row=1, column=1, sticky="nsew", padx=(6, 10), pady=(0, 10))
        detail_frame.grid_columnconfigure(1, weight=1)

        combo_vars: Dict[str, tk.StringVar] = {}
        combo_widgets: Dict[str, ttk.Combobox] = {}
        status_labels: Dict[str, ttk.Label] = {}

        # Iterate over indexed elements from var_keys to apply the per-item logic.
        for idx, key in enumerate(var_keys):
            label_text = self._column_variable_label(key)
            ttk.Label(detail_frame, text=label_text).grid(
                row=idx, column=0, sticky="w", padx=6, pady=3
            )
            var = tk.StringVar()
            combo = ttk.Combobox(detail_frame, textvariable=var, state="readonly")
            combo.grid(row=idx, column=1, sticky="ew", padx=6, pady=3)
            status = ttk.Label(detail_frame, text="")
            status.grid(row=idx, column=2, sticky="w", padx=6, pady=3)
            combo_vars[key] = var
            combo_widgets[key] = combo
            status_labels[key] = status

        current_sheet = tk.StringVar(value=selected_sheets[0])

        # Closure captures _open_per_sheet_column_mapping_window state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_per_sheet_column_mapping_window.
        def _update_status(sheet_name: str) -> None:
            """Update status.
            Used to keep status in sync with current state."""
            columns = set(sheet_columns.get(sheet_name, []))
            # Iterate over var_keys to apply the per-item logic.
            for key in var_keys:
                override = working_map.get(sheet_name, {}).get(key, "")
                candidate = override if override else global_map.get(key, "")
                if candidate in ("", "None", None):
                    status = "Missing"
                elif candidate in columns:
                    status = "Mapped"
                else:
                    status = "Missing"
                label = status_labels[key]
                label.configure(text=status)
                label.configure(
                    foreground=("#2e7d32" if status == "Mapped" else "#b71c1c")
                )

        # Closure captures _open_per_sheet_column_mapping_window local context to keep helper logic scoped and invoked directly within _open_per_sheet_column_mapping_window.
        def _load_sheet(sheet_name: str) -> None:
            """Load sheet.
            Used when restoring sheet from storage."""
            choices = [sentinel] + list(sheet_columns.get(sheet_name, []))
            # Iterate over var_keys to apply the per-item logic.
            for key in var_keys:
                override = working_map.get(sheet_name, {}).get(key, "")
                values = (
                    choices + [override]
                    if override and override not in choices
                    else choices
                )
                combo_widgets[key].configure(values=values)
                combo_vars[key].set(override if override else sentinel)
            _update_status(sheet_name)

        # Closure captures _open_per_sheet_column_mapping_window state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_per_sheet_column_mapping_window.
        def _on_combo_change(key: str) -> None:
            """Handle combo change.
            Used as an event callback for combo change."""
            sheet_name = current_sheet.get()
            if not sheet_name:
                return
            value = combo_vars[key].get()
            working_map.setdefault(sheet_name, {})[key] = self._normalize_column_choice(
                value
            )
            _update_status(sheet_name)

        # Iterate over items from combo_widgets to apply the per-item logic.
        for key, combo in combo_widgets.items():
            combo.bind("<<ComboboxSelected>>", lambda _e, k=key: _on_combo_change(k))

        # Closure captures _open_per_sheet_column_mapping_window state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_per_sheet_column_mapping_window.
        def _on_sheet_select(_event=None) -> None:
            """Handle sheet select.
            Used as an event callback for sheet select."""
            selection = listbox.curselection()
            if not selection:
                return
            sheet_name = listbox.get(selection[0])
            current_sheet.set(sheet_name)
            _load_sheet(sheet_name)

        # Iterate over selected_sheets to apply the per-item logic.
        for sheet in selected_sheets:
            listbox.insert(tk.END, sheet)
        listbox.selection_set(0)
        listbox.bind("<<ListboxSelect>>", _on_sheet_select)
        _load_sheet(selected_sheets[0])

        # Closure captures _open_per_sheet_column_mapping_window local context to keep helper logic scoped and invoked directly within _open_per_sheet_column_mapping_window.
        def _copy_from_sheet() -> None:
            """Perform copy from sheet.
            Used to keep the workflow logic localized and testable."""
            sheet_name = current_sheet.get()
            options = [name for name in selected_sheets if name != sheet_name]
            if not options:
                messagebox.showinfo(
                    "Copy Mapping", "Add another sheet to copy mapping from."
                )
                return
            picker = tk.Toplevel(win)
            picker.title("Copy From...")
            picker.transient(win)
            picker.resizable(False, False)
            ttk.Label(picker, text="Copy mapping from:").grid(
                row=0, column=0, padx=10, pady=(10, 4), sticky="w"
            )
            pick_list = tk.Listbox(picker, height=min(8, len(options)))
            pick_list.grid(row=1, column=0, padx=10, pady=(0, 10), sticky="nsew")
            # Iterate over options to apply the per-item logic.
            for name in options:
                pick_list.insert(tk.END, name)
            pick_list.selection_set(0)

            # Closure captures _copy_from_sheet state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _copy_from_sheet.
            def _apply_copy() -> None:
                """Apply copy.
                Used to apply copy changes to live state."""
                sel = list(pick_list.curselection())
                if not sel:
                    return
                source = pick_list.get(sel[0])
                working_map[sheet_name] = dict(working_map.get(source, {}))
                _load_sheet(sheet_name)
                picker.destroy()

            button_frame = ttk.Frame(picker)
            button_frame.grid(row=2, column=0, padx=10, pady=(0, 10), sticky="e")
            ttk.Button(button_frame, text="Copy", command=_apply_copy).grid(
                row=0, column=0, padx=(0, 6)
            )
            ttk.Button(button_frame, text="Cancel", command=picker.destroy).grid(
                row=0, column=1
            )

        # Closure captures _open_per_sheet_column_mapping_window state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_per_sheet_column_mapping_window.
        def _apply_global_defaults() -> None:
            """Apply global defaults.
            Used to apply global defaults changes to live state."""
            sheet_name = current_sheet.get()
            if not sheet_name:
                return
            columns = set(sheet_columns.get(sheet_name, []))
            global_choices = self._get_global_column_map()
            updated = working_map.setdefault(sheet_name, {})
            # Iterate over var_keys to apply the per-item logic.
            for key in var_keys:
                candidate = global_choices.get(key, "")
                if candidate and candidate != "None" and candidate in columns:
                    updated[key] = candidate
                else:
                    updated[key] = ""
            _load_sheet(sheet_name)

        # Closure captures _open_per_sheet_column_mapping_window local context to keep helper logic scoped and invoked directly within _open_per_sheet_column_mapping_window.
        def _clear_sheet_overrides() -> None:
            """Clear sheet overrides.
            Used to reset sheet overrides state safely."""
            sheet_name = current_sheet.get()
            if not sheet_name:
                return
            working_map[sheet_name] = {}
            _load_sheet(sheet_name)

        # Closure captures _open_per_sheet_column_mapping_window state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _open_per_sheet_column_mapping_window.
        def _apply_changes() -> None:
            """Apply changes.
            Used to apply changes changes to live state."""
            updated_map = dict(self._get_per_sheet_column_map())
            # Iterate over selected_sheets to apply the per-item logic.
            for sheet_name in selected_sheets:
                overrides = working_map.get(sheet_name, {})
                normalized = {
                    key: self._normalize_column_choice(overrides.get(key, ""))
                    # Iterate to apply the per-item logic.
                    for key in var_keys
                }
                updated_map[sheet_name] = normalized
            settings["per_sheet_column_map"] = updated_map
            self._per_sheet_column_map_cache = None
            try:
                _save_settings_to_disk()
            except Exception as exc:
                messagebox.showwarning(
                    "Save Settings",
                    f"Settings updated for this session, but the settings file "
                    f"could not be written:\n{exc}",
                )
            self._mark_columns_dirty(
                reason="per-sheet mapping applied", allow_during_apply=True
            )
            if (not self._is_applying_columns) and self.df is not None and self.columns:
                self._apply_columns(auto_refresh_axes=True)
            _close_window()

        button_frame = ttk.Frame(container)
        button_frame.grid(row=2, column=0, columnspan=2, sticky="e", padx=10, pady=10)
        ttk.Button(button_frame, text="Copy From...", command=_copy_from_sheet).grid(
            row=0, column=0, padx=(0, 6)
        )
        ttk.Button(
            button_frame,
            text="Apply Global As Defaults",
            command=_apply_global_defaults,
        ).grid(row=0, column=1, padx=(0, 6))
        ttk.Button(
            button_frame,
            text="Clear Sheet Overrides",
            command=_clear_sheet_overrides,
        ).grid(row=0, column=2, padx=(0, 12))
        ttk.Button(button_frame, text="Apply", command=_apply_changes).grid(
            row=0, column=3, padx=(0, 6)
        )
        ttk.Button(button_frame, text="Cancel", command=_close_window).grid(
            row=0, column=4
        )

    def _create_apply_indicator(
        self,
        parent,
        *,
        layout: str = "grid",
        row: int = 0,
        column: int = 0,
        padx=(4, 0),
        pady=0,
        sticky="w",
        side="left",
    ):
        """Create apply indicator.
        Used to instantiate apply indicator during setup."""
        canvas = tk.Canvas(parent, width=12, height=12, highlightthickness=0, bd=0)

        background_candidates = (parent, getattr(parent, "master", None), self)
        # Iterate over background_candidates to apply the per-item logic.
        for candidate in background_candidates:
            if candidate is None:
                continue
            try:
                bg = candidate.cget("background")
            except Exception:
                continue
            if bg:
                try:
                    canvas.configure(background=bg)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                break

        if layout == "pack":
            canvas.pack(side=side, padx=padx, pady=pady)
        else:
            canvas.grid(row=row, column=column, padx=padx, pady=pady, sticky=sticky)

        self._apply_indicator_canvases.append(canvas)
        self._update_apply_columns_indicator(self._apply_columns_indicator_state)
        return canvas

    def _create_vdw_indicator(
        self,
        parent,
        *,
        layout: str = "grid",
        row: int = 0,
        column: int = 0,
        padx=(4, 0),
        pady=0,
        sticky="w",
        side="left",
    ):
        """Create VDW indicator.
        Used to instantiate VDW indicator during setup."""
        canvas = tk.Canvas(parent, width=12, height=12, highlightthickness=0, bd=0)

        background_candidates = (parent, getattr(parent, "master", None), self)
        # Iterate over background_candidates to apply the per-item logic.
        for candidate in background_candidates:
            if candidate is None:
                continue
            try:
                bg = candidate.cget("background")
            except Exception:
                continue
            if bg:
                try:
                    canvas.configure(background=bg)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                break

        if layout == "pack":
            canvas.pack(side=side, padx=padx, pady=pady)
        else:
            canvas.grid(row=row, column=column, padx=padx, pady=pady, sticky=sticky)

        self._apply_vdw_indicator_canvases.append(canvas)
        self._update_apply_vdw_indicator(self._apply_vdw_indicator_state)
        return canvas

    def _update_apply_columns_indicator(self, state: str) -> None:
        """Update apply columns indicator.
        Used to keep apply columns indicator in sync with current state."""
        self._apply_columns_indicator_state = state

        active_canvases = []
        # Iterate over list(self._apply_indicator_canvases) to apply the per-item logic.
        for canvas in list(self._apply_indicator_canvases):
            if canvas is None or not canvas.winfo_exists():
                continue
            active_canvases.append(canvas)
            canvas.delete("all")

            radius = 4
            if state == "success":
                fill_color = "#2da44e"
            else:
                fill_color = "#d73a49"

            canvas.create_oval(
                2,
                2,
                2 + radius * 2,
                2 + radius * 2,
                fill=fill_color,
                outline="",
            )
        self._apply_indicator_canvases = active_canvases

    def _update_apply_vdw_indicator(self, state: str) -> None:
        """Update apply VDW indicator.
        Used to keep apply VDW indicator in sync with current state."""
        self._apply_vdw_indicator_state = state

        active_canvases = []
        # Iterate over list(self._apply_vdw_indicator_canvases) to apply the per-item logic.
        for canvas in list(self._apply_vdw_indicator_canvases):
            if canvas is None or not canvas.winfo_exists():
                continue
            active_canvases.append(canvas)
            canvas.delete("all")

            radius = 4
            if state == "success":
                fill_color = "#2da44e"
            else:
                fill_color = "#d73a49"

            canvas.create_oval(
                2,
                2,
                2 + radius * 2,
                2 + radius * 2,
                fill=fill_color,
                outline="",
            )
        self._apply_vdw_indicator_canvases = active_canvases

    def _register_apply_button(self, button):
        """Apply button.
        Used by register workflows to apply button."""
        if button is None:
            return
        try:
            button.winfo_exists()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return

        buttons = []
        # Iterate over getattr(self, "_apply_columns_buttons", []) to apply the per-item logic.
        for existing in getattr(self, "_apply_columns_buttons", []):
            try:
                if existing is button:
                    return
                if existing.winfo_exists():
                    buttons.append(existing)
            except Exception:
                continue

        buttons.append(button)
        self._apply_columns_buttons = buttons

    def _set_widget_enabled(self, widget, enabled: bool) -> None:
        """Set enabled/disabled state for tk, ttk, and CTk widgets.

        Purpose:
            Apply one consistent enabled/disabled state update across mixed widget
            toolkits used during staged CTk migration.
        Why:
            Some code paths currently assume ttk `.state(...)`, while CTk widgets
            require `configure(state=...)`; this helper prevents toolkit-specific
            branching from leaking into feature logic.
        Args:
            widget: Target widget instance to update.
            enabled: True to enable interaction, False to disable interaction.
        Returns:
            None.
        Side Effects:
            Mutates the widget state in-place when supported by the underlying
            toolkit (`ttk`, `tk`, or `customtkinter`).
        Exceptions:
            Best-effort only; unsupported widgets are ignored silently.
        """
        if widget is None:
            return
        ttk_state = ["!disabled"] if enabled else ["disabled"]
        tk_state = tk.NORMAL if enabled else tk.DISABLED
        if hasattr(widget, "state"):
            try:
                widget.state(ttk_state)
                return
            except Exception:
                # Fall through to configure/config for non-ttk widgets.
                pass
        if hasattr(widget, "configure"):
            try:
                widget.configure(state=tk_state)
                return
            except Exception:
                pass
        if hasattr(widget, "config"):
            try:
                widget.config(state=tk_state)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _reset_apply_buttons_state(self):
        """Reset tracked Apply buttons to a neutral enabled state.

        Purpose:
            Clear pressed/active visual state and ensure Apply buttons are enabled.
        Why:
            Columns UI now mixes ttk and CTk buttons, so reset behavior must avoid
            toolkit-specific assumptions like tk `relief` configuration.
        Args:
            None.
        Returns:
            None.
        Side Effects:
            Iterates and updates widgets tracked in `_apply_columns_buttons`.
        Exceptions:
            Missing/destroyed widgets are skipped without raising.
        """
        buttons = []
        # Iterate over getattr(self, "_apply_columns_buttons", []) to apply the per-item logic.
        for button in getattr(self, "_apply_columns_buttons", []):
            try:
                if not button.winfo_exists():
                    continue
                if hasattr(button, "state"):
                    try:
                        button.state(["!pressed", "!active"])
                    except Exception:
                        # Continue to generic enable fallback below.
                        pass
                self._set_widget_enabled(button, True)
                if isinstance(button, tk.Button):
                    button.config(relief=tk.RAISED)
                buttons.append(button)
            except Exception:
                continue
        self._apply_columns_buttons = buttons

    def _apply_columns_from_cycle_tab(self):
        """Apply columns from cycle tab.
        Used to apply columns from cycle tab changes to live state."""
        self._cancel_cycle_focus_callback()
        self._pending_cycle_tab_focus = False
        self.after_idle(lambda: self._apply_columns(auto_refresh_axes=True))

    def _browse_file(self):
        """Perform browse file.
        Used to keep the workflow logic localized and testable."""

        path = filedialog.askopenfilename(
            title="Select Excel File", filetypes=[("Excel Files", "*.xlsx *.xls")]
        )

        if not path:

            return

        self.file_path = path

        self.e_file.delete(0, tk.END)

        self.e_file.insert(0, path)

        settings["last_file_path"] = self.file_path

        _save_settings_to_disk()

        self._load_sheet_names()

    def _load_sheet_names(self):
        """Load sheet names.
        Used when restoring sheet names from storage."""

        if not self.file_path:

            return

        try:

            self.sheet_names = _read_excel_sheet_names(self.file_path)

        except Exception as exc:

            self.sheet_names = []

            self.lbl_status.config(text="Failed to load sheet names.")

            messagebox.showerror(
                "Load Error", f"Could not read sheet names from the workbook: {exc}"
            )

            return

        self._sheet_names_loaded = True

        # Always refresh the combobox values

        self.om_sheet.configure(values=self.sheet_names)

        # Ensure selection is valid

        if self.selected_sheet.get() not in self.sheet_names and not (
            self.multi_sheet_enabled and self.selected_sheets
        ):
            self.selected_sheet.set(self.sheet_names[0] if self.sheet_names else "")

        self._sync_selected_sheets(persist=True)
        self._refresh_multi_sheet_lists()
        self._columns_schema_preview = []
        self._columns_schema_preview_sheet = None
        self._columns_schema_preview_path = None
        if getattr(self, "columns_frame", None) is not None:
            try:
                self._refresh_columns_ui()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # Status line

        self.lbl_status.config(
            text=(
                f"Loaded {os.path.basename(self.file_path)}. "
                f"{len(self.sheet_names)} sheet(s) found."
            )
        )

    def _elapsed_unit_label(self) -> str:
        """Perform elapsed unit label.
        Used to keep the workflow logic localized and testable."""
        unit = _normalize_elapsed_time_unit(settings.get("elapsed_time_unit"))
        return unit

    def _elapsed_axis_label(self) -> str:
        """Perform elapsed axis label.
        Used to keep the workflow logic localized and testable."""
        return f"Elapsed Time ({self._elapsed_unit_label()})"

    def _elapsed_unit_seconds(self) -> float:
        """Perform elapsed unit seconds.
        Used to keep the workflow logic localized and testable."""
        unit = self._elapsed_unit_label()
        return float(ELAPSED_UNIT_SECONDS.get(unit, 86400.0))

    def _build_stitched_dataframe(self, selected_sheets, dt_col: str):
        """Build stitched dataframe.
        Used to assemble stitched dataframe during UI or plot setup."""
        if not self.file_path:
            raise ValueError("No Excel file selected.")
        if not selected_sheets:
            raise ValueError("No sheets selected for stitching.")
        if not dt_col or dt_col == "None":
            raise ValueError("No Date & Time column selected for stitching.")

        sheet_dfs = {}
        stitched_frames = []
        t0_candidates = []
        missing_dt_sheets = []

        # Iterate over selected_sheets to apply the per-item logic.
        for sheet_name in selected_sheets:
            df = _read_excel_dataframe(self.file_path, sheet_name)
            sheet_map = self._get_effective_sheet_column_map(sheet_name)
            sheet_dt_col = sheet_map.get("dt") or dt_col
            if not sheet_dt_col or sheet_dt_col == "None":
                sheet_dt_col = dt_col
            working = df.copy()
            if sheet_dt_col in working.columns:
                dt_series = pd.to_datetime(working[sheet_dt_col], errors="coerce")
            else:
                missing_dt_sheets.append(sheet_name)
                dt_series = pd.Series([pd.NaT] * len(working))
            working[self._stitched_dt_col] = dt_series
            dt_min = dt_series.min()
            if pd.notna(dt_min):
                t0_candidates.append(dt_min)
            sheet_dfs[sheet_name] = working
            stitched_frames.append(working)

        if missing_dt_sheets:
            messagebox.showwarning(
                "Stitching Warning",
                "Date & Time column missing for: "
                f"{', '.join(missing_dt_sheets)}. These rows will be NaN.",
            )

        if not t0_candidates:
            messagebox.showerror(
                "Stitching Error",
                "Could not determine a valid Date & Time reference across "
                "the selected sheets.",
            )
            raise ValueError("No valid Date & Time values found for stitching.")

        t0 = min(t0_candidates)
        unit_seconds = self._elapsed_unit_seconds()

        # Closure captures _build_stitched_dataframe local context to keep helper logic scoped and invoked directly within _build_stitched_dataframe.
        def _format_elapsed_hms(seconds):
            """Format elapsed hms.
            Used to prepare elapsed hms for display or export."""
            try:
                if seconds is None or not math.isfinite(seconds):
                    return np.nan
            except (TypeError, ValueError):
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                return np.nan
            total_seconds = int(round(seconds))
            sign = "-" if total_seconds < 0 else ""
            total_seconds = abs(total_seconds)
            days, rem = divmod(total_seconds, 86400)
            hours, rem = divmod(rem, 3600)
            minutes, secs = divmod(rem, 60)
            if days > 0:
                return f"{sign}{days} {hours:02d}:{minutes:02d}:{secs:02d}"
            return f"{sign}{hours:02d}:{minutes:02d}:{secs:02d}"

        stitched_parts = []
        # Iterate over indexed elements from stitched_frames to apply the per-item logic.
        for idx, frame in enumerate(stitched_frames):
            elapsed_seconds = (frame[self._stitched_dt_col] - t0).dt.total_seconds()
            frame[self._stitched_x_col] = elapsed_seconds / unit_seconds
            frame[self._stitched_hms_col] = elapsed_seconds.apply(_format_elapsed_hms)
            if idx > 0:
                separator = {}
                # Iterate over frame.columns to apply the per-item logic.
                for col in frame.columns:
                    dtype = frame[col].dtype
                    if pd.api.types.is_datetime64_any_dtype(dtype):
                        separator[col] = pd.NaT
                    elif pd.api.types.is_bool_dtype(dtype):
                        separator[col] = ""
                    elif pd.api.types.is_numeric_dtype(dtype):
                        separator[col] = np.nan
                    else:
                        separator[col] = ""
                stitched_parts.append(pd.DataFrame([separator]))
            stitched_parts.append(frame)

        stitched_df = pd.concat(stitched_parts, ignore_index=True, sort=False)
        self.sheet_dfs = sheet_dfs
        self.df = stitched_df
        self._clear_numeric_cache()
        self._cycle_mask = None
        self._cycle_pending_range = None
        self._cached_cycle_markers = None
        self._preloaded_cycle_markers = None
        self._markers_seeded_from_cache = False
        if isinstance(self.columns, dict):
            self.columns["x"] = self._stitched_x_col
        else:
            self.columns = {"x": self._stitched_x_col}
        settings_columns = settings.get("columns")
        if not isinstance(settings_columns, dict):
            settings_columns = {}
        settings_columns["x"] = self._stitched_x_col
        settings["columns"] = settings_columns
        return stitched_df

    def _load_dataframe(self):
        """Load dataframe.
        Used when restoring dataframe from storage."""

        if not self.file_path:

            messagebox.showerror("Missing Data", "Please choose a file first.")

            return

        if self.multi_sheet_enabled:
            if not self.selected_sheets:
                messagebox.showerror(
                    "Missing Data", "Select at least one sheet to include."
                )
                return
            dt_col = (self.columns or {}).get("dt")
            if not dt_col or dt_col == "None":
                messagebox.showerror(
                    "Missing Columns",
                    "Multi-sheet mode requires selecting a Date & Time column on the Columns tab.",
                )
                return
            try:
                self._build_stitched_dataframe(self.selected_sheets, dt_col)
                self.lbl_status.config(
                    text=(
                        f"Sheets loaded: {len(self.selected_sheets)} "
                        f"({len(self.df)} rows)."
                    )
                )
                settings["selected_sheets"] = list(self.selected_sheets)
                settings["multi_sheet_enabled"] = True
                _save_settings_to_disk()

                requested_temp = self._requested_cycle_temp_column or settings.get(
                    "cycle_temp_column", CYCLE_TEMP_DEFAULT_LABEL
                )
                if (
                    requested_temp
                    and requested_temp != CYCLE_TEMP_DEFAULT_LABEL
                    and requested_temp in self.df.columns
                ):
                    self.cycle_temp_column.set(requested_temp)
                    self._requested_cycle_temp_column = requested_temp

                self._last_applied_columns = None
                self._refresh_columns_ui()

                self._mark_columns_dirty(reason="load sheets")
                self._auto_title_view_cache.clear()
                self._update_auto_title_preview()

            except Exception as e:

                self.df = None

                self._clear_numeric_cache()

                messagebox.showerror("Load Error", f"Could not load sheets: {e}")

            return

        if not self.selected_sheet.get():

            messagebox.showerror("Missing Data", "Please choose a file and sheet.")

            return

        try:

            self.df = _read_excel_dataframe(self.file_path, self.selected_sheet.get())

            self._clear_numeric_cache()

            self.lbl_status.config(
                text=f"Sheet loaded: {self.selected_sheet.get()} ({len(self.df)} rows)."
            )

            settings["last_sheet_name"] = self.selected_sheet.get()

            _save_settings_to_disk()

            requested_temp = self._requested_cycle_temp_column or settings.get(
                "cycle_temp_column", CYCLE_TEMP_DEFAULT_LABEL
            )
            if (
                requested_temp
                and requested_temp != CYCLE_TEMP_DEFAULT_LABEL
                and requested_temp in self.df.columns
            ):
                self.cycle_temp_column.set(requested_temp)
                self._requested_cycle_temp_column = requested_temp

            self._last_applied_columns = None
            self._refresh_columns_ui()

            self._mark_columns_dirty(reason="load sheet")
            self._auto_title_view_cache.clear()
            self._update_auto_title_preview()

        except Exception as e:

            self.df = None

            self._clear_numeric_cache()

            messagebox.showerror("Load Error", f"Could not load sheet: {e}")

    def _apply_columns(self, *, auto_refresh_axes: bool = False):
        """Apply columns.
        Used to apply columns changes to live state."""

        if self.df is None:
            if not self.multi_sheet_enabled:
                messagebox.showerror("No Data", "Load a sheet first.")
                self._reset_apply_buttons_state()
                return
            if not self.file_path or not self.selected_sheets:
                messagebox.showerror(
                    "Missing Data", "Select a file and at least one sheet first."
                )
                self._reset_apply_buttons_state()
                return

        self._pending_cycle_tab_focus = False

        self._cancel_cycle_focus_callback()

        self._update_apply_columns_indicator("pending")

        task_id = getattr(self, "_apply_columns_task_id", None)

        if task_id is not None:

            try:

                self.lbl_status.config(text="Column selection already in progress...")

            except Exception:

                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._reset_apply_buttons_state()

            return

        self._is_applying_columns = True
        if DEBUG_SERIES_FLOW:
            self._series_flow_active = True
            self._series_flow_apply_id = getattr(self, "_series_flow_apply_id", 0) + 1
            self._series_flow_debug_seen = set()

        self.columns = {k: v.get() for k, v in self.columns_vars.items()}

        settings["columns"] = self.columns

        _save_settings_to_disk()

        if self.multi_sheet_enabled:
            dt_col = self.columns.get("dt")
            if not dt_col or dt_col == "None":
                self._is_applying_columns = False
                self._update_apply_columns_indicator("pending")
                self._reset_apply_buttons_state()
                messagebox.showerror(
                    "Missing Columns",
                    "Multi-sheet mode requires selecting a Date & Time column.",
                )
                return
            if not self.selected_sheets:
                self._is_applying_columns = False
                self._update_apply_columns_indicator("pending")
                self._reset_apply_buttons_state()
                messagebox.showerror(
                    "Missing Data", "Select at least one sheet to include."
                )
                return
            try:
                self._build_stitched_dataframe(self.selected_sheets, dt_col)
            except Exception:
                self._is_applying_columns = False
                self._update_apply_columns_indicator("pending")
                self._reset_apply_buttons_state()
                return
            try:
                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._refresh_columns_ui()

        # Update UI-facing column choices before background work begins.
        self._refresh_cycle_temp_choices()

        cycle_temp_choice = (
            self.cycle_temp_column.get() if hasattr(self, "cycle_temp_column") else None
        )
        self._requested_cycle_temp_column = cycle_temp_choice

        self._columns_applied = False

        self._cycle_mask = None

        self._cycle_pending_range = None

        if not getattr(self, "_cycle_ui_built", False):
            self._start_cycle_loading_indicator(
                "Applying column selection and preparing Cycle Analysis"
            )

        try:

            self._ensure_cycle_tab(defer_build=False)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        sel_label = getattr(self, "_cycle_sel_label", None)

        if sel_label is not None:

            self._set_cycle_selection_text("Selection: (updating...)")

        try:

            self._shade_selection(None)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:

            self.lbl_status.config(text="Applying column selection...")

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        axis_pad_pct = self._safe_get_var(self.axis_pad_pct, float)
        axis_auto_flags = self._get_axis_auto_range_flags()

        fallback_ranges = {
            "x_min": self._safe_get_var(self.min_time, float),
            "x_max": self._safe_get_var(self.max_time, float),
            "y_min": self._safe_get_var(self.min_y, float),
            "y_max": self._safe_get_var(self.max_y, float),
            "twin_y_min": self._safe_get_var(self.twin_y_min, float),
            "twin_y_max": self._safe_get_var(self.twin_y_max, float),
            "deriv_y_min": self._safe_get_var(self.deriv_y_min, float),
            "deriv_y_max": self._safe_get_var(self.deriv_y_max, float),
        }

        columns_snapshot = dict(self.columns)
        effective_columns_snapshot = dict(self._get_effective_columns())
        per_sheet_effective_map = {}
        if self.multi_sheet_enabled and self.selected_sheets:
            # Iterate over list(self.selected_sheets) to apply the per-item logic.
            for sheet_name in list(self.selected_sheets):
                per_sheet_effective_map[sheet_name] = (
                    self._get_effective_sheet_column_map(sheet_name)
                )

        with self._data_lock:
            # Snapshot shared data for thread safety/no-GIL readiness.
            df_snapshot = self.df
            sheet_dfs_snapshot = (
                dict(self.sheet_dfs) if isinstance(self.sheet_dfs, dict) else {}
            )
            selected_sheets_snapshot = list(self.selected_sheets)
            multi_sheet_enabled_snapshot = bool(self.multi_sheet_enabled)
            file_path_snapshot = self.file_path
            stitched_x_col_snapshot = self._stitched_x_col
            elapsed_axis_label = self._elapsed_axis_label()

        if DEBUG_SERIES_FLOW:
            y1_col = columns_snapshot.get("y1")
            in_df = bool(df_snapshot is not None and y1_col in df_snapshot.columns)
            self._debug_series_flow("snapshot", f"y1={y1_col!r} in_df={in_df}")

        self._update_apply_columns_indicator("pending")

        # Closure captures _apply_columns state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _apply_columns.
        def _worker(
            columns_snapshot=columns_snapshot,
            effective_columns_snapshot=effective_columns_snapshot,
            cycle_choice=cycle_temp_choice,
            auto_flags=axis_auto_flags,
        ):
            """Perform worker.
            Used to keep the workflow logic localized and testable."""
            local_cache: Dict[Tuple[str, bool], Optional[pd.Series]] = {}

            # Closure captures _apply_columns local context to keep helper logic scoped and invoked directly within _apply_columns.
            def _get_numeric_series_for_df(
                df: Optional[pd.DataFrame], colname: str, *, dropna: bool = False
            ) -> Optional[pd.Series]:
                """Return numeric series for df.
                Used to retrieve numeric series for df for downstream logic."""
                if df is None or not colname or colname == "None":
                    return None
                key = (colname, bool(dropna))
                if key in local_cache:
                    return local_cache[key]
                if dropna:
                    base = _get_numeric_series_for_df(df, colname, dropna=False)
                    if base is None:
                        result = None
                    else:
                        cleaned = base.dropna()
                        result = None if cleaned.empty else cleaned
                else:
                    try:
                        result = pd.to_numeric(df[colname], errors="coerce")
                    except Exception:
                        result = None
                local_cache[key] = result
                return result

            # Closure captures _apply_columns local context to keep helper logic scoped and invoked directly within _apply_columns.
            def _build_stitched_series_for_var(var_key: str) -> Optional[pd.Series]:
                """Build stitched series for var.
                Used to assemble stitched series for var during UI or plot setup."""
                if not selected_sheets_snapshot:
                    return None
                parts: List[pd.Series] = []
                # Iterate over indexed elements from selected_sheets_snapshot to apply the per-item logic.
                for idx, sheet_name in enumerate(selected_sheets_snapshot):
                    df = sheet_dfs_snapshot.get(sheet_name)
                    if df is None and file_path_snapshot:
                        try:
                            df = _read_excel_dataframe(file_path_snapshot, sheet_name)
                        except Exception:
                            df = None
                    if df is None:
                        continue
                    mapping = per_sheet_effective_map.get(
                        sheet_name, effective_columns_snapshot
                    )
                    colname = mapping.get(var_key)
                    if not colname or colname == "None" or colname not in df.columns:
                        part = pd.Series([np.nan] * len(df), dtype=float)
                    else:
                        try:
                            part = pd.to_numeric(df[colname], errors="coerce")
                        except Exception:
                            part = pd.Series([np.nan] * len(df), dtype=float)
                    parts.append(part)
                    if idx < len(selected_sheets_snapshot) - 1:
                        parts.append(pd.Series([np.nan], dtype=float))
                if not parts:
                    return None
                return pd.concat(parts, ignore_index=True)

            selected = dict(columns_snapshot or {})
            dt_col = selected.get("dt")
            if (
                multi_sheet_enabled_snapshot
                and dt_col
                and dt_col != "None"
                and effective_columns_snapshot.get("x") == stitched_x_col_snapshot
            ):
                selected["x"] = elapsed_axis_label

            use_per_sheet = bool(
                multi_sheet_enabled_snapshot
                and selected_sheets_snapshot
                and sheet_dfs_snapshot
            )
            series_map: Dict[str, Optional[pd.Series]] = {}
            # Iterate over ("x", "y1", "y2", "y3", "z", "z2") to apply the per-item logic.
            for key in ("x", "y1", "y2", "y3", "z", "z2"):
                if use_per_sheet:
                    series = _build_stitched_series_for_var(key)
                    if series is not None:
                        series_map[key] = series
                        continue
                colname = effective_columns_snapshot.get(key)
                if not colname or colname == "None":
                    series_map[key] = None
                else:
                    series_map[key] = _get_numeric_series_for_df(df_snapshot, colname)

            cycle_temp_series = None
            if cycle_choice and cycle_choice != CYCLE_TEMP_DEFAULT_LABEL:
                cycle_temp_series = _get_numeric_series_for_df(
                    df_snapshot, cycle_choice
                )

            payload = {
                "selected_columns": selected,
                "series": series_map,
                "cycle_temp_column": cycle_choice,
                "cycle_temp_series": cycle_temp_series,
            }
            x_series = series_map.get("x")
            payload["data_len"] = int(len(x_series)) if x_series is not None else 0

            ranges = None
            if auto_refresh_axes:
                ranges = self._compute_axis_ranges_for_snapshot(
                    effective_columns_snapshot,
                    axis_pad_pct,
                    fallback_ranges,
                    auto_flags=auto_flags,
                    series_map=series_map,
                    df_snapshot=df_snapshot,
                )
            return payload, ranges

        # Closure captures _apply_columns state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _apply_columns.
        def _on_ok(result):
            """Handle ok.
            Used as an event callback for ok."""
            payload, ranges = result
            if DEBUG_SERIES_FLOW:
                y1_series = (payload.get("series") or {}).get("y1")
                y1_none = y1_series is None
                y1_len = int(len(y1_series)) if y1_series is not None else 0
                self._debug_series_flow("payload", f"y1_none={y1_none} len={y1_len}")
            self._on_apply_columns_complete(
                payload, ranges, auto_refresh_axes, axis_auto_flags
            )

        # Closure captures _apply_columns state for callback wiring, kept nested to scope the handler, and invoked by bindings set in _apply_columns.
        def _on_err(exc):
            """Handle err.
            Used as an event callback for err."""
            self._on_apply_columns_failed(exc)

        self._apply_columns_task_id = self._task_runner.submit(
            "apply_columns", _worker, _on_ok, _on_err
        )

    def _on_apply_columns_complete(
        self, payload, ranges, auto_refresh_axes, auto_flags=None
    ):
        """Handle apply columns complete.
        Used as an event callback for apply columns complete."""

        self._apply_columns_task_id = None
        self._stop_cycle_loading_indicator()

        try:

            self._apply_series_payload(payload)

        except Exception as exc:

            self._on_apply_columns_failed(exc)

            return

        if auto_refresh_axes:
            if not isinstance(ranges, dict):

                self._on_apply_columns_failed(
                    RuntimeError("Column selection did not return axis ranges.")
                )

                return

            flags = (
                _sanitize_axis_auto_range_settings(auto_flags)
                if auto_flags is not None
                else self._get_axis_auto_range_flags()
            )

            try:

                if flags.get("time", True):
                    self.min_time.set(ranges["x_min"])

                    self.max_time.set(ranges["x_max"])

                if flags.get("pressure", True):
                    self.min_y.set(ranges["y_min"])

                    self.max_y.set(ranges["y_max"])

                if flags.get("temperature", True):
                    self.twin_y_min.set(ranges["twin_y_min"])

                    self.twin_y_max.set(ranges["twin_y_max"])

                if flags.get("derivative", True):
                    self.deriv_y_min.set(ranges["deriv_y_min"])

                    self.deriv_y_max.set(ranges["deriv_y_max"])

            except Exception as exc:

                self._on_apply_columns_failed(exc)

                return

        self._columns_applied = True
        try:
            self._last_applied_columns = dict(self.columns)
        except Exception:
            self._last_applied_columns = None

        self._cycle_mask = None

        self._cycle_pending_range = None

        try:

            self._shade_selection(None)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        self._refresh_cycle_selection_text()

        try:

            self.lbl_status.config(text="Column selection applied.")

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:

            self.save_settings()

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        self._update_apply_columns_indicator("success")
        self._reset_apply_buttons_state()

        auto_flag = bool(self.auto_detect_cycles.get())

        if getattr(self, "_suspend_cycle_autorun", False):

            if self._cycle_ui_built:

                self._show_cycle_ready_message()

            else:

                self._pending_cycle_recompute = {
                    "auto_detect": False,
                    "ignore_min_drop": False,
                    "preserve_view": False,
                }

        else:

            if self._cycle_ui_built:

                try:

                    self._recompute_cycle_analysis(auto_detect=auto_flag)

                except Exception as exc:

                    print(f"Cycle analysis auto-refresh failed: {exc}")

                    self._show_cycle_ready_message()

            else:

                self._pending_cycle_recompute = {
                    "auto_detect": auto_flag,
                    "ignore_min_drop": False,
                    "preserve_view": False,
                }

        if getattr(self, "_pending_cycle_tab_focus", False):
            self._focus_cycle_tab_when_ready()
        else:
            self._cancel_cycle_focus_callback()
        auto_jump = bool(
            getattr(self, "_auto_jump_plot_var", tk.BooleanVar(value=True)).get()
        )
        if auto_jump:
            self._focus_plot_tab()

        try:
            self._auto_title_view_cache.clear()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._update_auto_title_preview()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if getattr(self, "_profile_restore_pending", None):
            try:
                self._finalize_profile_restore()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        self._is_applying_columns = False
        if DEBUG_SERIES_FLOW:
            self._series_flow_active = False

    def _on_apply_columns_failed(self, exc):
        """Handle apply columns failed.
        Used as an event callback for apply columns failed."""

        self._apply_columns_task_id = None
        self._is_applying_columns = False
        self._profile_restore_pending = None
        if DEBUG_SERIES_FLOW:
            self._series_flow_active = False

        self._columns_applied = False
        self._stop_cycle_loading_indicator()

        try:

            self.lbl_status.config(text=f"Column selection failed: {exc}")

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:

            self._show_cycle_apply_prompt()

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        try:

            messagebox.showerror(
                "Apply Column Selection", f"Column selection failed: {exc}"
            )

        except Exception:

            print(f"Column selection failed: {exc}")

        self._pending_cycle_tab_focus = False
        self._cancel_cycle_focus_callback()
        self._update_apply_columns_indicator("pending")
        self._reset_apply_buttons_state()

    def _apply_product_settings(self, *_):
        """Apply product settings.
        Used to apply product settings changes to live state."""
        preset_key = self.v_product_preset.get()

        if preset_key not in PRODUCT_PRESETS:
            preset_key = next(iter(PRODUCT_PRESETS))
            self.v_product_preset.set(preset_key)

        preset_info = PRODUCT_PRESETS.get(preset_key) or {}

        name = preset_info.get("name", DEFAULT_PRODUCT_NAME)
        self.v_product_name.set(name)

        try:
            molar_mass = float(self.v_product_molar_mass.get())
        except Exception:
            try:
                messagebox.showerror(
                    "Invalid Input", "Please enter a valid molar mass (g/mol)."
                )
            except Exception:
                pass
            self.v_product_molar_mass.set(
                settings.get(
                    "starting_material_mw_g_mol",
                    settings.get("product_molar_mass", DEFAULT_STARTING_MATERIAL_MOLAR_MASS),
                )
            )
            return

        if molar_mass <= 0.0:
            try:
                messagebox.showerror(
                    "Invalid Input", "Molar mass must be greater than zero."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self.v_product_molar_mass.set(
                settings.get(
                    "starting_material_mw_g_mol",
                    settings.get("product_molar_mass", DEFAULT_STARTING_MATERIAL_MOLAR_MASS),
                )
            )
            return

        try:
            starting_mass = float(self.v_starting_mass.get())
        except Exception:
            try:
                messagebox.showerror(
                    "Invalid Input", "Please enter a valid starting material mass (g)."
                )
            except Exception:
                pass
            self.v_starting_mass.set(
                settings.get(
                    "starting_material_mass_g", settings.get("starting_mass", 0.0)
                )
            )
            return

        if starting_mass < 0.0:
            try:
                messagebox.showerror(
                    "Invalid Input", "Starting material mass cannot be negative."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self.v_starting_mass.set(
                max(
                    settings.get(
                        "starting_material_mass_g", settings.get("starting_mass", 0.0)
                    ),
                    0.0,
                )
            )
            return

        try:
            stoich_val = float(self.v_starting_stoich.get())
        except Exception:
            try:
                messagebox.showerror(
                    "Invalid Input",
                    "Please enter a valid stoichiometry value (mol gas per mol starting).",
                )
            except Exception:
                pass
            self.v_starting_stoich.set(
                settings.get(
                    "stoich_mol_gas_per_mol_starting",
                    DEFAULT_STOICH_MOL_GAS_PER_MOL_STARTING,
                )
            )
            return

        if stoich_val < 0.0:
            try:
                messagebox.showerror(
                    "Invalid Input", "Stoichiometry cannot be negative."
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self.v_starting_stoich.set(
                max(
                    settings.get(
                        "stoich_mol_gas_per_mol_starting",
                        DEFAULT_STOICH_MOL_GAS_PER_MOL_STARTING,
                    ),
                    0.0,
                )
            )
            return

        self.v_product_molar_mass.set(molar_mass)
        self.v_starting_mass.set(starting_mass)
        self.v_starting_stoich.set(stoich_val)

        display_name = self.v_starting_material_display_name.get().strip()
        display_note = self.v_starting_material_display_note.get().strip()
        self.v_starting_material_display_name.set(display_name)
        self.v_starting_material_display_note.set(display_note)

        settings["starting_material_preset"] = preset_key
        settings["starting_material_display_name"] = display_name
        settings["starting_material_display_note"] = display_note
        settings["starting_material_mw_g_mol"] = molar_mass
        settings["starting_material_mass_g"] = starting_mass
        settings["stoich_mol_gas_per_mol_starting"] = stoich_val

        settings["starting_mass"] = starting_mass
        settings["naoh_mass"] = starting_mass

        _save_settings_to_disk()

        self._prepare_series_globals()
        self._update_cycle_summary_conversion_status()
        self._refresh_cycle_summary_from_snapshot()

        if self._cycle_ready() and self._cycle_last_transfer_payload is None:
            try:
                self._recompute_cycle_analysis(auto_detect=False, preserve_view=True)
            except Exception:
                self._show_cycle_ready_message()

    def _apply_vdw(self):
        """Apply VDW.
        Used to apply VDW changes to live state."""

        try:

            # reading .get() validates convertibility (DoubleVar enforces float)

            _ = float(self.v_volume.get())

            _ = float(self.v_a.get())

            _ = float(self.v_b.get())

            _ = float(self.v_starting_mass.get())

            gas_molar_mass = float(self.v_gas_molar_mass.get())

        except Exception:

            messagebox.showerror(
                "Invalid Input",
                "Please enter valid numeric values for V, a, b, gaseous reagent molar mass, and starting material mass.",
            )

            return

        if not math.isfinite(gas_molar_mass) or gas_molar_mass <= 0.0:
            messagebox.showerror(
                "Invalid Input", "Gaseous reagent molar mass must be greater than zero."
            )
            return

        settings["vessel_volume"] = self.v_volume.get()

        settings["vdw_a"] = self.v_a.get()

        settings["vdw_b"] = self.v_b.get()

        settings["vdw_gas"] = self.v_gas.get()

        settings["starting_material_mass_g"] = self.v_starting_mass.get()

        settings["starting_mass"] = self.v_starting_mass.get()

        settings["naoh_mass"] = self.v_starting_mass.get()

        settings["vdw_gas_molar_mass"] = gas_molar_mass

        preset_name = self.v_gas.get()
        if preset_name:
            overrides = self._gas_preset_overrides.setdefault(preset_name, {})
            overrides["molar_mass"] = gas_molar_mass
            settings["gas_preset_overrides"] = self._gas_preset_overrides

        _save_settings_to_disk()

        self.a_const = self.v_a.get()
        self.b_const = self.v_b.get()

        globals()["volume"] = self.v_volume.get()
        globals()["a_const"] = self.v_a.get()
        globals()["b_const"] = self.v_b.get()
        globals()["starting_mass_g"] = self.v_starting_mass.get()
        globals()["starting_material_mass_g"] = self.v_starting_mass.get()
        globals()["gas_molar_mass"] = gas_molar_mass

        if self._cycle_ready():
            try:
                auto_flag = bool(self.auto_detect_cycles.get())
            except Exception:
                auto_flag = True
            try:
                self._recompute_cycle_analysis(
                    auto_detect=auto_flag, preserve_view=True
                )
            except Exception:
                self._show_cycle_ready_message()

        self._update_apply_vdw_indicator("success")
        self._update_cycle_summary_conversion_status()

    def _save_custom_gas_preset(self):
        """Save custom gas preset.
        Used when persisting custom gas preset to storage."""
        try:
            a_value = float(self.v_a.get())
            b_value = float(self.v_b.get())
            molar_mass = float(self.v_gas_molar_mass.get())
        except Exception:
            messagebox.showerror(
                "Save Preset",
                "Enter valid numeric values for a, b, and gaseous reagent molar mass before saving.",
            )
            return

        if not math.isfinite(a_value) or a_value <= 0.0:
            messagebox.showerror(
                "Save Preset", "Parameter 'a' must be a positive number."
            )
            return

        if not math.isfinite(b_value):
            messagebox.showerror("Save Preset", "Parameter 'b' must be a valid number.")
            return

        if not math.isfinite(molar_mass) or molar_mass <= 0.0:
            messagebox.showerror(
                "Save Preset", "Gaseous reagent molar mass must be greater than zero."
            )
            return

        name = simpledialog.askstring("Save VDW Preset", "Preset name:", parent=self)
        if name is None:
            return
        name = name.strip()
        if not name:
            messagebox.showerror("Save Preset", "Preset name cannot be empty.")
            return

        if name in BASE_GAS_PRESETS or name.lower() == "custom":
            messagebox.showerror(
                "Save Preset", "Choose a different name; this one is reserved."
            )
            return

        formula = simpledialog.askstring(
            "Save VDW Preset", "Chemical formula:", parent=self
        )
        if formula is None:
            return
        formula = formula.strip()
        if not formula:
            messagebox.showerror("Save Preset", "Chemical formula cannot be empty.")
            return

        candidate = {
            "a": a_value,
            "b": b_value,
            "formula": formula,
            "molar_mass": molar_mass,
        }
        normalized = _normalize_gas_preset_entry(name, candidate)
        if normalized is None:
            messagebox.showerror(
                "Save Preset",
                "Could not normalize preset values. Check inputs and try again.",
            )
            return

        if name in CUSTOM_GAS_PRESETS:
            if not messagebox.askyesno(
                "Overwrite Preset?",
                f"A preset named '{name}' already exists. Overwrite it?",
                parent=self,
            ):
                return

        CUSTOM_GAS_PRESETS[name] = normalized
        self._gas_preset_overrides.pop(name, None)
        _merge_gas_preset_sources()
        settings["custom_gas_presets"] = {
            preset_name: dict(config)
            # Iterate to apply the per-item logic.
            for preset_name, config in CUSTOM_GAS_PRESETS.items()
        }
        settings["vdw_gas"] = name
        settings["vdw_gas_molar_mass"] = molar_mass
        settings["gas_preset_overrides"] = {
            preset_name: dict(config)
            # Iterate to apply the per-item logic.
            for preset_name, config in self._gas_preset_overrides.items()
        }

        try:
            _save_settings_to_disk()
        except Exception as exc:
            messagebox.showwarning(
                "Save Preset",
                f"Preset saved for this session, but settings file could not be updated:\n{exc}",
            )

        self._refresh_gas_preset_choices(selected=name)
        self._on_gas_selected()
        messagebox.showinfo("Save Preset", f"Saved preset '{name}'.")

    def _get_effective_columns(self) -> dict:
        """Return effective columns.
        Used to retrieve effective columns for downstream logic."""
        effective = dict(self.columns or {})
        dt_col = effective.get("dt")
        if self.multi_sheet_enabled and dt_col and dt_col != "None":
            effective["x"] = self._stitched_x_col
        return effective

    def _data_prep_signature(self) -> Tuple[Any, ...]:
        """Perform data prep signature.
        Used to keep the workflow logic localized and testable."""
        signature: List[Any] = []
        if self.multi_sheet_enabled:
            per_sheet_entries: List[Tuple[str, Tuple[Tuple[str, str], ...]]] = []
            # Iterate over list(self.selected_sheets or []) to apply the per-item logic.
            for sheet_name in list(self.selected_sheets or []):
                mapping = self._get_effective_sheet_column_map(sheet_name)
                entry = tuple(
                    sorted(
                        (str(key), str(value or ""))
                        # Iterate to apply the per-item logic.
                        for key, value in (mapping or {}).items()
                    )
                )
                per_sheet_entries.append((str(sheet_name), entry))
            signature.append(tuple(sorted(per_sheet_entries)))
        return tuple(signature)

    def _build_data_fingerprint(self) -> DataFingerprint:
        """Build the data fingerprint used for caching prepared series.
        Used to invalidate cached results when source data or mappings change."""
        # Fingerprint is the cache key for prepared series; it must reflect any
        # user-visible source-of-truth that would change plotted values.
        try:
            file_path = os.path.abspath(self.file_path) if self.file_path else ""
        except Exception:
            file_path = str(self.file_path or "")
        if self.multi_sheet_enabled:
            sheet_key = tuple(str(name) for name in (self.selected_sheets or []))
        else:
            sheet_key = (str(self.selected_sheet.get() or ""),)
        columns_snapshot = dict(self.columns or {})
        columns_key = tuple(
            sorted(
                (str(key), str(columns_snapshot.get(key) or ""))
                # Iterate to apply the per-item logic.
                for key in columns_snapshot
            )
        )
        cycle_temp_column = CYCLE_TEMP_DEFAULT_LABEL
        try:
            cycle_temp_column = (
                self.cycle_temp_column.get()
                if hasattr(self, "cycle_temp_column")
                else CYCLE_TEMP_DEFAULT_LABEL
            )
        except Exception:
            cycle_temp_column = CYCLE_TEMP_DEFAULT_LABEL
        elapsed_unit = self._elapsed_unit_label()
        prep_signature = self._data_prep_signature()
        return DataFingerprint(
            file_path=file_path,
            sheet_key=sheet_key,
            columns_key=columns_key,
            cycle_temp_column=str(cycle_temp_column or ""),
            elapsed_unit=str(elapsed_unit or ""),
            multi_sheet=bool(self.multi_sheet_enabled),
            prep_signature=prep_signature,
        )

    def _build_data_fingerprint_from_snapshot(
        self, snapshot: Dict[str, Any]
    ) -> DataFingerprint:
        """Build data fingerprint from snapshot.
        Used to avoid Tk access while caching prepared series."""
        file_path = snapshot.get("file_path") or ""
        sheet_key = tuple(snapshot.get("sheet_key") or ())
        columns_snapshot = snapshot.get("columns_snapshot") or {}
        columns_key = tuple(
            sorted(
                (str(key), str(columns_snapshot.get(key) or ""))
                # Iterate to apply the per-item logic.
                for key in columns_snapshot
            )
        )
        cycle_temp_column = str(snapshot.get("cycle_temp_column") or "")
        elapsed_unit = str(snapshot.get("elapsed_unit") or "")
        prep_signature = snapshot.get("prep_signature") or ()
        return DataFingerprint(
            file_path=str(file_path),
            sheet_key=sheet_key,
            columns_key=columns_key,
            cycle_temp_column=cycle_temp_column,
            elapsed_unit=elapsed_unit,
            multi_sheet=bool(snapshot.get("multi_sheet")),
            prep_signature=prep_signature,
        )

    def _log_render_cache(self, message: str) -> None:
        """Record render cache status for debug output.

        Purpose:
            Capture cache hit/miss messages for diagnostics.
        Why:
            Makes render cache behavior observable without ad-hoc prints.
        Args:
            message: Cache status message to record and optionally log.
        Returns:
            None.
        Side Effects:
            Updates last cache status and logs when cache.render is enabled.
        Exceptions:
            Best-effort guards suppress logging failures.
        """
        self._last_render_cache_status = message
        self._dbg("cache.render", "%s", message)

    def _build_series_payload(
        self,
        columns_snapshot,
        cycle_temp_name,
        *,
        effective_columns: Optional[Dict[str, Any]] = None,
    ):
        """Build series payload.
        Used to assemble series payload during UI or plot setup."""

        selected = dict(columns_snapshot or {})
        effective = (
            dict(effective_columns)
            if isinstance(effective_columns, dict)
            else self._get_effective_columns()
        )
        dt_col = selected.get("dt")
        if (
            self.multi_sheet_enabled
            and dt_col
            and dt_col != "None"
            and effective.get("x") == self._stitched_x_col
        ):
            selected["x"] = self._elapsed_axis_label()

        series_map = {}
        use_per_sheet = bool(
            self.multi_sheet_enabled and self.selected_sheets and self.sheet_dfs
        )

        # Iterate over ("x", "y1", "y2", "y3", "z", "z2") to apply the per-item logic.
        for key in ("x", "y1", "y2", "y3", "z", "z2"):

            if use_per_sheet:
                series = self._build_stitched_series_for_var(
                    key, list(self.selected_sheets)
                )
                if series is not None:
                    series_map[key] = series
                    continue

            colname = effective.get(key)

            if not colname or colname == "None":

                series_map[key] = None

            else:

                series_map[key] = self._get_numeric_series(colname)

        payload = {
            "selected_columns": selected,
            "series": series_map,
            "cycle_temp_column": cycle_temp_name,
            "cycle_temp_series": self._get_cycle_temp_series_by_name(cycle_temp_name),
        }

        series_np: Dict[str, Any] = {}
        series_nan_mask: Dict[str, Any] = {}
        series_valid_mask: Dict[str, Any] = {}

        def _coerce_series_array(values: Any) -> Any:
            """Coerce series array.
            Used to normalize series values into contiguous arrays."""
            if values is None:
                return None
            try:
                arr = np.asarray(values)
            except Exception:
                return None
            try:
                return np.ascontiguousarray(arr)
            except Exception:
                return arr

        def _coerce_nan_mask(values: Any) -> Optional[np.ndarray]:
            """Coerce nan mask.
            Used to reuse NaN masks across plot updates."""
            if values is None:
                return None
            try:
                mask = np.isnan(values)
            except Exception:
                try:
                    mask = pd.isna(values)
                except Exception:
                    return None
            try:
                mask = np.asarray(mask, dtype=bool).reshape(-1)
            except Exception:
                return None
            return mask

        # Iterate over ("x", "y1", "y2", "y3", "z", "z2") to apply the per-item logic.
        for key in ("x", "y1", "y2", "y3", "z", "z2"):
            arr = _coerce_series_array(series_map.get(key))
            series_np[key] = arr
            mask = _coerce_nan_mask(arr)
            if mask is not None:
                series_nan_mask[key] = mask
                series_valid_mask[key] = ~mask

        payload["series_np"] = series_np
        payload["series_nan_mask"] = series_nan_mask
        payload["series_valid_mask"] = series_valid_mask
        x_series = series_map.get("x")
        payload["data_len"] = int(len(x_series)) if x_series is not None else 0

        return payload

    def _apply_series_payload(self, payload):
        """Apply series payload.
        Used to apply series payload changes to live state."""

        if not isinstance(payload, dict):

            return

        selected_columns = payload.get("selected_columns") or {}
        series_map = payload.get("series") or {}

        globals()["selected_columns"] = selected_columns

        # Iterate over ("x", "y1", "y2", "y3", "z", "z2") to apply the per-item logic.
        for key in ("x", "y1", "y2", "y3", "z", "z2"):

            globals()[key] = series_map.get(key)

        globals()["cycle_temp_series"] = payload.get("cycle_temp_series")

        globals()["volume"] = self.v_volume.get()

        globals()["a_const"] = self.v_a.get()

        globals()["b_const"] = self.v_b.get()

        globals()["starting_mass_g"] = self.v_starting_mass.get()
        globals()["starting_material_mass_g"] = self.v_starting_mass.get()

        starting_display_name = self.v_starting_material_display_name.get().strip()
        if not starting_display_name:
            starting_display_name = self.v_product_name.get().strip()
        globals()["starting_material_display_name"] = starting_display_name
        globals()["starting_material_display_note"] = (
            self.v_starting_material_display_note.get().strip()
        )
        globals()["starting_material_name"] = starting_display_name
        globals()["product_name"] = (
            starting_display_name or DEFAULT_STARTING_MATERIAL_NAME
        )

        preset_key = self.v_product_preset.get()
        preset_info = PRODUCT_PRESETS.get(preset_key) or {}
        formula = preset_info.get("formula") or settings.get(
            "starting_material_formula", DEFAULT_STARTING_MATERIAL_FORMULA
        )
        globals()["starting_material_formula"] = formula
        globals()["product_formula"] = formula

        globals()["starting_material_mw_g_mol"] = self.v_product_molar_mass.get()
        globals()["product_molar_mass"] = self.v_product_molar_mass.get()

        globals()["stoich_mol_gas_per_mol_starting"] = self.v_starting_stoich.get()

        globals()["gas_molar_mass"] = self.v_gas_molar_mass.get()

        if DEBUG_SERIES_FLOW and getattr(self, "_series_flow_active", False):
            y1_series = globals().get("y1")
            y1_none = y1_series is None
            y1_len = int(len(y1_series)) if y1_series is not None else 0
            self._debug_series_flow("globals", f"y1_none={y1_none} len={y1_len}")

        self._prime_cycle_markers_from_cache()

    def _apply_series_payload_from_snapshot(self, payload: Dict[str, Any]) -> None:
        """Apply series payload values without reading Tk variables.

        Purpose:
            Update module-level globals using snapshot-provided values.
        Why:
            Async render pipelines must avoid reading Tk variables from workers.
        Inputs:
            payload: Prepared series payload containing series and metadata.
        Outputs:
            None.
        Side Effects:
            Updates module-level globals and primes cached cycle markers.
        Exceptions:
            Errors are caught to avoid interrupting UI workflows.
        """
        if not isinstance(payload, dict):
            return
        selected_columns = payload.get("selected_columns") or {}
        series_map = payload.get("series") or {}
        globals()["selected_columns"] = selected_columns
        # Iterate over ("x", "y1", "y2", "y3", "z", "z2") to apply the per-item logic.
        for key in ("x", "y1", "y2", "y3", "z", "z2"):
            globals()[key] = series_map.get(key)
        globals()["cycle_temp_series"] = payload.get("cycle_temp_series")
        globals()["volume"] = payload.get("volume")
        globals()["a_const"] = payload.get("a_const")
        globals()["b_const"] = payload.get("b_const")
        globals()["starting_mass_g"] = payload.get("starting_mass_g")
        globals()["starting_material_mass_g"] = payload.get("starting_material_mass_g")
        starting_display_name = payload.get("starting_material_display_name") or ""
        globals()["starting_material_display_name"] = starting_display_name
        globals()["starting_material_display_note"] = payload.get(
            "starting_material_display_note"
        )
        globals()["starting_material_name"] = starting_display_name
        globals()["product_name"] = payload.get(
            "product_name", starting_display_name or DEFAULT_STARTING_MATERIAL_NAME
        )
        globals()["starting_material_formula"] = payload.get(
            "starting_material_formula", settings.get("starting_material_formula")
        )
        globals()["product_formula"] = payload.get(
            "product_formula", globals().get("starting_material_formula")
        )
        globals()["starting_material_mw_g_mol"] = payload.get("starting_material_mw_g_mol")
        globals()["product_molar_mass"] = payload.get("product_molar_mass")
        globals()["stoich_mol_gas_per_mol_starting"] = payload.get(
            "stoich_mol_gas_per_mol_starting"
        )
        globals()["gas_molar_mass"] = payload.get("gas_molar_mass")
        try:
            if DEBUG_SERIES_FLOW and getattr(self, "_series_flow_active", False):
                y1_series = globals().get("y1")
                y1_none = y1_series is None
                y1_len = int(len(y1_series)) if y1_series is not None else 0
                self._debug_series_flow("globals", f"y1_none={y1_none} len={y1_len}")
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            self._prime_cycle_markers_from_cache()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def _prepare_series_globals(self, *, skip_ui: bool = False):
        """Prepare series globals.
        Used to assemble series globals inputs for downstream calculations."""

        # Make df & selected columns into the globals expected by main_plotting_function

        if self.df is None or not self.columns:

            return

        if not skip_ui:
            self._refresh_cycle_temp_choices()

        self._update_scatter_globals()

        cycle_temp_name = (
            self.cycle_temp_column.get() if hasattr(self, "cycle_temp_column") else None
        )

        payload = self._build_series_payload(dict(self.columns), cycle_temp_name)

        self._apply_series_payload(payload)

    def _resolve_prepared_data_context(
        self,
        *,
        apply_globals: bool = True,
        perf: Optional[Dict[str, Any]] = None,
        snapshot: Optional[Dict[str, Any]] = None,
    ) -> Tuple[DataFingerprint, Dict[str, Any]]:
        """Resolve prepared series and return the cache fingerprint.

        Purpose:
            Retrieve or build prepared series data for rendering workflows.
        Why:
            Avoids repeated dataframe processing by caching prepared payloads.
        Args:
            apply_globals: When True, update module-level globals from payload.
            perf: Optional performance diagnostics accumulator.
            snapshot: Optional snapshot payload for thread-safe access.
        Returns:
            Tuple of DataFingerprint and prepared payload dict.
        Side Effects:
            Updates render cache, module-level globals, and perf counters.
        Exceptions:
            Best-effort guards suppress cache and apply failures.
        """
        if snapshot is not None:
            return self._resolve_prepared_data_context_snapshot(snapshot, perf=perf)
        # Prepared-series cache is keyed by fingerprint to avoid reprocessing
        # large data frames when only UI state changes.
        perf_start = time.perf_counter() if perf is not None else None
        fingerprint = self._build_data_fingerprint()
        cached = self._render_cache.get_prepared(fingerprint)
        if cached is not None:
            if apply_globals:
                try:
                    self._apply_series_payload(cached)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            self._log_render_cache("Render cache: prepared data hit.")
            self._perf_count("cache.render", "prepared.hit")
            if perf_start is not None:
                stages = perf.setdefault("stages", {})
                stages["prepared"] = {
                    "ms": (time.perf_counter() - perf_start) * 1000.0,
                    "cache": "hit",
                }
            return fingerprint, cached

        cycle_temp_name = CYCLE_TEMP_DEFAULT_LABEL
        try:
            cycle_temp_name = (
                self.cycle_temp_column.get()
                if hasattr(self, "cycle_temp_column")
                else CYCLE_TEMP_DEFAULT_LABEL
            )
        except Exception:
            cycle_temp_name = CYCLE_TEMP_DEFAULT_LABEL

        payload = self._build_series_payload(dict(self.columns or {}), cycle_temp_name)
        if not isinstance(payload, dict):
            payload = {}

        payload = dict(payload)
        payload["volume"] = self.v_volume.get()
        payload["a_const"] = self.v_a.get()
        payload["b_const"] = self.v_b.get()
        payload["starting_mass_g"] = self.v_starting_mass.get()
        payload["starting_material_mass_g"] = self.v_starting_mass.get()
        payload["gas_molar_mass"] = self.v_gas_molar_mass.get()
        starting_display_name = self.v_starting_material_display_name.get().strip()
        if not starting_display_name:
            starting_display_name = self.v_product_name.get().strip()
        payload["starting_material_display_name"] = starting_display_name
        payload["starting_material_display_note"] = (
            self.v_starting_material_display_note.get().strip()
        )
        payload["starting_material_name"] = starting_display_name
        payload["product_name"] = (
            starting_display_name or DEFAULT_STARTING_MATERIAL_NAME
        )
        preset_key = self.v_product_preset.get()
        preset_info = PRODUCT_PRESETS.get(preset_key) or {}
        payload["starting_material_formula"] = preset_info.get("formula") or settings.get(
            "starting_material_formula", DEFAULT_STARTING_MATERIAL_FORMULA
        )
        payload["product_formula"] = payload["starting_material_formula"]
        payload["starting_material_mw_g_mol"] = self.v_product_molar_mass.get()
        payload["product_molar_mass"] = self.v_product_molar_mass.get()
        payload["stoich_mol_gas_per_mol_starting"] = self.v_starting_stoich.get()

        self._render_cache.set_prepared(fingerprint, payload)
        if apply_globals:
            try:
                self._apply_series_payload(payload)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        self._log_render_cache("Render cache: prepared data miss.")
        self._perf_count("cache.render", "prepared.miss")
        if perf_start is not None:
            stages = perf.setdefault("stages", {})
            stages["prepared"] = {
                "ms": (time.perf_counter() - perf_start) * 1000.0,
                "cache": "miss",
            }
        return fingerprint, payload

    def _resolve_prepared_data_context_snapshot(
        self, snapshot: Dict[str, Any], *, perf: Optional[Dict[str, Any]] = None
    ) -> Tuple[DataFingerprint, Dict[str, Any]]:
        """Resolve prepared data context from a snapshot.

        Purpose:
            Build or retrieve prepared data without touching Tk state.
        Why:
            Enables background workers to reuse prepared payloads safely.
        Args:
            snapshot: Snapshot dict of UI state and column selections.
            perf: Optional performance diagnostics accumulator.
        Returns:
            Tuple of DataFingerprint and prepared payload dict.
        Side Effects:
            Updates render cache and perf counters.
        Exceptions:
            Best-effort guards suppress cache failures.
        """
        perf_start = time.perf_counter() if perf is not None else None
        fingerprint = self._build_data_fingerprint_from_snapshot(snapshot)
        cached = self._render_cache.get_prepared(fingerprint)
        if cached is not None:
            self._log_render_cache("Render cache: prepared data hit.")
            self._perf_count("cache.render", "prepared.hit")
            if perf_start is not None:
                stages = perf.setdefault("stages", {})
                stages["prepared"] = {
                    "ms": (time.perf_counter() - perf_start) * 1000.0,
                    "cache": "hit",
                }
            return fingerprint, cached

        cycle_temp_name = snapshot.get("cycle_temp_column") or CYCLE_TEMP_DEFAULT_LABEL
        payload = self._build_series_payload(
            dict(snapshot.get("columns_snapshot") or {}),
            cycle_temp_name,
            effective_columns=snapshot.get("effective_columns"),
        )
        if not isinstance(payload, dict):
            payload = {}

        payload = dict(payload)
        payload["volume"] = snapshot.get("volume")
        payload["a_const"] = snapshot.get("a_const")
        payload["b_const"] = snapshot.get("b_const")
        payload["starting_mass_g"] = snapshot.get("starting_mass_g")
        payload["starting_material_mass_g"] = snapshot.get("starting_mass_g")
        payload["gas_molar_mass"] = snapshot.get("gas_molar_mass")
        starting_display_name = snapshot.get("starting_material_display_name") or ""
        starting_display_name = str(starting_display_name).strip()
        payload["starting_material_display_name"] = starting_display_name
        payload["starting_material_display_note"] = snapshot.get(
            "starting_material_display_note"
        )
        payload["starting_material_name"] = starting_display_name
        payload["product_name"] = (
            starting_display_name or DEFAULT_STARTING_MATERIAL_NAME
        )
        preset_key = snapshot.get("product_preset")
        preset_info = PRODUCT_PRESETS.get(preset_key) or {}
        payload["starting_material_formula"] = preset_info.get("formula") or settings.get(
            "starting_material_formula", DEFAULT_STARTING_MATERIAL_FORMULA
        )
        payload["product_formula"] = payload["starting_material_formula"]
        payload["starting_material_mw_g_mol"] = snapshot.get("product_molar_mass")
        payload["product_molar_mass"] = snapshot.get("product_molar_mass")
        payload["stoich_mol_gas_per_mol_starting"] = snapshot.get("starting_stoich")

        self._render_cache.set_prepared(fingerprint, payload)
        self._log_render_cache("Render cache: prepared data miss.")
        self._perf_count("cache.render", "prepared.miss")
        if perf_start is not None:
            stages = perf.setdefault("stages", {})
            stages["prepared"] = {
                "ms": (time.perf_counter() - perf_start) * 1000.0,
                "cache": "miss",
            }
        return fingerprint, payload

    def _cycle_mask_for_data(
        self, data_ctx: Dict[str, Any], *, mask_override: Optional[Any] = None
    ) -> np.ndarray:
        """Perform cycle mask for data.
        Used to keep the workflow logic localized and testable."""
        series_map = data_ctx.get("series") or {}
        series_np = data_ctx.get("series_np") or {}
        series_nan = data_ctx.get("series_nan_mask") or {}
        x_values = series_np.get("x", series_map.get("x"))
        y_values = series_np.get("y1", series_map.get("y1"))
        if x_values is None or y_values is None:
            return np.zeros(0, dtype=bool)
        x_nan = series_nan.get("x")
        y_nan = series_nan.get("y1")
        if x_nan is None:
            try:
                x_nan = np.isnan(x_values)
            except Exception:
                x_nan = pd.isna(x_values)
        if y_nan is None:
            try:
                y_nan = np.isnan(y_values)
            except Exception:
                y_nan = pd.isna(y_values)
        base = (~np.asarray(x_nan, dtype=bool)) & (~np.asarray(y_nan, dtype=bool))
        base = base.values if hasattr(base, "values") else np.asarray(base, dtype=bool)
        if mask_override is None:
            mask_override = getattr(self, "_cycle_mask", None)
        if mask_override is None:
            return base
        try:
            mask_override = np.asarray(mask_override, dtype=bool)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return base
        if mask_override.size != base.size:
            return base
        return base & mask_override

    def _coerce_to_list(self, value, *, cast_int: bool = False) -> List[Any]:
        """Coerce to list.
        Used to force to list into a safe type or range."""
        if value is None:
            return []
        if isinstance(value, np.ndarray):
            if value.ndim == 0:
                scalar = value.item()
                if cast_int:
                    try:
                        return [int(scalar)]
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        return []
                return [scalar]
            return value.tolist()
        if isinstance(value, (list, tuple, set)):
            return list(value)
        if cast_int and isinstance(value, (np.integer, int)) and not isinstance(
            value, bool
        ):
            return [int(value)]
        return []

    def _resolve_cycle_context(
        self,
        data_ctx: Dict[str, Any],
        data_fingerprint: DataFingerprint,
        *,
        perf: Optional[Dict[str, Any]] = None,
        snapshot: Optional[Dict[str, Any]] = None,
    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """Resolve cycle segmentation and overlay context for plots.

        Purpose:
            Build or retrieve cycle overlay data for plotting workflows.
        Why:
            Reuses cached cycle segmentation and metrics to speed rendering.
        Args:
            data_ctx: Prepared series data context.
            data_fingerprint: Cache fingerprint for prepared series.
            perf: Optional performance diagnostics accumulator.
            snapshot: Optional snapshot payload for worker-safe access.
        Returns:
            Tuple of cycle summary dict and overlay payload dict.
        Side Effects:
            Updates render cache and performance counters.
        Exceptions:
            Best-effort guards suppress cache failures.
        """
        series_map = data_ctx.get("series") or {}
        series_np = data_ctx.get("series_np") or {}
        x_values = series_np.get("x", series_map.get("x"))
        y_values = series_np.get("y1", series_map.get("y1"))
        if x_values is None or y_values is None:
            empty_cycle = {
                "peaks_idx": [],
                "troughs_idx": [],
                "cycles": [],
                "total_drop": 0.0,
                "source_mode": "none",
            }
            empty_overlay = {"cycle_overlay": None, "moles_summary": None}
            return empty_cycle, empty_overlay

        perf_start = time.perf_counter() if perf is not None else None

        snapshot_provided = snapshot is not None
        if snapshot is None:
            snapshot = {
                "auto_peaks": set(getattr(self, "_auto_peaks", set())),
                "auto_troughs": set(getattr(self, "_auto_troughs", set())),
                "add_peaks": set(getattr(self, "_add_peaks", set())),
                "add_troughs": set(getattr(self, "_add_troughs", set())),
                "rm_peaks": set(getattr(self, "_rm_peaks", set())),
                "rm_troughs": set(getattr(self, "_rm_troughs", set())),
                "manual_revision": int(getattr(self, "_cycle_manual_revision", 0)),
            }

        # Cycle context is derived from prepared series plus manual overrides; any
        # user edits to peak/trough selection invalidate cached results.
        # Avoid Tk variable access when a snapshot is provided to worker threads.
        allow_ui_reads = not snapshot_provided
        auto_enabled_value = snapshot.get("auto_enabled")
        if auto_enabled_value is None:
            if allow_ui_reads:
                try:
                    auto_enabled_value = bool(self.auto_detect_cycles.get())
                except Exception:
                    auto_enabled_value = bool(
                        settings.get("cycle_auto_detect_enabled", True)
                    )
            else:
                auto_enabled_value = bool(
                    settings.get("cycle_auto_detect_enabled", True)
                )
        auto_enabled = bool(auto_enabled_value)

        manual_overrides = bool(
            snapshot.get("add_peaks")
            or snapshot.get("add_troughs")
            or snapshot.get("rm_peaks")
            or snapshot.get("rm_troughs")
        )
        manual_only = not auto_enabled
        if manual_only:
            source_mode = "manual"
            policy = "manual_only"
        elif manual_overrides:
            source_mode = "mixed"
            policy = "auto_with_manual_overrides"
        else:
            source_mode = "auto"
            policy = "auto_only"

        prom_default = float(settings.get("peak_prominence", 1.0) or 1.0)
        prom_value = snapshot.get("prominence")
        if prom_value is None:
            if allow_ui_reads:
                try:
                    prom_value = float(self.pk_prominence.get())
                except Exception:
                    prom_value = prom_default
            else:
                prom_value = prom_default
        try:
            prom = float(prom_value)
        except Exception:
            prom = prom_default

        dist_default = int(settings.get("peak_distance", 1) or 1)
        dist_value = snapshot.get("distance")
        if dist_value is None:
            if allow_ui_reads:
                try:
                    dist_value = int(self.pk_distance.get())
                except Exception:
                    dist_value = dist_default
            else:
                dist_value = dist_default
        try:
            dist = max(1, int(dist_value))
        except Exception:
            dist = max(1, dist_default)

        wid_default = int(settings.get("peak_width", 1) or 1)
        wid_value = snapshot.get("width")
        if wid_value is None:
            if allow_ui_reads:
                try:
                    wid_value = int(self.pk_width.get())
                except Exception:
                    wid_value = wid_default
            else:
                wid_value = wid_default
        try:
            wid = max(1, int(wid_value))
        except Exception:
            wid = max(1, wid_default)

        min_drop_default = float(settings.get("min_cycle_drop", 0.0) or 0.0)
        min_drop_value = snapshot.get("min_cycle_drop")
        if min_drop_value is None:
            if allow_ui_reads:
                try:
                    min_drop_value = float(self.min_cycle_drop.get())
                except Exception:
                    min_drop_value = min_drop_default
            else:
                min_drop_value = min_drop_default
        try:
            min_cycle_drop = float(min_drop_value)
        except Exception:
            min_cycle_drop = min_drop_default

        ignore_min_drop_value = snapshot.get("ignore_min_drop")
        if ignore_min_drop_value is None:
            if allow_ui_reads:
                ignore_min_drop_value = getattr(
                    self, "_cycle_last_ignore_min_drop", False
                )
            else:
                ignore_min_drop_value = False
        ignore_min_drop = bool(ignore_min_drop_value)

        mask = self._cycle_mask_for_data(
            data_ctx, mask_override=snapshot.get("cycle_mask")
        )
        mask_signature = 0
        if mask.size:
            try:
                mask_signature = hash(mask.tobytes())
            except Exception:
                mask_signature = int(mask.sum())

        moles_signature = (
            _coerce_float(data_ctx.get("volume")),
            _coerce_float(data_ctx.get("a_const")),
            _coerce_float(data_ctx.get("b_const")),
            _coerce_float(data_ctx.get("gas_molar_mass")),
            str(data_ctx.get("product_name") or ""),
            str(data_ctx.get("product_formula") or ""),
            _coerce_float(data_ctx.get("product_molar_mass")),
            _coerce_float(data_ctx.get("starting_mass_g")),
        )
        auto_params = (
            float(prom),
            int(dist),
            int(wid),
            float(min_cycle_drop),
            bool(ignore_min_drop),
            bool(auto_enabled),
        )
        seg_fingerprint = CycleSegFingerprint(
            data_fingerprint=data_fingerprint,
            mode=source_mode,
            auto_params=auto_params,
            manual_revision=int(snapshot.get("manual_revision", 0)),
            mask_signature=mask_signature,
            policy=policy,
        )
        metrics_fingerprint = CycleMetricsFingerprint(
            seg_fingerprint=seg_fingerprint, moles_signature=moles_signature
        )

        seg_cached = self._render_cache.get_cycle_segments(seg_fingerprint)
        metrics_cached = self._render_cache.get_cycle_metrics(metrics_fingerprint)
        cache_state = (
            "hit"
            if seg_cached and metrics_cached
            else ("seg_hit" if seg_cached else "miss")
        )
        if cache_state == "hit":
            self._perf_count("cache.render", "cycle.hit")
        elif cache_state == "seg_hit":
            self._perf_count("cache.render", "cycle.seg_hit")
        else:
            self._perf_count("cache.render", "cycle.miss")

        if not isinstance(seg_cached, dict):
            peak_finder = _get_peak_finder()
            try:
                seg_cached = self._compute_cycle_segmentation(
                    x_values,
                    y_values,
                    mask,
                    prom,
                    dist,
                    wid,
                    min_cycle_drop,
                    auto_enabled,
                    ignore_min_drop,
                    peak_finder,
                    snapshot,
                    manual_only=manual_only,
                )
            except Exception as exc:
                self._log_render_cache(f"Render cache: cycle build failed ({exc}).")
                empty_cycle = {
                    "peaks_idx": [],
                    "troughs_idx": [],
                    "cycles": [],
                    "total_drop": 0.0,
                    "source_mode": source_mode,
                }
                empty_overlay = {"cycle_overlay": None, "moles_summary": None}
                return empty_cycle, empty_overlay
            self._render_cache.set_cycle_segments(seg_fingerprint, seg_cached)
            cache_state = "miss"

        if not isinstance(metrics_cached, dict):
            try:
                z_series = data_ctx.get("cycle_temp_series")
                z_values = (
                    np.asarray(z_series, dtype=float) if z_series is not None else None
                )
            except Exception:
                z_values = None
            metrics_cached = self._compute_cycle_metrics_from_segmentation(
                seg_cached,
                x_values,
                y_values,
                z_values,
                prom,
                dist,
                wid,
                min_cycle_drop,
                ignore_min_drop,
                data_ctx=data_ctx,
            )
            self._render_cache.set_cycle_metrics(metrics_fingerprint, metrics_cached)

        peak_indices = self._coerce_to_list(seg_cached.get("plot_peaks"), cast_int=True)
        trough_indices = self._coerce_to_list(
            seg_cached.get("plot_troughs"), cast_int=True
        )
        try:
            xv = np.asarray(x_values, dtype=float)
            yv = np.asarray(y_values, dtype=float)
        except Exception:
            xv = np.asarray(x_values)
            yv = np.asarray(y_values)

        def _points_for(indices: Sequence[Any]) -> List[Tuple[float, float]]:
            """Perform points for.
            Used to keep the workflow logic localized and testable."""
            points: List[Tuple[float, float]] = []
            # Iterate over indices to apply the per-item logic.
            for idx in indices:
                try:
                    i = int(idx)
                except Exception:
                    continue
                if i < 0 or i >= len(xv):
                    continue
                try:
                    x_val = float(xv[i])
                    y_val = float(yv[i])
                except Exception:
                    continue
                if not (math.isfinite(x_val) and math.isfinite(y_val)):
                    continue
                points.append((x_val, y_val))
            return points

        peak_points = _points_for(peak_indices)
        trough_points = _points_for(trough_indices)

        payload = {
            "cycle_transfer": self._coerce_to_list(metrics_cached.get("cycle_transfer")),
            "total_moles_ideal": metrics_cached.get("total_moles_ideal"),
            "total_moles_vdw": metrics_cached.get("total_moles_vdw"),
            "vdw_used": metrics_cached.get("vdw_used"),
            "reagent_summary": metrics_cached.get("reagent_summary"),
            "gas_molar_mass": metrics_cached.get("gas_molar_mass"),
        }
        moles_lines = self._cycle_moles_legend_lines(payload, data_ctx=data_ctx)
        cycle_overlay = {
            "peaks_idx": list(peak_indices),
            "troughs_idx": list(trough_indices),
            "peak_points": peak_points,
            "trough_points": trough_points,
            "cycles": self._coerce_to_list(seg_cached.get("cycles")),
            "total_drop": float(seg_cached.get("total_drop", 0.0) or 0.0),
            "payload": payload,
            "moles_lines": moles_lines,
        }
        cycle_ctx = {
            "peaks_idx": list(peak_indices),
            "troughs_idx": list(trough_indices),
            "cycles": self._coerce_to_list(seg_cached.get("cycles")),
            "total_drop": float(seg_cached.get("total_drop", 0.0) or 0.0),
            "auto_detection_used": bool(seg_cached.get("auto_detection_used")),
            "source_mode": source_mode,
        }
        overlay_ctx = {"cycle_overlay": cycle_overlay, "moles_summary": moles_lines}

        if cache_state == "hit":
            self._log_render_cache("Render cache: cycle context hit.")
        elif cache_state == "seg_hit":
            self._log_render_cache("Render cache: cycle metrics miss.")
        else:
            self._log_render_cache("Render cache: cycle context miss.")
        if perf_start is not None and perf is not None:
            stages = perf.setdefault("stages", {})
            stages["cycle"] = {
                "ms": (time.perf_counter() - perf_start) * 1000.0,
                "cache": cache_state,
            }
        return cycle_ctx, overlay_ctx

    def _prime_cycle_markers_from_cache(self):
        """Perform prime cycle markers from cache.
        Used to keep the workflow logic localized and testable."""
        cache = getattr(self, "_cached_cycle_markers", None)
        if not cache:
            self._preloaded_cycle_markers = None
            self._markers_seeded_from_cache = False
            return

        try:
            current_path = os.path.abspath(self.file_path) if self.file_path else ""
        except Exception:
            current_path = str(self.file_path or "")

        cache_path = cache.get("file", "")
        if current_path != cache_path:
            self._preloaded_cycle_markers = None
            self._markers_seeded_from_cache = False
            return

        if self.multi_sheet_enabled:
            cached_sheets = cache.get("sheets")
            if (
                not isinstance(cached_sheets, list)
                or cached_sheets != self.selected_sheets
            ):
                self._preloaded_cycle_markers = None
                self._markers_seeded_from_cache = False
                return
        else:
            if (self.selected_sheet.get() or "") != cache.get("sheet", ""):
                self._preloaded_cycle_markers = None
                self._markers_seeded_from_cache = False
                return

        columns = cache.get("columns") or {}
        if self.columns.get("x") != columns.get("x") or self.columns.get(
            "y1"
        ) != columns.get("y1"):
            self._preloaded_cycle_markers = None
            self._markers_seeded_from_cache = False
            return

        try:
            current_len = len(globals().get("x") or [])
        except Exception:
            current_len = 0

        if int(current_len) != int(cache.get("data_len", -1)):
            self._preloaded_cycle_markers = None
            self._markers_seeded_from_cache = False
            return

        self._preloaded_cycle_markers = {
            "peaks": set(int(p) for p in cache.get("peaks", [])),
            "troughs": set(int(t) for t in cache.get("troughs", [])),
        }
        self._markers_seeded_from_cache = bool(
            self._preloaded_cycle_markers["peaks"]
            or self._preloaded_cycle_markers["troughs"]
        )

    @staticmethod
    def _round_axis_value(value):
        """Perform round axis value.
        Used to keep the workflow logic localized and testable."""
        try:
            return round(float(value), 2)
        except (TypeError, ValueError):
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return value

    def _get_axis_auto_range_flags(self) -> Dict[str, bool]:
        """Return axis auto range flags.
        Used to retrieve axis auto range flags for downstream logic."""
        flags = {
            "time": bool(self.axis_auto_time.get()),
            "pressure": bool(self.axis_auto_pressure.get()),
            "temperature": bool(self.axis_auto_temp.get()),
            "derivative": bool(self.axis_auto_deriv.get()),
        }
        return _sanitize_axis_auto_range_settings(flags)

    def _compute_axis_ranges_from_current_selection(self):
        """Compute axis ranges from current selection.
        Used to derive axis ranges from current selection for analysis or plotting."""

        if self.df is None or not self.columns:

            return None

        fallback = {
            "x_min": float(self.min_time.get()),
            "x_max": float(self.max_time.get()),
            "y_min": float(self.min_y.get()),
            "y_max": float(self.max_y.get()),
            "twin_y_min": float(self.twin_y_min.get()),
            "twin_y_max": float(self.twin_y_max.get()),
            "deriv_y_min": float(self.deriv_y_min.get()),
            "deriv_y_max": float(self.deriv_y_max.get()),
        }

        return self._compute_axis_ranges_for_snapshot(
            dict(self._get_effective_columns()),
            float(self.axis_pad_pct.get()),
            fallback,
            auto_flags=self._get_axis_auto_range_flags(),
        )

    def _compute_axis_ranges_for_snapshot(
        self,
        columns_snapshot,
        axis_pad_pct,
        fallback,
        *,
        series_map=None,
        auto_flags=None,
        df_snapshot=None,
    ):
        """Compute auto-axis limits for a data snapshot using current preferences.

        Purpose:
            Derive time/pressure/temperature/derivative bounds from snapshot data.
        Why:
            Refresh Axis Ranges must honor auto-range flags and span padding while
            falling back to current manual values when data is missing/invalid.
        Args:
            columns_snapshot: Mapping of logical channels (`x`, `y1`, etc.) to
                selected dataframe column names.
            axis_pad_pct: Padding percentage applied to each computed axis span.
            fallback: Dict of fallback min/max values for all supported axes.
            series_map: Optional precomputed series overrides by logical key.
            auto_flags: Optional per-axis auto-enable flags.
            df_snapshot: Optional dataframe override; defaults to `self.df`.
        Returns:
            Dict[str, float] | None: Computed limits or `None` when no dataframe exists.
        Side Effects:
            None; this method only computes and returns values.
        Exceptions:
            Internal per-axis failures fall back to provided values instead of raising.
        """

        data_frame = df_snapshot if df_snapshot is not None else self.df
        if data_frame is None:

            return None

        pad_fraction = max(float(axis_pad_pct) / 100.0, 0.0)
        flags = (
            _sanitize_axis_auto_range_settings(auto_flags)
            if auto_flags is not None
            else dict(DEFAULT_AXIS_AUTO_RANGE)
        )

        def _enabled(key):
            """Perform enabled.
            Used to keep the workflow logic localized and testable."""
            return bool(flags.get(key, True))

        def _series(key, dropna=False):
            """Perform series.
            Used to keep the workflow logic localized and testable."""

            source = None

            if series_map is not None:
                if key in series_map:
                    source = series_map.get(key)
                    if source is None:
                        return None

            if source is None:

                if (
                    self.multi_sheet_enabled
                    and self.selected_sheets
                    and isinstance(self.sheet_dfs, dict)
                    and self.sheet_dfs
                ):
                    source = self._build_stitched_series_for_var(
                        key, list(self.selected_sheets)
                    )

                if source is None:
                    colname = columns_snapshot.get(key) if columns_snapshot else None

                    if not colname or colname == "None":

                        return None

                    try:

                        source = self._get_numeric_series(colname)

                    except Exception:

                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        return None

            if source is None:

                return None

            if dropna:

                return source.dropna()

            return source

        def _chunked_nanminmax(values):
            """Perform chunked nanminmax.
            Used to keep the workflow logic localized and testable."""
            if values.size == 0:
                raise ValueError("empty array")

            chunk = max(1, min(values.size, 250_000))
            found = False
            min_val = math.inf
            max_val = -math.inf

            # Iterate over the configured range to apply the per-item logic.
            for start in range(0, values.size, chunk):
                sub = values[start : start + chunk]
                if sub.size == 0:
                    continue
                try:
                    sub_min = float(np.nanmin(sub))
                    sub_max = float(np.nanmax(sub))
                except ValueError:
                    # All-NaN slice; skip.
                    continue

                if math.isfinite(sub_min):
                    min_val = min(min_val, sub_min)
                    found = True
                if math.isfinite(sub_max):
                    max_val = max(max_val, sub_max)
                    found = True

            if not found:
                raise ValueError("no finite values")

            return min_val, max_val

        def _series_extent(series):
            """Perform series extent.
            Used to keep the workflow logic localized and testable."""
            values = series.to_numpy(dtype=float, copy=False)
            return _chunked_nanminmax(values)

        result = {}

        if _enabled("time"):
            x_series = _series("x", dropna=True)

            if x_series is not None and not getattr(x_series, "empty", False):

                try:

                    x_min_data, x_max_data = _series_extent(x_series)
                    x_span = max(x_max_data - x_min_data, 0.0)
                    # Use the same percent-based span padding rule as Y-axes.
                    x_pad = max(pad_fraction * x_span, 0.02 if x_span == 0 else 0.0)
                    result["x_min"] = self._round_axis_value(x_min_data - x_pad)
                    result["x_max"] = self._round_axis_value(x_max_data + x_pad)

                except Exception:

                    result["x_min"] = fallback["x_min"]

                    result["x_max"] = fallback["x_max"]

            else:

                result["x_min"] = fallback["x_min"]

                result["x_max"] = fallback["x_max"]
        else:
            result["x_min"] = fallback["x_min"]
            result["x_max"] = fallback["x_max"]

        if _enabled("pressure"):

            y_candidates = []

            # Iterate over ("y1", "y3") to apply the per-item logic.
            for key in ("y1", "y3"):

                series = _series(key, dropna=True)

                if series is not None and not getattr(series, "empty", False):

                    try:

                        ymin, ymax = _series_extent(series)

                        y_candidates.append(ymin)

                        y_candidates.append(ymax)

                    except Exception:

                        continue

            if y_candidates:

                y_min_data = float(np.nanmin(y_candidates))

                y_max_data = float(np.nanmax(y_candidates))

                span = max(y_max_data - y_min_data, 0.0)

                pad = max(pad_fraction * span, 1.0 if span == 0 else 0.0)

                result["y_min"] = self._round_axis_value(y_min_data - pad)

                result["y_max"] = self._round_axis_value(y_max_data + pad)

            else:

                result["y_min"] = fallback["y_min"]

                result["y_max"] = fallback["y_max"]
        else:

            result["y_min"] = fallback["y_min"]

            result["y_max"] = fallback["y_max"]

        if _enabled("temperature"):

            t_candidates = []

            # Iterate over ("z", "z2") to apply the per-item logic.
            for key in ("z", "z2"):

                series = _series(key, dropna=True)

                if series is not None and not getattr(series, "empty", False):

                    try:

                        tmin, tmax = _series_extent(series)

                        t_candidates.append(tmin)

                        t_candidates.append(tmax)

                    except Exception:

                        continue

            if t_candidates:

                t_min_data = float(np.nanmin(t_candidates))

                t_max_data = float(np.nanmax(t_candidates))

                t_span = max(t_max_data - t_min_data, 0.0)

                t_pad = max(pad_fraction * t_span, 1.0 if t_span == 0 else 0.0)

                result["twin_y_min"] = self._round_axis_value(t_min_data - t_pad)

                result["twin_y_max"] = self._round_axis_value(t_max_data + t_pad)

            else:

                result["twin_y_min"] = fallback["twin_y_min"]

                result["twin_y_max"] = fallback["twin_y_max"]
        else:

            result["twin_y_min"] = fallback["twin_y_min"]

            result["twin_y_max"] = fallback["twin_y_max"]

        if _enabled("derivative"):

            deriv_series = _series("y2", dropna=True)

            if deriv_series is not None and not getattr(deriv_series, "empty", False):

                try:

                    d_min_data, d_max_data = _series_extent(deriv_series)

                    d_span = max(d_max_data - d_min_data, 0.0)

                    d_pad = max(pad_fraction * d_span, 1.0 if d_span == 0 else 0.0)

                    result["deriv_y_min"] = self._round_axis_value(d_min_data - d_pad)

                    result["deriv_y_max"] = self._round_axis_value(d_max_data + d_pad)

                except Exception:

                    result["deriv_y_min"] = fallback["deriv_y_min"]

                    result["deriv_y_max"] = fallback["deriv_y_max"]

            else:

                result["deriv_y_min"] = fallback["deriv_y_min"]

                result["deriv_y_max"] = fallback["deriv_y_max"]
        else:

            result["deriv_y_min"] = fallback["deriv_y_min"]

            result["deriv_y_max"] = fallback["deriv_y_max"]

        return result

    def _refresh_axis_ranges(self):
        """Refresh axis ranges.
        Used to sync axis ranges with current settings."""

        flags = self._get_axis_auto_range_flags()
        if not any(flags.values()):
            messagebox.showinfo(
                "Axis Ranges Locked",
                "Automatic range updates are disabled for all axes in Preferences.",
            )
            return

        rng = self._compute_axis_ranges_from_current_selection()

        if not rng:

            messagebox.showerror("No Data", "Load data and select columns first.")

            return

        if flags.get("time", True):
            self.min_time.set(rng["x_min"])
            self.max_time.set(rng["x_max"])

        if flags.get("pressure", True):
            self.min_y.set(rng["y_min"])
            self.max_y.set(rng["y_max"])

        if flags.get("temperature", True):
            self.twin_y_min.set(rng["twin_y_min"])
            self.twin_y_max.set(rng["twin_y_max"])

        if flags.get("derivative", True):
            self.deriv_y_min.set(rng["deriv_y_min"])
            self.deriv_y_max.set(rng["deriv_y_max"])

        # Save immediately so settings.json stays in sync

        self.save_settings()

    def _collect_plot_args(self):
        """Collect plot args.
        Used to gather plot args into a structured payload."""

        min_time = self._safe_get_var(self.min_time, float)
        max_time = self._safe_get_var(self.max_time, float)
        min_y = self._safe_get_var(self.min_y, float)
        max_y = self._safe_get_var(self.max_y, float)
        twin_y_min = self._safe_get_var(self.twin_y_min, float)
        twin_y_max = self._safe_get_var(self.twin_y_max, float)
        deriv_y_min = self._safe_get_var(self.deriv_y_min, float)
        deriv_y_max = self._safe_get_var(self.deriv_y_max, float)
        xmaj_tick = self._safe_get_var(self.xmaj_tick, float)
        xmin_tick = self._safe_get_var(self.xmin_tick, float)
        ymaj_tick = self._safe_get_var(self.ymaj_tick, float)
        ymin_tick = self._safe_get_var(self.ymin_tick, float)
        temp_maj_tick = self._safe_get_var(self.temp_maj_tick, float)
        temp_min_tick = self._safe_get_var(self.temp_min_tick, float)
        deriv_maj_tick = self._safe_get_var(self.deriv_maj_tick, float)
        deriv_min_tick = self._safe_get_var(self.deriv_min_tick, float)
        min_cycle_drop = self._safe_get_var(self.min_cycle_drop, float)
        pk_prominence = self._safe_get_var(self.pk_prominence, float)
        pk_distance = self._safe_get_var(self.pk_distance, int)
        pk_width = self._safe_get_var(self.pk_width, int)
        show_cycle_markers_on_core = bool(self.show_cycle_markers_on_core.get())
        show_cycle_legend_on_core = bool(self.show_cycle_legend_on_core.get())
        include_moles_core_legend = bool(self.include_moles_core_legend.get())

        self._last_plot_args = (
            min_time,
            max_time,
            min_y,
            max_y,
            twin_y_min,
            twin_y_max,
            deriv_y_min,
            deriv_y_max,
            self.auto_time_ticks.get(),
            self.auto_y_ticks.get(),
            self.auto_temp_ticks.get(),
            self.auto_deriv_ticks.get(),
            self.title_text.get(),
            self.suptitle_text.get(),
            xmaj_tick,
            xmin_tick,
            ymaj_tick,
            ymin_tick,
            temp_maj_tick,
            temp_min_tick,
            deriv_maj_tick,
            deriv_min_tick,
            self.enable_temp_axis.get(),
            self.enable_deriv_axis.get(),
            min_cycle_drop,
            pk_prominence,
            pk_distance,
            pk_width,
            show_cycle_markers_on_core,
            show_cycle_legend_on_core,
            include_moles_core_legend,
        )

        return (
            min_time,
            max_time,
            min_y,
            max_y,
            twin_y_min,
            twin_y_max,
            deriv_y_min,
            deriv_y_max,
            self.auto_time_ticks.get(),
            self.auto_y_ticks.get(),
            self.auto_temp_ticks.get(),
            self.auto_deriv_ticks.get(),
            self.title_text.get(),
            self.suptitle_text.get(),
            xmaj_tick,
            xmin_tick,
            ymaj_tick,
            ymin_tick,
            temp_maj_tick,
            temp_min_tick,
            deriv_maj_tick,
            deriv_min_tick,
            self.enable_temp_axis.get(),
            self.enable_deriv_axis.get(),
            min_cycle_drop,
            pk_prominence,
            pk_distance,
            pk_width,
            show_cycle_markers_on_core,
            show_cycle_legend_on_core,
            include_moles_core_legend,
        )

    def _override_plot_args_gates(
        self, args: Tuple[Any, ...], gates_ctx: Dict[str, Any]
    ) -> Tuple[Any, ...]:
        """Perform override plot args gates.
        Used to keep the workflow logic localized and testable."""
        if not args:
            return args
        args_list = list(args)
        if len(args_list) >= 3:
            args_list[-3] = bool(
                gates_ctx.get("show_cycle_markers", args_list[-3])
            )
            args_list[-2] = bool(
                gates_ctx.get("show_cycle_legend", args_list[-2])
            )
            args_list[-1] = bool(gates_ctx.get("include_moles", args_list[-1]))
        return tuple(args_list)

    def _override_plot_args_title(self, args: Tuple[Any, ...]) -> Tuple[Any, ...]:
        """Perform override plot args title.
        Used to keep the workflow logic localized and testable."""
        if not args or len(args) < 14:
            return args
        args_list = list(args)
        manual_title = str(args_list[12] or "")
        args_list[12] = self._resolve_effective_title(manual_title)
        return tuple(args_list)

    def render_plot(
        self,
        plot_kind: str,
        *,
        target: str = "display",
        mode: Optional[str] = None,
        plot_id: Optional[str] = None,
        fig_size: Optional[Tuple[float, float]] = None,
    ) -> Optional[Any]:
        """Render plot.
        Used to draw plot for preview or export workflows."""
        target_value = (target or "display").strip().lower()
        mode_value = (mode or ("export" if target_value == "export" else "display"))
        plot_id = plot_id or self._plot_key_to_plot_id(plot_kind)

        plot_kind_value = (plot_kind or "").strip().lower()
        perf_run = None
        if plot_kind_value in {"fig_combined", "combined"} and bool(
            self._perf_diag_enabled_var.get()
        ):
            perf_run = {
                "plot_kind": plot_kind_value,
                "target": target_value,
                "timestamp": datetime.now().isoformat(timespec="seconds"),
                "stages": {},
            }

        data_fingerprint, data_ctx = self._resolve_prepared_data_context(
            apply_globals=True, perf=perf_run
        )

        gates_ctx = {
            "show_cycle_markers": bool(
                self.show_cycle_markers_on_core.get()
                if hasattr(self, "show_cycle_markers_on_core")
                else settings.get("show_cycle_markers_on_core_plots", False)
            ),
            "show_cycle_legend": bool(
                self.show_cycle_legend_on_core.get()
                if hasattr(self, "show_cycle_legend_on_core")
                else settings.get("show_cycle_legend_on_core_plots", False)
            ),
            "include_moles": bool(
                self.include_moles_core_legend.get()
                if hasattr(self, "include_moles_core_legend")
                else settings.get("include_moles_in_core_plot_legend", False)
            ),
        }

        cycle_ctx: Dict[str, Any] = {}
        overlay_ctx: Dict[str, Any] = {}
        cycle_needed = True
        if plot_kind_value in {"fig_combined", "combined"}:
            cycle_needed = bool(
                gates_ctx.get("show_cycle_markers")
                or gates_ctx.get("show_cycle_legend")
                or gates_ctx.get("include_moles")
            )
        if cycle_needed:
            cycle_ctx, overlay_ctx = self._resolve_cycle_context(
                data_ctx, data_fingerprint, perf=perf_run
            )
        else:
            cycle_ctx = {
                "peaks_idx": [],
                "troughs_idx": [],
                "cycles": [],
                "total_drop": 0.0,
                "source_mode": "none",
            }
            overlay_ctx = {"cycle_overlay": None, "moles_summary": None}
            if perf_run is not None:
                stages = perf_run.setdefault("stages", {})
                stages["cycle"] = {"ms": 0.0, "cache": "skipped"}

        overlay_ctx = dict(overlay_ctx or {})
        cycle_overlay = overlay_ctx.get("cycle_overlay")
        overlay_ctx["markers"] = (
            cycle_overlay if gates_ctx.get("show_cycle_markers") else None
        )
        overlay_ctx["cycle_legend"] = (
            cycle_overlay if gates_ctx.get("show_cycle_legend") else None
        )
        overlay_ctx["moles_summary"] = (
            overlay_ctx.get("moles_summary")
            if gates_ctx.get("include_moles")
            else None
        )

        style_ctx = {
            "scatter_config": self._gather_scatter_settings(),
            "scatter_series_configs": self._gather_series_scatter_settings(),
            "font_family": settings.get("font_family"),
            "core_legend_fontsize": settings.get("core_legend_fontsize"),
            "core_cycle_legend_fontsize": settings.get("core_cycle_legend_fontsize"),
            "core_plot_render_profiles": copy.deepcopy(_get_core_plot_render_profiles()),
        }
        layout_ctx = {
            "plot_id": plot_id,
            "profile": _get_layout_profile(plot_id) if plot_id else None,
            "target": target_value,
        }
        plot_elements_ctx = {
            "plot_id": plot_id,
            "elements": settings.get("plot_elements", {}),
        }

        render_ctx = RenderContext(
            data_ctx=data_ctx,
            cycle_ctx=cycle_ctx,
            overlay_ctx=overlay_ctx,
            gates_ctx=gates_ctx,
            style_ctx=style_ctx,
            layout_ctx=layout_ctx,
            plot_elements_ctx=plot_elements_ctx,
        )

        args = self._collect_plot_args()
        args = self._override_plot_args_gates(args, gates_ctx)
        args = self._override_plot_args_title(args)

        if plot_kind_value in {"fig1", "fig2", "fig_peaks", "core"}:
            figs = main_plotting_function(
                *args, fig_size=fig_size, render_ctx=render_ctx
            )
            if not isinstance(figs, dict):
                return None
            if plot_kind_value == "core":
                return figs
            return figs.get(plot_kind_value)

        if plot_kind_value in {"fig_combined", "combined"}:
            if fig_size is None:
                if mode_value == "export":
                    fig_size = (11.0, 8.5)
                else:
                    fig_size = self._compute_target_figsize_inches()
            fig = self._build_combined_triple_axis_from_state(
                args=args,
                fig_size=fig_size,
                mode=mode_value,
                reuse=(target_value == "display" and mode_value == "display"),
                render_ctx=render_ctx,
                perf_run=perf_run,
            )
            if perf_run is not None:
                self._record_performance_run(perf_run)
            return fig

        return None

    def _capture_plot_render_snapshot(
        self,
        *,
        fig_size: Optional[Tuple[float, float]],
        plot_id: str,
        target: str,
    ) -> Dict[str, Any]:
        """Capture a plot render snapshot for worker-safe computation.

        Purpose:
            Collect UI state needed for background plot computation.
        Why:
            Worker threads must not touch Tk variables directly.
        Inputs:
            fig_size: Optional figure size in inches for the render target.
            plot_id: Plot identifier used for layout/profile context.
            target: Render target (e.g., "display", "export").
        Outputs:
            Snapshot dict with data, layout, and style context.
        Side Effects:
            Reads current UI state to build a deterministic snapshot.
        Exceptions:
            Errors are caught to avoid interrupting the UI.
        """
        try:
            file_path = os.path.abspath(self.file_path) if self.file_path else ""
        except Exception:
            file_path = str(self.file_path or "")
        if self.multi_sheet_enabled:
            sheet_key = tuple(str(name) for name in (self.selected_sheets or []))
        else:
            try:
                sheet_key = (str(self.selected_sheet.get() or ""),)
            except Exception:
                sheet_key = ("",)

        cycle_temp_column = CYCLE_TEMP_DEFAULT_LABEL
        try:
            cycle_temp_column = (
                self.cycle_temp_column.get()
                if hasattr(self, "cycle_temp_column")
                else CYCLE_TEMP_DEFAULT_LABEL
            )
        except Exception:
            cycle_temp_column = CYCLE_TEMP_DEFAULT_LABEL

        try:
            starting_display_name = self.v_starting_material_display_name.get().strip()
        except Exception:
            starting_display_name = ""
        if not starting_display_name:
            try:
                starting_display_name = self.v_product_name.get().strip()
            except Exception:
                starting_display_name = ""

        gates_ctx = {
            "show_cycle_markers": bool(
                self.show_cycle_markers_on_core.get()
                if hasattr(self, "show_cycle_markers_on_core")
                else settings.get("show_cycle_markers_on_core_plots", False)
            ),
            "show_cycle_legend": bool(
                self.show_cycle_legend_on_core.get()
                if hasattr(self, "show_cycle_legend_on_core")
                else settings.get("show_cycle_legend_on_core_plots", False)
            ),
            "include_moles": bool(
                self.include_moles_core_legend.get()
                if hasattr(self, "include_moles_core_legend")
                else settings.get("include_moles_in_core_plot_legend", False)
            ),
        }

        args = self._collect_plot_args()
        args = self._override_plot_args_gates(args, gates_ctx)
        args = self._override_plot_args_title(args)

        snapshot = {
            "plot_id": plot_id,
            "target": target,
            "fig_size": fig_size,
            "file_path": file_path,
            "sheet_key": sheet_key,
            "columns_snapshot": dict(self.columns or {}),
            "effective_columns": self._get_effective_columns(),
            "cycle_temp_column": str(cycle_temp_column or ""),
            "elapsed_unit": self._elapsed_unit_label(),
            "prep_signature": self._data_prep_signature(),
            "multi_sheet": bool(self.multi_sheet_enabled),
            "volume": self.v_volume.get(),
            "a_const": self.v_a.get(),
            "b_const": self.v_b.get(),
            "starting_mass_g": self.v_starting_mass.get(),
            "gas_molar_mass": self.v_gas_molar_mass.get(),
            "starting_material_display_name": starting_display_name,
            "starting_material_display_note": self.v_starting_material_display_note.get(),
            "product_preset": self.v_product_preset.get(),
            "product_molar_mass": self.v_product_molar_mass.get(),
            "starting_stoich": self.v_starting_stoich.get(),
            "auto_enabled": bool(self.auto_detect_cycles.get())
            if hasattr(self, "auto_detect_cycles")
            else False,
            "prominence": float(self.pk_prominence.get())
            if hasattr(self, "pk_prominence")
            else 1.0,
            "distance": max(1, int(self.pk_distance.get()))
            if hasattr(self, "pk_distance")
            else 1,
            "width": max(1, int(self.pk_width.get()))
            if hasattr(self, "pk_width")
            else 1,
            "min_cycle_drop": float(self.min_cycle_drop.get())
            if hasattr(self, "min_cycle_drop")
            else 0.0,
            "ignore_min_drop": bool(getattr(self, "_cycle_last_ignore_min_drop", False)),
            "manual_revision": int(getattr(self, "_cycle_manual_revision", 0)),
            "auto_peaks": set(getattr(self, "_auto_peaks", set())),
            "auto_troughs": set(getattr(self, "_auto_troughs", set())),
            "add_peaks": set(getattr(self, "_add_peaks", set())),
            "add_troughs": set(getattr(self, "_add_troughs", set())),
            "rm_peaks": set(getattr(self, "_rm_peaks", set())),
            "rm_troughs": set(getattr(self, "_rm_troughs", set())),
            "gates_ctx": gates_ctx,
            "style_ctx": {
                "scatter_config": self._gather_scatter_settings(),
                "scatter_series_configs": self._gather_series_scatter_settings(),
                "font_family": settings.get("font_family"),
                "core_legend_fontsize": settings.get("core_legend_fontsize"),
                "core_cycle_legend_fontsize": settings.get("core_cycle_legend_fontsize"),
                "core_plot_render_profiles": copy.deepcopy(
                    _get_core_plot_render_profiles()
                ),
            },
            "layout_ctx": {
                "plot_id": plot_id,
                "profile": _get_layout_profile(plot_id) if plot_id else None,
                "target": target,
            },
            "plot_elements_ctx": {
                "plot_id": plot_id,
                "elements": settings.get("plot_elements", {}),
            },
            "cycle_overlays_enabled": bool(
                gates_ctx.get("show_cycle_markers")
                or gates_ctx.get("show_cycle_legend")
                or gates_ctx.get("include_moles")
            ),
            "args": args,
            "perf_enabled": bool(self._perf_diag_enabled_var.get()),
        }

        mask_override = getattr(self, "_cycle_mask", None)
        if mask_override is not None:
            try:
                snapshot["cycle_mask"] = np.asarray(mask_override, dtype=bool).copy()
            except Exception:
                snapshot["cycle_mask"] = mask_override
        else:
            snapshot["cycle_mask"] = None

        return snapshot

    def _capture_combined_render_snapshot(
        self,
        *,
        fig_size: Optional[Tuple[float, float]],
        plot_id: str,
        target: str,
    ) -> Dict[str, Any]:
        """Capture combined render snapshot.

        Purpose:
            Provide a combined-plot snapshot for background computation.
        Why:
            Combined renders need a worker-safe snapshot of UI state.
        Inputs:
            fig_size: Optional figure size in inches for the render target.
            plot_id: Combined plot identifier for layout context.
            target: Render target (e.g., "display", "export").
        Outputs:
            Snapshot dict suitable for background computation.
        Side Effects:
            Delegates to the generic snapshot helper.
        Exceptions:
            Errors are caught to avoid interrupting the UI.
        """
        return self._capture_plot_render_snapshot(
            fig_size=fig_size,
            plot_id=plot_id,
            target=target,
        )

    def _compute_combined_plot_data(self, snapshot: Dict[str, Any]) -> RenderPacket:
        """Compute combined plot data for UI-thread rendering.

        Purpose:
            Prepare a combined-plot render packet in a worker-safe step.
        Why:
            Heavy data prep must not block the UI thread.
        Inputs:
            snapshot: Snapshot of UI state and data selections.
        Outputs:
            RenderPacket with prepared render context and args.
        Side Effects:
            Updates render cache entries and performance counters.
        Exceptions:
            Errors propagate to the worker handler for reporting.
        """
        perf_run = None
        if snapshot.get("perf_enabled"):
            perf_run = {
                "plot_kind": "fig_combined",
                "target": snapshot.get("target", "display"),
                "timestamp": datetime.now().isoformat(timespec="seconds"),
                "stages": {},
            }

        data_fingerprint, data_ctx = self._resolve_prepared_data_context(
            apply_globals=False, perf=perf_run, snapshot=snapshot
        )

        if snapshot.get("cycle_overlays_enabled"):
            cycle_ctx, overlay_ctx = self._resolve_cycle_context(
                data_ctx, data_fingerprint, perf=perf_run, snapshot=snapshot
            )
        else:
            cycle_ctx = {
                "peaks_idx": [],
                "troughs_idx": [],
                "cycles": [],
                "total_drop": 0.0,
                "source_mode": "none",
            }
            overlay_ctx = {"cycle_overlay": None, "moles_summary": None}
            if perf_run is not None:
                stages = perf_run.setdefault("stages", {})
                stages["cycle"] = {"ms": 0.0, "cache": "skipped"}

        overlay_ctx = dict(overlay_ctx or {})
        gates_ctx = snapshot.get("gates_ctx") or {}
        cycle_overlay = overlay_ctx.get("cycle_overlay")
        overlay_ctx["markers"] = (
            cycle_overlay if gates_ctx.get("show_cycle_markers") else None
        )
        overlay_ctx["cycle_legend"] = (
            cycle_overlay if gates_ctx.get("show_cycle_legend") else None
        )
        overlay_ctx["moles_summary"] = (
            overlay_ctx.get("moles_summary")
            if gates_ctx.get("include_moles")
            else None
        )

        render_ctx = RenderContext(
            data_ctx=data_ctx,
            cycle_ctx=cycle_ctx,
            overlay_ctx=overlay_ctx,
            gates_ctx=gates_ctx,
            style_ctx=snapshot.get("style_ctx") or {},
            layout_ctx=snapshot.get("layout_ctx") or {},
            plot_elements_ctx=snapshot.get("plot_elements_ctx") or {},
        )

        return RenderPacket(
            render_ctx=render_ctx,
            data_fingerprint=data_fingerprint,
            args=tuple(snapshot.get("args") or ()),
            fig_size=snapshot.get("fig_size"),
            plot_id=snapshot.get("plot_id"),
            target=snapshot.get("target", "display"),
            perf=perf_run,
        )

    def _compute_core_plot_data(self, snapshot: Dict[str, Any]) -> RenderPacket:
        """Compute core plot data for UI-thread rendering.

        Purpose:
            Prepare the core plot render context in a worker-safe step.
        Why:
            Core plot generation should keep heavy data prep off the UI thread.
        Inputs:
            snapshot: Snapshot of UI state and data selections.
        Outputs:
            RenderPacket containing the render context and plot arguments.
        Side Effects:
            Updates render cache entries and performance counters.
        Exceptions:
            Errors propagate to the worker handler for reporting.
        """
        data_fingerprint, data_ctx = self._resolve_prepared_data_context(
            apply_globals=False, perf=None, snapshot=snapshot
        )

        gates_ctx = snapshot.get("gates_ctx") or {}
        cycle_ctx, overlay_ctx = self._resolve_cycle_context(
            data_ctx, data_fingerprint, perf=None, snapshot=snapshot
        )
        overlay_ctx = dict(overlay_ctx or {})
        cycle_overlay = overlay_ctx.get("cycle_overlay")
        overlay_ctx["markers"] = (
            cycle_overlay if gates_ctx.get("show_cycle_markers") else None
        )
        overlay_ctx["cycle_legend"] = (
            cycle_overlay if gates_ctx.get("show_cycle_legend") else None
        )
        overlay_ctx["moles_summary"] = (
            overlay_ctx.get("moles_summary")
            if gates_ctx.get("include_moles")
            else None
        )

        render_ctx = RenderContext(
            data_ctx=data_ctx,
            cycle_ctx=cycle_ctx,
            overlay_ctx=overlay_ctx,
            gates_ctx=gates_ctx,
            style_ctx=snapshot.get("style_ctx") or {},
            layout_ctx=snapshot.get("layout_ctx") or {},
            plot_elements_ctx=snapshot.get("plot_elements_ctx") or {},
        )

        return RenderPacket(
            render_ctx=render_ctx,
            data_fingerprint=data_fingerprint,
            args=tuple(snapshot.get("args") or ()),
            fig_size=snapshot.get("fig_size"),
            plot_id=snapshot.get("plot_id"),
            target=snapshot.get("target", "display"),
            perf=None,
        )

    def _render_core_plot_ui(
        self,
        packet: RenderPacket,
        plot_keys: Sequence[str],
        *,
        warn_on_failure: bool,
        placement_states: Optional[Dict[str, Any]] = None,
        task_id: Optional[int] = None,
    ) -> None:
        """Render core plots on the UI thread from a prepared packet.

        Purpose:
            Build Matplotlib figures from precomputed render context.
        Why:
            UI thread must own Matplotlib rendering and Tk canvas updates.
        Inputs:
            packet: RenderPacket computed in the worker phase.
            plot_keys: Plot keys to render (e.g., "fig1", "fig2").
            warn_on_failure: Whether to warn when no plots render.
            placement_states: Optional placement state per plot key.
            task_id: Optional task identifier for stale-result checks.
        Outputs:
            None.
        Side Effects:
            Updates globals, installs figures into tabs, and clears overlays.
        Exceptions:
            Errors are caught to avoid interrupting UI workflows.
        """
        plot_keys_list = [key for key in plot_keys if key]
        if not plot_keys_list:
            return
        for key in plot_keys_list:
            frame, _ = self._find_plot_tab_canvas(key)
            if frame is None:
                continue
            if task_id is not None and getattr(
                frame, "_plot_render_task_id", None
            ) != task_id:
                continue
            self._update_plot_loading_overlay_progress(
                frame,
                progress=65.0,
                message="Building plot figure...",
            )
        try:
            # Apply snapshot-derived globals on the UI thread for legacy consumers.
            self._apply_series_payload_from_snapshot(packet.render_ctx.data_ctx)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        try:
            figs = main_plotting_function(
                *packet.args, fig_size=packet.fig_size, render_ctx=packet.render_ctx
            )
        except Exception as exc:
            figs = None
            if warn_on_failure:
                try:
                    messagebox.showwarning(
                        "Plot Selection",
                        f"Core plot generation failed due to internal error.\n{exc}",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        if not isinstance(figs, dict):
            for key in plot_keys_list:
                frame, _ = self._find_plot_tab_canvas(key)
                if frame is None:
                    continue
                if task_id is not None and getattr(
                    frame, "_plot_render_task_id", None
                ) != task_id:
                    continue
                if key in {"fig1", "fig2"} and bool(
                    getattr(frame, "_core_overlay_hold", False)
                ):
                    self._finalize_core_overlay(frame, force_clear=True)
                elif getattr(frame, "_plot_auto_refresh_state", None) == "refreshing":
                    self._complete_plot_auto_refresh(frame)
                else:
                    self._clear_plot_loading_overlay(frame)
            if warn_on_failure:
                try:
                    messagebox.showwarning(
                        "Plot Selection",
                        "No plots were generated for the current data.",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            return

        rendered_any = False
        # Iterate over plot keys to apply the per-item render/update logic.
        for key in plot_keys_list:
            fig = figs.get(key)
            frame, canvas = self._find_plot_tab_canvas(key)
            if frame is None or canvas is None:
                continue
            if task_id is not None and getattr(
                frame, "_plot_render_task_id", None
            ) != task_id:
                continue
            if fig is None:
                if key in {"fig1", "fig2"} and bool(
                    getattr(frame, "_core_overlay_hold", False)
                ):
                    self._finalize_core_overlay(frame, force_clear=True)
                elif getattr(frame, "_plot_auto_refresh_state", None) == "refreshing":
                    self._complete_plot_auto_refresh(frame)
                else:
                    self._clear_plot_loading_overlay(frame)
                continue
            if key in {"fig1", "fig2"}:
                self._mark_core_figure_real(fig)
            placement_state = (
                placement_states.get(key) if isinstance(placement_states, dict) else None
            )
            self._update_plot_loading_overlay_progress(
                frame,
                progress=78.0,
                message="Installing refreshed figure...",
            )
            self._install_rendered_plot_in_tab(
                frame, canvas, key, fig, placement_state=placement_state
            )
            rendered_any = True

        if not rendered_any and warn_on_failure:
            try:
                messagebox.showwarning(
                    "Plot Selection",
                    "No plots were generated for the current data.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

    def _start_core_render_async(
        self,
        snapshot: Dict[str, Any],
        plot_keys: Sequence[str],
        *,
        warn_on_failure: bool,
        placement_states: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Start core plot rendering in a background worker.

        Purpose:
            Kick off a compute-only worker for core plot data prep.
        Why:
            Keeps the UI responsive while heavy computation runs.
        Inputs:
            snapshot: Snapshot payload captured on the UI thread.
            plot_keys: Plot keys to update on completion.
            warn_on_failure: Whether to warn on render failure.
            placement_states: Optional placement state per plot key.
        Outputs:
            None.
        Side Effects:
            Updates render task IDs on tabs and triggers UI-thread rendering.
        Exceptions:
            Errors are caught and reported without crashing the UI loop.
        """
        plot_keys_list = [key for key in plot_keys if key]
        if not plot_keys_list:
            return
        task_state: Dict[str, Optional[int]] = {"id": None}

        def _worker():
            """Compute core plot packet in a worker thread."""
            return self._compute_core_plot_data(snapshot)

        def _on_ok(packet):
            """Render core plots on the UI thread after compute completes."""
            for key in plot_keys_list:
                frame, _ = self._find_plot_tab_canvas(key)
                if frame is None:
                    continue
                if task_state["id"] is not None and getattr(
                    frame, "_plot_render_task_id", None
                ) != task_state["id"]:
                    continue
                self._update_plot_loading_overlay_progress(
                    frame,
                    progress=55.0,
                    message="Data prepared. Rendering plot...",
                )
            self._render_core_plot_ui(
                packet,
                plot_keys_list,
                warn_on_failure=warn_on_failure,
                placement_states=placement_states,
                task_id=task_state["id"],
            )

        def _on_err(exc):
            """Handle worker failures and clear loading overlays."""
            try:
                print(
                    "Core plot generation failed in background worker.",
                    file=sys.stderr,
                )
                traceback.print_exception(
                    type(exc), exc, exc.__traceback__, file=sys.stderr
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            for key in plot_keys_list:
                frame, _ = self._find_plot_tab_canvas(key)
                if frame is None:
                    continue
                if task_state["id"] is not None and getattr(
                    frame, "_plot_render_task_id", None
                ) != task_state["id"]:
                    continue
                if key in {"fig1", "fig2"} and bool(
                    getattr(frame, "_core_overlay_hold", False)
                ):
                    self._finalize_core_overlay(frame, force_clear=True)
                elif getattr(frame, "_plot_auto_refresh_state", None) == "refreshing":
                    self._complete_plot_auto_refresh(frame)
                else:
                    self._clear_plot_loading_overlay(frame)
            if warn_on_failure:
                try:
                    messagebox.showwarning(
                        "Plot Selection",
                        "Core plot generation failed due to internal error. "
                        "See console for details.",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        task_state["id"] = self._task_runner.submit(
            "core_plot_render", _worker, _on_ok, _on_err
        )
        self._core_render_task_id = task_state["id"]
        # Tag target tabs so stale results can be ignored safely.
        for key in plot_keys_list:
            frame, _ = self._find_plot_tab_canvas(key)
            if frame is None:
                continue
            frame._plot_render_task_id = task_state["id"]
            frame._plot_auto_refresh_state = "refreshing"
            frame._plot_auto_refresh_in_progress = True
            frame._plot_auto_refresh_after_id = None
            self._update_plot_loading_overlay_progress(
                frame,
                progress=20.0,
                message="Preparing plot data...",
            )

    def _start_combined_render_async(
        self,
        snapshot: Dict[str, Any],
        *,
        warn_on_failure: bool,
        frame: Optional[ttk.Frame] = None,
        canvas: Optional[FigureCanvasTkAgg] = None,
        placement_state: Optional[Dict[str, Any]] = None,
        on_success: Optional[Callable[[Figure], None]] = None,
    ) -> None:
        """Start combined render async.

        Purpose:
            Run combined plot computation in a worker and render on the UI thread.
        Why:
            Keeps Tk responsive while combined plot data is prepared.
        Inputs:
            snapshot: Snapshot payload captured on the UI thread.
            warn_on_failure: Whether to warn on render failure.
            frame: Optional target tab frame to update.
            canvas: Optional target canvas to update.
            placement_state: Optional placement state to restore after render.
            on_success: Optional callback invoked with the rendered figure.
        Outputs:
            None.
        Side Effects:
            Updates render task IDs, busy state, and target tab overlays.
        Exceptions:
            Errors are caught and reported without crashing the UI loop.
        """
        self._set_combined_render_busy(True)
        if frame is None or canvas is None:
            frame, canvas = self._find_plot_tab_canvas("fig_combined")
        task_state: Dict[str, Optional[int]] = {"id": None}

        def _worker():
            """Compute the combined render packet in a worker thread."""
            return self._compute_combined_plot_data(snapshot)

        def _on_ok(packet):
            """Render the combined plot on the UI thread after compute completes."""
            self._set_combined_render_busy(False)
            if frame is not None and (
                task_state["id"] is None
                or getattr(frame, "_plot_render_task_id", None) == task_state["id"]
            ):
                self._update_plot_loading_overlay_progress(
                    frame,
                    progress=55.0,
                    message="Data prepared. Rendering combined plot...",
                )
            self._render_combined_plot_ui(
                packet,
                warn_on_failure=warn_on_failure,
                frame=frame,
                canvas=canvas,
                placement_state=placement_state,
                task_id=task_state["id"],
                on_success=on_success,
            )

        def _on_err(exc):
            """Handle worker failures and clear loading overlays."""
            self._set_combined_render_busy(False)
            try:
                print(
                    "Combined plot generation failed in background worker.",
                    file=sys.stderr,
                )
                traceback.print_exception(
                    type(exc), exc, exc.__traceback__, file=sys.stderr
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if frame is not None and (
                task_state["id"] is None
                or getattr(frame, "_plot_render_task_id", None) == task_state["id"]
            ):
                if getattr(frame, "_plot_auto_refresh_state", None) == "refreshing":
                    self._complete_plot_auto_refresh(frame)
                else:
                    self._clear_plot_loading_overlay(frame)
            if warn_on_failure:
                try:
                    messagebox.showwarning(
                        "Plot Selection",
                        "Combined plot generation failed due to internal error. "
                        "See console for details.",
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        task_state["id"] = self._combined_render_runner.submit(
            "combined_render", _worker, _on_ok, _on_err
        )
        self._combined_render_task_id = task_state["id"]
        if frame is not None:
            frame._plot_render_task_id = task_state["id"]
            frame._plot_auto_refresh_state = "refreshing"
            frame._plot_auto_refresh_in_progress = True
            frame._plot_auto_refresh_after_id = None
            self._update_plot_loading_overlay_progress(
                frame,
                progress=20.0,
                message="Preparing combined plot data...",
            )

    def _render_combined_plot_ui(
        self,
        packet: RenderPacket,
        *,
        warn_on_failure: bool,
        frame: Optional[ttk.Frame] = None,
        canvas: Optional[FigureCanvasTkAgg] = None,
        placement_state: Optional[Dict[str, Any]] = None,
        task_id: Optional[int] = None,
        on_success: Optional[Callable[[Figure], None]] = None,
    ) -> None:
        """Render the combined plot on the UI thread from a prepared packet.

        Purpose:
            Build and install the combined figure after background compute.
        Why:
            Matplotlib/Tk operations must occur on the UI thread.
        Inputs:
            packet: RenderPacket computed in the worker phase.
            warn_on_failure: Whether to warn on render failure.
            frame: Optional target tab frame to update.
            canvas: Optional target canvas to update.
            placement_state: Optional plot element placement state to restore.
            task_id: Optional task identifier for stale-result checks.
            on_success: Optional callback invoked with the rendered figure.
        Outputs:
            None.
        Side Effects:
            Installs the combined figure, updates overlays, and records perf data.
        Exceptions:
            Errors are caught to avoid interrupting UI workflows.
        """
        perf_run = packet.perf if isinstance(packet.perf, dict) else None
        self._perf_diag_active_run = perf_run
        if frame is not None:
            self._update_plot_loading_overlay_progress(
                frame,
                progress=65.0,
                message="Building combined figure...",
            )
        try:
            fig = None
            render_error = None
            try:
                fig = self._build_combined_triple_axis_from_state(
                    args=packet.args,
                    fig_size=packet.fig_size,
                    mode="display",
                    reuse=True,
                    render_ctx=packet.render_ctx,
                    perf_run=perf_run,
                )
            except Exception as exc:
                render_error = exc
                fig = None
                try:
                    print(
                        "Combined plot generation failed on UI thread.",
                        file=sys.stderr,
                    )
                    traceback.print_exception(
                        type(exc), exc, exc.__traceback__, file=sys.stderr
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

            if fig is not None:
                target_frame = frame
                target_canvas = canvas
                if target_frame is None or target_canvas is None:
                    target_frame, target_canvas = self._find_plot_tab_canvas(
                        "fig_combined"
                    )
                if (
                    task_id is not None
                    and target_frame is not None
                    and getattr(target_frame, "_plot_render_task_id", None) != task_id
                ):
                    return
                try:
                    if target_frame is not None:
                        target_frame._combined_overlay_data_sig_current = (
                            packet.data_fingerprint
                        )
                    fig._gl260_combined_data_sig = packet.data_fingerprint  # type: ignore[attr-defined]
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                if target_frame is not None and target_canvas is not None:
                    self._update_plot_loading_overlay_progress(
                        target_frame,
                        progress=78.0,
                        message="Installing refreshed figure...",
                    )
                    self._install_rendered_plot_in_tab(
                        target_frame,
                        target_canvas,
                        "fig_combined",
                        fig,
                        placement_state=placement_state,
                    )
                else:
                    self._render_figures_in_tabs(
                        {"fig_combined": fig}, clear_existing=False
                    )
                if (
                    target_frame is not None
                    and getattr(
                        target_frame, "_post_first_draw_refresh_hold_overlay", False
                    )
                    and self._is_real_combined_figure(fig)
                ):
                    invoked_count = getattr(
                        target_frame, "_combined_overlay_refresh_invoked_count", 0
                    )
                    completed_before = getattr(
                        target_frame, "_combined_overlay_refresh_completed_count", 0
                    )
                    try:
                        invoked_count = int(invoked_count)
                    except Exception:
                        invoked_count = 0
                    try:
                        completed_before = int(completed_before)
                    except Exception:
                        completed_before = 0
                    if invoked_count > completed_before:
                        completed_count = self._mark_combined_overlay_refresh_completed(
                            target_frame,
                            fig=fig,
                        )
                        target_refreshes = getattr(
                            target_frame,
                            "_combined_overlay_target_refreshes",
                            self._combined_overlay_default_target_refreshes(),
                        )
                        self._log_plot_tab_debug(
                            "Combined auto-refresh completion recorded: invoked=%s completed=%s target=%s."
                            % (invoked_count, completed_count, target_refreshes)
                        )
                    else:
                        self._log_plot_tab_debug(
                            "Combined render install skipped completion count: invoked=%s completed=%s."
                            % (invoked_count, completed_before)
                        )
                if on_success is not None:
                    try:
                        on_success(fig)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
            else:
                if frame is not None and (
                    task_id is None
                    or getattr(frame, "_plot_render_task_id", None) == task_id
                ):
                    if getattr(frame, "_plot_auto_refresh_state", None) == "refreshing":
                        self._complete_plot_auto_refresh(frame)
                    else:
                        self._clear_plot_loading_overlay(frame)
                if warn_on_failure:
                    try:
                        messagebox.showwarning(
                            "Plot Selection",
                            (
                                "Combined plot generation failed due to internal error. "
                                "See console for details."
                                if render_error is not None
                                else "No plots were generated for the current data."
                            ),
                        )
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            if perf_run is not None:
                self._record_performance_run(perf_run)
        finally:
            self._perf_diag_active_run = None

    def _generate_selected_plots(self) -> None:
        """Generate selected plots.

        Purpose:
            Create plot tabs and run the selected plot renders asynchronously.
        Why:
            Keeps the UI responsive while compute-heavy plot prep runs.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Auto-applies pending Plot Settings dialog edits, creates placeholder
            tabs, starts background workers, and updates tabs.
        Exceptions:
            Errors are caught to avoid interrupting the UI workflow.
        """
        try:
            self._flush_open_plot_settings_dialog(refresh_after_apply=False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        fig1_var = getattr(self, "_plot_select_fig1_var", None)
        fig2_var = getattr(self, "_plot_select_fig2_var", None)
        combined_var = getattr(self, "_plot_select_combined_var", None)
        selections = {
            "fig1": bool(fig1_var.get()) if fig1_var is not None else False,
            "fig2": bool(fig2_var.get()) if fig2_var is not None else False,
            "fig_combined": bool(combined_var.get())
            if combined_var is not None
            else False,
        }

        selection_state = settings.get("plot_generation_selection")
        if not isinstance(selection_state, dict):
            selection_state = {}
            settings["plot_generation_selection"] = selection_state
        selection_state.update(selections)
        try:
            self._schedule_save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if not any(selections.values()):
            try:
                messagebox.showwarning(
                    "Plot Selection",
                    "Select at least one plot to generate before clicking Generate Plot.",
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return

        if self.df is None:
            messagebox.showerror("No Data", "Load a file and sheet first (Data tab).")
            return

        if (
            not self.columns
            or self.columns.get("x") in (None, "None")
            or self.columns.get("y1") in (None, "None")
        ):
            messagebox.showerror(
                "Missing Columns", "Select at least X and y1 on the Columns tab."
            )
            return

        # Create placeholder tabs immediately so loading overlays paint right away.
        placeholder_figs: Dict[str, Any] = {}
        if selections["fig1"]:
            placeholder_fig = Figure()
            try:
                placeholder_fig._gl260_core_real_figure = False  # type: ignore[attr-defined]
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            placeholder_figs["fig1"] = placeholder_fig
        if selections["fig2"]:
            placeholder_fig = Figure()
            try:
                placeholder_fig._gl260_core_real_figure = False  # type: ignore[attr-defined]
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            placeholder_figs["fig2"] = placeholder_fig
        if selections["fig_combined"]:
            placeholder_fig = Figure()
            try:
                placeholder_fig._gl260_combined_real_figure = False  # type: ignore[attr-defined]
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            placeholder_figs["fig_combined"] = placeholder_fig
        if placeholder_figs:
            self._render_figures_in_tabs(
                placeholder_figs, clear_existing=False, auto_refresh=False
            )

        core_keys = [key for key in ("fig1", "fig2") if selections.get(key)]
        if core_keys:
            core_sizes = self._resolve_initial_core_figsize_inches(
                core_keys,
                timeout_ms=250,
                poll_ms=25,
            )
            core_fig_size = core_sizes.get("fig1") or core_sizes.get("fig2")
            core_snapshot = self._capture_plot_render_snapshot(
                fig_size=core_fig_size,
                plot_id="",
                target="display",
            )
            self._start_core_render_async(
                core_snapshot,
                core_keys,
                warn_on_failure=not bool(selections.get("fig_combined")),
            )

        if selections["fig_combined"]:
            combined_frame, combined_canvas = self._find_plot_tab_canvas("fig_combined")
            fig_size = self._resolve_combined_initial_figsize_inches(
                combined_frame,
                combined_canvas,
                timeout_ms=250,
            )
            snapshot = self._capture_plot_render_snapshot(
                fig_size=fig_size,
                plot_id="fig_combined_triple_axis",
                target="display",
            )
            self._start_combined_render_async(
                snapshot,
                warn_on_failure=not bool(core_keys),
                frame=combined_frame,
                canvas=combined_canvas,
            )

    def update_plots(self, *, include_cycle: bool = True):
        """Update plots.

        Purpose:
            Refresh core plots to match current settings and data state.
        Why:
            Ensures plot tabs stay in sync after parameter changes.
        Inputs:
            include_cycle: When True, include the Cycle Analysis plot tab.
        Outputs:
            None.
        Side Effects:
            Rebuilds plot tabs, starts async rendering, and updates UI tabs.
        Exceptions:
            Errors are caught to keep the UI responsive.
        """

        if self.df is None:

            messagebox.showerror("No Data", "Load a file and sheet first (Data tab).")

            return

        if (
            not self.columns
            or self.columns.get("x") in (None, "None")
            or self.columns.get("y1") in (None, "None")
        ):

            messagebox.showerror(
                "Missing Columns", "Select at least X and y1 on the Columns tab."
            )

            return

        args = self._collect_plot_args()

        self._save_settings_dict(args)

        plot_keys: List[str] = ["fig1", "fig2"]
        if include_cycle:
            plot_keys.append("fig_peaks")
        # Render placeholders first to show loading overlays immediately.
        placeholder_figs: Dict[str, Figure] = {}
        for key in plot_keys:
            placeholder_fig = Figure()
            if key in {"fig1", "fig2"}:
                try:
                    placeholder_fig._gl260_core_real_figure = False  # type: ignore[attr-defined]
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            placeholder_figs[key] = placeholder_fig
        self._render_figures_in_tabs(
            placeholder_figs, clear_existing=True, auto_refresh=False
        )
        core_sizes = self._resolve_initial_core_figsize_inches(
            ("fig1", "fig2"),
            timeout_ms=250,
            poll_ms=25,
        )
        core_fig_size = core_sizes.get("fig1") or core_sizes.get("fig2")
        core_snapshot = self._capture_plot_render_snapshot(
            fig_size=core_fig_size,
            plot_id="",
            target="display",
        )
        self._start_core_render_async(
            core_snapshot,
            plot_keys,
            warn_on_failure=False,
        )

        # Show Cycle Analysis tab only after plots exist

        if include_cycle:
            self._ensure_cycle_tab()

    def generate_fig1_only(self):
        """Generate fig1 only.

        Purpose:
            Render only the Figure 1 plot on demand.
        Why:
            Allows a focused refresh without generating all plots.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Auto-applies pending Plot Settings dialog edits, then creates a
            placeholder tab and starts async rendering.
        Exceptions:
            Errors are caught to avoid interrupting the UI workflow.
        """
        try:
            self._flush_open_plot_settings_dialog(refresh_after_apply=False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        # Validate

        if self.df is None:

            messagebox.showerror("No Data", "Load a file and sheet first (Data tab).")

            return

        if (
            not self.columns
            or self.columns.get("x") in (None, "None")
            or self.columns.get("y1") in (None, "None")
        ):

            messagebox.showerror(
                "Missing Columns", "Select at least X and y1 on the Columns tab."
            )

            return

        # Create placeholder tab so the loading overlay is visible immediately.
        placeholder_fig = Figure()
        try:
            placeholder_fig._gl260_core_real_figure = False  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        placeholder_figs = {"fig1": placeholder_fig}
        self._render_figures_in_tabs(
            placeholder_figs, clear_existing=False, auto_refresh=False
        )
        core_sizes = self._resolve_initial_core_figsize_inches(
            ("fig1",),
            timeout_ms=250,
            poll_ms=25,
        )
        core_snapshot = self._capture_plot_render_snapshot(
            fig_size=core_sizes.get("fig1"),
            plot_id="",
            target="display",
        )
        self._start_core_render_async(
            core_snapshot,
            ["fig1"],
            warn_on_failure=False,
        )

    def generate_fig2_only(self):
        """Generate fig2 only.

        Purpose:
            Render only the Figure 2 plot on demand.
        Why:
            Allows a focused refresh without generating all plots.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Auto-applies pending Plot Settings dialog edits, then creates a
            placeholder tab and starts async rendering.
        Exceptions:
            Errors are caught to avoid interrupting the UI workflow.
        """
        try:
            self._flush_open_plot_settings_dialog(refresh_after_apply=False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        # Validate

        if self.df is None:

            messagebox.showerror("No Data", "Load a file and sheet first (Data tab).")

            return

        if (
            not self.columns
            or self.columns.get("x") in (None, "None")
            or self.columns.get("y1") in (None, "None")
        ):

            messagebox.showerror(
                "Missing Columns", "Select at least X and y1 on the Columns tab."
            )

            return

        # Create placeholder tab so the loading overlay is visible immediately.
        placeholder_fig = Figure()
        try:
            placeholder_fig._gl260_core_real_figure = False  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        placeholder_figs = {"fig2": placeholder_fig}
        self._render_figures_in_tabs(
            placeholder_figs, clear_existing=False, auto_refresh=False
        )
        core_sizes = self._resolve_initial_core_figsize_inches(
            ("fig2",),
            timeout_ms=250,
            poll_ms=25,
        )
        core_snapshot = self._capture_plot_render_snapshot(
            fig_size=core_sizes.get("fig2"),
            plot_id="",
            target="display",
        )
        self._start_core_render_async(
            core_snapshot,
            ["fig2"],
            warn_on_failure=False,
        )

    def generate_combined_plot(self):
        """Generate combined plot.

        Purpose:
            Render the combined triple-axis plot on demand.
        Why:
            Provides a focused combined plot render and export trigger.
        Inputs:
            None.
        Outputs:
            None.
        Side Effects:
            Auto-applies pending Plot Settings dialog edits, then creates a
            placeholder tab, starts async rendering, and may export.
        Exceptions:
            Errors are caught to avoid interrupting the UI workflow.
        """
        try:
            self._flush_open_plot_settings_dialog(refresh_after_apply=False)
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if self.df is None:

            messagebox.showerror("No Data", "Load a file and sheet first (Data tab).")

            return

        if (
            not self.columns
            or self.columns.get("x") in (None, "None")
            or self.columns.get("y1") in (None, "None")
        ):

            messagebox.showerror(
                "Missing Columns", "Select at least X and y1 on the Columns tab."
            )

            return

        # Create placeholder tab so the loading overlay is visible immediately.
        placeholder_fig = Figure()
        try:
            placeholder_fig._gl260_combined_real_figure = False  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        placeholder_figs = {"fig_combined": placeholder_fig}
        self._render_figures_in_tabs(
            placeholder_figs, clear_existing=False, auto_refresh=False
        )
        combined_frame, combined_canvas = self._find_plot_tab_canvas("fig_combined")
        fig_size = self._resolve_combined_initial_figsize_inches(
            combined_frame,
            combined_canvas,
            timeout_ms=250,
        )
        snapshot = self._capture_plot_render_snapshot(
            fig_size=fig_size,
            plot_id="fig_combined_triple_axis",
            target="display",
        )

        def _export_after_render(_fig: Figure) -> None:
            """Export the combined plot artifact after the UI render finishes.

            Purpose:
                Trigger export of the combined plot artifact post-render.
            Why:
                Ensures export runs only after the display render completes.
            Inputs:
                _fig: Rendered combined plot figure (unused by export logic).
            Outputs:
                None.
            Side Effects:
                Writes the combined plot artifact to disk via export workflow.
            Exceptions:
                Errors are caught to avoid interrupting the UI workflow.
            """
            try:
                report_state = settings.get("final_report", {}) or {}
                export_profile = report_state.get(
                    "profile_key", FINAL_REPORT_DEFAULT_STATE["profile_key"]
                )
                self._export_combined_plot_artifact(
                    export_profile,
                    {"state": report_state, "fig_size": (11.0, 8.5)},
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        self._start_combined_render_async(
            snapshot,
            warn_on_failure=False,
            frame=combined_frame,
            canvas=combined_canvas,
            on_success=_export_after_render,
        )

    def _combined_plot_config(
        self, args: Tuple[Any, ...], mode: str
    ) -> Optional[Dict[str, Any]]:
        """Normalize combined-plot configuration and layout parameters.

        Purpose:
            Build a normalized configuration payload for combined plot rendering.
        Why:
            A single config source keeps preview, display, and export pipelines
            consistent while honoring persisted layout and legend settings.

        Args:
            args: Plot argument tuple (time/axis ranges, ticks, titles).
            mode: "display" or "export" to select layout profile overrides.

        Returns:
            Dictionary of normalized combined plot configuration values, or
            None when required arguments are missing.

        Side Effects:
            Updates settings flags for cycle overlay toggles.

        Exceptions:
            Returns None on invalid inputs; errors are handled by callers.
        """
        # Centralized normalization of combined-plot layout settings ensures that
        # preview and export share the same margin and padding rules.
        if not args or len(args) < 24:
            return None
        base_args = args[:24]
        deriv_offset = self._safe_get_var(self.combined_deriv_axis_offset, float)
        legend_rows_value = self._safe_get_var(self.combined_legend_rows, int)
        legend_rows_value = max(1, legend_rows_value)
        wrap_enabled = bool(self.combined_legend_wrap.get())
        legend_alignment_value = _normalize_legend_alignment(
            self.combined_legend_alignment.get()
        )
        legend_gap_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_legend_label_gap, float),
            DEFAULT_COMBINED_LEGEND_GAP_PTS,
            MIN_COMBINED_LEGEND_GAP_PTS,
            MAX_COMBINED_LEGEND_GAP_PTS,
        )
        xlabel_tick_gap_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_xlabel_tick_gap, float),
            DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS,
            MIN_COMBINED_XLABEL_TICK_GAP_PTS,
            MAX_COMBINED_XLABEL_TICK_GAP_PTS,
        )
        legend_margin_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_legend_bottom_margin, float),
            DEFAULT_COMBINED_LEGEND_MARGIN_PTS,
            MIN_COMBINED_LEGEND_MARGIN_PTS,
            MAX_COMBINED_LEGEND_MARGIN_PTS,
        )
        left_padding_pct = _sanitize_spacing_value(
            self._safe_get_var(self.combined_left_padding_pct, float),
            DEFAULT_COMBINED_LEFT_PAD_PCT,
            MIN_COMBINED_SIDE_PAD_PCT,
            MAX_COMBINED_SIDE_PAD_PCT,
        )
        right_padding_pct = _sanitize_spacing_value(
            self._safe_get_var(self.combined_right_padding_pct, float),
            DEFAULT_COMBINED_RIGHT_PAD_PCT,
            MIN_COMBINED_SIDE_PAD_PCT,
            MAX_COMBINED_SIDE_PAD_PCT,
        )
        export_pad_pts = _sanitize_spacing_value(
            self._safe_get_var(self.combined_export_pad_pts, float),
            DEFAULT_COMBINED_EXPORT_PAD_PTS,
            MIN_COMBINED_EXPORT_PAD_PTS,
            MAX_COMBINED_EXPORT_PAD_PTS,
        )
        title_pad_pts = _sanitize_spacing_value(
            self._safe_get_var(self.combined_title_pad_pts, float),
            DEFAULT_COMBINED_TITLE_PAD_PTS,
            MIN_COMBINED_TITLE_PAD_PTS,
            MAX_COMBINED_TITLE_PAD_PTS,
        )
        suptitle_pad_pts = _sanitize_spacing_value(
            self._safe_get_var(self.combined_suptitle_pad_pts, float),
            DEFAULT_COMBINED_SUPTITLE_PAD_PTS,
            MIN_COMBINED_SUPTITLE_PAD_PTS,
            MAX_COMBINED_SUPTITLE_PAD_PTS,
        )
        suptitle_y_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_suptitle_y, float),
            DEFAULT_COMBINED_SUPTITLE_Y,
            MIN_COMBINED_SUPTITLE_Y,
            MAX_COMBINED_SUPTITLE_Y,
        )
        top_margin_pct = _sanitize_spacing_value(
            self._safe_get_var(self.combined_top_margin_pct, float),
            DEFAULT_COMBINED_TOP_MARGIN_PCT,
            MIN_COMBINED_TOP_MARGIN_PCT,
            MAX_COMBINED_TOP_MARGIN_PCT,
        )
        suptitle_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_suptitle_fontsize, float),
            DEFAULT_COMBINED_SUPTITLE_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        title_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_title_fontsize, float),
            DEFAULT_COMBINED_TITLE_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        label_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_label_fontsize, float),
            DEFAULT_COMBINED_LABEL_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        tick_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_tick_fontsize, float),
            DEFAULT_COMBINED_TICK_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        legend_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_legend_fontsize, float),
            DEFAULT_COMBINED_LEGEND_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        cycle_legend_font_value = _sanitize_spacing_value(
            self._safe_get_var(self.combined_cycle_legend_fontsize, float),
            legend_font_value,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        font_family_value = (self.combined_font_family.get() or "").strip()
        if not font_family_value:
            font_family_value = (settings.get("font_family") or "").strip()
        left_key, right_key, third_key = self._sanitize_combined_axis_keys(
            self.combined_y_left_key.get(),
            self.combined_y_right_key.get(),
            self.combined_y_third_key.get(),
        )
        self.combined_y_left_key.set(left_key)
        self.combined_y_right_key.set(right_key)
        self.combined_y_third_key.set(third_key)
        show_cycle_markers = bool(args[-3])
        show_cycle_legend = bool(args[-2])
        include_moles_core = bool(args[-1])
        settings["show_cycle_markers_on_core_plots"] = bool(show_cycle_markers)
        settings["show_cycle_legend_on_core_plots"] = bool(show_cycle_legend)
        settings["include_moles_in_core_plot_legend"] = bool(include_moles_core)
        legend_anchor = getattr(self, "_combined_legend_anchor", None)
        cycle_legend_anchor = getattr(self, "_combined_cycle_legend_anchor", None)
        legend_loc = getattr(self, "_combined_legend_loc", None)
        cycle_legend_loc = getattr(self, "_combined_cycle_legend_loc", None)
        cycle_legend_anchor_space = getattr(
            self, "_combined_cycle_legend_anchor_space", None
        )
        cycle_anchor_mode = settings.get("combined_cycle_legend_anchor_mode")
        if cycle_anchor_mode == "loc_tuple":
            normalized_cycle_loc = _normalize_legend_loc_value(cycle_legend_loc)
            if not (
                isinstance(normalized_cycle_loc, tuple)
                and len(normalized_cycle_loc) == 2
                and all(math.isfinite(float(v)) for v in normalized_cycle_loc)
            ):
                normalized_cycle_loc = _normalize_legend_loc_value(
                    settings.get("combined_cycle_legend_loc")
                )
            if (
                isinstance(normalized_cycle_loc, tuple)
                and len(normalized_cycle_loc) == 2
                and all(math.isfinite(float(v)) for v in normalized_cycle_loc)
            ):
                cycle_legend_loc = (
                    float(normalized_cycle_loc[0]),
                    float(normalized_cycle_loc[1]),
                )
            cycle_legend_anchor = None
            cycle_legend_anchor_space = "axes"
        if not bool(settings.get("combined_cycle_legend_persist_position", True)):
            # Persistence toggle should suppress stored cycle legend placement.
            cycle_legend_anchor = None
            cycle_legend_loc = None
            cycle_legend_anchor_space = None
        if cycle_legend_anchor is not None and cycle_legend_anchor_space not in {
            "figure",
            "axes",
        }:
            cycle_legend_anchor_space = "figure"
        layout_profile = _get_layout_profile("fig_combined_triple_axis")
        layout_section = _layout_profile_section(layout_profile, mode)
        profile_margins = layout_section.get("margins")
        profile_labelpads = layout_section.get("axis_labelpads", {})
        profile_legend_anchor = layout_section.get("legend_anchor")
        profile_cycle_anchor = layout_section.get("cycle_legend_anchor")
        profile_legend_anchor_y = layout_section.get("legend_anchor_y")
        profile_xlabel_pad = layout_section.get("xlabel_pad_pts")
        profile_detached_offset = layout_section.get("detached_spine_offset")
        profile_detached_labelpad = layout_section.get("detached_labelpad")
        mirror_detached_labelpad = bool(
            layout_profile.get("mirror_detached_labelpad", False)
        )
        axis_offset_values = _combined_cycle_axis_offset_values()
        if cycle_anchor_mode == "loc_tuple":
            axis_offset_values = None
        if bool(self.center_combined_plot_legend.get()):
            # When centering is enabled, ignore persisted main-legend anchors so the
            # builder's default centered placement applies on refresh.
            legend_anchor = None
            legend_loc = None
            legend_alignment_value = "center"
        if profile_legend_anchor is not None:
            legend_anchor = profile_legend_anchor
        if (
            profile_cycle_anchor is not None
            and cycle_legend_anchor is None
            and axis_offset_values is None
        ):
            cycle_legend_anchor = profile_cycle_anchor
        labelpad_overrides = self._combined_axis_labelpad_overrides()
        if isinstance(profile_labelpads, dict):
            if "primary" in profile_labelpads:
                labelpad_overrides["primary"] = profile_labelpads["primary"]
            if "right" in profile_labelpads:
                labelpad_overrides["temperature"] = profile_labelpads["right"]
            if "temperature" in profile_labelpads:
                labelpad_overrides["temperature"] = profile_labelpads["temperature"]
            if "third" in profile_labelpads:
                labelpad_overrides["derivative"] = profile_labelpads["third"]
            if "derivative" in profile_labelpads:
                labelpad_overrides["derivative"] = profile_labelpads["derivative"]
        if profile_detached_labelpad is not None:
            labelpad_overrides["derivative"] = profile_detached_labelpad
        if mirror_detached_labelpad:
            temp_pad = labelpad_overrides.get("temperature")
            if temp_pad is None:
                temp_pad = self._safe_get_var(self.combined_temp_labelpad, float)
            if temp_pad is not None:
                labelpad_overrides["derivative"] = temp_pad
        xlabel_pad_value = profile_xlabel_pad
        if xlabel_pad_value is None and isinstance(profile_labelpads, dict):
            xlabel_pad_value = profile_labelpads.get("x")
        if profile_detached_offset is not None:
            try:
                offset_value = float(profile_detached_offset)
            except Exception:
                offset_value = None
            if offset_value is not None and math.isfinite(offset_value):
                deriv_offset = offset_value
        axis_label_overrides = self._combined_axis_label_overrides()
        return {
            "base_args": base_args,
            "deriv_offset": deriv_offset,
            "wrap_enabled": wrap_enabled,
            "legend_rows_value": legend_rows_value,
            "legend_alignment_value": legend_alignment_value,
            "legend_gap_value": legend_gap_value,
            "xlabel_tick_gap_value": xlabel_tick_gap_value,
            "legend_margin_value": legend_margin_value,
            "left_padding_pct": left_padding_pct,
            "right_padding_pct": right_padding_pct,
            "export_pad_pts": export_pad_pts,
            "title_pad_pts": title_pad_pts,
            "suptitle_pad_pts": suptitle_pad_pts,
            "suptitle_y_value": suptitle_y_value,
            "top_margin_pct": top_margin_pct,
            "suptitle_font_value": suptitle_font_value,
            "title_font_value": title_font_value,
            "label_font_value": label_font_value,
            "tick_font_value": tick_font_value,
            "legend_font_value": legend_font_value,
            "cycle_legend_font_value": cycle_legend_font_value,
            "font_family_value": font_family_value,
            "left_key": left_key,
            "right_key": right_key,
            "third_key": third_key,
            "show_cycle_markers": show_cycle_markers,
            "show_cycle_legend": show_cycle_legend,
            "include_moles_core": include_moles_core,
            "legend_anchor": legend_anchor,
            "cycle_legend_anchor": cycle_legend_anchor,
            "legend_loc": legend_loc,
            "cycle_legend_loc": cycle_legend_loc,
            "cycle_legend_anchor_space": cycle_legend_anchor_space,
            "baseline_margins": profile_margins,
            "legend_anchor_y": profile_legend_anchor_y,
            "xlabel_pad_value": xlabel_pad_value,
            "axis_label_overrides": axis_label_overrides,
            "labelpad_overrides": labelpad_overrides,
            "layout_section": layout_section,
            "axis_offset_values": axis_offset_values,
        }

    def _combined_scatter_signature(
        self,
        series_keys: Sequence[str],
        *,
        scatter_config: Optional[Dict[str, Any]] = None,
        scatter_series_configs: Optional[Dict[str, Any]] = None,
    ) -> Tuple[Any, ...]:
        """Compute a structure signature for combined scatter/trace styling.

        Purpose:
            Build a deterministic signature from per-series scatter settings.
        Why:
            Combined display reuse must rebuild when style inputs that affect
            trace layering or appearance change, including z-order overrides.
        Inputs:
            series_keys: Ordered trace keys included in the signature.
            scatter_config: Optional shared scatter settings.
            scatter_series_configs: Optional per-series settings from Data Trace Settings.
        Outputs:
            Tuple signature used by combined structure invalidation logic.
        Side Effects:
            None.
        Exceptions:
            Invalid per-series settings are normalized to safe defaults.
        """
        signature = []
        default_zorders = {"y1": 2.0, "y3": 1.0, "y2": 3.0, "z": 3.0, "z2": 3.0}
        # Iterate over series_keys to apply the per-item logic.
        for key in series_keys:
            cfg = _get_scatter_config(
                key,
                scatter_config=scatter_config,
                scatter_series_configs=scatter_series_configs,
            )
            resolved_zorder = _resolve_effective_trace_zorder(
                default_zorders.get(key, 2.0),
                series_key=key,
                scatter_series_configs=scatter_series_configs,
            )
            if not math.isfinite(resolved_zorder):
                resolved_zorder = float(default_zorders.get(key, 2.0))
            signature.append(
                (
                    key,
                    bool(cfg.get("enabled")),
                    cfg.get("marker"),
                    cfg.get("linestyle"),
                    cfg.get("color"),
                    cfg.get("edgecolor"),
                    _coerce_float(cfg.get("size")),
                    _coerce_float(cfg.get("linewidth")),
                    _coerce_float(cfg.get("alpha")),
                    round(float(resolved_zorder), 6),
                )
            )
        return tuple(signature)

    def _combined_legend_config_signature(
        self, config: Mapping[str, Any]
    ) -> Tuple[Any, ...]:
        """Compute combined legend config signature.
        Used to detect legend layout changes during reuse."""
        return (
            bool(config.get("wrap_enabled")),
            config.get("legend_rows_value"),
            config.get("legend_alignment_value"),
            config.get("legend_anchor"),
            config.get("legend_loc"),
            config.get("cycle_legend_anchor"),
            config.get("cycle_legend_loc"),
            config.get("cycle_legend_anchor_space"),
        )

    def _combined_cycle_overlay_signature(
        self, overlay_ctx: Mapping[str, Any]
    ) -> Tuple[Any, ...]:
        """Compute combined cycle overlay signature.
        Used to detect cycle legend content changes."""
        cycle_overlay = overlay_ctx.get("cycle_overlay") or {}
        peaks = cycle_overlay.get("peak_points") or []
        troughs = cycle_overlay.get("trough_points") or []
        cycles = cycle_overlay.get("cycles") or []
        total_drop = _coerce_float(cycle_overlay.get("total_drop")) or 0.0
        moles_lines = overlay_ctx.get("moles_summary")
        if moles_lines is None and isinstance(cycle_overlay, dict):
            moles_lines = cycle_overlay.get("moles_lines")
        moles_lines = tuple(moles_lines or ())
        return (
            len(peaks),
            len(troughs),
            len(cycles),
            round(float(total_drop), 6),
            moles_lines,
        )

    def _combined_structure_signature(
        self,
        config: Mapping[str, Any],
        args: Tuple[Any, ...],
        *,
        cycle_overlay: Optional[Dict[str, Any]] = None,
        scatter_config: Optional[Dict[str, Any]] = None,
        scatter_series_configs: Optional[Dict[str, Any]] = None,
    ) -> Tuple[Any, ...]:
        """Compute the combined-plot structure signature.
        Used to decide when a full figure rebuild is required."""
        # Structure signature captures axis roles, overlay presence, and scatter
        # settings so cached figures are invalidated only when structure changes.
        base_args = config.get("base_args") or ()
        enable_temp_axis = bool(base_args[22]) if len(base_args) > 22 else False
        enable_deriv_axis = bool(base_args[23]) if len(base_args) > 23 else False
        cycle_sig = None
        if isinstance(cycle_overlay, dict):
            peaks = cycle_overlay.get("peak_points") or []
            troughs = cycle_overlay.get("trough_points") or []
            cycles = cycle_overlay.get("cycles") or []
            total_drop = _coerce_float(cycle_overlay.get("total_drop"))
            if total_drop is None:
                total_drop = 0.0
            cycle_sig = (
                len(peaks),
                len(troughs),
                len(cycles),
                round(total_drop, 6),
            )
        return (
            config.get("left_key"),
            config.get("right_key"),
            config.get("third_key"),
            enable_temp_axis,
            enable_deriv_axis,
            bool(config.get("show_cycle_markers")),
            bool(config.get("show_cycle_legend")),
            bool(config.get("include_moles_core")),
            self._combined_scatter_signature(
                ("y1", "y3", "y2", "z", "z2"),
                scatter_config=scatter_config,
                scatter_series_configs=scatter_series_configs,
            ),
            cycle_sig,
        )

    def _combined_layout_signature(
        self,
        config: Mapping[str, Any],
        args: Tuple[Any, ...],
        fig_size: Optional[Tuple[float, float]],
        *,
        legend_text_sig: Optional[Tuple[Tuple[str, ...], Tuple[str, ...]]] = None,
        plot_elements_sig: Optional[Tuple[Any, ...]] = None,
    ) -> Tuple[Any, ...]:
        """Compute the combined-plot layout signature.
        Used to detect spacing changes that require a layout re-solve."""
        # Layout signature isolates inputs that affect bbox/legend spacing so
        # preview-only updates do not unnecessarily rebuild the combined figure.
        base_args = config.get("base_args") or ()
        auto_time_ticks = bool(base_args[8]) if len(base_args) > 8 else False
        auto_y_ticks = bool(base_args[9]) if len(base_args) > 9 else False
        auto_temp_ticks = bool(base_args[10]) if len(base_args) > 10 else False
        auto_deriv_ticks = bool(base_args[11]) if len(base_args) > 11 else False
        title_text = base_args[12] if len(base_args) > 12 else ""
        suptitle_text = base_args[13] if len(base_args) > 13 else ""
        fig_size_value = None
        if fig_size is not None:
            try:
                fig_size_value = (
                    round(float(fig_size[0]), 4),
                    round(float(fig_size[1]), 4),
                )
            except Exception:
                fig_size_value = None
        baseline_margins = config.get("baseline_margins") or {}
        labelpad_overrides = config.get("labelpad_overrides") or {}
        label_overrides = config.get("axis_label_overrides") or {}
        return (
            fig_size_value,
            config.get("font_family_value"),
            config.get("suptitle_font_value"),
            config.get("title_font_value"),
            config.get("label_font_value"),
            config.get("tick_font_value"),
            config.get("legend_font_value"),
            config.get("cycle_legend_font_value"),
            title_text or "",
            suptitle_text or "",
            config.get("legend_alignment_value"),
            config.get("legend_anchor"),
            config.get("legend_anchor_y"),
            config.get("legend_loc"),
            bool(config.get("wrap_enabled")),
            config.get("legend_rows_value"),
            config.get("cycle_legend_anchor"),
            config.get("cycle_legend_loc"),
            config.get("cycle_legend_anchor_space"),
            config.get("axis_offset_values"),
            auto_time_ticks,
            auto_y_ticks,
            auto_temp_ticks,
            auto_deriv_ticks,
            config.get("legend_gap_value"),
            config.get("xlabel_tick_gap_value"),
            config.get("legend_margin_value"),
            config.get("left_padding_pct"),
            config.get("right_padding_pct"),
            config.get("export_pad_pts"),
            config.get("title_pad_pts"),
            config.get("suptitle_pad_pts"),
            config.get("suptitle_y_value"),
            config.get("top_margin_pct"),
            config.get("xlabel_pad_value"),
            tuple(sorted(baseline_margins.items())),
            tuple(sorted(labelpad_overrides.items())),
            tuple(sorted(label_overrides.items())),
            legend_text_sig or (),
            plot_elements_sig or (),
        )

    def _combined_legend_text_signature(
        self, fig: Optional[Figure]
    ) -> Tuple[Tuple[str, ...], Tuple[str, ...]]:
        """Collect combined legend text signature.
        Used to detect layout-affecting legend text changes."""
        if fig is None:
            return ((), ())
        main_labels: List[str] = []
        cycle_labels: List[str] = []
        # Iterate over self._collect_combined_legends(fig) to apply the per-item logic.
        for legend in self._collect_combined_legends(fig):
            try:
                texts = [txt.get_text() for txt in legend.get_texts() if txt is not None]
            except Exception:
                texts = []
            if self._is_combined_cycle_legend(legend):
                cycle_labels.extend(texts)
            elif getattr(legend, "_combined_main_legend", False):
                main_labels.extend(texts)
        return (tuple(main_labels), tuple(cycle_labels))

    def _plot_elements_signature(self, plot_id: Optional[str]) -> Tuple[Any, ...]:
        """Collect plot element signature.
        Used to detect layout-affecting plot element changes."""
        if not plot_id:
            return ()
        elements_map = settings.get("plot_elements", {})
        elements = (
            elements_map.get(plot_id)
            if isinstance(elements_map, dict)
            else None
        )
        elements = elements if isinstance(elements, list) else []

        def _signature(value: Any) -> Any:
            """Perform signature.
            Used to normalize plot element values for signatures."""
            if isinstance(value, dict):
                return tuple(
                    sorted((str(k), _signature(v)) for k, v in value.items())
                )
            if isinstance(value, (list, tuple)):
                return tuple(_signature(v) for v in value)
            if isinstance(value, (str, int, float, bool)) or value is None:
                return value
            try:
                return str(value)
            except Exception:
                return repr(value)

        return tuple(_signature(item) for item in elements)

    def _combined_preview_decimate(
        self,
        fig: Optional[Figure],
        canvas: Optional[FigureCanvasTkAgg],
        x_values: Any,
        series_values: Dict[str, Any],
        *,
        series_arrays: Optional[Dict[str, Any]] = None,
        series_nan_mask: Optional[Dict[str, Any]] = None,
    ) -> Tuple[Any, Dict[str, Any]]:
        """Perform combined preview decimate.
        Used to keep the workflow logic localized and testable."""
        series_arrays = series_arrays or {}
        series_nan_mask = series_nan_mask or {}
        if x_values is None and series_arrays.get("x") is None:
            return x_values, series_values
        try:
            x_array = (
                np.asarray(series_arrays.get("x"))
                if series_arrays.get("x") is not None
                else np.asarray(x_values)
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            return x_values, series_values
        if x_array.size <= 1:
            return x_values, series_values
        width_px = None
        if canvas is not None:
            try:
                width_px = int(canvas.get_width_height()[0])
            except Exception:
                width_px = None
        if width_px is None and fig is not None:
            try:
                width_px = int(max(fig.get_size_inches()[0] * fig.dpi, 1.0))
            except Exception:
                width_px = None
        if width_px is None or width_px <= 0:
            return x_values, series_values
        target_points = int(max(width_px * 3.0, 1.0))
        if x_array.size <= target_points:
            return x_array, series_values
        step = int(math.ceil(x_array.size / float(target_points)))
        if step <= 1:
            return x_array, series_values
        idx = np.arange(0, x_array.size, step)
        if idx.size == 0:
            return x_values, series_values
        if idx[-1] != x_array.size - 1:
            idx = np.append(idx, x_array.size - 1)
        required_mask = np.zeros(x_array.size, dtype=bool)
        x_nan = series_nan_mask.get("x")
        if x_nan is None:
            try:
                x_nan = np.isnan(x_array)
            except Exception:
                x_nan = None
        if x_nan is not None:
            try:
                x_nan = np.asarray(x_nan).reshape(-1)
            except Exception:
                x_nan = None
        if x_nan is not None and x_nan.size == x_array.size:
            required_mask |= x_nan
        # Iterate over items from series_values to apply the per-item logic.
        for key, values in series_values.items():
            if values is None:
                continue
            y_array = series_arrays.get(key)
            if y_array is None:
                try:
                    y_array = np.asarray(values)
                except Exception:
                    continue
            if y_array.shape[0] != x_array.shape[0]:
                continue
            y_nan = series_nan_mask.get(key)
            if y_nan is None:
                try:
                    y_nan = np.isnan(y_array)
                except Exception:
                    try:
                        y_nan = pd.isna(y_array)
                    except Exception:
                        y_nan = None
            if y_nan is None:
                continue
            try:
                y_nan = np.asarray(y_nan).reshape(-1)
            except Exception:
                continue
            if y_nan.size != x_array.size:
                continue
            required_mask |= y_nan
        if required_mask.any():
            required_idx = np.flatnonzero(required_mask)
            if required_idx.size:
                neighbor_idx = np.unique(
                    np.concatenate([required_idx - 1, required_idx + 1])
                )
                neighbor_idx = neighbor_idx[
                    (neighbor_idx >= 0) & (neighbor_idx < x_array.size)
                ]
                required_idx = np.unique(
                    np.concatenate([required_idx, neighbor_idx])
                )
                idx = np.unique(np.concatenate([idx, required_idx]))
        x_dec = x_array[idx]
        decimated: Dict[str, Any] = {}
        # Iterate over items from series_values to apply the per-item logic.
        for key, values in series_values.items():
            if values is None:
                decimated[key] = None
                continue
            y_array = series_arrays.get(key)
            if y_array is None:
                try:
                    y_array = np.asarray(values)
                except Exception:
                    decimated[key] = values
                    continue
            if y_array.shape[0] != x_array.shape[0]:
                decimated[key] = values
                continue
            decimated[key] = y_array[idx]
        return x_dec, decimated

    def _update_combined_triple_axis_display(
        self,
        config: Mapping[str, Any],
        args: Tuple[Any, ...],
        fig_size: Optional[Tuple[float, float]],
        canvas: Optional[FigureCanvasTkAgg],
        *,
        render_ctx: Optional[RenderContext] = None,
        perf_run: Optional[Dict[str, Any]] = None,
    ) -> Optional[Figure]:
        """Update the combined triple-axis display figure with reuse when possible.

        Purpose:
            Refresh the combined plot display with reuse or rebuild when needed.
        Why:
            Keeps interactive rendering fast while honoring overlay/legend changes.
        Args:
            config: Mapping of combined plot configuration values for display.
            args: Plot argument tuple (time/axis ranges, tick settings, titles).
            fig_size: Target figure size in inches for the display view.
            canvas: Tkinter-backed canvas used to guide decimation sizing.
            render_ctx: Optional RenderContext with prepared data/overlays/styles.
                Required on rebuild so cycle overlays and legends are preserved.
            perf_run: Optional performance accumulator updated with timing data.
        Returns:
            The updated Matplotlib Figure, or None if inputs are incomplete.
        Side Effects:
            Mutates figure artists, updates cached combined plot/layout state,
            and schedules a canvas redraw when available.
        Exceptions:
            Internal rendering errors are caught and ignored to avoid breaking
            the UI; returns None when required inputs are missing.
        """
        data_ctx = render_ctx.data_ctx if render_ctx else {}
        style_ctx = render_ctx.style_ctx if render_ctx else {}
        overlay_ctx = render_ctx.overlay_ctx if render_ctx else {}

        scatter_config = style_ctx.get("scatter_config")
        scatter_series_configs = style_ctx.get("scatter_series_configs")
        cycle_overlay = overlay_ctx.get("cycle_overlay")
        markers_overlay = overlay_ctx.get("markers", cycle_overlay)
        legend_overlay = overlay_ctx.get("cycle_legend", cycle_overlay)
        cycle_style = (
            get_cycle_trace_style() if (markers_overlay or legend_overlay) else None
        )
        moles_lines = overlay_ctx.get("moles_summary")
        if moles_lines is None and isinstance(cycle_overlay, dict):
            moles_lines = cycle_overlay.get("moles_lines")

        base_args = config.get("base_args") or ()
        if len(base_args) < 24:
            return None
        structure_sig = self._combined_structure_signature(
            config,
            args,
            cycle_overlay=cycle_overlay,
            scatter_config=scatter_config,
            scatter_series_configs=scatter_series_configs,
        )
        legend_sig = self._combined_legend_config_signature(config)
        cycle_overlay_sig = self._combined_cycle_overlay_signature(overlay_ctx)
        legend_font_value = config.get("legend_font_value")
        state = (
            self._combined_plot_state if isinstance(self._combined_plot_state, dict) else {}
        )
        fig = state.get("fig") if state else None
        cycle_overlay_changed = state.get("cycle_overlay_sig") != cycle_overlay_sig
        # When overlay content changes and cycle legend is enabled, force a rebuild
        # so the legend data refreshes without regressing reuse performance.
        force_overlay_rebuild = cycle_overlay_changed and bool(
            config.get("show_cycle_legend")
        )
        overlay_rebuild_applied = False
        if (
            fig is None
            or state.get("structure_sig") != structure_sig
            or force_overlay_rebuild
        ):
            self._dbg(
                "plotting.render",
                "Combined display rebuild structure_changed=%s overlay_rebuild=%s",
                state.get("structure_sig") != structure_sig,
                force_overlay_rebuild,
            )
            with self._perf_time("plotting.render", "combined_display_rebuild"):
                fig = build_combined_triple_axis_figure(
                    *base_args,
                    deriv_axis_offset=config.get("deriv_offset"),
                    legend_wrap=config.get("wrap_enabled"),
                    legend_rows=config.get("legend_rows_value"),
                    legend_alignment=config.get("legend_alignment_value"),
                    legend_label_gap_pts=config.get("legend_gap_value"),
                    xlabel_tick_gap_pts=config.get("xlabel_tick_gap_value"),
                    legend_bottom_margin_pts=config.get("legend_margin_value"),
                    left_pad_pct=config.get("left_padding_pct"),
                    right_pad_pct=config.get("right_padding_pct"),
                    export_pad_pts=config.get("export_pad_pts"),
                    title_pad_pts=config.get("title_pad_pts"),
                    suptitle_pad_pts=config.get("suptitle_pad_pts"),
                    suptitle_y=config.get("suptitle_y_value"),
                    top_margin_pct=config.get("top_margin_pct"),
                    suptitle_fontsize=config.get("suptitle_font_value"),
                    title_fontsize=config.get("title_font_value"),
                    label_fontsize_override=config.get("label_font_value"),
                    tick_fontsize_override=config.get("tick_font_value"),
                    legend_fontsize_override=config.get("legend_font_value"),
                    cycle_legend_fontsize_override=config.get("cycle_legend_font_value"),
                    font_family=config.get("font_family_value"),
                    axis_label_overrides=config.get("axis_label_overrides"),
                    labelpad_overrides=config.get("labelpad_overrides"),
                    left_dataset_key=config.get("left_key"),
                    right_dataset_key=config.get("right_key"),
                    third_dataset_key=config.get("third_key"),
                    show_cycle_markers_on_core_plots=config.get("show_cycle_markers"),
                    show_cycle_legend_on_core_plots=config.get("show_cycle_legend"),
                    include_moles_in_core_plot_legend=config.get("include_moles_core"),
                    legend_anchor=config.get("legend_anchor"),
                    cycle_legend_anchor=config.get("cycle_legend_anchor"),
                    legend_loc=config.get("legend_loc"),
                    cycle_legend_loc=config.get("cycle_legend_loc"),
                    cycle_legend_anchor_space=config.get("cycle_legend_anchor_space"),
                    baseline_margins=config.get("baseline_margins"),
                    legend_anchor_y=config.get("legend_anchor_y"),
                    xlabel_pad_pts=config.get("xlabel_pad_value"),
                    # Render context is mandatory on rebuilds so overlays/legends persist.
                    render_ctx=render_ctx,
                    mode="display",
                    fig_size=fig_size,
                )
            if fig is None:
                return None
            self._combined_plot_state = {
                "fig": fig,
                "structure_sig": structure_sig,
                "legend_sig": legend_sig,
                "cycle_overlay_sig": cycle_overlay_sig,
            }
            self._combined_layout_state = None
            self._combined_layout_dirty = True
            overlay_rebuild_applied = force_overlay_rebuild
            try:
                fig._gl260_expect_cycle_legend = bool(config.get("show_cycle_legend"))
                fig._gl260_expect_cycle_markers = bool(
                    config.get("show_cycle_markers")
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        axes_map = getattr(fig, "_gl260_combined_axes_map", None)
        if not isinstance(axes_map, dict):
            axes_map = self._resolve_plot_element_axes(fig)
        ax = axes_map.get("primary")
        ax_temp = axes_map.get("right")
        ax_deriv = axes_map.get("third")
        ax_overlay = axes_map.get("overlay")
        if ax is None:
            return fig
        try:
            current_size = tuple(fig.get_size_inches())
        except Exception:
            current_size = None
        if fig_size is not None and current_size is not None:
            if len(current_size) >= 2:
                if (
                    abs(current_size[0] - fig_size[0]) > 1e-3
                    or abs(current_size[1] - fig_size[1]) > 1e-3
                ):
                    try:
                        fig.set_size_inches(fig_size, forward=False)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

        (
            min_time,
            max_time,
            min_y,
            max_y,
            twin_y_min,
            twin_y_max,
            deriv_y_min,
            deriv_y_max,
            auto_time_ticks,
            auto_y_ticks,
            auto_temp_ticks,
            auto_deriv_ticks,
            title_text,
            suptitle_text,
            xmaj_tick,
            xmin_tick,
            ymaj_tick,
            ymin_tick,
            twin_maj_tick,
            twin_min_tick,
            deriv_maj_tick,
            deriv_min_tick,
            _enable_temp_axis,
            _enable_deriv_axis,
        ) = base_args

        from matplotlib.ticker import AutoLocator, AutoMinorLocator, MultipleLocator

        def _apply_axis_ticks(axis, auto_flag, major_tick, minor_tick):
            """Apply axis ticks.
            Used to apply axis ticks changes to live state."""
            if axis is None:
                return
            if auto_flag:
                axis.yaxis.set_major_locator(AutoLocator())
                axis.yaxis.set_minor_locator(AutoMinorLocator())
            else:
                axis.yaxis.set_major_locator(MultipleLocator(major_tick))
                axis.yaxis.set_minor_locator(MultipleLocator(minor_tick))
            axis.minorticks_on()
            axis.tick_params(
                axis="y",
                which="major",
                labelcolor="black",
                labelsize=config.get("tick_font_value"),
            )

        family_value = (config.get("font_family_value") or "").strip()

        def _apply_tick_font(axis):
            """Apply tick font.
            Used to apply tick font changes to live state."""
            if axis is None or not family_value:
                return
            try:
                labels = list(axis.get_xticklabels()) + list(axis.get_yticklabels())
                # Iterate over labels to apply the per-item logic.
                for lbl in labels:
                    lbl.set_fontfamily(family_value)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        selected_columns = data_ctx.get("selected_columns") or globals().get(
            "selected_columns", {}
        )
        prepared_series_map = data_ctx.get("series") or {}
        prepared_series_np = data_ctx.get("series_np") or {}
        svg_safe = _svg_safe_text
        fmt = _format_axis_label

        def _fmt_safe(value: Any) -> str:
            """Perform fmt safe.
            Used to keep the workflow logic localized and testable."""
            return svg_safe(fmt(value))

        def _text_safe(value: Any) -> str:
            """Perform text safe.
            Used to keep the workflow logic localized and testable."""
            return svg_safe(value)

        label_y1 = _fmt_safe(selected_columns.get("y1", "y1"))
        label_y3 = _fmt_safe(selected_columns.get("y3", "y3"))
        label_y2 = _fmt_safe(selected_columns.get("y2", "Derivative"))
        label_z = _fmt_safe(selected_columns.get("z", "Temp"))
        label_z2 = _fmt_safe(selected_columns.get("z2", "Temp 2"))
        default_x_label = _fmt_safe(selected_columns.get("x", "Time"))

        selected_map = {
            "y1": _is_selected(selected_columns.get("y1", "y1")),
            "y3": _is_selected(selected_columns.get("y3", "y3")),
            "y2": _is_selected(selected_columns.get("y2", "Derivative")),
            "z": _is_selected(selected_columns.get("z", "Temp")),
            "z2": _is_selected(selected_columns.get("z2", "Temp 2")),
        }

        dataset_meta = {
            "y1": {
                "series": prepared_series_np.get(
                    "y1", prepared_series_map.get("y1", globals().get("y1"))
                ),
                "label": label_y1,
                "axis_type": "primary",
                "selected": selected_map["y1"],
            },
            "y3": {
                "series": prepared_series_np.get(
                    "y3", prepared_series_map.get("y3", globals().get("y3"))
                ),
                "label": label_y3,
                "axis_type": "primary",
                "selected": selected_map["y3"],
            },
            "y2": {
                "series": prepared_series_np.get(
                    "y2", prepared_series_map.get("y2", globals().get("y2"))
                ),
                "label": label_y2,
                "axis_type": "derivative",
                "selected": selected_map["y2"],
            },
            "z": {
                "series": prepared_series_np.get(
                    "z", prepared_series_map.get("z", globals().get("z"))
                ),
                "label": label_z,
                "axis_type": "temperature",
                "selected": selected_map["z"],
            },
            "z2": {
                "series": prepared_series_np.get(
                    "z2", prepared_series_map.get("z2", globals().get("z2"))
                ),
                "label": label_z2,
                "axis_type": "temperature",
                "selected": selected_map["z2"],
            },
        }
        valid_dataset_keys = set(dataset_meta.keys())

        def _resolve_dataset_key(value: Any, default_key: str) -> str:
            """Resolve dataset key.
            Used to compute dataset key before rendering or export."""
            if value is None:
                return default_key
            candidate = str(value).strip().lower()
            return candidate if candidate in valid_dataset_keys else default_key

        left_key = _resolve_dataset_key(config.get("left_key"), "y1")
        right_key = _resolve_dataset_key(config.get("right_key"), "z")
        third_key = _resolve_dataset_key(config.get("third_key"), "y2")

        def _is_available(meta: Mapping[str, Any]) -> bool:
            """Check whether it is available.
            Used to gate conditional behavior in the workflow."""
            return bool(meta.get("series") is not None and meta.get("selected"))

        temp_axis_active = bool(_enable_temp_axis) and (
            _is_available(dataset_meta["z"]) or _is_available(dataset_meta["z2"])
        )
        deriv_axis_active = bool(_enable_deriv_axis) and _is_available(dataset_meta["y2"])

        right_meta = dataset_meta.get(right_key, dataset_meta["z"])
        third_meta = dataset_meta.get(third_key, dataset_meta["y2"])
        temp_available = _is_available(dataset_meta["z"]) or _is_available(dataset_meta["z2"])
        deriv_available = _is_available(dataset_meta["y2"])

        def _temperature_meta() -> Mapping[str, Any]:
            """Perform temperature meta.
            Used to keep the workflow logic localized and testable."""
            if _is_available(dataset_meta["z"]):
                return dataset_meta["z"]
            if _is_available(dataset_meta["z2"]):
                return dataset_meta["z2"]
            return dataset_meta["z"]

        right_role = right_meta.get("axis_type", "primary")
        third_role = third_meta.get("axis_type", "primary")
        if temp_available and "temperature" not in {right_role, third_role}:
            right_meta = _temperature_meta()
            right_role = right_meta.get("axis_type", "primary")
        if temp_available and right_role == "temperature" and not _is_available(right_meta):
            right_meta = _temperature_meta()
            right_role = right_meta.get("axis_type", "primary")
        if temp_available and third_role == "temperature" and not _is_available(third_meta):
            third_meta = _temperature_meta()
            third_role = third_meta.get("axis_type", "primary")
            right_role = right_meta.get("axis_type", "primary")
        if deriv_available and "derivative" not in {right_role, third_role}:
            if third_role != "temperature":
                third_meta = dataset_meta["y2"]
            else:
                if temp_available:
                    right_meta = _temperature_meta()
                    right_role = right_meta.get("axis_type", "primary")
                third_meta = dataset_meta["y2"]
            third_role = third_meta.get("axis_type", "primary")

        right_role = right_meta.get("axis_type", "primary")
        third_role = third_meta.get("axis_type", "primary")
        if temp_available and "temperature" not in {right_role, third_role}:
            right_meta = _temperature_meta()

        default_zorders = {"y1": 2, "y3": 1, "y2": 3, "z": 3, "z2": 3}
        resolved_trace_zorders: Dict[str, float] = {}
        # Iterate over default_zorders to resolve effective z-order per trace key.
        for trace_key, default_z in default_zorders.items():
            resolved_trace_zorders[trace_key] = _resolve_effective_trace_zorder(
                default_z,
                series_key=trace_key,
                scatter_series_configs=scatter_series_configs,
            )

        def _axis_role_layer_zorder(
            series_keys: Sequence[str], role_bias: float, fallback: float
        ) -> float:
            """Resolve one axis z-order from active trace z-order values.

            Purpose:
                Compute axis-level draw order from effective z-orders assigned to
                traces attached to that axis role.
            Why:
                Combined refresh must keep cross-axis foreground/background intent
                aligned with current per-trace priority/override settings.
            Inputs:
                series_keys: Trace keys mapped to one axis role.
                role_bias: Small tie-breaker for deterministic equal-z ordering.
                fallback: Fallback z-order when no active traces are present.
            Outputs:
                Float axis z-order value.
            Side Effects:
                None.
            Exceptions:
                Invalid/non-finite trace values are skipped.
            """
            z_values: List[float] = []
            # Iterate over series_keys and collect active trace z-order values.
            for trace_key in series_keys:
                meta = dataset_meta.get(trace_key, {})
                if not _is_available(meta):
                    continue
                candidate = resolved_trace_zorders.get(trace_key)
                if candidate is not None and math.isfinite(candidate):
                    z_values.append(float(candidate))
            base_value = max(z_values) if z_values else float(fallback)
            return float(base_value + role_bias)

        axis_layer_zorders = {
            "left": _axis_role_layer_zorder(
                ("y1", "y3"), role_bias=0.01, fallback=0.0
            ),
            "right": _axis_role_layer_zorder(
                ("z", "z2"), role_bias=0.02, fallback=0.0
            ),
            "third": _axis_role_layer_zorder(("y2",), role_bias=0.03, fallback=0.0),
        }
        axis_layer_zorders["overlay"] = max(axis_layer_zorders.values()) + 1000.0
        legend_layer_zorder = float(axis_layer_zorders["overlay"] + 1000.0)

        def _apply_combined_legend_layer(legend_obj: Any) -> None:
            """Force one combined legend above all axes during reuse updates.

            Purpose:
                Keep combined legends visible while display refresh reuses artists.
            Why:
                Dynamic axis z-orders can exceed default legend layering, so each
                refresh must reassert legend z-order dominance.
            Inputs:
                legend_obj: Combined legend artist to lift.
            Outputs:
                None.
            Side Effects:
                Updates legend z-order when set_zorder is available.
            Exceptions:
                Invalid artists are ignored without raising.
            """
            if legend_obj is None:
                return
            setter = getattr(legend_obj, "set_zorder", None)
            if callable(setter):
                try:
                    setter(legend_layer_zorder)
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        primary_meta = dataset_meta.get(left_key, dataset_meta["y1"])
        label_overrides = (
            config.get("axis_label_overrides")
            if isinstance(config.get("axis_label_overrides"), dict)
            else {}
        )
        pad_overrides = (
            config.get("labelpad_overrides")
            if isinstance(config.get("labelpad_overrides"), dict)
            else {}
        )

        def _label_or_default(key: str, default: str) -> str:
            """Return default value.
            Used by label or workflows to return value."""
            raw = label_overrides.get(key)
            if raw is None:
                return default
            text = str(raw).strip()
            return _fmt_safe(text) if text else default

        x_label_text = _label_or_default("x", default_x_label)

        def _pad_or_default(key: str, default: float) -> float:
            """Pad or default.
            Used to add spacing to or default for layout alignment."""
            try:
                candidate = float(pad_overrides.get(key))
                if math.isfinite(candidate):
                    return candidate
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            return default

        primary_labelpad = _pad_or_default("primary", yaxis_labelpad_amount)
        temp_labelpad = _pad_or_default("temperature", twinyaxis_labelpad_amount)
        deriv_labelpad = _pad_or_default("derivative", 15)
        label_fontsize = _sanitize_spacing_value(
            config.get("label_font_value"),
            DEFAULT_COMBINED_LABEL_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )
        tick_fontsize = _sanitize_spacing_value(
            config.get("tick_font_value"),
            DEFAULT_COMBINED_TICK_FONTSIZE,
            MIN_COMBINED_FONT_SIZE,
            MAX_COMBINED_FONT_SIZE,
        )

        if ax is not None:
            ax.set_xlim(min_time, max_time)
            ax.set_ylim(min_y, max_y)
            ax.set_zorder(axis_layer_zorders["left"])
            # Combined reuse can preserve older axis patches, so force the primary
            # patch transparent each refresh to avoid cross-axis occlusion.
            ax.patch.set_visible(False)
            ax.set_facecolor("none")
            ax.set_ylabel(
                _label_or_default("primary", primary_meta.get("label", "")),
                labelpad=primary_labelpad,
                fontsize=label_fontsize,
                fontfamily=family_value if family_value else None,
            )
        if ax_overlay is not None:
            # Keep the overlay axis aligned with pressure axis limits on reuse.
            ax_overlay.set_ylim(min_y, max_y)
            ax_overlay.set_zorder(axis_layer_zorders["overlay"])
            ax_overlay.set_autoscaley_on(False)
            ax_overlay.patch.set_visible(False)
            ax_overlay.set_facecolor("none")

        if ax_temp is not None:
            try:
                ax_temp.set_visible(bool(temp_axis_active))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if temp_axis_active:
                ax_temp.set_ylim(twin_y_min, twin_y_max)
                ax_temp.set_zorder(axis_layer_zorders["right"])
                ax_temp.patch.set_visible(False)
                ax_temp.set_facecolor("none")
                ax_temp.set_ylabel(
                    _label_or_default("temperature", right_meta.get("label", "")),
                    labelpad=temp_labelpad,
                    fontsize=label_fontsize,
                    fontfamily=family_value if family_value else None,
                    rotation=-90,
                    color="black",
                )
                ax_temp.tick_params(axis="y", labelcolor="black", labelsize=tick_fontsize)

        if ax_deriv is not None:
            try:
                ax_deriv.set_visible(bool(deriv_axis_active))
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if deriv_axis_active:
                ax_deriv.set_ylim(deriv_y_min, deriv_y_max)
                ax_deriv.set_zorder(axis_layer_zorders["third"])
                ax_deriv.patch.set_visible(False)
                ax_deriv.set_facecolor("none")
                ax_deriv.set_ylabel(
                    _label_or_default("derivative", third_meta.get("label", "")),
                    labelpad=deriv_labelpad,
                    fontsize=label_fontsize,
                    fontfamily=family_value if family_value else None,
                    rotation=-90,
                    color="black",
                )
                ax_deriv.tick_params(axis="y", labelcolor="black", labelsize=tick_fontsize)

        show_derivative_zero_line = bool(
            ax_deriv is not None
            and deriv_axis_active
            and str(third_role).strip().lower() == "derivative"
        )
        _ensure_combined_derivative_zero_line(
            fig,
            ax_overlay,
            ax_deriv,
            visible=show_derivative_zero_line,
            zorder=6.0,
        )

        if ax is not None:
            if auto_time_ticks:
                ax.xaxis.set_major_locator(AutoLocator())
                ax.xaxis.set_minor_locator(AutoMinorLocator())
            else:
                ax.xaxis.set_major_locator(MultipleLocator(xmaj_tick))
                ax.xaxis.set_minor_locator(MultipleLocator(xmin_tick))
            _apply_axis_ticks(ax, auto_y_ticks, ymaj_tick, ymin_tick)
            ax.tick_params(
                axis="both", which="major", labelcolor="black", labelsize=tick_fontsize
            )

        if ax_temp is not None and temp_axis_active:
            _apply_axis_ticks(ax_temp, auto_temp_ticks, twin_maj_tick, twin_min_tick)
        if ax_deriv is not None and deriv_axis_active:
            _apply_axis_ticks(ax_deriv, auto_deriv_ticks, deriv_maj_tick, deriv_min_tick)

        _apply_tick_font(ax)
        _apply_tick_font(ax_temp)
        _apply_tick_font(ax_deriv)

        line_map = getattr(fig, "_gl260_combined_line_map", None)
        if not isinstance(line_map, dict) or not line_map:
            return fig
        self._annotation_renderer.invalidate_trace_filter_baselines(fig, line_map.keys())

        series_map = data_ctx.get("series") or {}
        series_np = data_ctx.get("series_np") or {}
        series_nan_mask = data_ctx.get("series_nan_mask") or {}
        series_values = {
            "y1": series_np.get("y1", series_map.get("y1", globals().get("y1"))),
            "y3": series_np.get("y3", series_map.get("y3", globals().get("y3"))),
            "y2": series_np.get("y2", series_map.get("y2", globals().get("y2"))),
            "z": series_np.get("z", series_map.get("z", globals().get("z"))),
            "z2": series_np.get("z2", series_map.get("z2", globals().get("z2"))),
        }
        x_values = series_np.get("x", series_map.get("x", globals().get("x")))
        x_plot, decimated = self._combined_preview_decimate(
            fig,
            canvas,
            x_values,
            series_values,
            series_arrays=series_np,
            series_nan_mask=series_nan_mask,
        )

        if bool(config.get("show_cycle_markers")) and markers_overlay and cycle_style:
            marker_state = getattr(fig, "_gl260_cycle_marker_artists", None)
            peak_artist = (
                marker_state.get("peak") if isinstance(marker_state, dict) else None
            )
            trough_artist = (
                marker_state.get("trough") if isinstance(marker_state, dict) else None
            )
            peaks = markers_overlay.get("peak_points") or []
            troughs = markers_overlay.get("trough_points") or []

            def _apply_marker_offsets(artist, points):
                """Perform apply marker offsets.
                Used to update cycle marker positions on reuse."""
                if artist is None:
                    return
                if points:
                    try:
                        offsets = np.asarray(points, dtype=float)
                    except Exception:
                        offsets = None
                    if offsets is not None:
                        artist.set_offsets(offsets)
                        try:
                            artist.set_visible(True)
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass
                else:
                    try:
                        artist.set_offsets(np.zeros((0, 2), dtype=float))
                        artist.set_visible(False)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            _apply_marker_offsets(peak_artist, peaks)
            _apply_marker_offsets(trough_artist, troughs)

        legend_dirty = state.get("legend_sig") != legend_sig
        # Iterate over items from line_map to apply the per-item logic.
        for key, artist in line_map.items():
            if artist is None:
                continue
            meta = dataset_meta.get(key)
            if not meta or not _is_available(meta):
                try:
                    if artist.get_visible():
                        artist.set_visible(False)
                        legend_dirty = True
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                continue
            try:
                if not artist.get_visible():
                    artist.set_visible(True)
                    legend_dirty = True
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            # Reapply per-trace z-order on each refresh so Data Trace Settings
            # updates take effect even when figure artists are reused in-place.
            resolved_zorder = resolved_trace_zorders.get(key, 2.0)
            try:
                resolved_zorder = float(resolved_zorder)
            except Exception:
                resolved_zorder = 2.0
            if not math.isfinite(resolved_zorder):
                resolved_zorder = 2.0
            try:
                artist.set_zorder(resolved_zorder)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            y_vals = decimated.get(key)
            if y_vals is None or x_plot is None:
                continue
            if isinstance(artist, Line2D):
                artist.set_data(x_plot, y_vals)
            elif hasattr(artist, "set_offsets"):
                try:
                    offsets = np.column_stack([x_plot, y_vals])
                except Exception:
                    offsets = None
                if offsets is not None:
                    artist.set_offsets(offsets)
            new_label = None
            if key == "y1":
                new_label = label_y1
            elif key == "y3":
                new_label = label_y3
            elif key == "y2":
                new_label = label_y2
            elif key == "z":
                new_label = label_z
            elif key == "z2":
                new_label = label_z2
            if new_label is not None:
                try:
                    if artist.get_label() != new_label:
                        artist.set_label(new_label)
                        legend_dirty = True
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass

        elements_map = settings.get("plot_elements", {})
        combined_elements = (
            elements_map.get("fig_combined_triple_axis")
            if isinstance(elements_map, Mapping)
            else []
        )
        scatter_series_settings = settings.get("scatter_series", {})
        self._annotation_renderer.apply_trace_behavior_filters(
            fig,
            combined_elements or [],
            scatter_series_settings
            if isinstance(scatter_series_settings, Mapping)
            else {},
        )

        legend_handles: List[Any] = []
        # Iterate over ("y1", "y3", "z", "z2", "y2") to apply the per-item logic.
        for key in ("y1", "y3", "z", "z2", "y2"):
            artist = line_map.get(key)
            meta = dataset_meta.get(key)
            if artist is None or not meta or not _is_available(meta):
                continue
            legend_handles.append(artist)

        if legend_dirty:
            # Iterate over self._collect_combined_legends(fig) to apply the per-item logic.
            for legend in self._collect_combined_legends(fig):
                if getattr(legend, "_combined_main_legend", False):
                    try:
                        legend.remove()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
            legend_labels = [_text_safe(handle.get_label()) for handle in legend_handles]
            legend_handles, legend_labels = _filter_none_legend_entries(
                legend_handles, legend_labels
            )
            main_center_x = fig.subplotpars.left + (
                (fig.subplotpars.right - fig.subplotpars.left) / 2.0
            )
            try:
                pos = ax.get_position()
                main_center_x = pos.x0 + (pos.width / 2.0)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            if legend_handles:
                wrap_enabled = bool(config.get("wrap_enabled"))
                legend_rows_value = config.get("legend_rows_value")
                if wrap_enabled:
                    rows_value = 2 if legend_rows_value is None else legend_rows_value
                    try:
                        rows_value = int(rows_value)
                    except (TypeError, ValueError):
                        rows_value = 1
                    rows_value = max(1, rows_value)
                    ncol = max(1, math.ceil(len(legend_handles) / rows_value))
                else:
                    ncol = min(4, len(legend_handles))
                wrapped_labels = [_wrap_legend_label(label) for label in legend_labels]
                legend_markerscale = _coerce_float(
                    settings.get("combined_legend_markerscale")
                )
                if legend_markerscale is None:
                    base_font = legend_font_value if legend_font_value else 1.0
                    legend_markerscale = base_font / DEFAULT_COMBINED_LEGEND_FONTSIZE
                main_legend = fig.legend(
                    handles=legend_handles,
                    labels=wrapped_labels,
                    loc="lower center",
                    bbox_to_anchor=(main_center_x, 0.0),
                    columnspacing=1.0,
                    handletextpad=0.5,
                    fontsize=legend_font_value,
                    prop={"family": family_value, "size": legend_font_value},
                    markerscale=legend_markerscale,
                    ncol=ncol,
                    **_legend_shadowbox_kwargs(),
                )
                try:
                    main_legend._combined_main_legend = True  # type: ignore[attr-defined]
                    main_legend._gl260_markerscale = legend_markerscale  # type: ignore[attr-defined]
                    main_legend._gl260_legend_role = "main"  # type: ignore[attr-defined]
                    main_legend._gl260_markerscale_base_font = (  # type: ignore[attr-defined]
                        DEFAULT_COMBINED_LEGEND_FONTSIZE
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                _apply_combined_legend_layer(main_legend)
                legend_anchor = config.get("legend_anchor")
                legend_loc = config.get("legend_loc")
                if legend_anchor is not None:
                    _apply_legend_anchor_to_artist(
                        main_legend,
                        legend_anchor,
                        transform=fig.transFigure,
                        loc_override=legend_loc,
                    )
                elif legend_loc is not None:
                    try:
                        main_legend.set_loc(_normalize_legend_loc_value(legend_loc))
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

        cycle_legend_dirty = cycle_overlay_changed and not overlay_rebuild_applied
        if (
            cycle_legend_dirty
            and bool(config.get("show_cycle_legend"))
            and isinstance(legend_overlay, dict)
            and ax is not None
        ):
            cycle_anchor_ref_axis = None
            if config.get("cycle_legend_anchor_space") == "axes":
                # Use the configured reference axis for axes-space anchors.
                cycle_anchor_ref_axis = _resolve_combined_cycle_ref_axis(
                    fig,
                    ax_main=ax,
                    ax_right=ax_temp,
                    ax_deriv=ax_deriv,
                    ref_axis_key=settings.get("combined_cycle_legend_ref_axis"),
                )
                if cycle_anchor_ref_axis is None:
                    cycle_anchor_ref_axis = ax
            # Iterate over self._collect_combined_legends(fig) to apply the per-item logic.
            for legend in self._collect_combined_legends(fig):
                if self._is_combined_cycle_legend(legend):
                    try:
                        legend.remove()
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass

            def _cycle_marker_artist(marker, color):
                """Perform cycle marker artist.
                Used to keep the workflow logic localized and testable."""
                size_val = None
                try:
                    size_val = max(4.0, math.sqrt(float(cycle_style["marker_size"])))
                except Exception:
                    size_val = 6.0
                return Line2D(
                    [], [], linestyle="None", marker=marker, color=color, markersize=size_val
                )

            def _add_cycle_legend(
                ax_target,
                peak_artist,
                trough_artist,
                anchor=None,
                loc_override=None,
                anchor_space=None,
            ):
                """Perform add cycle legend.
                Used to keep the workflow logic localized and testable."""
                if not (legend_overlay and cycle_style):
                    return None
                handles_cycle: List[Any] = []
                labels_cycle: List[str] = []
                if peak_artist is not None:
                    handles_cycle.append(peak_artist)
                    labels_cycle.append(_text_safe("Peak"))
                elif cycle_style:
                    handles_cycle.append(
                        _cycle_marker_artist(
                            cycle_style["peak_marker"], cycle_style["peak_color"]
                        )
                    )
                    labels_cycle.append(_text_safe("Peak"))
                if trough_artist is not None:
                    handles_cycle.append(trough_artist)
                    labels_cycle.append(_text_safe("Trough"))
                elif cycle_style:
                    handles_cycle.append(
                        _cycle_marker_artist(
                            cycle_style["trough_marker"], cycle_style["trough_color"]
                        )
                    )
                    labels_cycle.append(_text_safe("Trough"))
                cycles_list = legend_overlay.get("cycles") or []
                total_drop_val = legend_overlay.get("total_drop", 0.0)
                try:
                    total_drop_val = float(total_drop_val)
                except Exception:
                    total_drop_val = 0.0
                handles_cycle.append(Line2D([], [], color="none"))
                labels_cycle.append(_text_safe(f"Cycles: {len(cycles_list)}"))
                import matplotlib.patches as mpatches

                handles_cycle.append(mpatches.Patch(color="none"))
                labels_cycle.append(_text_safe(f"Total ΔP: {total_drop_val:.2f} PSI"))
                if bool(config.get("include_moles_core")):
                    # Iterate over moles_lines or [] to apply the per-item logic.
                    for line in moles_lines or []:
                        handles_cycle.append(mpatches.Patch(color="none"))
                        labels_cycle.append(_text_safe(line))
                cycle_legend_font_value = config.get(
                    "cycle_legend_font_value", legend_font_value
                )
                cycle_legend_font_value = _sanitize_spacing_value(
                    cycle_legend_font_value,
                    legend_font_value,
                    MIN_COMBINED_FONT_SIZE,
                    MAX_COMBINED_FONT_SIZE,
                )
                cycle_legend_markerscale = _coerce_float(
                    settings.get("combined_cycle_legend_markerscale")
                )
                if cycle_legend_markerscale is None:
                    base_font = cycle_legend_font_value if cycle_legend_font_value else 1.0
                    cycle_legend_markerscale = (
                        base_font / DEFAULT_COMBINED_LEGEND_FONTSIZE
                    )
                legend_kwargs = {
                    "fontsize": cycle_legend_font_value,
                    "prop": {"family": family_value, "size": cycle_legend_font_value},
                    "markerscale": cycle_legend_markerscale,
                    **_legend_shadowbox_kwargs(),
                }
                loc_value = None
                if loc_override is not None:
                    loc_value = _normalize_legend_loc_value(loc_override)
                if loc_value is None:
                    loc_value = "upper right"
                if loc_value is not None:
                    legend_kwargs["loc"] = loc_value
                anchor_value = _validated_anchor_pair(anchor)
                if anchor_value is None and isinstance(loc_value, str):
                    loc_key = loc_value.strip().lower()
                    anchor_map = {
                        "upper right": (0.98, 0.98),
                        "upper left": (0.02, 0.98),
                        "lower right": (0.98, 0.02),
                        "lower left": (0.02, 0.02),
                        "center right": (0.98, 0.5),
                        "center left": (0.02, 0.5),
                        "upper center": (0.5, 0.98),
                        "lower center": (0.5, 0.02),
                        "center": (0.5, 0.5),
                    }
                    anchor_value = anchor_map.get(loc_key, (0.98, 0.98))
                if anchor_value is not None:
                    legend_kwargs["bbox_to_anchor"] = anchor_value
                legend = fig.legend(handles_cycle, labels_cycle, **legend_kwargs)
                if anchor_value is not None:
                    try:
                        transform = None
                        if anchor_space == "axes" and ax_target is not None:
                            transform = ax_target.transAxes
                        elif anchor_space in {"figure", None}:
                            transform = fig.transFigure
                        if transform is None:
                            legend.set_bbox_to_anchor(anchor_value)
                        else:
                            legend.set_bbox_to_anchor(anchor_value, transform=transform)
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                try:
                    legend._cycle_overlay_legend = True  # type: ignore[attr-defined]
                    legend._combined_cycle_legend = True  # type: ignore[attr-defined]
                    legend._gl260_legend_role = "cycle"  # type: ignore[attr-defined]
                    legend._gl260_markerscale = legend_kwargs.get(
                        "markerscale"
                    )  # type: ignore[attr-defined]
                    legend._gl260_markerscale_base_font = (  # type: ignore[attr-defined]
                        DEFAULT_COMBINED_LEGEND_FONTSIZE
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                _apply_combined_legend_layer(legend)
                defer_drag_enable = False
                try:
                    stored_mode = settings.get("combined_cycle_legend_anchor_mode")
                    stored_loc = _normalize_legend_loc_value(
                        settings.get("combined_cycle_legend_loc")
                    )
                    if stored_mode == "loc_tuple":
                        defer_drag_enable = True
                except Exception:
                    defer_drag_enable = False
                if not defer_drag_enable:
                    _make_legend_draggable(legend)
                return legend

            marker_state = getattr(fig, "_gl260_cycle_marker_artists", None)
            peak_artist = marker_state.get("peak") if isinstance(marker_state, dict) else None
            trough_artist = marker_state.get("trough") if isinstance(marker_state, dict) else None
            _add_cycle_legend(
                cycle_anchor_ref_axis or ax,
                peak_artist,
                trough_artist,
                anchor=config.get("cycle_legend_anchor"),
                loc_override=config.get("cycle_legend_loc"),
                anchor_space=config.get("cycle_legend_anchor_space"),
            )

        # Apply legend z-order on every refresh so existing legends remain above
        # high-priority axes even when no legend rebuild occurs.
        # Iterate over self._collect_combined_legends(fig) to apply the per-item logic.
        for legend in self._collect_combined_legends(fig):
            _apply_combined_legend_layer(legend)

        try:
            cycle_legend_font_value = config.get(
                "cycle_legend_font_value", legend_font_value
            )
            _enforce_gl260_legend_sizing(
                fig,
                legend_font_value,
                cycle_legend_font_value,
                font_family=family_value,
            )
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        title_display = svg_safe(title_text)
        suptitle_display = svg_safe(suptitle_text)
        if ax is not None:
            title_artist = getattr(fig, "_gl260_title_text", None)
            if title_artist is None:
                title_artist = ax.set_title(title_display)
                try:
                    fig._gl260_title_text = title_artist  # type: ignore[attr-defined]
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            try:
                title_artist.set_text(title_display)
                title_artist.set_fontsize(config.get("title_font_value"))
                title_artist.set_pad(config.get("title_pad_pts"))
                if family_value:
                    title_artist.set_fontfamily(family_value)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        suptitle_artist = getattr(fig, "_gl260_suptitle_text", None)
        if suptitle_artist is not None:
            try:
                suptitle_artist.set_text(suptitle_display)
                suptitle_artist.set_fontsize(config.get("suptitle_font_value"))
                if family_value:
                    suptitle_artist.set_fontfamily(family_value)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        xlabel_artist = getattr(fig, "_gl260_xlabel_text", None)
        if xlabel_artist is not None:
            try:
                xlabel_artist.set_text(x_label_text)
                xlabel_artist.set_fontsize(label_fontsize)
                if family_value:
                    xlabel_artist.set_fontfamily(family_value)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        fig._gl260_title_state = {
            "suptitle": suptitle_display,
            "title_fs": config.get("title_font_value"),
            "suptitle_fs": config.get("suptitle_font_value"),
            "font_family": family_value,
            "title_pad_pts": config.get("title_pad_pts"),
            "suptitle_pad_pts": config.get("suptitle_pad_pts"),
            "suptitle_y": config.get("suptitle_y_value"),
        }

        # Layout signature captures margin/legend inputs so we only re-solve when
        # layout-affecting settings change, avoiding unnecessary redraw churn.
        legend_text_sig = self._combined_legend_text_signature(fig)
        plot_elements_sig = self._plot_elements_signature("fig_combined_triple_axis")
        layout_sig = self._combined_layout_signature(
            config,
            args,
            fig_size,
            legend_text_sig=legend_text_sig,
            plot_elements_sig=plot_elements_sig,
        )
        try:
            fig._gl260_combined_layout_sig = layout_sig  # type: ignore[attr-defined]
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass
        layout_dirty = self._combined_layout_dirty or self._combined_layout_state != layout_sig

        # Preview layout uses the same inference as export but limits passes to
        # keep interactive rendering stable and fast.
        layout_mgr = PlotLayoutManager(
            fig,
            mode="display",
            baseline_margins=config.get("baseline_margins"),
            left_pad_pct=config.get("left_padding_pct", 0.0),
            right_pad_pct=config.get("right_padding_pct", 0.0),
            export_pad_pts=config.get("export_pad_pts", 0.0),
            legend_gap_pts=config.get("legend_gap_value", DEFAULT_COMBINED_LEGEND_GAP_PTS),
            xlabel_tick_gap_pts=config.get("xlabel_tick_gap_value", DEFAULT_COMBINED_XLABEL_TICK_GAP_PTS),
            legend_margin_pts=config.get("legend_margin_value", DEFAULT_COMBINED_LEGEND_MARGIN_PTS),
            title_pad_pts=config.get("title_pad_pts", DEFAULT_COMBINED_TITLE_PAD_PTS),
            suptitle_pad_pts=config.get("suptitle_pad_pts", DEFAULT_COMBINED_SUPTITLE_PAD_PTS),
            suptitle_y=config.get("suptitle_y_value", DEFAULT_COMBINED_SUPTITLE_Y),
            top_margin_pct=config.get("top_margin_pct", DEFAULT_COMBINED_TOP_MARGIN_PCT),
            legend_anchor=config.get("legend_anchor"),
            legend_anchor_y=config.get("legend_anchor_y"),
            xlabel_pad_pts=config.get("xlabel_pad_value") or 0.0,
        )
        layout_mgr.register_axes(ax, ax_temp, ax_deriv)
        layout_mgr.register_artist("title", getattr(fig, "_gl260_title_text", None))
        layout_mgr.register_artist("suptitle", getattr(fig, "_gl260_suptitle_text", None))
        layout_mgr.register_artist("xlabel", getattr(fig, "_gl260_xlabel_text", None))
        main_legend = None
        cycle_legend = None
        # Iterate over self._collect_combined_legends(fig) to apply the per-item logic.
        for legend in self._collect_combined_legends(fig):
            if self._is_combined_cycle_legend(legend):
                cycle_legend = legend
            elif getattr(legend, "_combined_main_legend", False):
                main_legend = legend
        axis_offset_values = config.get("axis_offset_values")
        layout_mgr.register_artist("plot_legend", main_legend)
        layout_mgr.register_artist("cycle_legend", cycle_legend)
        layout_mgr.set_legend_alignment(config.get("legend_alignment_value", "center"))
        if cycle_legend is not None:
            applied_tuple = False
            try:
                applied_tuple = self._apply_cycle_legend_loc_tuple_axes(
                    fig,
                    cycle_legend,
                    allow_draw=False,
                    clamp=True,
                )
            except Exception:
                applied_tuple = False
            if not applied_tuple and axis_offset_values is not None:
                try:
                    # Legacy fallback: keep offsets working, then migrate to canonical tuple.
                    ref_axis = _resolve_combined_cycle_ref_axis(
                        fig,
                        ref_axis_key=settings.get("combined_cycle_legend_ref_axis"),
                    )
                    loc_value = _resolve_combined_cycle_legend_loc()
                    applied_offset = _apply_cycle_legend_axis_offset(
                        fig,
                        cycle_legend,
                        ref_axis,
                        settings.get("combined_cycle_legend_ref_corner"),
                        axis_offset_values[0],
                        axis_offset_values[1],
                        loc_value,
                        allow_draw=False,
                    )
                    if applied_offset:
                        migrated = self._capture_cycle_legend_loc_tuple_axes(
                            fig,
                            cycle_legend,
                            source="sync",
                        )
                        if migrated:
                            _save_settings_to_disk()
                            axis_offset_values = None
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
        if layout_dirty:
            layout_start = time.perf_counter() if perf_run is not None else None
            layout_mgr.solve(max_passes=1, allow_draw=False)
            if perf_run is not None and layout_start is not None:
                stages = perf_run.setdefault("stages", {})
                combined_stage = stages.setdefault("combined", {})
                combined_stage["layout_ms"] = (
                    time.perf_counter() - layout_start
                ) * 1000.0
            self._combined_layout_state = layout_sig
            self._combined_layout_dirty = False
        fig._gl260_layout_manager = layout_mgr  # type: ignore[attr-defined]

        try:
            state["legend_sig"] = legend_sig
            state["cycle_overlay_sig"] = cycle_overlay_sig
            state["layout_sig"] = layout_sig
            state["line_map"] = line_map
            state["marker_artists"] = getattr(fig, "_gl260_cycle_marker_artists", None)
            self._combined_plot_state = state
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if fig.canvas is not None:
            try:
                fig.canvas.draw_idle()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
        return fig

    def _build_combined_triple_axis_from_state(
        self,
        *,
        args: Optional[Tuple[Any, ...]] = None,
        fig_size: Optional[Tuple[float, float]] = None,
        mode: str = "display",
        reuse: bool = False,
        canvas: Optional[FigureCanvasTkAgg] = None,
        render_ctx: Optional[RenderContext] = None,
        perf_run: Optional[Dict[str, Any]] = None,
    ) -> Optional[Figure]:
        """Build the combined triple-axis figure from state or render context.

        Purpose:
            Produce the combined triple-axis figure for preview/export workflows.
        Why:
            Centralizes combined plot assembly while honoring reuse and caching.
        Args:
            args: Optional plot argument tuple for axis limits/ticks/titles.
            fig_size: Optional (width, height) in inches for display rendering.
            mode: "display" or "export" to control layout behavior.
            reuse: When True, attempt to reuse existing figure artists.
            canvas: Optional Tk canvas used for sizing and draw operations.
            render_ctx: Optional RenderContext for prepared data/overlays.
            perf_run: Optional performance diagnostics accumulator.
        Returns:
            The combined Matplotlib Figure, or None if inputs are invalid.
        Side Effects:
            May update combined plot state, settings snapshots, and log debug/perf.
        Exceptions:
            Errors are caught to avoid breaking UI flows.
        """

        try:
            existing_state = (
                self._combined_plot_state
                if isinstance(self._combined_plot_state, dict)
                else {}
            )
            existing_fig = existing_state.get("fig")
        except Exception:
            existing_fig = None
        existing_fig_id = id(existing_fig) if existing_fig is not None else None
        self._dbg("plotting.render", "Combined build start fig_id=%s", existing_fig_id)

        def _debug_build_end(fig: Optional[Figure]) -> None:
            """Log the combined build end marker.

            Purpose:
                Emit a debug marker after combined build completion.
            Why:
                Helps correlate build timing with render events.
            Args:
                fig: Figure returned by the build path.
            Returns:
                None.
            Side Effects:
                Writes to the debug logger when plotting.render is enabled.
            Exceptions:
                Best-effort guards suppress logging failures.
            """
            try:
                fig_id = id(fig) if fig is not None else None
            except Exception:
                fig_id = None
            self._dbg("plotting.render", "Combined build end fig_id=%s", fig_id)

        data_ctx = render_ctx.data_ctx if render_ctx else {}
        style_ctx = render_ctx.style_ctx if render_ctx else {}
        overlay_ctx = render_ctx.overlay_ctx if render_ctx else {}
        scatter_config = style_ctx.get("scatter_config")
        scatter_series_configs = style_ctx.get("scatter_series_configs")
        cycle_overlay = overlay_ctx.get("cycle_overlay")

        # Render context lets export/report code bypass UI globals by injecting
        # prepared data, overlays, and style decisions in a consistent payload.

        if self.df is None:

            _debug_build_end(None)
            return None

        if render_ctx is None:
            try:
                ignore_min_drop = bool(getattr(self, "_cycle_last_ignore_min_drop", True))
                self._refresh_final_report_cycle_snapshot(
                    ignore_min_drop=ignore_min_drop
                )
                self._prime_core_cycle_overlay_globals()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        # If caller did not supply plot args, rebuild them from UI state and
        # fall back to the last successful snapshot to keep exports resilient.
        if args is None:

            try:

                self._prepare_series_globals()

                args = self._collect_plot_args()

            except Exception:

                args = getattr(self, "_last_plot_args", None)

        if not args or len(args) < 24:

            _debug_build_end(None)
            return None

        if render_ctx is None:
            try:
                ignore_min_drop = bool(getattr(self, "_cycle_last_ignore_min_drop", True))
                self._refresh_final_report_cycle_snapshot(ignore_min_drop=ignore_min_drop)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

            try:
                self._prime_core_cycle_overlay_globals()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass

        series_map = data_ctx.get("series") or {}
        required_series = {
            "y1": series_map.get("y1", globals().get("y1")),
            "y3": series_map.get("y3", globals().get("y3")),
            "y2": series_map.get("y2", globals().get("y2")),
            "z": series_map.get("z", globals().get("z")),
            "z2": series_map.get("z2", globals().get("z2")),
        }
        selected_columns = data_ctx.get("selected_columns") or globals().get(
            "selected_columns", {}
        )
        missing_required = [
            self._combined_dataset_label(key)
            # Iterate to apply the per-item logic.
            for key, series in required_series.items()
            if series is None and _is_selected(selected_columns.get(key, key))
        ]
        if missing_required:
            try:
                messagebox.showerror(
                    "Missing Columns",
                    "The combined triple-axis plot requires the following datasets: "
                    + ", ".join(missing_required),
                )
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            _debug_build_end(None)
            return None

        config = self._combined_plot_config(args, mode)
        if config is None:
            _debug_build_end(None)
            return None

        perf_start = time.perf_counter() if perf_run is not None else None
        if reuse and mode == "display":
            with self._perf_time("plotting.render", "combined_refresh"):
                fig = self._update_combined_triple_axis_display(
                    config,
                    args,
                    fig_size,
                    canvas,
                    render_ctx=render_ctx,
                    perf_run=perf_run,
                )
            if perf_start is not None and perf_run is not None:
                stages = perf_run.setdefault("stages", {})
                combined_stage = stages.setdefault("combined", {})
                combined_stage["ms"] = (time.perf_counter() - perf_start) * 1000.0
                combined_stage["path"] = "reuse"
            self._mark_combined_figure_real(fig)
            _debug_build_end(fig)
            return fig

        base_args = config["base_args"]
        deriv_offset = config["deriv_offset"]
        legend_rows_value = config["legend_rows_value"]
        wrap_enabled = config["wrap_enabled"]
        legend_alignment_value = config["legend_alignment_value"]
        legend_gap_value = config["legend_gap_value"]
        xlabel_tick_gap_value = config["xlabel_tick_gap_value"]
        legend_margin_value = config["legend_margin_value"]
        left_padding_pct = config["left_padding_pct"]
        right_padding_pct = config["right_padding_pct"]
        export_pad_pts = config["export_pad_pts"]
        title_pad_pts = config["title_pad_pts"]
        suptitle_pad_pts = config["suptitle_pad_pts"]
        suptitle_y_value = config["suptitle_y_value"]
        top_margin_pct = config["top_margin_pct"]
        suptitle_font_value = config["suptitle_font_value"]
        title_font_value = config["title_font_value"]
        label_font_value = config["label_font_value"]
        tick_font_value = config["tick_font_value"]
        legend_font_value = config["legend_font_value"]
        font_family_value = config["font_family_value"]
        left_key = config["left_key"]
        right_key = config["right_key"]
        third_key = config["third_key"]
        show_cycle_markers = config["show_cycle_markers"]
        show_cycle_legend = config["show_cycle_legend"]
        include_moles_core = config["include_moles_core"]
        legend_anchor = config["legend_anchor"]
        cycle_legend_anchor = config["cycle_legend_anchor"]
        legend_loc = config["legend_loc"]
        cycle_legend_loc = config["cycle_legend_loc"]
        cycle_legend_anchor_space = config["cycle_legend_anchor_space"]
        profile_margins = config["baseline_margins"]
        labelpad_overrides = config["labelpad_overrides"]
        axis_label_overrides = config["axis_label_overrides"]
        layout_section = config["layout_section"]
        axis_offset_values = config["axis_offset_values"]
        profile_legend_anchor_y = config["legend_anchor_y"]
        xlabel_pad_value = config["xlabel_pad_value"]

        with self._perf_time("plotting.render", "combined_build"):
            fig = build_combined_triple_axis_figure(
                *base_args,
                deriv_axis_offset=deriv_offset,
                legend_wrap=wrap_enabled,
                legend_rows=legend_rows_value,
                legend_alignment=legend_alignment_value,
                legend_label_gap_pts=legend_gap_value,
                xlabel_tick_gap_pts=xlabel_tick_gap_value,
                legend_bottom_margin_pts=legend_margin_value,
                left_pad_pct=left_padding_pct,
                right_pad_pct=right_padding_pct,
                export_pad_pts=export_pad_pts,
                title_pad_pts=title_pad_pts,
                suptitle_pad_pts=suptitle_pad_pts,
                suptitle_y=suptitle_y_value,
                top_margin_pct=top_margin_pct,
                suptitle_fontsize=suptitle_font_value,
                title_fontsize=title_font_value,
                label_fontsize_override=label_font_value,
                tick_fontsize_override=tick_font_value,
                legend_fontsize_override=legend_font_value,
                cycle_legend_fontsize_override=config.get("cycle_legend_font_value"),
                font_family=font_family_value,
                axis_label_overrides=axis_label_overrides,
                labelpad_overrides=labelpad_overrides,
                left_dataset_key=left_key,
                right_dataset_key=right_key,
                third_dataset_key=third_key,
                show_cycle_markers_on_core_plots=show_cycle_markers,
                show_cycle_legend_on_core_plots=show_cycle_legend,
                include_moles_in_core_plot_legend=include_moles_core,
                legend_anchor=legend_anchor,
                cycle_legend_anchor=cycle_legend_anchor,
                legend_loc=legend_loc,
                cycle_legend_loc=cycle_legend_loc,
                cycle_legend_anchor_space=cycle_legend_anchor_space,
                baseline_margins=profile_margins,
                legend_anchor_y=profile_legend_anchor_y,
                xlabel_pad_pts=xlabel_pad_value,
                mode=mode,
                fig_size=fig_size,
                render_ctx=render_ctx,
            )
        if fig is not None:
            try:
                fig._gl260_expect_cycle_legend = bool(show_cycle_legend)
                fig._gl260_expect_cycle_markers = bool(show_cycle_markers)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                self._apply_plot_elements(fig, "fig_combined_triple_axis")
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                layout_mgr = getattr(fig, "_gl260_layout_manager", None)
                if layout_mgr is not None:
                    # Pipeline boundary: build -> apply elements -> layout solve -> render.
                    layout_start = (
                        time.perf_counter() if perf_run is not None else None
                    )
                    with self._perf_time("plotting.layout", "combined_layout"):
                        if mode == "export":
                            layout_mgr.solve()
                        else:
                            layout_mgr.solve(max_passes=1, allow_draw=False)
                    if perf_run is not None and layout_start is not None:
                        stages = perf_run.setdefault("stages", {})
                        combined_stage = stages.setdefault("combined", {})
                        combined_stage["layout_ms"] = (
                            time.perf_counter() - layout_start
                        ) * 1000.0
                    if fig.canvas is not None:
                        if mode == "export":
                            fig.canvas.draw()
                        else:
                            fig.canvas.draw_idle()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            try:
                cycle_legend_font_value = config.get(
                    "cycle_legend_font_value", legend_font_value
                )
                main_legend = None
                cycle_legend = None
                legends: List[Any] = []
                try:
                    legends.extend(
                        [lg for lg in getattr(fig, "legends", []) if lg is not None]
                    )
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
                # Iterate over fig.get_axes() to apply the per-item logic.
                for axis in fig.get_axes():
                    try:
                        lg = axis.get_legend()
                    except Exception:
                        lg = None
                    if lg is None:
                        continue
                    legends.append(lg)
                # Iterate over legends to apply the per-item logic.
                for lg in legends:
                    if getattr(lg, "_combined_main_legend", False):
                        main_legend = lg
                    if self._is_combined_cycle_legend(lg):
                        cycle_legend = lg
                _enforce_gl260_legend_sizing(
                    fig,
                    legend_font_value,
                    cycle_legend_font_value,
                    font_family=font_family_value,
                )
                legend_anchor = config.get("legend_anchor")
                legend_loc = config.get("legend_loc")
                if main_legend is not None:
                    if legend_anchor is not None:
                        _apply_legend_anchor_to_artist(
                            main_legend,
                            legend_anchor,
                            transform=fig.transFigure,
                            loc_override=legend_loc,
                        )
                    elif legend_loc is not None:
                        try:
                            main_legend.set_loc(_normalize_legend_loc_value(legend_loc))
                        except Exception:
                            # Best-effort guard; ignore failures to avoid interrupting the workflow.
                            pass
                if cycle_legend is not None:
                    applied_tuple = self._apply_cycle_legend_loc_tuple_axes(
                        fig,
                        cycle_legend,
                        allow_draw=(mode == "export"),
                        clamp=True,
                    )
                    if not applied_tuple and axis_offset_values is not None:
                        ref_axis = _resolve_combined_cycle_ref_axis(
                            fig,
                            ref_axis_key=settings.get("combined_cycle_legend_ref_axis"),
                        )
                        loc_value = _resolve_combined_cycle_legend_loc()
                        applied_offset = _apply_cycle_legend_axis_offset(
                            fig,
                            cycle_legend,
                            ref_axis,
                            settings.get("combined_cycle_legend_ref_corner"),
                            axis_offset_values[0],
                            axis_offset_values[1],
                            loc_value,
                            allow_draw=(mode == "export"),
                        )
                        if applied_offset:
                            migrated = self._capture_cycle_legend_loc_tuple_axes(
                                fig,
                                cycle_legend,
                                source="sync",
                            )
                            if migrated:
                                _save_settings_to_disk()
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            _apply_title_positions(
                fig,
                title_xy=layout_section.get("title_xy"),
                suptitle_xy=layout_section.get("suptitle_xy"),
            )
            if mode == "display":
                try:
                    legend_sig = self._combined_legend_config_signature(config)
                    cycle_overlay_sig = self._combined_cycle_overlay_signature(overlay_ctx)
                    legend_text_sig = self._combined_legend_text_signature(fig)
                    plot_elements_sig = self._plot_elements_signature(
                        "fig_combined_triple_axis"
                    )
                    layout_sig = self._combined_layout_signature(
                        config,
                        args,
                        fig_size,
                        legend_text_sig=legend_text_sig,
                        plot_elements_sig=plot_elements_sig,
                    )
                    self._combined_plot_state = {
                        "fig": fig,
                        "structure_sig": self._combined_structure_signature(
                            config,
                            args,
                            cycle_overlay=cycle_overlay,
                            scatter_config=scatter_config,
                            scatter_series_configs=scatter_series_configs,
                        ),
                        "legend_sig": legend_sig,
                        "cycle_overlay_sig": cycle_overlay_sig,
                        "layout_sig": layout_sig,
                        "line_map": getattr(fig, "_gl260_combined_line_map", None),
                        "marker_artists": getattr(fig, "_gl260_cycle_marker_artists", None),
                    }
                    self._combined_layout_state = layout_sig
                    self._combined_layout_dirty = False
                    try:
                        fig._gl260_combined_layout_sig = layout_sig  # type: ignore[attr-defined]
                    except Exception:
                        # Best-effort guard; ignore failures to avoid interrupting the workflow.
                        pass
                except Exception:
                    # Best-effort guard; ignore failures to avoid interrupting the workflow.
                    pass
            if perf_start is not None and perf_run is not None:
                stages = perf_run.setdefault("stages", {})
                combined_stage = stages.setdefault("combined", {})
                combined_stage["ms"] = (time.perf_counter() - perf_start) * 1000.0
                combined_stage["path"] = "rebuild"
        self._mark_combined_figure_real(fig)
        _debug_build_end(fig)
        return fig

    def open_cycle_analysis_tab(self):
        """Open cycle analysis tab.
        Used by UI actions to open cycle analysis tab."""

        # Validate

        if self.df is None:

            messagebox.showerror("No Data", "Load a file and sheet first (Data tab).")

            return

        if (
            not self.columns
            or self.columns.get("x") in (None, "None")
            or self.columns.get("y1") in (None, "None")
        ):

            messagebox.showerror(
                "Missing Columns", "Select at least X and y1 on the Columns tab."
            )

            return

        # Sync globals with current UI choices

        self._prepare_series_globals()

        # Create the tab if needed, focus it, and leave analysis to the user controls

        tab = self._ensure_cycle_tab(defer_build=False)

        try:

            self.nb.select(tab)

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        # If no prior analysis has run, show guidance text so the tab appears immediately

        if getattr(self, "_cycle_mask", None) is None:

            self._show_cycle_ready_message()

    def save_settings(self):
        """Save settings.
        Used when persisting settings to storage."""

        args = self._collect_plot_args()

        # Persist current UI state as the source-of-truth for next launch.
        self._save_settings_dict(args)
        try:
            self._flush_save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def close_plots(self):
        """Close plots.
        Used by UI actions to close plots safely."""

        # remove canvases/tabs

        self._clear_plot_tabs()

        try:

            import matplotlib.pyplot as plt

            plt.close("all")

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    def save_and_close(self):
        """Save and close.
        Used when persisting and close to storage."""

        settings["window_geometry"] = getattr(
            self, "_last_normal_geometry", self.geometry()
        )

        args = self._collect_plot_args()

        self._save_settings_dict(args)
        try:
            self._flush_save_settings()
        except Exception:
            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        after_id = getattr(self, "_initial_tab_after_id", None)
        if after_id is not None:
            try:
                self.after_cancel(after_id)
            except Exception:
                # Best-effort guard; ignore failures to avoid interrupting the workflow.
                pass
            self._initial_tab_after_id = None

        try:

            plt.close("all")  # close every Matplotlib figure

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        self.quit()  # end the Tk event loop

        self.destroy()

    def _save_settings_dict(self, args_tuple):
        """Save settings dict.
        Used when persisting settings dict to storage."""

        (
            min_time,
            max_time,
            min_y,
            max_y,
            twin_y_min,
            twin_y_max,
            deriv_y_min,
            deriv_y_max,
            auto_time_ticks,
            auto_y_ticks,
            auto_temp_ticks,
            auto_deriv_ticks,
            title_text,
            suptitle_text,
            xmaj_tick,
            xmin_tick,
            ymaj_tick,
            ymin_tick,
            twin_maj_tick,
            twin_min_tick,
            deriv_maj_tick,
            deriv_min_tick,
            enable_temp_axis,
            enable_deriv_axis,
            min_cycle_drop,
            peak_prominence,
            peak_distance,
            peak_width,
            show_cycle_markers_on_core_plots,
            show_cycle_legend_on_core_plots,
            include_moles_in_core_plot_legend,
        ) = args_tuple

        settings["min_time"] = min_time

        settings["max_time"] = max_time

        settings["min_y"] = min_y

        settings["max_y"] = max_y

        settings["twin_y_min"] = twin_y_min

        settings["twin_y_max"] = twin_y_max

        settings["deriv_y_min"] = deriv_y_min

        settings["deriv_y_max"] = deriv_y_max

        settings["title_text"] = title_text

        settings["suptitle_text"] = suptitle_text

        auto_template = (self.auto_title_template_var.get() or "").strip()
        if not auto_template:
            auto_template = DEFAULT_AUTO_TITLE_TEMPLATE
        auto_source = (self.auto_title_source_var.get() or "").strip().lower()
        if auto_source not in AUTO_TITLE_SOURCES:
            auto_source = AUTO_TITLE_SOURCE_FULL
        auto_day_mode = (self.auto_title_day_mode_var.get() or "").strip().lower()
        if auto_day_mode not in AUTO_TITLE_DAY_MODES:
            auto_day_mode = AUTO_TITLE_DAY_DIFF
        settings["auto_title_enabled"] = bool(self.auto_title_enabled_var.get())
        settings["auto_title_template"] = auto_template
        settings["auto_title_source"] = auto_source
        settings["auto_title_day_mode"] = auto_day_mode
        settings["title_data_types"] = list(self._get_title_type_choices())
        settings["title_selected_type"] = self._resolve_title_type_selection()

        settings["auto_time_ticks"] = auto_time_ticks

        settings["auto_y_ticks"] = auto_y_ticks

        settings["auto_temp_ticks"] = auto_temp_ticks

        settings["auto_deriv_ticks"] = auto_deriv_ticks

        settings["x_major_tick"] = xmaj_tick

        settings["x_minor_tick"] = xmin_tick

        settings["y_major_tick"] = ymaj_tick

        settings["y_minor_tick"] = ymin_tick

        settings["temp_major_tick"] = twin_maj_tick

        settings["temp_minor_tick"] = twin_min_tick

        settings["deriv_major_tick"] = deriv_maj_tick

        settings["deriv_minor_tick"] = deriv_min_tick

        settings["enable_temp_axis"] = enable_temp_axis

        settings["enable_deriv_axis"] = enable_deriv_axis

        settings["min_cycle_drop"] = min_cycle_drop

        settings["vdw_gas"] = self.v_gas.get()

        current_gas_molar_mass = self.v_gas_molar_mass.get()

        settings["vdw_gas_molar_mass"] = current_gas_molar_mass

        if settings["vdw_gas"]:
            overrides = self._gas_preset_overrides.setdefault(settings["vdw_gas"], {})
            overrides["molar_mass"] = current_gas_molar_mass

        settings["gas_preset_overrides"] = {
            name: dict(config) for name, config in self._gas_preset_overrides.items()
        }

        # persist file + sheet

        if self.file_path:

            settings["last_file_path"] = self.file_path

        if self.selected_sheet.get():

            settings["last_sheet_name"] = self.selected_sheet.get()

        settings["multi_sheet_enabled"] = bool(self.multi_sheet_enabled)
        settings["selected_sheets"] = list(self.selected_sheets)

        # also persist columns & VDW values

        settings["columns"] = self.columns

        settings["vessel_volume"] = self.v_volume.get()

        settings["vdw_a"] = self.v_a.get()

        settings["vdw_b"] = self.v_b.get()

        settings["starting_material_mass_g"] = self.v_starting_mass.get()

        settings["starting_mass"] = self.v_starting_mass.get()

        settings["naoh_mass"] = self.v_starting_mass.get()

        settings["starting_material_preset"] = self.v_product_preset.get()
        starting_display_name = self.v_starting_material_display_name.get().strip()
        starting_display_note = self.v_starting_material_display_note.get().strip()
        settings["starting_material_display_name"] = starting_display_name
        settings["starting_material_display_note"] = starting_display_note

        settings["starting_material_mw_g_mol"] = self.v_product_molar_mass.get()

        settings["stoich_mol_gas_per_mol_starting"] = self.v_starting_stoich.get()

        settings["include_moles_legend"] = self.include_moles_legend.get()
        settings["show_cycle_markers_on_core_plots"] = bool(
            show_cycle_markers_on_core_plots
        )
        settings["show_cycle_legend_on_core_plots"] = bool(
            show_cycle_legend_on_core_plots
        )
        settings["include_moles_in_core_plot_legend"] = bool(
            include_moles_in_core_plot_legend
        )
        settings["show_contamination_tab"] = bool(self._contamination_tab_visible)
        settings["show_solubility_tab"] = bool(self._solubility_tab_visible)
        settings["show_solubility_new_tab"] = bool(self._solubility_new_tab_visible)
        settings["solubility_model_key"] = getattr(
            self, "_sol_model_key", DEFAULT_SPEC_MODEL_KEY
        )
        settings["cycle_auto_detect_enabled"] = bool(self.auto_detect_cycles.get())
        settings["summary_compact"] = bool(self.summary_compact.get())
        settings["summary_include_diagnostics"] = bool(
            self.summary_include_diagnostics.get()
        )
        settings["summary_include_per_cycle_gas_mass"] = bool(
            self.summary_include_per_cycle_gas_mass.get()
        )
        settings["summary_include_conversion_estimate"] = bool(
            self.summary_include_conversion_estimate.get()
        )
        settings["ui_font_size"] = getattr(
            self, "_base_font_size", getattr(self, "_default_font_size", 10)
        )

        scatter_settings = self._gather_scatter_settings()
        settings["scatter_enabled"] = scatter_settings["enabled"]
        settings["scatter_marker"] = scatter_settings["marker"]
        settings["scatter_size"] = scatter_settings["size"]
        settings["scatter_color"] = scatter_settings["color"]
        settings["scatter_alpha"] = scatter_settings["alpha"]
        settings["scatter_edgecolor"] = scatter_settings["edgecolor"]
        settings["scatter_linewidth"] = scatter_settings["linewidth"]
        settings["scatter_series"] = self._gather_series_scatter_settings()

        cycle_temp_value = self.cycle_temp_column.get() or CYCLE_TEMP_DEFAULT_LABEL

        settings["cycle_temp_column"] = cycle_temp_value
        settings["cycle_trace"] = {
            key: cycle_trace_settings[key] for key in DEFAULT_CYCLE_TRACE_SETTINGS
        }

        settings["peak_prominence"] = peak_prominence

        settings["peak_distance"] = peak_distance

        settings["peak_width"] = peak_width

        settings["axis_pad_pct"] = self._safe_get_var(self.axis_pad_pct, float)
        settings["axis_auto_range"] = self._get_axis_auto_range_flags()

        settings["combined_deriv_axis_offset"] = self._safe_get_var(
            self.combined_deriv_axis_offset, float
        )

        # NEW: persist manual cycle markers if the Cycle tab has been used

        try:

            settings["cycle_manual_add_peaks"] = sorted(
                int(i) for i in getattr(self, "_add_peaks", set())
            )

            settings["cycle_manual_add_troughs"] = sorted(
                int(i) for i in getattr(self, "_add_troughs", set())
            )

            settings["cycle_manual_remove_peaks"] = sorted(
                int(i) for i in getattr(self, "_rm_peaks", set())
            )

            settings["cycle_manual_remove_troughs"] = sorted(
                int(i) for i in getattr(self, "_rm_troughs", set())
            )

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        # Persist the Cycle Analysis splitter position as a fraction of the PanedWindow width

        try:

            pw = getattr(self, "_cycle_paned", None)

            if pw is not None and pw.winfo_exists():

                tot = pw.winfo_width()

                if tot > 1:

                    settings["cycle_split_frac"] = pw.sashpos(0) / tot

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

        if getattr(self, "_cycle_legend_anchor", None):

            settings["cycle_legend_anchor"] = [
                float(self._cycle_legend_anchor[0]),
                float(self._cycle_legend_anchor[1]),
            ]

        settings["custom_gas_presets"] = {
            name: dict(config) for name, config in CUSTOM_GAS_PRESETS.items()
        }
        settings["combined_y_left_key"] = self.combined_y_left_key.get()
        settings["combined_y_right_key"] = self.combined_y_right_key.get()
        settings["combined_y_third_key"] = self.combined_y_third_key.get()
        settings["combined_center_plot_legend"] = bool(
            self.center_combined_plot_legend.get()
        )
        anchor = getattr(self, "_combined_legend_anchor", None)
        if anchor and len(anchor) >= 2:
            try:
                settings["combined_legend_anchor"] = [
                    float(anchor[0]),
                    float(anchor[1]),
                ]
            except Exception:
                settings.pop("combined_legend_anchor", None)
        else:
            settings.pop("combined_legend_anchor", None)
        legend_loc_value = _normalize_legend_loc_value(
            getattr(self, "_combined_legend_loc", None)
        )
        if legend_loc_value is not None and anchor and len(anchor) >= 2:
            settings["combined_legend_loc"] = legend_loc_value
        else:
            settings.pop("combined_legend_loc", None)
        cycle_anchor = getattr(self, "_combined_cycle_legend_anchor", None)
        if cycle_anchor and len(cycle_anchor) >= 2:
            try:
                settings["combined_cycle_legend_anchor"] = [
                    float(cycle_anchor[0]),
                    float(cycle_anchor[1]),
                ]
            except Exception:
                settings.pop("combined_cycle_legend_anchor", None)
        else:
            settings.pop("combined_cycle_legend_anchor", None)
        cycle_loc_value = _normalize_legend_loc_value(
            getattr(self, "_combined_cycle_legend_loc", None)
        )
        if cycle_loc_value is not None and cycle_anchor and len(cycle_anchor) >= 2:
            settings["combined_cycle_legend_loc"] = cycle_loc_value
        else:
            settings.pop("combined_cycle_legend_loc", None)
        cycle_anchor_space = getattr(self, "_combined_cycle_legend_anchor_space", None)
        if (
            cycle_anchor_space in {"figure", "axes"}
            and cycle_anchor
            and len(cycle_anchor) >= 2
        ):
            settings["combined_cycle_legend_anchor_space"] = cycle_anchor_space
        else:
            settings.pop("combined_cycle_legend_anchor_space", None)
        settings["combined_cycle_legend_ref_axis"] = _normalize_combined_cycle_ref_axis(
            self.combined_cycle_legend_ref_axis.get()
        )
        settings[
            "combined_cycle_legend_ref_corner"
        ] = _normalize_combined_cycle_ref_corner(
            self.combined_cycle_legend_ref_corner.get()
        )
        if isinstance(cycle_loc_value, tuple):
            anchor_mode_value = "loc_tuple"
        elif _combined_cycle_axis_offset_values() is not None:
            anchor_mode_value = "axis_offset"
        else:
            anchor_mode_value = "legacy_anchor"
        settings["combined_cycle_legend_anchor_mode"] = anchor_mode_value
        settings["core_plot_render_profiles"] = _normalize_core_plot_render_profiles(
            settings.get("core_plot_render_profiles"),
            seed_source=settings,
        )
        _legacy_core_profile = settings["core_plot_render_profiles"].get(
            CORE_RENDER_PROFILE_PLOT_IDS[0]
        )
        _write_legacy_core_legend_settings_from_profile(_legacy_core_profile)

        _save_settings_to_disk()


# -----------------------------

# Launch the unified app

# -----------------------------

# TEMP sanity check

if __name__ == "__main__":

    if "--debug-validate-svg" in sys.argv[1:]:
        success, svg_path = _debug_validate_svg_export()
        status = "passed" if success else "failed"
        print(f"SVG validation {status}: {svg_path}")
        sys.exit(0)

    if os.environ.get("RUN_SOLUBILITY_REGRESSION") == "1":
        # Iterate over REGRESSION_TESTS to apply the per-item logic.
        for name, fn in REGRESSION_TESTS:
            print(f"Running regression: {name}")
            fn()
        sys.exit(0)

    if os.environ.get("RUN_PITZER_TESTS") == "1":
        _run_naoh_pitzer_internal_tests()
        _integration_test_planning_pitzer_smoke()
        sys.exit(0)

    if os.environ.get("RUN_TIMELINE_TABLE_EXPORT_TEST") == "1":
        success, out_dir, outputs, errors = _dev_test_timeline_table_export()
        status = "passed" if success else "failed"
        detail = f"{out_dir} ({len(outputs)} file(s))"
        if errors:
            detail = f"{detail} | Errors: {'; '.join(errors)}"
        print(f"Timeline table export test {status}: {detail}")
        sys.exit(0 if success else 1)

    if _maybe_run_cli_benchmark(sys.argv[1:]):

        sys.exit(0)

    app = None
    try:
        app = UnifiedApp()
        app.mainloop()
    except Exception:
        # Tear down partially initialized Tk roots so pending `after(...)`
        # callbacks do not fire against destroyed commands during startup failure.
        try:
            if app is not None:
                app.destroy()
            else:
                default_root = getattr(tk, "_default_root", None)
                if default_root is not None:
                    default_root.destroy()
        except Exception:
            # Best-effort guard; ignore failures to avoid masking root cause.
            pass
        raise
    finally:
        try:

            plt.close("all")

        except Exception:

            # Best-effort guard; ignore failures to avoid interrupting the workflow.
            pass

    sys.exit(0)
